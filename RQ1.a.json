[
    {
        "id": 56,
        "method": "private void createSampleData(String username, String password) {\n\t\tAssert.notNull(documentDao, \"DocumentDao required\");\n\t\tAssert.hasText(username, \"Username required\");\n\n\t\tAuthentication auth = new UsernamePasswordAuthenticationToken(username, password);\n\n\t\ttry {\n\t\t\t// Set the SecurityContextHolder ThreadLocal so any subclasses\n\t\t\t// automatically know which user is operating\n\t\t\tSecurityContextHolder.getContext().setAuthentication(auth);\n\n\t\t\t\t\t\tDirectory home = new Directory(username, Directory.ROOT_DIRECTORY);\n\t\t\tdocumentDao.create(home);\n\t\t\taddPermission(documentDao, home, username, LEVEL_GRANT_ADMIN);\n\t\t\taddPermission(documentDao, home, \"ROLE_USER\", LEVEL_GRANT_READ);\n\t\t\tcreateFiles(documentDao, home);\n\n\t\t\t// Now create the confidential directory\n\t\t\tDirectory confid = new Directory(\"confidential\", home);\n\t\t\tdocumentDao.create(confid);\n\t\t\taddPermission(documentDao, confid, \"ROLE_USER\", LEVEL_NEGATE_READ);\n\t\t\tcreateFiles(documentDao, confid);\n\n\t\t\t// Now create the shared directory\n\t\t\tDirectory shared = new Directory(\"shared\", home);\n\t\t\tdocumentDao.create(shared);\n\t\t\taddPermission(documentDao, shared, \"ROLE_USER\", LEVEL_GRANT_READ);\n\t\t\taddPermission(documentDao, shared, \"ROLE_USER\", LEVEL_GRANT_WRITE);\n\t\t\tcreateFiles(documentDao, shared);\n\t\t}\n\t\tfinally {\n\t\t\t// Clear the SecurityContextHolder ThreadLocal so future calls are\n\t\t\t// guaranteed to be clean\n\t\t\tSecurityContextHolder.clearContext();\n\t\t}\n\t}",
        "variable": "home",
        "reference": "the home directory",
        "explanation_by_ours": "the home directory",
        "explanation_by_baseline": "the home directory{"
    },
    {
        "id": 57,
        "method": "private void createSampleData(String username, String password) {\n\t\tAssert.notNull(documentDao, \"DocumentDao required\");\n\t\tAssert.hasText(username, \"Username required\");\n\n\t\tAuthentication auth = new UsernamePasswordAuthenticationToken(username, password);\n\n\t\ttry {\n\t\t\t// Set the SecurityContextHolder ThreadLocal so any subclasses\n\t\t\t// automatically know which user is operating\n\t\t\tSecurityContextHolder.getContext().setAuthentication(auth);\n\n\t\t\t// Create the home directory first\n\t\t\tDirectory home = new Directory(username, Directory.ROOT_DIRECTORY);\n\t\t\tdocumentDao.create(home);\n\t\t\taddPermission(documentDao, home, username, LEVEL_GRANT_ADMIN);\n\t\t\taddPermission(documentDao, home, \"ROLE_USER\", LEVEL_GRANT_READ);\n\t\t\tcreateFiles(documentDao, home);\n\n\t\t\t\t\t\tDirectory confid = new Directory(\"confidential\", home);\n\t\t\tdocumentDao.create(confid);\n\t\t\taddPermission(documentDao, confid, \"ROLE_USER\", LEVEL_NEGATE_READ);\n\t\t\tcreateFiles(documentDao, confid);\n\n\t\t\t// Now create the shared directory\n\t\t\tDirectory shared = new Directory(\"shared\", home);\n\t\t\tdocumentDao.create(shared);\n\t\t\taddPermission(documentDao, shared, \"ROLE_USER\", LEVEL_GRANT_READ);\n\t\t\taddPermission(documentDao, shared, \"ROLE_USER\", LEVEL_GRANT_WRITE);\n\t\t\tcreateFiles(documentDao, shared);\n\t\t}\n\t\tfinally {\n\t\t\t// Clear the SecurityContextHolder ThreadLocal so future calls are\n\t\t\t// guaranteed to be clean\n\t\t\tSecurityContextHolder.clearContext();\n\t\t}\n\t}",
        "variable": "confid",
        "reference": "the confidential directory",
        "explanation_by_ours": "the confidential directory",
        "explanation_by_baseline": "the confidential directory"
    },
    {
        "id": 58,
        "method": "private void createSampleData(String username, String password) {\n\t\tAssert.notNull(documentDao, \"DocumentDao required\");\n\t\tAssert.hasText(username, \"Username required\");\n\n\t\tAuthentication auth = new UsernamePasswordAuthenticationToken(username, password);\n\n\t\ttry {\n\t\t\t// Set the SecurityContextHolder ThreadLocal so any subclasses\n\t\t\t// automatically know which user is operating\n\t\t\tSecurityContextHolder.getContext().setAuthentication(auth);\n\n\t\t\t// Create the home directory first\n\t\t\tDirectory home = new Directory(username, Directory.ROOT_DIRECTORY);\n\t\t\tdocumentDao.create(home);\n\t\t\taddPermission(documentDao, home, username, LEVEL_GRANT_ADMIN);\n\t\t\taddPermission(documentDao, home, \"ROLE_USER\", LEVEL_GRANT_READ);\n\t\t\tcreateFiles(documentDao, home);\n\n\t\t\t// Now create the confidential directory\n\t\t\tDirectory confid = new Directory(\"confidential\", home);\n\t\t\tdocumentDao.create(confid);\n\t\t\taddPermission(documentDao, confid, \"ROLE_USER\", LEVEL_NEGATE_READ);\n\t\t\tcreateFiles(documentDao, confid);\n\n\t\t\t\t\t\tDirectory shared = new Directory(\"shared\", home);\n\t\t\tdocumentDao.create(shared);\n\t\t\taddPermission(documentDao, shared, \"ROLE_USER\", LEVEL_GRANT_READ);\n\t\t\taddPermission(documentDao, shared, \"ROLE_USER\", LEVEL_GRANT_WRITE);\n\t\t\tcreateFiles(documentDao, shared);\n\t\t}\n\t\tfinally {\n\t\t\t// Clear the SecurityContextHolder ThreadLocal so future calls are\n\t\t\t// guaranteed to be clean\n\t\t\tSecurityContextHolder.clearContext();\n\t\t}\n\t}",
        "variable": "shared",
        "reference": "the shared directory",
        "explanation_by_ours": "the shared",
        "explanation_by_baseline": "the shared directory{"
    },
    {
        "id": 68,
        "method": "protected void registerPublicPermissions(Class<? extends Permission> clazz) {\n\t\tAssert.notNull(clazz, \"Class required\");\n\n\t\tField[] fields = clazz.getFields();\n\n\t\tfor (Field field : fields) {\n\t\t\ttry {\n\t\t\t\tObject fieldValue = field.get(null);\n\n\t\t\t\tif (Permission.class.isAssignableFrom(fieldValue.getClass())) {\n\t\t\t\t\t\t\t\t\t\tPermission perm = (Permission) fieldValue;\n\t\t\t\t\tString permissionName = field.getName();\n\n\t\t\t\t\tregisterPermission(perm, permissionName);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (Exception ignore) {\n\t\t\t}\n\t\t}\n\t}",
        "variable": "perm",
        "reference": "a Permission static field",
        "explanation_by_ours": "the permission to register",
        "explanation_by_baseline": "permission.(Field"
    },
    {
        "id": 71,
        "method": "private BeanReference createFilterChain(Element element, ParserContext pc) {\n\t\tboolean secured = !OPT_SECURITY_NONE.equals(element.getAttribute(ATT_SECURED));\n\n\t\tif (!secured) {\n\t\t\tif (!StringUtils.hasText(element.getAttribute(ATT_PATH_PATTERN))\n\t\t\t\t\t&& !StringUtils.hasText(ATT_REQUEST_MATCHER_REF)) {\n\t\t\t\tpc.getReaderContext().error(\n\t\t\t\t\t\t\"The '\" + ATT_SECURED\n\t\t\t\t\t\t\t\t+ \"' attribute must be used in combination with\"\n\t\t\t\t\t\t\t\t+ \" the '\" + ATT_PATH_PATTERN + \"' or '\"\n\t\t\t\t\t\t\t\t+ ATT_REQUEST_MATCHER_REF + \"' attributes.\",\n\t\t\t\t\t\tpc.extractSource(element));\n\t\t\t}\n\n\t\t\tfor (int n = 0; n < element.getChildNodes().getLength(); n++) {\n\t\t\t\tif (element.getChildNodes().item(n) instanceof Element) {\n\t\t\t\t\tpc.getReaderContext().error(\n\t\t\t\t\t\t\t\"If you are using <http> to define an unsecured pattern, \"\n\t\t\t\t\t\t\t\t\t+ \"it cannot contain child elements.\",\n\t\t\t\t\t\t\tpc.extractSource(element));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn createSecurityFilterChainBean(element, pc, Collections.emptyList());\n\t\t}\n\n\t\tfinal BeanReference portMapper = createPortMapper(element, pc);\n\t\tfinal BeanReference portResolver = createPortResolver(portMapper, pc);\n\n\t\tManagedList<BeanReference> authenticationProviders = new ManagedList<>();\n\t\tBeanReference authenticationManager = createAuthenticationManager(element, pc,\n\t\t\t\tauthenticationProviders);\n\n\t\tboolean forceAutoConfig = isDefaultHttpConfig(element);\n\t\tHttpConfigurationBuilder httpBldr = new HttpConfigurationBuilder(element,\n\t\t\t\tforceAutoConfig, pc, portMapper, portResolver, authenticationManager);\n\n\t\tAuthenticationConfigBuilder authBldr = new AuthenticationConfigBuilder(element,\n\t\t\t\tforceAutoConfig, pc, httpBldr.getSessionCreationPolicy(),\n\t\t\t\thttpBldr.getRequestCache(), authenticationManager,\n\t\t\t\thttpBldr.getSessionStrategy(), portMapper, portResolver,\n\t\t\t\thttpBldr.getCsrfLogoutHandler());\n\n\t\thttpBldr.setLogoutHandlers(authBldr.getLogoutHandlers());\n\t\thttpBldr.setEntryPoint(authBldr.getEntryPointBean());\n\t\thttpBldr.setAccessDeniedHandler(authBldr.getAccessDeniedHandlerBean());\n\n\t\tauthenticationProviders.addAll(authBldr.getProviders());\n\n\t\tList<OrderDecorator> unorderedFilterChain = new ArrayList<>();\n\n\t\tunorderedFilterChain.addAll(httpBldr.getFilters());\n\t\tunorderedFilterChain.addAll(authBldr.getFilters());\n\t\tunorderedFilterChain.addAll(buildCustomFilterList(element, pc));\n\n\t\tCollections.sort(unorderedFilterChain, new OrderComparator());\n\t\tcheckFilterChainOrder(unorderedFilterChain, pc, pc.extractSource(element));\n\n\t\t\t\tList<BeanMetadataElement> filterChain = new ManagedList<>();\n\n\t\tfor (OrderDecorator od : unorderedFilterChain) {\n\t\t\tfilterChain.add(od.bean);\n\t\t}\n\n\t\treturn createSecurityFilterChainBean(element, pc, filterChain);\n\t}",
        "variable": "filterChain",
        "reference": "The chain of filter beans",
        "explanation_by_ours": "the filter chain",
        "explanation_by_baseline": ") { if ()"
    },
    {
        "id": 74,
        "method": "protected Authentication attemptExitUser(HttpServletRequest request)\n\t\t\tthrows AuthenticationCredentialsNotFoundException {\n\t\t// need to check to see if the current user has a SwitchUserGrantedAuthority\n\t\tAuthentication current = SecurityContextHolder.getContext().getAuthentication();\n\n\t\tif (null == current) {\n\t\t\tthrow new AuthenticationCredentialsNotFoundException(\n\t\t\t\t\tthis.messages.getMessage(\"SwitchUserFilter.noCurrentUser\",\n\t\t\t\t\t\t\t\"No current user associated with this request\"));\n\t\t}\n\n\t\t// check to see if the current user did actual switch to another user\n\t\t// if so, get the original source user so we can switch back\n\t\tAuthentication original = getSourceAuthentication(current);\n\n\t\tif (original == null) {\n\t\t\tthis.logger.debug(\"Could not find original user Authentication object!\");\n\t\t\tthrow new AuthenticationCredentialsNotFoundException(\n\t\t\t\t\tthis.messages.getMessage(\"SwitchUserFilter.noOriginalAuthentication\",\n\t\t\t\t\t\t\t\"Could not find original Authentication object\"));\n\t\t}\n\n\t\t\t\tUserDetails originalUser = null;\n\t\tObject obj = original.getPrincipal();\n\n\t\tif ((obj != null) && obj instanceof UserDetails) {\n\t\t\toriginalUser = (UserDetails) obj;\n\t\t}\n\n\t\t// publish event\n\t\tif (this.eventPublisher != null) {\n\t\t\tthis.eventPublisher.publishEvent(\n\t\t\t\t\tnew AuthenticationSwitchUserEvent(current, originalUser));\n\t\t}\n\n\t\treturn original;\n\t}",
        "variable": "originalUser",
        "reference": "the original user details",
        "explanation_by_ours": "the original user",
        "explanation_by_baseline": "if (this.eventPublisher"
    },
    {
        "id": 75,
        "method": "private UsernamePasswordAuthenticationToken createSwitchUserToken(\n\t\t\tHttpServletRequest request, UserDetails targetUser) {\n\n\t\tUsernamePasswordAuthenticationToken targetUserRequest;\n\n\t\t// grant an additional authority that contains the original Authentication object\n\t\t// which will be used to 'exit' from the current switched user.\n\n\t\tAuthentication currentAuth;\n\n\t\ttry {\n\t\t\t// SEC-1763. Check first if we are already switched.\n\t\t\tcurrentAuth = attemptExitUser(request);\n\t\t}\n\t\tcatch (AuthenticationCredentialsNotFoundException e) {\n\t\t\tcurrentAuth = SecurityContextHolder.getContext().getAuthentication();\n\t\t}\n\n\t\tGrantedAuthority switchAuthority = new SwitchUserGrantedAuthority(\n\t\t\t\tthis.switchAuthorityRole, currentAuth);\n\n\t\t\t\tCollection<? extends GrantedAuthority> orig = targetUser.getAuthorities();\n\n\t\t// Allow subclasses to change the authorities to be granted\n\t\tif (this.switchUserAuthorityChanger != null) {\n\t\t\torig = this.switchUserAuthorityChanger.modifyGrantedAuthorities(targetUser,\n\t\t\t\t\tcurrentAuth, orig);\n\t\t}\n\n\t\t// add the new switch user authority\n\t\tList<GrantedAuthority> newAuths = new ArrayList<>(orig);\n\t\tnewAuths.add(switchAuthority);\n\n\t\t// create the new authentication token\n\t\ttargetUserRequest = new UsernamePasswordAuthenticationToken(targetUser,\n\t\t\t\ttargetUser.getPassword(), newAuths);\n\n\t\t// set details\n\t\ttargetUserRequest\n\t\t\t\t.setDetails(this.authenticationDetailsSource.buildDetails(request));\n\n\t\treturn targetUserRequest;\n\t}",
        "variable": "orig",
        "reference": "the original authorities",
        "explanation_by_ours": "the original authorities",
        "explanation_by_baseline": "the original user authorities"
    },
    {
        "id": 76,
        "method": "private UsernamePasswordAuthenticationToken createSwitchUserToken(\n\t\t\tHttpServletRequest request, UserDetails targetUser) {\n\n\t\tUsernamePasswordAuthenticationToken targetUserRequest;\n\n\t\t// grant an additional authority that contains the original Authentication object\n\t\t// which will be used to 'exit' from the current switched user.\n\n\t\tAuthentication currentAuth;\n\n\t\ttry {\n\t\t\t// SEC-1763. Check first if we are already switched.\n\t\t\tcurrentAuth = attemptExitUser(request);\n\t\t}\n\t\tcatch (AuthenticationCredentialsNotFoundException e) {\n\t\t\tcurrentAuth = SecurityContextHolder.getContext().getAuthentication();\n\t\t}\n\n\t\tGrantedAuthority switchAuthority = new SwitchUserGrantedAuthority(\n\t\t\t\tthis.switchAuthorityRole, currentAuth);\n\n\t\t// get the original authorities\n\t\tCollection<? extends GrantedAuthority> orig = targetUser.getAuthorities();\n\n\t\t// Allow subclasses to change the authorities to be granted\n\t\tif (this.switchUserAuthorityChanger != null) {\n\t\t\torig = this.switchUserAuthorityChanger.modifyGrantedAuthorities(targetUser,\n\t\t\t\t\tcurrentAuth, orig);\n\t\t}\n\n\t\t\t\tList<GrantedAuthority> newAuths = new ArrayList<>(orig);\n\t\tnewAuths.add(switchAuthority);\n\n\t\t// create the new authentication token\n\t\ttargetUserRequest = new UsernamePasswordAuthenticationToken(targetUser,\n\t\t\t\ttargetUser.getPassword(), newAuths);\n\n\t\t// set details\n\t\ttargetUserRequest\n\t\t\t\t.setDetails(this.authenticationDetailsSource.buildDetails(request));\n\n\t\treturn targetUserRequest;\n\t}",
        "variable": "newAuths",
        "reference": "the new switch user authority",
        "explanation_by_ours": "the new authorities",
        "explanation_by_baseline": "the new authorities{"
    },
    {
        "id": 79,
        "method": "private void buildRolesReachableInOneOrMoreStepsMap() {\n\t\tthis.rolesReachableInOneOrMoreStepsMap = new HashMap<>();\n\t\t// iterate over all higher roles from rolesReachableInOneStepMap\n\n\t\tfor (GrantedAuthority role : this.rolesReachableInOneStepMap.keySet()) {\n\t\t\tSet<GrantedAuthority> rolesToVisitSet = new HashSet<>();\n\n\t\t\tif (this.rolesReachableInOneStepMap.containsKey(role)) {\n\t\t\t\trolesToVisitSet.addAll(this.rolesReachableInOneStepMap.get(role));\n\t\t\t}\n\n\t\t\tSet<GrantedAuthority> visitedRolesSet = new HashSet<>();\n\n\t\t\twhile (!rolesToVisitSet.isEmpty()) {\n\t\t\t\t\t\t\t\tGrantedAuthority aRole = rolesToVisitSet.iterator().next();\n\t\t\t\trolesToVisitSet.remove(aRole);\n\t\t\t\taddReachableRoles(visitedRolesSet, aRole);\n\t\t\t\tif (this.rolesReachableInOneStepMap.containsKey(aRole)) {\n\t\t\t\t\tSet<GrantedAuthority> newReachableRoles = this.rolesReachableInOneStepMap\n\t\t\t\t\t\t\t.get(aRole);\n\n\t\t\t\t\t// definition of a cycle: you can reach the role you are starting from\n\t\t\t\t\tif (rolesToVisitSet.contains(role)\n\t\t\t\t\t\t\t|| visitedRolesSet.contains(role)) {\n\t\t\t\t\t\tthrow new CycleInRoleHierarchyException();\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\t// no cycle\n\t\t\t\t\t\trolesToVisitSet.addAll(newReachableRoles);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis.rolesReachableInOneOrMoreStepsMap.put(role, visitedRolesSet);\n\n\t\t\tlogger.debug(\"buildRolesReachableInOneOrMoreStepsMap() - From role \" + role\n\t\t\t\t\t+ \" one can reach \" + visitedRolesSet + \" in one or more steps.\");\n\t\t}\n\n\t}",
        "variable": "aRole",
        "reference": "a role from the rolesToVisit set",
        "explanation_by_ours": "the role you are starting from.",
        "explanation_by_baseline": "the next role from rolesTo"
    },
    {
        "id": 85,
        "method": "public void onAuthentication(Authentication authentication,\n\t\t\tHttpServletRequest request, HttpServletResponse response) {\n\t\tboolean hadSessionAlready = request.getSession(false) != null;\n\n\t\tif (!hadSessionAlready && !alwaysCreateSession) {\n\t\t\t// Session fixation isn't a problem if there's no session\n\n\t\t\treturn;\n\t\t}\n\n\t\t\t\tHttpSession session = request.getSession();\n\n\t\tif (hadSessionAlready && request.isRequestedSessionIdValid()) {\n\n\t\t\tString originalSessionId;\n\t\t\tString newSessionId;\n\t\t\tObject mutex = WebUtils.getSessionMutex(session);\n\t\t\tsynchronized (mutex) {\n\t\t\t\t// We need to migrate to a new session\n\t\t\t\toriginalSessionId = session.getId();\n\n\t\t\t\tsession = applySessionFixation(request);\n\t\t\t\tnewSessionId = session.getId();\n\t\t\t}\n\n\t\t\tif (originalSessionId.equals(newSessionId)) {\n\t\t\t\tlogger.warn(\"Your servlet container did not change the session ID when a new session was created. You will\"\n\t\t\t\t\t\t+ \" not be adequately protected against session-fixation attacks\");\n\t\t\t}\n\n\t\t\tonSessionChange(originalSessionId, session, authentication);\n\t\t}\n\t}",
        "variable": "session",
        "reference": "new session",
        "explanation_by_ours": "the session",
        "explanation_by_baseline": "a new sessionif ("
    },
    {
        "id": 108,
        "method": "private boolean decodeHandshake( ByteBuffer socketBufferNew ) {\n\t\tByteBuffer socketBuffer;\n\t\tif( tmpHandshakeBytes.capacity() == 0 ) {\n\t\t\tsocketBuffer = socketBufferNew;\n\t\t} else {\n\t\t\tif( tmpHandshakeBytes.remaining() < socketBufferNew.remaining() ) {\n\t\t\t\tByteBuffer buf = ByteBuffer.allocate( tmpHandshakeBytes.capacity() + socketBufferNew.remaining() );\n\t\t\t\ttmpHandshakeBytes.flip();\n\t\t\t\tbuf.put( tmpHandshakeBytes );\n\t\t\t\ttmpHandshakeBytes = buf;\n\t\t\t}\n\n\t\t\ttmpHandshakeBytes.put( socketBufferNew );\n\t\t\ttmpHandshakeBytes.flip();\n\t\t\tsocketBuffer = tmpHandshakeBytes;\n\t\t}\n\t\tsocketBuffer.mark();\n\t\ttry {\n\t\t\tHandshakeState handshakestate;\n\t\t\ttry {\n\t\t\t\tif( role == Role.SERVER ) {\n\t\t\t\t\tif( draft == null ) {\n\t\t\t\t\t\tfor( Draft d : knownDrafts ) {\n\t\t\t\t\t\t\td = d.copyInstance();\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\td.setParseMode( role );\n\t\t\t\t\t\t\t\tsocketBuffer.reset();\n\t\t\t\t\t\t\t\tHandshakedata tmphandshake = d.translateHandshake( socketBuffer );\n\t\t\t\t\t\t\t\tif( !( tmphandshake instanceof ClientHandshake ) ) {\n\t\t\t\t\t\t\t\t\tlog.trace(\"Closing due to wrong handshake\");\n\t\t\t\t\t\t\t\t\tcloseConnectionDueToWrongHandshake( new InvalidDataException( CloseFrame.PROTOCOL_ERROR, \"wrong http function\" ) );\n\t\t\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tClientHandshake handshake = ( ClientHandshake ) tmphandshake;\n\t\t\t\t\t\t\t\thandshakestate = d.acceptHandshakeAsServer( handshake );\n\t\t\t\t\t\t\t\tif( handshakestate == HandshakeState.MATCHED ) {\n\t\t\t\t\t\t\t\t\tresourceDescriptor = handshake.getResourceDescriptor();\n\t\t\t\t\t\t\t\t\tServerHandshakeBuilder response;\n\t\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\t\tresponse = wsl.onWebsocketHandshakeReceivedAsServer( this, d, handshake );\n\t\t\t\t\t\t\t\t\t} catch ( InvalidDataException e ) {\n\t\t\t\t\t\t\t\t\t\tlog.trace(\"Closing due to wrong handshake. Possible handshake rejection\", e);\n\t\t\t\t\t\t\t\t\t\tcloseConnectionDueToWrongHandshake( e );\n\t\t\t\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\t\t\t\t} catch ( RuntimeException e ) {\n\t\t\t\t\t\t\t\t\t\tlog.error(\"Closing due to internal server error\", e);\n\t\t\t\t\t\t\t\t\t\twsl.onWebsocketError( this, e );\n\t\t\t\t\t\t\t\t\t\tcloseConnectionDueToInternalServerError( e );\n\t\t\t\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\twrite( d.createHandshake( d.postProcessHandshakeResponseAsServer( handshake, response ) ) );\n\t\t\t\t\t\t\t\t\tdraft = d;\n\t\t\t\t\t\t\t\t\topen( handshake );\n\t\t\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} catch ( InvalidHandshakeException e ) {\n\t\t\t\t\t\t\t\t// go on with an other draft\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif( draft == null ) {\n\t\t\t\t\t\t\tlog.trace(\"Closing due to protocol error: no draft matches\");\n\t\t\t\t\t\t\tcloseConnectionDueToWrongHandshake( new InvalidDataException( CloseFrame.PROTOCOL_ERROR, \"no draft matches\" ) );\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t\t\tHandshakedata tmphandshake = draft.translateHandshake( socketBuffer );\n\t\t\t\t\t\tif( !( tmphandshake instanceof ClientHandshake ) ) {\n\t\t\t\t\t\t\tlog.trace(\"Closing due to protocol error: wrong http function\");\n\t\t\t\t\t\t\tflushAndClose( CloseFrame.PROTOCOL_ERROR, \"wrong http function\", false );\n\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tClientHandshake handshake = ( ClientHandshake ) tmphandshake;\n\t\t\t\t\t\thandshakestate = draft.acceptHandshakeAsServer( handshake );\n\n\t\t\t\t\t\tif( handshakestate == HandshakeState.MATCHED ) {\n\t\t\t\t\t\t\topen( handshake );\n\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tlog.trace(\"Closing due to protocol error: the handshake did finally not match\");\n\t\t\t\t\t\t\tclose( CloseFrame.PROTOCOL_ERROR, \"the handshake did finally not match\" );\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t}\n\t\t\t\t} else if( role == Role.CLIENT ) {\n\t\t\t\t\tdraft.setParseMode( role );\n\t\t\t\t\tHandshakedata tmphandshake = draft.translateHandshake( socketBuffer );\n\t\t\t\t\tif( !( tmphandshake instanceof ServerHandshake ) ) {\n\t\t\t\t\t\tlog.trace(\"Closing due to protocol error: wrong http function\");\n\t\t\t\t\t\tflushAndClose( CloseFrame.PROTOCOL_ERROR, \"wrong http function\", false );\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t}\n\t\t\t\t\tServerHandshake handshake = ( ServerHandshake ) tmphandshake;\n\t\t\t\t\thandshakestate = draft.acceptHandshakeAsClient( handshakerequest, handshake );\n\t\t\t\t\tif( handshakestate == HandshakeState.MATCHED ) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\twsl.onWebsocketHandshakeReceivedAsClient( this, handshakerequest, handshake );\n\t\t\t\t\t\t} catch ( InvalidDataException e ) {\n\t\t\t\t\t\t\tlog.trace(\"Closing due to invalid data exception. Possible handshake rejection\", e);\n\t\t\t\t\t\t\tflushAndClose( e.getCloseCode(), e.getMessage(), false );\n\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\t} catch ( RuntimeException e ) {\n\t\t\t\t\t\t\tlog.error(\"Closing since client was never connected\", e);\n\t\t\t\t\t\t\twsl.onWebsocketError( this, e );\n\t\t\t\t\t\t\tflushAndClose( CloseFrame.NEVER_CONNECTED, e.getMessage(), false );\n\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\t}\n\t\t\t\t\t\topen( handshake );\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlog.trace(\"Closing due to protocol error: draft {} refuses handshake\", draft );\n\t\t\t\t\t\tclose( CloseFrame.PROTOCOL_ERROR, \"draft \" + draft + \" refuses handshake\" );\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch ( InvalidHandshakeException e ) {\n\t\t\t\tlog.trace(\"Closing due to invalid handshake\", e);\n\t\t\t\tclose( e );\n\t\t\t}\n\t\t} catch ( IncompleteHandshakeException e ) {\n\t\t\tif( tmpHandshakeBytes.capacity() == 0 ) {\n\t\t\t\tsocketBuffer.reset();\n\t\t\t\tint newsize = e.getPreferredSize();\n\t\t\t\tif( newsize == 0 ) {\n\t\t\t\t\tnewsize = socketBuffer.capacity() + 16;\n\t\t\t\t} else {\n\t\t\t\t\tassert ( e.getPreferredSize() >= socketBuffer.remaining() );\n\t\t\t\t}\n\t\t\t\ttmpHandshakeBytes = ByteBuffer.allocate( newsize );\n\n\t\t\t\ttmpHandshakeBytes.put( socketBufferNew );\n\t\t\t\t// tmpHandshakeBytes.flip();\n\t\t\t} else {\n\t\t\t\ttmpHandshakeBytes.position( tmpHandshakeBytes.limit() );\n\t\t\t\ttmpHandshakeBytes.limit( tmpHandshakeBytes.capacity() );\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}",
        "variable": "tmphandshake",
        "reference": "special case for multiple step handshakes",
        "explanation_by_ours": "the tmphandshake",
        "explanation_by_baseline": "go on with another draft"
    },
    {
        "id": 114,
        "method": "public Cookie decode(String header) {\n    if (header == null) {\n      throw new NullPointerException(\"header\");\n    }\n    final int headerLen = header.length();\n\n    if (headerLen == 0) {\n      return null;\n    }\n\n    CookieBuilder cookieBuilder = null;\n\n    loop:\n    for (int i = 0; ; ) {\n\n      // Skip spaces and separators.\n      for (; ; ) {\n        if (i == headerLen) {\n          break loop;\n        }\n        char c = header.charAt(i);\n        if (c == ',') {\n          // Having multiple cookies in a single Set-Cookie header is\n          // deprecated, modern browsers only parse the first one\n          break loop;\n\n        } else if (c == '\\t' || c == '\\n' || c == 0x0b || c == '\\f' || c == '\\r' || c == ' '\n            || c == ';') {\n          i++;\n          continue;\n        }\n        break;\n      }\n\n      int nameBegin = i;\n      int nameEnd = i;\n      int valueBegin = -1;\n      int valueEnd = -1;\n\n      if (i != headerLen) {\n        keyValLoop:\n        for (; ; ) {\n\n          char curChar = header.charAt(i);\n          if (curChar == ';') {\n            // NAME; (no value till ';')\n            nameEnd = i;\n            valueBegin = valueEnd = -1;\n            break keyValLoop;\n\n          } else if (curChar == '=') {\n            // NAME=VALUE\n            nameEnd = i;\n            i++;\n            if (i == headerLen) {\n              // NAME= (empty value, i.e. nothing after '=')\n              valueBegin = valueEnd = 0;\n              break keyValLoop;\n            }\n\n            valueBegin = i;\n            // NAME=VALUE;\n            int semiPos = header.indexOf(';', i);\n            valueEnd = i = semiPos > 0 ? semiPos : headerLen;\n            break keyValLoop;\n          } else {\n            i++;\n          }\n\n          if (i == headerLen) {\n            // NAME (no value till the end of string)\n            nameEnd = headerLen;\n            valueBegin = valueEnd = -1;\n            break;\n          }\n        }\n      }\n\n      if (valueEnd > 0 && header.charAt(valueEnd - 1) == ',') {\n        // old multiple cookies separator, skipping it\n        valueEnd--;\n      }\n\n      if (cookieBuilder == null) {\n        // cookie name-value pair\n        DefaultCookie cookie = initCookie(header, nameBegin, nameEnd, valueBegin, valueEnd);\n\n        if (cookie == null) {\n          return null;\n        }\n\n        cookieBuilder = new CookieBuilder(cookie);\n      } else {\n                String attrValue = valueBegin == -1 ? null : header.substring(valueBegin, valueEnd);\n        cookieBuilder.appendAttribute(header, nameBegin, nameEnd, attrValue);\n      }\n    }\n    return cookieBuilder.cookie();\n  }",
        "variable": "attrValue",
        "reference": "cookie attribute",
        "explanation_by_ours": "the value of the cookie",
        "explanation_by_baseline": "cookie name-value pair"
    },
    {
        "id": 117,
        "method": "public static Method getMatchingAccessibleMethod(\n      final Class<?> cls, final String methodName, final Class<?>... parameterTypes) {\n    try {\n      final Method method = cls.getMethod(methodName, parameterTypes);\n      MemberUtils.setAccessibleWorkaround(method);\n      return method;\n    } catch (final NoSuchMethodException e) { // NOPMD - Swallow the exception\n    }\n    // search through all methods\n    Method bestMatch = null;\n    final Method[] methods = cls.getMethods();\n    for (final Method method : methods) {\n      // compare name and parameters\n      if (method.getName().equals(methodName)\n          && MemberUtils.isMatchingMethod(method, parameterTypes)) {\n                final Method accessibleMethod = getAccessibleMethod(method);\n        if (accessibleMethod != null\n            && (bestMatch == null\n                || MemberUtils.compareMethodFit(accessibleMethod, bestMatch, parameterTypes) < 0)) {\n          bestMatch = accessibleMethod;\n        }\n      }\n    }\n    if (bestMatch != null) {\n      MemberUtils.setAccessibleWorkaround(bestMatch);\n    }\n\n    if (bestMatch != null\n        && bestMatch.isVarArgs()\n        && bestMatch.getParameterTypes().length > 0\n        && parameterTypes.length > 0) {\n      final Class<?>[] methodParameterTypes = bestMatch.getParameterTypes();\n      final Class<?> methodParameterComponentType =\n          methodParameterTypes[methodParameterTypes.length - 1].getComponentType();\n      final String methodParameterComponentTypeName =\n          ClassUtils.primitiveToWrapper(methodParameterComponentType).getName();\n      final String parameterTypeName = parameterTypes[parameterTypes.length - 1].getName();\n      final String parameterTypeSuperClassName =\n          parameterTypes[parameterTypes.length - 1].getSuperclass().getName();\n\n      if (!methodParameterComponentTypeName.equals(parameterTypeName)\n          && !methodParameterComponentTypeName.equals(parameterTypeSuperClassName)) {\n        return null;\n      }\n    }\n\n    return bestMatch;\n  }",
        "variable": "accessibleMethod",
        "reference": "accessible version of method",
        "explanation_by_ours": "the method to search for",
        "explanation_by_baseline": "the accessible methodif ("
    },
    {
        "id": 131,
        "method": "public <T> BeanDefinition<T> registerPetiteBean(\n\t\tfinal Class<T> type, String name,\n\t\tClass<? extends Scope> scopeType,\n\t\tWiringMode wiringMode,\n\t\tfinal boolean define,\n\t\tfinal Consumer<T> consumer\n\t) {\n\n\t\tif (name == null) {\n\t\t\tname = resolveBeanName(type);\n\t\t}\n\t\tif (wiringMode == null) {\n\t\t\twiringMode = annotationResolver.resolveBeanWiringMode(type);\n\t\t}\n\t\tif (wiringMode == WiringMode.DEFAULT) {\n\t\t\twiringMode = petiteConfig.getDefaultWiringMode();\n\t\t}\n\t\tif (scopeType == null) {\n\t\t\tscopeType = annotationResolver.resolveBeanScopeType(type);\n\t\t}\n\t\tif (scopeType == null) {\n\t\t\tscopeType = SingletonScope.class;\n\t\t}\n\n\t\t\t\tBeanDefinition existing = removeBean(name);\n\t\tif (existing != null) {\n\t\t\tif (petiteConfig.getDetectDuplicatedBeanNames()) {\n\t\t\t\tthrow new PetiteException(\n\t\t\t\t\t\t\"Duplicated bean name detected while registering class '\" + type.getName() + \"'. Petite bean class '\" +\n\t\t\t\t\t\texisting.type.getName() + \"' is already registered with the name: \" + name);\n\t\t\t}\n\t\t}\n\n\t\t// check if type is valid\n\t\tif (type.isInterface()) {\n\t\t\tthrow new PetiteException(\"PetiteBean can not be an interface: \" + type.getName());\n\t\t}\n\n\t\t// registration\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.info(\"Petite bean: [\" + name +\n\t\t\t\t\t\"] --> \" + type.getName() +\n\t\t\t\t\t\" @ \" + scopeType.getSimpleName() +\n\t\t\t\t\t\":\" + wiringMode.toString());\n\t\t}\n\n\t\t// register\n\t\tScope scope = resolveScope(scopeType);\n\t\tBeanDefinition<T> beanDefinition = createBeanDefinitionForRegistration(name, type, scope, wiringMode, consumer);\n\n\t\tregisterBean(name, beanDefinition);\n\n\t\t// providers\n\t\tProviderDefinition[] providerDefinitions = petiteResolvers.resolveProviderDefinitions(type, name);\n\n\t\tif (providerDefinitions != null) {\n\t\t\tfor (ProviderDefinition providerDefinition : providerDefinitions) {\n\t\t\t\tproviders.put(providerDefinition.name, providerDefinition);\n\t\t\t}\n\t\t}\n\n\t\t// define\n\t\tif (define) {\n\t\t\tbeanDefinition.ctor = petiteResolvers.resolveCtorInjectionPoint(beanDefinition.type());\n\t\t\tbeanDefinition.properties = PropertyInjectionPoint.EMPTY;\n\t\t\tbeanDefinition.methods = MethodInjectionPoint.EMPTY;\n\t\t\tbeanDefinition.initMethods = InitMethodPoint.EMPTY;\n\t\t\tbeanDefinition.destroyMethods = DestroyMethodPoint.EMPTY;\n\t\t}\n\n\t\t// return\n\t\treturn beanDefinition;\n\t}",
        "variable": "existing",
        "reference": "existing bean",
        "explanation_by_ours": "the existing bean definition",
        "explanation_by_baseline": "existing beanif (name"
    },
    {
        "id": 144,
        "method": "protected String[] readClassActionPath(final Class actionClass) {\n\t\t\t\tMadvocAction madvocActionAnnotation = ((Class<?>)actionClass).getAnnotation(MadvocAction.class);\n\n\t\tString classActionPath = madvocActionAnnotation != null ? madvocActionAnnotation.value().trim() : null;\n\n\t\tif (StringUtil.isEmpty(classActionPath)) {\n\t\t\tclassActionPath = null;\n\t\t}\n\n\t\tString actionClassName = actionClass.getSimpleName();\n\t\tactionClassName = StringUtil.uncapitalize(actionClassName);\n\t\tactionClassName = MadvocUtil.stripLastCamelWord(actionClassName);       // removes 'Action' from the class name\n\n\t\tif (classActionPath == null) {\n\t\t\tclassActionPath = actionClassName;\n\t\t}\n\n\t\treturn ArraysUtil.array(actionClassName, classActionPath);\n\t}",
        "variable": "madvocActionAnnotation",
        "reference": "class annotation",
        "explanation_by_ours": "the madvoc action annotation",
        "explanation_by_baseline": "class action pathif ("
    },
    {
        "id": 152,
        "method": "protected void createFirstChainDelegate_Start() {\n\t\t\t\tint access = msign.getAccessFlags();\n\t\tif (!wd.allowFinalMethods) {\n\t\t\tif ((access & AsmUtil.ACC_FINAL) != 0) {   // detect final\n\t\t\t\tthrow new ProxettaException(\n\t\t\t\t\t\"Unable to create proxy for final method: \" + msign + \". Remove final modifier or change the pointcut definition.\");\n\t\t\t}\n\t\t}\n\n\t\t// create proxy methods\n\t\ttmd = new TargetMethodData(msign, aspectList);\n\n\t\taccess &= ~ACC_NATIVE;\n\t\taccess &= ~ACC_ABSTRACT;\n\n\t\tmethodVisitor = wd.dest.visitMethod(\n\t\t\t\taccess, tmd.msign.getMethodName(), tmd.msign.getDescription(), tmd.msign.getAsmMethodSignature(), null);\n\t}",
        "variable": "access",
        "reference": "invalid access flags",
        "explanation_by_ours": "The access flags of the method.",
        "explanation_by_baseline": "access flagsif (access"
    },
    {
        "id": 154,
        "method": "public void writeTo(final OutputStream out, final HttpProgressListener progressListener) throws IOException {\n\n\t\t// start\n\n\t\tfinal int size = size();\n\t\tfinal int callbackSize = progressListener.callbackSize(size);\n\t\tint count = 0;\t\t// total count\n\t\tint step = 0;\t\t// step is offset in current chunk\n\n\t\tprogressListener.transferred(count);\n\n\t\t// loop\n\n\t\tfor (Object o : list) {\n\t\t\tif (o instanceof FastByteBuffer) {\n\t\t\t\tFastByteBuffer fastByteBuffer = (FastByteBuffer) o;\n\t\t\t\tbyte[] bytes = fastByteBuffer.toArray();\n\n\t\t\t\tint offset = 0;\n\n\t\t\t\twhile (offset < bytes.length) {\n\t\t\t\t\t\t\t\t\t\tint chunk = callbackSize - step;\n\n\t\t\t\t\t// check if this chunk size fits the bytes array\n\t\t\t\t\tif (offset + chunk > bytes.length) {\n\t\t\t\t\t\tchunk = bytes.length - offset;\n\t\t\t\t\t}\n\n\t\t\t\t\t// writes the chunk\n\t\t\t\t\tout.write(bytes, offset, chunk);\n\n\t\t\t\t\toffset += chunk;\n\t\t\t\t\tstep += chunk;\n\t\t\t\t\tcount += chunk;\n\n\t\t\t\t\t// listener\n\t\t\t\t\tif (step >= callbackSize) {\n\t\t\t\t\t\tprogressListener.transferred(count);\n\t\t\t\t\t\tstep -= callbackSize;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (o instanceof Uploadable) {\n\t\t\t\tUploadable uploadable = (Uploadable) o;\n\n\t\t\t\tInputStream inputStream = uploadable.openInputStream();\n\n\t\t\t\tint remaining = uploadable.getSize();\n\n\t\t\t\ttry {\n\t\t\t\t\twhile (remaining > 0) {\n\t\t\t\t\t\t\t\t\t\t\t\tint chunk = callbackSize - step;\n\n\t\t\t\t\t\t// check if this chunk size fits the remaining size\n\t\t\t\t\t\tif (chunk > remaining) {\n\t\t\t\t\t\t\tchunk = remaining;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// writes remaining chunk\n\t\t\t\t\t\tStreamUtil.copy(inputStream, out, chunk);\n\n\t\t\t\t\t\tremaining -= chunk;\n\t\t\t\t\t\tstep += chunk;\n\t\t\t\t\t\tcount += chunk;\n\n\t\t\t\t\t\t// listener\n\t\t\t\t\t\tif (step >= callbackSize) {\n\t\t\t\t\t\t\tprogressListener.transferred(count);\n\t\t\t\t\t\t\tstep -= callbackSize;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfinally {\n\t\t\t\t\tStreamUtil.close(inputStream);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// end\n\n\t\tif (step != 0) {\n\t\t\tprogressListener.transferred(count);\n\t\t}\n\t}",
        "variable": "chunk",
        "reference": "the remaining sending chunk size",
        "explanation_by_ours": "the number of bytes to write in each chunk",
        "explanation_by_baseline": "the remaining sending chunk size"
    },
    {
        "id": 158,
        "method": "public T embeddedAttachment(final EmailAttachment<? extends DataSource> attachment) {\n\t\tstoreAttachment(attachment);\n\n\t\tfinal List<EmailMessage> messages = messages();\n\t\tfinal int size = messages.size();\n\t\tif (size > 1) {\n\t\t\t\t\t\tfinal int lastMessagePos = size - 1;\n\t\t\tfinal EmailMessage lastMessage = messages.get(lastMessagePos);\n\t\t\tattachment.setEmbeddedMessage(lastMessage);\n\t\t}\n\n\t\treturn _this();\n\t}",
        "variable": "lastMessagePos",
        "reference": "the positon of last message",
        "explanation_by_ours": "the last message pos",
        "explanation_by_baseline": "@Override publicT"
    },
    {
        "id": 257,
        "method": "protected long[] convertArrayToArray(final Object value) {\n\t\tfinal Class valueComponentType = value.getClass().getComponentType();\n\n\t\tfinal long[] result;\n\n\t\tif (valueComponentType.isPrimitive()) {\n\t\t\tresult = convertPrimitiveArrayToArray(value, valueComponentType);\n\t\t} else {\n\t\t\t\t\t\tfinal Object[] array = (Object[]) value;\n\t\t\tresult = new long[array.length];\n\n\t\t\tfor (int i = 0; i < array.length; i++) {\n\t\t\t\tresult[i] = convertType(array[i]);\n\t\t\t}\n\t\t}\n\n\t\treturn result;\n\t}",
        "variable": "array",
        "reference": "object array",
        "explanation_by_ours": "the array",
        "explanation_by_baseline": "objectvalueComponentType.is"
    },
    {
        "id": 277,
        "method": "protected String removeToFrom(String sql) {\n\t\tint from = 0;\n\t\tint fromCount = 1;\n\t\tint selectCount = 0;\n\t\tint lastNdx = 0;\n\t\twhile (true) {\n\t\t\tint ndx = StringUtil.indexOfIgnoreCase(sql, \"from\", from);\n\t\t\tif (ndx == -1) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t\t\t\tString left = sql.substring(lastNdx, ndx);\n\t\t\tselectCount += StringUtil.countIgnoreCase(left, \"select\");\n\n\t\t\tif (fromCount >= selectCount) {\n\t\t\t\tsql = sql.substring(ndx);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// find next 'from'\n\t\t\tlastNdx = ndx;\n\t\t\tfrom = ndx + 4;\n\t\t\tfromCount++;\n\t\t}\n\t\treturn sql;\n\t}",
        "variable": "left",
        "reference": "left part",
        "explanation_by_ours": "the left",
        "explanation_by_baseline": "'from'if ("
    },
    {
        "id": 287,
        "method": "protected void fixElements() {\n\t\tfor (Element fosterElement : fosterElements) {\n\t\t\t// find parent table\n\t\t\tElement lastTable = findLastTable(fosterElement);\n\t\t\tNode fosterElementParent = fosterElement.getParentNode();\n\n\t\t\t\t\t\tNode[] fosterChilds = fosterElement.getChildNodes();\n\t\t\tfor (Node fosterChild : fosterChilds) {\n\t\t\t\tif (fosterChild.getNodeType() == Node.NodeType.ELEMENT) {\n\t\t\t\t\tif (isOneOfTableElements((Element) fosterChild)) {\n\t\t\t\t\t\t// move all child table elements outside\n\t\t\t\t\t\t// the foster element\n\t\t\t\t\t\tfosterChild.detachFromParent();\n\t\t\t\t\t\tfosterElementParent.insertBefore(fosterChild, fosterElement);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// finally, move foster element above the table\n\t\t\tfosterElement.detachFromParent();\n\t\t\tlastTable.getParentNode().insertBefore(fosterElement, lastTable);\n\t\t}\n\t}",
        "variable": "fosterChilds",
        "reference": "foster element",
        "explanation_by_ours": "the foster child nodes",
        "explanation_by_baseline": "child table elements}"
    },
    {
        "id": 294,
        "method": "protected T authenticateUserViaToken(final ActionRequest actionRequest) {\n\t\tfinal HttpServletRequest servletRequest = actionRequest.getHttpServletRequest();\n\n\t\t\t\tfinal String token = ServletUtil.resolveAuthBearerToken(servletRequest);\n\t\tif (token == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tfinal T authToken = userAuth().validateToken(token);\n\t\tif (authToken == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\t// granted\n\t\tfinal T newAuthToken = userAuth().rotateToken(authToken);\n\n\t\tactionRequest.getHttpServletResponse().setHeader(\"Authentication\", \"Bearer: \" + userAuth().tokenValue(newAuthToken));\n\n\t\treturn newAuthToken;\n\t}",
        "variable": "token",
        "reference": "the auth token",
        "explanation_by_ours": "the token",
        "explanation_by_baseline": "{if (authToken"
    },
    {
        "id": 298,
        "method": "@SuppressWarnings(\"NonConstantStringShouldBeStringBuffer\")\n\tprotected void acceptActionClass(final Class<?> actionClass) {\n\n\t\tif (actionClass == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (!checkClass(actionClass)) {\n\t\t\treturn; \n\t\t}\n\n\t\tif (actionClass.getAnnotation(MadvocAction.class) == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tClassDescriptor cd = ClassIntrospector.get().lookup(actionClass);\n\n\t\tMethodDescriptor[] allMethodDescriptors = cd.getAllMethodDescriptors();\n\t\tfor (MethodDescriptor methodDescriptor : allMethodDescriptors) {\n\t\t\tif (!methodDescriptor.isPublic()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t\t\t\tfinal Method method = methodDescriptor.getMethod();\n\n\t\t\tfinal boolean hasAnnotation = actionConfigManager.hasActionAnnotationOn(method);\n\n\t\t\tif (!hasAnnotation) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\twebappConfigurations.add(() -> actionsManager.registerAction(actionClass, method, null));\n\t\t}\n\t}",
        "variable": "method",
        "reference": "public method",
        "explanation_by_ours": "the action method",
        "explanation_by_baseline": "in case it is public"
    },
    {
        "id": 304,
        "method": "public static HttpResponse readFrom(final InputStream in) {\n\t\tInputStreamReader inputStreamReader;\n\t\ttry {\n\t\t\tinputStreamReader = new InputStreamReader(in, StringPool.ISO_8859_1);\n\t\t} catch (UnsupportedEncodingException unee) {\n\t\t\tthrow new HttpException(unee);\n\t\t}\n\t\tBufferedReader reader = new BufferedReader(inputStreamReader);\n\n\t\tHttpResponse httpResponse = new HttpResponse();\n\n\t\t// the first line\n\t\tString line;\n\t\ttry {\n\t\t\tline = reader.readLine();\n\t\t} catch (IOException ioex) {\n\t\t\tthrow new HttpException(ioex);\n\t\t}\n\n\t\tif (line != null) {\n\n\t\t\tline = line.trim();\n\n\t\t\tint ndx = line.indexOf(' ');\n\t\t\tint ndx2;\n\n\t\t\tif (ndx > -1) {\n\t\t\t\thttpResponse.httpVersion(line.substring(0, ndx));\n\n\t\t\t\tndx2 = line.indexOf(' ', ndx + 1);\n\t\t\t}\n\t\t\telse {\n\t\t\t\thttpResponse.httpVersion(HTTP_1_1);\n\t\t\t\tndx2 = -1;\n\t\t\t\tndx = 0;\n\t\t\t}\n\n\t\t\tif (ndx2 == -1) {\n\t\t\t\tndx2 = line.length();\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\thttpResponse.statusCode(Integer.parseInt(line.substring(ndx, ndx2).trim()));\n\t\t\t}\n\t\t\tcatch (NumberFormatException nfex) {\n\t\t\t\thttpResponse.statusCode(-1);\n\t\t\t}\n\n\t\t\thttpResponse.statusPhrase(line.substring(ndx2).trim());\n\t\t}\n\n\t\thttpResponse.readHeaders(reader);\n\t\thttpResponse.readBody(reader);\n\n\t\treturn httpResponse;\n\t}",
        "variable": "line",
        "reference": "the first line",
        "explanation_by_ours": "the first line",
        "explanation_by_baseline": "httpResponse.setContentType("
    },
    {
        "id": 312,
        "method": "protected void addCookies(final HttpRequest httpRequest) {\n\t\t\t\tList<Cookie> cookiesList = new ArrayList<>();\n\n\t\tif (!cookies.isEmpty()) {\n\t\t\tfor (Map.Entry<String, Cookie> cookieEntry : cookies) {\n\t\t\t\tcookiesList.add(cookieEntry.getValue());\n\t\t\t}\n\n\t\t\thttpRequest.cookies(cookiesList.toArray(new Cookie[0]));\n\t\t}\n\t}",
        "variable": "cookiesList",
        "reference": "all cookies",
        "explanation_by_ours": "the list of cookies to add",
        "explanation_by_baseline": "cookiesList"
    },
    {
        "id": 320,
        "method": "@Override\n\tpublic Object[] parseObjects(final Class... types) {\n\t\tresultColumns.clear();\n\n\t\tint totalTypes = types.length;\n\t\tObject[] result = new Object[totalTypes];\n\t\tboolean[] resultUsage = new boolean[totalTypes];\n\t\tDbEntityDescriptor[] dbEntityDescriptors = resolveDbEntityDescriptors(types);\n\t\tString[] typesTableNames = resolveTypesTableNames(types);\n\t\tString[][] mappedNames = resolveMappedTypesTableNames(types);\n\n\t\tint currentResult = 0;\n\t\tcachedColumnNdx = -1;\n\t\tint colNdx = 0;\n\t\twhile (colNdx < totalColumns) {\n\n\t\t\t// no more types for mapping?\n\t\t\tif (currentResult >= totalTypes) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// skip columns that doesn't map\n\t\t\tClass currentType = types[currentResult];\n\t\t\tif (currentType == null) {\n\t\t\t\tcolNdx++;\n\t\t\t\tcurrentResult++;\n\t\t\t\tresultColumns.clear();\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tString columnName = columnNames[colNdx];\n\t\t\tint columnDbSqlType = columnDbSqlTypes[colNdx];\n\t\t\tString tableName = tableNames[colNdx];\n\t\t\tString resultTableName = typesTableNames[currentResult];\t\t\t\n\n\t\t\tif (resultTableName == null) {\n\t\t\t\t// match: simple type\n\t\t\t\tresult[currentResult] = readColumnValue(colNdx, currentType, null, columnDbSqlType);\n\t\t\t\tresultUsage[currentResult] = true;\n\t\t\t\tcolNdx++;\n\t\t\t\tcurrentResult++; resultColumns.clear();\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t\t\t\tboolean tableMatched = false;\n\n\t\t\tif (tableName == null) {\n\t\t\t\ttableMatched = true;\n\t\t\t} else if (resultTableName.equals(tableName)) {\n\t\t\t\ttableMatched = true;\n\t\t\t} else {\n\t\t\t\tString[] mapped = mappedNames[currentResult];\n\t\t\t\tif (mapped != null) {\n\t\t\t\t\tfor (String m : mapped) {\n\t\t\t\t\t\tif (m.equals(tableName)) {\n\t\t\t\t\t\t\ttableMatched = true;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (tableMatched) {\n\t\t\t\tif (!resultColumns.contains(columnName)) {\n\t\t\t\t\t//DbEntityDescriptor ded = dbEntityManager.lookupType(currentType);\n\t\t\t\t\tDbEntityDescriptor ded = dbEntityDescriptors[currentResult];\n\n\t\t\t\t\tDbEntityColumnDescriptor dec = ded.findByColumnName(columnName);\n\t\t\t\t\tString propertyName = (dec == null ? null : dec.getPropertyName());\n\n\t\t\t\t\t// check if a property that matches column name exist\n\t\t\t\t\tif (propertyName != null) {\n\n\t\t\t\t\t\t// if current entity instance does not exist (i.e. we are at the first column\n\t\t\t\t\t\t// of some entity), create the instance and store it\n\t\t\t\t\t\tif (result[currentResult] == null) {\n\t\t\t\t\t\t\tresult[currentResult] = dbEntityManager.createEntityInstance(currentType);\n\t\t\t\t\t\t}\n/*\n\t\t\t\t\t\tboolean success = value != null ?\n\t\t\t\t\t\t\t\t\t\tBeanUtil.setDeclaredPropertySilent(result[currentResult], propertyName, value) :\n\t\t\t\t\t\t\t\t\t\tBeanUtil.hasDeclaredProperty(result[currentResult], propertyName);\n*/\n\t\t\t\t\t\tClass type = BeanUtil.declared.getPropertyType(result[currentResult], propertyName);\n\t\t\t\t\t\tif (type != null) {\n\t\t\t\t\t\t\t// match: entity\n\t\t\t\t\t\t\tdec.updateDbSqlType(columnDbSqlType);\t// updates column db sql type information for the entity!!!\n\t\t\t\t\t\t\tClass<? extends SqlType> sqlTypeClass = dec.getSqlTypeClass();\n\t\t\t\t\t\t\tObject value = readColumnValue(colNdx, type, sqlTypeClass, columnDbSqlType);\n\n\t\t\t\t\t\t\tif (value != null) {\n\t\t\t\t\t\t\t\t// inject column value into existing entity\n\t\t\t\t\t\t\t\tBeanUtil.declared.setProperty(result[currentResult], propertyName, value);\n\t\t\t\t\t\t\t\tresultUsage[currentResult] = true;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcolNdx++;\n\t\t\t\t\t\t\tresultColumns.add(columnName);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// go to next type, i.e. result\n\t\t\tcurrentResult++;\n\t\t\tresultColumns.clear();\n\t\t}\n\n\t\tresultColumns.clear();\n\t\tfor (int i = 0; i < resultUsage.length; i++) {\n\t\t\tif (!resultUsage[i]) {\n\t\t\t\tresult[i] = null;\n\t\t\t}\n\t\t}\n\n\t\tif (cacheEntities) {\n\t\t\tcacheResultSetEntities(result);\n\t\t}\n\n\t\treturn result;\n\t}",
        "variable": "tableMatched",
        "reference": "match table",
        "explanation_by_ours": "{@inheritDoc}",
        "explanation_by_baseline": "check if table matches type"
    },
    {
        "id": 327,
        "method": "private String[] process(final String actionPath, final boolean match) {\n\t\t// first check the first fixed as a prefix\n\t\tif (match && !actionPath.startsWith(fixed[0])) {\n\t\t\treturn null;\n\t\t}\n\n\t\tString[] values = new String[macrosCount];\n\n\t\tint offset = fixed[0].length();\n\t\tint i = 0;\n\n\t\twhile (i < macrosCount) {\n\t\t\tint nexti = i;\n\n\t\t\t// defines next fixed string to match\n\t\t\tString nextFixed;\n\t\t\twhile (true) {\n\t\t\t\tnexti++;\n\t\t\t\tif (nexti > macrosCount) {\n\t\t\t\t\tnextFixed = null;\t// match to the end of line\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnextFixed = fixed[nexti];\n\t\t\t\tif (nextFixed.length() != 0) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t// next fixed is an empty string, so skip the next macro.\n\t\t\t}\n\n\t\t\t// find next fixed string\n\t\t\tint ndx;\n\n\t\t\tif (nextFixed != null) {\n\t\t\t\tndx = actionPath.indexOf(nextFixed, offset);\n\t\t\t} else {\n\t\t\t\tndx = actionPath.length();\n\t\t\t}\n\n\t\t\tif (ndx == -1) {\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\tString macroValue = actionPath.substring(offset, ndx);\n\t\t\tvalues[i] = macroValue;\n\n\t\t\tif (match && patterns[i] != null) {\n\t\t\t\tif (!matchValue(i, macroValue)) {\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (nextFixed == null) {\n\t\t\t\toffset = ndx;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// iterate\n\t\t\tint nextFixedLength = nextFixed.length();\n\t\t\toffset = ndx + nextFixedLength;\n\n\t\t\ti = nexti;\n\t\t}\n\n\t\tif (offset != actionPath.length()) {\n\t\t\t// action path is not consumed fully during this matching\n\t\t\treturn null;\n\t\t}\n\n\t\treturn values;\n\t}",
        "variable": "nextFixed",
        "reference": "next fixed string to match",
        "explanation_by_ours": "the next fixed",
        "explanation_by_baseline": "the next fixed string{"
    },
    {
        "id": 330,
        "method": "protected Object parseValue(final Class targetType, final Class keyType, final Class componentType) {\n\t\tfinal ValueConverter valueConverter;\n\n\t\tfinal char c = input[ndx];\n\n\t\tswitch (c) {\n\t\t\tcase '\\'':\n\t\t\t\tif (!looseMode) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tcase '\"':\n\t\t\t\tndx++;\n\t\t\t\tObject string = parseStringContent(c);\n\n\t\t\t\tvalueConverter = lookupValueConverter();\n\t\t\t\tif (valueConverter != null) {\n\t\t\t\t\treturn valueConverter.convert(string);\n\t\t\t\t}\n\n\t\t\t\tif (targetType != null && targetType != String.class) {\n\t\t\t\t\tstring = convertType(string, targetType);\n\t\t\t\t}\n\t\t\t\treturn string;\n\n\t\t\tcase '{':\n\t\t\t\tndx++;\n\t\t\t\tif (lazy) {\n\t\t\t\t\tif (notFirstObject) {\n\t\t\t\t\t\tfinal Object value = new ObjectParser(this, targetType, keyType, componentType);\n\n\t\t\t\t\t\tskipObject();\n\n\t\t\t\t\t\treturn value;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tnotFirstObject = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\treturn parseObjectContent(targetType, keyType, componentType);\n\n\t\t\tcase '[':\n\t\t\t\tndx++;\n\t\t\t\treturn parseArrayContent(targetType, componentType);\n\n\t\t\tcase '0':\n\t\t\tcase '1':\n\t\t\tcase '2':\n\t\t\tcase '3':\n\t\t\tcase '4':\n\t\t\tcase '5':\n\t\t\tcase '6':\n\t\t\tcase '7':\n\t\t\tcase '8':\n\t\t\tcase '9':\n\t\t\tcase '-':\n\t\t\t\tObject number = parseNumber();\n\n\t\t\t\tvalueConverter = lookupValueConverter();\n\t\t\t\tif (valueConverter != null) {\n\t\t\t\t\treturn valueConverter.convert(number);\n\t\t\t\t}\n\n\t\t\t\tif (targetType != null) {\n\t\t\t\t\tnumber = convertType(number, targetType);\n\t\t\t\t}\n\t\t\t\treturn number;\n\n\t\t\tcase 'n':\n\t\t\t\tndx++;\n\t\t\t\tif (match(N_ULL)) {\n\t\t\t\t\tvalueConverter = lookupValueConverter();\n\t\t\t\t\tif (valueConverter != null) {\n\t\t\t\t\t\treturn valueConverter.convert(null);\n\t\t\t\t\t}\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tndx++;\n\t\t\t\tif (match(T_RUE)) {\n\t\t\t\t\tObject value = Boolean.TRUE;\n\n\t\t\t\t\tvalueConverter = lookupValueConverter();\n\t\t\t\t\tif (valueConverter != null) {\n\t\t\t\t\t\treturn valueConverter.convert(value);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (targetType != null) {\n\t\t\t\t\t\tvalue = convertType(value, targetType);\n\t\t\t\t\t}\n\t\t\t\t\treturn value;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase 'f':\n\t\t\t\tndx++;\n\t\t\t\tif (match(F_ALSE)) {\n\t\t\t\t\tObject value = Boolean.FALSE;\n\n\t\t\t\t\tvalueConverter = lookupValueConverter();\n\t\t\t\t\tif (valueConverter != null) {\n\t\t\t\t\t\treturn valueConverter.convert(value);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (targetType != null) {\n\t\t\t\t\t\tvalue = convertType(value, targetType);\n\t\t\t\t\t}\n\t\t\t\t\treturn value;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (looseMode) {\n\t\t\t\t\t\tObject string = parseUnquotedStringContent();\n\n\t\t\tvalueConverter = lookupValueConverter();\n\t\t\tif (valueConverter != null) {\n\t\t\t\treturn valueConverter.convert(string);\n\t\t\t}\n\n\t\t\tif (targetType != null && targetType != String.class) {\n\t\t\t\tstring = convertType(string, targetType);\n\t\t\t}\n\t\t\treturn string;\n\t\t}\n\n\t\tsyntaxError(\"Invalid char: \" + input[ndx]);\n\t\treturn null;\n\t}",
        "variable": "string",
        "reference": "unquoted string",
        "explanation_by_ours": "the string",
        "explanation_by_baseline": "unquoted string content("
    },
    {
        "id": 335,
        "method": "public static Method[] getAccessibleMethods(Class clazz, final Class limit) {\n\t\tPackage topPackage = clazz.getPackage();\n\t\tList<Method> methodList = new ArrayList<>();\n\t\tint topPackageHash = topPackage == null ? 0 : topPackage.hashCode();\n\t\tboolean top = true;\n\t\tdo {\n\t\t\tif (clazz == null) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tMethod[] declaredMethods = clazz.getDeclaredMethods();\n\t\t\tfor (Method method : declaredMethods) {\n\t\t\t\tif (Modifier.isVolatile(method.getModifiers())) {\n\t\t\t\t    continue;\n\t\t\t\t}\n//\t\t\t\tif (Modifier.isAbstract(method.getModifiers())) {\n//\t\t\t\t\tcontinue;\n//\t\t\t\t}\n\t\t\t\tif (top) {\t\t\t\t// add all top declared methods\n\t\t\t\t\tmethodList.add(method);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tint modifier = method.getModifiers();\n\t\t\t\tif (Modifier.isPrivate(modifier)) {\n\t\t\t\t\tcontinue;\t\t\t\t\t\t\t\t\t\t// ignore super private methods\n\t\t\t\t}\n\t\t\t\tif (Modifier.isAbstract(modifier)) {\t\t// ignore super abstract methods\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (Modifier.isPublic(modifier)) {\n\t\t\t\t\taddMethodIfNotExist(methodList, method);\t\t// add super public methods\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (Modifier.isProtected(modifier)) {\n\t\t\t\t\taddMethodIfNotExist(methodList, method);\t\t// add super protected methods\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\t\t\t\t\tPackage pckg = method.getDeclaringClass().getPackage();\n\t\t\t\tint pckgHash = pckg == null ? 0 : pckg.hashCode();\n\t\t\t\tif (pckgHash == topPackageHash) {\n\t\t\t\t\taddMethodIfNotExist(methodList, method);\n\t\t\t\t}\n\t\t\t}\n\t\t\ttop = false;\n\t\t} while ((clazz = clazz.getSuperclass()) != limit);\n\n\t\tMethod[] methods = new Method[methodList.size()];\n\t\tfor (int i = 0; i < methods.length; i++) {\n\t\t\tmethods[i] = methodList.get(i);\n\t\t}\n\t\treturn methods;\n\t}",
        "variable": "pckg",
        "reference": "the same package",
        "explanation_by_ours": "the package of the class to get the methods from.",
        "explanation_by_baseline": "super classes= false;"
    },
    {
        "id": 350,
        "method": "public List<CssSelector> parse() {\n\t\ttry {\n\t\t\tlexer.yylex();\n\t\t\tif (lexer.selectors.isEmpty()) {\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\t\t\t\tCssSelector last = lexer.selectors.get(lexer.selectors.size() - 1);\n\t\t\tif (last.getCombinator() == Combinator.DESCENDANT) {\n\t\t\t\tlast.setCombinator(null);\n\t\t\t}\n\n\t\t\t// set previous css selector\n\t\t\tCssSelector prevCssSelector = null;\n\t\t\tfor (CssSelector cssSelector : lexer.selectors) {\n\t\t\t\tif (prevCssSelector != null) {\n\t\t\t\t\tcssSelector.setPrevCssSelector(prevCssSelector);\n\t\t\t\t}\n\t\t\t\tprevCssSelector = cssSelector;\n\t\t\t}\n\n\t\t\treturn lexer.selectors;\n\t\t} catch (IOException ioex) {\n\t\t\tthrow new CSSellyException(ioex);\n\t\t}\n\t}",
        "variable": "last",
        "reference": "last combinator",
        "explanation_by_ours": "the last selector",
        "explanation_by_baseline": "last combinator{"
    },
    {
        "id": 351,
        "method": "public List<CssSelector> parse() {\n\t\ttry {\n\t\t\tlexer.yylex();\n\t\t\tif (lexer.selectors.isEmpty()) {\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\t// fixes last combinator\n\t\t\tCssSelector last = lexer.selectors.get(lexer.selectors.size() - 1);\n\t\t\tif (last.getCombinator() == Combinator.DESCENDANT) {\n\t\t\t\tlast.setCombinator(null);\n\t\t\t}\n\n\t\t\t\t\t\tCssSelector prevCssSelector = null;\n\t\t\tfor (CssSelector cssSelector : lexer.selectors) {\n\t\t\t\tif (prevCssSelector != null) {\n\t\t\t\t\tcssSelector.setPrevCssSelector(prevCssSelector);\n\t\t\t\t}\n\t\t\t\tprevCssSelector = cssSelector;\n\t\t\t}\n\n\t\t\treturn lexer.selectors;\n\t\t} catch (IOException ioex) {\n\t\t\tthrow new CSSellyException(ioex);\n\t\t}\n\t}",
        "variable": "prevCssSelector",
        "reference": "previous css selector",
        "explanation_by_ours": "the previous css selector",
        "explanation_by_baseline": "prev combinator{"
    },
    {
        "id": 353,
        "method": "public synchronized String registerBundle(final String contextPath, final String actionPath, final String tempBundleId, final String bundleContentType, final List<String> sources) {\n\n\t\tif (tempBundleId == null || sources.isEmpty()) {\n\t\t\tif (strategy == Strategy.ACTION_MANAGED) {\n\t\t\t\t// page does not include any resource source file\n\t\t\t\tactionBundles.put(actionPath, StringPool.EMPTY);\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\n\t\t\t\tString[] sourcesArray = sources.toArray(new String[0]);\n\t\tfor (int i = 0, sourcesArrayLength = sourcesArray.length; i < sourcesArrayLength; i++) {\n\t\t\tsourcesArray[i] = sourcesArray[i].trim().toLowerCase();\n\t\t}\n\t\tif (sortResources) {\n\t\t\tArrays.sort(sourcesArray);\n\t\t}\n\n\t\tStringBand sb = new StringBand(sourcesArray.length);\n\t\tfor (String src : sourcesArray) {\n\t\t\tsb.append(src);\n\t\t}\n\t\tString sourcesString = sb.toString();\n\n\t\tString bundleId = createDigest(sourcesString);\n\t\tbundleId += '.' + bundleContentType;\n\n\t\t// bundle appears for the first time, create the bundle\n\t\tif (strategy == Strategy.ACTION_MANAGED) {\n\t\t\tactionBundles.put(actionPath, bundleId);\n\t\t\tmirrors.put(tempBundleId, bundleId);\n\t\t}\n\t\ttry {\n\t\t\tcreateBundle(contextPath, actionPath, bundleId, sources);\n\t\t} catch (IOException ioex) {\n\t\t\tthrow new HtmlStaplerException(\"Can't create bundle\", ioex);\n\t\t}\n\t\treturn bundleId;\n\t}",
        "variable": "sourcesArray",
        "reference": "the collected sources",
        "explanation_by_ours": "the collected sources",
        "explanation_by_baseline": "the list of sources{"
    },
    {
        "id": 374,
        "method": "protected Socket createSocket(final String host, final int port, final int connectionTimeout) throws IOException {\n\t\tfinal SocketFactory socketFactory = getSocketFactory(proxy, false, false, connectionTimeout);\n\n\t\tif (connectionTimeout < 0) {\n\t\t\treturn socketFactory.createSocket(host, port);\n\t\t}\n\t\telse {\n\t\t\t\t\t\tSocket socket = socketFactory.createSocket();\n\n\t\t\tsocket.connect(new InetSocketAddress(host, port), connectionTimeout);\n\n\t\t\treturn socket;\n\t\t}\n\t}",
        "variable": "socket",
        "reference": "unconnected socket",
        "explanation_by_ours": "the socket",
        "explanation_by_baseline": "a new socket{"
    },
    {
        "id": 383,
        "method": "public String createHash(final char[] password) {\n\n\t\t\t\tSecureRandom random = new SecureRandom();\n\t\tbyte[] salt = new byte[saltBytes];\n\t\trandom.nextBytes(salt);\n\n\t\t// Hash the password\n\t\tbyte[] hash = pbkdf2(password, salt, pbkdf2Iterations, hashBytes);\n\n\t\t// format iterations:salt:hash\n\t\treturn pbkdf2Iterations + \":\" + StringUtil.toHexString(salt) + \":\" + StringUtil.toHexString(hash);\n\t}",
        "variable": "random",
        "reference": "a random salt",
        "explanation_by_ours": "the random number generator",
        "explanation_by_baseline": "salt public String"
    },
    {
        "id": 392,
        "method": "public String invoke(String actionPath, final HttpServletRequest servletRequest, final HttpServletResponse servletResponse) throws Exception {\n\t\tfinal String originalActionPath = actionPath;\n\t\tboolean characterEncodingSet = false;\n\n\t\twhile (actionPath != null) {\n\t\t\t// build action path\n\t\t\tfinal String httpMethod = servletRequest.getMethod().toUpperCase();\n\n\t\t\tif (log.isDebugEnabled()) {\n\t\t\t\tlog.debug(\"Action path: \" + httpMethod + \" \" + actionPath);\n\t\t\t}\n\n\t\t\tactionPath = actionPathRewriter.rewrite(servletRequest, actionPath, httpMethod);\n\n\t\t\tString[] actionPathChunks = MadvocUtil.splitPathToChunks(actionPath);\n\n\t\t\t// resolve action runtime\n\t\t\tActionRuntime actionRuntime = actionsManager.lookup(httpMethod, actionPathChunks);\n\n\t\t\tif (actionRuntime == null) {\n\n\t\t\t\t// special case!\n\t\t\t\tif (actionPath.endsWith(welcomeFile)) {\n\t\t\t\t\tactionPath = actionPath.substring(0, actionPath.length() - (welcomeFile.length() - 1));\n\t\t\t\t\tactionPathChunks = MadvocUtil.splitPathToChunks(actionPath);\n\t\t\t\t\tactionRuntime = actionsManager.lookup(httpMethod, actionPathChunks);\n\t\t\t\t}\n\t\t\t\tif (actionRuntime == null) {\n\t\t\t\t\treturn originalActionPath;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (log.isDebugEnabled()) {\n\t\t\t\tlog.debug(\"Invoke action for '\" + actionPath + \"' using \" + actionRuntime.createActionString());\n\t\t\t}\n\n\t\t\t// set character encoding\n\t\t\tif (!characterEncodingSet && applyCharacterEncoding) {\n\n\t\t\t\tfinal String encoding = madvocEncoding.getEncoding();\n\n\t\t\t\tif (encoding != null) {\n\t\t\t\t\tservletRequest.setCharacterEncoding(encoding);\n\t\t\t\t\tservletResponse.setCharacterEncoding(encoding);\n\t\t\t\t}\n\n\t\t\t\tcharacterEncodingSet = true;\n\t\t\t}\n\n\t\t\t// create action object\n\t\t\tfinal Object action;\n\n\t\t\tif (actionRuntime.isActionHandlerDefined()) {\n\t\t\t\taction = actionRuntime.getActionHandler();\n\t\t\t}\n\t\t\telse {\n\t\t\t\taction = createAction(actionRuntime.getActionClass());\n\t\t\t}\n\n\t\t\tfinal ActionRequest actionRequest = createActionRequest(\n\t\t\t\tactionPath,\n\t\t\t\tactionPathChunks,\n\t\t\t\tactionRuntime,\n\t\t\t\taction,\n\t\t\t\tservletRequest,\n\t\t\t\tservletResponse);\n\n\t\t\t// invoke and render\n\t\t\tif (actionRuntime.isAsync()) {\n\t\t\t\tasyncActionExecutor.invoke(actionRequest);\n\t\t\t} else {\n\t\t\t\tactionRequest.invoke();\n\t\t\t}\n\n\t\t\tactionPath = actionRequest.getNextActionPath();\n\t\t}\n\t\treturn null;\n\t}",
        "variable": "action",
        "reference": "action object",
        "explanation_by_ours": "the action",
        "explanation_by_baseline": "actionactionRuntime.is"
    },
    {
        "id": 393,
        "method": "@Override\n  public Converter getConverter(int fieldIndex) {\n\n        Converter delegateConverter = checkNotNull(delegate.getConverter(fieldIndex), \"delegate converter\");\n\n    // determine the indexFieldPath for the converter proxy we're about to make, which is\n    // this converter's path + the requested fieldIndex\n    List<Integer> newIndexFieldPath = new ArrayList<Integer>(indexFieldPath.size() + 1);\n    newIndexFieldPath.addAll(indexFieldPath);\n    newIndexFieldPath.add(fieldIndex);\n\n    if (delegateConverter.isPrimitive()) {\n      PrimitiveColumnIO columnIO = getColumnIO(newIndexFieldPath);\n      ColumnPath columnPath = ColumnPath.get(columnIO.getColumnDescriptor().getPath());\n      ValueInspector[] valueInspectors = getValueInspectors(columnPath);\n      return new FilteringPrimitiveConverter(delegateConverter.asPrimitiveConverter(), valueInspectors);\n    } else {\n      return new FilteringGroupConverter(delegateConverter.asGroupConverter(), newIndexFieldPath, valueInspectorsByColumn, columnIOsByIndexFieldPath);\n    }\n\n  }",
        "variable": "delegateConverter",
        "reference": "the real converter from the delegate",
        "explanation_by_ours": "the delegate converter",
        "explanation_by_baseline": "the delegate converter for this"
    },
    {
        "id": 397,
        "method": "@Deprecated\n  public static List<Footer> readAllFootersInParallelUsingSummaryFiles(\n      final Configuration configuration,\n      final Collection<FileStatus> partFiles,\n      final boolean skipRowGroups) throws IOException {\n\n    // figure out list of all parents to part files\n    Set<Path> parents = new HashSet<Path>();\n    for (FileStatus part : partFiles) {\n      parents.add(part.getPath().getParent());\n    }\n\n        List<Callable<Map<Path, Footer>>> summaries = new ArrayList<Callable<Map<Path, Footer>>>();\n    for (final Path path : parents) {\n      summaries.add(new Callable<Map<Path, Footer>>() {\n        @Override\n        public Map<Path, Footer> call() throws Exception {\n          ParquetMetadata mergedMetadata = readSummaryMetadata(configuration, path, skipRowGroups);\n          if (mergedMetadata != null) {\n            final List<Footer> footers;\n            if (skipRowGroups) {\n              footers = new ArrayList<Footer>();\n              for (FileStatus f : partFiles) {\n                footers.add(new Footer(f.getPath(), mergedMetadata));\n              }\n            } else {\n              footers = footersFromSummaryFile(path, mergedMetadata);\n            }\n            Map<Path, Footer> map = new HashMap<Path, Footer>();\n            for (Footer footer : footers) {\n              // the folder may have been moved\n              footer = new Footer(new Path(path, footer.getFile().getName()), footer.getParquetMetadata());\n              map.put(footer.getFile(), footer);\n            }\n            return map;\n          } else {\n            return Collections.emptyMap();\n          }\n        }\n      });\n    }\n\n    Map<Path, Footer> cache = new HashMap<Path, Footer>();\n    try {\n      List<Map<Path, Footer>> footersFromSummaries = runAllInParallel(configuration.getInt(PARQUET_READ_PARALLELISM, 5), summaries);\n      for (Map<Path, Footer> footers : footersFromSummaries) {\n        cache.putAll(footers);\n      }\n    } catch (ExecutionException e) {\n      throw new IOException(\"Error reading summaries\", e);\n    }\n\n    // keep only footers for files actually requested and read file footer if not found in summaries\n    List<Footer> result = new ArrayList<Footer>(partFiles.size());\n    List<FileStatus> toRead = new ArrayList<FileStatus>();\n    for (FileStatus part : partFiles) {\n      Footer f = cache.get(part.getPath());\n      if (f != null) {\n        result.add(f);\n      } else {\n        toRead.add(part);\n      }\n    }\n\n    if (toRead.size() > 0) {\n      // read the footers of the files that did not have a summary file\n      LOG.info(\"reading another {} footers\", toRead.size());\n      result.addAll(readAllFootersInParallel(configuration, toRead, skipRowGroups));\n    }\n\n    return result;\n  }",
        "variable": "summaries",
        "reference": "summary files",
        "explanation_by_ours": "the list of summaries to read",
        "explanation_by_baseline": "footers from summary files"
    },
    {
        "id": 407,
        "method": "static <T> List<ParquetInputSplit> generateSplits(\n          List<BlockMetaData> rowGroupBlocks,\n          BlockLocation[] hdfsBlocksArray,\n          FileStatus fileStatus,\n          String requestedSchema,\n          Map<String, String> readSupportMetadata, long minSplitSize, long maxSplitSize) throws IOException {\n\n    List<SplitInfo> splitRowGroups =\n        generateSplitInfo(rowGroupBlocks, hdfsBlocksArray, minSplitSize, maxSplitSize);\n\n        List<ParquetInputSplit> resultSplits = new ArrayList<ParquetInputSplit>();\n    for (SplitInfo splitInfo : splitRowGroups) {\n      ParquetInputSplit split = splitInfo.getParquetInputSplit(fileStatus, requestedSchema, readSupportMetadata);\n      resultSplits.add(split);\n    }\n    return resultSplits;\n  }",
        "variable": "resultSplits",
        "reference": "splits from rowGroups",
        "explanation_by_ours": "List of splits to generate",
        "explanation_by_baseline": "a single ParquetInputSplit"
    },
    {
        "id": 424,
        "method": "private List<String> getFieldsToNull(List<NullReplacerConditionalConfig> nullReplacerConditionalConfigs, Set<String> fieldsThatDoNotExist, Set<String> fieldPaths, Record record) throws OnRecordErrorException {\n        List<String> fieldsToNull = new ArrayList<>();\n\n    for (NullReplacerConditionalConfig nullReplacerConditionalConfig : nullReplacerConditionalConfigs) {\n      List<String> fieldNamesToNull = nullReplacerConditionalConfig.fieldsToNull;\n      //Gather fieldsPathsToNull for this nullReplacerConditionalConfig\n      List<String> fieldPathsToNull = new ArrayList<>();\n      //Gather existing paths for each nullReplacerConditionalConfig\n      //And if field does not exist gather them in fieldsThatDoNotExist\n      for (String fieldNameToNull : fieldNamesToNull) {\n        try {\n          final List<String> matchingPaths = FieldPathExpressionUtil.evaluateMatchingFieldPaths(\n              fieldNameToNull,\n              fieldPathEval,\n              fieldPathVars,\n              record,\n              fieldPaths\n          );\n          if (matchingPaths.isEmpty()) {\n            // FieldPathExpressionUtil.evaluateMatchingFieldPaths does NOT return the supplied param in its result\n            // regardless, like FieldRegexUtil#getMatchingFieldPaths did, so we add manually here\n            fieldsThatDoNotExist.add(fieldNameToNull);\n          } else {\n            for (String matchingField : matchingPaths) {\n              if (record.has(matchingField)) {\n                fieldPathsToNull.add(matchingField);\n              } else {\n                fieldsThatDoNotExist.add(matchingField);\n              }\n            }\n          }\n        } catch (ELEvalException e) {\n          LOG.error(\"Error evaluating condition: \" + nullReplacerConditionalConfig.condition, e);\n          throw new OnRecordErrorException(record, Errors.VALUE_REPLACER_07, fieldNameToNull, e.toString(), e);\n        }\n      }\n      //Now evaluate the condition in nullReplacerConditionalConfig\n      //If it empty or condition evaluates to true, add all the gathered fields in fieldsPathsToNull\n      // for this nullReplacerConditionalConfig to fieldsToNull\n      try {\n        boolean evaluatedCondition = true;\n        //If it is empty we assume it is true.\n        if (!StringUtils.isEmpty(nullReplacerConditionalConfig.condition)) {\n          evaluatedCondition = nullConditionELEval.eval(nullConditionELVars, nullReplacerConditionalConfig.condition, Boolean.class);\n        }\n        if (evaluatedCondition) {\n          fieldsToNull.addAll(fieldPathsToNull);\n        }\n      } catch (ELEvalException e) {\n        LOG.error(\"Error evaluating condition: \" + nullReplacerConditionalConfig.condition, e);\n        throw new OnRecordErrorException(record, Errors.VALUE_REPLACER_06, nullReplacerConditionalConfig.condition, e.toString());\n      }\n    }\n    return fieldsToNull;\n  }",
        "variable": "fieldsToNull",
        "reference": "this all fields to null",
        "explanation_by_ours": "The fields to null.",
        "explanation_by_baseline": "fieldsToNull for this null"
    },
    {
        "id": 427,
        "method": "public static Descriptors.Descriptor getDescriptor(\n      ProtoConfigurableEntity.Context context,\n      String protoDescriptorFile,\n      String messageType,\n      Map<String, Set<Descriptors.FieldDescriptor>> messageTypeToExtensionMap,\n      Map<String, Object> defaultValueMap\n  ) throws StageException {\n    File descriptorFileHandle = new File(context.getResourcesDirectory(), protoDescriptorFile);\n    try(\n      FileInputStream fin = new FileInputStream(descriptorFileHandle);\n      ) {\n      DescriptorProtos.FileDescriptorSet set = DescriptorProtos.FileDescriptorSet.parseFrom(fin);\n\n      // Iterate over all the file descriptor set computed above and cache dependencies and all encountered\n      // file descriptors\n\n      // this map holds all the dependencies that a given file descriptor has.\n      // This cached map will be looked up while building FileDescriptor instances\n      Map<String, Set<Descriptors.FileDescriptor>> fileDescriptorDependentsMap = new HashMap<>();\n      // All encountered FileDescriptor instances cached based on their name.\n      Map<String, Descriptors.FileDescriptor> fileDescriptorMap = new HashMap<>();\n      ProtobufTypeUtil.getAllFileDescriptors(set, fileDescriptorDependentsMap, fileDescriptorMap);\n\n            Descriptors.Descriptor descriptor = ProtobufTypeUtil.getDescriptor(set, fileDescriptorMap, protoDescriptorFile, messageType);\n\n      // Compute and cache all extensions defined for each message type\n      ProtobufTypeUtil.populateDefaultsAndExtensions(fileDescriptorMap, messageTypeToExtensionMap, defaultValueMap);\n      return descriptor;\n    } catch (FileNotFoundException e) {\n      throw new StageException(Errors.PROTOBUF_06, descriptorFileHandle.getAbsolutePath(), e);\n    } catch (IOException e) {\n      throw new StageException(Errors.PROTOBUF_08, e.toString(), e);\n    }\n  }",
        "variable": "descriptor",
        "reference": "the descriptor for the expected message type",
        "explanation_by_ours": "The descriptor to return.",
        "explanation_by_baseline": "the descriptor from the file"
    },
    {
        "id": 428,
        "method": "public static Descriptors.Descriptor getDescriptor(\n      DescriptorProtos.FileDescriptorSet set,\n      Map<String, Descriptors.FileDescriptor> fileDescriptorMap,\n      String descriptorFile,\n      String qualifiedMessageType\n  ) throws StageException {\n\n    // find the FileDescriptorProto which contains the message type\n    // IF cannot find, then bail out\n    String packageName = null;\n    String messageType = qualifiedMessageType;\n    int lastIndex = qualifiedMessageType.lastIndexOf('.');\n    if (lastIndex != -1) {\n      packageName = qualifiedMessageType.substring(0, lastIndex);\n      messageType = qualifiedMessageType.substring(lastIndex + 1);\n    }\n    DescriptorProtos.FileDescriptorProto file = getFileDescProtoForMsgType(packageName, messageType, set);\n    if (file == null) {\n      // could not find the message type from all the proto files contained in the descriptor file\n      throw new StageException(Errors.PROTOBUF_00, qualifiedMessageType, descriptorFile);\n    }\n        Descriptors.FileDescriptor fileDescriptor = fileDescriptorMap.get(file.getName());\n    // create builder using the FileDescriptor\n    // this can only find the top level message types\n    return fileDescriptor.findMessageTypeByName(messageType);\n\n  }",
        "variable": "fileDescriptor",
        "reference": "the FileDescriptor for the message type",
        "explanation_by_ours": "the file descriptor",
        "explanation_by_baseline": "the FileDescriptor from the"
    },
    {
        "id": 455,
        "method": "public String read(String path, String key, long delay) {\n    if (!secrets.containsKey(path)) {\n      VaultClient vault = new VaultClient(getConfig());\n      Secret secret;\n\n      try {\n        secret = vault.logical().read(path);\n      } catch (VaultException e) {\n        LOG.error(e.toString(), e);\n        throw new VaultRuntimeException(e.toString());\n      }\n\n      // Record the expiration date of this lease\n      String leaseId;\n      if (secret.isRenewable()) {\n                leaseId = secret.getLeaseId();\n      } else {\n                leaseId = path + \"/\";\n      }\n      leases.put(leaseId, System.currentTimeMillis() + (secret.getLeaseDuration() * 1000));\n\n      secrets.put(path, secret);\n\n      try {\n        Thread.sleep(delay);\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n      }\n    }\n\n    Map<String, Object> data = secrets.get(path).getData();\n    String value = getSecretValue(data, key).orElseThrow(() -> new VaultRuntimeException(\"Value not found for key\"));\n    LOG.trace(\"CredentialStore '{}' Vault, retrieved value for key '{}'\", csId, key);\n    return value;\n  }",
        "variable": "leaseId",
        "reference": "the expiration date of this lease",
        "explanation_by_ours": "the id of the lease",
        "explanation_by_baseline": "the leaseId for this secret"
    },
    {
        "id": 477,
        "method": "public void init(Source.Context context, String groupName, String prefix, List<Stage.ConfigIssue> issues) {\n\n        List<String> elConfigs = ImmutableList.of(\"resourceUrl\", \"requestBody\");\n    for (String configName : elConfigs) {\n      ELVars vars = context.createELVars();\n      vars.addVariable(START_AT, 0);\n      ELEval eval = context.createELEval(configName);\n      try {\n        eval.eval(vars, (String)getClass().getField(configName).get(this), String.class);\n      } catch (ELEvalException | NoSuchFieldException | IllegalAccessException e) {\n        LOG.error(Errors.HTTP_06.getMessage(), e.toString(), e);\n        issues.add(context.createConfigIssue(groupName, prefix + configName, Errors.HTTP_06, e.toString()));\n      }\n    }\n\n    client.init(context, Groups.PROXY.name(), prefix + \"client.\", issues);\n\n    // Validate the EL for each header entry\n    ELVars headerVars = context.createELVars();\n    ELEval headerEval = context.createELEval(\"headers\");\n    for (String headerValue : headers.values()) {\n      try {\n        headerEval.eval(headerVars, headerValue, String.class);\n      } catch (ELEvalException e) {\n        LOG.error(Errors.HTTP_06.getMessage(), e.toString(), e);\n        issues.add(context.createConfigIssue(groupName, prefix + \"headers\", Errors.HTTP_06, e.toString()));\n      }\n    }\n  }",
        "variable": "elConfigs",
        "reference": "the ELs for string configs",
        "explanation_by_ours": "the el configs",
        "explanation_by_baseline": "the EL for each config"
    },
    {
        "id": 490,
        "method": "public int produceEmptyBatchesForIdleRunners(long idleTime) throws PipelineException, StageException {\n    LOG.debug(\"Checking if any active runner is idle\");\n\n    // The empty batch is suppose to be fast - almost as a zero time. It could however happened that from some reason it\n    // will take a long time (possibly more then idleTime). To avoid infinite loops, this method will only processes up\n    // to total number of runners before returning.\n    int counter = 0;\n\n    try {\n      destroyLock.lock();\n\n      while(running && counter < pipes.size()) {\n        counter++;\n\n        PipeRunner runner = null;\n        try {\n          runner = runnerPool.getIdleRunner(idleTime);\n\n          // No more idle runners, simply stop the idle execution now\n          if(runner == null) {\n            return counter;\n          }\n\n          LOG.debug(\"Generating empty batch for runner: {}\", runner.getRunnerId());\n          pipeContext.getRuntimeStats().incIdleBatchCount();\n\n                    FullPipeBatch pipeBatch = new FullPipeBatch(null, null, 0, false);\n          pipeBatch.setIdleBatch(true);\n\n          // We're explicitly skipping origin because this is framework generated, empty batch\n          pipeBatch.skipStage(originPipe);\n\n          executeRunner(\n            runner,\n            System.currentTimeMillis(),\n            pipeBatch,\n            null,\n            null,\n            new HashMap<>(),\n            new HashMap<>()\n          );\n        } finally {\n          if(runner != null) {\n            runnerPool.returnRunner(runner);\n          }\n        }\n      }\n    } finally {\n      destroyLock.unlock();\n    }\n\n    return counter;\n  }",
        "variable": "pipeBatch",
        "reference": "Pipe batch to keep the batch info",
        "explanation_by_ours": "The full pipe batch to keep the batch info.",
        "explanation_by_baseline": "Generate empty batch for idle"
    },
    {
        "id": 497,
        "method": "@Override\n  public void createAndAddRecord(\n      ResultSet rs,\n      TableRuntimeContext tableRuntimeContext,\n      BatchContext batchContext\n  ) throws SQLException, StageException {\n    ResultSetMetaData md = rs.getMetaData();\n\n    LinkedHashMap<String, Field> fields = jdbcUtil.resultSetToFields(\n        rs,\n        commonSourceConfigBean,\n        errorRecordHandler,\n        tableJdbcConfigBean.unknownTypeAction,\n        recordHeader,\n        DatabaseVendor.SQL_SERVER\n    );\n\n    Map<String, String> columnOffsets = new HashMap<>();\n\n\n    // Generate Offset includes primary keys, sys_change_version, and sys_change_operation\n    for (String key : tableRuntimeContext.getSourceTableContext().getOffsetColumns()) {\n      String value = rs.getString(key);\n      if (Strings.isNullOrEmpty(value)) {\n        value = fields.get(key) != null ? fields.get(key).getValueAsString() : \"\";\n      }\n      columnOffsets.put(key, value);\n    }\n\n\n    columnOffsets.put(SYS_CHANGE_OPERATION, rs.getString(SYS_CHANGE_OPERATION));\n\n    String offsetFormat = OffsetQueryUtil.getOffsetFormat(columnOffsets);\n\n    Record record = context.createRecord(tableRuntimeContext.getQualifiedName() + \"::\" + offsetFormat);\n    record.set(Field.createListMap(fields));\n\n    //Set Column Headers\n    jdbcUtil.setColumnSpecificHeaders(\n        record,\n        Collections.singleton(tableRuntimeContext.getSourceTableContext().getTableName()),\n        md,\n        JDBC_NAMESPACE_HEADER\n    );\n\n        int op = MSOperationCode.convertToJDBCCode(rs.getString(SYS_CHANGE_OPERATION));\n    record.getHeader().setAttribute(OperationType.SDC_OPERATION_TYPE, String.valueOf(op));\n\n    for (String fieldName : recordHeader) {\n      record.getHeader().setAttribute(JDBC_NAMESPACE_HEADER + fieldName, rs.getString(fieldName) != null ? rs.getString(fieldName) : \"NULL\" );\n    }\n\n    int columns = rs.getMetaData().getColumnCount();\n    if (fields.size() != columns) {\n      errorRecordHandler.onError(JdbcErrors.JDBC_35, fields.size(), columns);\n      return; // Don't output this record.\n    } else {\n      batchContext.getBatchMaker().addRecord(record);\n    }\n\n    offsets.put(tableRuntimeContext.getOffsetKey(), offsetFormat);\n  }",
        "variable": "op",
        "reference": "Operation Headers",
        "explanation_by_ours": "{@inheritDoc}",
        "explanation_by_baseline": "Operation Type) {"
    },
    {
        "id": 507,
        "method": "@Override\n  public void doGet(HttpServletRequest request, HttpServletResponse response) {\n    try {\n      JsonGenerator jg = null;\n      String jsonpcb = null;\n      PrintWriter writer = null;\n      try {\n        writer = response.getWriter();\n\n        // \"callback\" parameter implies JSONP outpout\n        jsonpcb = request.getParameter(CALLBACK_PARAM);\n        if (jsonpcb != null) {\n          response.setContentType(\"application/javascript; charset=utf8\");\n          writer.write(jsonpcb + \"(\");\n        } else {\n          response.setContentType(\"application/json; charset=utf8\");\n        }\n\n        jg = jsonFactory.createGenerator(writer);\n        jg.disable(JsonGenerator.Feature.AUTO_CLOSE_TARGET);\n        jg.useDefaultPrettyPrinter();\n        jg.writeStartObject();\n\n        // query per mbean attribute\n        String getmethod = request.getParameter(\"get\");\n        if (getmethod != null) {\n          String[] splitStrings = getmethod.split(\"\\\\:\\\\:\");\n          if (splitStrings.length != 2) {\n            jg.writeStringField(\"result\", \"ERROR\");\n            jg.writeStringField(\"message\", \"query format is not as expected.\");\n            jg.flush();\n            response.setStatus(HttpServletResponse.SC_BAD_REQUEST);\n            return;\n          }\n          listBeans(jg, new ObjectName(splitStrings[0]), splitStrings[1],\n                    response);\n          return;\n        }\n\n                String qry = request.getParameter(\"qry\");\n        if (qry == null) {\n          qry = \"*:*\";\n        }\n        listBeans(jg, new ObjectName(qry), null, response);\n      } finally {\n        if (jg != null) {\n          jg.close();\n        }\n        if (jsonpcb != null) {\n          writer.write(\");\");\n        }\n        if (writer != null) {\n          writer.close();\n        }\n      }\n    } catch (IOException e) {\n\n      response.setStatus(HttpServletResponse.SC_INTERNAL_SERVER_ERROR);\n    } catch (MalformedObjectNameException e) {\n\n      response.setStatus(HttpServletResponse.SC_BAD_REQUEST);\n    }\n  }",
        "variable": "qry",
        "reference": "query per mbean",
        "explanation_by_ours": "The name of the query.",
        "explanation_by_baseline": "query per mbean attribute{"
    },
    {
        "id": 523,
        "method": "private Record createStartEvent() {\n    Preconditions.checkState(startEventStage != null, \"Start Event Stage is not set!\");\n    EventRecord eventRecord = new EventRecordImpl(\n      \"pipeline-start\",\n      1,\n      startEventStage.getInfo().getInstanceName(),\n      \"\",\n      null,\n      null\n    );\n\n    Map<String, Field> rootField = new LinkedHashMap<>();\n    rootField.put(\"user\", Field.create(Field.Type.STRING, userContext.getUser()));\n    rootField.put(\"pipelineId\", Field.create(Field.Type.STRING, name));\n    rootField.put(\"pipelineTitle\", Field.create(Field.Type.STRING, pipelineConf.getTitle()));\n\n        Map<String, Field> parameters = new LinkedHashMap<>();\n    if(runtimeParameters != null) {\n      for (Map.Entry<String, Object> entry : runtimeParameters.entrySet()) {\n        parameters.put(\n          entry.getKey(),\n          Field.create(Field.Type.STRING, entry.getValue().toString())\n        );\n      }\n    }\n    rootField.put(\"parameters\", Field.create(parameters));\n\n    eventRecord.set(Field.create(rootField));\n    return eventRecord;\n  }",
        "variable": "parameters",
        "reference": "Pipeline parameters",
        "explanation_by_ours": "the parameters",
        "explanation_by_baseline": "parameters = new LinkedHashMap<>();"
    },
    {
        "id": 528,
        "method": "private void setExceptions(Configuration configuration) {\n    this.exceptions.clear();\n    this.stageLibExceptions.clear();\n\n    // Load general exceptions\n    for(String path : configuration.get(PROPERTY_EXCEPTIONS, \"\").split(\",\")) {\n      this.exceptions.add(replaceVariables(path));\n    }\n\n        Configuration stageSpecific = configuration.getSubSetConfiguration(PROPERTY_STAGE_EXCEPTIONS, true);\n    for(Map.Entry<String, String> entry : stageSpecific.getValues().entrySet()) {\n      Set<String> stageExceptions = new HashSet<>();\n      for(String path : entry.getValue().split(\",\")) {\n        stageExceptions.add(replaceVariables(path));\n      }\n\n      this.stageLibExceptions.put(entry.getKey(), stageExceptions);\n    }\n  }",
        "variable": "stageSpecific",
        "reference": "Stage library specific exceptions",
        "explanation_by_ours": "the stage specific exceptions",
        "explanation_by_baseline": "stage specific exceptions) {"
    },
    {
        "id": 531,
        "method": "private static long getTimeFromRunner(\n    MetricRegistry metrics,\n    String runnerMetricName\n  ) {\n    // First get number of total runners from the runtime gauge\n    RuntimeStats runtimeStats = (RuntimeStats) ((Gauge)getMetric(metrics, \"RuntimeStatsGauge.gauge\", MetricType.GAUGE)).getValue();\n    long totalRunners = runtimeStats.getTotalRunners();\n\n    long currentTime = System.currentTimeMillis();\n    long maxTime = 0;\n\n    // Then iterate over all runners and find the biggest time difference\n    for(int runnerId = 0; runnerId < totalRunners; runnerId++) {\n      Map<String, Object> runnerMetrics = (Map<String, Object>) ((Gauge)getMetric(metrics, \"runner.\" + runnerId, MetricType.GAUGE)).getValue();\n\n            long value = (long) runnerMetrics.getOrDefault(runnerMetricName, 0L);\n\n      // Zero means that the runner is not in use at all and thus calculating running time makes no sense\n      if(value == 0) {\n        continue;\n      }\n\n      long runTime = currentTime - value;\n      if(maxTime < runTime) {\n        maxTime = runTime;\n      }\n    }\n\n    return maxTime;\n  }",
        "variable": "value",
        "reference": "current value",
        "explanation_by_ours": "the value of the metric",
        "explanation_by_baseline": "the value of the runner"
    },
    {
        "id": 535,
        "method": "private void decodeHeader(BufferedReader in, Map<String, String> pre, Map<String, List<String>> parms, Map<String, String> headers) throws ResponseException {\n        try {\n                        String inLine = in.readLine();\n            if (inLine == null) {\n                return;\n            }\n\n            StringTokenizer st = new StringTokenizer(inLine);\n            if (!st.hasMoreTokens()) {\n                throw new ResponseException(Status.BAD_REQUEST, \"BAD REQUEST: Syntax error. Usage: GET /example/file.html\");\n            }\n\n            pre.put(\"method\", st.nextToken());\n\n            if (!st.hasMoreTokens()) {\n                throw new ResponseException(Status.BAD_REQUEST, \"BAD REQUEST: Missing URI. Usage: GET /example/file.html\");\n            }\n\n            String uri = st.nextToken();\n\n            // Decode parameters from the URI\n            int qmi = uri.indexOf('?');\n            if (qmi >= 0) {\n                decodeParms(uri.substring(qmi + 1), parms);\n                uri = NanoHTTPD.decodePercent(uri.substring(0, qmi));\n            } else {\n                uri = NanoHTTPD.decodePercent(uri);\n            }\n\n            // If there's another token, its protocol version,\n            // followed by HTTP headers.\n            // NOTE: this now forces header names lower case since they are\n            // case insensitive and vary by client.\n            if (st.hasMoreTokens()) {\n                protocolVersion = st.nextToken();\n            } else {\n                protocolVersion = \"HTTP/1.1\";\n                NanoHTTPD.LOG.log(Level.FINE, \"no protocol version specified, strange. Assuming HTTP/1.1.\");\n            }\n            String line = in.readLine();\n            while (line != null && !line.trim().isEmpty()) {\n                int p = line.indexOf(':');\n                if (p >= 0) {\n                    headers.put(line.substring(0, p).trim().toLowerCase(Locale.US), line.substring(p + 1).trim());\n                }\n                line = in.readLine();\n            }\n\n            pre.put(\"uri\", uri);\n        } catch (IOException ioe) {\n            throw new ResponseException(Status.INTERNAL_ERROR, \"SERVER INTERNAL ERROR: IOException: \" + ioe.getMessage(), ioe);\n        }\n    }",
        "variable": "inLine",
        "reference": "the request line",
        "explanation_by_ours": "The line to decode.",
        "explanation_by_baseline": "the header lineif ("
    },
    {
        "id": 547,
        "method": "JSEArchiveMetaData create(final Deployment dep) {\n        if (WSLogger.ROOT_LOGGER.isTraceEnabled()) {\n            WSLogger.ROOT_LOGGER.tracef(\"Creating JBoss agnostic meta data for POJO webservice deployment: %s\", dep.getSimpleName());\n        }\n        final JBossWebMetaData jbossWebMD = WSHelper.getRequiredAttachment(dep, JBossWebMetaData.class);\n        final DeploymentUnit unit = WSHelper.getRequiredAttachment(dep, DeploymentUnit.class);\n        final List<POJOEndpoint> pojoEndpoints = getPojoEndpoints(unit);\n        final JSEArchiveMetaData.Builder builder = new JSEArchiveMetaData.Builder();\n\n        // set context root\n        final String contextRoot = getContextRoot(dep, jbossWebMD);\n        builder.setContextRoot(contextRoot);\n        WSLogger.ROOT_LOGGER.tracef(\"Setting context root: %s\", contextRoot);\n\n                final Map<String, String> servletMappings = getServletUrlPatternsMappings(jbossWebMD, pojoEndpoints);\n        builder.setServletMappings(servletMappings);\n\n        // set servlet class names mappings\n        final Map<String, String> servletClassNamesMappings = getServletClassMappings(jbossWebMD, pojoEndpoints);\n        builder.setServletClassNames(servletClassNamesMappings);\n\n        // set security domain\n        final String securityDomain = jbossWebMD.getSecurityDomain();\n        builder.setSecurityDomain(securityDomain);\n\n        // set wsdl location resolver\n        final JBossWebservicesMetaData jbossWebservicesMD = WSHelper.getOptionalAttachment(dep, JBossWebservicesMetaData.class);\n        if (jbossWebservicesMD != null) {\n            final PublishLocationAdapter resolver = new PublishLocationAdapterImpl(jbossWebservicesMD.getWebserviceDescriptions());\n            builder.setPublishLocationAdapter(resolver);\n        }\n\n        // set security meta data\n        final List<JSESecurityMetaData> jseSecurityMDs = getSecurityMetaData(jbossWebMD.getSecurityConstraints());\n        builder.setSecurityMetaData(jseSecurityMDs);\n\n        // set config name and file\n        setConfigNameAndFile(builder, jbossWebMD, jbossWebservicesMD);\n\n        return builder.build();\n    }",
        "variable": "servletMappings",
        "reference": "servlet url patterns mappings",
        "explanation_by_ours": "the servlet url patterns and servlet class names mappings",
        "explanation_by_baseline": "servlet url patterns mappings("
    },
    {
        "id": 551,
        "method": "JSEArchiveMetaData create(final Deployment dep) {\n        if (WSLogger.ROOT_LOGGER.isTraceEnabled()) {\n            WSLogger.ROOT_LOGGER.tracef(\"Creating JBoss agnostic meta data for POJO webservice deployment: %s\", dep.getSimpleName());\n        }\n        final JBossWebMetaData jbossWebMD = WSHelper.getRequiredAttachment(dep, JBossWebMetaData.class);\n        final DeploymentUnit unit = WSHelper.getRequiredAttachment(dep, DeploymentUnit.class);\n        final List<POJOEndpoint> pojoEndpoints = getPojoEndpoints(unit);\n        final JSEArchiveMetaData.Builder builder = new JSEArchiveMetaData.Builder();\n\n        // set context root\n        final String contextRoot = getContextRoot(dep, jbossWebMD);\n        builder.setContextRoot(contextRoot);\n        WSLogger.ROOT_LOGGER.tracef(\"Setting context root: %s\", contextRoot);\n\n        // set servlet url patterns mappings\n        final Map<String, String> servletMappings = getServletUrlPatternsMappings(jbossWebMD, pojoEndpoints);\n        builder.setServletMappings(servletMappings);\n\n        // set servlet class names mappings\n        final Map<String, String> servletClassNamesMappings = getServletClassMappings(jbossWebMD, pojoEndpoints);\n        builder.setServletClassNames(servletClassNamesMappings);\n\n        // set security domain\n        final String securityDomain = jbossWebMD.getSecurityDomain();\n        builder.setSecurityDomain(securityDomain);\n\n        // set wsdl location resolver\n        final JBossWebservicesMetaData jbossWebservicesMD = WSHelper.getOptionalAttachment(dep, JBossWebservicesMetaData.class);\n        if (jbossWebservicesMD != null) {\n            final PublishLocationAdapter resolver = new PublishLocationAdapterImpl(jbossWebservicesMD.getWebserviceDescriptions());\n            builder.setPublishLocationAdapter(resolver);\n        }\n\n                final List<JSESecurityMetaData> jseSecurityMDs = getSecurityMetaData(jbossWebMD.getSecurityConstraints());\n        builder.setSecurityMetaData(jseSecurityMDs);\n\n        // set config name and file\n        setConfigNameAndFile(builder, jbossWebMD, jbossWebservicesMD);\n\n        return builder.build();\n    }",
        "variable": "jseSecurityMDs",
        "reference": "security meta data",
        "explanation_by_ours": "the JSE security metadata",
        "explanation_by_baseline": "security metadata( ) ;"
    },
    {
        "id": 595,
        "method": "@Override\n    public void deploy(DeploymentPhaseContext deploymentPhase) throws DeploymentUnitProcessingException {\n\n        // get hold of the deployment unit.\n        final DeploymentUnit deploymentUnit = deploymentPhase.getDeploymentUnit();\n\n        // get the root of the deployment unit\n\n        final EEModuleDescription eeModuleDescription = deploymentUnit.getAttachment(org.jboss.as.ee.component.Attachments.EE_MODULE_DESCRIPTION);\n        final EEApplicationClasses applicationClassesDescription = deploymentUnit.getAttachment(org.jboss.as.ee.component.Attachments.EE_APPLICATION_CLASSES_DESCRIPTION);\n\n        final EjbJarMetaData ejbJarMetaData;\n        final EjbJarMetaData specMetaData = parseEjbJarXml(deploymentUnit);\n        final EjbJarMetaData jbossMetaData = parseJBossEjb3Xml(deploymentUnit);\n        if (specMetaData == null) {\n            if (jbossMetaData == null)\n                return;\n            ejbJarMetaData = jbossMetaData;\n        } else if (jbossMetaData == null) {\n            ejbJarMetaData = specMetaData;\n        } else {\n            ejbJarMetaData = jbossMetaData.createMerged(specMetaData);\n        }\n\n        // Mark it as an EJB deployment\n        EjbDeploymentMarker.mark(deploymentUnit);\n        if (!deploymentUnit.hasAttachment(EjbDeploymentAttachmentKeys.EJB_JAR_DESCRIPTION)) {\n            final EEModuleDescription moduleDescription = deploymentUnit.getAttachment(org.jboss.as.ee.component.Attachments.EE_MODULE_DESCRIPTION);\n            final EjbJarDescription ejbModuleDescription = new EjbJarDescription(moduleDescription, deploymentUnit.getName().endsWith(\".war\"));\n            deploymentUnit.putAttachment(EjbDeploymentAttachmentKeys.EJB_JAR_DESCRIPTION, ejbModuleDescription);\n        }\n\n        // attach the EjbJarMetaData to the deployment unit\n        deploymentUnit.putAttachment(EjbDeploymentAttachmentKeys.EJB_JAR_METADATA, ejbJarMetaData);\n\n        // if the jboss-ejb3.xml has a distinct-name configured then attach it to the deployment unit\n        if (jbossMetaData != null && jbossMetaData.getDistinctName() != null) {\n            deploymentUnit.putAttachment(org.jboss.as.ee.structure.Attachments.DISTINCT_NAME, jbossMetaData.getDistinctName());\n        }\n\n        if (ejbJarMetaData.getModuleName() != null) {\n            eeModuleDescription.setModuleName(ejbJarMetaData.getModuleName());\n        }\n        if (ejbJarMetaData.isMetadataComplete()) {\n            MetadataCompleteMarker.setMetadataComplete(deploymentUnit, true);\n        }\n        if (!ejbJarMetaData.isEJB3x()) {\n            //EJB spec 20.5.1, we do not process annotations for older deployments\n            MetadataCompleteMarker.setMetadataComplete(deploymentUnit, true);\n        }\n\n        if(ejbJarMetaData.getEnterpriseBeans() != null) {\n                        StringBuilder beans = new StringBuilder();\n            boolean error = false;\n            for (AbstractEnterpriseBeanMetaData bean : ejbJarMetaData.getEnterpriseBeans()) {\n                if (bean.getEjbType() == EjbType.ENTITY) {\n                    if (!error) {\n                        error = true;\n                    } else {\n                        beans.append(\", \");\n                    }\n                    beans.append(bean.getEjbName());\n                }\n            }\n            if (error) {\n                throw EjbLogger.ROOT_LOGGER.entityBeansAreNotSupported(beans.toString());\n            }\n        }\n\n    }",
        "variable": "beans",
        "reference": "entity beans",
        "explanation_by_ours": "the list of beans to be deployed.",
        "explanation_by_baseline": "unsupported entity beansif ("
    },
    {
        "id": 605,
        "method": "@Override\n    public void createPermissions(WarMetaData metaData, PolicyConfiguration pc) throws PolicyContextException {\n\n        JBossWebMetaData jbossWebMetaData = metaData.getMergedJBossWebMetaData();\n        HashMap<String, PatternInfo> patternMap = qualifyURLPatterns(jbossWebMetaData);\n\n        List<SecurityConstraintMetaData> secConstraints = jbossWebMetaData.getSecurityConstraints();\n\n        if (secConstraints != null) {\n            for (SecurityConstraintMetaData secConstraint : secConstraints) {\n                WebResourceCollectionsMetaData resourceCollectionsMetaData = secConstraint.getResourceCollections();\n                UserDataConstraintMetaData userDataConstraintMetaData = secConstraint.getUserDataConstraint();\n\n                if (resourceCollectionsMetaData != null) {\n                    if (secConstraint.isExcluded() || secConstraint.isUnchecked()) {\n                        // Process the permissions for the excluded/unchecked resources\n                        for (WebResourceCollectionMetaData resourceCollectionMetaData : resourceCollectionsMetaData) {\n                            List<String> httpMethods = new ArrayList<>(resourceCollectionMetaData.getHttpMethods());\n                            List<String> ommisions = resourceCollectionMetaData.getHttpMethodOmissions();\n                            if(httpMethods.isEmpty() && !ommisions.isEmpty()) {\n                                httpMethods.addAll(WebResourceCollectionMetaData.ALL_HTTP_METHODS);\n                                httpMethods.removeAll(ommisions);\n                            }\n                            List<String> urlPatterns = resourceCollectionMetaData.getUrlPatterns();\n                            for (String urlPattern : urlPatterns) {\n                                PatternInfo info = patternMap.get(urlPattern);\n                                info.descriptor=true;\n                                // Add the excluded methods\n                                if (secConstraint.isExcluded()) {\n                                    info.addExcludedMethods(httpMethods);\n                                }\n\n                                // SECURITY-63: Missing auth-constraint needs unchecked policy\n                                if (secConstraint.isUnchecked() && httpMethods.isEmpty()) {\n                                    info.isMissingAuthConstraint = true;\n                                } else {\n                                    info.missingAuthConstraintMethods.addAll(httpMethods);\n                                }\n                            }\n                        }\n                    } else {\n                        // Process the permission for the resources x roles\n                        for (WebResourceCollectionMetaData resourceCollectionMetaData : resourceCollectionsMetaData) {\n                            List<String> httpMethods = new ArrayList<>(resourceCollectionMetaData.getHttpMethods());\n                            List<String> methodOmissions = resourceCollectionMetaData.getHttpMethodOmissions();\n                            if(httpMethods.isEmpty() && !methodOmissions.isEmpty()) {\n                                httpMethods.addAll(WebResourceCollectionMetaData.ALL_HTTP_METHODS);\n                                httpMethods.removeAll(methodOmissions);\n                            }\n                            List<String> urlPatterns = resourceCollectionMetaData.getUrlPatterns();\n                            for (String urlPattern : urlPatterns) {\n                                // Get the qualified url pattern\n                                PatternInfo info = patternMap.get(urlPattern);\n                                info.descriptor=true;\n                                HashSet<String> mappedRoles = new HashSet<String>();\n                                secConstraint.getAuthConstraint().getRoleNames();\n                                List<String> authRoles = secConstraint.getAuthConstraint().getRoleNames();\n                                for (String role : authRoles) {\n                                    if (\"*\".equals(role)) {\n                                        // The wildcard ref maps to all declared security-role names\n                                        mappedRoles.addAll(jbossWebMetaData.getSecurityRoleNames());\n                                    }\n                                    else {\n                                        mappedRoles.add(role);\n                                    }\n                                }\n                                info.addRoles(mappedRoles, httpMethods);\n                                // Add the transport to methods\n                                if (userDataConstraintMetaData != null && userDataConstraintMetaData.getTransportGuarantee() != null)\n                                    info.addTransport(userDataConstraintMetaData.getTransportGuarantee().name(), httpMethods);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        JBossServletsMetaData servlets = jbossWebMetaData.getServlets();\n        List<ServletMappingMetaData> mappings = jbossWebMetaData.getServletMappings();\n        if(servlets != null && mappings != null) {\n\n            Map<String, List<String>> servletMappingMap = new HashMap<>();\n            for(ServletMappingMetaData mapping : mappings) {\n                List<String> list = servletMappingMap.get(mapping.getServletName());\n                if(list == null) {\n                    servletMappingMap.put(mapping.getServletName(), list = new ArrayList<>());\n                }\n                list.addAll(mapping.getUrlPatterns());\n            }\n            if(!jbossWebMetaData.isMetadataComplete()) {\n                for (JBossServletMetaData servlet : servlets) {\n                    ServletSecurityMetaData security = servlet.getServletSecurity();\n                    if (security != null) {\n                        List<String> servletMappings = servletMappingMap.get(servlet.getServletName());\n                        if (servletMappings != null) {\n\n                            if (security.getHttpMethodConstraints() != null) {\n                                for (HttpMethodConstraintMetaData s : security.getHttpMethodConstraints()) {\n                                    if (s.getRolesAllowed() == null || s.getRolesAllowed().isEmpty()) {\n                                        for (String urlPattern : servletMappings) {\n                                            // Get the qualified url pattern\n                                            PatternInfo info = patternMap.get(urlPattern);\n                                            if (info.descriptor) {\n                                                continue;\n                                            }\n                                            // Add the excluded methods\n                                            if (s.getEmptyRoleSemantic() == null || s.getEmptyRoleSemantic() == EmptyRoleSemanticType.PERMIT) {\n                                                info.missingAuthConstraintMethods.add(s.getMethod());\n                                            } else {\n                                                info.addExcludedMethods(Collections.singletonList(s.getMethod()));\n                                            }\n                                            // Add the transport to methods\n                                            if (s.getTransportGuarantee() != null)\n                                                info.addTransport(s.getTransportGuarantee().name(), Collections.singletonList(s.getMethod()));\n                                        }\n                                    } else {\n                                        for (String urlPattern : servletMappings) {\n                                            // Get the qualified url pattern\n                                            PatternInfo info = patternMap.get(urlPattern);\n                                            if (info.descriptor) {\n                                                continue;\n                                            }\n                                            HashSet<String> mappedRoles = new HashSet<String>();\n                                            List<String> authRoles = s.getRolesAllowed();\n                                            for (String role : authRoles) {\n                                                if (\"*\".equals(role)) {\n                                                    // The wildcard ref maps to all declared security-role names\n                                                    mappedRoles.addAll(jbossWebMetaData.getSecurityRoleNames());\n                                                } else {\n                                                    mappedRoles.add(role);\n                                                }\n                                            }\n                                            info.addRoles(mappedRoles, Collections.singletonList(s.getMethod()));\n                                            // Add the transport to methods\n                                            if (s.getTransportGuarantee() != null)\n                                                info.addTransport(s.getTransportGuarantee().name(), Collections.singletonList(s.getMethod()));\n                                        }\n                                    }\n                                }\n                            }\n                            if (security.getRolesAllowed() == null || security.getRolesAllowed().isEmpty()) {\n                                for (String urlPattern : servletMappings) {\n                                    // Get the qualified url pattern\n                                    PatternInfo info = patternMap.get(urlPattern);\n                                    if (info.descriptor) {\n                                        continue;\n                                    }\n                                    // Add the excluded methods\n                                    if (security.getEmptyRoleSemantic() == null || security.getEmptyRoleSemantic() == EmptyRoleSemanticType.PERMIT) {\n                                        info.isMissingAuthConstraint = true;\n                                    } else {\n                                        Set<String> methods = new HashSet<>(WebResourceCollectionMetaData.ALL_HTTP_METHODS);\n                                        if (security.getHttpMethodConstraints() != null) {\n                                            for (HttpMethodConstraintMetaData method : security.getHttpMethodConstraints()) {\n                                                methods.remove(method.getMethod());\n                                            }\n                                        }\n                                        info.addExcludedMethods(new ArrayList<>(methods));\n                                    }\n                                    // Add the transport to methods\n                                    if (security.getTransportGuarantee() != null)\n                                        info.addTransport(security.getTransportGuarantee().name(), Collections.emptyList());\n                                }\n                            } else {\n                                for (String urlPattern : servletMappings) {\n                                    // Get the qualified url pattern\n                                    PatternInfo info = patternMap.get(urlPattern);\n                                    if (info.descriptor) {\n                                        continue;\n                                    }\n                                    HashSet<String> mappedRoles = new HashSet<String>();\n                                    List<String> authRoles = security.getRolesAllowed();\n                                    for (String role : authRoles) {\n                                        if (\"*\".equals(role)) {\n                                            // The wildcard ref maps to all declared security-role names\n                                            mappedRoles.addAll(jbossWebMetaData.getSecurityRoleNames());\n                                        } else {\n                                            mappedRoles.add(role);\n                                        }\n                                    }\n                                    info.addRoles(mappedRoles, Collections.emptyList());\n                                    // Add the transport to methods\n                                    if (security.getTransportGuarantee() != null)\n                                        info.addTransport(security.getTransportGuarantee().name(), Collections.emptyList());\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        // Create the permissions\n        for (PatternInfo info : patternMap.values()) {\n            String qurl = info.getQualifiedPattern();\n            if (info.isOverridden) {\n                continue;\n            }\n            // Create the excluded permissions\n            String[] httpMethods = info.getExcludedMethods();\n            if (httpMethods != null) {\n                                WebResourcePermission wrp = new WebResourcePermission(qurl, httpMethods);\n                WebUserDataPermission wudp = new WebUserDataPermission(qurl, httpMethods, null);\n                pc.addToExcludedPolicy(wrp);\n                pc.addToExcludedPolicy(wudp);\n\n            }\n\n            // Create the role permissions\n            Iterator<Map.Entry<String, Set<String>>> roles = info.getRoleMethods();\n            Set<String> seenMethods = new HashSet<>();\n            while (roles.hasNext()) {\n                Map.Entry<String, Set<String>> roleMethods = roles.next();\n                String role = roleMethods.getKey();\n                Set<String> methods = roleMethods.getValue();\n                seenMethods.addAll(methods);\n                httpMethods = methods.toArray(new String[methods.size()]);\n                pc.addToRole(role, new WebResourcePermission(qurl, httpMethods));\n\n            }\n\n            //there are totally 7 http methods from the jacc spec (See WebResourceCollectionMetaData.ALL_HTTP_METHOD_NAMES)\n            final int NUMBER_OF_HTTP_METHODS = 7;\n            // JACC 1.1: create !(httpmethods) in unchecked perms\n            if(jbossWebMetaData.getDenyUncoveredHttpMethods() == null) {\n                if (seenMethods.size() != NUMBER_OF_HTTP_METHODS) {\n                    WebResourcePermission wrpUnchecked = new WebResourcePermission(qurl, \"!\"\n                            + getCommaSeparatedString(seenMethods.toArray(new String[seenMethods.size()])));\n                    pc.addToUncheckedPolicy(wrpUnchecked);\n                }\n            }\n            if (jbossWebMetaData.getDenyUncoveredHttpMethods() == null) {\n                // Create the unchecked permissions\n                String[] missingHttpMethods = info.getMissingMethods();\n                int length = missingHttpMethods.length;\n                roles = info.getRoleMethods();\n                if (length > 0 && !roles.hasNext()) {\n                                        WebResourcePermission wrp = new WebResourcePermission(qurl, missingHttpMethods);\n                    pc.addToUncheckedPolicy(wrp);\n                } else if (!roles.hasNext()) {\n                    pc.addToUncheckedPolicy(new WebResourcePermission(qurl, (String) null));\n                }\n\n                // SECURITY-63: Missing auth-constraint needs unchecked policy\n                if (info.isMissingAuthConstraint) {\n                    pc.addToUncheckedPolicy(new WebResourcePermission(qurl, (String) null));\n                } else if (!info.allMethods.containsAll(WebResourceCollectionMetaData.ALL_HTTP_METHODS)) {\n                    List<String> methods = new ArrayList<>(WebResourceCollectionMetaData.ALL_HTTP_METHODS);\n                    methods.removeAll(info.allMethods);\n                    pc.addToUncheckedPolicy(new WebResourcePermission(qurl, methods.toArray(new String[methods.size()])));\n\n                }\n                if (!info.missingAuthConstraintMethods.isEmpty()) {\n                    pc.addToUncheckedPolicy(new WebResourcePermission(qurl, info.missingAuthConstraintMethods.toArray(new String[info.missingAuthConstraintMethods.size()])));\n                }\n            }\n\n            // Create the unchecked permissions WebUserDataPermissions\n            Iterator<Map.Entry<String, Set<String>>> transportConstraints = info.getTransportMethods();\n            while (transportConstraints.hasNext()) {\n                Map.Entry<String, Set<String>> transportMethods = transportConstraints.next();\n                String transport = transportMethods.getKey();\n                Set<String> methods = transportMethods.getValue();\n                httpMethods = new String[methods.size()];\n                methods.toArray(httpMethods);\n                WebUserDataPermission wudp = new WebUserDataPermission(qurl, httpMethods, transport);\n                pc.addToUncheckedPolicy(wudp);\n\n                // If the transport is \"NONE\", then add an exclusive WebUserDataPermission\n                // with the url pattern and null\n                if (\"NONE\".equals(transport)) {\n                    WebUserDataPermission wudp1 = new WebUserDataPermission(qurl, null);\n                    pc.addToUncheckedPolicy(wudp1);\n                } else {\n                    // JACC 1.1: Transport is CONFIDENTIAL/INTEGRAL, add a !(http methods)\n                    WebUserDataPermission wudpNonNull = new WebUserDataPermission(qurl, \"!\"\n                            + getCommaSeparatedString(httpMethods));\n                    pc.addToUncheckedPolicy(wudpNonNull);\n                }\n            }\n        }\n\n        Set<String> declaredRoles = jbossWebMetaData.getSecurityRoleNames();\n        declaredRoles.add(ANY_AUTHENTICATED_USER_ROLE);\n\n        /*\n         * Create WebRoleRefPermissions for all servlet/security-role-refs along with all the cross product of servlets and\n         * security-role elements that are not referenced via a security-role-ref as described in JACC section 3.1.3.2\n         */\n        JBossServletsMetaData servletsMetaData = jbossWebMetaData.getServlets();\n        for (JBossServletMetaData servletMetaData : servletsMetaData) {\n            Set<String> unrefRoles = new HashSet<String>(declaredRoles);\n            String servletName = servletMetaData.getName();\n            SecurityRoleRefsMetaData roleRefsMetaData = servletMetaData.getSecurityRoleRefs();\n            // Perform the unreferenced roles processing for every servlet name\n            if (roleRefsMetaData != null) {\n                for (SecurityRoleRefMetaData roleRefMetaData : roleRefsMetaData) {\n                    String roleRef = roleRefMetaData.getRoleLink();\n                    String roleName = roleRefMetaData.getRoleName();\n                    WebRoleRefPermission wrrp = new WebRoleRefPermission(servletName, roleName);\n                    pc.addToRole(roleRef, wrrp);\n\n                    // Remove the role from the unreferencedRoles\n                    unrefRoles.remove(roleName);\n                }\n            }\n            // Spec 3.1.3.2: For each servlet element in the deployment descriptor\n            // a WebRoleRefPermission must be added to each security-role of the\n            // application whose name does not appear as the rolename\n            // in a security-role-ref within the servlet element.\n            for (String unrefRole : unrefRoles) {\n                WebRoleRefPermission unrefP = new WebRoleRefPermission(servletName, unrefRole);\n                pc.addToRole(unrefRole, unrefP);\n            }\n        }\n\n        // JACC 1.1:Spec 3.1.3.2: For each security-role defined in the deployment descriptor, an\n        // additional WebRoleRefPermission must be added to the corresponding role by\n        // calling the addToRole method on the PolicyConfiguration object. The\n        // name of all such permissions must be the empty string, and the actions of each\n        // such permission must be the role-name of the corresponding role.\n        for (String role : declaredRoles) {\n            WebRoleRefPermission wrrep = new WebRoleRefPermission(\"\", role);\n            pc.addToRole(role, wrrep);\n        }\n    }",
        "variable": "wrp",
        "reference": "WebResourcePermissions",
        "explanation_by_ours": "the policy configuration",
        "explanation_by_baseline": "if (security.getHttp"
    },
    {
        "id": 610,
        "method": "private void processViewAnnotations(final DeploymentUnit deploymentUnit, final Class<?> sessionBeanClass, final SessionBeanComponentDescription sessionBeanComponentDescription) throws DeploymentUnitProcessingException {\n        final Collection<Class<?>> remoteBusinessInterfaces = this.getRemoteBusinessInterfaces(deploymentUnit, sessionBeanClass);\n        if (remoteBusinessInterfaces != null && !remoteBusinessInterfaces.isEmpty()) {\n            sessionBeanComponentDescription.addRemoteBusinessInterfaceViews(this.toString(remoteBusinessInterfaces));\n        }\n\n                Collection<Class<?>> localBusinessInterfaces = this.getLocalBusinessInterfaces(deploymentUnit, sessionBeanClass);\n        if (localBusinessInterfaces != null && !localBusinessInterfaces.isEmpty()) {\n            sessionBeanComponentDescription.addLocalBusinessInterfaceViews(this.toString(localBusinessInterfaces));\n        }\n\n        if (hasNoInterfaceView(sessionBeanClass)) {\n            sessionBeanComponentDescription.addNoInterfaceView();\n        }\n\n        // EJB 3.1 FR 4.9.7 & 4.9.8, if the bean exposes no views\n        if (hasNoViews(sessionBeanComponentDescription)) {\n            final Set<Class<?>> potentialBusinessInterfaces = getPotentialBusinessInterfaces(sessionBeanClass);\n            if (potentialBusinessInterfaces.isEmpty()) {\n                sessionBeanComponentDescription.addNoInterfaceView();\n            } else if (potentialBusinessInterfaces.size() == 1) {\n                sessionBeanComponentDescription.addLocalBusinessInterfaceViews(potentialBusinessInterfaces.iterator().next().getName());\n            } else if (isEjbVersionGreaterThanOrEqualTo32(deploymentUnit)) {\n                // EJB 3.2 spec states (section 4.9.7):\n                // ... or if the bean class is annotated with neither the Local nor the Remote annotation, all implemented interfaces (excluding the interfaces listed above)\n                // are assumed to be local business interfaces of the bean\n                sessionBeanComponentDescription.addLocalBusinessInterfaceViews(toString(potentialBusinessInterfaces));\n            }\n        }\n    }",
        "variable": "localBusinessInterfaces",
        "reference": "the local business interfaces of the bean",
        "explanation_by_ours": "the local business interfaces",
        "explanation_by_baseline": "local business interfacessessionBean"
    },
    {
        "id": 619,
        "method": "public static String getTypeIDLName(Class cls)\n            throws RMIIIOPViolationException {\n\n        if (cls.isPrimitive())\n            return PrimitiveAnalysis.getPrimitiveAnalysis(cls).getIDLName();\n\n        if (cls.isArray()) {\n            // boxedRMI 1.3.6\n            Class componentClass = cls;\n            int sequence = 0;\n            while (componentClass.isArray()) {\n                componentClass = componentClass.getComponentType();\n                ++sequence;\n            }\n\n            String idlName = getTypeIDLName(componentClass);\n            int idx = idlName.lastIndexOf(\"::\");\n            String idlModule = idlName.substring(0, idx + 2);\n            String baseName = idlName.substring(idx + 2);\n            return \"::org::omg::boxedRMI\" + idlModule + \"seq\" + sequence + \"_\" + baseName;\n        }\n\n        // special classes\n        if (cls == java.lang.String.class)\n            return \"::CORBA::WStringValue\";\n        if (cls == java.lang.Object.class)\n            return \"::java::lang::_Object\";\n        if (cls == java.lang.Class.class)\n            return \"::javax::rmi::CORBA::ClassDesc\";\n        if (cls == java.io.Serializable.class)\n            return \"::java::io::Serializable\";\n        if (cls == java.io.Externalizable.class)\n            return \"::java::io::Externalizable\";\n        if (cls == java.rmi.Remote.class)\n            return \"::java::rmi::Remote\";\n        if (cls == org.omg.CORBA.Object.class)\n            return \"::CORBA::Object\";\n\n\n        // remote interface?\n        if (cls.isInterface() && java.rmi.Remote.class.isAssignableFrom(cls)) {\n            InterfaceAnalysis ia = InterfaceAnalysis.getInterfaceAnalysis(cls);\n\n            return ia.getIDLModuleName() + \"::\" + ia.getIDLName();\n        }\n\n        // IDL interface?\n        if (cls.isInterface() &&\n                org.omg.CORBA.Object.class.isAssignableFrom(cls) &&\n                org.omg.CORBA.portable.IDLEntity.class.isAssignableFrom(cls)) {\n            InterfaceAnalysis ia = InterfaceAnalysis.getInterfaceAnalysis(cls);\n\n            return ia.getIDLModuleName() + \"::\" + ia.getIDLName();\n        }\n\n        // exception?\n        if (Throwable.class.isAssignableFrom(cls)) {\n            if (Exception.class.isAssignableFrom(cls) &&\n                    !RuntimeException.class.isAssignableFrom(cls)) {\n                ExceptionAnalysis ea = ExceptionAnalysis.getExceptionAnalysis(cls);\n\n                return ea.getIDLModuleName() + \"::\" + ea.getIDLName();\n            }\n        }\n\n                ValueAnalysis va = ValueAnalysis.getValueAnalysis(cls);\n\n        return va.getIDLModuleName() + \"::\" + va.getIDLName();\n    }",
        "variable": "va",
        "reference": "value",
        "explanation_by_ours": "the value of the class to get the fully qualified name for",
        "explanation_by_baseline": "a value?if ("
    },
    {
        "id": 624,
        "method": "static long getClassHashCode(Class cls) {\n        // The simple cases\n        if (cls.isInterface())\n            return 0;\n        if (!Serializable.class.isAssignableFrom(cls))\n            return 0;\n        if (Externalizable.class.isAssignableFrom(cls))\n            return 1;\n\n        // Try cache\n        Long l = (Long) classHashCodeCache.get(cls);\n        if (l != null)\n            return l.longValue();\n\n        // Has to calculate the hash.\n\n        ByteArrayOutputStream baos = new ByteArrayOutputStream(256);\n        DataOutputStream dos = new DataOutputStream(baos);\n\n        // Step 1\n        Class superClass = cls.getSuperclass();\n        if (superClass != null && superClass != Object.class) {\n            try {\n                dos.writeLong(getClassHashCode(superClass));\n            } catch (IOException ex) {\n                throw IIOPLogger.ROOT_LOGGER.unexpectedException(ex);\n            }\n        }\n\n        // Step 2\n        boolean hasWriteObject = false;\n        try {\n            Method m;\n            int mods;\n\n            m = cls.getDeclaredMethod(\"writeObject\",\n                    new Class[]{ObjectOutputStream.class});\n            mods = m.getModifiers();\n\n            if (!Modifier.isPrivate(mods) && !Modifier.isStatic(mods))\n                hasWriteObject = true;\n        } catch (NoSuchMethodException ex) {\n            // ignore\n        }\n        try {\n            dos.writeInt(hasWriteObject ? 2 : 1);\n        } catch (IOException ex) {\n            throw IIOPLogger.ROOT_LOGGER.unexpectedException(ex);\n        }\n\n        // Step 3\n        Field[] fields = cls.getDeclaredFields();\n        SortedSet set = new TreeSet(new FieldComparator());\n\n        for (int i = 0; i < fields.length; ++i) {\n            int mods = fields[i].getModifiers();\n\n            if (!Modifier.isStatic(mods) && !Modifier.isTransient(mods))\n                set.add(fields[i]);\n        }\n        Iterator iter = set.iterator();\n        try {\n            while (iter.hasNext()) {\n                Field f = (Field) iter.next();\n\n                dos.writeUTF(f.getName());\n                dos.writeUTF(getSignature(f.getType()));\n            }\n        } catch (IOException ex) {\n            throw IIOPLogger.ROOT_LOGGER.unexpectedException(ex);\n        }\n\n        // Convert to byte[]\n        try {\n            dos.flush();\n        } catch (IOException ex) {\n            throw IIOPLogger.ROOT_LOGGER.unexpectedException(ex);\n        }\n        byte[] bytes = baos.toByteArray();\n\n        // Calculate SHA digest\n        MessageDigest digest;\n        try {\n            digest = MessageDigest.getInstance(\"SHA\");\n        } catch (NoSuchAlgorithmException ex) {\n            throw IIOPLogger.ROOT_LOGGER.unavailableSHADigest(ex);\n        }\n        digest.update(bytes);\n        byte[] sha = digest.digest();\n\n        // Calculate hash as per section 10.6.2\n        long hash = 0;\n        for (int i = 0; i < Math.min(8, sha.length); i++) {\n            hash += (long) (sha[i] & 255) << (i * 8);\n        }\n\n        // Save in cache\n        classHashCodeCache.put(cls, new Long(hash));\n\n        return hash;\n    }",
        "variable": "digest",
        "reference": "SHA digest",
        "explanation_by_ours": "the digest to use",
        "explanation_by_baseline": "hash as per section 10."
    },
    {
        "id": 627,
        "method": "@Override\n    public void deploy(final DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {\n        final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();\n        final JBossServiceXmlDescriptor serviceXmlDescriptor = deploymentUnit.getAttachment(JBossServiceXmlDescriptor.ATTACHMENT_KEY);\n        if (serviceXmlDescriptor == null) {\n            // Skip deployments without a service xml descriptor\n            return;\n        }\n\n                final Module module = deploymentUnit.getAttachment(Attachments.MODULE);\n        if (module == null)\n            throw SarLogger.ROOT_LOGGER.failedToGetAttachment(\"module\", deploymentUnit);\n\n        // assert reflection index\n        final DeploymentReflectionIndex reflectionIndex = deploymentUnit.getAttachment(Attachments.REFLECTION_INDEX);\n        if (reflectionIndex == null)\n            throw SarLogger.ROOT_LOGGER.failedToGetAttachment(\"reflection index\", deploymentUnit);\n\n        // install services\n        final ClassLoader classLoader = module.getClassLoader();\n        final List<JBossServiceConfig> serviceConfigs = serviceXmlDescriptor.getServiceConfigs();\n        final ServiceTarget target = phaseContext.getServiceTarget();\n        final Map<String,ServiceComponentInstantiator> serviceComponents = deploymentUnit.getAttachment(ServiceAttachments.SERVICE_COMPONENT_INSTANTIATORS);\n        for (final JBossServiceConfig serviceConfig : serviceConfigs) {\n            addServices(target, serviceConfig, classLoader, reflectionIndex, serviceComponents != null ? serviceComponents.get(serviceConfig.getName()) : null, phaseContext);\n        }\n    }",
        "variable": "module",
        "reference": "assert module",
        "explanation_by_ours": "the deployment unit's module.",
        "explanation_by_baseline": "assert module= deploymentUnit"
    },
    {
        "id": 630,
        "method": "synchronized void addListener(final String target, final int scope, final NamingListener namingListener) {\n        final TargetScope targetScope = new TargetScope(target, scope);\n                ListenerHolder holder = holdersByListener.get(namingListener);\n        if (holder == null) {\n            holder = new ListenerHolder(namingListener, targetScope);\n            final Map<NamingListener, ListenerHolder> byListenerCopy = new FastCopyHashMap<NamingListener, ListenerHolder>(holdersByListener);\n            byListenerCopy.put(namingListener, holder);\n            holdersByListener = byListenerCopy;\n        } else {\n            holder.addTarget(targetScope);\n        }\n\n        List<ListenerHolder> holdersForTarget = holdersByTarget.get(targetScope);\n        if (holdersForTarget == null) {\n            holdersForTarget = new CopyOnWriteArrayList<ListenerHolder>();\n            final Map<TargetScope, List<ListenerHolder>> byTargetCopy = new FastCopyHashMap<TargetScope, List<ListenerHolder>>(holdersByTarget);\n            byTargetCopy.put(targetScope, holdersForTarget);\n            holdersByTarget = byTargetCopy;\n        }\n        holdersForTarget.add(holder);\n    }",
        "variable": "holder",
        "reference": "the holder for this listener",
        "explanation_by_ours": "the holder",
        "explanation_by_baseline": ") { if ( holder"
    },
    {
        "id": 667,
        "method": "@Override\n    public List<PersistenceProvider> getPersistenceProviders() {\n        List<PersistenceProvider> providersCopy = new ArrayList<>(providers.size());\n\n        /**\n         * Add the application specified providers first so they are found before the global providers\n         */\n        synchronized(persistenceProviderPerClassLoader) {\n            if (persistenceProviderPerClassLoader.size() > 0) {\n                                ClassLoader deploymentClassLoader = findParentModuleCl(WildFlySecurityManager.getCurrentContextClassLoaderPrivileged());\n                ROOT_LOGGER.tracef(\"get application level Persistence Provider for classloader %s\" , deploymentClassLoader);\n                // collect persistence providers associated with deployment/each sub-deployment\n                List<Class<? extends PersistenceProvider>> deploymentSpecificPersistenceProviders = persistenceProviderPerClassLoader.get(deploymentClassLoader);\n                ROOT_LOGGER.tracef(\"got application level Persistence Provider list %s\" , deploymentSpecificPersistenceProviders);\n                if (deploymentSpecificPersistenceProviders != null) {\n\n                    for (Class<? extends PersistenceProvider> providerClass : deploymentSpecificPersistenceProviders) {\n                        try {\n                            ROOT_LOGGER.tracef(\"application has its own Persistence Provider %s\", providerClass.getName());\n                            providersCopy.add(providerClass.newInstance());\n                        } catch (InstantiationException e) {\n                            throw JpaLogger.ROOT_LOGGER.couldNotCreateInstanceProvider(e, providerClass.getName());\n                        } catch (IllegalAccessException e) {\n                            throw JpaLogger.ROOT_LOGGER.couldNotCreateInstanceProvider(e, providerClass.getName());\n                        }\n                    }\n                }\n            }\n        }\n\n        // add global persistence providers last (so application packaged providers have priority)\n        for (Class<?> providerClass : providers) {\n            try {\n                providersCopy.add((PersistenceProvider) providerClass.newInstance());\n                ROOT_LOGGER.tracef(\"returning global (module) Persistence Provider %s\", providerClass.getName());\n            } catch (InstantiationException e) {\n                throw JpaLogger.ROOT_LOGGER.couldNotCreateInstanceProvider(e, providerClass.getName());\n            } catch (IllegalAccessException e) {\n                throw JpaLogger.ROOT_LOGGER.couldNotCreateInstanceProvider(e, providerClass.getName());\n            }\n        }\n        return providersCopy;\n    }",
        "variable": "deploymentClassLoader",
        "reference": "the deployment or subdeployment classloader",
        "explanation_by_ours": "the classloader of the deployment or sub-deployment.",
        "explanation_by_baseline": "application level persistence provider for"
    },
    {
        "id": 696,
        "method": "protected void fixupOverloadedOperationNames()\n            throws RMIIIOPViolationException {\n        for (int i = 0; i < methods.length; ++i) {\n            if ((m_flags[i] & M_OVERLOADED) == 0)\n                continue;\n\n                        OperationAnalysis oa = null;\n            String javaName = methods[i].getName();\n            for (int opIdx = 0; oa == null && opIdx < operations.length; ++opIdx)\n                if (operations[opIdx].getMethod().equals(methods[i]))\n                    oa = operations[opIdx];\n\n            if (oa == null)\n                continue; // This method is not mapped.\n\n            // Calculate new IDL name\n            ParameterAnalysis[] params = oa.getParameters();\n            StringBuffer b = new StringBuffer(oa.getIDLName());\n            if (params.length == 0)\n                b.append(\"__\");\n            for (int j = 0; j < params.length; ++j) {\n                String s = params[j].getTypeIDLName();\n\n                if (s.startsWith(\"::\"))\n                    s = s.substring(2);\n\n                if (s.startsWith(\"_\")) {\n                    // remove leading underscore in IDL escaped identifier\n                    s = s.substring(1);\n                }\n\n                b.append('_');\n\n                while (!\"\".equals(s)) {\n                    int idx = s.indexOf(\"::\");\n\n                    b.append('_');\n\n                    if (idx == -1) {\n                        b.append(s);\n                        s = \"\";\n                    } else {\n                        b.append(s.substring(0, idx));\n                        if (s.length() > idx + 2 && s.charAt(idx + 2) == '_') {\n                            // remove leading underscore in IDL escaped identifier\n                            s = s.substring(idx + 3);\n                        } else {\n                            s = s.substring(idx + 2);\n                        }\n                    }\n                }\n            }\n\n            // Set new IDL name\n            oa.setIDLName(b.toString());\n        }\n    }",
        "variable": "oa",
        "reference": "the operation",
        "explanation_by_ours": "The OperationAnalysis that is mapped to the method.",
        "explanation_by_baseline": "operation analysis for this method"
    },
    {
        "id": 711,
        "method": "private static ClassFile generateCode(InterfaceAnalysis interfaceAnalysis,\n                                       Class<?> superclass, String stubClassName) {\n        final ClassFile asm =\n                new ClassFile(stubClassName, superclass.getName(), null, ModuleClassFactory.INSTANCE, interfaceAnalysis.getCls().getName());\n\n        int methodIndex = 0;\n\n        AttributeAnalysis[] attrs = interfaceAnalysis.getAttributes();\n        for (int i = 0; i < attrs.length; i++) {\n            OperationAnalysis op = attrs[i].getAccessorAnalysis();\n            generateMethodCode(asm, superclass, op.getMethod(), op.getIDLName(),\n                    strategy(methodIndex), init(methodIndex));\n            methodIndex++;\n            op = attrs[i].getMutatorAnalysis();\n            if (op != null) {\n                generateMethodCode(asm, superclass,\n                        op.getMethod(), op.getIDLName(),\n                        strategy(methodIndex), init(methodIndex));\n                methodIndex++;\n            }\n        }\n\n        final OperationAnalysis[] ops = interfaceAnalysis.getOperations();\n        for (int i = 0; i < ops.length; i++) {\n            generateMethodCode(asm, superclass,\n                    ops[i].getMethod(), ops[i].getIDLName(),\n                    strategy(methodIndex), init(methodIndex));\n            methodIndex++;\n        }\n\n                final ClassMethod ctor = asm.addMethod(Modifier.PUBLIC, \"<init>\", \"V\");\n        ctor.getCodeAttribute().aload(0);\n        ctor.getCodeAttribute().invokespecial(superclass.getName(), \"<init>\", \"()V\");\n        ctor.getCodeAttribute().returnInstruction();\n\n        // Generate the method _ids(), declared as abstract in ObjectImpl\n        final String[] ids = interfaceAnalysis.getAllTypeIds();\n        asm.addField(Modifier.PRIVATE + Modifier.STATIC, ID_FIELD_NAME, String[].class);\n        final CodeAttribute idMethod = asm.addMethod(Modifier.PUBLIC + Modifier.FINAL, \"_ids\", \"[Ljava/lang/String;\").getCodeAttribute();\n        idMethod.getstatic(stubClassName, ID_FIELD_NAME, \"[Ljava/lang/String;\");\n        idMethod.returnInstruction();\n\n        // Generate the static initializer\n        final CodeAttribute clinit = asm.addMethod(Modifier.STATIC, \"<clinit>\", \"V\").getCodeAttribute();\n        clinit.iconst(ids.length);\n        clinit.anewarray(String.class.getName());\n        for (int i = 0; i < ids.length; i++) {\n            clinit.dup();\n            clinit.iconst(i);\n            clinit.ldc(ids[i]);\n            clinit.aastore();\n        }\n        clinit.putstatic(stubClassName, ID_FIELD_NAME, \"[Ljava/lang/String;\");\n\n        int n = methodIndex; // last methodIndex + 1\n        for (methodIndex = 0; methodIndex < n; methodIndex++) {\n            clinit.invokestatic(stubClassName, init(methodIndex), \"()V\");\n        }\n        clinit.returnInstruction();\n\n        return asm;\n    }",
        "variable": "ctor",
        "reference": "the constructor",
        "explanation_by_ours": "the constructor",
        "explanation_by_baseline": "the method <init>"
    },
    {
        "id": 721,
        "method": "public SecurityDomainContext createSecurityDomainContext(String securityDomain,\n                                                                    AuthenticationCacheFactory cacheFactory,\n                                                                    JSSESecurityDomain jsseSecurityDomain) throws Exception {\n        SecurityLogger.ROOT_LOGGER.debugf(\"Creating SDC for domain = %s\", securityDomain);\n        AuthenticationManager am = createAuthenticationManager(securityDomain);\n        if (cacheFactory != null && am instanceof CacheableManager) {\n                        final Map<Principal, ?> cache = cacheFactory.getCache();\n            if (cache != null) {\n                @SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n                CacheableManager<Map, Principal> cm = (CacheableManager<Map, Principal>) am;\n                cm.setCache(cache);\n            }\n        }\n\n        // set DeepCopySubject option if supported\n        if (deepCopySubjectMode) {\n            setDeepCopySubjectMode(am);\n        }\n\n        return new SecurityDomainContext(am,\n                createAuthorizationManager(securityDomain),\n                createAuditManager(securityDomain),\n                createIdentityTrustManager(securityDomain), createMappingManager(securityDomain),\n                jsseSecurityDomain);\n    }",
        "variable": "cache",
        "reference": "the authentication cache",
        "explanation_by_ours": "the authentication cache",
        "explanation_by_baseline": "// create security domain context"
    },
    {
        "id": 736,
        "method": "private void addClass(Class cls)\n            throws RMIIIOPViolationException, IRConstructionException {\n        if (cls.isPrimitive())\n            return; // No need to add primitives.\n\n        if (cls.isArray()) {\n            // Add array mapping\n            addArray(cls);\n        } else if (cls.isInterface()) {\n            if (!RmiIdlUtil.isAbstractValueType(cls)) {\n                                InterfaceAnalysis ia = InterfaceAnalysis.getInterfaceAnalysis(cls);\n\n                // Add analyzed interface (which may be abstract)\n                addInterface(ia);\n            } else {\n                // Analyse the value\n                ValueAnalysis va = ValueAnalysis.getValueAnalysis(cls);\n\n                // Add analyzed value\n                addValue(va);\n            }\n        } else if (Exception.class.isAssignableFrom(cls)) { // Exception type.\n            // Analyse the exception\n            ExceptionAnalysis ea = ExceptionAnalysis.getExceptionAnalysis(cls);\n\n            // Add analyzed exception\n            addException(ea);\n        } else { // Got to be a value type.\n            // Analyse the value\n            ValueAnalysis va = ValueAnalysis.getValueAnalysis(cls);\n\n            // Add analyzed value\n            addValue(va);\n        }\n    }",
        "variable": "ia",
        "reference": "the interface",
        "explanation_by_ours": "the interface to add to the list of analyses",
        "explanation_by_baseline": "the interface{ //"
    },
    {
        "id": 737,
        "method": "private void addClass(Class cls)\n            throws RMIIIOPViolationException, IRConstructionException {\n        if (cls.isPrimitive())\n            return; // No need to add primitives.\n\n        if (cls.isArray()) {\n            // Add array mapping\n            addArray(cls);\n        } else if (cls.isInterface()) {\n            if (!RmiIdlUtil.isAbstractValueType(cls)) {\n                // Analyse the interface\n                InterfaceAnalysis ia = InterfaceAnalysis.getInterfaceAnalysis(cls);\n\n                // Add analyzed interface (which may be abstract)\n                addInterface(ia);\n            } else {\n                                ValueAnalysis va = ValueAnalysis.getValueAnalysis(cls);\n\n                // Add analyzed value\n                addValue(va);\n            }\n        } else if (Exception.class.isAssignableFrom(cls)) { // Exception type.\n            // Analyse the exception\n            ExceptionAnalysis ea = ExceptionAnalysis.getExceptionAnalysis(cls);\n\n            // Add analyzed exception\n            addException(ea);\n        } else { // Got to be a value type.\n                        ValueAnalysis va = ValueAnalysis.getValueAnalysis(cls);\n\n            // Add analyzed value\n            addValue(va);\n        }\n    }",
        "variable": "va",
        "reference": "the value",
        "explanation_by_ours": "the value to add",
        "explanation_by_baseline": "the value{ //"
    },
    {
        "id": 753,
        "method": "public void deploy(DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {\n        final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();\n        final ModuleLoader moduleLoader = Module.getBootModuleLoader();\n        final ModuleSpecification moduleSpecification = deploymentUnit.getAttachment(Attachments.MODULE_SPECIFICATION);\n        moduleSpecification.addSystemDependency(new ModuleDependency(moduleLoader, PICKETBOX_ID, false, false, false, false));\n\n                final ModuleDependency remoting = new ModuleDependency(moduleLoader, REMOTING_LOGIN_MODULE, false, false, false, false);\n        remoting.addImportFilter(PathFilters.is(RemotingLoginModule.class.getName().replace(\".\",\"/\")), true);\n        moduleSpecification.addSystemDependency(remoting);\n\n\n        moduleSpecification.addSystemDependency(new ModuleDependency(moduleLoader, JACC_API, false, false, true, false));\n        moduleSpecification.addSystemDependency(new ModuleDependency(moduleLoader, AUTH_MESSAGE_API, false, false, true, false));\n    }",
        "variable": "remoting",
        "reference": "the remoting login module",
        "explanation_by_ours": "the remoting module",
        "explanation_by_baseline": "remoting login module to"
    },
    {
        "id": 772,
        "method": "@Override\n    protected void processBeanMetaData(final SessionBeanMetaData sessionBean, final DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {\n        final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();\n        // get the module description\n        final EEModuleDescription moduleDescription = deploymentUnit.getAttachment(org.jboss.as.ee.component.Attachments.EE_MODULE_DESCRIPTION);\n\n        final String beanName = sessionBean.getName();\n\n        ComponentDescription bean = moduleDescription.getComponentByName(beanName);\n        if (appclient) {\n            if (bean == null) {\n                for (final ComponentDescription component : deploymentUnit.getAttachmentList(Attachments.ADDITIONAL_RESOLVABLE_COMPONENTS)) {\n                    if (component.getComponentName().equals(beanName)) {\n                        bean = component;\n                        break;\n                    }\n                }\n            }\n        }\n        if (!(bean instanceof SessionBeanComponentDescription)) {\n            //TODO: this is a hack to deal with descriptor merging\n            //if this is a GenericBeanMetadata it may actually represent an MDB\n            return;\n        }\n\n        SessionBeanComponentDescription sessionBeanDescription = (SessionBeanComponentDescription) bean;\n\n        sessionBeanDescription.setDeploymentDescriptorEnvironment(new DeploymentDescriptorEnvironment(\"java:comp/env/\", sessionBean));\n\n        // mapped-name\n        sessionBeanDescription.setMappedName(sessionBean.getMappedName());\n                final BusinessLocalsMetaData businessLocals = sessionBean.getBusinessLocals();\n        if (businessLocals != null && !businessLocals.isEmpty()) {\n            sessionBeanDescription.addLocalBusinessInterfaceViews(businessLocals);\n        }\n\n        final String local = sessionBean.getLocal();\n        if (local != null) {\n            sessionBeanDescription.addEjbLocalObjectView(local);\n        }\n\n        final String remote = sessionBean.getRemote();\n        if (remote != null) {\n            sessionBeanDescription.addEjbObjectView(remote);\n        }\n\n        // remote business interface views\n        final BusinessRemotesMetaData businessRemotes = sessionBean.getBusinessRemotes();\n        if (businessRemotes != null && !businessRemotes.isEmpty()) {\n            sessionBeanDescription.addRemoteBusinessInterfaceViews(businessRemotes);\n        }\n\n        // process EJB3.1 specific session bean description\n        if (sessionBean instanceof SessionBean31MetaData) {\n            this.processSessionBean31((SessionBean31MetaData) sessionBean, sessionBeanDescription);\n        }\n    }",
        "variable": "businessLocals",
        "reference": "local business interface views",
        "explanation_by_ours": "the business interface views",
        "explanation_by_baseline": "local business interface viewssession"
    },
    {
        "id": 773,
        "method": "@Override\n    protected void processBeanMetaData(final SessionBeanMetaData sessionBean, final DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {\n        final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();\n        // get the module description\n        final EEModuleDescription moduleDescription = deploymentUnit.getAttachment(org.jboss.as.ee.component.Attachments.EE_MODULE_DESCRIPTION);\n\n        final String beanName = sessionBean.getName();\n\n        ComponentDescription bean = moduleDescription.getComponentByName(beanName);\n        if (appclient) {\n            if (bean == null) {\n                for (final ComponentDescription component : deploymentUnit.getAttachmentList(Attachments.ADDITIONAL_RESOLVABLE_COMPONENTS)) {\n                    if (component.getComponentName().equals(beanName)) {\n                        bean = component;\n                        break;\n                    }\n                }\n            }\n        }\n        if (!(bean instanceof SessionBeanComponentDescription)) {\n            //TODO: this is a hack to deal with descriptor merging\n            //if this is a GenericBeanMetadata it may actually represent an MDB\n            return;\n        }\n\n        SessionBeanComponentDescription sessionBeanDescription = (SessionBeanComponentDescription) bean;\n\n        sessionBeanDescription.setDeploymentDescriptorEnvironment(new DeploymentDescriptorEnvironment(\"java:comp/env/\", sessionBean));\n\n        // mapped-name\n        sessionBeanDescription.setMappedName(sessionBean.getMappedName());\n        // local business interface views\n        final BusinessLocalsMetaData businessLocals = sessionBean.getBusinessLocals();\n        if (businessLocals != null && !businessLocals.isEmpty()) {\n            sessionBeanDescription.addLocalBusinessInterfaceViews(businessLocals);\n        }\n\n        final String local = sessionBean.getLocal();\n        if (local != null) {\n            sessionBeanDescription.addEjbLocalObjectView(local);\n        }\n\n        final String remote = sessionBean.getRemote();\n        if (remote != null) {\n            sessionBeanDescription.addEjbObjectView(remote);\n        }\n\n                final BusinessRemotesMetaData businessRemotes = sessionBean.getBusinessRemotes();\n        if (businessRemotes != null && !businessRemotes.isEmpty()) {\n            sessionBeanDescription.addRemoteBusinessInterfaceViews(businessRemotes);\n        }\n\n        // process EJB3.1 specific session bean description\n        if (sessionBean instanceof SessionBean31MetaData) {\n            this.processSessionBean31((SessionBean31MetaData) sessionBean, sessionBeanDescription);\n        }\n    }",
        "variable": "businessRemotes",
        "reference": "remote business interface views",
        "explanation_by_ours": "the business remotes",
        "explanation_by_baseline": "remote business interface viewssession"
    },
    {
        "id": 781,
        "method": "protected void loadLocalDatabases() {\n    final List<String> dbs = new ArrayList<String>(serverInstance.getAvailableStorageNames().keySet());\n    Collections.sort(dbs);\n\n    for (final String databaseName : dbs) {\n      if (messageService.getDatabase(databaseName) == null) {\n        ODistributedServerLog.info(this, nodeName, null, DIRECTION.NONE, \"Opening database '%s'...\", databaseName);\n\n                final ODistributedStorage stg = getStorage(databaseName);\n\n        executeInDistributedDatabaseLock(databaseName, 60000, null, new OCallable<Object, OModifiableDistributedConfiguration>() {\n          @Override\n          public Object call(OModifiableDistributedConfiguration cfg) {\n            ODistributedServerLog.info(this, nodeName, null, DIRECTION.NONE, \"Current node started as %s for database '%s'\",\n                cfg.getServerRole(nodeName), databaseName);\n\n            final ODistributedDatabaseImpl ddb = messageService.registerDatabase(databaseName, cfg);\n            ddb.resume();\n\n            // 1ST NODE TO HAVE THE DATABASE\n            cfg.addNewNodeInServerList(nodeName);\n\n            // COLLECT ALL THE CLUSTERS WITH REMOVED NODE AS OWNER\n            reassignClustersOwnership(nodeName, databaseName, cfg, true);\n\n            try {\n              ddb.getSyncConfiguration().setLastLSN(nodeName, ((OAbstractPaginatedStorage) stg.getUnderlying()).getLSN(), false);\n            } catch (IOException e) {\n              ODistributedServerLog\n                  .error(this, nodeName, null, DIRECTION.NONE, \"Error on saving distributed LSN for database '%s' (err=%s).\",\n                      databaseName, e.getMessage());\n            }\n            ddb.setOnline();\n\n            return null;\n          }\n        });\n      }\n    }\n  }",
        "variable": "stg",
        "reference": "THE STORAGE",
        "explanation_by_ours": "The storage to load the local databases from.",
        "explanation_by_baseline": "THE DISTRIBUTED DATABASE"
    },
    {
        "id": 792,
        "method": "public static ODocument toStream(final Object iPojo, final ODocument iRecord, final OEntityManager iEntityManager,\r\n      final OClass schemaClass, final OUserObject2RecordHandler iObj2RecHandler, final ODatabaseObject db,\r\n      final boolean iSaveOnlyDirty) {\r\n    if (iSaveOnlyDirty && !iRecord.isDirty())\r\n      return iRecord;\r\n\r\n    final long timer = Orient.instance().getProfiler().startChrono();\r\n\r\n    final Integer identityRecord = System.identityHashCode(iRecord);\r\n\r\n    if (OSerializationThreadLocal.INSTANCE.get().contains(identityRecord))\r\n      return iRecord;\r\n\r\n    OSerializationThreadLocal.INSTANCE.get().add(identityRecord);\r\n\r\n    OProperty schemaProperty;\r\n\r\n    final Class<?> pojoClass = iPojo.getClass();\r\n\r\n    final List<Field> properties = getClassFields(pojoClass);\r\n\r\n    // CHECK FOR ID BINDING\r\n    final Field idField = fieldIds.get(pojoClass);\r\n    if (idField != null) {\r\n      Object id = getFieldValue(iPojo, idField.getName());\r\n      if (id != null) {\r\n        // FOUND\r\n        if (id instanceof ORecordId) {\r\n          ORecordInternal.setIdentity(iRecord, (ORecordId) id);\r\n        } else if (id instanceof Number) {\r\n          // TREATS AS CLUSTER POSITION\r\n          ((ORecordId) iRecord.getIdentity()).setClusterId(schemaClass.getDefaultClusterId());\r\n          ((ORecordId) iRecord.getIdentity()).setClusterPosition(((Number) id).longValue());\r\n        } else if (id instanceof String)\r\n          ((ORecordId) iRecord.getIdentity()).fromString((String) id);\r\n        else if (id.getClass().equals(Object.class))\r\n          ORecordInternal.setIdentity(iRecord, (ORecordId) id);\r\n        else\r\n          OLogManager.instance().warn(OObjectSerializerHelper.class,\r\n              \"@Id field has been declared as %s while the supported are: ORID, Number, String, Object\", id.getClass());\r\n      }\r\n    }\r\n\r\n        final Field vField = fieldVersions.get(pojoClass);\r\n    boolean versionConfigured = false;\r\n    if (vField != null) {\r\n      versionConfigured = true;\r\n      Object ver = getFieldValue(iPojo, vField.getName());\r\n\r\n      final int version = convertVersion(ver);\r\n      ORecordInternal.setVersion(iRecord, version);\r\n    }\r\n\r\n    if (db.isMVCC() && !versionConfigured && db.getTransaction() instanceof OTransactionOptimistic)\r\n      throw new OTransactionException(\"Cannot involve an object of class '\" + pojoClass\r\n          + \"' in an Optimistic Transaction commit because it does not define @Version or @OVersion and therefore cannot handle MVCC\");\r\n\r\n    // SET OBJECT CLASS\r\n    iRecord.setClassName(schemaClass != null ? schemaClass.getName() : null);\r\n\r\n    String fieldName;\r\n    Object fieldValue;\r\n\r\n    // CALL BEFORE MARSHALLING\r\n    invokeCallback(iPojo, iRecord, OBeforeSerialization.class);\r\n\r\n    for (Field p : properties) {\r\n      fieldName = p.getName();\r\n\r\n      if (idField != null && fieldName.equals(idField.getName()))\r\n        continue;\r\n\r\n      if (vField != null && fieldName.equals(vField.getName()))\r\n        continue;\r\n\r\n      fieldValue = serializeFieldValue(getFieldType(iPojo, fieldName), getFieldValue(iPojo, fieldName));\r\n\r\n      schemaProperty = schemaClass != null ? schemaClass.getProperty(fieldName) : null;\r\n\r\n      if (fieldValue != null) {\r\n        if (isEmbeddedObject(iPojo.getClass(), fieldValue.getClass(), fieldName, iEntityManager)) {\r\n          // AUTO CREATE SCHEMA PROPERTY\r\n          if (schemaClass == null) {\r\n            db.getMetadata().getSchema().createClass(iPojo.getClass());\r\n            iRecord.setClassNameIfExists(iPojo.getClass().getSimpleName());\r\n          }\r\n\r\n          if (schemaProperty == null) {\r\n            OType t = OType.getTypeByClass(fieldValue.getClass());\r\n            if (t == null)\r\n              t = OType.EMBEDDED;\r\n            schemaProperty = iRecord.getSchemaClass().createProperty(fieldName, t);\r\n          }\r\n        }\r\n      }\r\n\r\n      fieldValue = typeToStream(fieldValue, schemaProperty != null ? schemaProperty.getType() : null, iEntityManager,\r\n          iObj2RecHandler, db, iRecord, iSaveOnlyDirty);\r\n\r\n      iRecord.field(fieldName, fieldValue);\r\n    }\r\n\r\n    iObj2RecHandler.registerUserObject(iPojo, iRecord);\r\n\r\n    // CALL AFTER MARSHALLING\r\n    invokeCallback(iPojo, iRecord, OAfterSerialization.class);\r\n\r\n    OSerializationThreadLocal.INSTANCE.get().remove(identityRecord);\r\n\r\n    Orient.instance().getProfiler().stopChrono(\"Object.toStream\", \"Serialize object to stream\", timer);\r\n\r\n    return iRecord;\r\n  }",
        "variable": "vField",
        "reference": "VERSION BINDING",
        "explanation_by_ours": "The field to use.",
        "explanation_by_baseline": "VERSION BINDINGfinal"
    },
    {
        "id": 802,
        "method": "private Object execute(OCommandContext ctx) {\n    if (destField == null)\n      throw new OCommandExecutionException(\"Cannot execute the command because it has not been parsed yet\");\n\n    final ODatabaseDocumentInternal database = getDatabase();\n    if (!(database.getDatabaseOwner() instanceof ODatabaseDocument))\n      throw new OCommandSQLParsingException(\n          \"This command supports only the database type ODatabaseDocumentTx and type '\" + database.getClass() + \"' was found\");\n\n    final ODatabaseDocument db = (ODatabaseDocument) database.getDatabaseOwner();\n\n    final OClass sourceClass = database.getMetadata().getSchema().getClass(getSourceClass().getStringValue());\n    if (sourceClass == null)\n      throw new OCommandExecutionException(\"Source class '\" + getSourceClass().getStringValue() + \"' not found\");\n\n    final OClass destClass = database.getMetadata().getSchema().getClass(getDestClass().getStringValue());\n    if (destClass == null)\n      throw new OCommandExecutionException(\"Destination class '\" + getDestClass().getStringValue() + \"' not found\");\n\n    Object value;\n\n    String cmd = \"select from \";\n    if (!ODocumentHelper.ATTRIBUTE_RID.equals(destField)) {\n      cmd = \"select from \" + getDestClass() + \" where \" + destField + \" = \";\n    }\n\n    List<ODocument> result;\n    ODocument target;\n    Object oldValue;\n    long total = 0;\n\n    String linkName = name == null ? sourceField.getStringValue() : name.getStringValue();\n\n    boolean multipleRelationship;\n    OType linkType = OType.valueOf(type.getStringValue().toUpperCase(Locale.ENGLISH));\n    if (linkType != null)\n      // DETERMINE BASED ON FORCED TYPE\n      multipleRelationship = linkType == OType.LINKSET || linkType == OType.LINKLIST;\n    else\n      multipleRelationship = false;\n\n    long totRecords = db.countClass(sourceClass.getName());\n    long currRecord = 0;\n\n    database.declareIntent(new OIntentMassiveInsert());\n    try {\n      // BROWSE ALL THE RECORDS OF THE SOURCE CLASS\n      for (ODocument doc : db.browseClass(sourceClass.getName())) {\n        if (breakExec) {\n          break;\n        }\n        value = doc.getProperty(sourceField.getStringValue());\n\n        if (value != null) {\n          if (value instanceof ODocument || value instanceof ORID) {\n            // ALREADY CONVERTED\n          } else if (value instanceof Collection<?>) {\n            // TODO\n          } else {\n            // SEARCH THE DESTINATION RECORD\n            target = null;\n\n            if (!ODocumentHelper.ATTRIBUTE_RID.equals(destField) && value instanceof String)\n              if (((String) value).length() == 0)\n                value = null;\n              else\n                value = \"'\" + value + \"'\";\n\n            OResultSet rs = database.query(cmd + value);\n            result = toList(rs);\n            rs.close();\n\n            if (result == null || result.size() == 0)\n              value = null;\n            else if (result.size() > 1)\n              throw new OCommandExecutionException(\n                  \"Cannot create link because multiple records was found in class '\" + destClass.getName() + \"' with value \" + value\n                      + \" in field '\" + destField + \"'\");\n            else {\n              target = result.get(0);\n              value = target;\n            }\n\n            if (target != null && inverse) {\n              // INVERSE RELATIONSHIP\n              oldValue = target.getProperty(linkName);\n\n              if (oldValue != null) {\n                if (!multipleRelationship)\n                  multipleRelationship = true;\n\n                Collection<ODocument> coll;\n                if (oldValue instanceof Collection) {\n                  // ADD IT IN THE EXISTENT COLLECTION\n                  coll = (Collection<ODocument>) oldValue;\n                  target.setDirty();\n                } else {\n                  // CREATE A NEW COLLECTION FOR BOTH\n                  coll = new ArrayList<ODocument>(2);\n                  target.setProperty(linkName, coll);\n                  coll.add((ODocument) oldValue);\n                }\n                coll.add(doc);\n              } else {\n                if (linkType != null)\n                  if (linkType == OType.LINKSET) {\n                    value = new ORecordLazySet(target);\n                    ((Set<OIdentifiable>) value).add(doc);\n                  } else if (linkType == OType.LINKLIST) {\n                    value = new ORecordLazyList(target);\n                    ((ORecordLazyList) value).add(doc);\n                  } else\n                    // IGNORE THE TYPE, SET IT AS LINK\n                    value = doc;\n                else\n                  value = doc;\n\n                target.setProperty(linkName, value);\n              }\n              target.save();\n\n            } else {\n              // SET THE REFERENCE\n              doc.setProperty(linkName, value);\n              doc.save();\n            }\n\n            total++;\n          }\n        }\n      }\n\n      if (total > 0) {\n        if (inverse) {\n                    OProperty prop = destClass.getProperty(linkName);\n          if (prop != null)\n            destClass.dropProperty(linkName);\n\n          if (linkType == null)\n            linkType = multipleRelationship ? OType.LINKSET : OType.LINK;\n\n          // CREATE THE PROPERTY\n          destClass.createProperty(linkName, linkType, sourceClass);\n\n        } else {\n\n                    OProperty prop = sourceClass.getProperty(linkName);\n          if (prop != null)\n            sourceClass.dropProperty(linkName);\n\n          // CREATE THE PROPERTY\n          sourceClass.createProperty(linkName, OType.LINK, destClass);\n        }\n      }\n    } catch (Exception e) {\n      throw OException.wrapException(new OCommandExecutionException(\"Error on creation of links\"), e);\n    } finally {\n      database.declareIntent(null);\n    }\n    return total;\n  }",
        "variable": "prop",
        "reference": "THE OLD PROPERTY",
        "explanation_by_ours": "the property",
        "explanation_by_baseline": "THE OLD PROPERTYif ("
    },
    {
        "id": 813,
        "method": "public void setServerOwner(final String iClusterName, final String iServerName) {\n    if (iClusterName == null)\n      throw new IllegalArgumentException(\"cluster name cannot be null\");\n\n    synchronized (configuration) {\n      final ODocument clusters = configuration.field(CLUSTERS);\n      ODocument cluster = clusters.field(iClusterName);\n\n      if (cluster == null)\n        // CREATE IT\n        cluster = createCluster(iClusterName);\n      else {\n                final String owner = cluster.field(OWNER);\n        if (owner != null && !iServerName.equalsIgnoreCase(owner))\n          throw new ODistributedException(\"Cannot overwrite ownership of cluster '\" + iClusterName + \"' to the server '\"\n              + iServerName + \"', because server '\" + owner + \"' was already configured as owner\");\n      }\n\n      List<String> serverList = getClusterConfiguration(iClusterName).field(SERVERS);\n      if (serverList == null) {\n        serverList = initClusterServers(cluster);\n      }\n\n      if (!serverList.isEmpty() && serverList.get(0).equals(iServerName))\n        // ALREADY OWNER\n        return;\n\n      // REMOVE THE NODE IF ANY\n      boolean removed = false;\n      for (Iterator<String> it = serverList.iterator(); it.hasNext();) {\n        if (it.next().equals(iServerName)) {\n          it.remove();\n          removed = true;\n          break;\n        }\n      }\n\n      if( !removed )\n        throw new ODistributedException(\"Cannot set ownership of cluster '\" + iClusterName + \"' to the server '\"\n            + iServerName + \"', because the server has no that cluster (sharding)\");\n\n      // ADD THE NODE AS FIRST OF THE LIST = MASTER\n      serverList.add(0, iServerName);\n\n      incrementVersion();\n    }\n  }",
        "variable": "owner",
        "reference": "THE OWNER ALREADY CONFIGURED",
        "explanation_by_ours": "The name of the server to set the owner of.",
        "explanation_by_baseline": "clustercluster. field ("
    },
    {
        "id": 815,
        "method": "public void dispatchResponseToThread(final ODistributedResponse response) {\n    try {\n      final long msgId = response.getRequestId().getMessageId();\n\n            final ODistributedResponseManager asynchMgr = responsesByRequestIds.get(msgId);\n      if (asynchMgr == null) {\n        if (ODistributedServerLog.isDebugEnabled())\n          ODistributedServerLog.debug(this, manager.getLocalNodeName(), response.getExecutorNodeName(), DIRECTION.IN,\n              \"received response for message %d after the timeout (%dms)\", msgId,\n              OGlobalConfiguration.DISTRIBUTED_ASYNCH_RESPONSES_TIMEOUT.getValueAsLong());\n      } else if (asynchMgr.collectResponse(response)) {\n        // ALL RESPONSE RECEIVED, REMOVE THE RESPONSE MANAGER WITHOUT WAITING THE PURGE THREAD REMOVE THEM FOR TIMEOUT\n        responsesByRequestIds.remove(msgId);\n      }\n    } finally {\n      Orient.instance().getProfiler()\n          .updateCounter(\"distributed.node.msgReceived\", \"Number of replication messages received in current node\", +1,\n              \"distributed.node.msgReceived\");\n\n      Orient.instance().getProfiler().updateCounter(\"distributed.node.\" + response.getExecutorNodeName() + \".msgReceived\",\n          \"Number of replication messages received in current node from a node\", +1, \"distributed.node.*.msgReceived\");\n    }\n  }",
        "variable": "asynchMgr",
        "reference": "ASYNCHRONOUS MSG MANAGER",
        "explanation_by_ours": "the ASYNCHRONOUS MSG MANAGER",
        "explanation_by_baseline": "ASYNCH_RESPONSE_"
    },
    {
        "id": 818,
        "method": "protected String checkForClassInSchema(final String className) {\n    if (className == null)\n      return null;\n\n    OrientBaseGraph graph = getGraph();\n    if (graph == null)\n      return className;\n\n    final OSchema schema = graph.getRawGraph().getMetadata().getSchema();\n\n    if (!schema.existsClass(className)) {\n      // CREATE A NEW CLASS AT THE FLY\n      try {\n        graph.executeOutsideTx(new OCallable<OClass, OrientBaseGraph>() {\n\n                                 @Override public OClass call(final OrientBaseGraph g) {\n                                   return schema.createClass(className, schema.getClass(getBaseClassName()));\n\n                                 }\n                               }, \"Committing the active transaction to create the new type '\", className, \"' as subclass of '\", getBaseClassName(),\n            \"'. The transaction will be reopen right after that. To avoid this behavior create the classes outside the transaction\");\n\n      } catch (OSchemaException e) {\n        if (!schema.existsClass(className))\n          throw e;\n      }\n    } else {\n            final OClass cls = schema.getClass(className);\n      if (!cls.isSubClassOf(getBaseClassName()))\n        throw new IllegalArgumentException(\"Class '\" + className + \"' is not an instance of \" + getBaseClassName());\n    }\n\n    return className;\n  }",
        "variable": "cls",
        "reference": "THE CLASS",
        "explanation_by_ours": "The class to check.",
        "explanation_by_baseline": "THE CLASSif (!schema"
    },
    {
        "id": 832,
        "method": "public OrientVertex addVertex(Object id, final Object... prop) {\n    makeActive();\n\n    String className = null;\n    String clusterName = null;\n    Object[] fields = null;\n\n    if (id != null) {\n      if (id instanceof String) {\n                final String[] args = ((String) id).split(\",\");\n        for (String s : args) {\n          if (s.startsWith(CLASS_PREFIX))\n            // GET THE CLASS NAME\n            className = s.substring(CLASS_PREFIX.length());\n          else if (s.startsWith(CLUSTER_PREFIX))\n            // GET THE CLASS NAME\n            clusterName = s.substring(CLUSTER_PREFIX.length());\n          else\n            id = s;\n        }\n      }\n\n      if (isSaveOriginalIds())\n        // SAVE THE ID TOO\n        fields = new Object[] { OrientElement.DEF_ORIGINAL_ID_FIELDNAME, id };\n    }\n\n    setCurrentGraphInThreadLocal();\n    autoStartTransaction();\n\n    final OrientVertex vertex = getVertexInstance(className, fields);\n    vertex.setPropertiesInternal(prop);\n\n    // SAVE IT\n    if (clusterName != null)\n      vertex.save(clusterName);\n    else\n      vertex.save();\n    return vertex;\n  }",
        "variable": "args",
        "reference": "the ARGUMENTS",
        "explanation_by_ours": "The arguments of the vertex.",
        "explanation_by_baseline": "final OrientVertex vertex ="
    },
    {
        "id": 859,
        "method": "public ORID moveTo(final String iClassName, final String iClusterName) {\n    final OrientBaseGraph graph = getGraph();\n\n    if (checkDeletedInTx())\n      graph.throwRecordNotFoundException(getIdentity(), \"The vertex \" + getIdentity() + \" has been deleted\");\n\n    final ORID oldIdentity = getIdentity().copy();\n\n    final ORecord oldRecord = oldIdentity.getRecord();\n    if (oldRecord == null)\n      graph.throwRecordNotFoundException(getIdentity(), \"The vertex \" + getIdentity() + \" has been deleted\");\n\n    final ODocument doc = ((ODocument) rawElement.getRecord()).copy();\n\n    final Iterable<Edge> outEdges = getEdges(Direction.OUT);\n    final Iterable<Edge> inEdges = getEdges(Direction.IN);\n\n    // DELETE THE OLD RECORD FIRST TO AVOID ISSUES WITH UNIQUE CONSTRAINTS\n    copyRidBags(oldRecord, doc);\n    removeEdgeLinks(oldRecord);\n    oldRecord.delete();\n\n    if (iClassName != null)\n      // OVERWRITE CLASS\n      doc.setClassName(iClassName);\n\n    // SAVE THE NEW VERTEX\n    doc.setDirty();\n\n    // RESET IDENTITY\n    ORecordInternal.setIdentity(doc, new ORecordId());\n\n    if (iClusterName != null)\n      doc.save(iClusterName);\n    else\n      doc.save();\n\n    final ORID newIdentity = doc.getIdentity();\n\n    // CONVERT OUT EDGES\n    for (Edge e : outEdges) {\n      final OrientEdge oe = (OrientEdge) e;\n      if (oe.isLightweight()) {\n                final OrientVertex inV = oe.getVertex(Direction.IN);\n\n        final String inFieldName = OrientVertex\n            .getConnectionFieldName(Direction.IN, oe.getLabel(), graph.isUseVertexFieldsForEdgeLabels());\n\n        replaceLinks(inV.getRecord(), inFieldName, oldIdentity, newIdentity);\n      } else {\n        // REPLACE WITH NEW VERTEX\n        oe.vOut = newIdentity;\n        oe.getRecord().field(OrientBaseGraph.CONNECTION_OUT, newIdentity);\n        oe.save();\n      }\n    }\n\n    for (Edge e : inEdges) {\n      final OrientEdge oe = (OrientEdge) e;\n      if (oe.isLightweight()) {\n        // REPLACE ALL REFS IN outVertex\n        final OrientVertex outV = oe.getVertex(Direction.OUT);\n\n        final String outFieldName = OrientVertex\n            .getConnectionFieldName(Direction.OUT, oe.getLabel(), graph.isUseVertexFieldsForEdgeLabels());\n\n        replaceLinks(outV.getRecord(), outFieldName, oldIdentity, newIdentity);\n      } else {\n        // REPLACE WITH NEW VERTEX\n        oe.vIn = newIdentity;\n        oe.getRecord().field(OrientBaseGraph.CONNECTION_IN, newIdentity);\n        oe.save();\n      }\n    }\n\n    // FINAL SAVE\n    doc.save();\n\n    return newIdentity;\n  }",
        "variable": "inV",
        "reference": "inVertex",
        "explanation_by_ours": "The vertex to move.",
        "explanation_by_baseline": "inVertexfinal Orient"
    },
    {
        "id": 860,
        "method": "public ORID moveTo(final String iClassName, final String iClusterName) {\n    final OrientBaseGraph graph = getGraph();\n\n    if (checkDeletedInTx())\n      graph.throwRecordNotFoundException(getIdentity(), \"The vertex \" + getIdentity() + \" has been deleted\");\n\n    final ORID oldIdentity = getIdentity().copy();\n\n    final ORecord oldRecord = oldIdentity.getRecord();\n    if (oldRecord == null)\n      graph.throwRecordNotFoundException(getIdentity(), \"The vertex \" + getIdentity() + \" has been deleted\");\n\n    final ODocument doc = ((ODocument) rawElement.getRecord()).copy();\n\n    final Iterable<Edge> outEdges = getEdges(Direction.OUT);\n    final Iterable<Edge> inEdges = getEdges(Direction.IN);\n\n    // DELETE THE OLD RECORD FIRST TO AVOID ISSUES WITH UNIQUE CONSTRAINTS\n    copyRidBags(oldRecord, doc);\n    removeEdgeLinks(oldRecord);\n    oldRecord.delete();\n\n    if (iClassName != null)\n      // OVERWRITE CLASS\n      doc.setClassName(iClassName);\n\n    // SAVE THE NEW VERTEX\n    doc.setDirty();\n\n    // RESET IDENTITY\n    ORecordInternal.setIdentity(doc, new ORecordId());\n\n    if (iClusterName != null)\n      doc.save(iClusterName);\n    else\n      doc.save();\n\n    final ORID newIdentity = doc.getIdentity();\n\n    // CONVERT OUT EDGES\n    for (Edge e : outEdges) {\n      final OrientEdge oe = (OrientEdge) e;\n      if (oe.isLightweight()) {\n        // REPLACE ALL REFS IN inVertex\n        final OrientVertex inV = oe.getVertex(Direction.IN);\n\n        final String inFieldName = OrientVertex\n            .getConnectionFieldName(Direction.IN, oe.getLabel(), graph.isUseVertexFieldsForEdgeLabels());\n\n        replaceLinks(inV.getRecord(), inFieldName, oldIdentity, newIdentity);\n      } else {\n        // REPLACE WITH NEW VERTEX\n        oe.vOut = newIdentity;\n        oe.getRecord().field(OrientBaseGraph.CONNECTION_OUT, newIdentity);\n        oe.save();\n      }\n    }\n\n    for (Edge e : inEdges) {\n      final OrientEdge oe = (OrientEdge) e;\n      if (oe.isLightweight()) {\n                final OrientVertex outV = oe.getVertex(Direction.OUT);\n\n        final String outFieldName = OrientVertex\n            .getConnectionFieldName(Direction.OUT, oe.getLabel(), graph.isUseVertexFieldsForEdgeLabels());\n\n        replaceLinks(outV.getRecord(), outFieldName, oldIdentity, newIdentity);\n      } else {\n        // REPLACE WITH NEW VERTEX\n        oe.vIn = newIdentity;\n        oe.getRecord().field(OrientBaseGraph.CONNECTION_IN, newIdentity);\n        oe.save();\n      }\n    }\n\n    // FINAL SAVE\n    doc.save();\n\n    return newIdentity;\n  }",
        "variable": "outV",
        "reference": "outVertex",
        "explanation_by_ours": "The vertex to move.",
        "explanation_by_baseline": "outVertexfinal Orient"
    },
    {
        "id": 872,
        "method": "private long putEntryInReadBuffer(OClosableEntry<K, V> entry, int bufferIndex) {\n        AtomicLong writeCounter = readBufferWriteCount[bufferIndex];\n    final long counter = writeCounter.get();\n\n    //we do not use CAS operations to limit contention between threads\n    //it is normal that because of duplications of indexes some of items will be lost\n    writeCounter.lazySet(counter + 1);\n\n    final AtomicReference<OClosableEntry<K, V>>[] buffer = readBuffers[bufferIndex];\n    AtomicReference<OClosableEntry<K, V>> bufferEntry = buffer[(int) (counter & READ_BUFFER_INDEX_MASK)];\n    bufferEntry.lazySet(entry);\n\n    return counter + 1;\n  }",
        "variable": "writeCounter",
        "reference": "next index to write",
        "explanation_by_ours": "the write counter",
        "explanation_by_baseline": "get the write counter//"
    },
    {
        "id": 887,
        "method": "public Object execute(final Map<Object, Object> iArgs) {\n    if (newRecords == null && content == null && subQuery == null)\n      throw new OCommandExecutionException(\"Cannot execute the command because it has not been parsed yet\");\n\n    final OCommandParameters commandParameters = new OCommandParameters(iArgs);\n    if (indexName != null) {\n      if (newRecords == null)\n        throw new OCommandExecutionException(\"No key/value found\");\n\n      final OIndex<?> index = getDatabase().getMetadata().getIndexManager().getIndex(indexName);\n      if (index == null)\n        throw new OCommandExecutionException(\"Target index '\" + indexName + \"' not found\");\n\n      // BIND VALUES\n      Map<String, Object> result = new HashMap<String, Object>();\n\n      for (Map<String, Object> candidate : newRecords) {\n        Object indexKey = getIndexKeyValue(commandParameters, candidate);\n        OIdentifiable indexValue = getIndexValue(commandParameters, candidate);\n\n        if (index instanceof OIndexMultiValues) {\n          final Collection<ORID> rids = ((OIndexMultiValues) index).get(indexKey);\n          if (!rids.contains(indexValue.getIdentity())) {\n            index.put(indexKey, indexValue);\n          }\n        } else {\n          index.put(indexKey, indexValue);\n        }\n\n        result.put(KEYWORD_KEY, indexKey);\n        result.put(KEYWORD_RID, indexValue);\n      }\n\n      // RETURN LAST ENTRY\n      return prepareReturnItem(new ODocument(result));\n    } else {\n            final List<ODocument> docs = new ArrayList<ODocument>();\n      if (newRecords != null) {\n        for (Map<String, Object> candidate : newRecords) {\n          final ODocument doc = className != null ? new ODocument(className) : new ODocument();\n          OSQLHelper.bindParameters(doc, candidate, commandParameters, context);\n\n          saveRecord(doc);\n          docs.add(doc);\n        }\n\n        if (docs.size() == 1)\n          return prepareReturnItem(docs.get(0));\n        else\n          return prepareReturnResult(docs);\n      } else if (content != null) {\n        final ODocument doc = className != null ? new ODocument(className) : new ODocument();\n        doc.merge(content, true, false);\n        saveRecord(doc);\n        return prepareReturnItem(doc);\n      } else if (subQuery != null) {\n        subQuery.execute();\n        if (queryResult != null)\n          return prepareReturnResult(queryResult);\n\n        return saved.longValue();\n      }\n    }\n    return null;\n  }",
        "variable": "docs",
        "reference": "DOCUMENTS",
        "explanation_by_ours": "the list of documents to be created",
        "explanation_by_baseline": "DOCUMENTif (newRecords"
    },
    {
        "id": 936,
        "method": "public static String getServiceURL(KubernetesClient client, String serviceName, String serviceNamespace, String serviceProtocol, boolean serviceExternal) {\n        Service srv = null;\n        String serviceHost = serviceToHostOrBlank(serviceName);\n        String servicePort = serviceToPortOrBlank(serviceName);\n        String serviceProto = serviceProtocol != null ? serviceProtocol : serviceToProtocol(serviceName, servicePort);\n\n        //Use specified or fallback namespace.\n        String actualNamespace = StringUtils.isNotBlank(serviceNamespace) ? serviceNamespace : client.getNamespace();\n\n        //1. Inside Kubernetes: Services as ENV vars\n        if (!serviceExternal && StringUtils.isNotBlank(serviceHost) && StringUtils.isNotBlank(servicePort) && StringUtils.isNotBlank(serviceProtocol)) {\n            return serviceProtocol + \"://\" + serviceHost + \":\" + servicePort;\n            //2. Anywhere: When namespace is passed System / Env var. Mostly needed for integration tests.\n        } else if (StringUtils.isNotBlank(actualNamespace)) {\n            srv = client.services().inNamespace(actualNamespace).withName(serviceName).get();\n        }\n\n        if (srv == null) {\n            // lets try use environment variables\n            String hostAndPort = getServiceHostAndPort(serviceName, \"\", \"\");\n            if (!hostAndPort.startsWith(\":\")) {\n                return serviceProto + \"://\" + hostAndPort;\n            }\n        }\n        if (srv == null) {\n            throw new IllegalArgumentException(\"No kubernetes service could be found for name: \" + serviceName + \" in namespace: \" + actualNamespace);\n        }\n\n        String answer = KubernetesHelper.getOrCreateAnnotations(srv).get(Fabric8Annotations.SERVICE_EXPOSE_URL.toString());\n        if (StringUtils.isNotBlank(answer)) {\n            return answer;\n        }\n\n        if (OpenshiftHelper.isOpenShift(client)) {\n            OpenShiftClient openShiftClient = client.adapt(OpenShiftClient.class);\n            Route route = openShiftClient.routes().inNamespace(actualNamespace).withName(serviceName).get();\n            if (route != null) {\n                return (serviceProto + \"://\" + route.getSpec().getHost()).toLowerCase();\n            }\n        }\n\n        ServicePort port = findServicePortByName(srv, null);\n        if (port == null) {\n            throw new RuntimeException(\"Couldn't find port: \" + null + \" for service:\" + serviceName);\n        }\n\n        String clusterIP = srv.getSpec().getClusterIP();\n        if (\"None\".equals(clusterIP)) {\n            throw new IllegalStateException(\"Service: \" + serviceName + \" in namespace:\" + serviceNamespace + \"is head-less. Search for endpoints instead.\");\n        }\n\n        Integer portNumber = port.getPort();\n        if (StringUtils.isBlank(clusterIP)) {\n            IngressList ingresses = client.extensions().ingresses().inNamespace(serviceNamespace).list();\n            if (ingresses != null) {\n                List<Ingress> items = ingresses.getItems();\n                if (items != null) {\n                    for (Ingress item : items) {\n                        String ns = KubernetesHelper.getNamespace(item);\n                        if (Objects.equal(serviceNamespace, ns)) {\n                            IngressSpec spec = item.getSpec();\n                            if (spec != null) {\n                                List<IngressRule> rules = spec.getRules();\n                                List<IngressTLS> tls = spec.getTls();\n                                if (rules != null) {\n                                    for (IngressRule rule : rules) {\n                                        HTTPIngressRuleValue http = rule.getHttp();\n                                        if (http != null) {\n                                            List<HTTPIngressPath> paths = http.getPaths();\n                                            if (paths != null) {\n                                                for (HTTPIngressPath path : paths) {\n                                                    IngressBackend backend = path.getBackend();\n                                                    if (backend != null) {\n                                                        String backendServiceName = backend.getServiceName();\n                                                        if (serviceName.equals(backendServiceName) && portsMatch(port, backend.getServicePort())) {\n                                                            String pathPostfix = path.getPath();\n                                                            if (tls != null) {\n                                                                for (IngressTLS tlsHost : tls) {\n                                                                    List<String> hosts = tlsHost.getHosts();\n                                                                    if (hosts != null) {\n                                                                        for (String host : hosts) {\n                                                                            if (StringUtils.isNotBlank(host)) {\n                                                                                return String.format(\"https://%s/%s\", host, preparePath(pathPostfix));\n                                                                            }\n                                                                        }\n                                                                    }\n                                                                }\n                                                            }\n                                                            answer = rule.getHost();\n                                                            if (StringUtils.isNotBlank(answer)) {\n                                                                return String.format(\"http://%s/%s\",answer, preparePath(pathPostfix));\n                                                            }\n                                                        }\n                                                    }\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n\n                        ServiceStatus status = srv.getStatus();\n            if (status != null) {\n                LoadBalancerStatus loadBalancerStatus = status.getLoadBalancer();\n                if (loadBalancerStatus != null) {\n                    List<LoadBalancerIngress> loadBalancerIngresses = loadBalancerStatus.getIngress();\n                    if (loadBalancerIngresses != null) {\n                        for (LoadBalancerIngress loadBalancerIngress : loadBalancerIngresses) {\n                            String ip = loadBalancerIngress.getIp();\n                            if (StringUtils.isNotBlank(ip)) {\n                                clusterIP = ip;\n                                break;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        if (StringUtils.isBlank(clusterIP)) {\n            // on vanilla kubernetes we can use nodePort to access things externally\n            boolean found = false;\n            Integer nodePort = port.getNodePort();\n            if (nodePort != null) {\n                NodeList nodeList = client.nodes().list();\n                if (nodeList != null) {\n                    List<Node> items = nodeList.getItems();\n                    if (items != null) {\n                        for (Node item : items) {\n                            NodeStatus status = item.getStatus();\n                            if (!found && status != null) {\n                                List<NodeAddress> addresses = status.getAddresses();\n                                if (addresses != null) {\n                                    for (NodeAddress address : addresses) {\n                                        String ip = address.getAddress();\n                                        if (StringUtils.isNotBlank(ip)) {\n                                            clusterIP = ip;\n                                            portNumber = nodePort;\n                                            found = true;\n                                            break;\n                                        }\n\n                                    }\n\n                                }\n                            }\n                            if (!found) {\n                                NodeSpec spec = item.getSpec();\n                                if (spec != null) {\n                                    clusterIP = spec.getExternalID();\n                                    if (StringUtils.isNotBlank(clusterIP)) {\n                                        portNumber = nodePort;\n                                        break;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        return (serviceProto + \"://\" + clusterIP + \":\" + portNumber).toLowerCase();\n    }",
        "variable": "status",
        "reference": "the status on GKE",
        "explanation_by_ours": "Status of the service",
        "explanation_by_baseline": "environment variablesif (String"
    },
    {
        "id": 938,
        "method": "private static void addShutdownHook(final Logger log, final Process process, final File command) {\n        Runtime.getRuntime().addShutdownHook(new Thread(command.getName()) {\n            @Override\n            public void run() {\n                if (process != null) {\n                                        boolean alive = false;\n                    try {\n                        process.exitValue();\n                    } catch (IllegalThreadStateException e) {\n                        alive = true;\n                    }\n\n                    if (alive) {\n                        log.info(\"Terminating process %s\", command);\n                        try {\n                            process.destroy();\n                        } catch (Exception e) {\n                            log.error(\"Failed to terminate process %s\", command);\n                        }\n                        /* Only available in Java 8: So disabled for now until we switch to Java 8\n                        try {\n                            if (process != null && process.isAlive()) {\n                                process.destroyForcibly();\n                            }\n                        } catch (Exception e) {\n                            log.error(\"Failed to forcibly terminate process %s\", command);\n                        }\n                        */\n                    }\n                }\n            }\n        });\n    }",
        "variable": "alive",
        "reference": "if the process is alive",
        "explanation_by_ours": "true if the process is alive, false otherwise.",
        "explanation_by_baseline": "if the process is alive"
    },
    {
        "id": 989,
        "method": "public static void unzipFileTo(String file, String dest) throws IOException {\n        File target = new File(file);\n        if (!target.exists())\n            throw new IllegalArgumentException(\"Archive doesnt exist\");\n        FileInputStream fin = new FileInputStream(target);\n        int BUFFER = 2048;\n        byte data[] = new byte[BUFFER];\n\n        if (file.endsWith(\".zip\") || file.endsWith(\".jar\")) {\n            try(ZipInputStream zis = new ZipInputStream(fin)) {\n                                ZipEntry ze = zis.getNextEntry();\n\n                while (ze != null) {\n                    String fileName = ze.getName();\n                    File newFile = new File(dest + File.separator + fileName);\n\n                    if (ze.isDirectory()) {\n                        newFile.mkdirs();\n                        zis.closeEntry();\n                        ze = zis.getNextEntry();\n                        continue;\n                    }\n\n                    FileOutputStream fos = new FileOutputStream(newFile);\n\n                    int len;\n                    while ((len = zis.read(data)) > 0) {\n                        fos.write(data, 0, len);\n                    }\n\n                    fos.close();\n                    ze = zis.getNextEntry();\n                    log.debug(\"File extracted: \" + newFile.getAbsoluteFile());\n                }\n\n                zis.closeEntry();\n            }\n        } else if (file.endsWith(\".tar.gz\") || file.endsWith(\".tgz\")) {\n\n            BufferedInputStream in = new BufferedInputStream(fin);\n            GzipCompressorInputStream gzIn = new GzipCompressorInputStream(in);\n            TarArchiveInputStream tarIn = new TarArchiveInputStream(gzIn);\n\n            TarArchiveEntry entry;\n            /* Read the tar entries using the getNextEntry method **/\n            while ((entry = (TarArchiveEntry) tarIn.getNextEntry()) != null) {\n                log.info(\"Extracting: \" + entry.getName());\n                /* If the entry is a directory, create the directory. */\n\n                if (entry.isDirectory()) {\n                    File f = new File(dest + File.separator + entry.getName());\n                    f.mkdirs();\n                }\n                /*\n                 * If the entry is a file,write the decompressed file to the disk\n                 * and close destination stream.\n                 */\n                else {\n                    int count;\n                    try(FileOutputStream fos = new FileOutputStream(dest + File.separator + entry.getName());\n                        BufferedOutputStream destStream = new BufferedOutputStream(fos, BUFFER);) {\n                        while ((count = tarIn.read(data, 0, BUFFER)) != -1) {\n                            destStream.write(data, 0, count);\n                        }\n\n                        destStream.flush();\n                        IOUtils.closeQuietly(destStream);\n                    }\n                }\n            }\n\n            // Close the input stream\n            tarIn.close();\n        } else if (file.endsWith(\".gz\")) {\n            File extracted = new File(target.getParent(), target.getName().replace(\".gz\", \"\"));\n            if (extracted.exists())\n                extracted.delete();\n            extracted.createNewFile();\n            try(GZIPInputStream is2 = new GZIPInputStream(fin); OutputStream fos = FileUtils.openOutputStream(extracted)) {\n                IOUtils.copyLarge(is2, fos);\n                fos.flush();\n            }\n        } else {\n            throw new IllegalStateException(\"Unable to infer file type (compression format) from source file name: \" +\n                    file);\n        }\n        target.delete();\n    }",
        "variable": "ze",
        "reference": "the zipped file list entry",
        "explanation_by_ours": "the zipped file list entry",
        "explanation_by_baseline": "the next entry in archive"
    },
    {
        "id": 996,
        "method": "public void exec(INDArrayIndex... indexes) {\n        val shape = arr.shape();\n\n        if (arr.isSparse()) {\n            resolveFixedDimensionsCOO(indexes);\n        }\n\n        // Check that given point indexes are not out of bounds\n        for (int i = 0; i < indexes.length; i++) {\n            INDArrayIndex idx = indexes[i];\n            // On vectors, the first dimension can be ignored when indexing them with a single point index\n            if (idx instanceof PointIndex && (arr.isVector() && indexes.length == 1 ? idx.current() >= shape[i + 1]\n                    : idx.current() >= shape[i])) {\n                throw new IllegalArgumentException(\n                        \"INDArrayIndex[\" + i + \"] is out of bounds (value: \" + idx.current() + \")\");\n            }\n        }\n\n        indexes = NDArrayIndex.resolve(arr.shapeInfoDataBuffer(), indexes);\n        if (tryShortCircuit(indexes)) {\n            return;\n        }\n\n\n        int numIntervals = 0;\n        //number of new axes dimensions to prepend to the beginning\n        int newAxesPrepend = 0;\n        //whether we have encountered an all so far\n        boolean encounteredAll = false;\n        int lastPrependIndex = -1;\n        List<Integer> oneDimensionWithAllEncountered = new ArrayList<>();\n\n                List<Long> accumShape = new ArrayList<>();\n        List<Long> accumStrides = new ArrayList<>();\n        List<Long> accumOffsets = new ArrayList<>();\n        List<Long> intervalStrides = new ArrayList<>();\n\n        //collect the indexes of the points that get removed\n        //for point purposes\n        //this will be used to compute the offset\n        //for the new array\n        List<Long> pointStrides = new ArrayList<>();\n        List<Long> pointOffsets = new ArrayList<>();\n        int numPointIndexes = 0;\n\n        //bump number to read from the shape\n        int shapeIndex = 0;\n        //stride index to read strides from the array\n        int strideIndex = 0;\n        //list of indexes to prepend to for new axes\n        //if all is encountered\n        List<Integer> prependNewAxes = new ArrayList<>();\n        for (int i = 0; i < indexes.length; i++) {\n            INDArrayIndex idx = indexes[i];\n            if (idx instanceof NDArrayIndexAll) {\n                encounteredAll = true;\n                if (i < arr.rank() && arr.size(i) == 1)\n                    oneDimensionWithAllEncountered.add(i);\n                //different dimension from new axis (look for new axis dimensions\n                //at at the beginning. track when the last new axis is encountered.\n                if (newAxesPrepend > 0 && lastPrependIndex < 0) {\n                    lastPrependIndex = i - 1;\n                }\n            }\n            //point: do nothing but move the shape counter\n            //also move the stride counter\n            if (idx instanceof PointIndex) {\n                pointOffsets.add(idx.offset());\n                pointStrides.add((long) arr.stride(strideIndex));\n                numPointIndexes++;\n                shapeIndex++;\n                strideIndex++;\n                //different dimension from new axis (look for new axis dimensions\n                //at at the beginning. track when the last new axis is encountered.\n                if (newAxesPrepend > 0 && lastPrependIndex < 0) {\n                    lastPrependIndex = i - 1;\n                }\n                continue;\n            }\n            //new axes encountered, need to track whether to prepend or\n            //to set the new axis in the middle\n            else if (idx instanceof NewAxis) {\n                //prepend the new axes at different indexes\n                accumShape.add(1L);\n                accumOffsets.add(0L);\n                accumStrides.add(0L);\n                prependNewAxes.add(i);\n                continue;\n\n            }\n\n            //points and intervals both have a direct desired length\n            else if (idx instanceof IntervalIndex && !(idx instanceof NDArrayIndexAll)\n                    || idx instanceof SpecifiedIndex) {\n                if (idx instanceof IntervalIndex) {\n                    accumStrides.add(arr.stride(strideIndex) * idx.stride());\n                    //used in computing an adjusted offset for the augmented strides\n                    intervalStrides.add(idx.stride());\n                    numIntervals++;\n                }\n\n                else\n                    accumStrides.add((long) arr.stride(strideIndex));\n                accumShape.add(idx.length());\n                //the stride stays the same\n                //add the offset for the index\n                if (idx instanceof IntervalIndex) {\n                    accumOffsets.add(idx.offset());\n                } else\n                    accumOffsets.add(idx.offset());\n\n                shapeIndex++;\n                strideIndex++;\n\n                //different dimension from new axis (look for new axis dimensions\n                //at at the beginning. track when the last new axis is encountered.\n                if (newAxesPrepend > 0 && lastPrependIndex < 0) {\n                    lastPrependIndex = i - 1;\n                }\n\n\n                continue;\n            }\n\n            //add the shape and stride\n            //based on the original stride/shape\n\n            accumShape.add((long) shape[shapeIndex++]);\n            //account for erroneous strides from dimensions of size 1\n            //move the stride index if its one and fill it in at the bottom\n            accumStrides.add((long) arr.stride(strideIndex++));\n\n            //default offsets are zero\n            accumOffsets.add(idx.offset());\n\n        }\n\n\n\n        //fill in missing strides and shapes\n        while (shapeIndex < shape.length) {\n            //scalar, should be 1 x 1 rather than the number of columns in the vector\n            if (Shape.isVector(shape)) {\n                accumShape.add(1L);\n                shapeIndex++;\n            } else\n                accumShape.add((long) shape[shapeIndex++]);\n        }\n\n\n        //fill in the rest of the offsets with zero\n        int delta = (shape.length <= 2 ? shape.length : shape.length - numPointIndexes);\n        boolean needsFilledIn = accumShape.size() != accumStrides.size() && accumOffsets.size() != accumShape.size();\n        while (accumOffsets.size() < delta && needsFilledIn)\n            accumOffsets.add(0L);\n\n\n        while (accumShape.size() < 2) {\n            if (Shape.isRowVectorShape(arr.shape()))\n                accumShape.add(0, 1L);\n            else\n                accumShape.add(1L);\n        }\n\n        while (strideIndex < accumShape.size()) {\n            accumStrides.add((long) arr.stride(strideIndex++));\n        }\n\n\n        /**\n         * For each dimension\n         * where we want to prepend a dimension\n         * we need to add it at the index such that\n         * we account for the offset of the number of indexes\n         * added up to that point.\n         *\n         * We do this by doing an offset\n         * for each item added \"so far\"\n         *\n         * Note that we also have an offset of - 1\n         * because we want to prepend to the given index.\n         *\n         * When prepend new axes for in the middle is triggered\n         * i is already > 0\n         */\n       /* int numAdded = 0;\n        for (int i = 0; i < prependNewAxes.size(); i++) {\n            accumShape.add(prependNewAxes.get(i) - numAdded, 1L);\n            //stride for the new axis is zero\n            accumStrides.add(prependNewAxes.get(i) - numAdded, 0L);\n            numAdded++;\n        }\n        for (int i = 0; i < newAxesPrepend; i++) {\n            prependNewAxes.add(0, i);\n        }\n\n        prependAxis = Ints.toArray(prependNewAxes);\n*/\n        /**\n         * Need to post process strides and offsets\n         * for trailing ones here\n         */\n        //prune off extra zeros for trailing and leading ones\n        int trailingZeroRemove = accumOffsets.size() - 1;\n        while (accumOffsets.size() > accumShape.size()) {\n            if (accumOffsets.get(trailingZeroRemove) == 0)\n                accumOffsets.remove(accumOffsets.size() - 1);\n            trailingZeroRemove--;\n        }\n\n        if (accumStrides.size() < accumOffsets.size())\n            accumStrides.addAll(pointStrides);\n        while (accumOffsets.size() < accumShape.size()) {\n            if (Shape.isRowVectorShape(arr.shape()))\n                accumOffsets.add(0, 0L);\n            else\n                accumOffsets.add(0L);\n        }\n\n\n        if (Shape.isMatrix(shape) && indexes[0] instanceof PointIndex && indexes[1] instanceof NDArrayIndexAll) {\n            Collections.reverse(accumShape);\n        }\n\n        if (arr.isMatrix() && indexes[0] instanceof PointIndex && indexes[1] instanceof IntervalIndex) {\n            this.shapes = new long[2];\n            shapes[0] = 1;\n            IntervalIndex idx = (IntervalIndex) indexes[1];\n            shapes[1] = idx.length();\n\n        } else\n            this.shapes = Longs.toArray(accumShape);\n\n\n        boolean isColumnVector = Shape.isColumnVectorShape(this.shapes);\n        //finally fill in teh rest of the strides if any are left over\n        while (accumStrides.size() < accumOffsets.size()) {\n            if (!isColumnVector)\n                accumStrides.add(0, (long) arr.elementStride());\n            else\n                accumStrides.add((long) arr.elementStride());\n        }\n\n\n        this.strides = Longs.toArray(accumStrides);\n        this.offsets = Longs.toArray(accumOffsets);\n\n        //compute point offsets differently\n        /**\n         * We need to prepend the strides for the point indexes\n         * such that the point index offsets are counted.\n         * Note here that we only use point strides\n         * when points strides isn't empty.\n         * When point strides is empty, this is\n         * because a point index was encountered\n         * but it was the lead index and therefore should\n         * not be counted with the offset.\n         *\n         *\n         * Another thing of note here is that the strides\n         * and offsets should line up such that the point\n         * and stride match up.\n         */\n        if (numPointIndexes > 0 && !pointStrides.isEmpty()) {\n            //append to the end for tensors\n            if (newAxesPrepend >= 1) {\n                while (pointStrides.size() < accumOffsets.size()) {\n                    pointStrides.add(1L);\n                }\n                //identify in the original accumulate strides\n                //where zero was set and emulate the\n                //same structure in the point strides\n                for (int i = 0; i < accumStrides.size(); i++) {\n                    if (accumStrides.get(i) == 0 && !(indexes[i] instanceof NewAxis) && lastPrependIndex <= 0)\n                        pointStrides.set(i, 0L);\n                }\n            }\n\n            //prepend any missing offsets where relevant for the dot product\n            //note here we are using the point offsets and strides\n            //for computing the offset\n            //the point of a point index is to drop a dimension\n            //and index in to a particular offset\n            while (pointOffsets.size() < pointStrides.size()) {\n                pointOffsets.add(0L);\n            }\n            //special case where offsets aren't caught\n            if (arr.isRowVector() && !intervalStrides.isEmpty() && pointOffsets.get(0) == 0\n                    && !(indexes[1] instanceof IntervalIndex))\n                this.offset = indexes[1].offset();\n            else\n                this.offset = ArrayUtil.dotProductLong2(pointOffsets, pointStrides);\n        } else {\n            this.offset = 0;\n        }\n        if (numIntervals > 0 && arr.rank() > 2) {\n            if (encounteredAll && arr.size(0) != 1 || indexes[0] instanceof PointIndex)\n                // FIXME: LONG\n                this.offset += ArrayUtil.dotProductLong2(accumOffsets, accumStrides);\n            else\n                // FIXME: LONG\n                this.offset += ArrayUtil.dotProductLong2(accumOffsets, accumStrides);\n\n        } else if (numIntervals > 0 && anyHaveStrideOne(indexes))\n            this.offset += ArrayUtil.calcOffsetLong2(accumShape, accumOffsets, accumStrides);\n        else\n            this.offset += ArrayUtil.calcOffsetLong2(accumShape, accumOffsets, accumStrides)\n                    / Math.max(1, numIntervals);\n\n\n        //collapse singular dimensions with specified index\n        List<Integer> removeShape = new ArrayList<>();\n        for (int i = 0; i < Math.min(this.shapes.length, indexes.length); i++) {\n            if (this.shapes[i] == 1 && indexes[i] instanceof SpecifiedIndex) {\n                removeShape.add(i);\n            }\n        }\n\n\n        if (!removeShape.isEmpty()) {\n            List<Long> newShape = new ArrayList<>();\n            List<Long> newStrides = new ArrayList<>();\n            for (int i = 0; i < this.shapes.length; i++) {\n                if (!removeShape.contains(i)) {\n                    newShape.add(this.shapes[i]);\n                    newStrides.add(this.strides[i]);\n                }\n            }\n\n            this.shapes = Longs.toArray(newShape);\n            this.strides = Longs.toArray(newStrides);\n        }\n\n    }",
        "variable": "accumShape",
        "reference": "accumulate the shapes",
        "explanation_by_ours": "the results to accumulate.",
        "explanation_by_baseline": "if (arr.isVector"
    },
    {
        "id": 997,
        "method": "public void exec(INDArrayIndex... indexes) {\n        val shape = arr.shape();\n\n        if (arr.isSparse()) {\n            resolveFixedDimensionsCOO(indexes);\n        }\n\n        // Check that given point indexes are not out of bounds\n        for (int i = 0; i < indexes.length; i++) {\n            INDArrayIndex idx = indexes[i];\n            // On vectors, the first dimension can be ignored when indexing them with a single point index\n            if (idx instanceof PointIndex && (arr.isVector() && indexes.length == 1 ? idx.current() >= shape[i + 1]\n                    : idx.current() >= shape[i])) {\n                throw new IllegalArgumentException(\n                        \"INDArrayIndex[\" + i + \"] is out of bounds (value: \" + idx.current() + \")\");\n            }\n        }\n\n        indexes = NDArrayIndex.resolve(arr.shapeInfoDataBuffer(), indexes);\n        if (tryShortCircuit(indexes)) {\n            return;\n        }\n\n\n        int numIntervals = 0;\n        //number of new axes dimensions to prepend to the beginning\n        int newAxesPrepend = 0;\n        //whether we have encountered an all so far\n        boolean encounteredAll = false;\n        int lastPrependIndex = -1;\n        List<Integer> oneDimensionWithAllEncountered = new ArrayList<>();\n\n        //accumulate the results\n        List<Long> accumShape = new ArrayList<>();\n        List<Long> accumStrides = new ArrayList<>();\n        List<Long> accumOffsets = new ArrayList<>();\n        List<Long> intervalStrides = new ArrayList<>();\n\n        //collect the indexes of the points that get removed\n        //for point purposes\n        //this will be used to compute the offset\n        //for the new array\n        List<Long> pointStrides = new ArrayList<>();\n        List<Long> pointOffsets = new ArrayList<>();\n        int numPointIndexes = 0;\n\n                int shapeIndex = 0;\n        //stride index to read strides from the array\n        int strideIndex = 0;\n        //list of indexes to prepend to for new axes\n        //if all is encountered\n        List<Integer> prependNewAxes = new ArrayList<>();\n        for (int i = 0; i < indexes.length; i++) {\n            INDArrayIndex idx = indexes[i];\n            if (idx instanceof NDArrayIndexAll) {\n                encounteredAll = true;\n                if (i < arr.rank() && arr.size(i) == 1)\n                    oneDimensionWithAllEncountered.add(i);\n                //different dimension from new axis (look for new axis dimensions\n                //at at the beginning. track when the last new axis is encountered.\n                if (newAxesPrepend > 0 && lastPrependIndex < 0) {\n                    lastPrependIndex = i - 1;\n                }\n            }\n            //point: do nothing but move the shape counter\n            //also move the stride counter\n            if (idx instanceof PointIndex) {\n                pointOffsets.add(idx.offset());\n                pointStrides.add((long) arr.stride(strideIndex));\n                numPointIndexes++;\n                shapeIndex++;\n                strideIndex++;\n                //different dimension from new axis (look for new axis dimensions\n                //at at the beginning. track when the last new axis is encountered.\n                if (newAxesPrepend > 0 && lastPrependIndex < 0) {\n                    lastPrependIndex = i - 1;\n                }\n                continue;\n            }\n            //new axes encountered, need to track whether to prepend or\n            //to set the new axis in the middle\n            else if (idx instanceof NewAxis) {\n                //prepend the new axes at different indexes\n                accumShape.add(1L);\n                accumOffsets.add(0L);\n                accumStrides.add(0L);\n                prependNewAxes.add(i);\n                continue;\n\n            }\n\n            //points and intervals both have a direct desired length\n            else if (idx instanceof IntervalIndex && !(idx instanceof NDArrayIndexAll)\n                    || idx instanceof SpecifiedIndex) {\n                if (idx instanceof IntervalIndex) {\n                    accumStrides.add(arr.stride(strideIndex) * idx.stride());\n                    //used in computing an adjusted offset for the augmented strides\n                    intervalStrides.add(idx.stride());\n                    numIntervals++;\n                }\n\n                else\n                    accumStrides.add((long) arr.stride(strideIndex));\n                accumShape.add(idx.length());\n                //the stride stays the same\n                //add the offset for the index\n                if (idx instanceof IntervalIndex) {\n                    accumOffsets.add(idx.offset());\n                } else\n                    accumOffsets.add(idx.offset());\n\n                shapeIndex++;\n                strideIndex++;\n\n                //different dimension from new axis (look for new axis dimensions\n                //at at the beginning. track when the last new axis is encountered.\n                if (newAxesPrepend > 0 && lastPrependIndex < 0) {\n                    lastPrependIndex = i - 1;\n                }\n\n\n                continue;\n            }\n\n            //add the shape and stride\n            //based on the original stride/shape\n\n            accumShape.add((long) shape[shapeIndex++]);\n            //account for erroneous strides from dimensions of size 1\n            //move the stride index if its one and fill it in at the bottom\n            accumStrides.add((long) arr.stride(strideIndex++));\n\n            //default offsets are zero\n            accumOffsets.add(idx.offset());\n\n        }\n\n\n\n        //fill in missing strides and shapes\n        while (shapeIndex < shape.length) {\n            //scalar, should be 1 x 1 rather than the number of columns in the vector\n            if (Shape.isVector(shape)) {\n                accumShape.add(1L);\n                shapeIndex++;\n            } else\n                accumShape.add((long) shape[shapeIndex++]);\n        }\n\n\n        //fill in the rest of the offsets with zero\n        int delta = (shape.length <= 2 ? shape.length : shape.length - numPointIndexes);\n        boolean needsFilledIn = accumShape.size() != accumStrides.size() && accumOffsets.size() != accumShape.size();\n        while (accumOffsets.size() < delta && needsFilledIn)\n            accumOffsets.add(0L);\n\n\n        while (accumShape.size() < 2) {\n            if (Shape.isRowVectorShape(arr.shape()))\n                accumShape.add(0, 1L);\n            else\n                accumShape.add(1L);\n        }\n\n        while (strideIndex < accumShape.size()) {\n            accumStrides.add((long) arr.stride(strideIndex++));\n        }\n\n\n        /**\n         * For each dimension\n         * where we want to prepend a dimension\n         * we need to add it at the index such that\n         * we account for the offset of the number of indexes\n         * added up to that point.\n         *\n         * We do this by doing an offset\n         * for each item added \"so far\"\n         *\n         * Note that we also have an offset of - 1\n         * because we want to prepend to the given index.\n         *\n         * When prepend new axes for in the middle is triggered\n         * i is already > 0\n         */\n       /* int numAdded = 0;\n        for (int i = 0; i < prependNewAxes.size(); i++) {\n            accumShape.add(prependNewAxes.get(i) - numAdded, 1L);\n            //stride for the new axis is zero\n            accumStrides.add(prependNewAxes.get(i) - numAdded, 0L);\n            numAdded++;\n        }\n        for (int i = 0; i < newAxesPrepend; i++) {\n            prependNewAxes.add(0, i);\n        }\n\n        prependAxis = Ints.toArray(prependNewAxes);\n*/\n        /**\n         * Need to post process strides and offsets\n         * for trailing ones here\n         */\n        //prune off extra zeros for trailing and leading ones\n        int trailingZeroRemove = accumOffsets.size() - 1;\n        while (accumOffsets.size() > accumShape.size()) {\n            if (accumOffsets.get(trailingZeroRemove) == 0)\n                accumOffsets.remove(accumOffsets.size() - 1);\n            trailingZeroRemove--;\n        }\n\n        if (accumStrides.size() < accumOffsets.size())\n            accumStrides.addAll(pointStrides);\n        while (accumOffsets.size() < accumShape.size()) {\n            if (Shape.isRowVectorShape(arr.shape()))\n                accumOffsets.add(0, 0L);\n            else\n                accumOffsets.add(0L);\n        }\n\n\n        if (Shape.isMatrix(shape) && indexes[0] instanceof PointIndex && indexes[1] instanceof NDArrayIndexAll) {\n            Collections.reverse(accumShape);\n        }\n\n        if (arr.isMatrix() && indexes[0] instanceof PointIndex && indexes[1] instanceof IntervalIndex) {\n            this.shapes = new long[2];\n            shapes[0] = 1;\n            IntervalIndex idx = (IntervalIndex) indexes[1];\n            shapes[1] = idx.length();\n\n        } else\n            this.shapes = Longs.toArray(accumShape);\n\n\n        boolean isColumnVector = Shape.isColumnVectorShape(this.shapes);\n        //finally fill in teh rest of the strides if any are left over\n        while (accumStrides.size() < accumOffsets.size()) {\n            if (!isColumnVector)\n                accumStrides.add(0, (long) arr.elementStride());\n            else\n                accumStrides.add((long) arr.elementStride());\n        }\n\n\n        this.strides = Longs.toArray(accumStrides);\n        this.offsets = Longs.toArray(accumOffsets);\n\n        //compute point offsets differently\n        /**\n         * We need to prepend the strides for the point indexes\n         * such that the point index offsets are counted.\n         * Note here that we only use point strides\n         * when points strides isn't empty.\n         * When point strides is empty, this is\n         * because a point index was encountered\n         * but it was the lead index and therefore should\n         * not be counted with the offset.\n         *\n         *\n         * Another thing of note here is that the strides\n         * and offsets should line up such that the point\n         * and stride match up.\n         */\n        if (numPointIndexes > 0 && !pointStrides.isEmpty()) {\n            //append to the end for tensors\n            if (newAxesPrepend >= 1) {\n                while (pointStrides.size() < accumOffsets.size()) {\n                    pointStrides.add(1L);\n                }\n                //identify in the original accumulate strides\n                //where zero was set and emulate the\n                //same structure in the point strides\n                for (int i = 0; i < accumStrides.size(); i++) {\n                    if (accumStrides.get(i) == 0 && !(indexes[i] instanceof NewAxis) && lastPrependIndex <= 0)\n                        pointStrides.set(i, 0L);\n                }\n            }\n\n            //prepend any missing offsets where relevant for the dot product\n            //note here we are using the point offsets and strides\n            //for computing the offset\n            //the point of a point index is to drop a dimension\n            //and index in to a particular offset\n            while (pointOffsets.size() < pointStrides.size()) {\n                pointOffsets.add(0L);\n            }\n            //special case where offsets aren't caught\n            if (arr.isRowVector() && !intervalStrides.isEmpty() && pointOffsets.get(0) == 0\n                    && !(indexes[1] instanceof IntervalIndex))\n                this.offset = indexes[1].offset();\n            else\n                this.offset = ArrayUtil.dotProductLong2(pointOffsets, pointStrides);\n        } else {\n            this.offset = 0;\n        }\n        if (numIntervals > 0 && arr.rank() > 2) {\n            if (encounteredAll && arr.size(0) != 1 || indexes[0] instanceof PointIndex)\n                // FIXME: LONG\n                this.offset += ArrayUtil.dotProductLong2(accumOffsets, accumStrides);\n            else\n                // FIXME: LONG\n                this.offset += ArrayUtil.dotProductLong2(accumOffsets, accumStrides);\n\n        } else if (numIntervals > 0 && anyHaveStrideOne(indexes))\n            this.offset += ArrayUtil.calcOffsetLong2(accumShape, accumOffsets, accumStrides);\n        else\n            this.offset += ArrayUtil.calcOffsetLong2(accumShape, accumOffsets, accumStrides)\n                    / Math.max(1, numIntervals);\n\n\n        //collapse singular dimensions with specified index\n        List<Integer> removeShape = new ArrayList<>();\n        for (int i = 0; i < Math.min(this.shapes.length, indexes.length); i++) {\n            if (this.shapes[i] == 1 && indexes[i] instanceof SpecifiedIndex) {\n                removeShape.add(i);\n            }\n        }\n\n\n        if (!removeShape.isEmpty()) {\n            List<Long> newShape = new ArrayList<>();\n            List<Long> newStrides = new ArrayList<>();\n            for (int i = 0; i < this.shapes.length; i++) {\n                if (!removeShape.contains(i)) {\n                    newShape.add(this.shapes[i]);\n                    newStrides.add(this.strides[i]);\n                }\n            }\n\n            this.shapes = Longs.toArray(newShape);\n            this.strides = Longs.toArray(newStrides);\n        }\n\n    }",
        "variable": "shapeIndex",
        "reference": "bump number to read from the shape",
        "explanation_by_ours": "the shape of the array to execute the operation on.",
        "explanation_by_baseline": "if (idx instanceof PointIndex"
    },
    {
        "id": 998,
        "method": "public void exec(INDArrayIndex... indexes) {\n        val shape = arr.shape();\n\n        if (arr.isSparse()) {\n            resolveFixedDimensionsCOO(indexes);\n        }\n\n        // Check that given point indexes are not out of bounds\n        for (int i = 0; i < indexes.length; i++) {\n            INDArrayIndex idx = indexes[i];\n            // On vectors, the first dimension can be ignored when indexing them with a single point index\n            if (idx instanceof PointIndex && (arr.isVector() && indexes.length == 1 ? idx.current() >= shape[i + 1]\n                    : idx.current() >= shape[i])) {\n                throw new IllegalArgumentException(\n                        \"INDArrayIndex[\" + i + \"] is out of bounds (value: \" + idx.current() + \")\");\n            }\n        }\n\n        indexes = NDArrayIndex.resolve(arr.shapeInfoDataBuffer(), indexes);\n        if (tryShortCircuit(indexes)) {\n            return;\n        }\n\n\n        int numIntervals = 0;\n        //number of new axes dimensions to prepend to the beginning\n        int newAxesPrepend = 0;\n        //whether we have encountered an all so far\n        boolean encounteredAll = false;\n        int lastPrependIndex = -1;\n        List<Integer> oneDimensionWithAllEncountered = new ArrayList<>();\n\n        //accumulate the results\n        List<Long> accumShape = new ArrayList<>();\n        List<Long> accumStrides = new ArrayList<>();\n        List<Long> accumOffsets = new ArrayList<>();\n        List<Long> intervalStrides = new ArrayList<>();\n\n        //collect the indexes of the points that get removed\n        //for point purposes\n        //this will be used to compute the offset\n        //for the new array\n        List<Long> pointStrides = new ArrayList<>();\n        List<Long> pointOffsets = new ArrayList<>();\n        int numPointIndexes = 0;\n\n        //bump number to read from the shape\n        int shapeIndex = 0;\n                int strideIndex = 0;\n        //list of indexes to prepend to for new axes\n        //if all is encountered\n        List<Integer> prependNewAxes = new ArrayList<>();\n        for (int i = 0; i < indexes.length; i++) {\n            INDArrayIndex idx = indexes[i];\n            if (idx instanceof NDArrayIndexAll) {\n                encounteredAll = true;\n                if (i < arr.rank() && arr.size(i) == 1)\n                    oneDimensionWithAllEncountered.add(i);\n                //different dimension from new axis (look for new axis dimensions\n                //at at the beginning. track when the last new axis is encountered.\n                if (newAxesPrepend > 0 && lastPrependIndex < 0) {\n                    lastPrependIndex = i - 1;\n                }\n            }\n            //point: do nothing but move the shape counter\n            //also move the stride counter\n            if (idx instanceof PointIndex) {\n                pointOffsets.add(idx.offset());\n                pointStrides.add((long) arr.stride(strideIndex));\n                numPointIndexes++;\n                shapeIndex++;\n                strideIndex++;\n                //different dimension from new axis (look for new axis dimensions\n                //at at the beginning. track when the last new axis is encountered.\n                if (newAxesPrepend > 0 && lastPrependIndex < 0) {\n                    lastPrependIndex = i - 1;\n                }\n                continue;\n            }\n            //new axes encountered, need to track whether to prepend or\n            //to set the new axis in the middle\n            else if (idx instanceof NewAxis) {\n                //prepend the new axes at different indexes\n                accumShape.add(1L);\n                accumOffsets.add(0L);\n                accumStrides.add(0L);\n                prependNewAxes.add(i);\n                continue;\n\n            }\n\n            //points and intervals both have a direct desired length\n            else if (idx instanceof IntervalIndex && !(idx instanceof NDArrayIndexAll)\n                    || idx instanceof SpecifiedIndex) {\n                if (idx instanceof IntervalIndex) {\n                    accumStrides.add(arr.stride(strideIndex) * idx.stride());\n                    //used in computing an adjusted offset for the augmented strides\n                    intervalStrides.add(idx.stride());\n                    numIntervals++;\n                }\n\n                else\n                    accumStrides.add((long) arr.stride(strideIndex));\n                accumShape.add(idx.length());\n                //the stride stays the same\n                //add the offset for the index\n                if (idx instanceof IntervalIndex) {\n                    accumOffsets.add(idx.offset());\n                } else\n                    accumOffsets.add(idx.offset());\n\n                shapeIndex++;\n                strideIndex++;\n\n                //different dimension from new axis (look for new axis dimensions\n                //at at the beginning. track when the last new axis is encountered.\n                if (newAxesPrepend > 0 && lastPrependIndex < 0) {\n                    lastPrependIndex = i - 1;\n                }\n\n\n                continue;\n            }\n\n            //add the shape and stride\n            //based on the original stride/shape\n\n            accumShape.add((long) shape[shapeIndex++]);\n            //account for erroneous strides from dimensions of size 1\n            //move the stride index if its one and fill it in at the bottom\n            accumStrides.add((long) arr.stride(strideIndex++));\n\n            //default offsets are zero\n            accumOffsets.add(idx.offset());\n\n        }\n\n\n\n        //fill in missing strides and shapes\n        while (shapeIndex < shape.length) {\n            //scalar, should be 1 x 1 rather than the number of columns in the vector\n            if (Shape.isVector(shape)) {\n                accumShape.add(1L);\n                shapeIndex++;\n            } else\n                accumShape.add((long) shape[shapeIndex++]);\n        }\n\n\n        //fill in the rest of the offsets with zero\n        int delta = (shape.length <= 2 ? shape.length : shape.length - numPointIndexes);\n        boolean needsFilledIn = accumShape.size() != accumStrides.size() && accumOffsets.size() != accumShape.size();\n        while (accumOffsets.size() < delta && needsFilledIn)\n            accumOffsets.add(0L);\n\n\n        while (accumShape.size() < 2) {\n            if (Shape.isRowVectorShape(arr.shape()))\n                accumShape.add(0, 1L);\n            else\n                accumShape.add(1L);\n        }\n\n        while (strideIndex < accumShape.size()) {\n            accumStrides.add((long) arr.stride(strideIndex++));\n        }\n\n\n        /**\n         * For each dimension\n         * where we want to prepend a dimension\n         * we need to add it at the index such that\n         * we account for the offset of the number of indexes\n         * added up to that point.\n         *\n         * We do this by doing an offset\n         * for each item added \"so far\"\n         *\n         * Note that we also have an offset of - 1\n         * because we want to prepend to the given index.\n         *\n         * When prepend new axes for in the middle is triggered\n         * i is already > 0\n         */\n       /* int numAdded = 0;\n        for (int i = 0; i < prependNewAxes.size(); i++) {\n            accumShape.add(prependNewAxes.get(i) - numAdded, 1L);\n            //stride for the new axis is zero\n            accumStrides.add(prependNewAxes.get(i) - numAdded, 0L);\n            numAdded++;\n        }\n        for (int i = 0; i < newAxesPrepend; i++) {\n            prependNewAxes.add(0, i);\n        }\n\n        prependAxis = Ints.toArray(prependNewAxes);\n*/\n        /**\n         * Need to post process strides and offsets\n         * for trailing ones here\n         */\n        //prune off extra zeros for trailing and leading ones\n        int trailingZeroRemove = accumOffsets.size() - 1;\n        while (accumOffsets.size() > accumShape.size()) {\n            if (accumOffsets.get(trailingZeroRemove) == 0)\n                accumOffsets.remove(accumOffsets.size() - 1);\n            trailingZeroRemove--;\n        }\n\n        if (accumStrides.size() < accumOffsets.size())\n            accumStrides.addAll(pointStrides);\n        while (accumOffsets.size() < accumShape.size()) {\n            if (Shape.isRowVectorShape(arr.shape()))\n                accumOffsets.add(0, 0L);\n            else\n                accumOffsets.add(0L);\n        }\n\n\n        if (Shape.isMatrix(shape) && indexes[0] instanceof PointIndex && indexes[1] instanceof NDArrayIndexAll) {\n            Collections.reverse(accumShape);\n        }\n\n        if (arr.isMatrix() && indexes[0] instanceof PointIndex && indexes[1] instanceof IntervalIndex) {\n            this.shapes = new long[2];\n            shapes[0] = 1;\n            IntervalIndex idx = (IntervalIndex) indexes[1];\n            shapes[1] = idx.length();\n\n        } else\n            this.shapes = Longs.toArray(accumShape);\n\n\n        boolean isColumnVector = Shape.isColumnVectorShape(this.shapes);\n        //finally fill in teh rest of the strides if any are left over\n        while (accumStrides.size() < accumOffsets.size()) {\n            if (!isColumnVector)\n                accumStrides.add(0, (long) arr.elementStride());\n            else\n                accumStrides.add((long) arr.elementStride());\n        }\n\n\n        this.strides = Longs.toArray(accumStrides);\n        this.offsets = Longs.toArray(accumOffsets);\n\n        //compute point offsets differently\n        /**\n         * We need to prepend the strides for the point indexes\n         * such that the point index offsets are counted.\n         * Note here that we only use point strides\n         * when points strides isn't empty.\n         * When point strides is empty, this is\n         * because a point index was encountered\n         * but it was the lead index and therefore should\n         * not be counted with the offset.\n         *\n         *\n         * Another thing of note here is that the strides\n         * and offsets should line up such that the point\n         * and stride match up.\n         */\n        if (numPointIndexes > 0 && !pointStrides.isEmpty()) {\n            //append to the end for tensors\n            if (newAxesPrepend >= 1) {\n                while (pointStrides.size() < accumOffsets.size()) {\n                    pointStrides.add(1L);\n                }\n                //identify in the original accumulate strides\n                //where zero was set and emulate the\n                //same structure in the point strides\n                for (int i = 0; i < accumStrides.size(); i++) {\n                    if (accumStrides.get(i) == 0 && !(indexes[i] instanceof NewAxis) && lastPrependIndex <= 0)\n                        pointStrides.set(i, 0L);\n                }\n            }\n\n            //prepend any missing offsets where relevant for the dot product\n            //note here we are using the point offsets and strides\n            //for computing the offset\n            //the point of a point index is to drop a dimension\n            //and index in to a particular offset\n            while (pointOffsets.size() < pointStrides.size()) {\n                pointOffsets.add(0L);\n            }\n            //special case where offsets aren't caught\n            if (arr.isRowVector() && !intervalStrides.isEmpty() && pointOffsets.get(0) == 0\n                    && !(indexes[1] instanceof IntervalIndex))\n                this.offset = indexes[1].offset();\n            else\n                this.offset = ArrayUtil.dotProductLong2(pointOffsets, pointStrides);\n        } else {\n            this.offset = 0;\n        }\n        if (numIntervals > 0 && arr.rank() > 2) {\n            if (encounteredAll && arr.size(0) != 1 || indexes[0] instanceof PointIndex)\n                // FIXME: LONG\n                this.offset += ArrayUtil.dotProductLong2(accumOffsets, accumStrides);\n            else\n                // FIXME: LONG\n                this.offset += ArrayUtil.dotProductLong2(accumOffsets, accumStrides);\n\n        } else if (numIntervals > 0 && anyHaveStrideOne(indexes))\n            this.offset += ArrayUtil.calcOffsetLong2(accumShape, accumOffsets, accumStrides);\n        else\n            this.offset += ArrayUtil.calcOffsetLong2(accumShape, accumOffsets, accumStrides)\n                    / Math.max(1, numIntervals);\n\n\n        //collapse singular dimensions with specified index\n        List<Integer> removeShape = new ArrayList<>();\n        for (int i = 0; i < Math.min(this.shapes.length, indexes.length); i++) {\n            if (this.shapes[i] == 1 && indexes[i] instanceof SpecifiedIndex) {\n                removeShape.add(i);\n            }\n        }\n\n\n        if (!removeShape.isEmpty()) {\n            List<Long> newShape = new ArrayList<>();\n            List<Long> newStrides = new ArrayList<>();\n            for (int i = 0; i < this.shapes.length; i++) {\n                if (!removeShape.contains(i)) {\n                    newShape.add(this.shapes[i]);\n                    newStrides.add(this.strides[i]);\n                }\n            }\n\n            this.shapes = Longs.toArray(newShape);\n            this.strides = Longs.toArray(newStrides);\n        }\n\n    }",
        "variable": "strideIndex",
        "reference": "stride index to read strides from the array",
        "explanation_by_ours": "the stride index.",
        "explanation_by_baseline": "add the stride counterif"
    },
    {
        "id": 1003,
        "method": "@Override\n    public void spotrf(byte uplo, int N, INDArray A, INDArray INFO) {\n        INDArray a = A;\n\n        if (Nd4j.dataType() != DataBuffer.Type.FLOAT)\n            log.warn(\"DOUBLE potrf called in FLOAT environment\");\n\n        if (A.ordering() == 'c')\n            a = A.dup('f');\n\n        if (Nd4j.getExecutioner() instanceof GridExecutioner)\n            ((GridExecutioner) Nd4j.getExecutioner()).flushQueue();\n\n                CudaContext ctx = (CudaContext) allocator.getDeviceContext().getContext();\n\n        // setup the solver handles for cuSolver calls\n        cusolverDnHandle_t handle = ctx.getSolverHandle();\n        cusolverDnContext solverDn = new cusolverDnContext(handle);\n\n        // synchronized on the solver\n        synchronized (handle) {\n            int result = cusolverDnSetStream(new cusolverDnContext(handle), new CUstream_st(ctx.getOldStream()));\n            if (result != 0)\n                throw new BlasException(\"solverSetStream failed\");\n\n            // transfer the INDArray into GPU memory\n            CublasPointer xAPointer = new CublasPointer(a, ctx);\n\n            // this output - indicates how much memory we'll need for the real operation\n            DataBuffer worksizeBuffer = Nd4j.getDataBufferFactory().createInt(1);\n\n            int stat = cusolverDnSpotrf_bufferSize(solverDn, uplo, N, \n                        (FloatPointer) xAPointer.getDevicePointer(), N,\n                        (IntPointer) worksizeBuffer.addressPointer() // we intentionally use host pointer here\n            );\n\n            if (stat != CUSOLVER_STATUS_SUCCESS) {\n                throw new BlasException(\"cusolverDnSpotrf_bufferSize failed\", stat);\n            }\n\n            int worksize = worksizeBuffer.getInt(0);\n            // Now allocate memory for the workspace, the permutation matrix and a return code\n            Pointer workspace = new Workspace(worksize * Nd4j.sizeOfDataType());\n\n            // Do the actual decomp\n            stat = cusolverDnSpotrf(solverDn, uplo, N, \n                            (FloatPointer) xAPointer.getDevicePointer(), N,\n                            new CudaPointer(workspace).asFloatPointer(),\n                            worksize,\n                            new CudaPointer(allocator.getPointer(INFO, ctx)).asIntPointer()\n                            );\n\n            if (stat != CUSOLVER_STATUS_SUCCESS) {\n                throw new BlasException(\"cusolverDnSpotrf failed\", stat);\n            }\n        }\n        allocator.registerAction(ctx, a);\n        allocator.registerAction(ctx, INFO);\n\n        if (a != A)\n            A.assign(a);\n\n        if( uplo == 'U' ) {\t\t\n            A.assign( A.transpose() ) ;\t\n\t\t\tINDArrayIndex ix[] = new INDArrayIndex[ 2 ] ;\n\t\t\tfor( int i=1 ; i<Math.min( A.rows(), A.columns() ) ; i++ ) {\n\t\t\t\tix[0] = NDArrayIndex.point( i ) ;\n\t\t\t\tix[1] = NDArrayIndex.interval( 0, i ) ;\t\t\t\t\n\t\t\t\tA.put(ix, 0) ;\n\t\t\t}            \n        } else {\n            INDArrayIndex ix[] = new INDArrayIndex[ 2 ] ;\n            for( int i=0 ; i<Math.min( A.rows(), A.columns()-1 ) ; i++ ) {\n                ix[0] = NDArrayIndex.point( i ) ;\n                ix[1] = NDArrayIndex.interval( i+1, A.columns() ) ;\n                A.put(ix, 0) ;\n            }        \n        }\n\n        log.info(\"A: {}\", A);\n    }",
        "variable": "ctx",
        "reference": "the context for current thread",
        "explanation_by_ours": "The context of the solver.",
        "explanation_by_baseline": "= new INDArrayIndex[2"
    },
    {
        "id": 1004,
        "method": "@Override\n    public void spotrf(byte uplo, int N, INDArray A, INDArray INFO) {\n        INDArray a = A;\n\n        if (Nd4j.dataType() != DataBuffer.Type.FLOAT)\n            log.warn(\"DOUBLE potrf called in FLOAT environment\");\n\n        if (A.ordering() == 'c')\n            a = A.dup('f');\n\n        if (Nd4j.getExecutioner() instanceof GridExecutioner)\n            ((GridExecutioner) Nd4j.getExecutioner()).flushQueue();\n\n        // Get context for current thread\n        CudaContext ctx = (CudaContext) allocator.getDeviceContext().getContext();\n\n                cusolverDnHandle_t handle = ctx.getSolverHandle();\n        cusolverDnContext solverDn = new cusolverDnContext(handle);\n\n        // synchronized on the solver\n        synchronized (handle) {\n            int result = cusolverDnSetStream(new cusolverDnContext(handle), new CUstream_st(ctx.getOldStream()));\n            if (result != 0)\n                throw new BlasException(\"solverSetStream failed\");\n\n            // transfer the INDArray into GPU memory\n            CublasPointer xAPointer = new CublasPointer(a, ctx);\n\n            // this output - indicates how much memory we'll need for the real operation\n            DataBuffer worksizeBuffer = Nd4j.getDataBufferFactory().createInt(1);\n\n            int stat = cusolverDnSpotrf_bufferSize(solverDn, uplo, N, \n                        (FloatPointer) xAPointer.getDevicePointer(), N,\n                        (IntPointer) worksizeBuffer.addressPointer() // we intentionally use host pointer here\n            );\n\n            if (stat != CUSOLVER_STATUS_SUCCESS) {\n                throw new BlasException(\"cusolverDnSpotrf_bufferSize failed\", stat);\n            }\n\n            int worksize = worksizeBuffer.getInt(0);\n            // Now allocate memory for the workspace, the permutation matrix and a return code\n            Pointer workspace = new Workspace(worksize * Nd4j.sizeOfDataType());\n\n            // Do the actual decomp\n            stat = cusolverDnSpotrf(solverDn, uplo, N, \n                            (FloatPointer) xAPointer.getDevicePointer(), N,\n                            new CudaPointer(workspace).asFloatPointer(),\n                            worksize,\n                            new CudaPointer(allocator.getPointer(INFO, ctx)).asIntPointer()\n                            );\n\n            if (stat != CUSOLVER_STATUS_SUCCESS) {\n                throw new BlasException(\"cusolverDnSpotrf failed\", stat);\n            }\n        }\n        allocator.registerAction(ctx, a);\n        allocator.registerAction(ctx, INFO);\n\n        if (a != A)\n            A.assign(a);\n\n        if( uplo == 'U' ) {\t\t\n            A.assign( A.transpose() ) ;\t\n\t\t\tINDArrayIndex ix[] = new INDArrayIndex[ 2 ] ;\n\t\t\tfor( int i=1 ; i<Math.min( A.rows(), A.columns() ) ; i++ ) {\n\t\t\t\tix[0] = NDArrayIndex.point( i ) ;\n\t\t\t\tix[1] = NDArrayIndex.interval( 0, i ) ;\t\t\t\t\n\t\t\t\tA.put(ix, 0) ;\n\t\t\t}            \n        } else {\n            INDArrayIndex ix[] = new INDArrayIndex[ 2 ] ;\n            for( int i=0 ; i<Math.min( A.rows(), A.columns()-1 ) ; i++ ) {\n                ix[0] = NDArrayIndex.point( i ) ;\n                ix[1] = NDArrayIndex.interval( i+1, A.columns() ) ;\n                A.put(ix, 0) ;\n            }        \n        }\n\n        log.info(\"A: {}\", A);\n    }",
        "variable": "handle",
        "reference": "the solver handles for cuSolver calls",
        "explanation_by_ours": "Solver handle",
        "explanation_by_baseline": "the solver( int i"
    },
    {
        "id": 1070,
        "method": "public boolean filter(String url, Metadata metadata)\n            throws MalformedURLException {\n        URL u = new URL(url);\n\n        // first try the full hostname\n        String hostname = u.getHost();\n        if (checkScope(hostNameRules.get(hostname), u)) {\n            return true;\n        }\n\n                String[] domainParts = hostname.split(\"\\\\.\");\n        String domain = null;\n        for (int i = domainParts.length - 1; i >= 0; i--) {\n            domain = domainParts[i] + (domain == null ? \"\" : \".\" + domain);\n            if (checkScope(domainRules.get(domain), u)) {\n                return true;\n            }\n        }\n\n        // check on parent's URL metadata\n        for (MDScope scope : metadataRules) {\n            String[] vals = metadata.getValues(scope.getKey());\n            if (vals == null) {\n                continue;\n            }\n            for (String v : vals) {\n                if (v.equalsIgnoreCase(scope.getValue())) {\n                    FastURLFilter.LOG.debug(\n                            \"Filtering {} matching metadata {}:{}\", url,\n                            scope.getKey(), scope.getValue());\n                    if (checkScope(scope, u)) {\n                        return true;\n                    }\n                }\n            }\n        }\n\n        if (checkScope(globalRules, u)) {\n            return true;\n        }\n\n        return false;\n    }",
        "variable": "domainParts",
        "reference": "the parts of the domain",
        "explanation_by_ours": "the parts of the hostname",
        "explanation_by_baseline": "if (checkScope(global"
    },
    {
        "id": 1080,
        "method": "public static ArrayChar makeFromStringArray(ArrayObject values, int strlen) {\r\n\r\n    // create shape for equivilent charArray\r\n    try {\r\n      Section section = new Section(values.getShape());\r\n      section.appendRange(strlen);\r\n\r\n      int[] shape = section.getShape();\r\n      long size = section.computeSize();\r\n\r\n      // populate char array\r\n      char[] cdata = new char[(int) size];\r\n      int start = 0;\r\n      IndexIterator ii = values.getIndexIterator();\r\n      while (ii.hasNext()) {\r\n        String s = (String) ii.next();\r\n        for (int k = 0; k < s.length() && k < strlen; k++)\r\n          cdata[start + k] = s.charAt(k);\r\n        start += strlen;\r\n      }\r\n\r\n            Array carr = Array.factory(DataType.CHAR, shape, cdata);\r\n      return (ArrayChar) carr;\r\n    } catch (InvalidRangeException e) {\r\n      e.printStackTrace();  // cant happen.\r\n      return null;\r\n    }\r\n  }",
        "variable": "carr",
        "reference": "the char Array",
        "explanation_by_ours": "The charArray to be created.",
        "explanation_by_baseline": "a new char array//"
    },
    {
        "id": 1103,
        "method": "private Object makeDynamicCatalog(String path, URI baseURI) throws IOException {\n    boolean isLatest = path.endsWith(\"/latest.xml\");\n\n    // strip off the filename\n    int pos = path.lastIndexOf(\"/\");\n    String workPath = (pos >= 0) ? path.substring(0, pos) : path;\n    String filename = (pos > 0) ? path.substring(pos + 1) : path;\n\n    // now look through the data roots for a maximal match\n    DataRootManager.DataRootMatch match = dataRootManager.findDataRootMatch(workPath);\n    if (match == null)\n      return null;\n\n    // Feature Collection\n    if (match.dataRoot.getFeatureCollection() != null) {\n      InvDatasetFeatureCollection fc = featureCollectionCache.get(match.dataRoot.getFeatureCollection());\n\n      if (isLatest)\n        return fc.makeLatest(match.remaining, path, baseURI);\n      else\n        return fc.makeCatalog(match.remaining, path, baseURI);\n    }\n\n        DatasetScan dscan = match.dataRoot.getDatasetScan();\n    if (dscan != null) {\n      if (log.isDebugEnabled()) log.debug(\"makeDynamicCatalog(): Calling DatasetScan.makeCatalogForDirectory( \" + baseURI + \", \" + path + \").\");\n      CatalogBuilder cat;\n\n      if (isLatest)\n        cat = dscan.makeCatalogForLatest(workPath, baseURI);\n      else\n        cat = dscan.makeCatalogForDirectory(workPath, baseURI);\n\n      if (null == cat)\n        log.error(\"makeDynamicCatalog(): DatasetScan.makeCatalogForDirectory failed = \" + workPath);\n\n      return cat;\n    }\n\n    // CatalogScan\n    CatalogScan catScan = match.dataRoot.getCatalogScan();\n    if (catScan != null) {\n      if (!filename.equalsIgnoreCase(CatalogScan.CATSCAN)) { // its an actual catalog\n        return catScan.getCatalog(tdsContext.getThreddsDirectory(), match.remaining, filename, ccc);\n      }\n\n      if (log.isDebugEnabled()) log.debug(\"makeDynamicCatalog(): Calling CatalogScan.makeCatalogForDirectory( \" + baseURI + \", \" + path + \").\");\n      CatalogBuilder cat = catScan.makeCatalogFromDirectory(tdsContext.getThreddsDirectory(), match.remaining, baseURI);\n\n      if (null == cat)\n        log.error(\"makeDynamicCatalog(): CatalogScan.makeCatalogForDirectory failed = \" + workPath);\n\n      return cat;\n    }\n\n    log.warn(\"makeDynamicCatalog() failed for =\" + workPath + \" request path= \" + path);\n    return null;\n  }",
        "variable": "dscan",
        "reference": "DatasetScan",
        "explanation_by_ours": "The DatasetScan to use to create the catalog.",
        "explanation_by_baseline": "DatasetScanif (is"
    },
    {
        "id": 1104,
        "method": "private Object makeDynamicCatalog(String path, URI baseURI) throws IOException {\n    boolean isLatest = path.endsWith(\"/latest.xml\");\n\n    // strip off the filename\n    int pos = path.lastIndexOf(\"/\");\n    String workPath = (pos >= 0) ? path.substring(0, pos) : path;\n    String filename = (pos > 0) ? path.substring(pos + 1) : path;\n\n    // now look through the data roots for a maximal match\n    DataRootManager.DataRootMatch match = dataRootManager.findDataRootMatch(workPath);\n    if (match == null)\n      return null;\n\n    // Feature Collection\n    if (match.dataRoot.getFeatureCollection() != null) {\n      InvDatasetFeatureCollection fc = featureCollectionCache.get(match.dataRoot.getFeatureCollection());\n\n      if (isLatest)\n        return fc.makeLatest(match.remaining, path, baseURI);\n      else\n        return fc.makeCatalog(match.remaining, path, baseURI);\n    }\n\n    // DatasetScan\n    DatasetScan dscan = match.dataRoot.getDatasetScan();\n    if (dscan != null) {\n      if (log.isDebugEnabled()) log.debug(\"makeDynamicCatalog(): Calling DatasetScan.makeCatalogForDirectory( \" + baseURI + \", \" + path + \").\");\n      CatalogBuilder cat;\n\n      if (isLatest)\n        cat = dscan.makeCatalogForLatest(workPath, baseURI);\n      else\n        cat = dscan.makeCatalogForDirectory(workPath, baseURI);\n\n      if (null == cat)\n        log.error(\"makeDynamicCatalog(): DatasetScan.makeCatalogForDirectory failed = \" + workPath);\n\n      return cat;\n    }\n\n        CatalogScan catScan = match.dataRoot.getCatalogScan();\n    if (catScan != null) {\n      if (!filename.equalsIgnoreCase(CatalogScan.CATSCAN)) { // its an actual catalog\n        return catScan.getCatalog(tdsContext.getThreddsDirectory(), match.remaining, filename, ccc);\n      }\n\n      if (log.isDebugEnabled()) log.debug(\"makeDynamicCatalog(): Calling CatalogScan.makeCatalogForDirectory( \" + baseURI + \", \" + path + \").\");\n      CatalogBuilder cat = catScan.makeCatalogFromDirectory(tdsContext.getThreddsDirectory(), match.remaining, baseURI);\n\n      if (null == cat)\n        log.error(\"makeDynamicCatalog(): CatalogScan.makeCatalogForDirectory failed = \" + workPath);\n\n      return cat;\n    }\n\n    log.warn(\"makeDynamicCatalog() failed for =\" + workPath + \" request path= \" + path);\n    return null;\n  }",
        "variable": "catScan",
        "reference": "CatalogScan",
        "explanation_by_ours": "The catalog scan.",
        "explanation_by_baseline": "CatalogScanif (cat"
    },
    {
        "id": 1129,
        "method": "public static void main(String args[]) {\n    boolean usePopup = false;\n\n    for (int i = 0; i < args.length; i++) {\n      if (args[i].equals(\"-usePopup\"))\n        usePopup = true;\n    }\n\n    try {\n      store = XMLStore.createFromFile(\"ThreddsDatasetChooser\", null);\n      p = store.getPreferences();\n    } catch (IOException e) {\n      System.out.println(\"XMLStore Creation failed \" + e);\n    }\n\n        final JFrame frame = new JFrame(\"Thredds Dataset Chooser\");\n    frame.addWindowListener(new WindowAdapter() {\n      public void windowClosing(WindowEvent e) {\n        chooser.save();\n        Rectangle bounds = frame.getBounds();\n        p.putBeanObject(FRAME_SIZE, bounds);\n        try {\n          store.save();\n        } catch (IOException ioe) {\n          ioe.printStackTrace();\n        }\n\n        System.exit(0);\n      }\n    });\n\n    chooser = new ThreddsDatasetChooser(p, null, frame, true, usePopup, false);\n    chooser.setDoResolve(true);\n\n    //\n    frame.getContentPane().add(chooser);\n    Rectangle bounds = (Rectangle) p.getBean(FRAME_SIZE, new Rectangle(50, 50, 800, 450));\n    frame.setBounds(bounds);\n\n    frame.pack();\n    frame.setBounds(bounds);\n    frame.setVisible(true);\n  }",
        "variable": "frame",
        "reference": "a JFrame",
        "explanation_by_ours": "the JFrame",
        "explanation_by_baseline": "a new frame //="
    },
    {
        "id": 1136,
        "method": "void finishInit() {\r\n\r\n      // some widgets from the GridUI\r\n    np = ui.panz;\r\n    vertPanel = ui.vertPanel;\r\n    dataValueLabel = ui.dataValueLabel;\r\n    posLabel = ui.positionLabel;\r\n\r\n      // get last saved Projection\r\n    project = (ProjectionImpl) store.getBean(LastProjectionName, null);\r\n    if (project != null)\r\n      setProjection( project);\r\n\r\n          ProjectionRect ma = (ProjectionRect) store.getBean(LastMapAreaName, null);\r\n    if (ma != null)\r\n      np.setMapArea( ma);\r\n\r\n    makeEventManagement();\r\n\r\n    // last thing\r\n    /* get last dataset filename and reopen it\r\n    String filename = (String) store.get(LastDatasetName);\r\n    if (filename != null)\r\n      setDataset(filename); */\r\n  }",
        "variable": "ma",
        "reference": "MapArea",
        "explanation_by_ours": "the map area.",
        "explanation_by_baseline": "MapArea= (Grid"
    },
    {
        "id": 1142,
        "method": "protected boolean init(boolean fullCheck) throws IOException {\n\n    boolean ok = super.init(fullCheck);\n    if (!ok) return false;\n\n    // Modeled after GD_OFIL\n    if (dmLabel.kftype != MFGD) {\n      logError(\"not a grid file\");\n      return false;\n    }\n        DMPart part = getPart(\"GRID\");\n\n    if (part == null) {\n      logError(\"No part named GRID found\");\n      return false;\n    }\n    int lenhdr = part.klnhdr;\n    if (lenhdr > LLGDHD) {\n      logError(\"Grid part header too long\");\n      return false;\n    }\n    // int khdrln = lenhdr - 2;\n\n    // check that the column names are correct\n    for (int i = 0; i < keys.kkcol.size(); i++) {\n      Key colkey = keys.kkcol.get(i);\n      if (!colkey.name.equals(kcolnm[i])) {\n        logError(\"Column name \" + colkey + \" doesn't match \" + kcolnm[i]);\n        return false;\n      }\n    }\n\n    if (!fullCheck) {\n      return true;\n    }\n\n    gridIndex = new GridIndex(filename);\n    // Make the NAV and ANAL blocks\n    float[] headerArray = getFileHeader(NAVB);\n    if (headerArray == null) {\n      return false;\n    }\n    navBlock = new NavigationBlock(headerArray);\n    //System.out.println(\"nav = \" + navBlock);\n    gridIndex.addHorizCoordSys(navBlock);\n\n    headerArray = getFileHeader(ANLB);\n    if (headerArray == null) {\n      return false;\n    }\n    analBlock = new AnalysisBlock(headerArray);\n\n    // Make the grid headers\n    // TODO: move this up into GempakFileReader using DM_RHDA\n    // and account for the flipping there.\n    List<GempakGridRecord> tmpList = new ArrayList<>();\n    int[] header = new int[dmLabel.kckeys];\n    if ((headers == null) || (headers.colHeaders == null)) {\n      return false;\n    }\n    int gridNum = 0;\n    for (int[] fullHeader : headers.colHeaders) {\n      gridNum++;  // grid numbers are 1 based\n      if ((fullHeader == null) || (fullHeader[0] == IMISSD)) {\n        continue;\n      }\n      // TODO: have GempakGridRecord skip the first word\n      System.arraycopy(fullHeader, 1, header, 0, header.length);\n      GempakGridRecord gh = new GempakGridRecord(gridNum, header);\n      gh.navBlock = navBlock;\n      String name = gh.getParameterName();\n      //if (name.equals(\"TMPK\") ||\n      //    name.equals(\"UREL\") ||\n      //    name.equals(\"VREL\") ||\n      //    name.equals(\"PMSL\")) {\n      tmpList.add(gh);\n      //}\n    }\n\n    // reset the file size since we've gone through all the grids.\n    fileSize = rf.length();\n\n    // find the packing types for these grids\n    // TODO: go back to using gridList\n    //List gridList = gridIndex.getGridRecords();\n    //if ( !gridList.isEmpty()) {\n    if (!tmpList.isEmpty()) {\n      for (GempakGridRecord gh : tmpList) {\n        gh.packingType = getGridPackingType(gh.gridNumber);\n        if ((gh.packingType == MDGGRB) || (gh.packingType == MDGRB2)\n                || (gh.packingType == MDGNON)) {\n          gridIndex.addGridRecord(gh);\n        }\n      }\n    } else {\n      return false;\n    }\n\n    // check to see if there are any grids that we can handle\n    if (gridIndex.getGridRecords().isEmpty()) {\n      return false;\n    }\n\n    return true;\n\n  }",
        "variable": "part",
        "reference": "the part for GRID",
        "explanation_by_ours": "the DMPart to find the part for",
        "explanation_by_baseline": "the GRID partif"
    },
    {
        "id": 1150,
        "method": "public void doonce(HttpServletRequest req)\n            throws SendError\n    {\n        if(once)\n            return;\n        super.initOnce(req);\n        if(this.downloaddir == null)\n            throw new SendError(HttpStatus.SC_PRECONDITION_FAILED, \"Download disabled\");\n        this.downloaddirname = new File(this.downloaddir).getName();\n\n                File downform = null;\n        downform = tdsContext.getDownloadForm();\n        if(downform == null) {   // Look in WEB-INF directory\n            File root = tdsContext.getServletRootDirectory();\n            downform = new File(root, DEFAULTDOWNLOADFORM);\n        }\n        try {\n            this.downloadform = loadForm(downform);\n        } catch (IOException ioe) {\n            throw new SendError(HttpStatus.SC_PRECONDITION_FAILED, ioe);\n        }\n    }",
        "variable": "downform",
        "reference": "the download form",
        "explanation_by_ours": "the downform",
        "explanation_by_baseline": "the download formif ("
    },
    {
        "id": 1158,
        "method": "private Element makeVariable( VariableDS var) {\r\n\r\n    Element varElem = new Element(\"variable\", thredds.client.catalog.Catalog.ncmlNS);\r\n\r\n    varElem.setAttribute(\"name\", var.getFullName());\r\n\r\n    StringBuffer buff = new StringBuffer();\r\n    List dims = var.getDimensions();\r\n    for (int i=0; i<dims.size(); i++) {\r\n      Dimension dim = (Dimension) dims.get(i);\r\n      if (i > 0) buff.append( \" \");\r\n      buff.append( dim.getShortName());\r\n    }\r\n    if (buff.length() > 0)\r\n      varElem.setAttribute(\"shape\", buff.toString());\r\n\r\n    DataType dt = var.getDataType();\r\n    if (dt != null)\r\n      varElem.setAttribute(\"type\", dt.toString());\r\n\r\n        // attributes\r\n    for (Attribute att : var.getAttributes()) {\r\n      varElem.addContent(makeAttribute(att, \"attribute\"));\r\n    }\r\n\r\n    if (var.isMetadata())\r\n      varElem.addContent( makeValues( var));\r\n\r\n        List csys = var.getCoordinateSystems();\r\n    if (csys.size() > 0) {\r\n      buff.setLength(0);\r\n      for (int i=0; i<csys.size(); i++) {\r\n        CoordinateSystem cs = (CoordinateSystem) csys.get(i);\r\n        if (i>0) buff.append(\" \");\r\n        buff.append( cs.getName());\r\n      }\r\n      varElem.setAttribute(\"coordinateSystems\", buff.toString());\r\n    }\r\n\r\n    return varElem;\r\n  }",
        "variable": "csys",
        "reference": "coordinate systems",
        "explanation_by_ours": "the coordinate systems",
        "explanation_by_baseline": "coordinate systems= var."
    },
    {
        "id": 1229,
        "method": "@Override\n  protected Boolean makeRecordStructure() {\n    if (this.orgFile == null) return false;\n\n    Boolean hasRecord = (Boolean) this.orgFile.sendIospMessage(NetcdfFile.IOSP_MESSAGE_ADD_RECORD_STRUCTURE);\n    if ((hasRecord == null) || !hasRecord) return false;\n\n    Variable orgV = this.orgFile.getRootGroup().findVariable(\"record\");\n    if ((orgV == null) || !(orgV instanceof Structure)) return false;\n    Structure orgStructure = (Structure) orgV;\n\n    Dimension udim = getUnlimitedDimension();\n    if (udim == null) return false;\n\n    Group root = getRootGroup();\n    StructureDS newStructure = new StructureDS(this, root, null, \"record\", udim.getShortName(), null, null);\n    newStructure.setOriginalVariable(orgStructure);\n\n    for (Variable v : getVariables()) {\n      if (!v.isUnlimited()) continue;\n      VariableDS memberV;\n\n      try {\n        memberV = (VariableDS) v.slice(0, 0); // set unlimited dimension to 0\n      } catch (InvalidRangeException e) {\n        log.error(\"Cant slice variable \" + v);\n        return false;\n      }\n      memberV.setParentStructure(newStructure); // reparent\n      /* memberV.createNewCache(); // decouple caching\n      //orgV = orgStructure.findVariable(v.getShortName());\n      //if (orgV != null)\n      //  memberV.setOriginalVariable(orgV);\n\n            List<Dimension> dims = new ArrayList<Dimension>(v.getDimensions());\n      dims.remove(0);\n      memberV.setDimensions(dims); */\n\n      newStructure.addMemberVariable(memberV);\n    }\n\n    root.addVariable(newStructure);\n    finish();\n\n    //if (isEnhancedScaleOffset())\n    //  newStructure.enhance();\n    return true;\n  }",
        "variable": "dims",
        "reference": "record dimension",
        "explanation_by_ours": "The list of dimensions for the new record structure.",
        "explanation_by_baseline": "unlimited dimension from list"
    },
    {
        "id": 1233,
        "method": "public synchronized void deserialize(DataInputStream source,\r\n                                         ServerVersion sv,\r\n                                         StatusUI statusUI)\r\n            throws IOException, EOFException, DataReadException {\r\n\r\n        int modFour = vals.length % 4;\r\n                int pad = (modFour != 0) ? (4 - modFour) : 0;\r\n\r\n        for (int i = 0; i < vals.length; i++) {\r\n            vals[i] = source.readByte();\r\n            if (statusUI != null) {\r\n                statusUI.incrementByteCount(1);\r\n                if (statusUI.userCancelled())\r\n                    throw new DataReadException(\"User cancelled\");\r\n            }\r\n        }\r\n        // pad out to a multiple of four bytes\r\n        byte unused;\r\n        for (int i = 0; i < pad; i++)\r\n            unused = source.readByte();\r\n        if (statusUI != null)\r\n            statusUI.incrementByteCount(pad);\r\n    }",
        "variable": "pad",
        "reference": "number of bytes to pad",
        "explanation_by_ours": "the number of bytes to pad out",
        "explanation_by_baseline": "pad out to a multiple"
    },
    {
        "id": 1237,
        "method": "public static InputStream getInputStream(String resourceName) throws FileNotFoundException {\r\n\r\n        ClassLoader cl = GribResourceReader.class.getClassLoader();\r\n    InputStream s = cl.getResourceAsStream(resourceName);\r\n    if (s != null) {\r\n      return s;\r\n    }\r\n\r\n    // Try the file system\r\n    File f = new File(resourceName);\r\n    if (f.exists())\r\n      return new FileInputStream(f);\r\n\r\n    // give up\r\n    throw new FileNotFoundException(\"Cant find resource \"+resourceName);\r\n  }",
        "variable": "cl",
        "reference": "the class loader to get resource",
        "explanation_by_ours": "The class loader to use.",
        "explanation_by_baseline": "// Try the file system"
    },
    {
        "id": 1240,
        "method": "static public @Nonnull\r\n  CoordSysBuilderIF factory(NetcdfDataset ds, CancelTask cancelTask) throws IOException {\r\n\r\n        String convName = ds.findAttValueIgnoreCase(null, CDM.CONVENTIONS, null);\r\n    if (convName == null)\r\n      convName = ds.findAttValueIgnoreCase(null, \"Convention\", null); // common mistake Convention instead of Conventions\r\n    if (convName != null)\r\n      convName = convName.trim();\r\n\r\n    // look for ncml first\r\n    if (convName != null) {\r\n      String convNcML = ncmlHash.get(convName);\r\n      if (convNcML != null) {\r\n        CoordSysBuilder csb = new CoordSysBuilder();\r\n        NcMLReader.wrapNcML(ds, convNcML, cancelTask);\r\n        return csb;\r\n      }\r\n    }\r\n\r\n    // look for registered conventions using convention name\r\n    Class convClass = null;\r\n    if (convName != null) {\r\n      convClass = matchConvention(convName);\r\n\r\n      // now look for comma or semicolon or / delimited list\r\n      if (convClass == null) {\r\n        List<String> names = breakupConventionNames(convName);\r\n        if (names.size() > 0) {\r\n          // search the registered conventions, in order\r\n          for (Convention conv : conventionList) {\r\n            for (String name : names) {\r\n              if (name.equalsIgnoreCase(conv.convName)) {\r\n                convClass = conv.convClass;\r\n                convName = name;\r\n              }\r\n            }\r\n            if (convClass != null) break;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    // look for ones that dont use Convention attribute, in order added.\r\n    // call static isMine() using reflection.\r\n    if (convClass == null) {\r\n      for (Convention conv : conventionList) {\r\n        Class c = conv.convClass;\r\n        Method m;\r\n\r\n        try {\r\n          m = c.getMethod(\"isMine\", NetcdfFile.class);   // LOOK cant we test if method exists ?\r\n        } catch (NoSuchMethodException ex) {\r\n          continue;\r\n        }\r\n\r\n        try {\r\n          Boolean result = (Boolean) m.invoke(null, ds);\r\n          if (result) {\r\n            convClass = c;\r\n            break;\r\n          }\r\n        } catch (Exception ex) {\r\n          log.error(\"ERROR: Class \" + c.getName() + \" Exception invoking isMine method\\n\" + ex);\r\n        }\r\n      }\r\n    }\r\n\r\n    // use service loader mechanism\r\n    // call static isMine() using reflection.\r\n    CoordSysBuilderIF builder = null;\r\n    if (convClass == null) {\r\n      for (CoordSysBuilderIF csb : ServiceLoader.load(CoordSysBuilderIF.class)) {\r\n\r\n        Class c = csb.getClass();\r\n        Method m;\r\n        try {\r\n          m = c.getMethod(\"isMine\", NetcdfFile.class);\r\n        } catch (NoSuchMethodException ex) {\r\n          continue;\r\n        }\r\n\r\n        try {\r\n          Boolean result = (Boolean) m.invoke(null, ds);\r\n          if (result) {\r\n            builder = csb;\r\n            convClass = c;\r\n            break;\r\n          }\r\n        } catch (Exception ex) {\r\n          log.error(\"ERROR: Class \" + c.getName() + \" Exception invoking isMine method%n\" + ex);\r\n        }\r\n      }\r\n\r\n    }\r\n\r\n    // if no convention class found, use the default\r\n    if (convClass == null)\r\n      convClass = DefaultConvention.class;\r\n\r\n    if (builder == null) {\r\n      // get an instance of the class\r\n      try {\r\n        builder = (CoordSysBuilderIF) convClass.newInstance();\r\n      } catch (Exception e) {\r\n        log.error(\"failed on CoordSysBuilderIF for \" + convClass.getName(), e);\r\n        throw new RuntimeException(e);\r\n      }\r\n    }\r\n\r\n    if (convName == null)\r\n      builder.addUserAdvice(\"No 'Conventions' global attribute.\");\r\n    else if (convClass == DefaultConvention.class)\r\n      builder.addUserAdvice(\"No CoordSysBuilder is defined for Conventions= '\" + convName + \"'\\n\");\r\n    else\r\n      builder.setConventionUsed(convClass.getName());\r\n\r\n    ds.addAttribute(null, new Attribute(_Coordinate._CoordSysBuilder, convClass.getName()));\r\n    return builder;\r\n  }",
        "variable": "convName",
        "reference": "the Conventions attribute",
        "explanation_by_ours": "the name of the Conventions attribute",
        "explanation_by_baseline": "ncml firstif ("
    },
    {
        "id": 1252,
        "method": "public void initOnce(HttpServletRequest req)\n            throws SendError\n    {\n        if(once)\n            return;\n        once = true;\n        log.info(getClass().getName() + \" GET initialization\");\n        if(this.tdsContext == null)\n            throw new SendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR, \"Cannot find TDS Context\");\n        // Get server host + port name\n        StringBuilder buf = new StringBuilder();\n        buf.append(req.getServerName());\n        int port = req.getServerPort();\n        if(port > 0) {\n            buf.append(\":\");\n            buf.append(port);\n        }\n        this.server = buf.toString();\n\n        // Obtain servlet path info\n        String tmp = HTTPUtil.canonicalpath(req.getContextPath());\n        this.threddsname = HTTPUtil.nullify(HTTPUtil.relpath(tmp));\n        tmp = HTTPUtil.canonicalpath(req.getServletPath());\n        this.requestname = HTTPUtil.nullify(HTTPUtil.relpath(tmp));\n\n        if(this.threddsname == null)\n            this.threddsname = DEFAULTSERVLETNAME;\n\n                File updir = tdsContext.getUploadDir();\n        if(updir == null) {\n            log.warn(\"No tds.upload.dir specified\");\n            this.uploaddir = null;\n        } else\n            this.uploaddir = HTTPUtil.canonicalpath(updir.getAbsolutePath());\n        // Get the download dir\n        File downdir = tdsContext.getDownloadDir();\n        if(downdir == null) {\n            log.warn(\"No tds.download.dir specified\");\n            this.downloaddir = null;\n        } else\n            this.downloaddir = HTTPUtil.canonicalpath(downdir.getAbsolutePath());\n\n    }",
        "variable": "updir",
        "reference": "the upload dir",
        "explanation_by_ours": "The upload dir.",
        "explanation_by_baseline": "the upload dirif("
    },
    {
        "id": 1253,
        "method": "public void initOnce(HttpServletRequest req)\n            throws SendError\n    {\n        if(once)\n            return;\n        once = true;\n        log.info(getClass().getName() + \" GET initialization\");\n        if(this.tdsContext == null)\n            throw new SendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR, \"Cannot find TDS Context\");\n        // Get server host + port name\n        StringBuilder buf = new StringBuilder();\n        buf.append(req.getServerName());\n        int port = req.getServerPort();\n        if(port > 0) {\n            buf.append(\":\");\n            buf.append(port);\n        }\n        this.server = buf.toString();\n\n        // Obtain servlet path info\n        String tmp = HTTPUtil.canonicalpath(req.getContextPath());\n        this.threddsname = HTTPUtil.nullify(HTTPUtil.relpath(tmp));\n        tmp = HTTPUtil.canonicalpath(req.getServletPath());\n        this.requestname = HTTPUtil.nullify(HTTPUtil.relpath(tmp));\n\n        if(this.threddsname == null)\n            this.threddsname = DEFAULTSERVLETNAME;\n\n        // Get the upload dir\n        File updir = tdsContext.getUploadDir();\n        if(updir == null) {\n            log.warn(\"No tds.upload.dir specified\");\n            this.uploaddir = null;\n        } else\n            this.uploaddir = HTTPUtil.canonicalpath(updir.getAbsolutePath());\n                File downdir = tdsContext.getDownloadDir();\n        if(downdir == null) {\n            log.warn(\"No tds.download.dir specified\");\n            this.downloaddir = null;\n        } else\n            this.downloaddir = HTTPUtil.canonicalpath(downdir.getAbsolutePath());\n\n    }",
        "variable": "downdir",
        "reference": "the download dir",
        "explanation_by_ours": "The download directory.",
        "explanation_by_baseline": "the download dirif("
    },
    {
        "id": 1257,
        "method": "@Nullable\r\n  public TimeCoordIntvDateValue getForecastTimeInterval(Grib2Record gr) {\r\n    // note  from Arthur Taylor (degrib):\r\n    /* If there was a range I used:\r\n\r\n    End of interval (EI) = (bytes 36-42 show an \"end of overall time interval\")\r\n    C1) End of Interval = EI;\r\n    Begin of Interval = EI - range\r\n\r\n    and if there was no interval then I used:\r\n    C2) End of Interval = Begin of Interval = Ref + ForeT.\r\n    */\r\n    if (!gr.getPDS().isTimeInterval()) return null;\r\n    Grib2Pds.PdsInterval pdsIntv = (Grib2Pds.PdsInterval) gr.getPDS();\r\n    int timeUnitOrg = gr.getPDS().getTimeUnit();\r\n\r\n    // calculate total \"range\"\r\n    int range = 0;\r\n    for (Grib2Pds.TimeInterval ti : pdsIntv.getTimeIntervals()) {\r\n      if (ti.timeRangeUnit == 255)\r\n        continue;\r\n      if ((ti.timeRangeUnit != timeUnitOrg) || (ti.timeIncrementUnit != timeUnitOrg && ti.timeIncrementUnit != 255 && ti.timeIncrement != 0)) {\r\n        if (!timeUnitWarnWasSent) {\r\n          logger.warn(\"TimeInterval has different units timeUnit org=\" + timeUnitOrg + \" TimeInterval=\" + ti.timeIncrementUnit);\r\n          timeUnitWarnWasSent = true;\r\n          // throw new RuntimeException(\"TimeInterval(2) has different units\");\r\n        }\r\n      }\r\n\r\n      range += ti.timeRangeLength;\r\n      if (ti.timeIncrementUnit != 255) range += ti.timeIncrement;\r\n    }\r\n\r\n    CalendarPeriod unitPeriod = Grib2Utils.getCalendarPeriod(convertTimeUnit(timeUnitOrg));\r\n    if (unitPeriod == null) return null;\r\n    CalendarPeriod period = unitPeriod.multiply(range);\r\n\r\n        CalendarDate EI = pdsIntv.getIntervalTimeEnd();\r\n    if (EI == CalendarDate.UNKNOWN) {  // all values were set to zero   LOOK guessing!\r\n      return new TimeCoordIntvDateValue(gr.getReferenceDate(), period);\r\n    } else {\r\n      return new TimeCoordIntvDateValue(period, EI);\r\n    }\r\n  }",
        "variable": "EI",
        "reference": "End of Interval",
        "explanation_by_ours": "End of interval",
        "explanation_by_baseline": "get interval time end//"
    },
    {
        "id": 1262,
        "method": "public DapNode\n    lookup(String fqn, DapSort... sortset)\n            throws DapException\n    {\n        fqn = fqn.trim();\n        if(fqn == null)\n            return null;\n        if(\"\".equals(fqn) || \"/\".equals(fqn)) {\n            return this;\n        }\n        if(fqn.charAt(0) == '/')\n            fqn = fqn.substring(1); // remove leading /\n        //Check first for an atomic type\n        TypeSort ts = TypeSort.getTypeSort(fqn);\n        if(ts != null && ts.isAtomic()) {\n            // see if we are looking for an atomic type\n            for(DapSort ds: sortset) {\n                if(ds == DapSort.ATOMICTYPE)\n                    return DapType.lookup(ts);\n            }\n        }\n\n        // Do not use split to be able to look for escaped '/'\n        // Warning: elements of path are unescaped\n        List<String> path = DapUtil.backslashSplit(fqn, '/');\n        DapGroup current = dataset;\n        // Walk all but the last element to walk group path\n        for(int i = 0; i < path.size() - 1; i++) {\n            String groupname = Escape.backslashUnescape(path.get(i));\n            DapGroup g = (DapGroup)current.findInGroup(groupname, DapSort.GROUP);\n            if(g == null)\n                return null;\n            assert (g.getSort() == DapSort.GROUP);\n            current = (DapGroup) g;\n        }\n        if(!ALLOWFIELDMAPS) {\n            String targetname = Escape.backslashUnescape(path.get(path.size()-1));\n            return current.findInGroup(targetname, sortset);\n        } else { // ALLOWFIELDMAPS)\n            // We need to handle the last segment of the group path\n            // to deal with struct walking using '.'. We need to obtain the last segment\n            // with escapes intact so we can spot '.' separators.\n            // Locate the last element in the last group\n            // Start by looking for any containing structure\n            String varpart = path.get(path.size() - 1); // Note that this still has escapes\n            // So that '.' parsing will be correct.\n            List<String> structpath = DapUtil.backslashSplit(varpart, '.');\n            String outer = Escape.backslashUnescape(structpath.get(0));\n            if(structpath.size() == 1) {\n                return current.findInGroup(outer, sortset);\n            } else {// It is apparently a structure field\n                                DapStructure currentstruct = (DapStructure) current.findInGroup(outer, DapSort.STRUCTURE, DapSort.SEQUENCE);\n                if(currentstruct == null)\n                    return null; // does not exist\n                // search for the innermost structure\n                String fieldname;\n                for(int i = 1; i < structpath.size() - 1; i++) {\n                    fieldname = Escape.backslashUnescape(structpath.get(i));\n                    DapVariable field = (DapVariable) currentstruct.findByName(fieldname);\n                    if(field == null)\n                        throw new DapException(\"No such field: \" + fieldname);\n                    if(!field.isCompound())\n                        break;\n                    currentstruct = (DapStructure) field.getBaseType();\n                }\n                fieldname = Escape.backslashUnescape(structpath.get(structpath.size() - 1));\n                DapVariable field = currentstruct.findByName(fieldname);\n                if(field == null)\n                    throw new DapException(\"No such field: \" + fieldname);\n                if(field.getSort().oneof(sortset))\n                    return (field);\n            }\n        }\n        return null;\n    }",
        "variable": "currentstruct",
        "reference": "the outermost structure to start with",
        "explanation_by_ours": "The current DAP node.",
        "explanation_by_baseline": "the innermost structure"
    },
    {
        "id": 1266,
        "method": "public void open(RandomAccessFile raf, NetcdfFile ncfile, CancelTask cancelTask) throws IOException {\r\n    /*\r\n     * <b>open</b> initializes the file meta data and creates all variables.\r\n     * The meta-data and variable information is gathered from the UAM-IV\r\n     * header.  The header format is detailed in the CAMx User's \r\n     * guide and copied here.\r\n     * \r\n     * Header:\r\n     * name,note,ione,nspec,ibdate,btime,iedate,etime\r\n     * rdum,rdum,iutm,xorg,yorg,delx,dely,nx,ny,nz,idum,idum,rdum,rdum,rdum\r\n     * ione,ione,nx,ny\r\n     * (mspec(l),l=1,nspec)\r\n     *\r\n     * name - Text string (character*4(10) array)\r\n     * note - Text string containing file description (character*4(60) array)\r\n     * ione - Dummy variable = 1\r\n     * nspec - Number of species on file\r\n     * ibdate - Beginning date (YYJJJ)\r\n     * btime - Beginning hour (HHMM)\r\n     * iedate - Ending date (YYJJJ)\r\n     * etime - Ending hour (HHMM)\r\n     * rdum - Dummy real variable\r\n     * iutm - UTM zone (ignored for other projections)\r\n     * xorg - Grid x-origin at southwest corner of domain (m or degrees longitude)\r\n     * yorg - Grid y-origin at southwest corner of domain (m or degrees latitude)\r\n     * delx - Cell size in x-direction (m or degrees longitude)\r\n     * dely - Cell size in y-direction (m or degrees longitude)\r\n     * nx - Number of grid columns\r\n     * ny - Number of grid rows\r\n     * nz - Number of layers\r\n     * idum - Dummy integer variable\r\n     * mspec - Species names for nspec species (character*4(10,nspec) array)\r\n     *\r\n     *\r\n     *   time step is HHMMSS\r\n     *\r\n     *  the projection is:\r\n     *   LCC // >  :GDTYP = 2; // int\r\n     *   First True Latitude (Alpha):  \t30N // >  :P_ALP = 30.0; // double\r\n     *   Second True Latitude (Beta): \t60N // >  :P_BET = 60.0; // double\r\n     *   Central Longitude (Gamma): \t100W //>  :XCENT = -100.0; // double\r\n     *   Projection Origin: \t(100W, 40N) //>  :YCENT = 40.0; // double\r\n     *\r\n     */\r\n    // Internalize raf and ncfile\r\n    super.open(raf, ncfile, cancelTask);\r\n\r\n    // set raf to big endian and start at the beginning\r\n    raf.order(RandomAccessFile.BIG_ENDIAN);\r\n    raf.seek(0);\r\n\r\n    // Read first line of UAM-IV header\r\n    raf.skipBytes(4); // Skip record pad\r\n    String name = raf.readString(40); // read 40 name\r\n    String note = raf.readString(240);\r\n    int itzone = raf.readInt(); // Read the time zone\r\n    int nspec = raf.readInt(); // Read number of species\r\n    int bdate = raf.readInt(); // get file start date\r\n    float btime = raf.readFloat(); // get file start time\r\n    int edate = raf.readInt(); // get file end date\r\n    float etime = raf.readFloat(); // get file end time\r\n    int btimei = (int) btime; // convert btime to an integer\r\n\r\n    // CAMx times are sometimes provided as HH or HHMM.\r\n    // IOAPI times are always provided as HHMMSS.\r\n    // CAMx times less than 100 are HH and should be\r\n    // multipled by 100 to get HHMM.  CAMx times less\r\n    // 10000 are HHMM and should be multipled by 100\r\n    // to get HHMMSS.\r\n    if (btimei < 100) btimei = btimei * 100;\r\n    if (btimei < 10000) btimei = btimei * 100;\r\n\r\n    /*\r\n    * Dates are YYJJJ and are heuristically converted\r\n    * to YYYYJJJ based on the following assumption:\r\n    * YY < 70 are 2000\r\n    * YY >= 70 are 1900\r\n    *\r\n    */\r\n    if (bdate < 70000) {\r\n      edate = edate + 2000000;\r\n      bdate = bdate + 2000000;\r\n    } else {\r\n      edate = edate + 1900000;\r\n      bdate = bdate + 1900000;\r\n    }\r\n\r\n    raf.skipBytes(4); //Skip record pad\r\n\r\n    // Read second line of UAM-IV header\r\n    raf.skipBytes(4); //Skip record pad\r\n    float plon = raf.readFloat(); // get polar longitude\r\n    float plat = raf.readFloat(); // get polar latitude\r\n    int iutm = raf.readInt(); // get utm\r\n    float xorg = raf.readFloat(); // get x origin in meters\r\n    float yorg = raf.readFloat(); // get y origin in meters\r\n    float delx = raf.readFloat(); // get x cell size in meters\r\n    float dely = raf.readFloat(); // get y cell size in meters\r\n    int nx = raf.readInt(); // get number of columns\r\n    int ny = raf.readInt(); // get number of rows\r\n    int nz = raf.readInt(); // get number of layers\r\n    // get projection number\r\n    //    (0: lat-lon;\r\n    //     1: Universal Transverse Mercator;\r\n    //     2: Lambert Conic Conformal;\r\n    //     3: Polar stereographic)\r\n    // These translate to IOAPI GDTYP3D values 1, 5, 2, and 6 respectively\r\n    int iproj = raf.readInt(); \r\n    int istag = raf.readInt(); // Read stagger indicator\r\n    float tlat1 = raf.readFloat(); // Read true latitude 1\r\n    float tlat2 = raf.readFloat(); // Read true latitude 2\r\n    raf.skipBytes(4); //Skip 1 dummies\r\n    raf.skipBytes(4); //Skip record pad\r\n\r\n    // Read third line of UAM-IV header\r\n    raf.skipBytes(4); //Skip record pad\r\n    raf.skipBytes(8); //Skip 2 dummies\r\n    int nx2 = raf.readInt(); // duplicate number of columns\r\n    int ny2 = raf.readInt(); // duplicate number of rows\r\n    raf.skipBytes(8); //Skip 2 dummies    \r\n    nz = Math.max(nz, 1); // number of layers; Emissions files occasionally report 0 layers\r\n    /*\r\n     * 1) Read each species name\r\n     * 2) remove white space from the name\r\n     * 3) store the names\r\n     * 4) internalize them\r\n     */\r\n    int count = 0;\r\n    String[] spc_names = new String[nspec];\r\n    while (count < nspec) {\r\n      String spc = raf.readString(40); // 1) read species name\r\n      spc_names[count++] = spc.replace(\" \", \"\"); // 2&3) store name without whitespace\r\n    }\r\n    this.species_names = spc_names; // 4) internalize names\r\n    raf.skipBytes(4); // Skip record pad\r\n\r\n    // Note this position; it is the start of the data block\r\n    this.data_start = raf.getFilePointer();\r\n\r\n    // Note the number of float equivalents (4 byte chunks) in data block\r\n    int data_length_float_equivalents = ((int) raf.length() - (int) data_start) / 4;\r\n\r\n    // Store 2D value size\r\n    this.n2dvals = nx * ny;\r\n\r\n    // Store 3D value size\r\n    this.n3dvals = nx * ny * nz;\r\n\r\n    // Store 2D binary data block size: include values (nx*ny), \r\n    // species name (10), a dummy (1) and 2 record pads\r\n    int spc_2D_block = nx * ny + 10 + 2 + 1;\r\n\r\n    // Store 3D binary data block size\r\n    this.spc_3D_block = spc_2D_block * nz;\r\n\r\n    // Store whole data block size; includes date (6)\r\n    this.data_block = this.spc_3D_block * nspec + 6;\r\n\r\n        int ntimes = data_length_float_equivalents / this.data_block;\r\n\r\n\r\n    // Add dimensions based on header values\r\n    ncfile.addDimension(null, new Dimension(\"TSTEP\", ntimes, true));\r\n    ncfile.addDimension(null, new Dimension(\"LAY\", nz, true));\r\n    ncfile.addDimension(null, new Dimension(\"ROW\", ny, true));\r\n    ncfile.addDimension(null, new Dimension(\"COL\", nx, true));\r\n\r\n    // Force sync of dimensions\r\n    ncfile.finish();\r\n    count = 0;\r\n\r\n    /*\r\n    * For each species, create a variable with long_name,\r\n    * and var_desc, and units.  long_name and var_desc are\r\n    * simply the species name.  units is heuristically\r\n    * determined from the name\r\n    */\r\n    HashSet<String> AeroSpcs = new HashSet<>(Arrays.asList( \"PSO4\", \"PNO3\", \"PNH4\", \"PH2O\", \"SOPA\", \"SOPB\",  \"NA\", \"PCL\", \"POA\", \"PEC\", \"FPRM\", \"FCRS\", \"CPRM\", \"CCRS\"));\r\n    HashSet<String> LULC = new HashSet<>(Arrays.asList(\"WATER\", \"ICE\", \"LAKE\", \"ENEEDL\", \"EBROAD\", \"DNEEDL\", \"DBROAD\", \"TBROAD\", \"DDECID\", \"ESHRUB\", \"DSHRUB\", \"TSHRUB\", \"SGRASS\", \"LGRASS\", \"CROPS\", \"RICE\", \"SUGAR\", \"MAIZE\", \"COTTON\", \"ICROPS\", \"URBAN\", \"TUNDRA\", \"SWAMP\", \"DESERT\", \"MWOOD\", \"TFOREST\"));\r\n    \r\n    while (count < nspec) {\r\n      String spc = spc_names[count++];\r\n      Variable temp = ncfile.addVariable(null, spc, DataType.FLOAT, \"TSTEP LAY ROW COL\");\r\n      if (spc.equals(WINDX) || spc.equals(WINDY) ||\r\n              spc.equals(SPEED)) {\r\n        temp.addAttribute(new Attribute(CDM.UNITS, \"m/s\"));\r\n      } else if (spc.equals(VERTDIFF)) {\r\n        temp.addAttribute(new Attribute(CDM.UNITS, \"m**2/s\"));\r\n      } else if (spc.equals(TEMP)) {\r\n        temp.addAttribute(new Attribute(CDM.UNITS, \"K\"));\r\n      } else if (spc.equals(PRESS)) {\r\n        temp.addAttribute(new Attribute(CDM.UNITS, \"hPa\"));\r\n      } else if (spc.equals(HEIGHT) || spc.equals(PBL)) {\r\n        temp.addAttribute(new Attribute(CDM.UNITS, \"m\"));\r\n      } else if (spc.equals(CLDWATER) || spc.equals(PRECIP) || spc.equals(RAIN)) {\r\n        temp.addAttribute(new Attribute(CDM.UNITS, \"g/m**3\"));\r\n      } else if (spc.equals(CLDOD) || spc.equals(\"CLOUDOD\")) {\r\n        temp.addAttribute(new Attribute(CDM.UNITS, \"none\"));\r\n      } else if (spc.equals(\"SNOWCOVER\")) {\r\n        temp.addAttribute(new Attribute(CDM.UNITS, \"yes/no\"));        \r\n      } else if (spc.startsWith(\"SOA\") || AeroSpcs.contains(spc)) {\r\n        if (name.equals(EMISSIONS)) {\r\n          temp.addAttribute(new Attribute(CDM.UNITS, \"g/time\"));\r\n        } else {\r\n          temp.addAttribute(new Attribute(CDM.UNITS, \"ug/m**3\"));\r\n        }\r\n      } else if (LULC.contains(spc)) {\r\n          temp.addAttribute(new Attribute(CDM.UNITS, \"fraction\"));\r\n      } else if (spc.lastIndexOf(\"_\") > -1) {\r\n        String tmpunit = spc.substring(spc.lastIndexOf(\"_\") + 1);\r\n        tmpunit = tmpunit.trim();\r\n        switch (tmpunit) {\r\n          case \"M2pS\":\r\n            tmpunit = \"m**2/s\";\r\n            break;\r\n          case \"MpS\":\r\n            tmpunit = \"m/s\";\r\n            break;\r\n          case \"PPM\":\r\n            tmpunit = \"ppm\";\r\n            break;\r\n          case \"MB\":\r\n            tmpunit = \"millibar\";\r\n            break;\r\n          case \"GpM3\":\r\n            tmpunit = \"g/m**3\";\r\n            break;\r\n          case \"M\":\r\n            tmpunit = \"m\";\r\n            break;\r\n        }\r\n        temp.addAttribute(new Attribute(CDM.UNITS, tmpunit));\r\n      } else {\r\n        if (name.equals(EMISSIONS)) {\r\n          temp.addAttribute(new Attribute(CDM.UNITS, \"mol/time\"));\r\n        } else {\r\n          temp.addAttribute(new Attribute(CDM.UNITS, \"ppm\"));\r\n        }\r\n      }\r\n      temp.addAttribute(new Attribute(CDM.LONG_NAME, spc));\r\n      temp.addAttribute(new Attribute(\"var_desc\", spc));\r\n    }\r\n\r\n    /*\r\n    * Create 1...n array of \"sigma\" values\r\n    */\r\n    double[] sigma = new double[nz + 1];\r\n    count = 0;\r\n    while (count < nz + 1) {\r\n      sigma[count++] = count;\r\n    }\r\n    int[] size = new int[1];\r\n    size[0] = nz + 1;\r\n    Array sigma_arr = Array.factory(DataType.DOUBLE, size, sigma);\r\n\r\n    /*\r\n    * Add meta-data according to the IOAPI conventions\r\n    * http://www.baronams.com/products/ioapi\r\n    */\r\n    ncfile.addAttribute(null, new Attribute(\"VGLVLS\", sigma_arr));\r\n    ncfile.addAttribute(null, new Attribute(\"SDATE\", bdate));\r\n    ncfile.addAttribute(null, new Attribute(\"STIME\", btimei));\r\n    ncfile.addAttribute(null, new Attribute(\"TSTEP\", 10000));\r\n    ncfile.addAttribute(null, new Attribute(\"NSTEPS\", ntimes));\r\n    ncfile.addAttribute(null, new Attribute(\"NLAYS\", nz));\r\n    ncfile.addAttribute(null, new Attribute(\"NROWS\", ny));\r\n    ncfile.addAttribute(null, new Attribute(\"NCOLS\", nx));\r\n    ncfile.addAttribute(null, new Attribute(\"XORIG\", (double) xorg));\r\n    ncfile.addAttribute(null, new Attribute(\"YORIG\", (double) yorg));\r\n    ncfile.addAttribute(null, new Attribute(\"XCELL\", (double) delx));\r\n    ncfile.addAttribute(null, new Attribute(\"YCELL\", (double) dely));\r\n\r\n    /*\r\n     * IOAPI Projection parameters are provided by a colocated camxproj.txt file;\r\n     *\r\n     * to do:\r\n     * 1) needs earth radius\r\n     * 2) needs better error checking\r\n    */\r\n    Integer gdtyp = 2;\r\n    Double p_alp = 20.;\r\n    Double p_bet = 60.;\r\n    Double p_gam = 0.;\r\n    Double xcent = -95.;\r\n    Double ycent = 25.;\r\n    if (!((iproj == 0) && (tlat1 == 0) && (tlat2 == 0) && (plon == 0) && (plat == 0))) {\r\n      xcent = (double) plon;\r\n      ycent = (double) plat;\r\n      if (iproj == 0) {\r\n        // Lat-Lon (iproj=0) has no additional information\r\n        gdtyp = 1;\r\n      } else if (iproj == 1){\r\n        // UTM uses only iutm \r\n        gdtyp = 5;\r\n        p_alp = (double) iutm;\r\n      } else if (iproj == 2){\r\n        gdtyp = 2;\r\n        p_alp = (double) tlat1;\r\n        p_bet = (double) tlat2;\r\n        p_gam = (double) plon;\r\n      } else if (iproj == 3){\r\n        gdtyp = 6;\r\n        if (plat == 90){\r\n          p_alp = 1.;\r\n        } else if (plat == -90) {\r\n          p_alp = -1.;\r\n        }\r\n        p_bet = (double) tlat1;\r\n        p_gam = (double) plon;\r\n      } else {\r\n        gdtyp = 2;\r\n        p_alp = 20.;\r\n        p_bet = 60.;\r\n        p_gam = 0.;\r\n        xcent = -95.;\r\n        ycent = 25.;\r\n      }\r\n    }\r\n\r\n    String thisLine;\r\n    String projpath = raf.getLocation();\r\n    Boolean lgdtyp = false;\r\n    Boolean lp_alp = false;\r\n    Boolean lp_bet = false;\r\n    Boolean lp_gam = false;\r\n    Boolean lxcent = false;\r\n    Boolean lycent = false;\r\n    int lastIndex = projpath.lastIndexOf(File.separator);\r\n    if (lastIndex <= 0)\r\n      lastIndex = projpath.lastIndexOf('/');\r\n    if (lastIndex > 0)\r\n      projpath = projpath.substring(0, lastIndex);\r\n    projpath = projpath + File.separator + \"camxproj.txt\";\r\n    File paramFile = new File(projpath);\r\n\r\n    if (paramFile.exists()) {\r\n      try (BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(paramFile), CDM.UTF8))) {\r\n        while ((thisLine = br.readLine()) != null) {\r\n          if (thisLine.length() == 0) continue;\r\n          if (thisLine.charAt(0) == '#') continue;\r\n          String[] key_value = thisLine.split(\"=\");\r\n          switch (key_value[0]) {\r\n            case \"GDTYP\":\r\n              gdtyp = Integer.parseInt(key_value[1]);\r\n              lgdtyp = true;\r\n              break;\r\n            case \"P_ALP\":\r\n              p_alp = Double.parseDouble(key_value[1]);\r\n              lp_alp = true;\r\n              break;\r\n            case \"P_BET\":\r\n              p_bet = Double.parseDouble(key_value[1]);\r\n              lp_bet = true;\r\n              break;\r\n            case \"P_GAM\":\r\n              p_gam = Double.parseDouble(key_value[1]);\r\n              lp_gam = true;\r\n              break;\r\n            case \"YCENT\":\r\n              ycent = Double.parseDouble(key_value[1]);\r\n              lycent = true;\r\n              break;\r\n            case \"XCENT\":\r\n              xcent = Double.parseDouble(key_value[1]);\r\n              lxcent = true;\r\n              break;\r\n          }\r\n        }\r\n      }\r\n      if (!lgdtyp) log.warn(\"GDTYP not found; using \" + gdtyp.toString());\r\n      if (!lp_alp) log.warn(\"P_ALP not found; using \" + p_alp.toString());\r\n      if (!lp_bet) log.warn(\"P_BET not found; using \" + p_bet.toString());\r\n      if (!lp_gam) log.warn(\"P_GAM not found; using \" + p_gam.toString());\r\n      if (!lxcent) log.warn(\"XCENT not found; using \" + xcent.toString());\r\n      if (!lycent) log.warn(\"YCENT not found; using \" + ycent.toString());\r\n\r\n    } else {\r\n      if (log.isDebugEnabled()) log.debug(\"UAMIVServiceProvider: adding projection file\");\r\n      try (FileOutputStream out = new FileOutputStream(paramFile)) {\r\n        OutputStreamWriter fout = new OutputStreamWriter(out, CDM.utf8Charset);\r\n        BufferedWriter bw = new BufferedWriter(fout);\r\n\r\n        bw.write(\"# Projection parameters are based on IOAPI.  For details, see www.baronams.com/products/ioapi/GRIDS.html\");\r\n        bw.newLine();\r\n        bw.write(\"GDTYP=\");\r\n        bw.write(gdtyp.toString());\r\n        bw.newLine();\r\n        bw.write(\"P_ALP=\");\r\n        bw.write(p_alp.toString());\r\n        bw.newLine();\r\n        bw.write(\"P_BET=\");\r\n        bw.write(p_bet.toString());\r\n        bw.newLine();\r\n        bw.write(\"P_GAM=\");\r\n        bw.write(p_gam.toString());\r\n        bw.newLine();\r\n        bw.write(\"XCENT=\");\r\n        bw.write(xcent.toString());\r\n        bw.newLine();\r\n        bw.write(\"YCENT=\");\r\n        bw.write(ycent.toString());\r\n        bw.newLine();\r\n        bw.flush();\r\n        bw.close();\r\n      }\r\n    }\r\n\r\n    ncfile.addAttribute(null, new Attribute(\"GDTYP\", gdtyp));\r\n    ncfile.addAttribute(null, new Attribute(\"P_ALP\", p_alp));\r\n    ncfile.addAttribute(null, new Attribute(\"P_BET\", p_bet));\r\n    ncfile.addAttribute(null, new Attribute(\"P_GAM\", p_gam));\r\n    ncfile.addAttribute(null, new Attribute(\"XCENT\", xcent));\r\n    ncfile.addAttribute(null, new Attribute(\"YCENT\", ycent));\r\n  }",
        "variable": "ntimes",
        "reference": "the number of times",
        "explanation_by_ours": "Number of times on the file",
        "explanation_by_baseline": "2D data block size"
    },
    {
        "id": 1269,
        "method": "public ucar.ma2.Array readData(Variable v2, Section wantSection) throws IOException, InvalidRangeException {\r\n    /*\r\n     * <b>readData</b> seeks and reads the data for each variable.  The variable\r\n     * data format is detailed in the CAMx User's guide and summarized here.\r\n     * \r\n     * For each time:\r\n     *   ibdate,btime,iedate,etime\r\n     *   Loop from 1 to nspec species:\r\n     *     ione,mspec(l),((val(i,j,l),i=1,nx),j=1,ny)\r\n     *\r\n     *\r\n     * ione - Dummy variable = 1\r\n     * nspec - Number of species on file\r\n     * ibdate - Beginning date (YYJJJ)\r\n     * btime - Beginning hour (HHMM)\r\n     * iedate - Ending date (YYJJJ)\r\n     * etime - Ending hour (HHMM)\r\n     * mspec - Species names for nspec species (character*4(10,nspec) array)\r\n     * val - Species l, layer k initial concentrations (ppm for gases, ug/m3 for aerosols)\r\n     *       for nx grid columns and ny grid rows\r\n     *\r\n     */\r\n    // CAMx UAM-IV Files are all big endian\r\n    raf.order(RandomAccessFile.BIG_ENDIAN);\r\n\r\n    // Prepare an array for binary data\r\n    int size = (int) v2.getSize();\r\n    float[] arr = new float[size];\r\n\r\n    // Move to data block of file\r\n    raf.seek(this.data_start);\r\n\r\n    /*\r\n     * First record is stime,sdate,etime,edate\r\n     * We are skipping the data, but checking\r\n     * the consistency of the Fortran \"unformatted\"\r\n     * data record\r\n    */\r\n    int pad1 = raf.readInt();\r\n    raf.skipBytes(16);\r\n    int pad2 = raf.readInt();\r\n    if (pad1 != pad2) {\r\n      throw new IOException(\"Asymmetric fortran buffer values: 1\");\r\n    }\r\n\r\n    // Find species name/id associated with this variable\r\n    int spcid = -1;\r\n    String spc = \"\";\r\n    while (!spc.equals(v2.getShortName())) {\r\n      spc = this.species_names[++spcid];\r\n    }\r\n\r\n    /*\r\n    * Skip data associated with species that are prior\r\n    * in the data block\r\n    */\r\n    raf.skipBytes(this.spc_3D_block * spcid * 4);\r\n\r\n        int count = 0;\r\n\r\n\r\n    while (count < size) {\r\n\r\n      /*\r\n      * Read species name and store the initial record pad.\r\n      * Note: it might be good to compare\r\n      *       spc string to variable.getShortName\r\n      */\r\n      if (count == 0) {\r\n        pad1 = raf.readInt();\r\n        int ione = raf.readInt();\r\n        spc = raf.readString(40);\r\n      }\r\n\r\n      /*\r\n      * If we have read a 2D slice, read the final record pad\r\n      * and compare to initial record pad.  If everything is okay, proceed.\r\n      * (1) skip to next 2D slice\r\n      * (2) store initial pad\r\n      * (3) read spc name\r\n      * Note: it might be good to compare\r\n      *       spc string to variable.getShortName\r\n      */\r\n      if ((count != 0) && ((count % this.n2dvals) == 0)) {\r\n        pad2 = raf.readInt();\r\n        if (pad1 != pad2) {\r\n          //System.out.println(pad1);\r\n          //System.out.println(pad2);\r\n          throw new IOException(\"Asymmetric fortran buffer values: 2\");\r\n        }\r\n        if ((count % this.n3dvals) == 0) {\r\n          raf.skipBytes((this.data_block - this.spc_3D_block) * 4);\r\n        }\r\n        pad1 = raf.readInt();\r\n        int ione = raf.readInt();\r\n        spc = raf.readString(40);\r\n      }\r\n\r\n      /*\r\n      * Attempt to read a Float from the file\r\n      */\r\n      try {\r\n        arr[count++] = raf.readFloat();\r\n      } catch (java.lang.ArrayIndexOutOfBoundsException io) {\r\n        throw new IOException(io.getMessage());\r\n      }\r\n    }\r\n\r\n    // Convert java float[] to ma2.Array\r\n    Array data = Array.factory(DataType.FLOAT, v2.getShape(), arr);\r\n\r\n    // Subset the data based on the wantSection and return a 4D variable\r\n    return data.sectionNoReduce(wantSection.getRanges());\r\n  }",
        "variable": "count",
        "reference": "the count for indexing arr",
        "explanation_by_ours": "The number of variables to read.",
        "explanation_by_baseline": "=( int )"
    },
    {
        "id": 1274,
        "method": "private Object readData(H5header.Vinfo vinfo, Variable v, Layout layout, DataType dataType, int[] shape,\n                          Object fillValue, int endian) throws java.io.IOException, InvalidRangeException {\n\n    H5header.TypeInfo typeInfo = vinfo.typeInfo;\n\n    // special processing\n    if (typeInfo.hdfType == 2) { // time\n      Object data = IospHelper.readDataFill(raf, layout, dataType, fillValue, endian, true);\n      Array timeArray = Array.factory(dataType, shape, data);\n\n            String[] stringData = new String[(int) timeArray.getSize()];\n      int count = 0;\n      while (timeArray.hasNext()) {\n        long time = timeArray.nextLong();\n        stringData[count++] = CalendarDate.of(time).toString();\n      }\n      return Array.factory(DataType.STRING, shape, stringData);\n    }\n\n    if (typeInfo.hdfType == 8) { // enum\n      Object data = IospHelper.readDataFill(raf, layout, dataType, fillValue, endian);\n      return Array.factory(dataType, shape, data);\n    }\n\n    if (typeInfo.isVlen) { // vlen (not string)\n      DataType readType = dataType;\n      if (typeInfo.base.hdfType == 7) // reference\n        readType = DataType.LONG;\n\n      // general case is to read an array of vlen objects\n      // each vlen generates an Array - so return ArrayObject of Array\n      // boolean scalar = false; // layout.getTotalNelems() == 1; // if scalar, return just the len Array // remove 12/25/10 jcaron\n      Array[] data = new Array[(int) layout.getTotalNelems()];\n      int count = 0;\n      while (layout.hasNext()) {\n        Layout.Chunk chunk = layout.next();\n        if (chunk == null) continue;\n        for (int i = 0; i < chunk.getNelems(); i++) {\n          long address = chunk.getSrcPos() + layout.getElemSize() * i;\n          Array vlenArray = headerParser.getHeapDataArray(address, readType, endian);\n          data[count++] = (typeInfo.base.hdfType == 7) ? convertReference(vlenArray) : vlenArray;\n        }\n      }\n      int prefixrank = 0;\n      for (int i=0;i<shape.length;i++) { // find leftmost vlen\n        if (shape[i] < 0) {\n          prefixrank = i;\n          break;\n        }\n      }\n      Array result;\n      if(prefixrank == 0) // if scalar, return just the singleton vlen array\n        result = data[0];\n       else {\n        int[] newshape = new int[prefixrank];\n        System.arraycopy(shape, 0, newshape, 0, prefixrank);\n        // result = Array.makeObjectArray(readType, data[0].getClass(), newshape, data);\n        result = Array.makeVlenArray(newshape, data);\n      }\n\n      /*\n      else if (prefixrank == 1) // LOOK cant these two cases be combines - just differ in shape ??\n        result = Array.makeObjectArray(readType, data[0].getClass(), new int[]{count}, data);\n     else {  // LOOK cant these two cases be combines - just differ in shape ??\n          // Otherwise create and fill in an n-dimensional Array Of Arrays\n          int[] newshape = new int[prefixrank];\n          System.arraycopy(shape, 0, newshape, 0, prefixrank);\n          Array ndimarray = Array.makeObjectArray(readType, Array.class, newshape, null);\n          // Transfer the elements of data into the n-dim arrays\n          IndexIterator iter = ndimarray.getIndexIterator();\n          for(int i = 0;iter.hasNext();i++) {\n              iter.setObjectNext(data[i]);\n          }\n          result = ndimarray;\n      } */\n      //return (scalar) ? data[0] : new ArrayObject(data[0].getClass(), shape, data);\n      //return new ArrayObject(data[0].getClass(), shape, data);\n      return result;\n    }\n\n    if (dataType == DataType.STRUCTURE) {  // LOOK what about subset ?\n      int recsize = layout.getElemSize();\n      long size = recsize * layout.getTotalNelems();\n      byte[] byteArray = new byte[(int)size];\n      while (layout.hasNext()) {\n        Layout.Chunk chunk = layout.next();\n        if (chunk == null) continue;\n        if (debugStructure)\n          System.out.println(\" readStructure \" + v.getFullName() + \" chunk= \" + chunk + \" index.getElemSize= \" + layout.getElemSize());\n        // copy bytes directly into the underlying byte[] LOOK : assumes contiguous layout ??\n        raf.seek(chunk.getSrcPos());\n        raf.readFully(byteArray, (int) chunk.getDestElem() * recsize, chunk.getNelems() * recsize);\n      }\n\n      // place data into an ArrayStructureBB\n      return convertStructure((Structure) v, layout, shape, byteArray); // LOOK\n    }\n\n    // normal case\n    return readDataPrimitive(layout, dataType, shape, fillValue, endian, true);\n  }",
        "variable": "stringData",
        "reference": "an ISO Date String",
        "explanation_by_ours": "string data to read from the HDF file",
        "explanation_by_baseline": "a String array//"
    },
    {
        "id": 1298,
        "method": "private InputStream getInputStream(String resourceName) throws IOException {\r\n\r\n        ClassLoader cl = GempakParameterTable.class.getClassLoader();\r\n    InputStream s = cl.getResourceAsStream(resourceName);\r\n    if (s != null) {\r\n      return s;\r\n    }\r\n\r\n    //Try the file system\r\n    File f = new File(resourceName);\r\n    if (f.exists()) {\r\n        s = new FileInputStream(f);\r\n    }\r\n    if (s != null) {\r\n      return s;\r\n    }\r\n\r\n    //Try it as a url\r\n    Matcher m = Pattern.compile(\" \").matcher(resourceName);\r\n    String encodedUrl = m.replaceAll(\"%20\");\r\n    URL dataUrl = new URL(encodedUrl);\r\n    URLConnection connection = dataUrl.openConnection();\r\n    return connection.getInputStream();\r\n  }",
        "variable": "cl",
        "reference": "The class loader to get resource",
        "explanation_by_ours": "The class loader to use",
        "explanation_by_baseline": "s = new FileInputStream(resource"
    },
    {
        "id": 1309,
        "method": "private static String formatDouble( double d, int min_sigFigs, int fixed_decimals) {\r\n    String s = java.lang.Double.toString( d);\r\n\r\n    if (java.lang.Double.isNaN(d)) return s;\r\n\r\n    // extract the sign\r\n    String sign;\r\n    String unsigned;\r\n    if ( s.startsWith( \"-\" ) || s.startsWith( \"+\" ) ) {\r\n      sign = s.substring( 0, 1 );\r\n      unsigned = s.substring( 1 );\r\n    } else {\r\n      sign = \"\";\r\n      unsigned = s;\r\n    }\r\n\r\n    // deal with exponential notation\r\n    String mantissa;\r\n    String exponent;\r\n    int eInd = unsigned.indexOf( 'E' );\r\n    if ( eInd == -1 )\r\n      eInd = unsigned.indexOf( 'e' );\r\n    if ( eInd == -1 ) {\r\n      mantissa = unsigned;\r\n      exponent = \"\";\r\n    } else {\r\n      mantissa = unsigned.substring( 0, eInd );\r\n      exponent = unsigned.substring( eInd );\r\n    }\r\n\r\n    // deal with decimal point\r\n    StringBuffer number, fraction;\r\n    int dotInd = mantissa.indexOf( '.' );\r\n    if ( dotInd == -1 ) {\r\n      number = new StringBuffer( mantissa );\r\n      fraction = new StringBuffer( \"\" );\r\n    } else {\r\n      number = new StringBuffer( mantissa.substring( 0, dotInd ) );\r\n      fraction = new StringBuffer( mantissa.substring( dotInd + 1 ) );\r\n    }\r\n\r\n        int numFigs = number.length();\r\n    int fracFigs = fraction.length();\r\n\r\n    // can do either fixed_decimals or min_sigFigs\r\n    if (fixed_decimals != -1) {\r\n      if (fixed_decimals == 0) {\r\n        fraction.setLength( 0 );\r\n      } else if (fixed_decimals > fracFigs) {\r\n        int want = fixed_decimals - fracFigs;\r\n        for (int i=0; i<want; i++)\r\n          fraction.append(\"0\");\r\n      } else if (fixed_decimals < fracFigs) {\r\n        int chop = fracFigs - fixed_decimals;   // LOOK should round !!\r\n        fraction.setLength( fraction.length() - chop );\r\n      }\r\n      fracFigs = fixed_decimals;\r\n\r\n    } else {\r\n            // Don't count leading zeros in the fraction, if no number\r\n      if ( ( numFigs == 0 || number.toString().equals( \"0\" ) ) && fracFigs > 0 ) {\r\n        numFigs = 0;\r\n        number = new StringBuffer( \"\" );\r\n        for ( int i = 0; i < fraction.length(); ++i ) {\r\n          if ( fraction.charAt( i ) != '0' )\r\n            break;\r\n          --fracFigs;\r\n        }\r\n      }\r\n        // Don't count trailing zeroes in the number if no fraction\r\n      if ( ( fracFigs == 0) && numFigs > 0 ) {\r\n        for ( int i=number.length()-1; i > 0; i-- ) {\r\n          if ( number.charAt( i ) != '0' )\r\n            break;\r\n          --numFigs;\r\n        }\r\n      }\r\n        // deal with min sig figures\r\n      int sigFigs = numFigs + fracFigs;\r\n      if (sigFigs > min_sigFigs) {\r\n          // Want fewer figures in the fraction; chop (should round? )\r\n        int chop = Math.min(sigFigs - min_sigFigs, fracFigs);\r\n        fraction.setLength( fraction.length() - chop );\r\n        fracFigs -= chop;\r\n      }\r\n    }\r\n\r\n\r\n    /*int sigFigs = numFigs + fracFigs;\r\n    if (sigFigs > max_sigFigs) {\r\n\r\n      if (numFigs >= max_sigFigs) {  // enough sig figs in just the number part\r\n        fraction.setLength( 0 );\r\n        for ( int i=max_sigFigs; i<numFigs; ++i )\r\n          number.setCharAt( i, '0' );  // should round?\r\n      } else {\r\n\r\n        // Want fewer figures in the fraction; chop (should round? )\r\n        int chop = sigFigs - max_sigFigs;\r\n        fraction.setLength( fraction.length() - chop );\r\n      }\r\n    }\r\n\r\n\r\n    /* may want a fixed decimal place\r\n    if (dec_places != -1) {\r\n\r\n      if (dec_places == 0) {\r\n        fraction.setLength( 0 );\r\n        fracFigs = 0;\r\n      } else if (dec_places > fracFigs) {\r\n        int want = dec_places - fracFigs;\r\n        for (int i=0; i<want; i++)\r\n          fraction.append(\"0\");\r\n      } else if (dec_places < fracFigs) {\r\n        int chop = fracFigs - dec_places;\r\n        fraction.setLength( fraction.length() - chop );\r\n        fracFigs = dec_places;\r\n      }\r\n\r\n    } */\r\n\r\n    if ( fraction.length() == 0 )\r\n      return sign + number + exponent;\r\n    else\r\n      return sign + number + \".\" + fraction + exponent;\r\n  }\r\n\r\n}",
        "variable": "numFigs",
        "reference": "number of figures",
        "explanation_by_ours": "the number of significant figures to use",
        "explanation_by_baseline": "int dec_places ="
    },
    {
        "id": 1310,
        "method": "private static String formatDouble( double d, int min_sigFigs, int fixed_decimals) {\r\n    String s = java.lang.Double.toString( d);\r\n\r\n    if (java.lang.Double.isNaN(d)) return s;\r\n\r\n    // extract the sign\r\n    String sign;\r\n    String unsigned;\r\n    if ( s.startsWith( \"-\" ) || s.startsWith( \"+\" ) ) {\r\n      sign = s.substring( 0, 1 );\r\n      unsigned = s.substring( 1 );\r\n    } else {\r\n      sign = \"\";\r\n      unsigned = s;\r\n    }\r\n\r\n    // deal with exponential notation\r\n    String mantissa;\r\n    String exponent;\r\n    int eInd = unsigned.indexOf( 'E' );\r\n    if ( eInd == -1 )\r\n      eInd = unsigned.indexOf( 'e' );\r\n    if ( eInd == -1 ) {\r\n      mantissa = unsigned;\r\n      exponent = \"\";\r\n    } else {\r\n      mantissa = unsigned.substring( 0, eInd );\r\n      exponent = unsigned.substring( eInd );\r\n    }\r\n\r\n    // deal with decimal point\r\n    StringBuffer number, fraction;\r\n    int dotInd = mantissa.indexOf( '.' );\r\n    if ( dotInd == -1 ) {\r\n      number = new StringBuffer( mantissa );\r\n      fraction = new StringBuffer( \"\" );\r\n    } else {\r\n      number = new StringBuffer( mantissa.substring( 0, dotInd ) );\r\n      fraction = new StringBuffer( mantissa.substring( dotInd + 1 ) );\r\n    }\r\n\r\n    // number of significant figures\r\n    int numFigs = number.length();\r\n    int fracFigs = fraction.length();\r\n\r\n    // can do either fixed_decimals or min_sigFigs\r\n    if (fixed_decimals != -1) {\r\n      if (fixed_decimals == 0) {\r\n        fraction.setLength( 0 );\r\n      } else if (fixed_decimals > fracFigs) {\r\n        int want = fixed_decimals - fracFigs;\r\n        for (int i=0; i<want; i++)\r\n          fraction.append(\"0\");\r\n      } else if (fixed_decimals < fracFigs) {\r\n        int chop = fracFigs - fixed_decimals;   // LOOK should round !!\r\n        fraction.setLength( fraction.length() - chop );\r\n      }\r\n      fracFigs = fixed_decimals;\r\n\r\n    } else {\r\n            // Don't count leading zeros in the fraction, if no number\r\n      if ( ( numFigs == 0 || number.toString().equals( \"0\" ) ) && fracFigs > 0 ) {\r\n        numFigs = 0;\r\n        number = new StringBuffer( \"\" );\r\n        for ( int i = 0; i < fraction.length(); ++i ) {\r\n          if ( fraction.charAt( i ) != '0' )\r\n            break;\r\n          --fracFigs;\r\n        }\r\n      }\r\n        // Don't count trailing zeroes in the number if no fraction\r\n      if ( ( fracFigs == 0) && numFigs > 0 ) {\r\n        for ( int i=number.length()-1; i > 0; i-- ) {\r\n          if ( number.charAt( i ) != '0' )\r\n            break;\r\n          --numFigs;\r\n        }\r\n      }\r\n              int sigFigs = numFigs + fracFigs;\r\n      if (sigFigs > min_sigFigs) {\r\n          // Want fewer figures in the fraction; chop (should round? )\r\n        int chop = Math.min(sigFigs - min_sigFigs, fracFigs);\r\n        fraction.setLength( fraction.length() - chop );\r\n        fracFigs -= chop;\r\n      }\r\n    }\r\n\r\n\r\n    /*int sigFigs = numFigs + fracFigs;\r\n    if (sigFigs > max_sigFigs) {\r\n\r\n      if (numFigs >= max_sigFigs) {  // enough sig figs in just the number part\r\n        fraction.setLength( 0 );\r\n        for ( int i=max_sigFigs; i<numFigs; ++i )\r\n          number.setCharAt( i, '0' );  // should round?\r\n      } else {\r\n\r\n        // Want fewer figures in the fraction; chop (should round? )\r\n        int chop = sigFigs - max_sigFigs;\r\n        fraction.setLength( fraction.length() - chop );\r\n      }\r\n    }\r\n\r\n\r\n    /* may want a fixed decimal place\r\n    if (dec_places != -1) {\r\n\r\n      if (dec_places == 0) {\r\n        fraction.setLength( 0 );\r\n        fracFigs = 0;\r\n      } else if (dec_places > fracFigs) {\r\n        int want = dec_places - fracFigs;\r\n        for (int i=0; i<want; i++)\r\n          fraction.append(\"0\");\r\n      } else if (dec_places < fracFigs) {\r\n        int chop = fracFigs - dec_places;\r\n        fraction.setLength( fraction.length() - chop );\r\n        fracFigs = dec_places;\r\n      }\r\n\r\n    } */\r\n\r\n    if ( fraction.length() == 0 )\r\n      return sign + number + exponent;\r\n    else\r\n      return sign + number + \".\" + fraction + exponent;\r\n  }\r\n\r\n}",
        "variable": "sigFigs",
        "reference": "sig figures",
        "explanation_by_ours": "the minimum number of significant figures",
        "explanation_by_baseline": "and max sig figures"
    },
    {
        "id": 1328,
        "method": "public Line setupLine(NetcdfDataset dataset, Variable var, int index)\r\n\t{\r\n\t\tthis.points.clear();\r\n\t\tArray xPts = null;\r\n\t\tArray yPts = null;\r\n\t\tVariable nodeCounts = null;\r\n\t\tVariable partNodeCounts = null;\r\n\r\n\t\tList<CoordinateAxis> axes = dataset.getCoordinateAxes();\r\n\t\tCoordinateAxis x = null; CoordinateAxis y = null;\r\n\t\t\r\n\t\tString[] nodeCoords = var.findAttributeIgnoreCase(CF.NODE_COORDINATES).getStringValue().split(\" \");\r\n\t\t\r\n\t\t// Look for x and y\r\n\t\t\r\n\t\tfor(CoordinateAxis ax : axes){\r\n\t\t\t\r\n\t\t\tif(ax.getFullName().equals(nodeCoords[0])) x = ax;\r\n\t\t\tif(ax.getFullName().equals(nodeCoords[1])) y = ax;\r\n\t\t}\r\n\t\t\r\n\t\t// Affirm node counts\r\n\t\tString node_c_str = var.findAttValueIgnoreCase(CF.NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!node_c_str.equals(\"\")) {\r\n\t\t\tnodeCounts = dataset.findVariable(node_c_str);\r\n\t\t}\r\n\t\t\r\n\t\telse return null;\r\n\t\t\r\n\t\t\t\tString pNodeCoStr = var.findAttValueIgnoreCase(CF.PART_NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!pNodeCoStr.equals(\"\")) {\r\n\t\t\tpartNodeCounts = dataset.findVariable(pNodeCoStr);\r\n\t\t}\r\n\t\t\r\n\t\tSimpleGeometryIndexFinder indexFinder = new SimpleGeometryIndexFinder(nodeCounts);\r\n\t\t\r\n\t\t//Get beginning and ending indicies for this polygon\r\n\t\tint lower = indexFinder.getBeginning(index);\r\n\t\tint upper = indexFinder.getEnd(index);\r\n\r\n\t\t\r\n\t\ttry {\r\n\t\t\t\r\n\t\t\txPts = x.read( lower + \":\" + upper ).reduce();\r\n\t\t\tyPts = y.read( lower + \":\" + upper ).reduce(); \r\n\r\n\t\t\tIndexIterator itrX = xPts.getIndexIterator();\r\n\t\t\tIndexIterator itrY = yPts.getIndexIterator();\r\n\t\t\t\r\n\t\t\t// No multipolygons just read in the whole thing\r\n\t\t\tif(partNodeCounts == null) {\r\n\t\t\t\t\r\n\t\t\t\tthis.next = null;\r\n\t\t\t\tthis.prev = null;\r\n\t\t\t\t\r\n\t\t\t\t// x and y should have the same shape, will add some handling on this\r\n\t\t\t\twhile(itrX.hasNext()) {\r\n\t\t\t\t\tthis.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t}\r\n\t\r\n\t\t\t\tswitch(var.getRank()) {\r\n\t\t\t\t\r\n\t\t\t\tcase 2:\r\n\t\t\t\t\tthis.setData(var.read(CFSimpleGeometryHelper.getSubsetString(var, index)).reduce());\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tcase 1:\r\n\t\t\t\t\tthis.setData(var.read(\"\" + index));\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tdefault:\r\n\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t// If there are multipolygons then take the upper and lower of it and divy it up\r\n\t\t\telse {\r\n\t\t\t\t\r\n\t\t\t\tLine tail = this;\r\n\t\t\t\tArray pnc = partNodeCounts.read();\r\n\t\t\t\tIndexIterator pncItr = pnc.getIndexIterator();\r\n\t\t\t\t\r\n\t\t\t\t// In part node count search for the right index to begin looking for \"part node counts\"\r\n\t\t\t\tint pncInd = 0;\r\n\t\t\t\tint pncEnd = 0;\r\n\t\t\t\twhile(pncEnd < lower)\r\n\t\t\t\t{\r\n\t\t\t\t\tpncEnd += pncItr.getIntNext();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t// Now the index is found, use part node count and the index to find each part node count of each individual part\r\n\t\t\t\twhile(lower < upper) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tint smaller = pnc.getInt(pncInd);\r\n\t\t\t\t\t\r\n\t\t\t\t\twhile(smaller > 0) {\r\n\t\t\t\t\t\ttail.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t\t\tsmaller--;\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\t// Set data of each\t\r\n\t\t\t\t\tswitch(var.getRank()) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tcase 2:\r\n\t\t\t\t\t\ttail.setData(var.read(CFSimpleGeometryHelper.getSubsetString(var, index)).reduce());\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tcase 1:\r\n\t\t\t\t\t\ttail.setData(var.read(\"\" + index));\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tdefault:\r\n\t\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\t\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\tlower += tail.getPoints().size();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t\ttail.setNext(new CFLine());\r\n\t\t\t\t\ttail = tail.getNext();\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t//Clean up\r\n\t\t\t\ttail = tail.getPrev();\r\n\t\t\t\tif(tail != null) tail.setNext(null);\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tcatch (IOException  | InvalidRangeException  | InvalidDataseriesException e) {\r\n\t\t\tcfl.error(e.getMessage());;\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\t\r\n\t\treturn this;\r\n\t}",
        "variable": "pNodeCoStr",
        "reference": "part node counts",
        "explanation_by_ours": "The name of the part node counts.",
        "explanation_by_baseline": "part node counts) {"
    },
    {
        "id": 1342,
        "method": "public void setProjection(ProjectionManager.ProjectionClass pc)  {\r\n      // clear out any fields\r\n      removeAll();\r\n\r\n      for (ProjectionManager.ProjectionParam pp : pc.paramList) {\r\n        // construct the label\r\n        JPanel thisPanel = new JPanel();\r\n        thisPanel.add(new JLabel(pp.name + \": \"));\r\n\r\n                JTextField tf = new JTextField();\r\n        pp.setTextField(tf);\r\n        tf.setColumns(12);\r\n        thisPanel.add(tf);\r\n        add(thisPanel);\r\n      }\r\n      revalidate();\r\n    }",
        "variable": "tf",
        "reference": "text input field",
        "explanation_by_ours": "the text input field",
        "explanation_by_baseline": "set the field{"
    },
    {
        "id": 1347,
        "method": "private void openURL(String urlString, Command command) {\r\n    try {\r\n      //Open the URLConnection for reading\r\n      URL u = new URL(urlString);\r\n      currentConnection = (HttpURLConnection) u.openConnection();\r\n      currentConnection.setRequestMethod(command.toString()); // GET or HEAD\r\n      currentConnection.setAllowUserInteraction(true);\r\n\r\n      clear();\r\n      appendLine(command + \" request for \" + urlString);\r\n\r\n            Map<String, List<String>> reqs = currentConnection.getRequestProperties();\r\n      for (Map.Entry<String, List<String>> ent : reqs.entrySet()) {\r\n        append(\" \" + ent.getKey() + \": \");\r\n        for (String v : ent.getValue())\r\n          append(v + \" \");\r\n        appendLine(\"\");\r\n      }\r\n      appendLine(\"\");\r\n      appendLine(\"getFollowRedirects=\" + HttpURLConnection.getFollowRedirects());\r\n      appendLine(\"getInstanceFollowRedirects=\" + currentConnection.getInstanceFollowRedirects());\r\n      appendLine(\"AllowUserInteraction=\" + currentConnection.getAllowUserInteraction());\r\n      appendLine(\"\");\r\n\r\n      int code = currentConnection.getResponseCode();\r\n      String response = currentConnection.getResponseMessage();\r\n\r\n      // response headers\r\n      appendLine(\" HTTP/1.x \" + code + \" \" + response);\r\n      appendLine(\" content-length: \" + currentConnection.getContentLength());\r\n      appendLine(\" content-encoding: \" + currentConnection.getContentEncoding());\r\n      appendLine(\" content-type: \" + currentConnection.getContentType());\r\n      appendLine(\"\\nHeaders: \");\r\n\r\n      for (int j = 1; true; j++) {\r\n        String header = currentConnection.getHeaderField(j);\r\n        String key = currentConnection.getHeaderFieldKey(j);\r\n        if (header == null || key == null) break;\r\n        appendLine(\" \" + key + \": \" + header);\r\n      }\r\n\r\n      appendLine(\"\");\r\n      appendLine(\"contents:\");\r\n\r\n      // read it\r\n      java.io.InputStream is = currentConnection.getInputStream();\r\n      ByteArrayOutputStream bout = new ByteArrayOutputStream(200000);\r\n      IO.copy(is, bout);\r\n      is.close();\r\n\r\n      append(new String(bout.toByteArray(), CDM.utf8Charset));\r\n      appendLine(\"end contents\");\r\n\r\n    } catch (MalformedURLException e) {\r\n      append(urlString + \" is not a parseable URL\");\r\n    }\r\n    catch (IOException e) {\r\n      e.printStackTrace();\r\n    }\r\n  }",
        "variable": "reqs",
        "reference": "request headers",
        "explanation_by_ours": "the request properties",
        "explanation_by_baseline": "request headers) {"
    },
    {
        "id": 1355,
        "method": "public void writeDataset(InvDataset ds, Element rootElem) {\n\n    rootElem.addContent( new Element(\"title\", defNS).addContent(ds.getName()));\n\n    rootElem.addContent( new Element(\"Entry_ID\", defNS).addContent(ds.getUniqueID()));\n\n    // keywords\n    List<ThreddsMetadata.Vocab> list = ds.getKeywords();\n    if (list.size() > 0) {\n      for (ThreddsMetadata.Vocab k : list) {\n        rootElem.addContent( new Element(\"Keyword\", defNS).addContent( k.getText()));\n      }\n    }\n\n        CalendarDateRange tm = ds.getCalendarDateCoverage();\n    Element tmElem = new Element(\"Temporal_Coverage\", defNS);\n    rootElem.addContent( tmElem);\n\n    tmElem.addContent( new Element(\"Start_Date\", defNS).addContent( tm.getStart().toString()));\n    tmElem.addContent( new Element(\"End_Date\", defNS).addContent( tm.getEnd().toString()));\n\n    //geospatial\n    ThreddsMetadata.GeospatialCoverage geo = ds.getGeospatialCoverage();\n    Element geoElem = new Element(\"Spatial_Coverage\", defNS);\n    rootElem.addContent( geoElem);\n\n    geoElem.addContent( new Element(\"Southernmost_Latitude\", defNS).addContent( Double.toString(geo.getLatSouth())));\n    geoElem.addContent( new Element(\"Northernmost_Latitude\", defNS).addContent(Double.toString(geo.getLatNorth())));\n    geoElem.addContent( new Element(\"Westernmost_Latitude\", defNS).addContent(Double.toString(geo.getLonWest())));\n    geoElem.addContent( new Element(\"Easternmost_Latitude\", defNS).addContent(Double.toString(geo.getLonEast())));\n\n    rootElem.addContent( new Element(\"Use_Constraints\", defNS).addContent(ds.getDocumentation(\"rights\")));\n\n    // data center\n    List<ThreddsMetadata.Source> slist = ds.getPublishers();\n    if (list.size() > 0) {\n      for ( ThreddsMetadata.Source p : slist) {\n        Element dataCenter = new Element(\"Data_Center\", defNS);\n        rootElem.addContent( dataCenter);\n        writePublisher(p, dataCenter);\n      }\n    }\n\n    rootElem.addContent( new Element(\"Summary\", defNS).addContent(ds.getDocumentation(\"summary\")));\n\n    Element primaryURLelem = new Element(\"Related_URL\", defNS);\n    rootElem.addContent( primaryURLelem);\n\n    String primaryURL = threddsServerURL +\n        \"?catalog=\"+((InvCatalogImpl)ds.getParentCatalog()).getBaseURI().toString() +\n        \"&dataset=\"+ds.getID();\n    primaryURLelem.addContent( new Element(\"URL_Content_Type\", defNS).addContent(\"THREDDS access page\"));\n    primaryURLelem.addContent( new Element(\"URL\", defNS).addContent(primaryURL));\n\n    DateType today = new DateType(false, new Date());\n    rootElem.addContent(new Element(\"DIF_Creation_Date\", defNS).addContent(today.toDateTimeStringISO()));\n\n  }",
        "variable": "tm",
        "reference": "temporal",
        "explanation_by_ours": "ThreddsMetadata.CalendarDateRange",
        "explanation_by_baseline": "temporalnew Element(\""
    },
    {
        "id": 1356,
        "method": "public void writeDataset(InvDataset ds, Element rootElem) {\n\n    rootElem.addContent( new Element(\"title\", defNS).addContent(ds.getName()));\n\n    rootElem.addContent( new Element(\"Entry_ID\", defNS).addContent(ds.getUniqueID()));\n\n    // keywords\n    List<ThreddsMetadata.Vocab> list = ds.getKeywords();\n    if (list.size() > 0) {\n      for (ThreddsMetadata.Vocab k : list) {\n        rootElem.addContent( new Element(\"Keyword\", defNS).addContent( k.getText()));\n      }\n    }\n\n    //temporal\n    CalendarDateRange tm = ds.getCalendarDateCoverage();\n    Element tmElem = new Element(\"Temporal_Coverage\", defNS);\n    rootElem.addContent( tmElem);\n\n    tmElem.addContent( new Element(\"Start_Date\", defNS).addContent( tm.getStart().toString()));\n    tmElem.addContent( new Element(\"End_Date\", defNS).addContent( tm.getEnd().toString()));\n\n        ThreddsMetadata.GeospatialCoverage geo = ds.getGeospatialCoverage();\n    Element geoElem = new Element(\"Spatial_Coverage\", defNS);\n    rootElem.addContent( geoElem);\n\n    geoElem.addContent( new Element(\"Southernmost_Latitude\", defNS).addContent( Double.toString(geo.getLatSouth())));\n    geoElem.addContent( new Element(\"Northernmost_Latitude\", defNS).addContent(Double.toString(geo.getLatNorth())));\n    geoElem.addContent( new Element(\"Westernmost_Latitude\", defNS).addContent(Double.toString(geo.getLonWest())));\n    geoElem.addContent( new Element(\"Easternmost_Latitude\", defNS).addContent(Double.toString(geo.getLonEast())));\n\n    rootElem.addContent( new Element(\"Use_Constraints\", defNS).addContent(ds.getDocumentation(\"rights\")));\n\n    // data center\n    List<ThreddsMetadata.Source> slist = ds.getPublishers();\n    if (list.size() > 0) {\n      for ( ThreddsMetadata.Source p : slist) {\n        Element dataCenter = new Element(\"Data_Center\", defNS);\n        rootElem.addContent( dataCenter);\n        writePublisher(p, dataCenter);\n      }\n    }\n\n    rootElem.addContent( new Element(\"Summary\", defNS).addContent(ds.getDocumentation(\"summary\")));\n\n    Element primaryURLelem = new Element(\"Related_URL\", defNS);\n    rootElem.addContent( primaryURLelem);\n\n    String primaryURL = threddsServerURL +\n        \"?catalog=\"+((InvCatalogImpl)ds.getParentCatalog()).getBaseURI().toString() +\n        \"&dataset=\"+ds.getID();\n    primaryURLelem.addContent( new Element(\"URL_Content_Type\", defNS).addContent(\"THREDDS access page\"));\n    primaryURLelem.addContent( new Element(\"URL\", defNS).addContent(primaryURL));\n\n    DateType today = new DateType(false, new Date());\n    rootElem.addContent(new Element(\"DIF_Creation_Date\", defNS).addContent(today.toDateTimeStringISO()));\n\n  }",
        "variable": "geo",
        "reference": "geospatial",
        "explanation_by_ours": "the geospatial data",
        "explanation_by_baseline": "geospatial coverage"
    },
    {
        "id": 1381,
        "method": "void finish() {\r\n    gridList = new ArrayList<>(uvHash.values());\r\n    Collections.sort(gridList);\r\n\r\n    // find the common coordinates\r\n    for (GridVariable grid : gridList) {\r\n      grid.finish();\r\n    }\r\n\r\n        int seqno = 0;\r\n    for (TimeCoord tc : timeCoords)\r\n      tc.setId(seqno++);\r\n\r\n    // assign sequence number for vertical coords with same name\r\n    HashMap<String, List<VertCoord>> map = new HashMap<>();\r\n    for (VertCoord vc : vertCoords) {\r\n      List<VertCoord> list = map.get(vc.getName());\r\n      if (list == null) {\r\n        list = new ArrayList<>();\r\n        map.put(vc.getName(), list);\r\n      }\r\n      list.add(vc);\r\n    }\r\n    for (List<VertCoord> list : map.values()) {\r\n      if (list.size() > 0) {\r\n        int count = 0;\r\n        for (VertCoord vc : list) {\r\n          if (count > 0) vc.setName(vc.getName()+count);\r\n          count++;\r\n        }\r\n      }\r\n    }\r\n\r\n  }",
        "variable": "seqno",
        "reference": "sequence number for time",
        "explanation_by_ours": "the sequence number",
        "explanation_by_baseline": "sequence number for time coords"
    },
    {
        "id": 1386,
        "method": "private void createRecordVariables(List<? extends VariableSimpleIF> dataVars) {\n\n    ncfileOut.addDimension(null, new Dimension(recordDimName, 0, true, true, false));\n\n        Variable timeVar = ncfileOut.addVariable(null, timeName, DataType.DOUBLE, recordDimName);\n    timeVar.addAttribute(new Attribute(CDM.UNITS, \"secs since 1970-01-01 00:00:00\"));\n    timeVar.addAttribute(new Attribute(CDM.LONG_NAME, \"date/time of observation\"));\n    recordVars.add(timeVar);\n\n    // latitude variable\n    Variable latVar = ncfileOut.addVariable(null, latName, DataType.DOUBLE, recordDimName);\n    latVar.addAttribute(new Attribute(CDM.UNITS, \"degrees_north\"));\n    latVar.addAttribute(new Attribute(CDM.LONG_NAME, \"latitude of observation\"));\n    latVar.addAttribute(new Attribute(\"standard_name\", \"latitude\"));\n    recordVars.add(latVar);\n\n    // longitude variable\n    Variable lonVar = ncfileOut.addVariable(null, lonName, DataType.DOUBLE, recordDimName);\n    lonVar.addAttribute(new Attribute(CDM.UNITS, \"degrees_east\"));\n    lonVar.addAttribute(new Attribute(CDM.LONG_NAME, \"longitude of observation\"));\n    lonVar.addAttribute(new Attribute(\"standard_name\", \"longitude\"));\n    recordVars.add(lonVar);\n\n    if (useAlt) {\n      // altitude variable\n      Variable altVar = ncfileOut.addVariable(null, altName, DataType.DOUBLE, recordDimName);\n      altVar.addAttribute(new Attribute(CDM.UNITS, altUnits));\n      altVar.addAttribute(new Attribute(CDM.LONG_NAME, \"altitude of observation\"));\n      altVar.addAttribute(new Attribute(\"standard_name\", \"longitude\"));\n      altVar.addAttribute(new Attribute(CF.POSITIVE, CF1Convention.getZisPositive(altName, altUnits)));\n      recordVars.add(altVar);\n    }\n\n    String coordinates = timeName + \" \" + latName + \" \" + lonName;\n    if (useAlt) coordinates = coordinates + \" \" + altName;\n    Attribute coordAtt = new Attribute(CF.COORDINATES, coordinates);\n\n    // find all dimensions needed by the data variables\n    for (VariableSimpleIF var : dataVars) {\n      List<Dimension> dims = var.getDimensions();\n      dimSet.addAll(dims);\n    }\n\n    // add them\n    for (Dimension d : dimSet) {\n      if (isExtraDimension(d))\n        ncfileOut.addDimension(null, new Dimension(d.getShortName(), d.getLength(), true, false, d.isVariableLength()));\n    }\n\n    // add the data variables all using the record dimension\n    for (VariableSimpleIF oldVar : dataVars) {\n      if (ncfileOut.findVariable(oldVar.getShortName()) != null) continue;\n      List<Dimension> dims = oldVar.getDimensions();\n      StringBuilder dimNames = new StringBuilder(recordDimName);\n      for (Dimension d : dims) {\n        if (isExtraDimension(d))\n          dimNames.append(\" \").append(d.getShortName());\n      }\n      Variable newVar = ncfileOut.addVariable(null, oldVar.getShortName(), oldVar.getDataType(), dimNames.toString());\n      recordVars.add(newVar);\n\n      List<Attribute> atts = oldVar.getAttributes();\n      for (Attribute att : atts)\n        newVar.addAttribute(att);\n      newVar.addAttribute(coordAtt);\n    }\n\n  }",
        "variable": "timeVar",
        "reference": "time variable",
        "explanation_by_ours": "the time variable.",
        "explanation_by_baseline": "date/time variablenew"
    },
    {
        "id": 1387,
        "method": "private void createRecordVariables(List<? extends VariableSimpleIF> dataVars) {\n\n    ncfileOut.addDimension(null, new Dimension(recordDimName, 0, true, true, false));\n\n    // time variable\n    Variable timeVar = ncfileOut.addVariable(null, timeName, DataType.DOUBLE, recordDimName);\n    timeVar.addAttribute(new Attribute(CDM.UNITS, \"secs since 1970-01-01 00:00:00\"));\n    timeVar.addAttribute(new Attribute(CDM.LONG_NAME, \"date/time of observation\"));\n    recordVars.add(timeVar);\n\n        Variable latVar = ncfileOut.addVariable(null, latName, DataType.DOUBLE, recordDimName);\n    latVar.addAttribute(new Attribute(CDM.UNITS, \"degrees_north\"));\n    latVar.addAttribute(new Attribute(CDM.LONG_NAME, \"latitude of observation\"));\n    latVar.addAttribute(new Attribute(\"standard_name\", \"latitude\"));\n    recordVars.add(latVar);\n\n    // longitude variable\n    Variable lonVar = ncfileOut.addVariable(null, lonName, DataType.DOUBLE, recordDimName);\n    lonVar.addAttribute(new Attribute(CDM.UNITS, \"degrees_east\"));\n    lonVar.addAttribute(new Attribute(CDM.LONG_NAME, \"longitude of observation\"));\n    lonVar.addAttribute(new Attribute(\"standard_name\", \"longitude\"));\n    recordVars.add(lonVar);\n\n    if (useAlt) {\n      // altitude variable\n      Variable altVar = ncfileOut.addVariable(null, altName, DataType.DOUBLE, recordDimName);\n      altVar.addAttribute(new Attribute(CDM.UNITS, altUnits));\n      altVar.addAttribute(new Attribute(CDM.LONG_NAME, \"altitude of observation\"));\n      altVar.addAttribute(new Attribute(\"standard_name\", \"longitude\"));\n      altVar.addAttribute(new Attribute(CF.POSITIVE, CF1Convention.getZisPositive(altName, altUnits)));\n      recordVars.add(altVar);\n    }\n\n    String coordinates = timeName + \" \" + latName + \" \" + lonName;\n    if (useAlt) coordinates = coordinates + \" \" + altName;\n    Attribute coordAtt = new Attribute(CF.COORDINATES, coordinates);\n\n    // find all dimensions needed by the data variables\n    for (VariableSimpleIF var : dataVars) {\n      List<Dimension> dims = var.getDimensions();\n      dimSet.addAll(dims);\n    }\n\n    // add them\n    for (Dimension d : dimSet) {\n      if (isExtraDimension(d))\n        ncfileOut.addDimension(null, new Dimension(d.getShortName(), d.getLength(), true, false, d.isVariableLength()));\n    }\n\n    // add the data variables all using the record dimension\n    for (VariableSimpleIF oldVar : dataVars) {\n      if (ncfileOut.findVariable(oldVar.getShortName()) != null) continue;\n      List<Dimension> dims = oldVar.getDimensions();\n      StringBuilder dimNames = new StringBuilder(recordDimName);\n      for (Dimension d : dims) {\n        if (isExtraDimension(d))\n          dimNames.append(\" \").append(d.getShortName());\n      }\n      Variable newVar = ncfileOut.addVariable(null, oldVar.getShortName(), oldVar.getDataType(), dimNames.toString());\n      recordVars.add(newVar);\n\n      List<Attribute> atts = oldVar.getAttributes();\n      for (Attribute att : atts)\n        newVar.addAttribute(att);\n      newVar.addAttribute(coordAtt);\n    }\n\n  }",
        "variable": "latVar",
        "reference": "latitude variable",
        "explanation_by_ours": "the latitude variable.",
        "explanation_by_baseline": "latitude variable= ncfile"
    },
    {
        "id": 1388,
        "method": "private void createRecordVariables(List<? extends VariableSimpleIF> dataVars) {\n\n    ncfileOut.addDimension(null, new Dimension(recordDimName, 0, true, true, false));\n\n    // time variable\n    Variable timeVar = ncfileOut.addVariable(null, timeName, DataType.DOUBLE, recordDimName);\n    timeVar.addAttribute(new Attribute(CDM.UNITS, \"secs since 1970-01-01 00:00:00\"));\n    timeVar.addAttribute(new Attribute(CDM.LONG_NAME, \"date/time of observation\"));\n    recordVars.add(timeVar);\n\n    // latitude variable\n    Variable latVar = ncfileOut.addVariable(null, latName, DataType.DOUBLE, recordDimName);\n    latVar.addAttribute(new Attribute(CDM.UNITS, \"degrees_north\"));\n    latVar.addAttribute(new Attribute(CDM.LONG_NAME, \"latitude of observation\"));\n    latVar.addAttribute(new Attribute(\"standard_name\", \"latitude\"));\n    recordVars.add(latVar);\n\n        Variable lonVar = ncfileOut.addVariable(null, lonName, DataType.DOUBLE, recordDimName);\n    lonVar.addAttribute(new Attribute(CDM.UNITS, \"degrees_east\"));\n    lonVar.addAttribute(new Attribute(CDM.LONG_NAME, \"longitude of observation\"));\n    lonVar.addAttribute(new Attribute(\"standard_name\", \"longitude\"));\n    recordVars.add(lonVar);\n\n    if (useAlt) {\n      // altitude variable\n      Variable altVar = ncfileOut.addVariable(null, altName, DataType.DOUBLE, recordDimName);\n      altVar.addAttribute(new Attribute(CDM.UNITS, altUnits));\n      altVar.addAttribute(new Attribute(CDM.LONG_NAME, \"altitude of observation\"));\n      altVar.addAttribute(new Attribute(\"standard_name\", \"longitude\"));\n      altVar.addAttribute(new Attribute(CF.POSITIVE, CF1Convention.getZisPositive(altName, altUnits)));\n      recordVars.add(altVar);\n    }\n\n    String coordinates = timeName + \" \" + latName + \" \" + lonName;\n    if (useAlt) coordinates = coordinates + \" \" + altName;\n    Attribute coordAtt = new Attribute(CF.COORDINATES, coordinates);\n\n    // find all dimensions needed by the data variables\n    for (VariableSimpleIF var : dataVars) {\n      List<Dimension> dims = var.getDimensions();\n      dimSet.addAll(dims);\n    }\n\n    // add them\n    for (Dimension d : dimSet) {\n      if (isExtraDimension(d))\n        ncfileOut.addDimension(null, new Dimension(d.getShortName(), d.getLength(), true, false, d.isVariableLength()));\n    }\n\n    // add the data variables all using the record dimension\n    for (VariableSimpleIF oldVar : dataVars) {\n      if (ncfileOut.findVariable(oldVar.getShortName()) != null) continue;\n      List<Dimension> dims = oldVar.getDimensions();\n      StringBuilder dimNames = new StringBuilder(recordDimName);\n      for (Dimension d : dims) {\n        if (isExtraDimension(d))\n          dimNames.append(\" \").append(d.getShortName());\n      }\n      Variable newVar = ncfileOut.addVariable(null, oldVar.getShortName(), oldVar.getDataType(), dimNames.toString());\n      recordVars.add(newVar);\n\n      List<Attribute> atts = oldVar.getAttributes();\n      for (Attribute att : atts)\n        newVar.addAttribute(att);\n      newVar.addAttribute(coordAtt);\n    }\n\n  }",
        "variable": "lonVar",
        "reference": "longitude variable",
        "explanation_by_ours": "the longitude variable.",
        "explanation_by_baseline": "longitude variable= ncfile"
    },
    {
        "id": 1389,
        "method": "private void createRecordVariables(List<? extends VariableSimpleIF> dataVars) {\n\n    ncfileOut.addDimension(null, new Dimension(recordDimName, 0, true, true, false));\n\n    // time variable\n    Variable timeVar = ncfileOut.addVariable(null, timeName, DataType.DOUBLE, recordDimName);\n    timeVar.addAttribute(new Attribute(CDM.UNITS, \"secs since 1970-01-01 00:00:00\"));\n    timeVar.addAttribute(new Attribute(CDM.LONG_NAME, \"date/time of observation\"));\n    recordVars.add(timeVar);\n\n    // latitude variable\n    Variable latVar = ncfileOut.addVariable(null, latName, DataType.DOUBLE, recordDimName);\n    latVar.addAttribute(new Attribute(CDM.UNITS, \"degrees_north\"));\n    latVar.addAttribute(new Attribute(CDM.LONG_NAME, \"latitude of observation\"));\n    latVar.addAttribute(new Attribute(\"standard_name\", \"latitude\"));\n    recordVars.add(latVar);\n\n    // longitude variable\n    Variable lonVar = ncfileOut.addVariable(null, lonName, DataType.DOUBLE, recordDimName);\n    lonVar.addAttribute(new Attribute(CDM.UNITS, \"degrees_east\"));\n    lonVar.addAttribute(new Attribute(CDM.LONG_NAME, \"longitude of observation\"));\n    lonVar.addAttribute(new Attribute(\"standard_name\", \"longitude\"));\n    recordVars.add(lonVar);\n\n    if (useAlt) {\n            Variable altVar = ncfileOut.addVariable(null, altName, DataType.DOUBLE, recordDimName);\n      altVar.addAttribute(new Attribute(CDM.UNITS, altUnits));\n      altVar.addAttribute(new Attribute(CDM.LONG_NAME, \"altitude of observation\"));\n      altVar.addAttribute(new Attribute(\"standard_name\", \"longitude\"));\n      altVar.addAttribute(new Attribute(CF.POSITIVE, CF1Convention.getZisPositive(altName, altUnits)));\n      recordVars.add(altVar);\n    }\n\n    String coordinates = timeName + \" \" + latName + \" \" + lonName;\n    if (useAlt) coordinates = coordinates + \" \" + altName;\n    Attribute coordAtt = new Attribute(CF.COORDINATES, coordinates);\n\n    // find all dimensions needed by the data variables\n    for (VariableSimpleIF var : dataVars) {\n      List<Dimension> dims = var.getDimensions();\n      dimSet.addAll(dims);\n    }\n\n    // add them\n    for (Dimension d : dimSet) {\n      if (isExtraDimension(d))\n        ncfileOut.addDimension(null, new Dimension(d.getShortName(), d.getLength(), true, false, d.isVariableLength()));\n    }\n\n    // add the data variables all using the record dimension\n    for (VariableSimpleIF oldVar : dataVars) {\n      if (ncfileOut.findVariable(oldVar.getShortName()) != null) continue;\n      List<Dimension> dims = oldVar.getDimensions();\n      StringBuilder dimNames = new StringBuilder(recordDimName);\n      for (Dimension d : dims) {\n        if (isExtraDimension(d))\n          dimNames.append(\" \").append(d.getShortName());\n      }\n      Variable newVar = ncfileOut.addVariable(null, oldVar.getShortName(), oldVar.getDataType(), dimNames.toString());\n      recordVars.add(newVar);\n\n      List<Attribute> atts = oldVar.getAttributes();\n      for (Attribute att : atts)\n        newVar.addAttribute(att);\n      newVar.addAttribute(coordAtt);\n    }\n\n  }",
        "variable": "altVar",
        "reference": "altitude variable",
        "explanation_by_ours": "the alt variable.",
        "explanation_by_baseline": "altitude variablenew"
    },
    {
        "id": 1432,
        "method": "private void write(StationObsDataset sobsDataset) throws IOException {\n    createGlobalAttributes();\n    createStations(sobsDataset.getStations());\n\n    ncfile.addGlobalAttribute(\"time_coverage_start\", dateFormatter.toDateTimeStringISO(sobsDataset.getStartDate()));\n    ncfile.addGlobalAttribute(\"time_coverage_end\", dateFormatter.toDateTimeStringISO(sobsDataset.getEndDate()));\n\n    createDataVariables(sobsDataset.getDataVariables());\n\n        List gatts = sobsDataset.getGlobalAttributes();\n    for (int i = 0; i < gatts.size(); i++) {\n      Attribute att = (Attribute) gatts.get(i);\n      ncfile.addGlobalAttribute(att);\n    }\n\n    // done with define mode\n    ncfile.create();\n\n    // write out the station info\n    writeStationData(sobsDataset.getStations());\n\n    // now write the observations\n    if (! (Boolean) ncfile.sendIospMessage(NetcdfFile.IOSP_MESSAGE_ADD_RECORD_STRUCTURE))\n      throw new IllegalStateException(\"can't add record variable\");\n\n    int[] origin = new int[1];\n    int[] originTime = new int[2];\n    int recno = 0;\n    ArrayStructureW sArray = null;\n    ArrayObject.D1 timeArray = new ArrayObject.D1(DataType.STRING, String.class, false, 1);\n\n    DataIterator diter = sobsDataset.getDataIterator(1000 * 1000);\n    while (diter.hasNext()) {\n      StationObsDatatype sobs = (StationObsDatatype) diter.nextData();\n      StructureData recordData = sobs.getData();\n\n      // needs to be wrapped as an ArrayStructure, even though we are only writing one at a time.\n      if (sArray == null)\n        sArray = new ArrayStructureW(recordData.getStructureMembers(), new int[]{1});\n      sArray.setStructureData(recordData, 0);\n\n      // date is handled specially\n      timeArray.set(0, dateFormatter.toDateTimeStringISO(sobs.getObservationTimeAsDate()));\n\n      // write the recno record\n      origin[0] = recno;\n      originTime[0] = recno;\n      try {\n        ncfile.write(\"record\", origin, sArray);\n        ncfile.writeStringData(timeName, originTime, timeArray);\n\n      } catch (InvalidRangeException e) {\n        e.printStackTrace();\n        throw new IllegalStateException(e);\n      }\n      recno++;\n    }\n\n    ncfile.close();\n  }",
        "variable": "gatts",
        "reference": "global attributes",
        "explanation_by_ours": "list of global attributes",
        "explanation_by_baseline": "write out the global attributes"
    },
    {
        "id": 1474,
        "method": "public void serialize(String dataset,DataOutputStream sink,CEEvaluator ce,Object specialO)\n                                    throws NoSuchVariableException, DAP2ServerSideException, IOException {\n\n    if (org == null) {\n      super.serialize(dataset, sink, ce, specialO);\n      return;\n    }\n\n    // use the projection info in the original\n    java.util.Enumeration vars = org.getVariables();\n\n        StructureMembers sm = sdata.getStructureMembers();\n\n    int count = 0;\n    while (vars.hasMoreElements()) {\n      HasNetcdfVariable sm_org = (HasNetcdfVariable) vars.nextElement();\n      boolean isProjected = ((ServerMethods) sm_org).isProject();\n      if (isProjected) {\n        StructureMembers.Member m = sm.getMember(count);\n        sm_org.serialize( sink, sdata, m);\n      }\n      count++;\n    }\n\n  }",
        "variable": "sm",
        "reference": "structure member",
        "explanation_by_ours": "the server-side projection",
        "explanation_by_baseline": "variable in the original("
    },
    {
        "id": 1485,
        "method": "public void readData(InputStream is, StatusUI statusUI)\r\n            throws IOException, EOFException, DAP2Exception {\r\n\r\n      /* ByteArrayOutputStream bout = new ByteArrayOutputStream(50 * 1000);\r\n      copy(is, bout);\r\n      LogStream.dbg.printf(\" readData size=%d %n\",bout.size());\r\n      LogStream.dbg.logflush();\r\n      ByteArrayInputStream bufferedIS = new ByteArrayInputStream( bout.toByteArray());  */\r\n      //statusUI = new Counter();\r\n\r\n                BufferedInputStream bufferedIS = new BufferedInputStream(is);\r\n        // Use a DataInputStream for deserialize\r\n        DataInputStream dataIS = new DataInputStream(bufferedIS);\r\n\r\n        for (Enumeration e = getVariables(); e.hasMoreElements();) {\r\n            if (statusUI != null && statusUI.userCancelled()) throw new DataReadException(\"User cancelled\");\r\n            ClientIO bt = (ClientIO) e.nextElement();\r\n\r\n          /* if (true) {\r\n            BaseType btt = (BaseType) bt;\r\n            System.out.printf(\"Deserializing: %s (%s) %n\", btt.getEncodedName(), ((BaseType) bt).getTypeName());\r\n          } */\r\n            bt.deserialize(dataIS, ver, statusUI);\r\n        }\r\n        //LogStream.out.printf(\"Deserializing: total size = %s %n\", counter);\r\n\r\n        // notify GUI of finished download\r\n        if (statusUI != null)\r\n            statusUI.finished();\r\n    }",
        "variable": "bufferedIS",
        "reference": "the buffer input stream",
        "explanation_by_ours": "The input stream to read from.",
        "explanation_by_baseline": "= (ClientIO)"
    },
    {
        "id": 1486,
        "method": "public void readData(InputStream is, StatusUI statusUI)\r\n            throws IOException, EOFException, DAP2Exception {\r\n\r\n      /* ByteArrayOutputStream bout = new ByteArrayOutputStream(50 * 1000);\r\n      copy(is, bout);\r\n      LogStream.dbg.printf(\" readData size=%d %n\",bout.size());\r\n      LogStream.dbg.logflush();\r\n      ByteArrayInputStream bufferedIS = new ByteArrayInputStream( bout.toByteArray());  */\r\n      //statusUI = new Counter();\r\n\r\n        // Buffer the input stream for better performance\r\n        BufferedInputStream bufferedIS = new BufferedInputStream(is);\r\n                DataInputStream dataIS = new DataInputStream(bufferedIS);\r\n\r\n        for (Enumeration e = getVariables(); e.hasMoreElements();) {\r\n            if (statusUI != null && statusUI.userCancelled()) throw new DataReadException(\"User cancelled\");\r\n            ClientIO bt = (ClientIO) e.nextElement();\r\n\r\n          /* if (true) {\r\n            BaseType btt = (BaseType) bt;\r\n            System.out.printf(\"Deserializing: %s (%s) %n\", btt.getEncodedName(), ((BaseType) bt).getTypeName());\r\n          } */\r\n            bt.deserialize(dataIS, ver, statusUI);\r\n        }\r\n        //LogStream.out.printf(\"Deserializing: total size = %s %n\", counter);\r\n\r\n        // notify GUI of finished download\r\n        if (statusUI != null)\r\n            statusUI.finished();\r\n    }",
        "variable": "dataIS",
        "reference": "DataInputStream",
        "explanation_by_ours": "The input stream to read the data from.",
        "explanation_by_baseline": "DataInputStream= (Client"
    },
    {
        "id": 1487,
        "method": "public final void externalize(OutputStream os, boolean compress, boolean headers)\r\n            throws IOException {\r\n        // First, print headers\r\n        if (headers) {\r\n            PrintWriter pw = new PrintWriter(new OutputStreamWriter(os,Util.UTF8));\r\n            pw.println(\"HTTP/1.0 200 OK\");\r\n            pw.println(\"XDAP: \" + ServerVersion.DAP2_PROTOCOL_VERSION);\r\n            pw.println(\"XDODS-Server: DODS/\" + ServerVersion.DAP2_PROTOCOL_VERSION);\r\n            pw.println(\"Content-type: application/octet-stream\");\r\n            pw.println(\"Content-Description: dods-data\");\r\n            if (compress) {\r\n                pw.println(\"Content-Encoding: deflate\");\r\n            }\r\n            pw.println();\r\n            pw.flush();\r\n        }\r\n\r\n        // Buffer the output stream for better performance\r\n        OutputStream bufferedOS;\r\n        if (compress) {\r\n                        bufferedOS = new BufferedOutputStream(new DeflaterOutputStream(os));\r\n        } else {\r\n            bufferedOS = new BufferedOutputStream(os);\r\n        }\r\n\r\n        // Redefine PrintWriter here, so the DDS is also compressed if necessary\r\n        PrintWriter pw = new PrintWriter(new OutputStreamWriter(bufferedOS,Util.UTF8));\r\n        print(pw);\r\n        // pw.println(\"Data:\");  // JCARON CHANGED\r\n        pw.flush();\r\n        bufferedOS.write(\"\\nData:\\n\".getBytes(CDM.utf8Charset)); // JCARON CHANGED\r\n        bufferedOS.flush();\r\n\r\n        // Use a DataOutputStream for serialize\r\n        DataOutputStream dataOS = new DataOutputStream(bufferedOS);\r\n        for (Enumeration e = getVariables(); e.hasMoreElements();) {\r\n            ClientIO bt = (ClientIO) e.nextElement();\r\n            bt.externalize(dataOS);\r\n        }\r\n        // Note: for DeflaterOutputStream, flush() is not sufficient to flush\r\n        // all buffered data\r\n        dataOS.close();\r\n    }",
        "variable": "bufferedOS",
        "reference": "the buffered output stream",
        "explanation_by_ours": "The output stream to write to.",
        "explanation_by_baseline": ") {( ) ;"
    },
    {
        "id": 1489,
        "method": "public final void externalize(OutputStream os, boolean compress, boolean headers)\r\n            throws IOException {\r\n        // First, print headers\r\n        if (headers) {\r\n            PrintWriter pw = new PrintWriter(new OutputStreamWriter(os,Util.UTF8));\r\n            pw.println(\"HTTP/1.0 200 OK\");\r\n            pw.println(\"XDAP: \" + ServerVersion.DAP2_PROTOCOL_VERSION);\r\n            pw.println(\"XDODS-Server: DODS/\" + ServerVersion.DAP2_PROTOCOL_VERSION);\r\n            pw.println(\"Content-type: application/octet-stream\");\r\n            pw.println(\"Content-Description: dods-data\");\r\n            if (compress) {\r\n                pw.println(\"Content-Encoding: deflate\");\r\n            }\r\n            pw.println();\r\n            pw.flush();\r\n        }\r\n\r\n        // Buffer the output stream for better performance\r\n        OutputStream bufferedOS;\r\n        if (compress) {\r\n            // need a BufferedOutputStream - 3X performance - LOOK: why ??\r\n            bufferedOS = new BufferedOutputStream(new DeflaterOutputStream(os));\r\n        } else {\r\n            bufferedOS = new BufferedOutputStream(os);\r\n        }\r\n\r\n        // Redefine PrintWriter here, so the DDS is also compressed if necessary\r\n        PrintWriter pw = new PrintWriter(new OutputStreamWriter(bufferedOS,Util.UTF8));\r\n        print(pw);\r\n        // pw.println(\"Data:\");  // JCARON CHANGED\r\n        pw.flush();\r\n        bufferedOS.write(\"\\nData:\\n\".getBytes(CDM.utf8Charset)); // JCARON CHANGED\r\n        bufferedOS.flush();\r\n\r\n                DataOutputStream dataOS = new DataOutputStream(bufferedOS);\r\n        for (Enumeration e = getVariables(); e.hasMoreElements();) {\r\n            ClientIO bt = (ClientIO) e.nextElement();\r\n            bt.externalize(dataOS);\r\n        }\r\n        // Note: for DeflaterOutputStream, flush() is not sufficient to flush\r\n        // all buffered data\r\n        dataOS.close();\r\n    }",
        "variable": "dataOS",
        "reference": "DataOutputStream",
        "explanation_by_ours": "The output stream to write to.",
        "explanation_by_baseline": "DataOutputStream{ //"
    },
    {
        "id": 1504,
        "method": "public Optional<HorizCoordSys> subset(SubsetParams params) {\n    LatLonRect llbb = (LatLonRect) params.get(SubsetParams.latlonBB);\n    ProjectionRect projbb = (ProjectionRect) params.get(SubsetParams.projBB);\n    LatLonPoint latlon = (LatLonPoint) params.get(SubsetParams.latlonPoint);\n    Integer horizStride = (Integer) params.get(SubsetParams.horizStride);\n    if (horizStride == null || horizStride < 1) horizStride = 1;\n\n    CoverageCoordAxis1D xaxisSubset = null, yaxisSubset = null;\n    CoverageCoordAxis lataxisSubset = null, lonaxisSubset = null;\n    Optional<CoverageCoordAxis> opt;\n    Optional<CoverageCoordAxisBuilder> optb;\n\n    Formatter errMessages = new Formatter();\n    try {\n      if (latlon != null) { // overrides other horiz subset params\n        if (isProjection) {\n          CoordAxisHelper xhelper = new CoordAxisHelper(xAxis);\n          CoordAxisHelper yhelper = new CoordAxisHelper(yAxis);\n\n                    ProjectionImpl proj = transform.getProjection();\n          ProjectionPoint pp = proj.latLonToProj(latlon);\n          optb = xhelper.subsetContaining(pp.getX());\n          if (optb.isPresent()) xaxisSubset = new CoverageCoordAxis1D(optb.get());\n          else errMessages.format(\"xaxis: %s;%n\", optb.getErrorMessage());\n\n          optb = yhelper.subsetContaining(pp.getY());\n          if (optb.isPresent()) yaxisSubset = new CoverageCoordAxis1D(optb.get());\n          else errMessages.format(\"yaxis: %s;%n\", optb.getErrorMessage());\n\n        } else {\n          CoordAxisHelper xhelper = new CoordAxisHelper(lonAxis);\n          CoordAxisHelper yhelper = new CoordAxisHelper(latAxis);\n\n          double lonNormal = LatLonPointImpl.lonNormalFrom(latlon.getLongitude(), lonAxis.getStartValue());\n          optb = xhelper.subsetContaining(lonNormal);\n          if (optb.isPresent()) lonaxisSubset = new CoverageCoordAxis1D(optb.get());\n          else errMessages.format(\"lonaxis: %s;%n\", optb.getErrorMessage());\n\n          optb = yhelper.subsetContaining(latlon.getLatitude());\n          if (optb.isPresent()) lataxisSubset = new CoverageCoordAxis1D(optb.get());\n          else errMessages.format(\"lataxis: %s;%n\", optb.getErrorMessage());\n        }\n\n      } else if (projbb != null) {\n        if (isProjection) {\n          opt = xAxis.subset(projbb.getMinX(), projbb.getMaxX(), horizStride);\n          if (opt.isPresent()) xaxisSubset = (CoverageCoordAxis1D) opt.get();\n          else errMessages.format(\"xaxis: %s;%n\", opt.getErrorMessage());\n\n          opt = yAxis.subset(projbb.getMinY(), projbb.getMaxY(), horizStride);\n          if (opt.isPresent()) yaxisSubset = (CoverageCoordAxis1D) opt.get();\n          else errMessages.format(\"yaxis: %s;%n\", opt.getErrorMessage());\n\n        } /* else {            ProjectionImpl proj = transform.getProjection();\n          LatLonRect llrect = proj.projToLatLonBB(projbb);\n          opt = lonaxis.subset(llrect.getLonMin(), llrect.getLonMax(), horizStride);\n          if (opt.isPresent()) lonaxisSubset = opt.get();\n          else errMessages.format(\"lonaxis: %s;%n\", opt.getErrorMessage());\n\n          opt = lataxis.subset(llrect.getLatMin(), llrect.getLatMax(), horizStride);\n          if (opt.isPresent()) lataxisSubset = opt.get();\n          else errMessages.format(\"lataxis: %s;%n\", opt.getErrorMessage());\n        } */\n\n      } else if (llbb != null) {\n        LatLonRect full = calcLatLonBoundingBox();\n        assert full != null;\n\n        if (!full.containedIn(llbb)) { // if request contains entire bb, then no subsetting needed\n\n          if (isProjection) {\n                        ProjectionImpl proj = transform.getProjection();\n            ProjectionRect prect = proj.latLonToProjBB(llbb); // allow projection to override\n            opt = xAxis.subset(prect.getMinX(), prect.getMaxX(), horizStride);\n            if (opt.isPresent()) xaxisSubset = (CoverageCoordAxis1D) opt.get();\n            else errMessages.format(\"xaxis: %s;%n\", opt.getErrorMessage());\n\n            opt = yAxis.subset(prect.getMinY(), prect.getMaxY(), horizStride);\n            if (opt.isPresent()) yaxisSubset = (CoverageCoordAxis1D) opt.get();\n            else errMessages.format(\"yaxis: %s;%n\", opt.getErrorMessage());\n\n          } else {\n            opt = subsetLon(llbb, horizStride);\n            if (opt.isPresent()) lonaxisSubset = opt.get();\n            else errMessages.format(\"lonaxis: %s;%n\", opt.getErrorMessage());\n\n            opt = latAxis.subset(llbb.getLatMin(), llbb.getLatMax(), horizStride);\n            if (opt.isPresent()) lataxisSubset = opt.get();\n            else errMessages.format(\"lataxis: %s;%n\", opt.getErrorMessage());\n          }\n        }\n\n      } else if (horizStride > 1) { // no bounding box, just horiz stride\n        if (isProjection) {\n          opt = xAxis.subsetByIndex(xAxis.getRange().setStride(horizStride));\n          if (opt.isPresent()) xaxisSubset = (CoverageCoordAxis1D) opt.get();\n          else errMessages.format(\"xaxis: %s;%n\", opt.getErrorMessage());\n\n          opt = yAxis.subsetByIndex(yAxis.getRange().setStride(horizStride));\n          if (opt.isPresent()) yaxisSubset = (CoverageCoordAxis1D) opt.get();\n          else errMessages.format(\"yaxis: %s;%n\", opt.getErrorMessage());\n\n        } else {\n          opt = lonAxis.subsetByIndex(lonAxis.getRange().setStride(horizStride));\n          if (opt.isPresent()) lonaxisSubset = opt.get();\n          else errMessages.format(\"lonaxis: %s;%n\", opt.getErrorMessage());\n\n          opt = latAxis.subsetByIndex(latAxis.getRange().setStride(horizStride));\n          if (opt.isPresent()) lataxisSubset = opt.get();\n          else errMessages.format(\"lataxis: %s;%n\", opt.getErrorMessage());\n        }\n      }\n    } catch (InvalidRangeException e) {\n      errMessages.format(\"%s;%n\", e.getMessage());\n    }\n\n    String errs = errMessages.toString();\n    if (errs.length() > 0)\n      return Optional.empty(errs);\n\n    // makes a copy of the axis\n    if (xaxisSubset == null && xAxis != null) xaxisSubset = (CoverageCoordAxis1D) xAxis.copy();\n    if (yaxisSubset == null && yAxis != null) yaxisSubset = (CoverageCoordAxis1D) yAxis.copy();\n    if (lataxisSubset == null && latAxis != null) lataxisSubset = latAxis.copy();\n    if (lonaxisSubset == null && lonAxis != null) lonaxisSubset = lonAxis.copy();\n\n    return Optional.of(new HorizCoordSys(xaxisSubset, yaxisSubset, lataxisSubset, lonaxisSubset, transform));\n  }",
        "variable": "proj",
        "reference": "projection coordinates",
        "explanation_by_ours": "the projection",
        "explanation_by_baseline": "projection coordinatesif (h"
    },
    {
        "id": 1508,
        "method": "synchronized\n    protected void\n    setAuthenticationAndProxy(HttpClientBuilder cb)\n            throws HTTPException\n    {\n        // First, setup the ssl factory\n        cb.setSSLSocketFactory((SSLConnectionSocketFactory) authcontrols.get(AuthProp.SSLFACTORY));\n\n        // Second, Construct a CredentialsProvider that is\n        // the union of the Proxy credentials plus\n        // either the global or local credentials; local overrides global\n        // Unfortunately, we cannot either clone or extract the contents\n        // of the client supplied provider, so we are forced (for now)\n        // to modify the client supplied provider.\n\n        // Look in the local credentials first for for best scope match\n        AuthScope bestMatch = HTTPAuthUtil.bestmatch(scope, localcreds.keySet());\n        CredentialsProvider cp = null;\n        if(bestMatch != null) {\n            cp = localcreds.get(bestMatch);\n        } else {\n            bestMatch = HTTPAuthUtil.bestmatch(scope, globalcredfactories.keySet());\n            if(bestMatch != null) {\n                HTTPProviderFactory factory = globalcredfactories.get(bestMatch);\n                cp = factory.getProvider(bestMatch);\n            }\n        }\n                Credentials proxycreds = null;\n        AuthScope proxyscope = null;\n        String user = (String) authcontrols.get(AuthProp.PROXYUSER);\n        String pwd = (String) authcontrols.get(AuthProp.PROXYPWD);\n        HttpHost httpproxy = (HttpHost) authcontrols.get(AuthProp.HTTPPROXY);\n        HttpHost httpsproxy = (HttpHost) authcontrols.get(AuthProp.HTTPSPROXY);\n        if(user != null && (httpproxy != null || httpsproxy != null)) {\n            if(httpproxy != null)\n                proxyscope = HTTPAuthUtil.hostToAuthScope(httpproxy);\n            else //httpsproxy != null\n                proxyscope = HTTPAuthUtil.hostToAuthScope(httpsproxy);\n            proxycreds = new UsernamePasswordCredentials(user, pwd);\n        }\n        if(cp == null && proxycreds != null && proxyscope != null) {\n            // If client provider is null and proxycreds are not,\n            // then use proxycreds alone\n            cp = new BasicCredentialsProvider();\n            cp.setCredentials(proxyscope, proxycreds);\n        } else if(cp != null && proxycreds != null && proxyscope != null) {\n            // If client provider is not null and proxycreds are not,\n            // then add proxycreds to the client provider\n            cp.setCredentials(proxyscope, proxycreds);\n        }\n        if(cp != null)\n            this.sessioncontext.setCredentialsProvider(cp);\n    }",
        "variable": "proxycreds",
        "reference": "the proxy credentials",
        "explanation_by_ours": "the proxy credentials",
        "explanation_by_baseline": "a CredentialsProviderif ("
    },
    {
        "id": 1523,
        "method": "public boolean resourceControlOk(HttpServletRequest req, HttpServletResponse res, String reqPath) {\n    if (null == reqPath)\n      reqPath = TdsPathUtils.extractPath(req, null);\n\n        String rc = null;\n    DataRootManager.DataRootMatch match = dataRootManager.findDataRootMatch(reqPath);\n    if (match != null) {\n      rc = match.dataRoot.getRestrict(); // datasetScan, featCollection are restricted at the dataRoot\n    }\n\n    if (rc == null) {\n      rc = datasetTracker.findResourceControl(reqPath); // regular datasets tracked here\n    }\n\n    return resourceAuthorized(req, res, rc);\n  }",
        "variable": "rc",
        "reference": "resource control",
        "explanation_by_ours": "The resource control",
        "explanation_by_baseline": "theif (null =="
    },
    {
        "id": 1541,
        "method": "private opendap.dap.Attribute getAliasAttribute(AttributeTable att, Vector aNames)\r\n            throws MalformedAliasException, UnresolvedAliasException\r\n    {\r\n\r\n        // Get the first node name form the vector.\r\n        String aName = (String) aNames.get(0);\r\n\r\n        // Get the list of child nodes from the AttributeTable\r\n        Enumeration e = att.getNames();\r\n        while (e.hasMoreElements()) {\r\n\r\n                        String atName = (String) e.nextElement();\r\n            opendap.dap.Attribute a = att.getAttribute(atName);\r\n\r\n            // Get the Attributes name and Normalize it.\r\n            String normName = opendap.dap.DDS.normalize(a.getEncodedName());\r\n\r\n            // Are they the same?\r\n            if (normName.equals(aName)) {\r\n\r\n                // Make sure this reference doesn't pass through an Alias.\r\n                if (a.isAlias()) {\r\n                    throw new MalformedAliasException(\"Aliases may NOT point to other aliases\");\r\n                }\r\n\r\n                //dump the name from the list of names.\r\n                aNames.remove(0);\r\n\r\n                // Are there more?\r\n                if (aNames.size() == 0) {\r\n                    //No! We found it!\r\n                    return (a);\r\n\r\n                } else if (a.isContainer()) { // Is this Attribute a container (it better be)\r\n\r\n                    try {\r\n                        // Recursively search for the rest of the name vector in the container.\r\n                        return (getAliasAttribute(a.getContainer(), aNames));\r\n\r\n                    } catch (NoSuchAttributeException nsae) {\r\n                        throw new MalformedAliasException(\"Attribute \" + a.getEncodedName() +\r\n                                \" is not an attribute container. (AttributeTable) \" +\r\n                                \" It may not contain the attribute: \" +\r\n                                aName);\r\n                    }\r\n\r\n                } else { // Dead-end, through an exception!\r\n\r\n                    throw new MalformedAliasException(\"Attribute \" + a.getEncodedName() +\r\n                            \" is not an attribute container. (AttributeTable) \" +\r\n                            \" It may not contain the attribute: \" +\r\n                            aName);\r\n                }\r\n\r\n            }\r\n        }\r\n        // Nothing Matched, so this search failed.\r\n        throw new UnresolvedAliasException(\"The alias `\" + currentAlias.getEncodedName() +\r\n                \"` references the attribute: `\" + aName + \"` which cannot be found.\");\r\n\r\n\r\n    }",
        "variable": "atName",
        "reference": "Attribute Name",
        "explanation_by_ours": "The name of the Attribute to get.",
        "explanation_by_baseline": "{//the"
    },
    {
        "id": 1548,
        "method": "public D4Cursor\n    compileSequence(DapVariable var, DapSequence dapseq, D4Cursor container)\n            throws DapException\n    {\n        int pos = getPos(this.databuffer);\n        D4Cursor seq = new D4Cursor(Scheme.SEQUENCE, this.dsp, var, container)\n                .setOffset(pos);\n        List<DapVariable> dfields = dapseq.getFields();\n                long nrecs = getCount(this.databuffer);\n        for(int r = 0; r < nrecs; r++) {\n            pos = getPos(this.databuffer);\n            D4Cursor rec = (D4Cursor) new D4Cursor(D4Cursor.Scheme.RECORD, this.dsp, var, container)\n                    .setOffset(pos).setRecordIndex(r);\n            for(int m = 0; m < dfields.size(); m++) {\n                DapVariable dfield = dfields.get(m);\n                D4Cursor dvfield = compileVar(dfield, rec);\n                rec.addField(m, dvfield);\n                assert dfield.getParent() != null;\n            }\n            seq.addRecord(rec);\n        }\n        return seq;\n    }",
        "variable": "nrecs",
        "reference": "the number of records",
        "explanation_by_ours": "the number of records to compile",
        "explanation_by_baseline": "records in the sequence."
    },
    {
        "id": 1551,
        "method": "public void finish( boolean addButtons, String where) {\n    if (finished)\n      throw new IllegalStateException(\"PrefPanel \"+name+\": already called finish()\");  \n\n    StringBuilder sbuff = new StringBuilder();\n\n    // column layout, first sort by col\n    Collections.sort(layoutComponents, new Comparator<LayoutComponent>() {\n      public int compare(LayoutComponent o1, LayoutComponent o2) {\n        return o1.col - o2.col;\n      }\n      public boolean equals(Object o1) { return o1 == this; }\n    });\n\n    // now create column layout spec and x cell constraint\n    sbuff.setLength(0);\n    int currCol = -1;\n    Iterator iter = layoutComponents.iterator();\n    while (iter.hasNext()) {\n      LayoutComponent lc = (LayoutComponent) iter.next();\n      if (lc.col > currCol) {\n        if (currCol >= 0)\n          sbuff.append(\", 5dlu, \");\n        else\n          sbuff.append(\"3dlu, \");\n        sbuff.append( \"right:default, 3dlu, default:grow\");\n        currCol += 2;\n      }\n      lc.ccLabel.gridX = 2*lc.col+2;\n      lc.cc.gridX = 2*lc.col+4;\n    }\n    String colSpec = sbuff.toString();\n    if (debugLayout) System.out.println(\" column layout = \"+ colSpec);\n    int ncols = 2*currCol;\n\n    // row layout, first sort by row\n    Collections.sort(layoutComponents, new Comparator<LayoutComponent>() {\n      public int compare(LayoutComponent o1, LayoutComponent o2) {\n        return o1.row - o2.row;\n      }\n      public boolean equals(Object o1) { return o1 == this; }\n    });\n\n    // now adjust for any headings, put into y cell constraint\n    int incr = 0;\n    iter = layoutComponents.iterator();\n    while (iter.hasNext()) {\n      LayoutComponent lc = (LayoutComponent) iter.next();\n      if ((lc.comp instanceof String) && (lc.row > 0)) // its a header, not in first position\n        incr++; // leave space by adding a row\n\n      lc.cc.gridY = lc.row + incr + 1; // adjust downward\n      lc.ccLabel.gridY = lc.cc.gridY;\n      if (debugLayout) System.out.println(lc+\" constraint = \"+ lc.cc);\n    }\n\n    // now create row layout spec\n    sbuff.setLength(0);\n    int currRow = -1;\n    iter = layoutComponents.iterator();\n    while (iter.hasNext()) {\n      LayoutComponent lc = (LayoutComponent) iter.next();\n      while (lc.row > currRow) {\n        if ((lc.comp instanceof String) && (lc.row > 0)) {\n          sbuff.append( \", 5dlu, default\");\n        } else if ((lc.comp == null)) {\n          sbuff.append(\", \").append(lc.col).append(\"dlu\");\n        } else {\n          if (currRow >= 0) sbuff.append(\", \");\n          sbuff.append(\"default\");\n        }\n        currRow++;\n      }\n    }\n    String rowSpec = sbuff.toString();\n    if (debugLayout) System.out.println(\" row layout = \"+ rowSpec);\n\n    // the jgoodies form layout\n    FormLayout layout = new FormLayout( colSpec, rowSpec);\n\n    PanelBuilder builder = new PanelBuilder(layout);\n    builder.setDefaultDialogBorder();\n\n    CellConstraints cc = new CellConstraints();\n\n    // now add each component with correct constraint\n    iter = layoutComponents.iterator();\n    while (iter.hasNext()) {\n      LayoutComponent lc = (LayoutComponent) iter.next();\n\n      if (lc.comp instanceof Field) {\n        Field fld = (Field) lc.comp;\n        builder.addLabel( fld.getLabel()+\":\", lc.ccLabel);\n        Component comp = fld.getEditComponent();\n        if (lc.comp instanceof Field.TextArea)\n          comp= new JScrollPane( comp);\n        builder.add( comp,  lc.cc);\n      } else if (lc.comp instanceof String) {\n         String header = (String) lc.comp;\n         builder.addSeparator(header, cc.xyw(1, lc.cc.gridY, ncols));\n      }  else if (lc.comp instanceof Component) {\n         builder.add( (Component) lc.comp,  lc.cc);\n      }\n    }\n\n    mainPanel =  builder.getPanel();\n\n          JPanel buttPanel = new JPanel();\n    JButton acceptButton = new JButton(\"Apply\");\n    buttPanel.add(acceptButton, null);\n    for (JComponent auxButton : auxButtons)\n      buttPanel.add( auxButton, null);\n\n      // button listeners\n    acceptButton.addActionListener(new ActionListener() {\n      public void actionPerformed(ActionEvent evt) {\n        accept();\n      }\n    });\n\n    setLayout( new BorderLayout());\n    add(mainPanel, BorderLayout.CENTER);\n\n    if (addButtons) {\n      if (where.equals( BorderLayout.SOUTH)) {\n        JPanel south = new JPanel();\n        south.setLayout(new BoxLayout( south, BoxLayout.Y_AXIS));\n        south.add( new JSeparator(SwingConstants.HORIZONTAL));\n        south.add( buttPanel);\n        add( south, BorderLayout.SOUTH);\n      } else\n        add(buttPanel, where);\n    }\n\n    finished = true;\n  }",
        "variable": "buttPanel",
        "reference": "button panel",
        "explanation_by_ours": "the panel to finish",
        "explanation_by_baseline": "add buttons to the panel"
    },
    {
        "id": 1574,
        "method": "void addToNetcdfFile(NetcdfFile ncfile, Group g) {\n    if (!isVertDimensionUsed()) {\n      typicalRecord = null; // allow gc\n      return;\n    }\n\n    if (g == null) {\n      g = ncfile.getRootGroup();\n    }\n\n    // coordinate axis\n    Variable v = new Variable(ncfile, g, null, getVariableName());\n    v.setDataType(DataType.DOUBLE);\n\n    String desc =  getLevelDesc();\n    v.addAttribute(new Attribute(\"long_name\", desc));\n    v.addAttribute(new Attribute(\"units\", lookup.getLevelUnit(typicalRecord)));\n\n    // positive attribute needed for CF-1 Height and Pressure\n    if (positive != null) {\n      v.addAttribute(new Attribute(\"positive\", positive));\n    }\n\n    if (units != null) {\n      AxisType axisType;\n      if (SimpleUnit.isCompatible(\"millibar\", units)) {\n        axisType = AxisType.Pressure;\n      } else if (SimpleUnit.isCompatible(\"m\", units)) {\n        axisType = AxisType.Height;\n      } else {\n        axisType = AxisType.GeoZ;\n      }\n\n      addExtraAttributes(v);\n      v.addAttribute(new Attribute(_Coordinate.AxisType, axisType.toString()));\n    }\n\n    if (coordValues == null) {\n      coordValues = new double[levels.size()];\n      for (int i = 0; i < levels.size(); i++) {\n        LevelCoord lc = (LevelCoord) levels.get(i);\n        coordValues[i] = lc.mid;\n      }\n    }\n    Array dataArray = Array.factory(DataType.DOUBLE, new int[]{coordValues.length}, coordValues);\n\n    v.setDimensions(getVariableName());\n    v.setCachedData(dataArray, true);\n\n    ncfile.addVariable(g, v);\n\n    if (usesBounds) {\n      Dimension bd = ucar.nc2.dataset.DatasetConstructor.getBoundsDimension(ncfile);\n\n      String bname = getVariableName() + \"_bounds\";\n      v.addAttribute(new Attribute(\"bounds\", bname));\n      v.addAttribute(new Attribute(_Coordinate.ZisLayer, \"true\"));\n\n      Variable b = new Variable(ncfile, g, null, bname);\n      b.setDataType(DataType.DOUBLE);\n      b.setDimensions(getVariableName() + \" \" + bd.getShortName());\n      b.addAttribute(new Attribute(\"long_name\",\n          \"bounds for \" + v.getFullName()));\n      b.addAttribute(new Attribute(\"units\",\n          lookup.getLevelUnit(typicalRecord)));\n\n      Array boundsArray = Array.factory(DataType.DOUBLE,\n          new int[]{coordValues.length,\n              2});\n      ucar.ma2.Index ima = boundsArray.getIndex();\n      for (int i = 0; i < coordValues.length; i++) {\n        LevelCoord lc = (LevelCoord) levels.get(i);\n        boundsArray.setDouble(ima.set(i, 0), lc.value1);\n        boundsArray.setDouble(ima.set(i, 1), lc.value2);\n      }\n      b.setCachedData(boundsArray, true);\n\n      ncfile.addVariable(g, b);\n    }\n\n    if (factors != null) {\n      // check if already created\n      if (g == null) {\n        g = ncfile.getRootGroup();\n      }\n      if ( g.findVariable ( \"hybrida\" ) != null)\n        return ;\n      v.addAttribute(new Attribute(\"standard_name\", \"atmosphere_hybrid_sigma_pressure_coordinate\" ));\n      v.addAttribute(new Attribute(\"formula_terms\", \"ap: hybrida b: hybridb ps: Pressure\" ));\n      // create  hybrid factor variables\n      // add hybrida variable\n      Variable ha = new Variable(ncfile, g, null, \"hybrida\");\n      ha.setDataType(DataType.DOUBLE);\n      ha.addAttribute(new Attribute(\"long_name\",  \"level_a_factor\" ));\n      ha.addAttribute(new Attribute(\"units\", \"\"));\n      ha.setDimensions(getVariableName());\n      // add data\n      int middle = factors.length / 2;\n      double[] adata;\n      double[] bdata;\n      if( levels.size() < middle ) { // only partial data wanted\n        adata = new double[ levels.size() ];\n        bdata = new double[ levels.size() ];\n      } else {\n        adata = new double[ middle ];\n        bdata = new double[ middle ];\n      }\n      for( int i = 0; i < middle && i < levels.size(); i++ )\n        adata[ i ] = factors[ i ];\n      Array haArray = Array.factory(DataType.DOUBLE, new int[]{adata.length},adata);\n      ha.setCachedData(haArray, true);\n      ncfile.addVariable(g, ha);\n\n            Variable hb = new Variable(ncfile, g, null, \"hybridb\");\n      hb.setDataType(DataType.DOUBLE);\n      hb.addAttribute(new Attribute(\"long_name\",  \"level_b_factor\" ));\n      hb.addAttribute(new Attribute(\"units\", \"\"));\n      hb.setDimensions(getVariableName());\n      // add data\n      for( int i = 0; i < middle && i < levels.size(); i++ )\n        bdata[ i ] = factors[ i + middle ];\n      Array hbArray = Array.factory(DataType.DOUBLE, new int[]{bdata.length},bdata);\n      hb.setCachedData(hbArray, true);\n      ncfile.addVariable(g, hb);\n\n\n      /*  // TODO: delete next time modifying code\n      double[] adata = new double[ middle ];\n      for( int i = 0; i < middle; i++ )\n        adata[ i ] = factors[ i ];\n      Array haArray = Array.factory(DataType.DOUBLE, new int[]{adata.length}, adata);\n      ha.setCachedData(haArray, true);\n      ncfile.addVariable(g, ha);\n\n            Variable hb = new Variable(ncfile, g, null, \"hybridb\");\n      hb.setDataType(DataType.DOUBLE);\n      hb.addAttribute(new Attribute(\"long_name\",  \"level_b_factor\" ));\n      //hb.addAttribute(new Attribute(\"standard_name\", \"atmosphere_hybrid_sigma_pressure_coordinate\" ));\n      hb.addAttribute(new Attribute(\"units\", \"\"));\n      hb.setDimensions(getVariableName());\n      // add data\n      double[] bdata = new double[ middle ];\n      for( int i = 0; i < middle; i++ )\n        bdata[ i ] = factors[ i + middle ];\n      Array hbArray = Array.factory(DataType.DOUBLE, new int[]{bdata.length}, bdata);\n      hb.setCachedData(hbArray, true);\n      ncfile.addVariable(g, hb);\n      */\n    }\n\n    // allow gc\n    // typicalRecord = null;\n  }",
        "variable": "hb",
        "reference": "hybridb variable",
        "explanation_by_ours": "How the variable should be added to the NetCDF file",
        "explanation_by_baseline": "hybridb variable="
    },
    {
        "id": 1578,
        "method": "public void setSelected( VariableIF v ) {\r\n        if (v == null) { return; }\r\n\r\n                final List<VariableIF> vchain = new ArrayList<>();\r\n        vchain.add( v);\r\n\r\n        VariableIF vp = v;\r\n        while (vp.isMemberOfStructure()) {\r\n            vp = vp.getParentStructure();\r\n            vchain.add( 0, vp); // reverse\r\n        }\r\n\r\n        // construct chain of groups\r\n        final List<Group> gchain = new ArrayList<>();\r\n        Group gp = vp.getParentGroup();\r\n\r\n        gchain.add( gp);\r\n        while (gp.getParentGroup() != null) {\r\n            gp = gp.getParentGroup();\r\n            gchain.add( 0, gp); // reverse\r\n        }\r\n\r\n        final List<Object> pathList = new ArrayList<>();\r\n\r\n        // start at root, work down through the nested groups, if any\r\n        GroupNode gnode = (GroupNode) model.getRoot();\r\n        pathList.add( gnode);\r\n        Group parentGroup = gchain.get(0); // always the root group\r\n\r\n        for (int i=1; i < gchain.size(); i++) {\r\n            parentGroup = gchain.get(i);\r\n            gnode = gnode.findNestedGroup( parentGroup);\r\n            assert gnode != null;\r\n            pathList.add( gnode);\r\n        }\r\n\r\n        vp = vchain.get(0);\r\n        VariableNode vnode = gnode.findNestedVariable( vp);\r\n        if (vnode == null) { return; } // not found\r\n        pathList.add( vnode);\r\n\r\n        // now work down through the structure members, if any\r\n        for (int i=1; i < vchain.size(); i++) {\r\n            vp = vchain.get(i);\r\n            vnode = vnode.findNestedVariable( vp);\r\n            if (vnode == null) { return; } // not found\r\n            pathList.add(vnode);\r\n        }\r\n\r\n        // convert to TreePath, and select it\r\n        final Object[] paths = pathList.toArray();\r\n        final TreePath treePath = new TreePath(paths);\r\n        tree.setSelectionPath( treePath);\r\n        tree.scrollPathToVisible( treePath);\r\n    }",
        "variable": "vchain",
        "reference": "chain of variables",
        "explanation_by_ours": "the variable chain",
        "explanation_by_baseline": "chain of variablesfinal"
    },
    {
        "id": 1579,
        "method": "public void setSelected( VariableIF v ) {\r\n        if (v == null) { return; }\r\n\r\n        // construct chain of variables\r\n        final List<VariableIF> vchain = new ArrayList<>();\r\n        vchain.add( v);\r\n\r\n        VariableIF vp = v;\r\n        while (vp.isMemberOfStructure()) {\r\n            vp = vp.getParentStructure();\r\n            vchain.add( 0, vp); // reverse\r\n        }\r\n\r\n                final List<Group> gchain = new ArrayList<>();\r\n        Group gp = vp.getParentGroup();\r\n\r\n        gchain.add( gp);\r\n        while (gp.getParentGroup() != null) {\r\n            gp = gp.getParentGroup();\r\n            gchain.add( 0, gp); // reverse\r\n        }\r\n\r\n        final List<Object> pathList = new ArrayList<>();\r\n\r\n        // start at root, work down through the nested groups, if any\r\n        GroupNode gnode = (GroupNode) model.getRoot();\r\n        pathList.add( gnode);\r\n        Group parentGroup = gchain.get(0); // always the root group\r\n\r\n        for (int i=1; i < gchain.size(); i++) {\r\n            parentGroup = gchain.get(i);\r\n            gnode = gnode.findNestedGroup( parentGroup);\r\n            assert gnode != null;\r\n            pathList.add( gnode);\r\n        }\r\n\r\n        vp = vchain.get(0);\r\n        VariableNode vnode = gnode.findNestedVariable( vp);\r\n        if (vnode == null) { return; } // not found\r\n        pathList.add( vnode);\r\n\r\n        // now work down through the structure members, if any\r\n        for (int i=1; i < vchain.size(); i++) {\r\n            vp = vchain.get(i);\r\n            vnode = vnode.findNestedVariable( vp);\r\n            if (vnode == null) { return; } // not found\r\n            pathList.add(vnode);\r\n        }\r\n\r\n        // convert to TreePath, and select it\r\n        final Object[] paths = pathList.toArray();\r\n        final TreePath treePath = new TreePath(paths);\r\n        tree.setSelectionPath( treePath);\r\n        tree.scrollPathToVisible( treePath);\r\n    }",
        "variable": "gchain",
        "reference": "chain of groups",
        "explanation_by_ours": "the group chain",
        "explanation_by_baseline": "chain of groups//"
    },
    {
        "id": 1603,
        "method": "protected void\n    doDMR(DapRequest drq, DapContext cxt)\n            throws IOException\n    {\n        // Convert the url to an absolute path\n        String realpath = getResourcePath(drq, drq.getDatasetPath());\n\n        DSP dsp = DapCache.open(realpath, cxt);\n        DapDataset dmr = dsp.getDMR();\n\n        /* Annotate with our endianness */\n        ByteOrder order = (ByteOrder) cxt.get(Dap4Util.DAP4ENDIANTAG);\n        setEndianness(dmr, order);\n\n                CEConstraint ce = null;\n        String sce = drq.queryLookup(DapProtocol.CONSTRAINTTAG);\n        ce = CEConstraint.compile(sce, dmr);\n        setConstraint(dmr, ce);\n\n        // Provide a PrintWriter for capturing the DMR.\n        StringWriter sw = new StringWriter();\n        PrintWriter pw = new PrintWriter(sw);\n\n        // Get the DMR as a string\n        DMRPrinter dapprinter = new DMRPrinter(dmr, ce, pw, drq.getFormat());\n        if(cxt.get(Dap4Util.DAP4TESTTAG) != null)\n            dapprinter.testprint();\n        else\n            dapprinter.print();\n        pw.close();\n        sw.close();\n\n        String sdmr = sw.toString();\n        if(DEBUG)\n            System.err.println(\"Sending: DMR:\\n\" + sdmr);\n\n        addCommonHeaders(drq);// Add relevant headers\n\n        // Wrap the outputstream with a Chunk writer\n        OutputStream out = drq.getOutputStream();\n        ChunkWriter cw = new ChunkWriter(out, RequestMode.DMR, order);\n        cw.cacheDMR(sdmr);\n        cw.close();\n    }",
        "variable": "ce",
        "reference": "constraint view",
        "explanation_by_ours": "The constraint view.",
        "explanation_by_baseline": "CE constraints( ) ;"
    },
    {
        "id": 1630,
        "method": "public void restoreState(PreferencesExt store) {\n    if (store == null)\n      return;\n\n    int ncols = table.getColumnCount();\n\n    // stored column order\n    int[] modelIndex = (int[]) store.getBean(\"ColumnOrder\", null);\n\n    if ((modelIndex != null) && (modelIndex.length == ncols)) { // what about invisible ??\n\n      // make invisible any not stored\n      boolean[] visible = new boolean[ncols];\n      for (int aModelIndex : modelIndex)\n        if (aModelIndex < ncols)\n          visible[aModelIndex] = true;\n\n      // modify popup menu\n      for (int i = 0; i < ncols; i++)\n        if (!visible[i]) {\n          //System.out.println( colName[i]+\" hide \"+i);\n          acts[i].hideColumn();\n          acts[i].putValue(BAMutil.STATE, new Boolean(false));\n        }\n\n      // now set the header order\n      TableColumnModel tcm = table.getColumnModel();\n      int n = Math.min(modelIndex.length, table.getColumnCount());\n      for (int i = 0; i < n; i++) {\n        TableColumn tc = tcm.getColumn(i);\n        tc.setModelIndex(modelIndex[i]);\n        String name = model.getColumnName(modelIndex[i]);\n        tc.setHeaderValue(name);\n        tc.setIdentifier(name);\n        if (useThreads && (modelIndex[i] == threadCol)) {\n          threadHeaderRenderer = new ThreadHeaderRenderer(threadCol);\n          tc.setHeaderRenderer(threadHeaderRenderer);\n        } else\n          tc.setHeaderRenderer(new SortedHeaderRenderer(name, modelIndex[i]));\n      }\n    }\n\n        Object colWidths = store.getBean(\"ColumnWidths\", null);\n    if (colWidths == null)\n      return;\n    int[] size = (int[]) colWidths;\n    setColumnWidths(size);\n\n    if (debug) {\n      System.out.println(\" read widths = \");\n      for (int aSize : size)\n        System.out.print(\" \" + aSize);\n      System.out.println();\n    }\n\n    boolean isThreadsOn = store.getBoolean(\"isThreadsOn\", false);\n    if (useThreads) {\n      model.setThreadsOn(isThreadsOn);\n      threadHeaderRenderer.setOn(isThreadsOn);\n    }\n\n    int colNo = store.getInt(\"SortOnCol\", 0);\n    boolean reverse = store.getBoolean(\"SortReverse\", false);\n    model.setSortCol(colNo);\n    model.setReverse(reverse);\n    setSortCol(colNo, reverse);\n\n    model.sort();\n    table.fireDataChanged();\n  }\n\n  private void setColumnWidths(int[] sizes) {\n    TableColumnModel tcm = table.getColumnModel();\n    for (int i = 0; i < table.getColumnCount(); i++) {\n      TableColumn tc = tcm.getColumn(i);\n      int maxw = ((sizes == null) || (i >= sizes.length)) ? 10 : sizes[i];\n      //     model.getPreferredWidthForColumn(tc) : sizes[i];\n      tc.setPreferredWidth(maxw);\n    }\n    //table.sizeColumnsToFit(0);     //  must be called due to a JTable bug\n  }\n\n  public void setColOn(int colno, boolean state, int pos) {\n    // System.out.println(\"setColOn \"+colno+\" \"+state+\" \"+pos);\n    acts[colno].putValue(BAMutil.STATE, new Boolean(state));\n    if (state)\n      acts[colno].addAtPos(pos);\n    else\n      acts[colno].hideColumn();\n  }",
        "variable": "colWidths",
        "reference": "the column widths",
        "explanation_by_ours": "the column widths to restore.",
        "explanation_by_baseline": "the column widthsif ("
    },
    {
        "id": 1655,
        "method": "protected TableConfig getStationConfig(NetcdfDataset ds, EncodingInfo info, Formatter errlog) throws IOException {\r\n    if (!identifyEncodingStation(ds, info, CF.FeatureType.timeSeries, errlog))\r\n      return null;\r\n\r\n        TableConfig stnTable = makeStationTable(ds, FeatureType.STATION, info, errlog);\r\n    if (stnTable == null) return null;\r\n\r\n    Dimension obsDim = info.childDim;\r\n    TableConfig obsTable = null;\r\n    switch (info.encoding) {\r\n      case single:\r\n        obsTable = makeSingle(ds, obsDim, errlog);\r\n        break;\r\n\r\n      case multidim:\r\n        obsTable = makeMultidimInner(ds, stnTable, info.childDim, info, errlog);\r\n        if (info.time.getRank() == 1) { // join time(time)\r\n          obsTable.addJoin(new JoinArray(info.time, JoinArray.Type.raw, 0));\r\n          obsTable.time = info.time.getFullName();\r\n        }\r\n        break;\r\n\r\n      case raggedContiguous:\r\n        stnTable.numRecords = info.ragged_rowSize.getFullName();\r\n        obsTable = makeRaggedContiguousChildTable(ds, info.parentDim, info.childDim, info.childStruct, errlog);\r\n        break;\r\n\r\n      case raggedIndex:\r\n        obsTable = makeRaggedIndexChildTable(ds, info.parentDim, info.childDim, info.ragged_parentIndex, errlog);\r\n        break;\r\n\r\n      case flat:\r\n        info.set(Encoding.flat, obsDim);\r\n        obsTable = makeStructTable(ds, FeatureType.STATION, info, errlog);\r\n        obsTable.parentIndex = (info.instanceId == null) ? null : info.instanceId.getFullName();\r\n        Variable stnIdVar = Evaluator.findVariableWithAttributeAndDimension(ds, CF.CF_ROLE, CF.STATION_ID, obsDim, errlog);\r\n        if (stnIdVar == null)\r\n          stnIdVar = Evaluator.findVariableWithAttributeAndDimension(ds, CF.STANDARD_NAME, CF.STATION_ID, obsDim, errlog);\r\n        obsTable.stnId = (stnIdVar == null) ? null : stnIdVar.getFullName();\r\n        obsTable.stnDesc = Evaluator.findNameOfVariableWithAttributeValue(ds, CF.STANDARD_NAME, CF.PLATFORM_NAME);\r\n        if (obsTable.stnDesc == null)\r\n          obsTable.stnDesc = Evaluator.findNameOfVariableWithAttributeValue(ds, CF.STANDARD_NAME, CF.STATION_DESC);\r\n        obsTable.stnWmoId = Evaluator.findNameVariableWithStandardNameAndDimension(ds, CF.STATION_WMOID, obsDim, errlog);\r\n        obsTable.stnAlt = Evaluator.findNameVariableWithStandardNameAndDimension(ds, CF.SURFACE_ALTITUDE, obsDim, errlog);\r\n        if (obsTable.stnAlt == null)\r\n          obsTable.stnAlt = Evaluator.findNameVariableWithStandardNameAndDimension(ds, CF.STATION_ALTITUDE, obsDim, errlog);\r\n        break;\r\n    }\r\n    if (obsTable == null) return null;\r\n\r\n    stnTable.addChild(obsTable);\r\n    return stnTable;\r\n  }",
        "variable": "stnTable",
        "reference": "station table",
        "explanation_by_ours": "The station table.",
        "explanation_by_baseline": "the station table //="
    },
    {
        "id": 1660,
        "method": "protected boolean identifyEncodingStation(NetcdfDataset ds, EncodingInfo info, CF.FeatureType ftype, Formatter errlog) {\r\n        Dimension obsDim = null;\r\n    if (info.time.getRank() > 0)\r\n      obsDim = info.time.getDimension(info.time.getRank() - 1); // may be time(time) or time(stn, obs)\r\n    else if (info.time.getParentStructure() != null) {\r\n      Structure parent = info.time.getParentStructure();       obsDim = parent.getDimension(parent.getRank() - 1);\r\n    }\r\n    if (obsDim == null) {\r\n      errlog.format(\"CFpointObs: must have a non-scalar Time coordinate%n\");\r\n      return false;\r\n    }\r\n\r\n    // find the station dimension\r\n    if (info.lat.getRank() == 0) {// scalar means single\r\n      info.set(Encoding.single, null, obsDim);\r\n      return true;\r\n    }\r\n\r\n    Dimension stnDim = info.lat.getDimension(0);\r\n    if (obsDim == stnDim) {\r\n      info.set(Encoding.flat, null, obsDim); // not used ?\r\n      return true;\r\n    }\r\n\r\n    // the raggeds\r\n    if (identifyRaggeds(ds, info, stnDim, obsDim, errlog))\r\n      return true;\r\n\r\n    // heres whats left\r\n    if (info.lat.getRank() == 1) {\r\n      //Encoding e = (info.time.getParentStructure() != null) ? Encoding.multiStructure : Encoding.multidim;\r\n      info.set(Encoding.multidim, stnDim, obsDim);\r\n      return true;\r\n    }\r\n\r\n    errlog.format(\"CFpointObs: %s Must have Lat/Lon coordinates of rank 0 or 1%n\", ftype);\r\n    return false;\r\n  }",
        "variable": "obsDim",
        "reference": "the obs dimension",
        "explanation_by_ours": "the obs dimension",
        "explanation_by_baseline": "the time axisinfo."
    },
    {
        "id": 1699,
        "method": "public void open(GridIndex index, GridTableLookup lookup, int version,\n                   NetcdfFile ncfile, CancelTask cancelTask) throws IOException {\n\n    // create the HorizCoord Systems : one for each gds\n    List<GridDefRecord> hcsList = index.getHorizCoordSys();\n    boolean needGroups = (hcsList.size() > 1);\n    for (GridDefRecord gds : hcsList) {\n      Group g = null;\n      if (needGroups) {\n        g = new Group(ncfile, null, gds.getGroupName());\n        ncfile.addGroup(null, g);\n      }\n      // (GridDefRecord gdsIndex, String grid_name, String shape_name, Group g)\n      GridHorizCoordSys hcs = makeGridHorizCoordSys(gds, lookup, g);\n      hcsHash.put(gds.getParam(GridDefRecord.GDS_KEY), hcs);\n    }\n\n    // run through each record\n    GridRecord firstRecord = null;\n    List<GridRecord> records = index.getGridRecords();\n\n    for (GridRecord gridRecord : records) {\n      if (firstRecord == null) {\n        firstRecord = gridRecord;\n      }\n\n      GridHorizCoordSys hcs =  hcsHash.get(gridRecord.getGridDefRecordId());\n      int cdmHash = gridRecord.cdmVariableHash();\n      GridVariable pv = hcs.varHash.get(cdmHash);\n      if (null == pv) {\n        String name = gridRecord.cdmVariableName(lookup, true, true);\n        pv = makeGridVariable(indexFilename, name, hcs, lookup);\n        hcs.varHash.put(cdmHash, pv);\n\n        // keep track of all products with same parameter name == \"simple name\"\n        String simpleName = gridRecord.getParameterDescription();\n        List<GridVariable> plist = hcs.productHash.get(simpleName);\n        if (null == plist) {\n          plist = new ArrayList<>();\n          hcs.productHash.put(simpleName, plist);\n        }\n        plist.add(pv);\n\n      } /* else if ( lookup instanceof Grib2GridTableLookup ) {\n        Grib2GridTableLookup g2lookup = (Grib2GridTableLookup) lookup;\n        // check for non interval pv and interval record which needs a interval pv\n        if( ! pv.isInterval() && g2lookup.isInterval(gridRecord) ) {\n                    String interval = name +\"_interval\";\n          pv = (GridVariable) hcs.varHash.get(interval);\n          if (null == pv) {\n            pv = new GridVariable(interval, hcs, lookup);\n            hcs.varHash.put(cdmHash, pv);\n            String simpleName = makeVariableName(gridRecord, lookup, false, true); // LOOK may not be a good idea\n            List<GridVariable> plist = hcs.productHash.get(simpleName);\n            if (null == plist) {\n              plist = new ArrayList<GridVariable>();\n              hcs.productHash.put(simpleName, plist);\n            }\n            plist.add(pv);\n          }\n\n        } else if ( pv.isInterval() && !g2lookup.isInterval(gridRecord)  ) {\n          // make a non-interval variable\n          // logger.info( \"Non-Interval records for %s%n\", pv.getName());  LOOK\n            continue;\n        }\n      } // grid2 */\n\n      pv.addProduct(gridRecord);\n    }\n\n    // global CF Conventions\n    // Conventions attribute change must be in sync with CDM code\n    ncfile.addAttribute(null, new Attribute(\"Conventions\", \"CF-1.4\"));\n\n    addExtraAttributes(firstRecord, lookup, ncfile);\n\n    // CF Global attributes\n    ncfile.addAttribute(null, new Attribute(\"title\", lookup.getTitle()));\n    if (lookup.getInstitution() != null)\n      ncfile.addAttribute(null, new Attribute(\"institution\", lookup.getInstitution()));\n    String source = lookup.getSource();\n    if ( source != null && ! source.startsWith( \"Unknown\"))\n      ncfile.addAttribute(null, new Attribute(\"source\", source));\n    // String now = formatter.toDateTimeStringISO( Calendar.getInstance().getTime());\n    ncfile.addAttribute(null, new Attribute(\"history\", \"Direct read of \"+ lookup.getGridType() +\" into NetCDF-Java 4 API\"));\n    if ( lookup.getComment() != null)\n      ncfile.addAttribute(null, new Attribute(\"comment\", lookup.getComment()));\n\n    // dataset discovery\n    //if ( center != null)\n    //  ncfile.addAttribute(null, new Attribute(\"center_name\", center));\n\n    // CDM attributes\n    ncfile.addAttribute(null, new Attribute(CF.FEATURE_TYPE, FeatureType.GRID.toString()));\n    ncfile.addAttribute(null, new Attribute(\"file_format\", lookup.getGridType()));\n    // ncfile.addAttribute(null, new Attribute(\"location\", ncfile.getLocation()));\n    ncfile.addAttribute(null, new Attribute(_Coordinate.ModelRunDate,\n            formatter.toDateTimeStringISO(lookup.getFirstBaseTime())));\n\n    /* if (fmrcCoordSys != null) {\n      makeDefinedCoordSys(ncfile, lookup, fmrcCoordSys);\n    } else {\n      makeDenseCoordSys(ncfile, lookup, cancelTask);\n    } */\n    makeDenseCoordSys(ncfile, lookup, cancelTask);\n\n    if (GridServiceProvider.debugMissing) {\n      try (Formatter f = new Formatter(System.out)) {\n        int count = 0;\n        Collection<GridHorizCoordSys> hcset = hcsHash.values();\n        for (GridHorizCoordSys hcs : hcset) {\n          List<GridVariable> gribvars = new ArrayList<>(hcs.varHash.values());\n          for (GridVariable gv : gribvars) {\n            count += gv.showMissingSummary(f);\n          }\n        }\n        System.out.println(\" total missing= \" + count);\n      }\n    }\n\n    if (GridServiceProvider.debugMissingDetails) {\n      Formatter f = new Formatter();\n      Collection<GridHorizCoordSys> hcset = hcsHash.values();\n      for (GridHorizCoordSys hcs : hcset) {\n        f.format(\"******** Horiz Coordinate= %s%n\", hcs.getGridName());\n\n        String lastVertDesc = null;\n        List<GridVariable> gribvars = new ArrayList<>(hcs.varHash.values());\n        Collections.sort(gribvars, new CompareGridVariableByVertName());\n\n        for (GridVariable gv : gribvars) {\n          String vertDesc = gv.getVertName();\n          if (!vertDesc.equals(lastVertDesc)) {\n            f.format(\"---Vertical Coordinate= %s%n\", vertDesc);\n            lastVertDesc = vertDesc;\n          }\n          gv.showMissing(f);\n        }\n      }\n    }\n\n    // clean out stuff we dont need anymore\n    //for (GridHorizCoordSys ghcs : hcsHash.values()) {\n    //  ghcs.empty();\n    //}\n  }",
        "variable": "interval",
        "reference": "the interval variable",
        "explanation_by_ours": "The interval of the grids in the index.",
        "explanation_by_baseline": "= new ArrayList<>();"
    },
    {
        "id": 1731,
        "method": "public DatasetScanConfig readDatasetScanConfig(Element dsElem) {\n    DatasetScanConfig result = new DatasetScanConfig();\n\n    result.name = dsElem.getAttributeValue(\"name\");\n    result.path = StringUtil2.trim(dsElem.getAttributeValue(\"path\"), '/');\n    if (result.path == null) {\n      errlog.format(\"ERROR: must specify path attribute.%n\");\n      fatalError = true;\n    }\n\n    String scanDir = dsElem.getAttributeValue(\"location\");\n    if (scanDir == null) {\n      errlog.format(\"ERROR: must specify directory root in location attribute.%n\");\n      fatalError = true;\n    } else {\n      result.scanDir = AliasTranslator.translateAlias(scanDir);\n      File scanFile = new File(result.scanDir);\n      if (!scanFile.exists()) {\n        errlog.format(\"ERROR: directory %s does not exist%n\", result.scanDir);\n        fatalError = true;\n      }\n    }\n\n    result.restrictAccess = dsElem.getAttributeValue(\"restrictAccess\");\n\n    // look for ncml\n    Element ncmlElem = dsElem.getChild(\"netcdf\", Catalog.defNS);\n    if (ncmlElem != null) {\n      ncmlElem.detach();\n      result.ncmlElement = ncmlElem;\n    }\n\n        Element filterElem = dsElem.getChild(\"filter\", Catalog.defNS);\n    result.filters = readDatasetScanFilter(filterElem);\n\n    // Read namer element\n    Element namerElem = dsElem.getChild(\"namer\", Catalog.defNS);\n    result.namers = readDatasetScanNamer(namerElem);\n\n    // Read filesSort or sort element\n    Element filesSortElem = dsElem.getChild(\"filesSort\", Catalog.defNS);\n    if (filesSortElem != null)\n      result.isSortIncreasing = readFilesSort(filesSortElem);\n    Element sorterElem = dsElem.getChild(\"sort\", Catalog.defNS);\n    if (!result.isSortIncreasing.isPresent() && sorterElem != null)\n      result.isSortIncreasing = readSort(sorterElem);\n\n    // Deal with latest\n    String addLatestAttribute = dsElem.getAttributeValue(\"addLatest\");\n    Element addLatestElem = dsElem.getChild(\"addLatest\", Catalog.defNS);      // not in docs\n    Element addProxiesElem = dsElem.getChild(\"addProxies\", Catalog.defNS);\n    result.addLatest = readDatasetScanAddProxies(addProxiesElem, addLatestElem, addLatestAttribute);\n\n    /* Read addDatasetSize element.\n    Element addDsSizeElem = dsElem.getChild(\"addDatasetSize\", Catalog.defNS);\n    if (addDsSizeElem != null) {                                               // docs: default true\n      if (addDsSizeElem.getTextNormalize().equalsIgnoreCase(\"false\"))\n        result.addDatasetSize = false;\n    } */\n\n    // Read addTimeCoverage element.\n    Element addTimeCovElem = dsElem.getChild(\"addTimeCoverage\", Catalog.defNS);\n    if (addTimeCovElem != null) {\n      result.addTimeCoverage = readDatasetScanAddTimeCoverage(addTimeCovElem);\n    }\n\n    return result;\n  }",
        "variable": "filterElem",
        "reference": "the filter element",
        "explanation_by_ours": "XML element to read from.",
        "explanation_by_baseline": "if (dsElem.get"
    },
    {
        "id": 1732,
        "method": "public DatasetScanConfig readDatasetScanConfig(Element dsElem) {\n    DatasetScanConfig result = new DatasetScanConfig();\n\n    result.name = dsElem.getAttributeValue(\"name\");\n    result.path = StringUtil2.trim(dsElem.getAttributeValue(\"path\"), '/');\n    if (result.path == null) {\n      errlog.format(\"ERROR: must specify path attribute.%n\");\n      fatalError = true;\n    }\n\n    String scanDir = dsElem.getAttributeValue(\"location\");\n    if (scanDir == null) {\n      errlog.format(\"ERROR: must specify directory root in location attribute.%n\");\n      fatalError = true;\n    } else {\n      result.scanDir = AliasTranslator.translateAlias(scanDir);\n      File scanFile = new File(result.scanDir);\n      if (!scanFile.exists()) {\n        errlog.format(\"ERROR: directory %s does not exist%n\", result.scanDir);\n        fatalError = true;\n      }\n    }\n\n    result.restrictAccess = dsElem.getAttributeValue(\"restrictAccess\");\n\n    // look for ncml\n    Element ncmlElem = dsElem.getChild(\"netcdf\", Catalog.defNS);\n    if (ncmlElem != null) {\n      ncmlElem.detach();\n      result.ncmlElement = ncmlElem;\n    }\n\n    // Read filter element\n    Element filterElem = dsElem.getChild(\"filter\", Catalog.defNS);\n    result.filters = readDatasetScanFilter(filterElem);\n\n        Element namerElem = dsElem.getChild(\"namer\", Catalog.defNS);\n    result.namers = readDatasetScanNamer(namerElem);\n\n    // Read filesSort or sort element\n    Element filesSortElem = dsElem.getChild(\"filesSort\", Catalog.defNS);\n    if (filesSortElem != null)\n      result.isSortIncreasing = readFilesSort(filesSortElem);\n    Element sorterElem = dsElem.getChild(\"sort\", Catalog.defNS);\n    if (!result.isSortIncreasing.isPresent() && sorterElem != null)\n      result.isSortIncreasing = readSort(sorterElem);\n\n    // Deal with latest\n    String addLatestAttribute = dsElem.getAttributeValue(\"addLatest\");\n    Element addLatestElem = dsElem.getChild(\"addLatest\", Catalog.defNS);      // not in docs\n    Element addProxiesElem = dsElem.getChild(\"addProxies\", Catalog.defNS);\n    result.addLatest = readDatasetScanAddProxies(addProxiesElem, addLatestElem, addLatestAttribute);\n\n    /* Read addDatasetSize element.\n    Element addDsSizeElem = dsElem.getChild(\"addDatasetSize\", Catalog.defNS);\n    if (addDsSizeElem != null) {                                               // docs: default true\n      if (addDsSizeElem.getTextNormalize().equalsIgnoreCase(\"false\"))\n        result.addDatasetSize = false;\n    } */\n\n    // Read addTimeCoverage element.\n    Element addTimeCovElem = dsElem.getChild(\"addTimeCoverage\", Catalog.defNS);\n    if (addTimeCovElem != null) {\n      result.addTimeCoverage = readDatasetScanAddTimeCoverage(addTimeCovElem);\n    }\n\n    return result;\n  }",
        "variable": "namerElem",
        "reference": "the namer element",
        "explanation_by_ours": "XML element to read from.",
        "explanation_by_baseline": "if (dsElem.get"
    },
    {
        "id": 1741,
        "method": "public void doGetDDX(ReqState rs)\n            throws Exception\n    {\n        if(Debug.isSet(\"showResponse\")) {\n            log.debug(\"doGetDDX for dataset: \" + rs.getDataSet());\n        }\n\n        GuardedDataset ds = null;\n        try {\n            ds = getDataset(rs);\n            if(null == ds) return;\n\n            rs.getResponse().setContentType(\"text/plain\");\n            rs.getResponse().setHeader(\"XDODS-Server\", getServerVersion());\n            rs.getResponse().setHeader(\"Content-Description\", \"dods-ddx\");\n            // Commented because of a bug in the OPeNDAP C++ stuff...\n            // rs.getResponse().setHeader(\"Content-Encoding\", \"plain\");\n\n            OutputStream Out = new BufferedOutputStream(rs.getResponse().getOutputStream());\n\n            // Utilize the getDDS() method to get a parsed and populated DDS\n            // for this server.\n            ServerDDS myDDS = ds.getDDS();\n\n            if(rs.getConstraintExpression().equals(\"\")) { // No Constraint Expression?\n                // Send the whole DDS\n                myDDS.printXML(Out);\n                Out.flush();\n            } else { // Otherwise, send the constrained DDS\n\n                                CEEvaluator ce = new CEEvaluator(myDDS);\n                ce.parseConstraint(rs);\n\n                // Send the constrained DDS back to the client\n                PrintWriter pw = new PrintWriter(new OutputStreamWriter(Out, Util.UTF8));\n                myDDS.printConstrainedXML(pw);\n                pw.flush();\n            }\n\n            rs.getResponse().setStatus(HttpServletResponse.SC_OK);\n            if(Debug.isSet(\"showResponse\")) {\n                if(rs.getConstraintExpression().equals(\"\")) { // No Constraint Expression?\n//          log.debug(\"Unconstrained DDX=\\n\");\n//          myDDS.printXML(System.out);\n                } else {\n//          log.debug(\"Constrained DDX=\\n\");\n//          myDDS.printConstrainedXML(System.out);\n                }\n            }\n        } catch (ParseException pe) {\n            parseExceptionHandler(pe, rs.getResponse());\n        } catch (DAP2Exception de) {\n            dap2ExceptionHandler(de, rs.getResponse());\n        } catch (IOException pe) {\n            IOExceptionHandler(pe, rs);\n        } catch (Throwable t) {\n            anyExceptionHandler(t, rs);\n        } finally { // release lock if needed\n            if(ds != null) ds.release();\n        }\n\n    }",
        "variable": "ce",
        "reference": "the constraint expression",
        "explanation_by_ours": "The CEEvaluator to use to parse the constraint expression.",
        "explanation_by_baseline": "the constraint for this server"
    },
    {
        "id": 1765,
        "method": "public List<NamedObject> getNames() {\n    int n = getDimension(0).getLength();\n    List<NamedObject> names = new ArrayList<>(n);\n    for (int i = 0; i < n; i++)\n      names.add(new ucar.nc2.util.NamedAnything(getCoordName(i), getShortName() + \" \" + getUnitsString()));\n    return names;\n  }\n\n  /**\n   * The \"name\" of the ith coordinate. If nominal, this is all there is to a coordinate.\n   * If numeric, this will return a String representation of the coordinate.\n   *\n   * @param index which one ?\n   * @return the ith coordinate value as a String\n   */\n  public String getCoordName(int index) {\n    if (!wasRead) doRead();\n    if (isNumeric())\n      return Format.d(getCoordValue(index), 5, 8);\n    else\n      return names[index];\n  }\n\n  /**\n   * Get the ith coordinate value. This is the value of the coordinate axis at which\n   * the data value is associated. These must be strictly monotonic.\n   *\n   * @param index which coordinate. Between 0 and getNumElements()-1 inclusive.\n   * @return coordinate value.\n   * @throws UnsupportedOperationException if !isNumeric()\n   */\n  public double getCoordValue(int index) {\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis1D.getCoordValue() on non-numeric\");\n    if (!wasRead) doRead();\n    return coords[index];\n  }\n\n  @Override\n  public double getMinValue() {\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis1D.getCoordValue() on non-numeric\");\n    if (!wasRead) doRead();\n\n    return Math.min(coords[0], coords[coords.length - 1]);\n  }\n\n  @Override\n  public double getMaxValue() {\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis1D.getCoordValue() on non-numeric\");\n    if (!wasRead) doRead();\n\n    return Math.max(coords[0], coords[coords.length - 1]);\n  }\n\n  public double getMinEdgeValue() {\n    if (edge == null) return getMinValue();\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis1D.getCoordValue() on non-numeric\");\n    if (!wasRead) doRead();\n\n    return Math.min(edge[0], edge[edge.length - 1]);\n  }\n\n  public double getMaxEdgeValue() {\n    if (edge == null) return getMaxValue();\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis1D.getCoordValue() on non-numeric\");\n    if (!wasRead) doRead();\n\n    return Math.max(edge[0], edge[edge.length - 1]);\n  }\n\n  /**\n   * Get the ith coordinate edge. Exact only if isContiguous() is true, otherwise use getBound1() and getBound2().\n   * This is the value where the underlying grid element switches\n   * from \"belonging to\" coordinate value i-1 to \"belonging to\" coordinate value i.\n   * In some grids, this may not be well defined, and so should be considered an\n   * approximation or a visualization hint.\n   * <p><pre>\n   *  Coordinate edges must be strictly monotonic:\n   *    coordEdge(0) < coordValue(0) < coordEdge(1) < coordValue(1) ...\n   *    ... coordEdge(i) < coordValue(i) < coordEdge(i+1) < coordValue(i+1) ...\n   *    ... coordEdge(n-1) < coordValue(n-1) < coordEdge(n)\n   *  </pre>\n   *\n   * @param index which coordinate. Between 0 and getNumElements() inclusive.\n   * @return coordinate edge.\n   * @throws UnsupportedOperationException if !isNumeric()\n   */\n  public double getCoordEdge(int index) {\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis1D.getCoordEdge() on non-numeric\");\n    if (!wasBoundsDone) makeBounds();\n    return edge[index];\n  }\n\n  /**\n   * Get the coordinate values as a double array.\n   *\n   * @return coordinate value.\n   * @throws UnsupportedOperationException if !isNumeric()\n   */\n  public double[] getCoordValues() {\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis1D.getCoordValues() on non-numeric\");\n    if (!wasRead) doRead();\n    return coords.clone();\n  }\n\n  /**\n   * Get the coordinate edges as a double array.\n   * Exact only if isContiguous() is true, otherwise use getBound1() and getBound2().\n   *\n   * @return coordinate edges.\n   * @throws UnsupportedOperationException if !isNumeric()\n   */\n  public double[] getCoordEdges() {\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis1D.getCoordEdges() on non-numeric\");\n    if (!wasBoundsDone) makeBounds();\n    return edge.clone();\n  }\n\n  @Override\n  public boolean isContiguous() {\n    if (!wasBoundsDone) makeBounds();  // this sets isContiguous\n    return isContiguous;\n  }\n\n  ///////////////////////////////////////////////\n\n  /**\n   * If this coordinate has interval values.\n   * If so, then one should use getBound1, getBound2, and not getCoordEdges()\n   *\n   * @return true if coordinate has interval values\n   */\n  public boolean isInterval() {\n    if (!wasBoundsDone) makeBounds();      // this sets isInterval\n    return isInterval;\n  }\n\n  /**\n   * Get the coordinate bound1 as a double array.\n   * bound1[i] # coordValue[i] # bound2[i], where # is < if increasing (bound1[i] < bound1[i+1])\n   * else < if decreasing.\n   *\n   * @return coordinate bound1.\n   * @throws UnsupportedOperationException if !isNumeric()\n   */\n  public double[] getBound1() {\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis1D.getBound1() on non-numeric\");\n    if (!wasBoundsDone) makeBounds();\n    if (bound1 == null) makeBoundsFromEdges();\n    assert bound1 != null;\n    return bound1.clone();\n  }\n\n  /**\n   * Get the coordinate bound1 as a double array.\n   * bound1[i] # coordValue[i] # bound2[i],  where # is < if increasing (bound1[i] < bound1[i+1])\n   * else < if decreasing.\n   *\n   * @return coordinate bound2.\n   * @throws UnsupportedOperationException if !isNumeric()\n   */\n  public double[] getBound2() {\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis1D.getBound2() on non-numeric\");\n    if (!wasBoundsDone) makeBounds();\n    if (bound2 == null) makeBoundsFromEdges();\n    assert bound2 != null;\n    return bound2.clone();\n  }\n\n  /**\n   * Get the coordinate bounds for the ith coordinate.\n   * Can use this for isContiguous() true or false.\n   *\n   * @param i coordinate index\n   * @return double[2] edges for ith coordinate\n   */\n  public double[] getCoordBounds(int i) {\n    if (!wasBoundsDone) makeBounds();\n\n    double[] e = new double[2];\n    if (isContiguous()) {\n      e[0] = getCoordEdge(i);\n      e[1] = getCoordEdge(i + 1);\n    } else {\n      e[0] = bound1[i];\n      e[1] = bound2[i];\n    }\n    return e;\n  }\n\n  public double getCoordBoundsMidpoint(int i) {\n    double[] bounds = getCoordBounds(i);\n    return (bounds[0]+bounds[1])/2;\n  }\n\n  /**\n   * Given a coordinate value, find what grid element contains it.\n   * This means that\n   * <pre>\n   * edge[i] <= value < edge[i+1] (if values are ascending)\n   * edge[i] > value >= edge[i+1] (if values are descending)\n   * </pre>\n   *\n   * @param coordVal position in this coordinate system\n   * @return index of grid point containing it, or -1 if outside grid area\n   */\n  public int findCoordElement(double coordVal) {\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis.findCoordElement() on non-numeric\");\n\n    if (isRegular())\n      return findCoordElementRegular(coordVal, false);\n    if (isContiguous())\n      return findCoordElementIrregular(coordVal, false);\n    else\n      return findCoordElementNonContiguous(coordVal, false);\n  }\n\n  /**\n   * Given a coordinate position, find what grid element contains it, or is closest to it.\n   *\n   * @param coordVal position in this coordinate system\n   * @return index of grid point containing it, or best estimate of closest grid interval.\n   */\n  public int findCoordElementBounded(double coordVal) {\n    if (!isNumeric())\n      throw new UnsupportedOperationException(\"CoordinateAxis.findCoordElementBounded() on non-numeric\");\n\n    // the scalar or len-1 case:\n    if (this.getSize() == 1) return 0;\n\n    if (isRegular())\n      return findCoordElementRegular(coordVal, true);\n    if (isContiguous())\n      return findCoordElementIrregular(coordVal, true);\n    else\n      return findCoordElementNonContiguous(coordVal, true);\n  }\n\n  /**\n   * @deprecated use findCoordElement(coordVal)\n   */\n  public int findCoordElement(double coordVal, int lastIndex) {\n    return findCoordElement(coordVal);\n  }\n\n  //////////////////////////////////////////////////////////////////\n  // following is from Jon Blower's ncWMS\n  // faster routines for coordValue -> index search\n  // significantly modified\n\n  /**\n   * Optimize the regular case\n   * Gets the index of the given point. Uses index = (value - start) / stride,\n   * hence this is faster than an exhaustive search.\n   * from jon blower's ncWMS.\n   *\n   * @param coordValue The value along this coordinate axis\n   * @param bounded    if false and not in range, return -1, else nearest index\n   * @return the index that is nearest to this point, or -1 if the point is\n   * out of range for the axis\n   */\n  private int findCoordElementRegular(double coordValue, boolean bounded) {\n    int n = (int) this.getSize();\n\n    // the scalar or len-1 case:\n    if (this.getSize() == 1) {\n      return 0;\n    }\n\n  /*  if (axisType == AxisType.Lon) {\n      double maxValue = this.start + this.increment * n;\n      if (betweenLon(coordValue, this.start, maxValue)) {\n        double distance = LatLonPointImpl.getClockwiseDistanceTo(this.start, coordValue);\n        double exactNumSteps = distance / this.increment;\n        // This axis might wrap, so we make sure that the returned index is within range\n        return ((int) Math.round(exactNumSteps)) % (int) this.getSize();\n\n      } else if (coordValue < this.start) {\n        return bounded ? 0 : -1;\n      } else {\n        return bounded ? n - 1 : -1;\n      }\n    } */\n\n    double distance = coordValue - this.start;\n    double exactNumSteps = distance / this.increment;\n    int index = (int) Math.round(exactNumSteps);\n    if (index < 0)\n      return bounded ? 0 : -1;\n    else if (index >= n)\n      return bounded ? n - 1 : -1;\n    return index;\n  }\n\n  private boolean betweenLon(double lon, double lonBeg, double lonEnd) {\n    while (lon < lonBeg) lon += 360;\n    return (lon >= lonBeg) && (lon <= lonEnd);\n  }\n\n  /**\n   * Performs a binary search to find the index of the element of the array\n   * whose value is contained in the interval, so must be contiguous.\n   *\n   * @param target  The value to search for\n   * @param bounded if false, and not in range, return -1, else nearest index\n   * @return the index of the element in values whose value is closest to target,\n   * or -1 if the target is out of range\n   */\n  private int findCoordElementIrregular(double target, boolean bounded) {\n    int n = (int) this.getSize();\n    int low = 0;\n    int high = n;\n\n    if (isAscending) {\n      // Check that the point is within range\n      if (target < this.edge[low])\n        return bounded ? 0 : -1;\n      else if (target > this.edge[high])\n        return bounded ? n - 1 : -1;\n\n      // do a binary search to find the nearest index\n      int mid = low;\n      while (high > low + 1) {\n        mid = (low + high) / 2;\n        double midVal = this.edge[mid];\n        if (midVal == target) return mid;\n        else if (midVal < target) low = mid;\n        else high = mid;\n      }\n\n      return low;\n\n    } else {\n\n      // Check that the point is within range\n      if (target > this.edge[low])\n        return bounded ? 0 : -1;\n      else if (target < this.edge[high])\n        return bounded ? n - 1 : -1;\n\n      // do a binary search to find the nearest index\n      int mid = low;\n      while (high > low + 1) {\n        mid = (low + high) / 2;\n        double midVal = this.edge[mid];\n        if (midVal == target) return mid;\n        else if (midVal < target) high = mid;\n        else low = mid;\n      }\n\n      return high - 1;\n    }\n  }\n\n  /**\n   * Given a coordinate position, find what grid element contains it.\n   * Only use if isContiguous() == false\n   * This algorithm does a linear search in the bound1[] amd bound2[] array.\n   * <p>\n   * This means that\n   * <pre>\n   * edge[i] <= pos < edge[i+1] (if values are ascending)\n   * edge[i] > pos >= edge[i+1] (if values are descending)\n   * </pre>\n   *\n   * @param target  The value to search for\n   * @param bounded if false, and not in range, return -1, else nearest index\n   * @return the index of the element in values whose value is closest to target,\n   * or -1 if the target is out of range\n   */\n  private int findCoordElementNonContiguous(double target, boolean bounded) {\n\n    double[] bounds1 = getBound1();\n    double[] bounds2 = getBound2();\n    int n = bounds1.length;\n\n    if (isAscending) {\n      // Check that the point is within range\n      if (target < bounds1[0])\n        return bounded ? 0 : -1;\n      else if (target > bounds2[n - 1])\n        return bounded ? n - 1 : -1;\n\n      int[] idx = findSingleHit(bounds1, bounds2, target);\n      if (idx[0] == 0 && !bounded) return -1;  // no hits\n      if (idx[0] == 1) return idx[1];          // one hit\n\n      // multiple hits = choose closest to the midpoint i guess\n      return findClosest(coords, target);\n\n    } else {\n\n      // Check that the point is within range\n      if (target > bounds1[0])\n        return bounded ? 0 : -1;\n      else if (target < bounds2[n - 1])\n        return bounded ? n - 1 : -1;\n\n      int[] idx = findSingleHit(bounds2, bounds1, target);\n      if (idx[0] == 0 && !bounded) return -1;  // no hits\n      if (idx[0] == 1) return idx[1];\n\n      // multiple hits = choose closest to the midpoint i guess\n      return findClosest(getCoordValues(), target);\n    }\n  }\n\n  // return index if only one match, else -1\n  private int[] findSingleHit(double[] low, double[] high, double target) {\n    int hits = 0;\n    int idxFound = -1;\n    int n = low.length;\n    for (int i = 0; i < n; i++) {\n      if ((low[i] <= target) && (target <= high[i])) {\n        hits++;\n        idxFound = i;\n      }\n    }\n    return new int[] {hits, idxFound};\n  }\n\n  // return index of closest value to target\n  private int findClosest(double[] values, double target) {\n    double minDiff =  Double.MAX_VALUE;\n    int idxFound = -1;\n    int n = values.length;\n    for (int i = 0; i < n; i++) {\n      double diff =  Math.abs(values[i]-target);\n      if (diff < minDiff) {\n        minDiff = diff;\n        idxFound = i;\n      }\n    }\n    return idxFound;\n  }\n\n  ///////////////////////////////////////////////////////////////////////////////\n  // check if Regular\n\n  /**\n   * Get starting value if isRegular()\n   *\n   * @return starting value if isRegular()\n   */\n  public double getStart() {\n    calcIsRegular();\n    return start;\n  }\n\n  /**\n   * Get increment value if isRegular()\n   *\n   * @return increment value if isRegular()\n   */\n  public double getIncrement() {\n    calcIsRegular();\n    return increment;\n  }\n\n  /**\n   * If true, then value(i) = <i>getStart()</i> + i * <i>getIncrement()</i>.\n   *\n   * @return if evenly spaced.\n   */\n  public boolean isRegular() {\n    calcIsRegular();\n    return isRegular;\n  }\n\n  private void calcIsRegular() {\n    if (wasCalcRegular) return;\n    if (!wasRead) doRead();\n\n    if (!isNumeric())\n      isRegular = false;\n    else if (getSize() < 2)\n      isRegular = true;\n    else {\n      start = getCoordValue(0);\n      int n = (int) getSize();\n      increment = (getCoordValue(n - 1) - getCoordValue(0)) / (n - 1);\n      isRegular = true;\n      for (int i = 1; i < getSize(); i++)\n        if (!ucar.nc2.util.Misc.nearlyEquals(getCoordValue(i) - getCoordValue(i - 1), increment, 5.0e-3)) {\n          isRegular = false;\n          break;\n        }\n    }\n    wasCalcRegular = true;\n  }\n\n  ///////////////////////////////////////////////////////////////////////////////\n\n\n  private void doRead() {\n    if (isNumeric()) {\n      readValues();\n      wasRead = true;\n\n      if (getSize() < 2)\n        isAscending = true;\n      else\n        isAscending = getCoordValue(0) < getCoordValue(1);\n      //  calcIsRegular(); */\n    } else if (getDataType() == DataType.STRING) {\n      readStringValues();\n      wasRead = true;\n    } else {\n      readCharValues();\n      wasRead = true;\n    }\n  }\n\n  // turns longitude coordinate into monotonic, dealing with possible wrap.\n  public void correctLongitudeWrap() {\n    // correct non-monotonic longitude coords\n    if (axisType != AxisType.Lon) {\n      return;\n    }\n\n    if (!wasRead) doRead();\n    if (!wasBoundsDone) makeBounds();\n\n    boolean monotonic = true;\n    for (int i = 0; i < coords.length - 1; i++)\n      monotonic &= isAscending ? coords[i] < coords[i + 1] : coords[i] > coords[i + 1];\n\n    if (!monotonic) {\n      boolean cross = false;\n      if (isAscending) {\n        for (int i = 0; i < coords.length; i++) {\n          if (cross) coords[i] += 360;\n          if (!cross && (i < coords.length - 1) && (coords[i] > coords[i + 1]))\n            cross = true;\n        }\n      } else {\n        for (int i = 0; i < coords.length; i++) {\n          if (cross) coords[i] -= 360;\n          if (!cross && (i < coords.length - 1) && (coords[i] < coords[i + 1]))\n            cross = true;\n        }\n      }\n\n      // LOOK - need to make sure we get stuff from the cache\n      Array cachedData = Array.factory(DataType.DOUBLE, getShape(), coords);\n      if (getDataType() != DataType.DOUBLE)\n        cachedData = MAMath.convert(cachedData, getDataType());\n      setCachedData(cachedData);\n\n      if (!isInterval) {\n        makeEdges();\n      }\n    }\n\n  }\n\n  // only used if String\n\n  private void readStringValues() {\n    int count = 0;\n    Array data;\n    try {\n      data = read();\n    } catch (IOException ioe) {\n      log.error(\"Error reading string coordinate values \", ioe);\n      throw new IllegalStateException(ioe);\n    }\n\n    names = new String[(int) data.getSize()];\n    IndexIterator ii = data.getIndexIterator();\n    while (ii.hasNext())\n      names[count++] = (String) ii.getObjectNext();\n  }\n\n  private void readCharValues() {\n    int count = 0;\n    ArrayChar data;\n    try {\n      data = (ArrayChar) read();\n    } catch (IOException ioe) {\n      log.error(\"Error reading char coordinate values \", ioe);\n      throw new IllegalStateException(ioe);\n    }\n    ArrayChar.StringIterator iter = data.getStringIterator();\n    names = new String[iter.getNumElems()];\n    while (iter.hasNext())\n      names[count++] = iter.next();\n  }\n\n  private void readValues() {\n    Array data;\n    try {\n      // setUseNaNs(false); // missing values not allowed LOOK not true for point data !!\n      data = read();\n      // if (!hasCachedData()) setCachedData(data, false); //cache data for subsequent reading\n    } catch (IOException ioe) {\n      log.error(\"Error reading coordinate values \", ioe);\n      throw new IllegalStateException(ioe);\n    }\n\n    coords = (double []) data.get1DJavaArray(DataType.DOUBLE);\n    //IndexIterator iter = data.getIndexIterator();\n    //while (iter.hasNext())\n    //  coords[count++] = iter.getDoubleNext();\n  }\n\n  /**\n   * Calculate bounds, set isInterval, isContiguous\n   */\n  private void makeBounds() {\n    if (!wasRead) doRead();\n    if (isNumeric()) {\n      if (!makeBoundsFromAux()) {\n        makeEdges();\n      }\n    }\n    wasBoundsDone = true;\n  }\n\n  private boolean makeBoundsFromAux() {\n    Attribute boundsAtt = findAttributeIgnoreCase(CF.BOUNDS);\n    if ((null == boundsAtt) || !boundsAtt.isString()) return false;\n    String boundsVarName = boundsAtt.getStringValue();\n    VariableDS boundsVar = (VariableDS) ncd.findVariable(getParentGroup(), boundsVarName);\n    if (null == boundsVar) return false;\n    if (2 != boundsVar.getRank()) return false;\n\n    if (getDimension(0) != boundsVar.getDimension(0)) return false;\n    if (2 != boundsVar.getDimension(1).getLength()) return false;\n\n    Array data;\n    try {\n      boundsVar.removeEnhancement(NetcdfDataset.Enhance.ConvertMissing);  // Don't convert missing values to NaN.\n      data = boundsVar.read();\n    } catch (IOException e) {\n      log.warn(\"CoordinateAxis1D.hasBounds read failed \", e);\n      return false;\n    }\n\n    assert (data.getRank() == 2) && (data.getShape()[1] == 2) : \"incorrect shape data for variable \" + boundsVar;\n\n    // extract the bounds\n    int n = shape[0];\n    double[] value1 = new double[n];\n    double[] value2 = new double[n];\n    Index ima = data.getIndex();\n    for (int i = 0; i < n; i++) {\n      ima.set0(i);\n      value1[i] = data.getDouble(ima.set1(0));\n      value2[i] = data.getDouble(ima.set1(1));\n    }\n\n    /* flip if needed\n    boolean firstLower = true; // in the first interval, is lower < upper ?\n    for (int i = 0; i < value1.length; i++) {\n      if (Misc.nearlyEquals(value1[i], value2[i])) continue; // skip when lower == upper\n      firstLower = value1[i] < value2[i];\n      break;\n    }\n    // check first against last : lower, unless all lower equal then upper\n    boolean goesUp = (n < 2) || value1[n - 1] > value1[0] || (Misc.nearlyEquals(value1[n - 1], value2[0]) && value2[n - 1] > value2[0]);\n    if (goesUp != firstLower) {\n      double[] temp = value1;\n      value1 = value2;\n      value2 = temp;\n    } */\n\n        boolean contig = true;\n    for (int i = 0; i < n - 1; i++) {\n      if (!ucar.nc2.util.Misc.nearlyEquals(value1[i + 1], value2[i]))\n        contig = false;\n    }\n\n    if (contig) {\n      edge = new double[n + 1];\n      edge[0] = value1[0];\n      for (int i = 1; i < n + 1; i++)\n        edge[i] = value2[i - 1];\n    } else {                           // what does edge mean when not contiguous ??\n      edge = new double[n + 1];\n      edge[0] = value1[0];\n      for (int i = 1; i < n; i++)\n        edge[i] = (value1[i] + value2[i - 1]) / 2;\n      edge[n] = value2[n - 1];\n      isContiguous = false;\n    }\n\n    bound1 = value1;\n    bound2 = value2;\n    isInterval = true;\n\n    return true;\n  }\n\n  private void makeEdges() {\n    int size = (int) getSize();\n    edge = new double[size + 1];\n    if (size < 1) return;\n    for (int i = 1; i < size; i++)\n      edge[i] = (coords[i - 1] + coords[i]) / 2;\n    edge[0] = coords[0] - (edge[1] - coords[0]);\n    edge[size] = coords[size - 1] + (coords[size - 1] - edge[size - 1]);\n    isContiguous = true;\n  }\n\n  private void makeBoundsFromEdges() {\n    int size = (int) getSize();\n    if (size == 0) return;\n\n    bound1 = new double[size];\n    bound2 = new double[size];\n    for (int i = 0; i < size; i++) {\n      bound1[i] = edge[i];\n      bound2[i] = edge[i + 1];\n    }\n\n    // flip if needed\n    if (bound1[0] > bound2[0]) {\n      double[] temp = bound1;\n      bound1 = bound2;\n      bound2 = temp;\n    }\n  }\n\n}",
        "variable": "contig",
        "reference": "decide if they are contiguous",
        "explanation_by_ours": "the name of the coordinate axis.",
        "explanation_by_baseline": "if (n == 1)"
    },
    {
        "id": 1766,
        "method": "static public TableConfigurer getTableConfigurer(FeatureType wantFeatureType, NetcdfDataset ds) throws IOException {\r\n    String convUsed = null;\r\n\r\n        String convName = ds.findAttValueIgnoreCase(null, CDM.CONVENTIONS, null);\r\n    if (convName == null)\r\n      convName = ds.findAttValueIgnoreCase(null, \"Convention\", null);\r\n\r\n    // now search for TableConfigurer using that Convention\r\n    Configurator anal = null;\r\n    if (convName != null) {\r\n      convName = convName.trim();\r\n\r\n      // search for Convention parsing class\r\n      anal = matchConfigurator(convName);\r\n      if (anal != null) {\r\n        convUsed = convName;\r\n        if (debug) System.out.println(\"  TableConfigurer found using convName \"+convName);\r\n      }\r\n\r\n      // now search for comma or semicolon or / delimited list\r\n      if (anal == null) {\r\n        List<String> names = new ArrayList<>();\r\n\r\n        if ((convName.indexOf(',') > 0) || (convName.indexOf(';') > 0)) {\r\n          StringTokenizer stoke = new StringTokenizer(convName, \",;\");\r\n          while (stoke.hasMoreTokens()) {\r\n            String name = stoke.nextToken();\r\n            names.add(name.trim());\r\n          }\r\n        } else if ((convName.indexOf('/') > 0)) {\r\n          StringTokenizer stoke = new StringTokenizer(convName, \"/\");\r\n          while (stoke.hasMoreTokens()) {\r\n            String name = stoke.nextToken();\r\n            names.add(name.trim());\r\n          }\r\n        }\r\n\r\n        if (names.size() > 0) {\r\n          // search the registered conventions, in order\r\n          for (Configurator conv : conventionList) {\r\n            for (String name : names) {\r\n              if (name.equalsIgnoreCase(conv.convName)) {\r\n                anal = conv;\r\n                convUsed = name;\r\n                if (debug) System.out.println(\"  TableConfigurer found using convName \"+convName);\r\n              }\r\n            }\r\n            if (anal != null) break;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    // search for ones that dont use Convention attribute, in order added.\r\n    // call method isMine() using reflection.\r\n    if (anal == null) {\r\n      for (Configurator conv : conventionList) {\r\n        Class c = conv.confClass;\r\n        Method isMineMethod;\r\n\r\n        try {\r\n          isMineMethod = c.getMethod(\"isMine\", new Class[]{FeatureType.class, NetcdfDataset.class});\r\n        } catch (NoSuchMethodException ex) {\r\n          continue;\r\n        }\r\n\r\n        try {\r\n          Boolean result = (Boolean) isMineMethod.invoke(conv.confInstance, wantFeatureType, ds);\r\n          if (debug) System.out.println(\"  TableConfigurer.isMine \"+c.getName()+ \" result = \" + result);\r\n          if (result) {\r\n            anal = conv;\r\n            convUsed = conv.convName;\r\n            break;\r\n          }\r\n        } catch (Exception ex) {\r\n          System.out.println(\"ERROR: Class \" + c.getName() + \" Exception invoking isMine method%n\" + ex);\r\n        }\r\n      }\r\n    }\r\n\r\n    // Instantiate a new TableConfigurer object\r\n    TableConfigurer tc = null;\r\n    if (anal != null) {\r\n      try {\r\n        tc = (TableConfigurer) anal.confClass.newInstance();\r\n        tc.setConvName( convName);\r\n        tc.setConvUsed( convUsed);\r\n      } catch (InstantiationException | IllegalAccessException e) {\r\n        log.error(\"TableConfigurer create failed\", e);\r\n      }\r\n    }\r\n\r\n    return tc;\r\n  }",
        "variable": "convName",
        "reference": "the Conventions attribute",
        "explanation_by_ours": "the name of the Conventions attribute",
        "explanation_by_baseline": "convention attributeif ("
    },
    {
        "id": 1768,
        "method": "static public TableConfigurer getTableConfigurer(FeatureType wantFeatureType, NetcdfDataset ds) throws IOException {\r\n    String convUsed = null;\r\n\r\n    // search for the Conventions attribute\r\n    String convName = ds.findAttValueIgnoreCase(null, CDM.CONVENTIONS, null);\r\n    if (convName == null)\r\n      convName = ds.findAttValueIgnoreCase(null, \"Convention\", null);\r\n\r\n    // now search for TableConfigurer using that Convention\r\n    Configurator anal = null;\r\n    if (convName != null) {\r\n      convName = convName.trim();\r\n\r\n      // search for Convention parsing class\r\n      anal = matchConfigurator(convName);\r\n      if (anal != null) {\r\n        convUsed = convName;\r\n        if (debug) System.out.println(\"  TableConfigurer found using convName \"+convName);\r\n      }\r\n\r\n      // now search for comma or semicolon or / delimited list\r\n      if (anal == null) {\r\n        List<String> names = new ArrayList<>();\r\n\r\n        if ((convName.indexOf(',') > 0) || (convName.indexOf(';') > 0)) {\r\n          StringTokenizer stoke = new StringTokenizer(convName, \",;\");\r\n          while (stoke.hasMoreTokens()) {\r\n            String name = stoke.nextToken();\r\n            names.add(name.trim());\r\n          }\r\n        } else if ((convName.indexOf('/') > 0)) {\r\n          StringTokenizer stoke = new StringTokenizer(convName, \"/\");\r\n          while (stoke.hasMoreTokens()) {\r\n            String name = stoke.nextToken();\r\n            names.add(name.trim());\r\n          }\r\n        }\r\n\r\n        if (names.size() > 0) {\r\n          // search the registered conventions, in order\r\n          for (Configurator conv : conventionList) {\r\n            for (String name : names) {\r\n              if (name.equalsIgnoreCase(conv.convName)) {\r\n                anal = conv;\r\n                convUsed = name;\r\n                if (debug) System.out.println(\"  TableConfigurer found using convName \"+convName);\r\n              }\r\n            }\r\n            if (anal != null) break;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    // search for ones that dont use Convention attribute, in order added.\r\n    // call method isMine() using reflection.\r\n    if (anal == null) {\r\n      for (Configurator conv : conventionList) {\r\n        Class c = conv.confClass;\r\n        Method isMineMethod;\r\n\r\n        try {\r\n          isMineMethod = c.getMethod(\"isMine\", new Class[]{FeatureType.class, NetcdfDataset.class});\r\n        } catch (NoSuchMethodException ex) {\r\n          continue;\r\n        }\r\n\r\n        try {\r\n          Boolean result = (Boolean) isMineMethod.invoke(conv.confInstance, wantFeatureType, ds);\r\n          if (debug) System.out.println(\"  TableConfigurer.isMine \"+c.getName()+ \" result = \" + result);\r\n          if (result) {\r\n            anal = conv;\r\n            convUsed = conv.convName;\r\n            break;\r\n          }\r\n        } catch (Exception ex) {\r\n          System.out.println(\"ERROR: Class \" + c.getName() + \" Exception invoking isMine method%n\" + ex);\r\n        }\r\n      }\r\n    }\r\n\r\n        TableConfigurer tc = null;\r\n    if (anal != null) {\r\n      try {\r\n        tc = (TableConfigurer) anal.confClass.newInstance();\r\n        tc.setConvName( convName);\r\n        tc.setConvUsed( convUsed);\r\n      } catch (InstantiationException | IllegalAccessException e) {\r\n        log.error(\"TableConfigurer create failed\", e);\r\n      }\r\n    }\r\n\r\n    return tc;\r\n  }",
        "variable": "tc",
        "reference": "a new TableConfigurer object",
        "explanation_by_ours": "the feature type",
        "explanation_by_baseline": "the TableConfigurer using reflection"
    },
    {
        "id": 1771,
        "method": "private void makeTablesDefault(boolean structAdded) throws IOException {\r\n\r\n    // make Structures into a table\r\n    List<Variable> vars = new ArrayList<>(ds.getVariables());\r\n    Iterator<Variable> iter = vars.iterator();\r\n    while (iter.hasNext()) {\r\n      Variable v = iter.next();\r\n      if (v instanceof Structure) {  // handles Sequences too\r\n        TableConfig st = new TableConfig(Table.Type.Structure, v.getFullName());\r\n        CoordSysEvaluator.findCoords(st, ds, null);\r\n        st.structName = v.getFullName();\r\n        st.nestedTableName = v.getShortName();\r\n\r\n        addTable(st);\r\n        checkIfTrajectory(st);\r\n\r\n        iter.remove();\r\n        findNestedStructures((Structure) v, st); // look for nested structures\r\n\r\n      } else if (structAdded && v.isUnlimited()) {\r\n        iter.remove();\r\n      }\r\n    }\r\n\r\n    if (tableSet.size() > 0) return;\r\n\r\n    // search at dimensions that lat, lon, time coordinates use\r\n    Set<Dimension> dimSet = new HashSet<>(10);\r\n    for (CoordinateAxis axis : ds.getCoordinateAxes()) {\r\n      if ((axis.getAxisType() == AxisType.Lat) || (axis.getAxisType() == AxisType.Lon)|| (axis.getAxisType() == AxisType.Time))\r\n        for (Dimension dim : axis.getDimensions())\r\n          dimSet.add(dim);\r\n    }\r\n\r\n    // lat, lon, time all use same dimension - use it\r\n    if (dimSet.size() == 1) {\r\n      final Dimension obsDim = (Dimension) dimSet.toArray()[0];\r\n      TableConfig st = new TableConfig(Table.Type.Structure, obsDim.getShortName());\r\n      st.structureType = obsDim.isUnlimited() ? TableConfig.StructureType.Structure : TableConfig.StructureType.PsuedoStructure;\r\n      st.structName = obsDim.isUnlimited() ? \"record\" : obsDim.getShortName();\r\n      st.dimName = obsDim.getShortName();\r\n      CoordSysEvaluator.findCoords(st, ds, new CoordSysEvaluator.Predicate() {\r\n        public boolean match(CoordinateAxis axis) {\r\n          return obsDim.equals(axis.getDimension(0));\r\n        }\r\n      });\r\n\r\n      CoordinateAxis time = CoordSysEvaluator.findCoordByType(ds, AxisType.Time);\r\n      if ((time != null) && (time.getRank() == 0)) {\r\n        st.addJoin(new JoinArray(time, JoinArray.Type.scalar, 0));\r\n        st.time = time.getShortName();\r\n      }\r\n      addTable( st);\r\n      checkIfTrajectory(st);\r\n    }\r\n\r\n    if (tableSet.size() > 0) return;\r\n\r\n        CoordinateAxis time = null;\r\n    for (CoordinateAxis axis : ds.getCoordinateAxes()) {\r\n      if ((axis.getAxisType() == AxisType.Time) && axis.isIndependentCoordinate()) {\r\n        time = axis;\r\n        break;\r\n      }\r\n    }\r\n    if (time != null) {\r\n      Dimension obsDim = time.getDimension(0);\r\n      TableConfig st = new TableConfig(Table.Type.Structure, obsDim.getShortName());\r\n      st.structureType = TableConfig.StructureType.PsuedoStructure;\r\n      st.dimName = obsDim.getShortName();\r\n      CoordSysEvaluator.findCoords(st, ds, null);\r\n\r\n      addTable( st);\r\n    }\r\n\r\n  }",
        "variable": "time",
        "reference": "the time dimension",
        "explanation_by_ours": "if true, the time table will be created.",
        "explanation_by_baseline": "to find a time coordinate"
    },
    {
        "id": 1782,
        "method": "private BaseType getDeepestMatchingVariable(DConstructor dcBT, Vector vNames)\n    {\n\n                String vName = (String) vNames.get(0);\n\n        // Get all of the child variables from the Dconstructor\n        Enumeration bte = dcBT.getVariables();\n        while (bte.hasMoreElements()) {\n            // Get this variable\n            BaseType bt = (BaseType) bte.nextElement();\n\n            // Get and normalize it's name.\n            String normName = normalize(bt.getClearName());\n\n            // Compare the names\n            if (normName.equals(vName)) {\n\n                // They match!\n\n                // Remove the name from the vector.\n                vNames.remove(0);\n\n\n                if (vNames.size() == 0) { // are there more names?\n                    // Nope! We Found it!\n                    return bt;\n                }\n\n                if (bt instanceof DConstructor) {\n                    // If there are more names then this thing better be a container\n                    // recursively search it for the remaining names...\n                    BaseType nextBT = getDeepestMatchingVariable((DConstructor) bt, vNames);\n\n                    if (nextBT != null)\n                        return (nextBT);\n\n                    return (bt);\n                }\n\n                return (bt);\n            }\n        }\n        return (null);\n    }",
        "variable": "vName",
        "reference": "the first name from the Vector",
        "explanation_by_ours": "The name of the variable.",
        "explanation_by_baseline": "the name of the variable"
    },
    {
        "id": 1789,
        "method": "public static Vector tokenizeAliasField(String field) throws MalformedAliasException\n    {\n\n        boolean Debug = false;\n\n        // find the index of the last element in the field.\n        int lastIndex = field.length() - 1;\n\n        // make a place to put the tokens.\n        Vector tokens = new Vector();\n\n        //Coverity[DEADCODE]\n        if (Debug) {\n\t\tDAPNode.log.debug(\"lastIndexOf(dot): \" + field.lastIndexOf(dot) + \"   lastIndex: \" + lastIndex);\n\t    }\n\n        // Does this thing start with a quote?\n        if (field.charAt(0) == quote) {\n            // find the closing quote.\n            // Because this token starts with a quote, it must be normalized\n            // (see method description). The closing quote must exist,\n            // and it cannont be escaped.\n\n            // The first character in the token is the one following the\n            // leadin quote.\n            int start = 1;\n\n            // prepare to search for a closing quote.\n            int end = -1;\n            boolean done = false;\n            boolean escaped = false;\n\n            // search for the quote\n\n            for (int i = 1; i <= lastIndex || !done; i++) {\n                char c = field.charAt(i);\n                //LogStream.out.println(\"Checking for clear quote on char: \"+c+\" escaped=\"+escaped+\"  done=\"+done);\n\n                // Was this character escaped (with a slash)?\n                if (escaped) {\n                    // then ignore it and unset the escaped flag\n                    // since the escape has been consumed.\n                    escaped = false;\n                } else {\n                    // otherwise, is it an escape (slash) character\n                    if (c == slash) {\n                        // the set the escaoed flag to true.\n                        escaped = true;\n                    } else if (c == quote) {  // if it's not an escape (slash) then is it a quote?\n\n                        //LogStream.out.println(\"Found quote!\");\n\n                        end = i;\n                        done = true;\n                    }\n\n                }\n            }\n\n            //LogStream.out.println(\"start=\"+start+\"  end=\"+end+\"  lastIndex=\"+lastIndex);\n\n            // if the end is less than 0 then it didn't get set\n            // during the search for the quote, and thus the closing quote wasn't\n            // found. Throw an exception!\n            if (end < 0)\n                throw new MalformedAliasException(\"Alias fields that begin with the quote (\\\") sign \" +\n                        \"must have a closing quote.\");\n\n            // If there is more stuff, and that stuff is not seperated from the\n            // closing quote by a dot character, then it's bad syntax.\n            if (lastIndex > end && field.charAt(end + 1) != dot)\n                throw new MalformedAliasException(\"Alias fields must be seperated by the dot (.) character.\");\n\n            // The last caharcter in the field may not be an (unquoted) dot.\n            if (field.charAt(lastIndex) == dot)\n                throw new MalformedAliasException(\"Alias fields may not end with the dot (.) character.\");\n\n            // Looks like we found a complete token.\n            // Get it.\n            String firstToken = field.substring(start, end);\n\n            // Add it to the tokens Vector.\n            tokens.add(firstToken);\n\n            // if there is more stuff, then tokenize it.\n            if (end < lastIndex) {\n\n                                String theRest = field.substring(end + 2);\n\n                // tokenize it and add each of the returned tokens to\n                // this tokens Vector.\n                // Recursive call.\n                Enumeration tkns = tokenizeAliasField(theRest).elements();\n                while (tkns.hasMoreElements())\n                    tokens.add(tkns.nextElement());\n            }\n\n            return (tokens);\n\n\n        }\n\n        // Find the first dot. This simplistic search is appropriate because\n        // if this field contained a dot as part of it's name it should have\n        // been encased in quotes and handled by the previous logic.\n\n        int firstDot = field.indexOf(dot);\n\n        if (firstDot == 0) { // Does this thing start with dot?\n\n            // Then it must be an absolute path.\n            // NOTE: This should be true ONLY for the first token\n            // in the list. By that I mean that a leading dot in\n            // the field string should only occur when the\n            // variable or alias field begins a dot. A secondary\n            // token may only start with a dot if the dot is\n            // actually part of the field, and thus it should be\n            // encased in quotes.\n            String thisToken = \".\";\n            tokens.add(thisToken);\n            // Check to see if there are more characters in the field to be tokenized.\n            // If there are, tokenize them.\n            if (lastIndex > 0) {\n                String theRest = field.substring(1);\n                // Recursive call\n                Enumeration tkns = tokenizeAliasField(theRest).elements();\n\n                // Take the tokens from the rest of the fields and\n                // add them to this token vector.\n                while (tkns.hasMoreElements())\n                    tokens.add(tkns.nextElement());\n            }\n            return (tokens);\n        }\n\n\n        if (firstDot > 0) {\n            // A secondary token may only contain a dot if the dot is\n            // actually part of the field, and thus the field should have been\n            // encased in quotes. Since we already check for a leading quote,\n            // the first dor MUST be the end of the token.\n            String firstToken = field.substring(0, firstDot);\n            tokens.add(firstToken);\n\n            // A quick syntax check.\n            if (lastIndex == firstDot)\n                throw new MalformedAliasException(\"Alias fields may not end with the dot (.) character.\");\n\n                        String theRest = field.substring(firstDot + 1);\n\n            // tokenize it, and add it's tokens to this token Vector.\n            Enumeration tkns = tokenizeAliasField(theRest).elements();\n            while (tkns.hasMoreElements())\n                tokens.add(tkns.nextElement());\n\n            return (tokens);\n\n        }\n\n        // This field string might be the final token, if we\n        // get here it must be so add it to the tokens vector\n        tokens.add(field);\n\n        return (tokens);\n\n\n    }",
        "variable": "theRest",
        "reference": "the rest of the stuff",
        "explanation_by_ours": "the rest of the field name.",
        "explanation_by_baseline": "the rest of the field"
    },
    {
        "id": 1814,
        "method": "private void makeDatasetBest(GribCollectionMutable.Dataset ds2D, boolean isComplete) {\n    GribCollectionMutable.Dataset dsBest = result.makeDataset(isComplete ? GribCollectionImmutable.Type.BestComplete : GribCollectionImmutable.Type.Best);\n\n    int npart = result.getPartitionSize();\n\n    // for each 2D group\n    for (GribCollectionMutable.GroupGC group2D : ds2D.groups) {\n      GribCollectionMutable.GroupGC groupB = dsBest.addGroupCopy(group2D);  // make copy of group, add to Best dataset\n      groupB.isTwoD = false;\n\n      // for each time2D, create the best time coordinates\n      HashMap<Coordinate, CoordinateTimeAbstract> map2DtoBest = new HashMap<>(); // associate 2D coord with best\n      CoordinateSharerBest sharer = new CoordinateSharerBest();\n      for (Coordinate coord : group2D.coords) {\n        if (coord instanceof CoordinateRuntime) continue; // skip it\n        if (coord instanceof CoordinateTime2D) {\n          CoordinateTimeAbstract best = ((CoordinateTime2D) coord).makeBestTimeCoordinate(result.masterRuntime);\n          if (!isComplete) best = best.makeBestFromComplete();\n          sharer.addCoordinate(best);\n          map2DtoBest.put(coord, best);\n        } else {\n          sharer.addCoordinate(coord);\n        }\n      }\n      groupB.coords = sharer.finish();  // these are the unique coords for group Best\n\n      // transfer variables to Best group, set shared Coordinates\n      for (GribCollectionMutable.VariableIndex vi2d : group2D.variList) {\n        // copy vi2d and add to groupB\n        PartitionCollectionMutable.VariableIndexPartitioned vip = result.makeVariableIndexPartitioned(groupB, vi2d, npart);\n        vip.finish();\n\n                List<Coordinate> newCoords = new ArrayList<>();\n        for (Integer groupIndex : vi2d.coordIndex) {\n          Coordinate coord2D = group2D.coords.get(groupIndex);\n          if (coord2D instanceof CoordinateRuntime) continue; // skip runtime;\n          if (coord2D instanceof CoordinateTime2D) {\n            newCoords.add(map2DtoBest.get(coord2D)); // add the best coordinate for that CoordinateTime2D\n          } else {\n            newCoords.add(coord2D);\n          }\n        }\n        vip.coordIndex = sharer.reindex(newCoords);\n      }\n\n    } // loop over groups\n  }",
        "variable": "newCoords",
        "reference": "shared coordinates",
        "explanation_by_ours": "the new coordinates",
        "explanation_by_baseline": "new Coordinatesfor ("
    },
    {
        "id": 1819,
        "method": "private GribCollectionProto.Variable writeVariableProto(Grib1CollectionBuilder.VariableBag vb) {\n    GribCollectionProto.Variable.Builder b = GribCollectionProto.Variable.newBuilder();\n\n    b.setDiscipline(0);\n    b.setPds(ByteString.copyFrom(vb.first.getPDSsection().getRawBytes()));\n\n    b.setRecordsPos(vb.pos);\n    b.setRecordsLen(vb.length);\n\n    for (int idx : vb.coordIndex) {\n      b.addCoordIdx(idx);\n    }\n\n        SparseArray sa = vb.coordND.getSparseArray();\n    if (sa != null) {\n      b.setNdups(sa.getNdups());\n      b.setNrecords(sa.countNotMissing());\n      b.setMissing(sa.countMissing());\n    }\n\n    return b.build();\n  }",
        "variable": "sa",
        "reference": "stats",
        "explanation_by_ours": "the sparse array to write.",
        "explanation_by_baseline": "the sparse array= vb"
    },
    {
        "id": 1826,
        "method": "public void\n    expand()\n    {\n                Queue<DapVariable> queue = new ArrayDeque<DapVariable>();\n\n        for(int i = 0; i < variables.size(); i++) {\n            DapVariable var = variables.get(i);\n            if(!var.isTopLevel())\n                continue;\n            // prime the queue\n            DapType base = var.getBaseType();\n            if(base.getTypeSort().isCompound()) {\n                DapStructure struct = (DapStructure) base; // remember Sequence subclass Structure\n                if(expansionCount(struct) == 0)\n                    queue.add(var);\n            }\n        }\n        // Process the queue in prefix order\n        while(queue.size() > 0) {\n            DapVariable vvstruct = queue.remove();\n            DapStructure dstruct = (DapStructure) vvstruct.getBaseType();\n            for(DapVariable field : dstruct.getFields()) {\n                if(findVariableIndex(field) < 0) {\n                    // Add field as leaf\n                    this.segments.add(new Segment(field));\n                    this.variables.add(field);\n                }\n                DapType fbase = field.getBaseType();\n                if(fbase.getTypeSort().isCompound()) {\n                    if(expansionCount((DapStructure) fbase) == 0)\n                        queue.add(field);\n                }\n            }\n        }\n        this.expansion = Expand.EXPANDED;\n    }",
        "variable": "queue",
        "reference": "a queue of unprocessed leaf compounds",
        "explanation_by_ours": "The queue of unprocessed leaf compounds.",
        "explanation_by_baseline": "the queue in prefix order"
    },
    {
        "id": 1828,
        "method": "public void\n    contract()\n    {\n                Set<DapStructure> contracted = new HashSet<>();\n        for(int i = 0; i < variables.size(); i++) {\n            DapVariable var = variables.get(i);\n            if(var.isTopLevel()) {\n                DapType base = var.getBaseType();\n                if(base.getTypeSort().isCompound()) {\n                    contractR((DapStructure) base, contracted);\n                }\n            }\n        }\n        this.expansion = Expand.CONTRACTED;\n    }",
        "variable": "contracted",
        "reference": "a set of contracted compounds",
        "explanation_by_ours": "The set of compounds that should be contracted.",
        "explanation_by_baseline": "contracted set //public"
    },
    {
        "id": 1841,
        "method": "public void parse(InputStream is, DDS targetDDS, BaseTypeFactory fac, boolean validation) throws DAP2Exception {\r\n\r\n\r\n        try {\r\n\r\n            // get a jdom parser to parse and validate the XML document.\r\n            SAXBuilder parser = new SAXBuilder();\r\n            // optionally turn on validation\r\n            parser.setFeature(\"http://apache.org/xml/features/validation/schema\", validation);\r\n\r\n                        Document doc = parser.build(is);\r\n\r\n            if (_Debug) System.out.println(\"Document is \" +\r\n                    (validation ? \"valid and \" : \"\") +\r\n                    \"well-formed.\\nContent: \" + doc);\r\n\r\n            parse(doc, targetDDS, fac, validation);\r\n\r\n        } catch (JDOMException jde) {\r\n            throw new DAP2Exception(jde);\r\n        }\r\n        catch (IOException ioe) {\r\n            throw new DAP2Exception(ioe);\r\n        }\r\n\r\n\r\n    }",
        "variable": "doc",
        "reference": "a hierarchical document",
        "explanation_by_ours": "The XML document to parse into a hierarchical document.",
        "explanation_by_baseline": "an XML document.{"
    },
    {
        "id": 1851,
        "method": "private Array readStandardData(Variable v2, Section section)\r\n          throws IOException {\r\n\r\n    Array array = null;\r\n    if (v2 instanceof Structure) {\r\n      List<GempakParameter> params =\r\n              gemreader.getParameters(GempakSurfaceFileReader.SFDT);\r\n      Structure pdata = (Structure) v2;\r\n      StructureMembers members = pdata.makeStructureMembers();\r\n      List<StructureMembers.Member> mbers =\r\n              members.getMembers();\r\n      int i = 0;\r\n      int numBytes = 0;\r\n      int totalNumBytes = 0;\r\n      for (StructureMembers.Member member : mbers) {\r\n        member.setDataParam(4 * i++);\r\n        numBytes = member.getDataType().getSize();\r\n        totalNumBytes += numBytes;\r\n      }\r\n      // one member is a byte\r\n      members.setStructureSize(totalNumBytes);\r\n      float[] missing = new float[mbers.size()];\r\n      int missnum = 0;\r\n      for (Variable v : pdata.getVariables()) {\r\n        Attribute att = v.findAttribute(\"missing_value\");\r\n        missing[missnum++] = (att == null)\r\n                ? GempakConstants.RMISSD\r\n                : att.getNumericValue().floatValue();\r\n      }\r\n\r\n\r\n      //int num = 0;\r\n      Range stationRange = section.getRange(0);\r\n      Range timeRange = section.getRange(1);\r\n      int size = stationRange.length() * timeRange.length();\r\n            byte[] bytes = new byte[totalNumBytes * size];\r\n      ByteBuffer buf = ByteBuffer.wrap(bytes);\r\n      array = new ArrayStructureBB(members, new int[]{size}, buf, 0);\r\n\r\n      for (int stnIdx : stationRange) {\r\n        for (int timeIdx : timeRange) {\r\n          GempakFileReader.RData vals = gemreader.DM_RDTR(timeIdx + 1, stnIdx + 1, GempakSurfaceFileReader.SFDT);\r\n          if (vals == null) {\r\n            int k = 0;\r\n            for (StructureMembers.Member member : mbers) {\r\n              if (member.getDataType().equals(DataType.FLOAT)) {\r\n                buf.putFloat(missing[k]);\r\n              } else {\r\n                buf.put((byte) 1);\r\n              }\r\n              k++;\r\n            }\r\n          } else {\r\n            float[] reals = vals.data;\r\n            int var = 0;\r\n            for (GempakParameter param : params) {\r\n              if (members.findMember(param.getName()) != null) {\r\n                buf.putFloat(reals[var]);\r\n              }\r\n              var++;\r\n            }\r\n            // always add the missing flag\r\n            buf.put((byte) 0);\r\n          }\r\n        }\r\n      }\r\n      //Trace.call2(\"GEMPAKSIOSP: readStandardData\");\r\n    }\r\n    return array;\r\n  }",
        "variable": "bytes",
        "reference": "a ByteBuffer",
        "explanation_by_ours": "array of bytes",
        "explanation_by_baseline": "a new ArrayStructureBB"
    },
    {
        "id": 1854,
        "method": "private void buildStandardFile() {\r\n        List<GempakStation> stations = gemreader.getStations();\r\n    //Trace.msg(\"GEMPAKSIOSP: now have \" + stations.size() + \" stations\");\r\n    Dimension station = new Dimension(\"station\", stations.size(), true);\r\n    ncfile.addDimension(null, station);\r\n    ncfile.addDimension(null, DIM_LEN8);\r\n    ncfile.addDimension(null, DIM_LEN4);\r\n    ncfile.addDimension(null, DIM_LEN2);\r\n    List<Variable> stationVars = makeStationVars(stations, station);\r\n    // loop through and add to ncfile\r\n    for (Variable stnVar : stationVars) {\r\n      ncfile.addVariable(null, stnVar);\r\n    }\r\n\r\n\r\n    // Build variable list (var(station,time))\r\n    // time\r\n    List<Date> timeList = gemreader.getDates();\r\n    int numTimes = timeList.size();\r\n    Dimension times = new Dimension(TIME_VAR, numTimes, true);\r\n    ncfile.addDimension(null, times);\r\n    Array varArray;\r\n    Variable timeVar = new Variable(ncfile, null, null, TIME_VAR, DataType.DOUBLE, TIME_VAR);\r\n    timeVar.addAttribute(new Attribute(CDM.UNITS, \"seconds since 1970-01-01 00:00:00\"));\r\n    timeVar.addAttribute(new Attribute(\"long_name\", TIME_VAR));\r\n    varArray = new ArrayDouble.D1(numTimes);\r\n    int i = 0;\r\n    for (Date date : timeList) {\r\n      ((ArrayDouble.D1) varArray).set(i, date.getTime() / 1000.d);\r\n      i++;\r\n    }\r\n    timeVar.setCachedData(varArray, false);\r\n    ncfile.addVariable(null, timeVar);\r\n\r\n\r\n    List<Dimension> stationTime = new ArrayList<>();\r\n    stationTime.add(station);\r\n    stationTime.add(times);\r\n    // TODO: handle other parts\r\n    Structure sfData = makeStructure(GempakSurfaceFileReader.SFDT,\r\n            stationTime, true);\r\n    if (sfData == null) {\r\n      return;\r\n    }\r\n    sfData.addAttribute(new Attribute(CF.COORDINATES, \"time SLAT SLON SELV\"));\r\n    ncfile.addVariable(null, sfData);\r\n    ncfile.addAttribute(\r\n            null,\r\n            new Attribute(\r\n                    \"CF:featureType\",\r\n                    CF.FeatureType.timeSeries.toString()));\r\n  }",
        "variable": "stations",
        "reference": "the station list",
        "explanation_by_ours": "the list of stations to build the file for.",
        "explanation_by_baseline": ") ;()"
    },
    {
        "id": 1914,
        "method": "public void writeStringData(Variable v, int[] origin, Array values) throws java.io.IOException, InvalidRangeException {\r\n\r\n    if (values.getElementType() != String.class)\r\n      throw new IllegalArgumentException(\"Must be ArrayObject of String \");\r\n\r\n    if (v.getDataType() != DataType.CHAR)\r\n      throw new IllegalArgumentException(\"variable \" + v.getFullName() + \" is not type CHAR\");\r\n    int rank = v.getRank();\r\n    int strlen = v.getShape(rank - 1);\r\n\r\n        ArrayChar cvalues = ArrayChar.makeFromStringArray((ArrayObject) values, strlen);\r\n\r\n    int[] corigin = new int[rank];\r\n    System.arraycopy(origin, 0, corigin, 0, rank - 1);\r\n\r\n    write(v, corigin, cvalues);\r\n  }",
        "variable": "cvalues",
        "reference": "an ArrayChar",
        "explanation_by_ours": "the char array to write",
        "explanation_by_baseline": "an array char="
    },
    {
        "id": 1941,
        "method": "private void nameDatasetList( InvDatasetImpl dataset)\n  {\n    // Create temporary dataset in which to hold named datasets.\n    InvDatasetImpl namedDs = new InvDatasetImpl( dataset,\n          \"nameDatastList() temp dataset\", null, null, null);\n    // InvDatasetImpl(parentDs, name, dataType, serviceName, urlPath)\n    dataset.addDataset( namedDs);\n\n        DatasetNamer curNamer = null;\n    for ( int i = 0; i < this.datasetNamerList.size(); i++)\n    {\n      curNamer = (DatasetNamer) this.datasetNamerList.get( i);\n      logger.debug( \"nameDatasetList(): trying namer ({})\", curNamer.getName());\n\n      // If the current DatasetNamer adds a new level, create a new dataset.\n      InvDatasetImpl addLevelDs = null;\n      if ( curNamer.getAddLevel())\n      {\n        addLevelDs = new InvDatasetImpl( null, curNamer.getName(),\n                                         null, null, null );\n      }\n\n      // Iterate over remaining unnamed datasets.\n      InvDatasetImpl curDs = null;\n      java.util.Iterator dsIter = dataset.getDatasets().iterator();\n      while ( dsIter.hasNext())\n      {\n        curDs = (InvDatasetImpl) dsIter.next();\n        logger.debug( \"nameDatasetList(): try namer on this ds ({}-{})\", curDs.getName(), curDs.getUrlPath() );\n\n        // Try to name the current dataset.\n        if ( curNamer.nameDataset( curDs))\n        {\n          logger.debug( \"nameDatasetList(): ds named ({})\", curDs.getName());\n          // If adding a level, add named datasets to the added level dataset.\n          if ( curNamer.getAddLevel())\n          {\n            addLevelDs.addDataset( curDs);\n          }\n          // Otherwise, add the named datasets to namedDs.\n          else\n          {\n            namedDs.addDataset( curDs);\n          }\n\n          // Remove the now-named dataset from list of unnamed datasets.\n          dsIter.remove();\n        }\n      } // END - InvDatasetImpl loop\n\n      // If the namer added a level and a dataset was named by this namer, add the\n      // new level to the list of named datasets.\n      if ( curNamer.getAddLevel())\n      {\n        if ( addLevelDs.hasNestedDatasets())\n        {\n          namedDs.addDataset( addLevelDs);\n        }\n      }\n\n    } // END - DatasetNamer loop\n    namedDs.finish();\n\n    // Once all datasets are named (or unnamable with these DatasetNamers),\n    // add all the datasets in namedDs back into the given containerDataset.\n    if (logger.isDebugEnabled()) {\n      logger.debug( \"nameDatasetList(): number of unnamed datasets is \" + dataset.getDatasets().size() + \".\");\n      logger.debug( \"nameDatasetList(): add named datasets back to container.\");\n    }\n    for ( int i = 0; i < namedDs.getDatasets().size(); i++)\n    {\n      dataset.addDataset( (InvDatasetImpl) namedDs.getDatasets().get( i));\n    }\n    dataset.removeDataset( namedDs);\n\n    return;\n  }",
        "variable": "curNamer",
        "reference": "the DatasetNamers",
        "explanation_by_ours": "The current DatasetNamer.",
        "explanation_by_baseline": "the dataset namers."
    },
    {
        "id": 1965,
        "method": "private Variable readVariable(NetcdfFile ncfile, Group g, Structure parentS, Element varElem) {\r\n    String name = varElem.getAttributeValue(\"name\");\r\n    if (name == null) {\r\n      errlog.format(\"NcML Variable name is required (%s)%n\", varElem);\r\n      return null;\r\n    }\r\n\r\n    String type = varElem.getAttributeValue(\"type\");\r\n    if (type == null) {\r\n      errlog.format(\"NcML variable (%s) must have type attribute\", name);\r\n      return null;\r\n    }\r\n    DataType dtype = DataType.getType(type);\r\n\r\n    String shape = varElem.getAttributeValue(\"shape\");\r\n    if (shape == null)\r\n      shape = \"\"; // deprecated, prefer explicit \"\"\r\n\r\n    Variable v;\r\n\r\n    if (dtype == DataType.STRUCTURE) {\r\n      Structure s = new Structure(ncfile, g, parentS, name);\r\n      s.setDimensions(shape);\r\n      v = s;\r\n      // look for nested variables\r\n      java.util.List<Element> varList = varElem.getChildren(\"variable\", Catalog.ncmlNS);\r\n      for (Element vElem : varList) {\r\n        readVariable(ncfile, g, s, vElem);\r\n      }\r\n\r\n    } else if (dtype == DataType.SEQUENCE) {\r\n        Sequence s = new Sequence(ncfile, g, parentS, name);\r\n        v = s;\r\n        // look for nested variables\r\n        java.util.List<Element> varList = varElem.getChildren(\"variable\", Catalog.ncmlNS);\r\n        for (Element vElem : varList) {\r\n          readVariable(ncfile, g, s, vElem);\r\n        }\r\n\r\n    } else {\r\n      v = new Variable(ncfile, g, parentS, name, dtype, shape);\r\n\r\n      // deal with values\r\n      Element valueElem = varElem.getChild(\"values\", Catalog.ncmlNS);\r\n      if (valueElem != null)\r\n        readValues(v, varElem, valueElem);\r\n      // otherwise has fill values.\r\n    }\r\n\r\n    // look for attributes\r\n    java.util.List<Element> attList = varElem.getChildren(\"attribute\", Catalog.ncmlNS);\r\n    for (Element attElem : attList)\r\n      readAtt(v, attElem);\r\n\r\n    if (parentS != null)\r\n      parentS.addMemberVariable(v);\r\n    else\r\n      g.addVariable(v);    \r\n\r\n    return v;\r\n  }\r\n\r\n  private void readValues(Variable v, Element varElem, Element valuesElem) {\r\n\r\n    // check if values are specified by start / increment\r\n    String startS = valuesElem.getAttributeValue(\"start\");\r\n    String incrS = valuesElem.getAttributeValue(\"increment\");\r\n    String nptsS = valuesElem.getAttributeValue(\"npts\");\r\n    int npts = (nptsS == null) ? (int) v.getSize() : Integer.parseInt(nptsS);\r\n\r\n    // either start, increment are specified\r\n    if ((startS != null) && (incrS != null)) {\r\n      double start = Double.parseDouble(startS);\r\n      double incr = Double.parseDouble(incrS);\r\n      v.setValues(npts, start, incr);\r\n      return;\r\n    }\r\n\r\n    // otherwise values are listed in text\r\n    String values = varElem.getChildText(\"values\", Catalog.ncmlNS);\r\n    String sep = valuesElem.getAttributeValue(\"separator\");\r\n    if (sep == null) sep = \" \";\r\n\r\n    if (v.getDataType() == DataType.CHAR) {\r\n      int nhave = values.length();\r\n      int nwant = (int) v.getSize();\r\n      char[] data = new char[nwant];\r\n      int min = Math.min(nhave, nwant);\r\n      for (int i = 0; i < min; i++) {\r\n        data[i] = values.charAt(i);\r\n      }\r\n      Array dataArray = Array.factory(DataType.CHAR, v.getShape(), data);\r\n      v.setCachedData(dataArray, true);\r\n\r\n    } else {\r\n            List<String> valList = new ArrayList<>();\r\n      StringTokenizer tokn = new StringTokenizer(values, sep);\r\n      while (tokn.hasMoreTokens())\r\n        valList.add(tokn.nextToken());\r\n      v.setValues(valList);\r\n    }\r\n  }\r\n\r\n  private void readAtt(Object parent, Element attElem) {\r\n    String name = attElem.getAttributeValue(\"name\");\r\n    if (name == null) {\r\n      errlog.format(\"NcML Attribute name is required (%s)%n\", attElem);\r\n      return;\r\n    }\r\n\r\n    try {\r\n      ucar.ma2.Array values = NcMLReader.readAttributeValues(attElem);\r\n      Attribute att = new ucar.nc2.Attribute(name, values);\r\n      if (parent instanceof Group)\r\n        ((Group) parent).addAttribute(att);\r\n      else if (parent instanceof Variable)\r\n        ((Variable) parent).addAttribute(att);\r\n    } catch (RuntimeException e) {\r\n      errlog.format(\"NcML new Attribute Exception: %s att=%s in=%s%n\", e.getMessage(), name, parent);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read an NcML dimension element.\r\n   *\r\n   * @param g       put dimension into this group\r\n   * @param dimElem ncml dimension element\r\n   */\r\n  private void readDim(Group g, Element dimElem) {\r\n    String name = dimElem.getAttributeValue(\"name\");\r\n    if (name == null) {\r\n      errlog.format(\"NcML Dimension name is required (%s)%n\", dimElem);\r\n      return;\r\n    }\r\n\r\n    String lengthS = dimElem.getAttributeValue(\"length\");\r\n    String isUnlimitedS = dimElem.getAttributeValue(\"isUnlimited\");\r\n    String isSharedS = dimElem.getAttributeValue(\"isShared\");\r\n    String isUnknownS = dimElem.getAttributeValue(\"isVariableLength\");\r\n\r\n    boolean isUnlimited = (isUnlimitedS != null) && isUnlimitedS.equalsIgnoreCase(\"true\");\r\n    boolean isUnknown = (isUnknownS != null) && isUnknownS.equalsIgnoreCase(\"true\");\r\n    boolean isShared = true;\r\n    if ((isSharedS != null) && isSharedS.equalsIgnoreCase(\"false\"))\r\n      isShared = false;\r\n\r\n    int len = Integer.parseInt(lengthS);\r\n    if ((isUnknownS != null) && isUnknownS.equalsIgnoreCase(\"false\"))\r\n      len = Dimension.VLEN.getLength();\r\n\r\n    Dimension dim = new Dimension(name, len, isShared, isUnlimited, isUnknown);\r\n\r\n    if (debugConstruct) System.out.println(\" add new dim = \" + dim);\r\n    g.addDimension(dim);\r\n  }\r\n\r\n}",
        "variable": "valList",
        "reference": "a list of values",
        "explanation_by_ours": "List of variable elements",
        "explanation_by_baseline": "start/increment are specified"
    },
    {
        "id": 1983,
        "method": "public Polygon setupPolygon(NetcdfDataset dataset, Variable polyvar, int index)\r\n\t{\r\n\t\tthis.points.clear();\r\n\t\tArray xPts = null;\r\n\t\tArray yPts = null;\r\n\t\tVariable nodeCounts = null;\r\n\t\tVariable partNodeCounts = null;\r\n\t\tVariable interiorRings = null;\r\n\r\n\t\tList<CoordinateAxis> axes = dataset.getCoordinateAxes();\r\n\t\tCoordinateAxis x = null; CoordinateAxis y = null;\r\n\t\t\r\n\t\tString[] nodeCoords = polyvar.findAttributeIgnoreCase(CF.NODE_COORDINATES).getStringValue().split(\" \");\r\n\t\t\r\n\t\t// Look for x and y\r\n\t\t\r\n\t\tfor(CoordinateAxis ax : axes){\r\n\t\t\t\r\n\t\t\tif(ax.getFullName().equals(nodeCoords[0])) x = ax;\r\n\t\t\tif(ax.getFullName().equals(nodeCoords[1])) y = ax;\r\n\t\t}\r\n\t\t\r\n\t\t\t\tString nodeCoStr = polyvar.findAttValueIgnoreCase(CF.NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!nodeCoStr.equals(\"\")) {\r\n\t\t\tnodeCounts = dataset.findVariable(nodeCoStr);\r\n\t\t}\r\n\t\t\r\n\t\telse return null;\r\n\t\t\r\n\t\t// Affirm part node counts\r\n\t\tString pNodeCoStr = polyvar.findAttValueIgnoreCase(CF.PART_NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!pNodeCoStr.equals(\"\")) {\r\n\t\t\tpartNodeCounts = dataset.findVariable(pNodeCoStr);\r\n\t\t}\r\n\t\t\r\n\t\t// Affirm interior rings\r\n\t\tString interiorRingsStr = polyvar.findAttValueIgnoreCase(CF.PART_NODE_COUNT, \"\");\r\n\t\t\t\t\r\n\t\tif(!interiorRingsStr.equals(\"\")) {\r\n\t\t\t\tinteriorRings = dataset.findVariable(interiorRingsStr);\r\n\t\t}\r\n\t\t\r\n\t\tSimpleGeometryIndexFinder indexFinder = new SimpleGeometryIndexFinder(nodeCounts);\r\n\t\t\r\n\t\t//Get beginning and ending indicies for this polygon\r\n\t\tint lower = indexFinder.getBeginning(index);\r\n\t\tint upper = indexFinder.getEnd(index);\r\n\r\n\t\t\r\n\t\ttry {\r\n\t\t\t\r\n\t\t\txPts = x.read( lower + \":\" + upper ).reduce();\r\n\t\t\tyPts = y.read( lower + \":\" + upper ).reduce(); \r\n\r\n\t\t\tIndexIterator itrX = xPts.getIndexIterator();\r\n\t\t\tIndexIterator itrY = yPts.getIndexIterator();\r\n\t\t\t\r\n\t\t\t// No multipolygons just read in the whole thing\r\n\t\t\tif(partNodeCounts == null) {\r\n\t\t\t\t\r\n\t\t\t\tthis.next = null;\r\n\t\t\t\tthis.prev = null;\r\n\t\t\t\tthis.isInteriorRing = false;\r\n\t\t\t\t\r\n\t\t\t\t// x and y should have the same shape, will add some handling on this\r\n\t\t\t\twhile(itrX.hasNext()) {\r\n\t\t\t\t\tthis.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t}\r\n\t\r\n\t\t\t\t\r\n\t\t\t\tswitch(polyvar.getRank()) {\r\n\t\t\t\t\r\n\t\t\t\tcase 2:\r\n\t\t\t\t\tthis.setData(polyvar.read(CFSimpleGeometryHelper.getSubsetString(polyvar, index)).reduce());\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tcase 1:\r\n\t\t\t\t\tthis.setData(polyvar.read(\"\" + index));\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tdefault:\r\n\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t// If there are multipolygons then take the upper and lower of it and divy it up\r\n\t\t\telse {\r\n\t\t\t\t\r\n\t\t\t\tPolygon tail = this;\r\n\t\t\t\tArray pnc = partNodeCounts.read();\r\n\t\t\t\tArray ir = null;\r\n\t\t\t\tIndexIterator pncItr = pnc.getIndexIterator();\r\n\t\t\t\t\r\n\t\t\t\tif(interiorRings != null) ir = interiorRings.read();\r\n\t\t\t\t\r\n\t\t\t\t// In part node count search for the right index to begin looking for \"part node counts\"\r\n\t\t\t\tint pncInd = 0;\r\n\t\t\t\tint pncEnd = 0;\r\n\t\t\t\twhile(pncEnd < lower)\r\n\t\t\t\t{\r\n\t\t\t\t\tpncEnd += pncItr.getIntNext();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t// Now the index is found, use part node count and the index to find each part node count of each individual part\r\n\t\t\t\twhile(lower < upper) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tint smaller = pnc.getInt(pncInd);\r\n\t\t\t\t\t\r\n\t\t\t\t\t// Set interior ring if needed\r\n\t\t\t\t\tif(interiorRings != null)\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\tint interiorRingValue = ir.getInt(pncInd);\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tswitch(interiorRingValue) {\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tcase 0:\r\n\t\t\t\t\t\t\t\tthis.setInteriorRing(false);\r\n\t\t\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tcase 1:\r\n\t\t\t\t\t\t\t\tthis.setInteriorRing(true);\r\n\t\t\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t// will handle default case\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t} else this.isInteriorRing = false;\r\n\t\t\t\t\t\r\n\t\t\t\t\twhile(smaller > 0) {\r\n\t\t\t\t\t\ttail.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t\t\tsmaller--;\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\t// Set data of each\r\n\t\t\t\t\tswitch(polyvar.getRank()) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tcase 2:\r\n\t\t\t\t\t\ttail.setData(polyvar.read(CFSimpleGeometryHelper.getSubsetString(polyvar, index)).reduce());\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tcase 1:\r\n\t\t\t\t\t\ttail.setData(polyvar.read(\"\" + index));\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tdefault:\r\n\t\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\t\r\n\t\t\t\t\t}\r\n\r\n\t\t\t\t\tlower += tail.getPoints().size();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t\ttail.setNext(new CFPolygon());\r\n\t\t\t\t\ttail = tail.getNext();\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t//Clean up\r\n\t\t\t\ttail = tail.getPrev();\r\n\t\t\t\tif(tail != null) tail.setNext(null);\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tcatch (IOException | InvalidRangeException | InvalidDataseriesException e) {\r\n\t\t\tcfpl.error(e.getMessage());\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\t\r\n\t\treturn this;\r\n\t}",
        "variable": "nodeCoStr",
        "reference": "node counts",
        "explanation_by_ours": "The name of the node coordinates.",
        "explanation_by_baseline": "node counts) {"
    },
    {
        "id": 1984,
        "method": "public Polygon setupPolygon(NetcdfDataset dataset, Variable polyvar, int index)\r\n\t{\r\n\t\tthis.points.clear();\r\n\t\tArray xPts = null;\r\n\t\tArray yPts = null;\r\n\t\tVariable nodeCounts = null;\r\n\t\tVariable partNodeCounts = null;\r\n\t\tVariable interiorRings = null;\r\n\r\n\t\tList<CoordinateAxis> axes = dataset.getCoordinateAxes();\r\n\t\tCoordinateAxis x = null; CoordinateAxis y = null;\r\n\t\t\r\n\t\tString[] nodeCoords = polyvar.findAttributeIgnoreCase(CF.NODE_COORDINATES).getStringValue().split(\" \");\r\n\t\t\r\n\t\t// Look for x and y\r\n\t\t\r\n\t\tfor(CoordinateAxis ax : axes){\r\n\t\t\t\r\n\t\t\tif(ax.getFullName().equals(nodeCoords[0])) x = ax;\r\n\t\t\tif(ax.getFullName().equals(nodeCoords[1])) y = ax;\r\n\t\t}\r\n\t\t\r\n\t\t// Affirm node counts\r\n\t\tString nodeCoStr = polyvar.findAttValueIgnoreCase(CF.NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!nodeCoStr.equals(\"\")) {\r\n\t\t\tnodeCounts = dataset.findVariable(nodeCoStr);\r\n\t\t}\r\n\t\t\r\n\t\telse return null;\r\n\t\t\r\n\t\t\t\tString pNodeCoStr = polyvar.findAttValueIgnoreCase(CF.PART_NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!pNodeCoStr.equals(\"\")) {\r\n\t\t\tpartNodeCounts = dataset.findVariable(pNodeCoStr);\r\n\t\t}\r\n\t\t\r\n\t\t// Affirm interior rings\r\n\t\tString interiorRingsStr = polyvar.findAttValueIgnoreCase(CF.PART_NODE_COUNT, \"\");\r\n\t\t\t\t\r\n\t\tif(!interiorRingsStr.equals(\"\")) {\r\n\t\t\t\tinteriorRings = dataset.findVariable(interiorRingsStr);\r\n\t\t}\r\n\t\t\r\n\t\tSimpleGeometryIndexFinder indexFinder = new SimpleGeometryIndexFinder(nodeCounts);\r\n\t\t\r\n\t\t//Get beginning and ending indicies for this polygon\r\n\t\tint lower = indexFinder.getBeginning(index);\r\n\t\tint upper = indexFinder.getEnd(index);\r\n\r\n\t\t\r\n\t\ttry {\r\n\t\t\t\r\n\t\t\txPts = x.read( lower + \":\" + upper ).reduce();\r\n\t\t\tyPts = y.read( lower + \":\" + upper ).reduce(); \r\n\r\n\t\t\tIndexIterator itrX = xPts.getIndexIterator();\r\n\t\t\tIndexIterator itrY = yPts.getIndexIterator();\r\n\t\t\t\r\n\t\t\t// No multipolygons just read in the whole thing\r\n\t\t\tif(partNodeCounts == null) {\r\n\t\t\t\t\r\n\t\t\t\tthis.next = null;\r\n\t\t\t\tthis.prev = null;\r\n\t\t\t\tthis.isInteriorRing = false;\r\n\t\t\t\t\r\n\t\t\t\t// x and y should have the same shape, will add some handling on this\r\n\t\t\t\twhile(itrX.hasNext()) {\r\n\t\t\t\t\tthis.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t}\r\n\t\r\n\t\t\t\t\r\n\t\t\t\tswitch(polyvar.getRank()) {\r\n\t\t\t\t\r\n\t\t\t\tcase 2:\r\n\t\t\t\t\tthis.setData(polyvar.read(CFSimpleGeometryHelper.getSubsetString(polyvar, index)).reduce());\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tcase 1:\r\n\t\t\t\t\tthis.setData(polyvar.read(\"\" + index));\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tdefault:\r\n\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t// If there are multipolygons then take the upper and lower of it and divy it up\r\n\t\t\telse {\r\n\t\t\t\t\r\n\t\t\t\tPolygon tail = this;\r\n\t\t\t\tArray pnc = partNodeCounts.read();\r\n\t\t\t\tArray ir = null;\r\n\t\t\t\tIndexIterator pncItr = pnc.getIndexIterator();\r\n\t\t\t\t\r\n\t\t\t\tif(interiorRings != null) ir = interiorRings.read();\r\n\t\t\t\t\r\n\t\t\t\t// In part node count search for the right index to begin looking for \"part node counts\"\r\n\t\t\t\tint pncInd = 0;\r\n\t\t\t\tint pncEnd = 0;\r\n\t\t\t\twhile(pncEnd < lower)\r\n\t\t\t\t{\r\n\t\t\t\t\tpncEnd += pncItr.getIntNext();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t// Now the index is found, use part node count and the index to find each part node count of each individual part\r\n\t\t\t\twhile(lower < upper) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tint smaller = pnc.getInt(pncInd);\r\n\t\t\t\t\t\r\n\t\t\t\t\t// Set interior ring if needed\r\n\t\t\t\t\tif(interiorRings != null)\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\tint interiorRingValue = ir.getInt(pncInd);\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tswitch(interiorRingValue) {\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tcase 0:\r\n\t\t\t\t\t\t\t\tthis.setInteriorRing(false);\r\n\t\t\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tcase 1:\r\n\t\t\t\t\t\t\t\tthis.setInteriorRing(true);\r\n\t\t\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t// will handle default case\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t} else this.isInteriorRing = false;\r\n\t\t\t\t\t\r\n\t\t\t\t\twhile(smaller > 0) {\r\n\t\t\t\t\t\ttail.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t\t\tsmaller--;\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\t// Set data of each\r\n\t\t\t\t\tswitch(polyvar.getRank()) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tcase 2:\r\n\t\t\t\t\t\ttail.setData(polyvar.read(CFSimpleGeometryHelper.getSubsetString(polyvar, index)).reduce());\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tcase 1:\r\n\t\t\t\t\t\ttail.setData(polyvar.read(\"\" + index));\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tdefault:\r\n\t\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\t\r\n\t\t\t\t\t}\r\n\r\n\t\t\t\t\tlower += tail.getPoints().size();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t\ttail.setNext(new CFPolygon());\r\n\t\t\t\t\ttail = tail.getNext();\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t//Clean up\r\n\t\t\t\ttail = tail.getPrev();\r\n\t\t\t\tif(tail != null) tail.setNext(null);\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tcatch (IOException | InvalidRangeException | InvalidDataseriesException e) {\r\n\t\t\tcfpl.error(e.getMessage());\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\t\r\n\t\treturn this;\r\n\t}",
        "variable": "pNodeCoStr",
        "reference": "part node counts",
        "explanation_by_ours": "The name of the part node.",
        "explanation_by_baseline": "part node counts) {"
    },
    {
        "id": 1985,
        "method": "public Polygon setupPolygon(NetcdfDataset dataset, Variable polyvar, int index)\r\n\t{\r\n\t\tthis.points.clear();\r\n\t\tArray xPts = null;\r\n\t\tArray yPts = null;\r\n\t\tVariable nodeCounts = null;\r\n\t\tVariable partNodeCounts = null;\r\n\t\tVariable interiorRings = null;\r\n\r\n\t\tList<CoordinateAxis> axes = dataset.getCoordinateAxes();\r\n\t\tCoordinateAxis x = null; CoordinateAxis y = null;\r\n\t\t\r\n\t\tString[] nodeCoords = polyvar.findAttributeIgnoreCase(CF.NODE_COORDINATES).getStringValue().split(\" \");\r\n\t\t\r\n\t\t// Look for x and y\r\n\t\t\r\n\t\tfor(CoordinateAxis ax : axes){\r\n\t\t\t\r\n\t\t\tif(ax.getFullName().equals(nodeCoords[0])) x = ax;\r\n\t\t\tif(ax.getFullName().equals(nodeCoords[1])) y = ax;\r\n\t\t}\r\n\t\t\r\n\t\t// Affirm node counts\r\n\t\tString nodeCoStr = polyvar.findAttValueIgnoreCase(CF.NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!nodeCoStr.equals(\"\")) {\r\n\t\t\tnodeCounts = dataset.findVariable(nodeCoStr);\r\n\t\t}\r\n\t\t\r\n\t\telse return null;\r\n\t\t\r\n\t\t// Affirm part node counts\r\n\t\tString pNodeCoStr = polyvar.findAttValueIgnoreCase(CF.PART_NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!pNodeCoStr.equals(\"\")) {\r\n\t\t\tpartNodeCounts = dataset.findVariable(pNodeCoStr);\r\n\t\t}\r\n\t\t\r\n\t\t\t\tString interiorRingsStr = polyvar.findAttValueIgnoreCase(CF.PART_NODE_COUNT, \"\");\r\n\t\t\t\t\r\n\t\tif(!interiorRingsStr.equals(\"\")) {\r\n\t\t\t\tinteriorRings = dataset.findVariable(interiorRingsStr);\r\n\t\t}\r\n\t\t\r\n\t\tSimpleGeometryIndexFinder indexFinder = new SimpleGeometryIndexFinder(nodeCounts);\r\n\t\t\r\n\t\t//Get beginning and ending indicies for this polygon\r\n\t\tint lower = indexFinder.getBeginning(index);\r\n\t\tint upper = indexFinder.getEnd(index);\r\n\r\n\t\t\r\n\t\ttry {\r\n\t\t\t\r\n\t\t\txPts = x.read( lower + \":\" + upper ).reduce();\r\n\t\t\tyPts = y.read( lower + \":\" + upper ).reduce(); \r\n\r\n\t\t\tIndexIterator itrX = xPts.getIndexIterator();\r\n\t\t\tIndexIterator itrY = yPts.getIndexIterator();\r\n\t\t\t\r\n\t\t\t// No multipolygons just read in the whole thing\r\n\t\t\tif(partNodeCounts == null) {\r\n\t\t\t\t\r\n\t\t\t\tthis.next = null;\r\n\t\t\t\tthis.prev = null;\r\n\t\t\t\tthis.isInteriorRing = false;\r\n\t\t\t\t\r\n\t\t\t\t// x and y should have the same shape, will add some handling on this\r\n\t\t\t\twhile(itrX.hasNext()) {\r\n\t\t\t\t\tthis.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t}\r\n\t\r\n\t\t\t\t\r\n\t\t\t\tswitch(polyvar.getRank()) {\r\n\t\t\t\t\r\n\t\t\t\tcase 2:\r\n\t\t\t\t\tthis.setData(polyvar.read(CFSimpleGeometryHelper.getSubsetString(polyvar, index)).reduce());\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tcase 1:\r\n\t\t\t\t\tthis.setData(polyvar.read(\"\" + index));\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tdefault:\r\n\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t// If there are multipolygons then take the upper and lower of it and divy it up\r\n\t\t\telse {\r\n\t\t\t\t\r\n\t\t\t\tPolygon tail = this;\r\n\t\t\t\tArray pnc = partNodeCounts.read();\r\n\t\t\t\tArray ir = null;\r\n\t\t\t\tIndexIterator pncItr = pnc.getIndexIterator();\r\n\t\t\t\t\r\n\t\t\t\tif(interiorRings != null) ir = interiorRings.read();\r\n\t\t\t\t\r\n\t\t\t\t// In part node count search for the right index to begin looking for \"part node counts\"\r\n\t\t\t\tint pncInd = 0;\r\n\t\t\t\tint pncEnd = 0;\r\n\t\t\t\twhile(pncEnd < lower)\r\n\t\t\t\t{\r\n\t\t\t\t\tpncEnd += pncItr.getIntNext();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t// Now the index is found, use part node count and the index to find each part node count of each individual part\r\n\t\t\t\twhile(lower < upper) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tint smaller = pnc.getInt(pncInd);\r\n\t\t\t\t\t\r\n\t\t\t\t\t// Set interior ring if needed\r\n\t\t\t\t\tif(interiorRings != null)\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\tint interiorRingValue = ir.getInt(pncInd);\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tswitch(interiorRingValue) {\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tcase 0:\r\n\t\t\t\t\t\t\t\tthis.setInteriorRing(false);\r\n\t\t\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tcase 1:\r\n\t\t\t\t\t\t\t\tthis.setInteriorRing(true);\r\n\t\t\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t// will handle default case\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t} else this.isInteriorRing = false;\r\n\t\t\t\t\t\r\n\t\t\t\t\twhile(smaller > 0) {\r\n\t\t\t\t\t\ttail.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t\t\tsmaller--;\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\t// Set data of each\r\n\t\t\t\t\tswitch(polyvar.getRank()) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tcase 2:\r\n\t\t\t\t\t\ttail.setData(polyvar.read(CFSimpleGeometryHelper.getSubsetString(polyvar, index)).reduce());\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tcase 1:\r\n\t\t\t\t\t\ttail.setData(polyvar.read(\"\" + index));\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tdefault:\r\n\t\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\t\r\n\t\t\t\t\t}\r\n\r\n\t\t\t\t\tlower += tail.getPoints().size();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t\ttail.setNext(new CFPolygon());\r\n\t\t\t\t\ttail = tail.getNext();\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t//Clean up\r\n\t\t\t\ttail = tail.getPrev();\r\n\t\t\t\tif(tail != null) tail.setNext(null);\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tcatch (IOException | InvalidRangeException | InvalidDataseriesException e) {\r\n\t\t\tcfpl.error(e.getMessage());\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\t\r\n\t\treturn this;\r\n\t}",
        "variable": "interiorRingsStr",
        "reference": "interior rings",
        "explanation_by_ours": "The string representation of the interior rings.",
        "explanation_by_baseline": "interior ring) {"
    },
    {
        "id": 1999,
        "method": "public void\n    doonce(HttpServletRequest req)\n            throws SendError\n\n    {\n        if(once)\n            return;\n        super.initOnce(req);\n\n        if(this.uploaddir == null)\n            throw new SendError(HttpStatus.SC_PRECONDITION_FAILED, \"Upload disabled\");\n        this.uploaddirname = new File(this.uploaddir).getName();\n\n                File upform = null;\n        upform = tdsContext.getUploadForm();\n        if(upform == null) {   // Look in WEB-INF directory\n            File root = tdsContext.getServletRootDirectory();\n            upform = new File(root, DEFAULTUPLOADFORM);\n        }\n\ttry {\n\tthis.uploadform = loadForm(upform);\n\t} catch (IOException ioe) {\n            throw new SendError(HttpStatus.SC_PRECONDITION_FAILED, ioe);\n\t}\n    }",
        "variable": "upform",
        "reference": "the upload form",
        "explanation_by_ours": "the upload form",
        "explanation_by_baseline": "upload formif (once"
    },
    {
        "id": 2009,
        "method": "protected AxisType getAxisType(NetcdfDataset ncDataset, VariableEnhanced v) {\r\n\r\n         String sname = ncDataset.findAttValueIgnoreCase((Variable) v, CF.STANDARD_NAME, null);\r\n    if (sname != null) {\r\n      sname = sname.trim();\r\n\r\n      for (String vertical_coord : vertical_coords)\r\n        if (sname.equalsIgnoreCase(vertical_coord))\r\n          return AxisType.GeoZ;\r\n    }\r\n\r\n    // COARDS - check units\r\n    AxisType at = super.getAxisType(ncDataset, v);\r\n    if (at != null) return at;\r\n\r\n    // standard names for X, Y : bug in CDO putting wrong standard name, so check units first (!)\r\n    if (sname != null) {\r\n      if (sname.equalsIgnoreCase(CF.ENSEMBLE))\r\n        return AxisType.Ensemble;\r\n\r\n      if (sname.equalsIgnoreCase(CF.LATITUDE))\r\n        return AxisType.Lat;\r\n\r\n      if (sname.equalsIgnoreCase(CF.LONGITUDE))\r\n        return AxisType.Lon;\r\n\r\n      if (sname.equalsIgnoreCase(CF.PROJECTION_X_COORDINATE) || sname.equalsIgnoreCase(CF.GRID_LONGITUDE) || sname.equalsIgnoreCase(\"rotated_longitude\"))\r\n        return AxisType.GeoX;\r\n\r\n      if (sname.equalsIgnoreCase(CF.PROJECTION_Y_COORDINATE) || sname.equalsIgnoreCase(CF.GRID_LATITUDE) || sname.equalsIgnoreCase(\"rotated_latitude\"))\r\n        return AxisType.GeoY;\r\n\r\n      if (sname.equalsIgnoreCase(CF.TIME_REFERENCE))\r\n        return AxisType.RunTime;\r\n\r\n      if (sname.equalsIgnoreCase(CF.TIME_OFFSET))\r\n        return AxisType.TimeOffset;\r\n    }\r\n\r\n    // check axis attribute - only for X, Y, Z\r\n    String axis = ncDataset.findAttValueIgnoreCase((Variable) v, CF.AXIS, null);\r\n    if (axis != null) {\r\n      axis = axis.trim();\r\n      String unit = v.getUnitsString();\r\n\r\n      if (axis.equalsIgnoreCase(\"X\")) {\r\n        if (SimpleUnit.isCompatible(\"m\", unit))\r\n          return AxisType.GeoX;\r\n\r\n      } else if (axis.equalsIgnoreCase(\"Y\")) {\r\n        if (SimpleUnit.isCompatible(\"m\", unit))\r\n          return AxisType.GeoY;\r\n\r\n      } else if (axis.equalsIgnoreCase(\"Z\")) {\r\n        if (unit == null) return AxisType.GeoZ;\r\n        if (SimpleUnit.isCompatible(\"m\", unit))\r\n          return AxisType.Height;\r\n        else if (SimpleUnit.isCompatible(\"mbar\", unit))\r\n          return AxisType.Pressure;\r\n        else\r\n          return AxisType.GeoZ;\r\n      }\r\n    }\r\n\r\n    if (avhrr_oiv2) {\r\n      if (v.getShortName().equals(\"zlev\"))\r\n        return AxisType.Height;\r\n    }\r\n\r\n    try {\r\n      String units = v.getUnitsString();\r\n      CalendarDateUnit cd = CalendarDateUnit.of(null, units);\r\n      if (cd != null) return AxisType.Time;\r\n    } catch (Throwable t) {\r\n      // ignore\r\n    }\r\n\r\n    return null;\r\n  }",
        "variable": "sname",
        "reference": "standard names for unitless vertical coords",
        "explanation_by_ours": "the standard name of the variable.",
        "explanation_by_baseline": "check standard nameif ("
    },
    {
        "id": 2034,
        "method": "@Override\n    public Cursor newCursor(SQLiteDatabase db, SQLiteCursorDriver driver,\n                            String editTable, SQLiteQuery query) {\n\n                Cursor cursor = new SQLiteCursor(driver, editTable, query);\n\n        // Check if there is an edit table\n        if (editTable != null) {\n            // Check if the table has a cursor wrapper\n            GeoPackageCursorWrapper cursorWrapper = tableCursors.get(editTable);\n            if (cursorWrapper != null) {\n                cursor = cursorWrapper.wrapCursor(cursor);\n            }\n        }\n\n        return cursor;\n    }",
        "variable": "cursor",
        "reference": "a standard cursor",
        "explanation_by_ours": "{@inheritDoc}",
        "explanation_by_baseline": "a new cursorif ("
    },
    {
        "id": 2054,
        "method": "@Override\n    public boolean copy(String database, String databaseCopy) {\n                File dbFile = getFile(database);\n        File dbCopyFile = context.getDatabasePath(databaseCopy);\n        try {\n            GeoPackageIOUtils.copyFile(dbFile, dbCopyFile);\n        } catch (IOException e) {\n            throw new GeoPackageException(\n                    \"Failed to copy GeoPackage database '\" + database\n                            + \"' to '\" + databaseCopy + \"'\", e);\n        }\n\n        return exists(databaseCopy);\n    }",
        "variable": "dbFile",
        "reference": "the database as a new file",
        "explanation_by_ours": "{@inheritDoc}",
        "explanation_by_baseline": "GeoPackage database //if"
    },
    {
        "id": 2066,
        "method": "private Bitmap reprojectTile(Bitmap tile, int requestedTileWidth, int requestedTileHeight, BoundingBox requestBoundingBox, ProjectionTransform transformRequestToTiles, BoundingBox tilesBoundingBox) {\n\n        final double requestedWidthUnitsPerPixel = (requestBoundingBox.getMaxLongitude() - requestBoundingBox.getMinLongitude()) / requestedTileWidth;\n        final double requestedHeightUnitsPerPixel = (requestBoundingBox.getMaxLatitude() - requestBoundingBox.getMinLatitude()) / requestedTileHeight;\n\n        final double tilesDistanceWidth = tilesBoundingBox.getMaxLongitude() - tilesBoundingBox.getMinLongitude();\n        final double tilesDistanceHeight = tilesBoundingBox.getMaxLatitude() - tilesBoundingBox.getMinLatitude();\n\n        final int width = tile.getWidth();\n        final int height = tile.getHeight();\n\n                int[] pixels = new int[width * height];\n        tile.getPixels(pixels, 0, width, 0, 0, width, height);\n\n        // Projected tile pixels to draw the reprojected tile\n        int[] projectedPixels = new int[requestedTileWidth * requestedTileHeight];\n\n        // Retrieve each pixel in the new tile from the unprojected tile\n        for (int y = 0; y < requestedTileHeight; y++) {\n            for (int x = 0; x < requestedTileWidth; x++) {\n\n                double longitude = requestBoundingBox.getMinLongitude() + (x * requestedWidthUnitsPerPixel);\n                double latitude = requestBoundingBox.getMaxLatitude() - (y * requestedHeightUnitsPerPixel);\n                ProjCoordinate fromCoord = new ProjCoordinate(longitude, latitude);\n                ProjCoordinate toCoord = transformRequestToTiles.transform(fromCoord);\n                double projectedLongitude = toCoord.x;\n                double projectedLatitude = toCoord.y;\n\n                int xPixel = (int) Math.round(((projectedLongitude - tilesBoundingBox.getMinLongitude()) / tilesDistanceWidth) * width);\n                int yPixel = (int) Math.round(((tilesBoundingBox.getMaxLatitude() - projectedLatitude) / tilesDistanceHeight) * height);\n\n                xPixel = Math.max(0, xPixel);\n                xPixel = Math.min(width - 1, xPixel);\n\n                yPixel = Math.max(0, yPixel);\n                yPixel = Math.min(height - 1, yPixel);\n\n                int color = pixels[(yPixel * width) + xPixel];\n                projectedPixels[(y * requestedTileWidth) + x] = color;\n            }\n        }\n\n        // Draw the new tile bitmap\n        Bitmap projectedTileBitmap = Bitmap.createBitmap(requestedTileWidth,\n                requestedTileHeight, tile.getConfig());\n        projectedTileBitmap.setPixels(projectedPixels, 0, requestedTileWidth, 0, 0, requestedTileWidth, requestedTileHeight);\n\n        return projectedTileBitmap;\n    }",
        "variable": "pixels",
        "reference": "Tile pixels of the tile matrix tiles",
        "explanation_by_ours": "tile pixels",
        "explanation_by_baseline": "Pixels to draw the tile"
    },
    {
        "id": 2067,
        "method": "private Bitmap reprojectTile(Bitmap tile, int requestedTileWidth, int requestedTileHeight, BoundingBox requestBoundingBox, ProjectionTransform transformRequestToTiles, BoundingBox tilesBoundingBox) {\n\n        final double requestedWidthUnitsPerPixel = (requestBoundingBox.getMaxLongitude() - requestBoundingBox.getMinLongitude()) / requestedTileWidth;\n        final double requestedHeightUnitsPerPixel = (requestBoundingBox.getMaxLatitude() - requestBoundingBox.getMinLatitude()) / requestedTileHeight;\n\n        final double tilesDistanceWidth = tilesBoundingBox.getMaxLongitude() - tilesBoundingBox.getMinLongitude();\n        final double tilesDistanceHeight = tilesBoundingBox.getMaxLatitude() - tilesBoundingBox.getMinLatitude();\n\n        final int width = tile.getWidth();\n        final int height = tile.getHeight();\n\n        // Tile pixels of the tile matrix tiles\n        int[] pixels = new int[width * height];\n        tile.getPixels(pixels, 0, width, 0, 0, width, height);\n\n                int[] projectedPixels = new int[requestedTileWidth * requestedTileHeight];\n\n        // Retrieve each pixel in the new tile from the unprojected tile\n        for (int y = 0; y < requestedTileHeight; y++) {\n            for (int x = 0; x < requestedTileWidth; x++) {\n\n                double longitude = requestBoundingBox.getMinLongitude() + (x * requestedWidthUnitsPerPixel);\n                double latitude = requestBoundingBox.getMaxLatitude() - (y * requestedHeightUnitsPerPixel);\n                ProjCoordinate fromCoord = new ProjCoordinate(longitude, latitude);\n                ProjCoordinate toCoord = transformRequestToTiles.transform(fromCoord);\n                double projectedLongitude = toCoord.x;\n                double projectedLatitude = toCoord.y;\n\n                int xPixel = (int) Math.round(((projectedLongitude - tilesBoundingBox.getMinLongitude()) / tilesDistanceWidth) * width);\n                int yPixel = (int) Math.round(((tilesBoundingBox.getMaxLatitude() - projectedLatitude) / tilesDistanceHeight) * height);\n\n                xPixel = Math.max(0, xPixel);\n                xPixel = Math.min(width - 1, xPixel);\n\n                yPixel = Math.max(0, yPixel);\n                yPixel = Math.min(height - 1, yPixel);\n\n                int color = pixels[(yPixel * width) + xPixel];\n                projectedPixels[(y * requestedTileWidth) + x] = color;\n            }\n        }\n\n        // Draw the new tile bitmap\n        Bitmap projectedTileBitmap = Bitmap.createBitmap(requestedTileWidth,\n                requestedTileHeight, tile.getConfig());\n        projectedTileBitmap.setPixels(projectedPixels, 0, requestedTileWidth, 0, 0, requestedTileWidth, requestedTileHeight);\n\n        return projectedTileBitmap;\n    }",
        "variable": "projectedPixels",
        "reference": "Projected tile pixels to draw the reprojected tile",
        "explanation_by_ours": "array of projected pixels",
        "explanation_by_baseline": "Projected tile pixelsint"
    },
    {
        "id": 2084,
        "method": "public void prioritizeQueryLocation(FeatureIndexType... types) {\n                Set<FeatureIndexType> queryOrder = new LinkedHashSet<>();\n        for (FeatureIndexType type : types) {\n            if (type != FeatureIndexType.NONE) {\n                queryOrder.add(type);\n            }\n        }\n        // Add any locations not provided to this method\n        queryOrder.addAll(indexLocationQueryOrder);\n        // Update the query order set\n        indexLocationQueryOrder = queryOrder;\n    }",
        "variable": "queryOrder",
        "reference": "a new query order set",
        "explanation_by_ours": "the query order of the query locations to prioritize",
        "explanation_by_baseline": "the query order set//"
    },
    {
        "id": 2091,
        "method": "public void setupProperties(LoggerContext context) {\n        Properties props = new Properties();\n    props.setProperty(CoreConstants.DATA_DIR_KEY, getFilesDirectoryPath());\n    final String extDir = getMountedExternalStorageDirectoryPath();\n    if (extDir != null) {\n      props.setProperty(CoreConstants.EXT_DIR_KEY, extDir);\n    }\n    props.setProperty(CoreConstants.PACKAGE_NAME_KEY, getPackageName());\n    props.setProperty(CoreConstants.VERSION_CODE_KEY, getVersionCode());\n    props.setProperty(CoreConstants.VERSION_NAME_KEY, getVersionName());\n\n    context.putProperties(props);\n  }",
        "variable": "props",
        "reference": "legacy properties",
        "explanation_by_ours": "the properties",
        "explanation_by_baseline": "System.out.println(\""
    },
    {
        "id": 2095,
        "method": "public void run() {\n    logger.info(this + \": connected\");\n    HardenedObjectInputStream ois = null;\n    try {\n      ois = createObjectInputStream();\n      while (true) {\n                ILoggingEvent event = (ILoggingEvent) ois.readObject();\n        // get a logger from the hierarchy. The name of the logger is taken to\n        // be the name contained in the event.\n        Logger remoteLogger = lc.getLogger(event.getLoggerName());\n        // apply the logger-level filter\n        if (remoteLogger.isEnabledFor(event.getLevel())) {\n          // finally log the event as if was generated locally\n          remoteLogger.callAppenders(event);\n        }\n      }\n    }\n    catch (EOFException ex) {\n      // this is normal and expected\n      assert true;\n    }\n    catch (IOException ex) {\n      logger.info(this + \": \" + ex);\n    }\n    catch (ClassNotFoundException ex) {\n      logger.error(this + \": unknown event class\");\n    }\n    catch (RuntimeException ex) {\n      logger.error(this + \": \" + ex);\n    }\n    finally {\n      if (ois != null) {\n        CloseUtil.closeQuietly(ois);\n      }\n      close();\n      logger.info(this + \": connection closed\");\n    }\n  }",
        "variable": "event",
        "reference": "an event from the wire",
        "explanation_by_ours": "the event to log.",
        "explanation_by_baseline": "the event from the stream"
    },
    {
        "id": 2096,
        "method": "protected void append(E eventObject) {\n\n    if (!checkEntryConditions()) {\n      return;\n    }\n\n    String key = discriminator.getDiscriminatingValue(eventObject);\n    long now = System.currentTimeMillis();\n    final CyclicBuffer<E> cb = cbTracker.getOrCreate(key, now);\n    subAppend(cb, eventObject);\n\n    try {\n      if (eventEvaluator.evaluate(eventObject)) {\n                CyclicBuffer<E> cbClone = new CyclicBuffer<E>(cb);\n        // see http://jira.qos.ch/browse/LBCLASSIC-221\n        cb.clear();\n\n        if (asynchronousSending) {\n          // perform actual sending asynchronously\n          SenderRunnable senderRunnable = new SenderRunnable(cbClone, eventObject);\n          context.getScheduledExecutorService().execute(senderRunnable);\n        } else {\n          // synchronous sending\n          sendBuffer(cbClone, eventObject);\n        }\n      }\n    } catch (EvaluationException ex) {\n      errorCount++;\n      if (errorCount < CoreConstants.MAX_ERROR_COUNT) {\n        addError(\"SMTPAppender's EventEvaluator threw an Exception-\", ex);\n      }\n    }\n\n    // immediately remove the buffer if asked by the user\n    if (eventMarksEndOfLife(eventObject)) {\n      cbTracker.endOfLife(key);\n    }\n\n    cbTracker.removeStaleComponents(now);\n\n    if (lastTrackerStatusPrint + delayBetweenStatusMessages < now) {\n      addInfo(\"SMTPAppender [\" + name + \"] is tracking [\" + cbTracker.getComponentCount() + \"] buffers\");\n      lastTrackerStatusPrint = now;\n      // quadruple 'delay' assuming less than max delay\n      if (delayBetweenStatusMessages < MAX_DELAY_BETWEEN_STATUS_MESSAGES) {\n        delayBetweenStatusMessages *= 4;\n      }\n    }\n  }",
        "variable": "cbClone",
        "reference": "clone of the CyclicBuffer",
        "explanation_by_ours": "the CyclicBuffer to be cloned before sending out asynchronously",
        "explanation_by_baseline": "if (delayBetweenStatusMessages"
    },
    {
        "id": 2135,
        "method": "protected Composite getFieldEditorParent() {\n\t\tif (style == FLAT) {\n\t\t\t\t\t\tComposite parent = new Composite(fieldEditorParent, SWT.NULL);\n\t\t\tparent.setLayoutData(new GridData(GridData.FILL_HORIZONTAL));\n\t\t\treturn parent;\n\t\t}\n\t\t// Just return the parent\n\t\treturn fieldEditorParent;\n\t}",
        "variable": "parent",
        "reference": "a new parent for each field editor",
        "explanation_by_ours": "the parent composite",
        "explanation_by_baseline": "parent"
    },
    {
        "id": 2141,
        "method": "public EditPart createEditPart(EditPart context,\n                                   Object modelElement) {\n                EditPart part = getPartForElement( modelElement );\n        // store model element in EditPart\n        part.setModel( modelElement );\n        return part;\n    }",
        "variable": "part",
        "reference": "EditPart for model element",
        "explanation_by_ours": "the part to create",
        "explanation_by_baseline": "EditPart"
    },
    {
        "id": 2143,
        "method": "public void drawGraph(ReteGraph newGraph) {\n\n        LayerManager manager = (LayerManager) getGraphicalViewer().getEditPartRegistry().get( LayerManager.ID );\n        ConnectionLayer connLayer = (ConnectionLayer) manager.getLayer( LayerConstants.CONNECTION_LAYER );\n\n        // Lazy-init model initialization\n        if ( getGraphicalViewer().getContents() == null ) {\n            getGraphicalViewer().setContents( getModel() );\n        }\n\n        final boolean isNewDiagram = newGraph != null && newGraph != diagram;\n\n        if ( isNewDiagram ) {\n            diagram.removeAll();\n        }\n\n        // Update connection router according to new model size\n        ConnectionRouter router;\n        if ( (isNewDiagram && newGraph.getChildren().size() < SIMPLE_ROUTER_MIN_NODES) || (!isNewDiagram && getModel().getChildren().size() < SIMPLE_ROUTER_MIN_NODES) ) {\n            router = new ShortestPathConnectionRouter( (IFigure) rootEditPart.getContentPane().getChildren().get( 0 ) );\n        } else {\n            router = ConnectionRouter.NULL;\n        }\n        connLayer.setConnectionRouter( router );\n\n        if ( newGraph != null && newGraph != diagram ) {\n            diagram.addAll( newGraph.getChildren() );\n        }\n\n    }",
        "variable": "router",
        "reference": "connection router",
        "explanation_by_ours": "the connection router",
        "explanation_by_baseline": "connection routernewGraph!="
    },
    {
        "id": 2213,
        "method": "private int getCharIndexAt(TextView textView, MotionEvent event) {\n        // get coordinates\n        int x = (int) event.getX();\n        int y = (int) event.getY();\n        x -= textView.getTotalPaddingLeft();\n        y -= textView.getTotalPaddingTop();\n        x += textView.getScrollX();\n        y += textView.getScrollY();\n\n        /*\n         * Fail-fast check of the line bound.\n         * If we're not within the line bound no character was touched\n         */\n        Layout layout = textView.getLayout();\n        int line = layout.getLineForVertical(y);\n        synchronized (sLineBounds) {\n            layout.getLineBounds(line, sLineBounds);\n            if (!sLineBounds.contains(x, y)) {\n                return -1;\n            }\n        }\n\n                Spanned text = (Spanned) textView.getText();\n        int lineStart = layout.getLineStart(line);\n        int lineEnd = layout.getLineEnd(line);\n        int lineLength = lineEnd - lineStart;\n        if (lineLength == 0) {\n            return -1;\n        }\n        Spanned lineText = (Spanned) text.subSequence(lineStart, lineEnd);\n\n        // compute leading margin and subtract it from the x coordinate\n        int margin = 0;\n        LeadingMarginSpan[] marginSpans = lineText.getSpans(0, lineLength, LeadingMarginSpan.class);\n        if (marginSpans != null) {\n            for (LeadingMarginSpan span : marginSpans) {\n                margin += span.getLeadingMargin(true);\n            }\n        }\n        x -= margin;\n\n        // retrieve text widths\n        float[] widths = new float[lineLength];\n        TextPaint paint = textView.getPaint();\n        paint.getTextWidths(lineText, 0, lineLength, widths);\n\n        // scale text widths by relative font size (absolute size / default size)\n        final float defaultSize = textView.getTextSize();\n        float scaleFactor = 1f;\n        AbsoluteSizeSpan[] absSpans = lineText.getSpans(0, lineLength, AbsoluteSizeSpan.class);\n        if (absSpans != null) {\n            for (AbsoluteSizeSpan span : absSpans) {\n                int spanStart = lineText.getSpanStart(span);\n                int spanEnd = lineText.getSpanEnd(span);\n                scaleFactor = span.getSize() / defaultSize;\n                int start = Math.max(lineStart, spanStart);\n                int end = Math.min(lineEnd, spanEnd);\n                for (int i = start; i < end; i++) {\n                    widths[i] *= scaleFactor;\n                }\n            }\n        }\n\n        // find index of touched character\n        float startChar = 0;\n        float endChar = 0;\n        for (int i = 0; i < lineLength; i++) {\n            startChar = endChar;\n            endChar += widths[i];\n            if (endChar >= x) {\n                // which \"end\" is closer to x, the start or the end of the character?\n                int index = lineStart + (x - startChar < endChar - x ? i : i + 1);\n                //Logger.e(Logger.LOG_TAG, \"Found character: \" + (text.length()>index ? text.charAt(index) : \"\"));\n                return index;\n            }\n        }\n\n        return -1;\n    }",
        "variable": "text",
        "reference": "line text",
        "explanation_by_ours": "The text to get the character index from.",
        "explanation_by_baseline": "line textif (line"
    },
    {
        "id": 2215,
        "method": "private int getCharIndexAt(TextView textView, MotionEvent event) {\n        // get coordinates\n        int x = (int) event.getX();\n        int y = (int) event.getY();\n        x -= textView.getTotalPaddingLeft();\n        y -= textView.getTotalPaddingTop();\n        x += textView.getScrollX();\n        y += textView.getScrollY();\n\n        /*\n         * Fail-fast check of the line bound.\n         * If we're not within the line bound no character was touched\n         */\n        Layout layout = textView.getLayout();\n        int line = layout.getLineForVertical(y);\n        synchronized (sLineBounds) {\n            layout.getLineBounds(line, sLineBounds);\n            if (!sLineBounds.contains(x, y)) {\n                return -1;\n            }\n        }\n\n        // retrieve line text\n        Spanned text = (Spanned) textView.getText();\n        int lineStart = layout.getLineStart(line);\n        int lineEnd = layout.getLineEnd(line);\n        int lineLength = lineEnd - lineStart;\n        if (lineLength == 0) {\n            return -1;\n        }\n        Spanned lineText = (Spanned) text.subSequence(lineStart, lineEnd);\n\n        // compute leading margin and subtract it from the x coordinate\n        int margin = 0;\n        LeadingMarginSpan[] marginSpans = lineText.getSpans(0, lineLength, LeadingMarginSpan.class);\n        if (marginSpans != null) {\n            for (LeadingMarginSpan span : marginSpans) {\n                margin += span.getLeadingMargin(true);\n            }\n        }\n        x -= margin;\n\n                float[] widths = new float[lineLength];\n        TextPaint paint = textView.getPaint();\n        paint.getTextWidths(lineText, 0, lineLength, widths);\n\n        // scale text widths by relative font size (absolute size / default size)\n        final float defaultSize = textView.getTextSize();\n        float scaleFactor = 1f;\n        AbsoluteSizeSpan[] absSpans = lineText.getSpans(0, lineLength, AbsoluteSizeSpan.class);\n        if (absSpans != null) {\n            for (AbsoluteSizeSpan span : absSpans) {\n                int spanStart = lineText.getSpanStart(span);\n                int spanEnd = lineText.getSpanEnd(span);\n                scaleFactor = span.getSize() / defaultSize;\n                int start = Math.max(lineStart, spanStart);\n                int end = Math.min(lineEnd, spanEnd);\n                for (int i = start; i < end; i++) {\n                    widths[i] *= scaleFactor;\n                }\n            }\n        }\n\n        // find index of touched character\n        float startChar = 0;\n        float endChar = 0;\n        for (int i = 0; i < lineLength; i++) {\n            startChar = endChar;\n            endChar += widths[i];\n            if (endChar >= x) {\n                // which \"end\" is closer to x, the start or the end of the character?\n                int index = lineStart + (x - startChar < endChar - x ? i : i + 1);\n                //Logger.e(Logger.LOG_TAG, \"Found character: \" + (text.length()>index ? text.charAt(index) : \"\"));\n                return index;\n            }\n        }\n\n        return -1;\n    }",
        "variable": "widths",
        "reference": "text widths",
        "explanation_by_ours": "The widths of the view.",
        "explanation_by_baseline": "text widthsif (line"
    },
    {
        "id": 2335,
        "method": "public Collection<ProfileLocalObject> findProfilesByAttribute(String attributeName,\n\t\t\tObject attributeValue) throws NullPointerException,\n\t\t\tIllegalArgumentException, TransactionRequiredLocalException,\n\t\t\tSLEEException {\n\t\t\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"findProfilesByAttribute( attributeName = \"+attributeName+\" , attributeValue = \"+attributeValue+\" )\");\n\t\t}\n\t\t\n\t\tsleeContainer.getTransactionManager().mandateTransaction();\n\n\t\t// We get profile entities\n\t\tCollection<ProfileEntity> profileEntities = null;\n\t\ttry {\n\t\t\tprofileEntities = getProfileEntitiesByAttribute(attributeName, attributeValue, true);\n\t\t}\n\t\tcatch (AttributeNotIndexedException e) {\n\t\t\tthrow new SLEEException(e.getMessage(),e);\n\t\t} catch (UnrecognizedAttributeException e) {\n\t\t\tthrow new IllegalArgumentException(e);\n\t\t} catch (AttributeTypeMismatchException e) {\n\t\t\tthrow new IllegalArgumentException(e);\n\t\t}\n\n\t\t       ArrayList<ProfileLocalObject> plocs = new ArrayList<ProfileLocalObject>();\n       for(ProfileEntity profileEntity : profileEntities) {\n    \t   plocs.add(transactionView.getProfile(profileEntity).getProfileLocalObject());\n      }\n      return Collections.unmodifiableCollection(plocs);\n\t}",
        "variable": "plocs",
        "reference": "ProfileLocalObjects",
        "explanation_by_ours": "a {@link java.util.Collection} of {@link ProfileLocal",
        "explanation_by_baseline": "to get plocs{"
    },
    {
        "id": 2361,
        "method": "public void start(URL deployableUnitURL, String deployableUnitName) throws DeploymentException {\n\t\tDeployableUnitWrapper du = new DeployableUnitWrapper(deployableUnitURL, deployableUnitName);\n\n\t\tif (logger.isTraceEnabled()) {\n\t\t\tlogger.trace(\"Method start called for \" + du.getUrl() + \" [DU: \" + deployableUnitName + \"]\");\n\t\t}\n\n\t\ttry {\n\t\t\t\t\t\tDeployableUnit realDU = deployableUnits.get(du.getFileName());\n\n\t\t\t// If it exists, install it.\n\t\t\tif (realDU != null) {\n\t\t\t\twhile (isInUndeployList(du.getFileName())) {\n\t\t\t\t\tThread.sleep(getWaitTimeBetweenOperations());\n\t\t\t\t}\n\t\t\t\tsleeContainerDeployer.getDeploymentManager().installDeployableUnit(realDU);\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"\", e);\n\t\t}\n\t}",
        "variable": "realDU",
        "reference": "the deployable unit object",
        "explanation_by_ours": "the real deployable unit object",
        "explanation_by_baseline": "the real DU."
    },
    {
        "id": 2382,
        "method": "private void parseDeployConfig(InputStream deployConfigInputStream,\n\t\t\tResourceManagement resourceManagement) throws SAXException,\n\t\t\tParserConfigurationException, IOException {\n\n\t\tif (deployConfigInputStream == null) {\n\t\t\tthrow new NullPointerException(\"null deploy config input stream\");\n\t\t}\n\n\t\tDocument doc = null;\n\t\ttry {\n\n\t\t\t// Read the file into a Document\n\t\t\tSchemaFactory schemaFactory = SchemaFactory\n\t\t\t\t\t.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI);\n\t\t\tSchema schema = schemaFactory.newSchema(DeployConfigParser.class\n\t\t\t\t\t.getClassLoader().getResource(\"deploy-config.xsd\"));\n\n\t\t\tDocumentBuilderFactory factory = DocumentBuilderFactory\n\t\t\t\t\t.newInstance();\n\t\t\t// factory.setValidating(false);\n\t\t\tfactory.setSchema(schema);\n\t\t\tDocumentBuilder builder = factory.newDocumentBuilder();\n\n\t\t\tbuilder.setErrorHandler(new ErrorHandler() {\n\t\t\t\tpublic void error(SAXParseException e) throws SAXException {\n\t\t\t\t\tlogger.error(\"Error parsing deploy-config.xml\", e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tpublic void fatalError(SAXParseException e) throws SAXException {\n\t\t\t\t\tlogger.error(\"Fatal error parsing deploy-config.xml\", e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tpublic void warning(SAXParseException e) throws SAXException {\n\t\t\t\t\tlogger.warn(\"Warning parsing deploy-config.xml\", e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tdoc = builder.parse(deployConfigInputStream);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tdeployConfigInputStream.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tlogger.error(\"failed to close deploy config input stream\", e);\n\t\t\t}\n\t\t}\n\n\t\tMap<String, Collection<ManagementAction>> postInstallActions = new HashMap<String, Collection<ManagementAction>>();\n\n\t\tMap<String, Collection<ManagementAction>> preUninstallActions = new HashMap<String, Collection<ManagementAction>>();\n\n\t\t// By now we only care about <ra-entity> nodes\n\t\tNodeList raEntities = doc.getElementsByTagName(\"ra-entity\");\n\n\t\t\t\tString raId = null;\n\n\t\t// The collection of Post-Install Actions\n\t\tCollection<ManagementAction> cPostInstallActions = new ArrayList<ManagementAction>();\n\n\t\t// The collection of Pre-Uninstall Actions\n\t\tCollection<ManagementAction> cPreUninstallActions = new ArrayList<ManagementAction>();\n\n\t\t// Iterate through each ra-entity node\n\t\tfor (int i = 0; i < raEntities.getLength(); i++) {\n\t\t\tElement raEntity = (Element) raEntities.item(i);\n\n\t\t\t// Get the component ID\n\t\t\tComponentIDPropertyEditor cidpe = new ComponentIDPropertyEditor();\n\t\t\tcidpe.setAsText(raEntity.getAttribute(\"resource-adaptor-id\"));\n\n\t\t\traId = cidpe.getValue().toString();\n\n\t\t\t// The RA Entity Name\n\t\t\tString entityName = raEntity.getAttribute(\"entity-name\");\n\n\t\t\t// Select the properties node\n\t\t\tNodeList propsNodeList = raEntity\n\t\t\t\t\t.getElementsByTagName(\"properties\");\n\n\t\t\tif (propsNodeList.getLength() > 1) {\n\t\t\t\tlogger.warn(\"Invalid ra-entity element, has more than one properties child. Reading only first.\");\n\t\t\t}\n\n\t\t\t// The properties for this RA\n\t\t\tConfigProperties props = new ConfigProperties();\n\t\t\tElement propsNode = (Element) propsNodeList.item(0);\n\t\t\t// Do we have any properties at all?\n\t\t\tif (propsNode != null) {\n\t\t\t\t// Select the property elements\n\t\t\t\tNodeList propsList = propsNode.getElementsByTagName(\"property\");\n\t\t\t\t// For each element, add it to the Properties object\n\t\t\t\tfor (int j = 0; j < propsList.getLength(); j++) {\n\t\t\t\t\tElement property = (Element) propsList.item(j);\n\t\t\t\t\tString propertyName = property.getAttribute(\"name\");\n\t\t\t\t\tString propertyType = property.getAttribute(\"type\");\n\t\t\t\t\tString propertyValue = property.getAttribute(\"value\");\n\t\t\t\t\tprops.addProperty(new ConfigProperties.Property(\n\t\t\t\t\t\t\tpropertyName, propertyType,\n\t\t\t\t\t\t\tConfigProperties.Property.toObject(propertyType,\n\t\t\t\t\t\t\t\t\tpropertyValue)));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Create the Resource Adaptor ID\n\t\t\tcidpe.setAsText(raEntity.getAttribute(\"resource-adaptor-id\"));\n\n\t\t\tResourceAdaptorID componentID = (ResourceAdaptorID) cidpe\n\t\t\t\t\t.getValue();\n\n\t\t\t// Add the Create and Activate RA Entity actions to the Post-Install\n\t\t\t// Actions\n\t\t\tcPostInstallActions.add(new CreateResourceAdaptorEntityAction(\n\t\t\t\t\tcomponentID, entityName, props, resourceManagement));\n\t\t\tcPostInstallActions.add(new ActivateResourceAdaptorEntityAction(\n\t\t\t\t\tentityName, resourceManagement));\n\n\t\t\t// Each RA might have zero or more links.. get them\n\t\t\tNodeList links = raEntity.getElementsByTagName(\"ra-link\");\n\n\t\t\tfor (int j = 0; j < links.getLength(); j++) {\n\t\t\t\tString linkName = ((Element) links.item(j))\n\t\t\t\t\t\t.getAttribute(\"name\");\n\n\t\t\t\tcPostInstallActions.add(new BindLinkNameAction(linkName,\n\t\t\t\t\t\tentityName, resourceManagement));\n\n\t\t\t\tcPreUninstallActions.add(new UnbindLinkNameAction(linkName,\n\t\t\t\t\t\tresourceManagement));\n\t\t\t}\n\n\t\t\t// Add the Deactivate and Remove RA Entity actions to the\n\t\t\t// Pre-Uninstall Actions\n\t\t\tcPreUninstallActions.add(new DeactivateResourceAdaptorEntityAction(\n\t\t\t\t\tentityName, resourceManagement));\n\t\t\tcPreUninstallActions.add(new RemoveResourceAdaptorEntityAction(\n\t\t\t\t\tentityName, resourceManagement));\n\n\t\t\t// Finally add the actions to the respective hashmap.\n\t\t\tif (raId != null) {\n\t\t\t\t// We need to check if we are updating or adding new ones.\n\t\t\t\tif (postInstallActions.containsKey(raId)) {\n\t\t\t\t\tpostInstallActions.get(raId).addAll(cPostInstallActions);\n\t\t\t\t} else {\n\t\t\t\t\tpostInstallActions.put(raId, cPostInstallActions);\n\t\t\t\t}\n\n\t\t\t\t// Same here...\n\t\t\t\tif (preUninstallActions.containsKey(raId)) {\n\t\t\t\t\tpreUninstallActions.get(raId).addAll(cPreUninstallActions);\n\t\t\t\t} else {\n\t\t\t\t\tpreUninstallActions.put(raId, cPreUninstallActions);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// recreate the lists for the next round (might come a new RA ID)...\n\t\t\tcPostInstallActions = new ArrayList<ManagementAction>();\n\t\t\tcPreUninstallActions = new ArrayList<ManagementAction>();\n\t\t\traId = null;\n\n\t\t}\n\n\t\tthis.postInstallActions = Collections\n\t\t\t\t.unmodifiableMap(postInstallActions);\n\t\tthis.preUninstallActions = Collections\n\t\t\t\t.unmodifiableMap(preUninstallActions);\n\t}",
        "variable": "raId",
        "reference": "The RA identifier",
        "explanation_by_ours": "the resource id",
        "explanation_by_baseline": "The RA ID= new"
    },
    {
        "id": 2386,
        "method": "private void parseDeployConfig(InputStream deployConfigInputStream,\n\t\t\tResourceManagement resourceManagement) throws SAXException,\n\t\t\tParserConfigurationException, IOException {\n\n\t\tif (deployConfigInputStream == null) {\n\t\t\tthrow new NullPointerException(\"null deploy config input stream\");\n\t\t}\n\n\t\tDocument doc = null;\n\t\ttry {\n\n\t\t\t// Read the file into a Document\n\t\t\tSchemaFactory schemaFactory = SchemaFactory\n\t\t\t\t\t.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI);\n\t\t\tSchema schema = schemaFactory.newSchema(DeployConfigParser.class\n\t\t\t\t\t.getClassLoader().getResource(\"deploy-config.xsd\"));\n\n\t\t\tDocumentBuilderFactory factory = DocumentBuilderFactory\n\t\t\t\t\t.newInstance();\n\t\t\t// factory.setValidating(false);\n\t\t\tfactory.setSchema(schema);\n\t\t\tDocumentBuilder builder = factory.newDocumentBuilder();\n\n\t\t\tbuilder.setErrorHandler(new ErrorHandler() {\n\t\t\t\tpublic void error(SAXParseException e) throws SAXException {\n\t\t\t\t\tlogger.error(\"Error parsing deploy-config.xml\", e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tpublic void fatalError(SAXParseException e) throws SAXException {\n\t\t\t\t\tlogger.error(\"Fatal error parsing deploy-config.xml\", e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tpublic void warning(SAXParseException e) throws SAXException {\n\t\t\t\t\tlogger.warn(\"Warning parsing deploy-config.xml\", e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tdoc = builder.parse(deployConfigInputStream);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tdeployConfigInputStream.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tlogger.error(\"failed to close deploy config input stream\", e);\n\t\t\t}\n\t\t}\n\n\t\tMap<String, Collection<ManagementAction>> postInstallActions = new HashMap<String, Collection<ManagementAction>>();\n\n\t\tMap<String, Collection<ManagementAction>> preUninstallActions = new HashMap<String, Collection<ManagementAction>>();\n\n\t\t// By now we only care about <ra-entity> nodes\n\t\tNodeList raEntities = doc.getElementsByTagName(\"ra-entity\");\n\n\t\t// The RA identifier\n\t\tString raId = null;\n\n\t\t// The collection of Post-Install Actions\n\t\tCollection<ManagementAction> cPostInstallActions = new ArrayList<ManagementAction>();\n\n\t\t// The collection of Pre-Uninstall Actions\n\t\tCollection<ManagementAction> cPreUninstallActions = new ArrayList<ManagementAction>();\n\n\t\t// Iterate through each ra-entity node\n\t\tfor (int i = 0; i < raEntities.getLength(); i++) {\n\t\t\tElement raEntity = (Element) raEntities.item(i);\n\n\t\t\t// Get the component ID\n\t\t\tComponentIDPropertyEditor cidpe = new ComponentIDPropertyEditor();\n\t\t\tcidpe.setAsText(raEntity.getAttribute(\"resource-adaptor-id\"));\n\n\t\t\traId = cidpe.getValue().toString();\n\n\t\t\t\t\t\tString entityName = raEntity.getAttribute(\"entity-name\");\n\n\t\t\t// Select the properties node\n\t\t\tNodeList propsNodeList = raEntity\n\t\t\t\t\t.getElementsByTagName(\"properties\");\n\n\t\t\tif (propsNodeList.getLength() > 1) {\n\t\t\t\tlogger.warn(\"Invalid ra-entity element, has more than one properties child. Reading only first.\");\n\t\t\t}\n\n\t\t\t// The properties for this RA\n\t\t\tConfigProperties props = new ConfigProperties();\n\t\t\tElement propsNode = (Element) propsNodeList.item(0);\n\t\t\t// Do we have any properties at all?\n\t\t\tif (propsNode != null) {\n\t\t\t\t// Select the property elements\n\t\t\t\tNodeList propsList = propsNode.getElementsByTagName(\"property\");\n\t\t\t\t// For each element, add it to the Properties object\n\t\t\t\tfor (int j = 0; j < propsList.getLength(); j++) {\n\t\t\t\t\tElement property = (Element) propsList.item(j);\n\t\t\t\t\tString propertyName = property.getAttribute(\"name\");\n\t\t\t\t\tString propertyType = property.getAttribute(\"type\");\n\t\t\t\t\tString propertyValue = property.getAttribute(\"value\");\n\t\t\t\t\tprops.addProperty(new ConfigProperties.Property(\n\t\t\t\t\t\t\tpropertyName, propertyType,\n\t\t\t\t\t\t\tConfigProperties.Property.toObject(propertyType,\n\t\t\t\t\t\t\t\t\tpropertyValue)));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Create the Resource Adaptor ID\n\t\t\tcidpe.setAsText(raEntity.getAttribute(\"resource-adaptor-id\"));\n\n\t\t\tResourceAdaptorID componentID = (ResourceAdaptorID) cidpe\n\t\t\t\t\t.getValue();\n\n\t\t\t// Add the Create and Activate RA Entity actions to the Post-Install\n\t\t\t// Actions\n\t\t\tcPostInstallActions.add(new CreateResourceAdaptorEntityAction(\n\t\t\t\t\tcomponentID, entityName, props, resourceManagement));\n\t\t\tcPostInstallActions.add(new ActivateResourceAdaptorEntityAction(\n\t\t\t\t\tentityName, resourceManagement));\n\n\t\t\t// Each RA might have zero or more links.. get them\n\t\t\tNodeList links = raEntity.getElementsByTagName(\"ra-link\");\n\n\t\t\tfor (int j = 0; j < links.getLength(); j++) {\n\t\t\t\tString linkName = ((Element) links.item(j))\n\t\t\t\t\t\t.getAttribute(\"name\");\n\n\t\t\t\tcPostInstallActions.add(new BindLinkNameAction(linkName,\n\t\t\t\t\t\tentityName, resourceManagement));\n\n\t\t\t\tcPreUninstallActions.add(new UnbindLinkNameAction(linkName,\n\t\t\t\t\t\tresourceManagement));\n\t\t\t}\n\n\t\t\t// Add the Deactivate and Remove RA Entity actions to the\n\t\t\t// Pre-Uninstall Actions\n\t\t\tcPreUninstallActions.add(new DeactivateResourceAdaptorEntityAction(\n\t\t\t\t\tentityName, resourceManagement));\n\t\t\tcPreUninstallActions.add(new RemoveResourceAdaptorEntityAction(\n\t\t\t\t\tentityName, resourceManagement));\n\n\t\t\t// Finally add the actions to the respective hashmap.\n\t\t\tif (raId != null) {\n\t\t\t\t// We need to check if we are updating or adding new ones.\n\t\t\t\tif (postInstallActions.containsKey(raId)) {\n\t\t\t\t\tpostInstallActions.get(raId).addAll(cPostInstallActions);\n\t\t\t\t} else {\n\t\t\t\t\tpostInstallActions.put(raId, cPostInstallActions);\n\t\t\t\t}\n\n\t\t\t\t// Same here...\n\t\t\t\tif (preUninstallActions.containsKey(raId)) {\n\t\t\t\t\tpreUninstallActions.get(raId).addAll(cPreUninstallActions);\n\t\t\t\t} else {\n\t\t\t\t\tpreUninstallActions.put(raId, cPreUninstallActions);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// recreate the lists for the next round (might come a new RA ID)...\n\t\t\tcPostInstallActions = new ArrayList<ManagementAction>();\n\t\t\tcPreUninstallActions = new ArrayList<ManagementAction>();\n\t\t\traId = null;\n\n\t\t}\n\n\t\tthis.postInstallActions = Collections\n\t\t\t\t.unmodifiableMap(postInstallActions);\n\t\tthis.preUninstallActions = Collections\n\t\t\t\t.unmodifiableMap(preUninstallActions);\n\t}",
        "variable": "entityName",
        "reference": "The RA Entity Name",
        "explanation_by_ours": "the entity name",
        "explanation_by_baseline": "Get the RA entity name"
    },
    {
        "id": 2387,
        "method": "private void parseDeployConfig(InputStream deployConfigInputStream,\n\t\t\tResourceManagement resourceManagement) throws SAXException,\n\t\t\tParserConfigurationException, IOException {\n\n\t\tif (deployConfigInputStream == null) {\n\t\t\tthrow new NullPointerException(\"null deploy config input stream\");\n\t\t}\n\n\t\tDocument doc = null;\n\t\ttry {\n\n\t\t\t// Read the file into a Document\n\t\t\tSchemaFactory schemaFactory = SchemaFactory\n\t\t\t\t\t.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI);\n\t\t\tSchema schema = schemaFactory.newSchema(DeployConfigParser.class\n\t\t\t\t\t.getClassLoader().getResource(\"deploy-config.xsd\"));\n\n\t\t\tDocumentBuilderFactory factory = DocumentBuilderFactory\n\t\t\t\t\t.newInstance();\n\t\t\t// factory.setValidating(false);\n\t\t\tfactory.setSchema(schema);\n\t\t\tDocumentBuilder builder = factory.newDocumentBuilder();\n\n\t\t\tbuilder.setErrorHandler(new ErrorHandler() {\n\t\t\t\tpublic void error(SAXParseException e) throws SAXException {\n\t\t\t\t\tlogger.error(\"Error parsing deploy-config.xml\", e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tpublic void fatalError(SAXParseException e) throws SAXException {\n\t\t\t\t\tlogger.error(\"Fatal error parsing deploy-config.xml\", e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tpublic void warning(SAXParseException e) throws SAXException {\n\t\t\t\t\tlogger.warn(\"Warning parsing deploy-config.xml\", e);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tdoc = builder.parse(deployConfigInputStream);\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tdeployConfigInputStream.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tlogger.error(\"failed to close deploy config input stream\", e);\n\t\t\t}\n\t\t}\n\n\t\tMap<String, Collection<ManagementAction>> postInstallActions = new HashMap<String, Collection<ManagementAction>>();\n\n\t\tMap<String, Collection<ManagementAction>> preUninstallActions = new HashMap<String, Collection<ManagementAction>>();\n\n\t\t// By now we only care about <ra-entity> nodes\n\t\tNodeList raEntities = doc.getElementsByTagName(\"ra-entity\");\n\n\t\t// The RA identifier\n\t\tString raId = null;\n\n\t\t// The collection of Post-Install Actions\n\t\tCollection<ManagementAction> cPostInstallActions = new ArrayList<ManagementAction>();\n\n\t\t// The collection of Pre-Uninstall Actions\n\t\tCollection<ManagementAction> cPreUninstallActions = new ArrayList<ManagementAction>();\n\n\t\t// Iterate through each ra-entity node\n\t\tfor (int i = 0; i < raEntities.getLength(); i++) {\n\t\t\tElement raEntity = (Element) raEntities.item(i);\n\n\t\t\t// Get the component ID\n\t\t\tComponentIDPropertyEditor cidpe = new ComponentIDPropertyEditor();\n\t\t\tcidpe.setAsText(raEntity.getAttribute(\"resource-adaptor-id\"));\n\n\t\t\traId = cidpe.getValue().toString();\n\n\t\t\t// The RA Entity Name\n\t\t\tString entityName = raEntity.getAttribute(\"entity-name\");\n\n\t\t\t// Select the properties node\n\t\t\tNodeList propsNodeList = raEntity\n\t\t\t\t\t.getElementsByTagName(\"properties\");\n\n\t\t\tif (propsNodeList.getLength() > 1) {\n\t\t\t\tlogger.warn(\"Invalid ra-entity element, has more than one properties child. Reading only first.\");\n\t\t\t}\n\n\t\t\t\t\t\tConfigProperties props = new ConfigProperties();\n\t\t\tElement propsNode = (Element) propsNodeList.item(0);\n\t\t\t// Do we have any properties at all?\n\t\t\tif (propsNode != null) {\n\t\t\t\t// Select the property elements\n\t\t\t\tNodeList propsList = propsNode.getElementsByTagName(\"property\");\n\t\t\t\t// For each element, add it to the Properties object\n\t\t\t\tfor (int j = 0; j < propsList.getLength(); j++) {\n\t\t\t\t\tElement property = (Element) propsList.item(j);\n\t\t\t\t\tString propertyName = property.getAttribute(\"name\");\n\t\t\t\t\tString propertyType = property.getAttribute(\"type\");\n\t\t\t\t\tString propertyValue = property.getAttribute(\"value\");\n\t\t\t\t\tprops.addProperty(new ConfigProperties.Property(\n\t\t\t\t\t\t\tpropertyName, propertyType,\n\t\t\t\t\t\t\tConfigProperties.Property.toObject(propertyType,\n\t\t\t\t\t\t\t\t\tpropertyValue)));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Create the Resource Adaptor ID\n\t\t\tcidpe.setAsText(raEntity.getAttribute(\"resource-adaptor-id\"));\n\n\t\t\tResourceAdaptorID componentID = (ResourceAdaptorID) cidpe\n\t\t\t\t\t.getValue();\n\n\t\t\t// Add the Create and Activate RA Entity actions to the Post-Install\n\t\t\t// Actions\n\t\t\tcPostInstallActions.add(new CreateResourceAdaptorEntityAction(\n\t\t\t\t\tcomponentID, entityName, props, resourceManagement));\n\t\t\tcPostInstallActions.add(new ActivateResourceAdaptorEntityAction(\n\t\t\t\t\tentityName, resourceManagement));\n\n\t\t\t// Each RA might have zero or more links.. get them\n\t\t\tNodeList links = raEntity.getElementsByTagName(\"ra-link\");\n\n\t\t\tfor (int j = 0; j < links.getLength(); j++) {\n\t\t\t\tString linkName = ((Element) links.item(j))\n\t\t\t\t\t\t.getAttribute(\"name\");\n\n\t\t\t\tcPostInstallActions.add(new BindLinkNameAction(linkName,\n\t\t\t\t\t\tentityName, resourceManagement));\n\n\t\t\t\tcPreUninstallActions.add(new UnbindLinkNameAction(linkName,\n\t\t\t\t\t\tresourceManagement));\n\t\t\t}\n\n\t\t\t// Add the Deactivate and Remove RA Entity actions to the\n\t\t\t// Pre-Uninstall Actions\n\t\t\tcPreUninstallActions.add(new DeactivateResourceAdaptorEntityAction(\n\t\t\t\t\tentityName, resourceManagement));\n\t\t\tcPreUninstallActions.add(new RemoveResourceAdaptorEntityAction(\n\t\t\t\t\tentityName, resourceManagement));\n\n\t\t\t// Finally add the actions to the respective hashmap.\n\t\t\tif (raId != null) {\n\t\t\t\t// We need to check if we are updating or adding new ones.\n\t\t\t\tif (postInstallActions.containsKey(raId)) {\n\t\t\t\t\tpostInstallActions.get(raId).addAll(cPostInstallActions);\n\t\t\t\t} else {\n\t\t\t\t\tpostInstallActions.put(raId, cPostInstallActions);\n\t\t\t\t}\n\n\t\t\t\t// Same here...\n\t\t\t\tif (preUninstallActions.containsKey(raId)) {\n\t\t\t\t\tpreUninstallActions.get(raId).addAll(cPreUninstallActions);\n\t\t\t\t} else {\n\t\t\t\t\tpreUninstallActions.put(raId, cPreUninstallActions);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// recreate the lists for the next round (might come a new RA ID)...\n\t\t\tcPostInstallActions = new ArrayList<ManagementAction>();\n\t\t\tcPreUninstallActions = new ArrayList<ManagementAction>();\n\t\t\traId = null;\n\n\t\t}\n\n\t\tthis.postInstallActions = Collections\n\t\t\t\t.unmodifiableMap(postInstallActions);\n\t\tthis.preUninstallActions = Collections\n\t\t\t\t.unmodifiableMap(preUninstallActions);\n\t}",
        "variable": "props",
        "reference": "The properties for this RA",
        "explanation_by_ours": "the properties",
        "explanation_by_baseline": "Add the properties to it"
    },
    {
        "id": 2401,
        "method": "private boolean hasReferringDU() throws Exception {\r\n\r\n        SleeContainer sC = SleeContainer.lookupFromJndi();\r\n\r\n    for (String componentIdString : this.getComponents()) {\r\n      ComponentIDPropertyEditor cidpe = new ComponentIDPropertyEditor();\r\n      cidpe.setAsText( componentIdString );\r\n\r\n      ComponentID componentId = (ComponentID) cidpe.getValue();\r\n\r\n      for (ComponentID referringComponentId : sC.getComponentRepository().getReferringComponents(componentId)) {\r\n        ComponentIDPropertyEditor rcidpe = new ComponentIDPropertyEditor();\r\n        rcidpe.setValue( referringComponentId );\r\n\r\n        String referringComponentIdString = rcidpe.getAsText();\r\n\r\n        if (!this.getComponents().contains( referringComponentIdString )) {\r\n          return true;\r\n        }\r\n      }\r\n    }\r\n\r\n    return false;\r\n  }",
        "variable": "sC",
        "reference": "SleeContainer instance from JNDI",
        "explanation_by_ours": "the SleeContainer instance",
        "explanation_by_baseline": "all referring components from"
    },
    {
        "id": 2463,
        "method": "public <T> Page<T> queryPage(int rowsPerPage, String param, Class<T> classOfT) {\n\t\tif(param == null) { // assume first page\n\t\t\treturn queryNextPage(rowsPerPage, null, null, null, null, classOfT);\n\t\t}\n\t\tString currentStartKey;\n\t\tString currentStartKeyDocId;\n\t\tString startKey;\n\t\tString startKeyDocId;\n\t\tString action;\n\t\ttry {\n\t\t\t\t\t\tfinal JsonObject json = new JsonParser().parse(new String(Base64.decodeBase64(param.getBytes()))).getAsJsonObject();\n\t\t\tif(log.isDebugEnabled()) {\n\t\t\t\tlog.debug(\"Paging Param Decoded = \" + json);\n\t\t\t}\n\t\t\tfinal JsonObject jsonCurrent = json.getAsJsonObject(CURRENT_KEYS);\n\t\t\tcurrentStartKey = jsonCurrent.get(CURRENT_START_KEY).getAsString();\n\t\t\tcurrentStartKeyDocId = jsonCurrent.get(CURRENT_START_KEY_DOC_ID).getAsString();\n\t\t\tstartKey = json.get(START_KEY).getAsString();\n\t\t\tstartKeyDocId = json.get(START_KEY_DOC_ID).getAsString();\n\t\t\taction = json.get(ACTION).getAsString();\n\t\t} catch (Exception e) {\n\t\t\tthrow new CouchDbException(\"could not parse the given param!\", e);\n\t\t}\n\t\tif(PREVIOUS.equals(action)) { // previous\n\t\t\treturn queryPreviousPage(rowsPerPage, currentStartKey, currentStartKeyDocId, startKey, startKeyDocId, classOfT);\n\t\t} else { // next\n\t\t\treturn queryNextPage(rowsPerPage, currentStartKey, currentStartKeyDocId, startKey, startKeyDocId, classOfT);\n\t\t}\n\t}",
        "variable": "json",
        "reference": "the returned HEXed JSON object",
        "explanation_by_ours": "the JSON object containing the paging parameters",
        "explanation_by_baseline": "the given param try {"
    },
    {
        "id": 2473,
        "method": "private NotificationResponse prepareResponse(Set<JpaEntry> entries, String username) {\n\n        Map<String,NotificationCategory> categories = new HashMap<>();\n        for (JpaEntry entry : entries) {\n\n            // Choose a category title\n            final String categryTitle = !StringUtils.isBlank(entry.getCategory())\n                    ? entry.getCategory()\n                    : messages.getMessage(UNCATEGORIZED_MESSAGE_CODE, null, \n                            UNCATEGORIZED_DEFAULT_MESSAGE, Locale.getDefault());\n\n                        NotificationCategory category = categories.get(categryTitle);\n            if (category == null) {\n                category = new NotificationCategory();\n                category.setTitle(categryTitle);\n                categories.put(categryTitle, category);\n            }\n\n            // Prepare a NotificationEntry\n            NotificationEntry y = prepareEntry(entry, username);\n            if (y != null) {\n                category.addEntries(Collections.singletonList(y));\n            }\n\n        }\n\n        // Create & load the response\n        final List<NotificationCategory> cList = new ArrayList<>(categories.values());\n        final List<NotificationError> eList = Collections.emptyList();  // Anything here?\n\n        return new NotificationResponse(cList, eList);\n\n    }",
        "variable": "category",
        "reference": "the category object matching the title",
        "explanation_by_ours": "the category",
        "explanation_by_baseline": "a categorynew NotificationResponse"
    },
    {
        "id": 2516,
        "method": "public static EllipseRotated_F64 convert( EllipseQuadratic_F64 input , EllipseRotated_F64 output ) {\n\t\tif( output == null )\n\t\t\toutput = new EllipseRotated_F64();\n\n\t\tdouble a11 = input.A;\n\t\tdouble a12 = input.B;\n\t\tdouble a22 = input.C;\n\t\tdouble b1  = 2*input.D;\n\t\tdouble b2  = 2*input.E;\n\t\tdouble c = input.F;\n\n\t\toutput.center.x = (a22*b1-a12*b2)/(2*(a12*a12 - a11*a22));\n\t\toutput.center.y = (a11*b2-a12*b1)/(2*(a12*a12 - a11*a22));\n\n\t\tdouble k1 = output.center.x;\n\t\tdouble k2 = output.center.y;\n\n\t\tdouble mu = 1.0/(a11*k1*k1 + 2*a12*k1*k2 + a22*k2*k2 - c);\n\t\tdouble m11 = mu*a11;\n\t\tdouble m12 = mu*a12;\n\t\tdouble m22 = mu*a22;\n\n\t\tdouble inner = Math.sqrt((m11-m22)*(m11-m22) + 4*m12*m12);\n\t\tdouble l1 = ((m11+m22) + inner)/2.0;\n\t\tdouble l2 = ((m11+m22) - inner)/2.0;\n\n\t\toutput.b = 1/(double)Math.sqrt(l1);\n\t\toutput.a = 1/(double)Math.sqrt(l2);\n\n\t\t// direction of minor axis\n\t\tdouble dx,dy;\n\t\tif( m11 >= m22 ) {\n\t\t\tdx = l1-m22;\n\t\t\tdy = m12;\n\t\t} else {\n\t\t\tdx = m12;\n\t\t\tdy = l1-m11;\n\t\t}\n\n\t\t// direction of major axis\n\t\toutput.phi = Math.atan2(-dx,dy);\n\t\tif( output.phi < -GrlConstants.PId2 ) {\n\t\t\toutput.phi += (double)Math.PI;\n\t\t} else if( output.phi > GrlConstants.PId2 ) {\n\t\t\toutput.phi -= (double)Math.PI;\n\t\t}\n\n\t\treturn output;\n\t}",
        "variable": "dx",
        "reference": "direction of minor axis",
        "explanation_by_ours": "The rotation of the ellipse.",
        "explanation_by_baseline": "direction of minor axis="
    },
    {
        "id": 2547,
        "method": "public static void makeAFishyDecision(int numberOfFish)\n  {\n    // Use a switch...case on the numberOfFish\n    switch (numberOfFish)\n    {\n      // When the numberOfFish is -1\n      case -1 :\n        // Uncomment to create a string of this image\n        String image = \"../TeachingKidsProgramming.Source.Java/src/main/resources/icons/thumb-up.png\";\n                ImageIcon icon = new ImageIcon(image);\n        // Show a message with the fancy message box this text, this title and this icon...\n        FancyMessageBox.showMesage(\"Had a Fish\", \"Not hungry anymore...\", icon);\n        // End\n        break;\n      // When the numberOfFish is 0  \n      case 0 :\n        // Uncomment to create a string of this image\n        String image0 = \"../TeachingKidsProgramming.Source.Java/src/main/resources/icons/information.png\";\n        //  Create a new ImageIcon from your image\n        ImageIcon icon0 = new ImageIcon(image0);\n        // Show a message with the fancy message box this text, this title and this icon...\n        FancyMessageBox.showMesage(\"No Fish\", \"Still hungry\", icon0);\n        // End\n        break;\n      // When the numberOfFish is 1    \n      case 1 :\n        // Uncomment to create a string of this image\n        String image1 = \"../TeachingKidsProgramming.Source.Java/src/main/resources/icons/star.png\";\n        // Create a new ImageIcon from your image\n        ImageIcon icon1 = new ImageIcon(image1);\n        // Show a message with the fancy message box this text, this title and this icon...\n        FancyMessageBox.showMesage(\"One Fish\", \"This one has a little star\", icon1);\n        // End\n        break;\n      // When the numberOfFish is 0    \n      case 2 :\n        // Uncomment to create a string of this image\n        String image2 = \"../TeachingKidsProgramming.Source.Java/src/main/resources/icons/github.png\";\n        //  Create a new ImageIcon from your image\n        ImageIcon icon2 = new ImageIcon(image2);\n        // Show a message with the fancy message box this text, this title and this icon...\n        FancyMessageBox.showMesage(\"Two Fish\", \"Funny things are everywhere\", icon2);\n        // End\n        break;\n      // Otherwise  \n      default :\n        // Uncomment to create a string of this image\n        String image4 = \"../TeachingKidsProgramming.Source.Java/src/main/resources/icons/hint.png\";\n        // Create a new ImageIcon from your image\n        ImageIcon icon4 = new ImageIcon(image4);\n        // Show a message with the fancy message box this text, this title and this icon...\n        FancyMessageBox.showMesage(\"Vegetaraian meal\", \"Fish are icky\", icon4);\n        // End\n        break;\n    }\n  }",
        "variable": "icon",
        "reference": "a new ImageIcon from your image",
        "explanation_by_ours": "The icon to use for the message box.",
        "explanation_by_baseline": "a new ImageIcon from your"
    },
    {
        "id": 2557,
        "method": "@Override\n    public Optional<BasicToken> authenticate(String tokenString) throws AuthenticationException {\n        tokenString = tokenString.replaceAll(\"\\\"\", \"\");\n        LOGGER.debug(\"Authenticating from database:  \" + tokenString);\n        try {\n                        BasicToken token = new BasicToken(tokenString);\n\n            Optional<UserEntry> user = (Optional<UserEntry>) userStore.findByUsername(token.getUsername());\n            if (!user.isPresent()) {\n                LOGGER.warn(\"User is not available: \" + tokenString);\n                return Optional.empty();\n            }\n            // If user exists and active than check Service Permissions for authorization controls\n            if (user.get().isActive()) {\n\n                if (token.getPermissions() == null) {\n                    LOGGER.debug(\"Loading Permissions from DB: \" + tokenString);\n                    Set<String> permissions = new HashSet<String>();\n                    Set<PermissionEntry> rolePermissions = new HashSet<PermissionEntry>();\n\n                    //If user role is a group than add sub role permissions to group\n\n                    Optional<RoleEntry> role = (Optional<RoleEntry>) roleStore.findByRoleId(user.get().getRoleId());\n\n                    getAllRolePermissions(role.get(), rolePermissions);\n\n                    for (PermissionEntry permission : rolePermissions) {\n                        if (permission.getType().equals(PermissionEntry.Type.SERVICE)) {\n                            Optional<? extends ServiceEntry> service = serviceStore.findByCode(permission.getRestrictedItemId());\n                            if (service.isPresent()) {\n                                permissions.add(service.get().getPath() + \":\" + service.get().getMethod());\n                            }\n                        }\n                    }\n                    // Create credentials with user info and permission list\n                    token.setPermissions(Collections.unmodifiableSet(permissions));\n                } else {\n                    LOGGER.debug(\"Loading Permissions from Cache: \" + tokenString);\n                }\n\n                return Optional.ofNullable(token);\n            }\n        } catch (Exception e) {\n            LOGGER.error(tokenString, e);\n        }\n        return Optional.empty();\n\n    }",
        "variable": "token",
        "reference": "tokenString",
        "explanation_by_ours": "the token to authenticate.",
        "explanation_by_baseline": "tokenif (!"
    },
    {
        "id": 2603,
        "method": "private boolean parseAttribute(AttributesImpl attrs)\n\t        throws JasperException {\n\n\t\tString qName = parseName();\n\tif (qName == null)\n\t    return false;\n\n\t// Determine prefix and local name components\n\tString localName = qName;\n\tString uri = \"\";\n\tint index = qName.indexOf(':');\n\tif (index != -1) {\n\t    String prefix = qName.substring(0, index);\n\t    uri = pageInfo.getURI(prefix);\n\t    if (uri == null) {\n\t\terr.jspError(reader.mark(),\n\t\t\t     \"jsp.error.attribute.invalidPrefix\", prefix);\n\t    }\n\t    localName = qName.substring(index+1);\n\t}\n\n \treader.skipSpaces();\n\tif (!reader.matches(\"=\"))\n\t    err.jspError(reader.mark(), \"jsp.error.attribute.noequal\");\n\n \treader.skipSpaces();\n\tchar quote = (char) reader.nextChar();\n\tif (quote != '\\'' && quote != '\"')\n\t    err.jspError(reader.mark(), \"jsp.error.attribute.noquote\");\n\n \tString watchString = \"\";\n\tif (reader.matches(\"<%=\"))\n\t    watchString = \"%>\";\n\twatchString = watchString + quote;\n\t\n\tString attrValue = parseAttributeValue(watchString);\n\tattrs.addAttribute(uri, localName, qName, \"CDATA\", attrValue);\n\treturn true;\n    }",
        "variable": "qName",
        "reference": "the qualified name",
        "explanation_by_ours": "the qualified name of the attribute",
        "explanation_by_baseline": "qName componentsif ("
    },
    {
        "id": 2604,
        "method": "private boolean parseAttribute(AttributesImpl attrs)\n\t        throws JasperException {\n\n\t// Get the qualified name\n\tString qName = parseName();\n\tif (qName == null)\n\t    return false;\n\n\t\tString localName = qName;\n\tString uri = \"\";\n\tint index = qName.indexOf(':');\n\tif (index != -1) {\n\t    String prefix = qName.substring(0, index);\n\t    uri = pageInfo.getURI(prefix);\n\t    if (uri == null) {\n\t\terr.jspError(reader.mark(),\n\t\t\t     \"jsp.error.attribute.invalidPrefix\", prefix);\n\t    }\n\t    localName = qName.substring(index+1);\n\t}\n\n \treader.skipSpaces();\n\tif (!reader.matches(\"=\"))\n\t    err.jspError(reader.mark(), \"jsp.error.attribute.noequal\");\n\n \treader.skipSpaces();\n\tchar quote = (char) reader.nextChar();\n\tif (quote != '\\'' && quote != '\"')\n\t    err.jspError(reader.mark(), \"jsp.error.attribute.noquote\");\n\n \tString watchString = \"\";\n\tif (reader.matches(\"<%=\"))\n\t    watchString = \"%>\";\n\twatchString = watchString + quote;\n\t\n\tString attrValue = parseAttributeValue(watchString);\n\tattrs.addAttribute(uri, localName, qName, \"CDATA\", attrValue);\n\treturn true;\n    }",
        "variable": "localName",
        "reference": "local name components",
        "explanation_by_ours": "the local name of the attribute",
        "explanation_by_baseline": "local nameif (q"
    },
    {
        "id": 2608,
        "method": "private void parseTemplateText(Node parent) throws JasperException {\n\n\tif (!reader.hasMoreInput())\n\t    return;\n\n\tCharArrayWriter ttext = new CharArrayWriter();\n\t\tint ch = reader.nextChar();\n        if (ch == '\\\\') {\n            reader.pushChar();\n        } else {\n            ttext.write(ch);\n        }\n\n\twhile (reader.hasMoreInput()) {\n\t    ch = reader.nextChar();\n\t    if (ch == '<') {\n                reader.pushChar();\n                break;\n            }\n\t    else if( ch == '$' || ch == '#') {\n\t\tif (!reader.hasMoreInput()) {\n\t\t    ttext.write(ch);\n\t\t    break;\n                }\n\t\tif (reader.nextChar() == '{') {\n\t\t    reader.pushChar();\n\t\t    reader.pushChar();\n\t\t    break;\n\t\t}\n\t\tttext.write(ch);\n\t\treader.pushChar();\n\t\tcontinue;\n\t    }\n\t    else if (ch == '\\\\') {\n\t\tif (!reader.hasMoreInput()) {\n\t\t    ttext.write('\\\\');\n\t\t    break;\n\t\t}\n                char next = (char)reader.peekChar();\n                // Looking for \\% or \\$\n                // Note that this behavior can be altered by the attributes\n                // el-ignored and deferred-syntax-allowed-as-literal and\n                // similar attributes in a page directive.  However, since\n                // the page direcitve may appear later in the same page, the\n                // '\\' will be regenerated in Generator.java.\n                if (next == '%' || next == '$' || next == '#') {\n                    ch = reader.nextChar();\n                }\n\t    }\n\t    ttext.write(ch);\n\t}\n\tnew Node.TemplateText(ttext.toString(), start, parent);\n    }",
        "variable": "ch",
        "reference": "the first character",
        "explanation_by_ours": "the current character of the template text node",
        "explanation_by_baseline": "of the template text."
    },
    {
        "id": 2620,
        "method": "private void dispatch(Mark where, String errCode, Object[] args,\n\t\t\t  Exception e) throws JasperException {\n\tString file = null;\n\tString errMsg = null;\n\tint line = -1;\n\tint column = -1;\n\tboolean hasLocation = false;\n\n\t// Localize\n\tif (errCode != null) {\n\t    errMsg = Localizer.getMessage(errCode, args);\n\t} else if (e != null) {\n\t    // give a hint about what's wrong\n\t    errMsg = e.getMessage();\n\t}\n\n\t// Get error location\n\tif (where != null) {\n            if (jspcMode) {\n                // Get the full URL of the resource that caused the error\n                try {\n                    file = where.getURL().toString();\n                } catch (MalformedURLException me) {\n                    // Fallback to using context-relative path\n                    file = where.getFile();\n                }\n            } else {\n                // Get the context-relative resource path, so as to not\n                // disclose any local filesystem details\n                file = where.getFile();\n            }\n\t    line = where.getLineNumber();\n\t    column = where.getColumnNumber();\n\t    hasLocation = true;\n\t}\n\n\t\tException nestedEx = e;\n\tif ((e instanceof SAXException)\n\t        && (((SAXException) e).getException() != null)) {\n\t    nestedEx = ((SAXException) e).getException();\n\t}\n\n\tif (hasLocation) {\n\t    errHandler.jspError(file, line, column, errMsg, nestedEx);\n\t} else {\n\t    errHandler.jspError(errMsg, nestedEx);\n\t}\n    }",
        "variable": "nestedEx",
        "reference": "the nested exception",
        "explanation_by_ours": "the nested exception",
        "explanation_by_baseline": "if (jspcMode)"
    },
    {
        "id": 2623,
        "method": "protected TreeNode convert(TreeNode parent, Node node) {\n\n        // Construct a new TreeNode for this node\n        TreeNode treeNode = new TreeNode(node.getNodeName(), parent);\n\n        // Convert all attributes of this node\n        NamedNodeMap attributes = node.getAttributes();\n        if (attributes != null) {\n            int n = attributes.getLength();\n            for (int i = 0; i < n; i++) {\n                Node attribute = attributes.item(i);\n                treeNode.addAttribute(attribute.getNodeName(),\n                                      attribute.getNodeValue());\n            }\n        }\n\n                NodeList children = node.getChildNodes();\n        if (children != null) {\n            int n = children.getLength();\n            for (int i = 0; i < n; i++) {\n                Node child = children.item(i);\n                if (child instanceof Comment)\n                    continue;\n                if (child instanceof Text) {\n                    String body = ((Text) child).getData();\n                    if (body != null) {\n                        body = body.trim();\n                        if (body.length() > 0)\n                            treeNode.setBody(body);\n                    }\n                } else {\n                    TreeNode treeChild = convert(treeNode, child);\n                }\n            }\n        }\n        \n        // Return the completed TreeNode graph\n        return (treeNode);\n    }",
        "variable": "children",
        "reference": "all children of this node",
        "explanation_by_ours": "The children of the node",
        "explanation_by_baseline": "all children of this node"
    },
    {
        "id": 2631,
        "method": "public Mark popStream() {\n\t// make sure we have something to pop\n\tif ( includeStack.size() <= 0 ) {\n\t    return null;\n\t}\n\n\t\tIncludeState state = includeStack.pop( );\n\n\t// set new variables\n\tcursor = state.cursor;\n\tline = state.line;\n\tcol = state.col;\n\tfileid = state.fileid;\n\tfileName = state.fileName;\n\tbaseDir = state.baseDir;\n\tstream = state.stream;\n\treturn this;\n    }",
        "variable": "state",
        "reference": "previous state in stack",
        "explanation_by_ours": "the current include state",
        "explanation_by_baseline": "statereturn null;}"
    },
    {
        "id": 2671,
        "method": "@Override\n    public DAbstractMetricIO getIO( String rollupType, Granularity granularity ) {\n\n                RollupType rType = RollupType.fromString( rollupType );\n\n        // get the right PreaggregatedIO class that can process\n        // this rollupType\n        DAbstractMetricIO io = rollupTypeToIO.get( rType );\n\n        if (io == null) {\n            throw new InvalidDataException( String.format(\"getIO: unsupported rollupType=%s\", rollupType));\n        }\n\n        return io;\n    }",
        "variable": "rType",
        "reference": "the rollupType for this locator",
        "explanation_by_ours": "a {@link org.apache.gobblin.metrics.",
        "explanation_by_baseline": "the rollupType//"
    },
    {
        "id": 2673,
        "method": "@SuppressWarnings(\"Duplicates\")\n    public static void main(String[] args) {\n        // init logging\n        PropertyConfigurator.configure(\n                TrovitWritingExample.class.getResource(PACKAGE + \"/log4j.properties\"));\n\n        // create a Trovit object with some example data\n        // this object corresponds to the <trovit> element in XML\n        Trovit trovit = FACTORY.createTrovit();\n\n        // append some example ads to the transfer\n        trovit.getAd().add(createAd());\n        trovit.getAd().add(createAd());\n        trovit.getAd().add(createAd());\n\n                TrovitDocument doc = null;\n        try {\n            doc = TrovitDocument.newDocument(trovit);\n        } catch (Exception ex) {\n            LOGGER.error(\"Can't create XML document!\");\n            LOGGER.error(\"> \" + ex.getLocalizedMessage(), ex);\n            System.exit(1);\n        }\n\n        // write XML document into a java.io.File\n        try {\n            write(doc, File.createTempFile(\"output-\", \".xml\"));\n        } catch (IOException ex) {\n            LOGGER.error(\"Can't create temporary file!\");\n            LOGGER.error(\"> \" + ex.getLocalizedMessage(), ex);\n            System.exit(1);\n        }\n\n        // write XML document into a java.io.OutputStream\n        write(doc, new NullOutputStream());\n\n        // write XML document into a java.io.Writer\n        write(doc, new NullWriter());\n\n        // write XML document into a string and send it to the console\n        writeToConsole(doc);\n    }",
        "variable": "doc",
        "reference": "a XML document",
        "explanation_by_ours": "the XML document",
        "explanation_by_baseline": "a TrovitDocument"
    },
    {
        "id": 2677,
        "method": "@SuppressWarnings(\"CatchMayIgnoreException\")\n    protected static Image createPropertyImage(String id, int pos) {\n                Image img = FACTORY.createImagesTypeImage();\n        img.setId(pos);\n        try {\n            img.setUrl(new URI(\"http://website.com/property/\" + id + \"/image_\" + pos + \".jpg\"));\n        } catch (URISyntaxException ex) {\n        }\n\n        return img;\n    }",
        "variable": "img",
        "reference": "an example image",
        "explanation_by_ours": "the image",
        "explanation_by_baseline": "images type image"
    },
    {
        "id": 2678,
        "method": "@SuppressWarnings(\"Duplicates\")\n    public static void main(String[] args) {\n        // init logging\n        PropertyConfigurator.configure(\n                Is24CsvWritingExample.class.getResource(PACKAGE + \"/log4j.properties\"));\n\n                List<Is24CsvRecord> records = new ArrayList<>();\n        records.add(createHausKaufRecord());\n        records.add(createHausKaufRecord());\n        records.add(createWohnungMieteRecord());\n        records.add(createWohnungMieteRecord());\n\n        // write CSV records into a java.io.File\n        try {\n            write(records, File.createTempFile(\"output-\", \".csv\"));\n        } catch (IOException ex) {\n            LOGGER.error(\"Can't create temporary file!\");\n            LOGGER.error(\"> \" + ex.getLocalizedMessage(), ex);\n            System.exit(1);\n        }\n\n        // write CSV records into a java.io.OutputStream\n        write(records, new NullOutputStream());\n\n        // write CSV records into a java.io.Writer\n        write(records, new NullWriter());\n\n        // write CSV records into a string and send it to the console\n        writeToConsole(records);\n    }",
        "variable": "records",
        "reference": "CSV records",
        "explanation_by_ours": "list of records to be written",
        "explanation_by_baseline": "records into a java.util"
    },
    {
        "id": 2744,
        "method": "private int getTextColor(int item) {\n\n        int scrollX = getScrollX();\n\n                int color = textColor.getDefaultColor();\n        int itemWithPadding = (int) (itemWidth + dividerSize);\n        if (scrollX > itemWithPadding * item - itemWithPadding / 2 &&\n                scrollX < itemWithPadding * (item + 1) - itemWithPadding / 2) {\n            int position = scrollX - itemWithPadding / 2;\n            color = getColor(position, item);\n        } else if(item == pressedItem) {\n            color = textColor.getColorForState(new int[] { android.R.attr.state_pressed }, color);\n        }\n\n        return color;\n\n    }",
        "variable": "color",
        "reference": "the color of text",
        "explanation_by_ours": "The color of the item.",
        "explanation_by_baseline": "if (scrollX > item"
    },
    {
        "id": 2762,
        "method": "private void makeDropTarget( final java.io.PrintStream out, final java.awt.Component c, boolean recursive )\r\n    {\r\n                final java.awt.dnd.DropTarget dt = new java.awt.dnd.DropTarget();\r\n        try\r\n        {   dt.addDropTargetListener( dropListener );\r\n        }   // end try\r\n        catch( java.util.TooManyListenersException e )\r\n        {   e.printStackTrace();\r\n            log(out, \"FileDrop: Drop will not work due to previous error. Do you have another listener attached?\" );\r\n        }   // end catch\r\n        \r\n        // Listen for hierarchy changes and remove the drop target when the parent gets cleared out.\r\n        c.addHierarchyListener( new java.awt.event.HierarchyListener()\r\n        {   public void hierarchyChanged( java.awt.event.HierarchyEvent evt )\r\n            {   log( out, \"FileDrop: Hierarchy changed.\" );\r\n                java.awt.Component parent = c.getParent();\r\n                if( parent == null )\r\n                {   c.setDropTarget( null );\r\n                    log( out, \"FileDrop: Drop target cleared from component.\" );\r\n                }   // end if: null parent\r\n                else\r\n                {   new java.awt.dnd.DropTarget(c, dropListener);\r\n                    log( out, \"FileDrop: Drop target added to component.\" );\r\n                }   // end else: parent not null\r\n            }   // end hierarchyChanged\r\n        }); // end hierarchy listener\r\n        if( c.getParent() != null )\r\n            new java.awt.dnd.DropTarget(c, dropListener);\r\n        \r\n        if( recursive && (c instanceof java.awt.Container ) )\r\n        {   \r\n            // Get the container\r\n            java.awt.Container cont = (java.awt.Container) c;\r\n            \r\n            // Get it's components\r\n            java.awt.Component[] comps = cont.getComponents();\r\n            \r\n            // Set it's components as listeners also\r\n            for( int i = 0; i < comps.length; i++ )\r\n                makeDropTarget( out, comps[i], recursive );\r\n        }   // end if: recursively set components as listener\r\n    }",
        "variable": "dt",
        "reference": "the drop target",
        "explanation_by_ours": "the drop target",
        "explanation_by_baseline": "( int i = 0;"
    },
    {
        "id": 2763,
        "method": "private void makeDropTarget( final java.io.PrintStream out, final java.awt.Component c, boolean recursive )\r\n    {\r\n        // Make drop target\r\n        final java.awt.dnd.DropTarget dt = new java.awt.dnd.DropTarget();\r\n        try\r\n        {   dt.addDropTargetListener( dropListener );\r\n        }   // end try\r\n        catch( java.util.TooManyListenersException e )\r\n        {   e.printStackTrace();\r\n            log(out, \"FileDrop: Drop will not work due to previous error. Do you have another listener attached?\" );\r\n        }   // end catch\r\n        \r\n        // Listen for hierarchy changes and remove the drop target when the parent gets cleared out.\r\n        c.addHierarchyListener( new java.awt.event.HierarchyListener()\r\n        {   public void hierarchyChanged( java.awt.event.HierarchyEvent evt )\r\n            {   log( out, \"FileDrop: Hierarchy changed.\" );\r\n                java.awt.Component parent = c.getParent();\r\n                if( parent == null )\r\n                {   c.setDropTarget( null );\r\n                    log( out, \"FileDrop: Drop target cleared from component.\" );\r\n                }   // end if: null parent\r\n                else\r\n                {   new java.awt.dnd.DropTarget(c, dropListener);\r\n                    log( out, \"FileDrop: Drop target added to component.\" );\r\n                }   // end else: parent not null\r\n            }   // end hierarchyChanged\r\n        }); // end hierarchy listener\r\n        if( c.getParent() != null )\r\n            new java.awt.dnd.DropTarget(c, dropListener);\r\n        \r\n        if( recursive && (c instanceof java.awt.Container ) )\r\n        {   \r\n                        java.awt.Container cont = (java.awt.Container) c;\r\n            \r\n            // Get it's components\r\n            java.awt.Component[] comps = cont.getComponents();\r\n            \r\n            // Set it's components as listeners also\r\n            for( int i = 0; i < comps.length; i++ )\r\n                makeDropTarget( out, comps[i], recursive );\r\n        }   // end if: recursively set components as listener\r\n    }",
        "variable": "cont",
        "reference": "the container",
        "explanation_by_ours": "the container",
        "explanation_by_baseline": "it's container( int"
    },
    {
        "id": 2765,
        "method": "private boolean isDragOk( final java.io.PrintStream out, final java.awt.dnd.DropTargetDragEvent evt )\r\n    {   boolean ok = false;\r\n        \r\n                java.awt.datatransfer.DataFlavor[] flavors = evt.getCurrentDataFlavors();\r\n        \r\n        // See if any of the flavors are a file list\r\n        int i = 0;\r\n        while( !ok && i < flavors.length )\r\n        {   \r\n            // BEGIN 2007-09-12 Nathan Blomquist -- Linux (KDE/Gnome) support added.\r\n            // Is the flavor a file list?\r\n            final DataFlavor curFlavor = flavors[i];\r\n            if( curFlavor.equals( java.awt.datatransfer.DataFlavor.javaFileListFlavor ) ||\r\n                curFlavor.isRepresentationClassReader()){\r\n                ok = true;\r\n            }\r\n            // END 2007-09-12 Nathan Blomquist -- Linux (KDE/Gnome) support added.\r\n            i++;\r\n        }   // end while: through flavors\r\n        \r\n        // If logging is enabled, show data flavors\r\n        if( out != null )\r\n        {   if( flavors.length == 0 )\r\n                log( out, \"FileDrop: no data flavors.\" );\r\n            for( i = 0; i < flavors.length; i++ )\r\n                log( out, flavors[i].toString() );\r\n        }   // end if: logging enabled\r\n        \r\n        return ok;\r\n    }   // end isDragOk\r\n    \r\n    \r\n    /** Outputs <tt>message</tt> to <tt>out</tt> if it's not null. */\r\n    private static void log( java.io.PrintStream out, String message )\r\n    {   // Log message if requested\r\n        if( out != null )\r\n            out.println( message );\r\n    }   // end log\r\n\r\n    \r\n    \r\n    \r\n    /**\r\n     * Removes the drag-and-drop hooks from the component and optionally\r\n     * from the all children. You should call this if you add and remove\r\n     * components after you've set up the drag-and-drop.\r\n     * This will recursively unregister all components contained within\r\n     * <var>c</var> if <var>c</var> is a {@link java.awt.Container}.\r\n     *\r\n     * @param c The component to unregister as a drop target\r\n     * @since 1.0\r\n     */\r\n    public static boolean remove( java.awt.Component c)\r\n    {   return remove( null, c, true );\r\n    }   // end remove\r\n    \r\n    \r\n    \r\n    /**\r\n     * Removes the drag-and-drop hooks from the component and optionally\r\n     * from the all children. You should call this if you add and remove\r\n     * components after you've set up the drag-and-drop.\r\n     *\r\n     * @param out Optional {@link java.io.PrintStream} for logging drag and drop messages\r\n     * @param c The component to unregister\r\n     * @param recursive Recursively unregister components within a container\r\n     * @since 1.0\r\n     */\r\n    public static boolean remove( java.io.PrintStream out, java.awt.Component c, boolean recursive )\r\n    {   // Make sure we support dnd.\r\n        if( supportsDnD() )\r\n        {   log( out, \"FileDrop: Removing drag-and-drop hooks.\" );\r\n            c.setDropTarget( null );\r\n            if( recursive && ( c instanceof java.awt.Container ) )\r\n            {   java.awt.Component[] comps = ((java.awt.Container)c).getComponents();\r\n                for( int i = 0; i < comps.length; i++ )\r\n                    remove( out, comps[i], recursive );\r\n                return true;\r\n            }   // end if: recursive\r\n            else return false;\r\n        }   // end if: supports DnD\r\n        else return false;\r\n    }   // end remove\r\n    \r\n    \r\n\r\n    \r\n/* ********  I N N E R   I N T E R F A C E   L I S T E N E R  ******** */    \r\n    \r\n    \r\n    /**\r\n     * Implement this inner interface to listen for when files are dropped. For example\r\n     * your class declaration may begin like this:\r\n     * <code><pre>\r\n     *      public class MyClass implements FileDrop.Listener\r\n     *      ...\r\n     *      public void filesDropped( java.io.File[] files )\r\n     *      {\r\n     *          ...\r\n     *      }   // end filesDropped\r\n     *      ...\r\n     * </pre></code>\r\n     *\r\n     * @since 1.1\r\n     */\r\n    public static interface Listener {\r\n       \r\n        /**\r\n         * This method is called when files have been successfully dropped.\r\n         *\r\n         * @param files An array of <tt>File</tt>s that were dropped.\r\n         * @since 1.0\r\n         */\r\n        public abstract void filesDropped( java.io.File[] files );\r\n        \r\n        \r\n    }   // end inner-interface Listener\r\n    \r\n    \r\n/* ********  I N N E R   C L A S S  ******** */    \r\n    \r\n    \r\n    /**\r\n     * This is the event that is passed to the\r\n     * {@link FileDropListener#filesDropped filesDropped(...)} method in\r\n     * your {@link FileDropListener} when files are dropped onto\r\n     * a registered drop target.\r\n     *\r\n     * <p>I'm releasing this code into the Public Domain. Enjoy.</p>\r\n     * \r\n     * @author  Robert Harder\r\n     * @author  rob@iharder.net\r\n     * @version 1.2\r\n     */\r\n    public static class Event extends java.util.EventObject {\r\n\r\n        private java.io.File[] files;\r\n\r\n        /**\r\n         * Constructs an {@link Event} with the array\r\n         * of files that were dropped and the\r\n         * {@link FileDrop} that initiated the event.\r\n         *\r\n         * @param files The array of files that were dropped\r\n         * @source The event source\r\n         * @since 1.1\r\n         */\r\n        public Event( java.io.File[] files, Object source ) {\r\n            super( source );\r\n            this.files = files;\r\n        }   // end constructor\r\n\r\n        /**\r\n         * Returns an array of files that were dropped on a\r\n         * registered drop target.\r\n         *\r\n         * @return array of files that were dropped\r\n         * @since 1.1\r\n         */\r\n        public java.io.File[] getFiles() {\r\n            return files;\r\n        }   // end getFiles\r\n    \r\n    }   // end inner class Event\r\n    \r\n    \r\n    \r\n/* ********  I N N E R   C L A S S  ******** */\r\n    \r\n\r\n    /**\r\n     * At last an easy way to encapsulate your custom objects for dragging and dropping\r\n     * in your Java programs!\r\n     * When you need to create a {@link java.awt.datatransfer.Transferable} object,\r\n     * use this class to wrap your object.\r\n     * For example:\r\n     * <pre><code>\r\n     *      ...\r\n     *      MyCoolClass myObj = new MyCoolClass();\r\n     *      Transferable xfer = new TransferableObject( myObj );\r\n     *      ...\r\n     * </code></pre>\r\n     * Or if you need to know when the data was actually dropped, like when you're\r\n     * moving data out of a list, say, you can use the {@link TransferableObject.Fetcher}\r\n     * inner class to return your object Just in Time.\r\n     * For example:\r\n     * <pre><code>\r\n     *      ...\r\n     *      final MyCoolClass myObj = new MyCoolClass();\r\n     *\r\n     *      TransferableObject.Fetcher fetcher = new TransferableObject.Fetcher()\r\n     *      {   public Object getObject(){ return myObj; }\r\n     *      }; // end fetcher\r\n     *\r\n     *      Transferable xfer = new TransferableObject( fetcher );\r\n     *      ...\r\n     * </code></pre>\r\n     *\r\n     * The {@link java.awt.datatransfer.DataFlavor} associated with \r\n     * {@link TransferableObject} has the representation class\r\n     * <tt>net.iharder.dnd.TransferableObject.class</tt> and MIME type\r\n     * <tt>application/x-net.iharder.dnd.TransferableObject</tt>.\r\n     * This data flavor is accessible via the static\r\n     * {@link #DATA_FLAVOR} property.\r\n     *\r\n     *\r\n     * <p>I'm releasing this code into the Public Domain. Enjoy.</p>\r\n     * \r\n     * @author  Robert Harder\r\n     * @author  rob@iharder.net\r\n     * @version 1.2\r\n     */\r\n    public static class TransferableObject implements java.awt.datatransfer.Transferable\r\n    {\r\n        /**\r\n         * The MIME type for {@link #DATA_FLAVOR} is \r\n         * <tt>application/x-net.iharder.dnd.TransferableObject</tt>.\r\n         *\r\n         * @since 1.1\r\n         */\r\n        public final static String MIME_TYPE = \"application/x-net.iharder.dnd.TransferableObject\";\r\n\r\n\r\n        /**\r\n         * The default {@link java.awt.datatransfer.DataFlavor} for\r\n         * {@link TransferableObject} has the representation class\r\n         * <tt>net.iharder.dnd.TransferableObject.class</tt>\r\n         * and the MIME type \r\n         * <tt>application/x-net.iharder.dnd.TransferableObject</tt>.\r\n         *\r\n         * @since 1.1\r\n         */\r\n        public final static java.awt.datatransfer.DataFlavor DATA_FLAVOR = \r\n            new java.awt.datatransfer.DataFlavor( FileDrop.TransferableObject.class, MIME_TYPE );\r\n\r\n\r\n        private Fetcher fetcher;\r\n        private Object data;\r\n\r\n        private java.awt.datatransfer.DataFlavor customFlavor; \r\n\r\n\r\n\r\n        /**\r\n         * Creates a new {@link TransferableObject} that wraps <var>data</var>.\r\n         * Along with the {@link #DATA_FLAVOR} associated with this class,\r\n         * this creates a custom data flavor with a representation class \r\n         * determined from <code>data.getClass()</code> and the MIME type\r\n         * <tt>application/x-net.iharder.dnd.TransferableObject</tt>.\r\n         *\r\n         * @param data The data to transfer\r\n         * @since 1.1\r\n         */\r\n        public TransferableObject( Object data )\r\n        {   this.data = data;\r\n            this.customFlavor = new java.awt.datatransfer.DataFlavor( data.getClass(), MIME_TYPE );\r\n        }   // end constructor\r\n\r\n\r\n\r\n        /**\r\n         * Creates a new {@link TransferableObject} that will return the\r\n         * object that is returned by <var>fetcher</var>.\r\n         * No custom data flavor is set other than the default\r\n         * {@link #DATA_FLAVOR}.\r\n         *\r\n         * @see Fetcher\r\n         * @param fetcher The {@link Fetcher} that will return the data object\r\n         * @since 1.1\r\n         */\r\n        public TransferableObject( Fetcher fetcher )\r\n        {   this.fetcher = fetcher;\r\n        }   // end constructor\r\n\r\n\r\n\r\n        /**\r\n         * Creates a new {@link TransferableObject} that will return the\r\n         * object that is returned by <var>fetcher</var>.\r\n         * Along with the {@link #DATA_FLAVOR} associated with this class,\r\n         * this creates a custom data flavor with a representation class <var>dataClass</var>\r\n         * and the MIME type\r\n         * <tt>application/x-net.iharder.dnd.TransferableObject</tt>.\r\n         *\r\n         * @see Fetcher\r\n         * @param dataClass The {@link java.lang.Class} to use in the custom data flavor\r\n         * @param fetcher The {@link Fetcher} that will return the data object\r\n         * @since 1.1\r\n         */\r\n        public TransferableObject( Class dataClass, Fetcher fetcher )\r\n        {   this.fetcher = fetcher;\r\n            this.customFlavor = new java.awt.datatransfer.DataFlavor( dataClass, MIME_TYPE );\r\n        }   // end constructor\r\n\r\n        /**\r\n         * Returns the custom {@link java.awt.datatransfer.DataFlavor} associated\r\n         * with the encapsulated object or <tt>null</tt> if the {@link Fetcher}\r\n         * constructor was used without passing a {@link java.lang.Class}.\r\n         *\r\n         * @return The custom data flavor for the encapsulated object\r\n         * @since 1.1\r\n         */\r\n        public java.awt.datatransfer.DataFlavor getCustomDataFlavor()\r\n        {   return customFlavor;\r\n        }   // end getCustomDataFlavor\r\n\r\n\r\n    /* ********  T R A N S F E R A B L E   M E T H O D S  ******** */    \r\n\r\n\r\n        /**\r\n         * Returns a two- or three-element array containing first\r\n         * the custom data flavor, if one was created in the constructors,\r\n         * second the default {@link #DATA_FLAVOR} associated with\r\n         * {@link TransferableObject}, and third the\r\n         * {@link java.awt.datatransfer.DataFlavor.stringFlavor}.\r\n         *\r\n         * @return An array of supported data flavors\r\n         * @since 1.1\r\n         */\r\n        public java.awt.datatransfer.DataFlavor[] getTransferDataFlavors() \r\n        {   \r\n            if( customFlavor != null )\r\n                return new java.awt.datatransfer.DataFlavor[]\r\n                {   customFlavor,\r\n                    DATA_FLAVOR,\r\n                    java.awt.datatransfer.DataFlavor.stringFlavor\r\n                };  // end flavors array\r\n            else\r\n                return new java.awt.datatransfer.DataFlavor[]\r\n                {   DATA_FLAVOR,\r\n                    java.awt.datatransfer.DataFlavor.stringFlavor\r\n                };  // end flavors array\r\n        }   // end getTransferDataFlavors\r\n\r\n\r\n\r\n        /**\r\n         * Returns the data encapsulated in this {@link TransferableObject}.\r\n         * If the {@link Fetcher} constructor was used, then this is when\r\n         * the {@link Fetcher#getObject getObject()} method will be called.\r\n         * If the requested data flavor is not supported, then the\r\n         * {@link Fetcher#getObject getObject()} method will not be called.\r\n         *\r\n         * @param flavor The data flavor for the data to return\r\n         * @return The dropped data\r\n         * @since 1.1\r\n         */\r\n        public Object getTransferData( java.awt.datatransfer.DataFlavor flavor )\r\n        throws java.awt.datatransfer.UnsupportedFlavorException, java.io.IOException \r\n        {   \r\n            // Native object\r\n            if( flavor.equals( DATA_FLAVOR ) )\r\n                return fetcher == null ? data : fetcher.getObject();\r\n\r\n            // String\r\n            if( flavor.equals( java.awt.datatransfer.DataFlavor.stringFlavor ) )\r\n                return fetcher == null ? data.toString() : fetcher.getObject().toString();\r\n\r\n            // We can't do anything else\r\n            throw new java.awt.datatransfer.UnsupportedFlavorException(flavor);\r\n        }   // end getTransferData\r\n\r\n\r\n\r\n\r\n        /**\r\n         * Returns <tt>true</tt> if <var>flavor</var> is one of the supported\r\n         * flavors. Flavors are supported using the <code>equals(...)</code> method.\r\n         *\r\n         * @param flavor The data flavor to check\r\n         * @return Whether or not the flavor is supported\r\n         * @since 1.1\r\n         */\r\n        public boolean isDataFlavorSupported( java.awt.datatransfer.DataFlavor flavor ) \r\n        {\r\n            // Native object\r\n            if( flavor.equals( DATA_FLAVOR ) )\r\n                return true;\r\n\r\n            // String\r\n            if( flavor.equals( java.awt.datatransfer.DataFlavor.stringFlavor ) )\r\n                return true;\r\n\r\n            // We can't do anything else\r\n            return false;\r\n        }   // end isDataFlavorSupported\r\n\r\n\r\n    /* ********  I N N E R   I N T E R F A C E   F E T C H E R  ******** */    \r\n\r\n        /**\r\n         * Instead of passing your data directly to the {@link TransferableObject}\r\n         * constructor, you may want to know exactly when your data was received\r\n         * in case you need to remove it from its source (or do anyting else to it).\r\n         * When the {@link #getTransferData getTransferData(...)} method is called\r\n         * on the {@link TransferableObject}, the {@link Fetcher}'s\r\n         * {@link #getObject getObject()} method will be called.\r\n         *\r\n         * @author Robert Harder\r\n         * @copyright 2001\r\n         * @version 1.1\r\n         * @since 1.1\r\n         */\r\n        public static interface Fetcher\r\n        {\r\n            /**\r\n             * Return the object being encapsulated in the\r\n             * {@link TransferableObject}.\r\n             *\r\n             * @return The dropped object\r\n             * @since 1.1\r\n             */\r\n            public abstract Object getObject();\r\n        }   // end inner interface Fetcher\r\n\r\n\r\n\r\n    }   // end class TransferableObject\r\n\r\n    \r\n    \r\n    \r\n    \r\n}",
        "variable": "flavors",
        "reference": "data flavors being dragged",
        "explanation_by_ours": "The data flavors being dragged.",
        "explanation_by_baseline": "the list of data flavors"
    },
    {
        "id": 2785,
        "method": "@SuppressWarnings(\"rawtypes\")\r\n\tprivate static CTShape getCtShapeFromVml(final Cell sourceCell, XSSFVMLDrawing sourceVml)\r\n\t\t\tthrows ReflectiveOperationException {\r\n\t\tMethod findshape;\r\n\t\t\t\tClass[] paramInt = new Class[2];\r\n\t\tparamInt[0] = Integer.TYPE;\r\n\t\tparamInt[1] = Integer.TYPE;\r\n\t\tfindshape = sourceVml.getClass().getDeclaredMethod(\"findCommentShape\", paramInt);\r\n\t\tfindshape.setAccessible(true);\r\n\t\treturn (CTShape) findshape.invoke(sourceVml, sourceCell.getRowIndex(), sourceCell.getColumnIndex());\r\n\t}",
        "variable": "paramInt",
        "reference": "int parameter",
        "explanation_by_ours": "the param int",
        "explanation_by_baseline": "@SuppressWarnings(\"unchecked\")"
    },
    {
        "id": 2809,
        "method": "public <T> BlockingQueue<T> registerCq(String cqName,String oql) \n\t{\n\t\ttry\n\t\t{\n\t\t\tQueryService queryService = this.clientCache.getQueryService();\n\t\t\t\n\n\t\t\t\t\t\tCqAttributesFactory cqf = new CqAttributesFactory();\n\n\t\t\t// Create a listener and add it to the CQ attributes callback defined below\n\t\t\tCqQueueListener<T> cqListener = new CqQueueListener<T>();\n\t\t\tcqf.addCqListener(cqListener);\n\t\t\tCqAttributes cqa = cqf.create();\n\t\t\t// Name of the CQ and its query\n\t\t\t\n\t\t\t// Create the CqQuery\n\t\t\tCqQuery cqQuery = queryService.newCq(cqName, oql, cqa);\n\t\t\t\n\t\t\tcqListener.setCqQuery(cqQuery);\n\n\t\t\t// Execute CQ, getting the optional initial result set\n\t\t\t// Without the initial result set, the call is priceTracker.execute();\n\t\t\tcqQuery.execute();\n\t\t\t\n\t\t\treturn cqListener;\n\t\t}\n\t\tcatch (CqException| CqClosedException |RegionNotFoundException |QueryInvalidException | CqExistsException  e)\n\t\t{\n\t\t  throw new nyla.solutions.core.exception.SystemException\n\t\t  (\"ERROR:\"+e.getMessage()+\" cqName:\"+cqName+\" oql:\"+oql,e);\n\t\t}\n\t}",
        "variable": "cqf",
        "reference": "the CqAttributeFactory",
        "explanation_by_ours": "The CqAttributesFactory",
        "explanation_by_baseline": "CqQueue<T>"
    },
    {
        "id": 2865,
        "method": "protected byte[] uncompress(\n\t\t\tbyte[] compressedBytesParam\n\t) throws IOException {\n\n\t\tbyte[] buffer = new byte[1024];\n\n\t\tbyte[] returnVal = null;\n\t\tZipInputStream zis = null;\n\t\tif(CHARSET == null) {\n\t\t\tzis = new ZipInputStream(\n\t\t\t\t\tnew ByteArrayInputStream(compressedBytesParam));\n\t\t} else {\n\t\t\tzis = new ZipInputStream(\n\t\t\t\t\tnew ByteArrayInputStream(compressedBytesParam),\n\t\t\t\t\tCHARSET);\n\t\t}\n\n\t\t//get the zip file content\n\t\tByteArrayOutputStream bos = new ByteArrayOutputStream();\n\n\t\t\t\tZipEntry ze = zis.getNextEntry();\n\t\tif(ze == null){\n\t\t\treturn returnVal;\n\t\t}\n\n\t\tint len;\n\t\twhile ((len = zis.read(buffer)) > 0) {\n\t\t\tbos.write(buffer, 0, len);\n\t\t}\n\n\t\tzis.closeEntry();\n\t\tzis.close();\n\n\t\tbos.flush();\n\t\tbos.close();\n\n\t\treturnVal = bos.toByteArray();\n\n\t\treturn returnVal;\n\t}",
        "variable": "ze",
        "reference": "the zipped file list entry",
        "explanation_by_ours": "the zipped file list entry.",
        "explanation_by_baseline": "the zip file content="
    },
    {
        "id": 2924,
        "method": "public URLStreamHandler createURLStreamHandler(final String protocol)\n   {\n      // Check the handler map\n      URLStreamHandler handler = (URLStreamHandler) handlerMap.get(protocol);\n      if( handler != null )\n         return handler;\n\n      // Validate that createURLStreamHandler is not recursing\n      String prevProtocol = (String) createURLStreamHandlerProtocol.get();\n      if( prevProtocol != null && prevProtocol.equals(protocol) )\n         return null;\n      createURLStreamHandlerProtocol.set(protocol);\n\n      // See if the handler pkgs definition has changed\n      checkHandlerPkgs();\n\n      // Search the handlerPkgs for a matching protocol handler\n      ClassLoader ctxLoader = Thread.currentThread().getContextClassLoader();\n      for(int p = 0; p < handlerPkgs.length; p ++)\n      {\n         try\n         {\n                        String classname = handlerPkgs[p] + \".\" + protocol + \".Handler\";\n            Class<?> type = null;\n\n            try\n            {\n               type = ctxLoader.loadClass(classname);\n            }\n            catch(ClassNotFoundException e)\n            {\n               // Try our class loader\n               type = Class.forName(classname);\n            }\n\n            if( type != null )\n            {\n               handler = (URLStreamHandler) type.newInstance();\n               handlerMap.put(protocol, handler);\n               log.trace(\"Found protocol:\"+protocol+\" handler:\"+handler);\n            }\n         }\n         catch (Throwable ignore)\n         {\n         }\n      }\n\n      createURLStreamHandlerProtocol.set(null);\n      return handler;\n   }",
        "variable": "classname",
        "reference": "the standard protocol handler class name",
        "explanation_by_ours": "the URLStreamHandler class name",
        "explanation_by_baseline": "the classname for the handler"
    },
    {
        "id": 2933,
        "method": "public static Constructor getCompatibleConstructor(final Class type,\n                                                      final Class valueType)\n   {\n      // first try and find a constructor with the exact argument type\n      try {\n         return type.getConstructor(new Class[] { valueType });\n      }\n      catch (Exception ignore) {\n         // if the above failed, then try and find a constructor with\n         // an compatible argument type\n\n                  Class[] types = type.getClasses();\n\n         for (int i=0; i<types.length; i++) {\n            try {\n               return type.getConstructor(new Class[] { types[i] });\n            }\n            catch (Exception ignore2) {}\n         }\n      }\n\n      // if we get this far, then we can't find a compatible constructor\n      return null;\n   }",
        "variable": "types",
        "reference": "an array of compatible types",
        "explanation_by_ours": "an array of compatible types",
        "explanation_by_baseline": "the compatible argument types //"
    },
    {
        "id": 2940,
        "method": "public void load(String prefix, Map map) throws PropertyException\n   {\n      // prefix can be null\n      if (map == null)\n         throw new NullArgumentException(\"map\");\n\n      // set properties for each key in map\n      Iterator iter = map.keySet().iterator();\n      while (iter.hasNext())\n      {\n                  String key = String.valueOf(iter.next());\n         String name = makePrefixedPropertyName(key, prefix);\n         String value = String.valueOf(map.get(name));\n\n         // set the property\n         setProperty(name, value);\n      }\n   }",
        "variable": "key",
        "reference": "a string key with optional prefix",
        "explanation_by_ours": "the key of the property",
        "explanation_by_baseline": "prefixed property name("
    },
    {
        "id": 2942,
        "method": "public String[] getArrayProperty(String base, String[] defaultValues)\n   {\n      if (base == null)\n         throw new NullArgumentException(\"base\");\n\n      // create a new list to store indexed values into\n      List list = new LinkedList();\n\n      int i = 0;\n      while (true)\n      {\n                  String name = makeIndexPropertyName(base, i);\n\n         // see if there is a value for this property\n         String value = getProperty(name);\n\n         if (value != null)\n         {\n            list.add(value);\n         }\n         else if (i >= 0)\n         {\n            break; // no more index properties\n         }\n\n         i++;\n      }\n\n      String values[] = defaultValues;\n\n      // if the list is not empty, then return it as an array\n      if (list.size() != 0)\n      {\n         values = (String[]) list.toArray(new String[list.size()]);\n      }\n\n      return values;\n   }",
        "variable": "name",
        "reference": "the index property name",
        "explanation_by_ours": "property name",
        "explanation_by_baseline": "a name for this property"
    },
    {
        "id": 2948,
        "method": "public static void displayClassInfo(Class clazz, StringBuffer results)\n   {\n            ClassLoader cl = clazz.getClassLoader();\n      results.append(\"\\n\");\n      results.append(clazz.getName());\n      results.append(\"(\");\n      results.append(Integer.toHexString(clazz.hashCode()));\n      results.append(\").ClassLoader=\");\n      results.append(cl);\n      ClassLoader parent = cl;\n      while( parent != null )\n      {\n         results.append(\"\\n..\");\n         results.append(parent);\n         URL[] urls = getClassLoaderURLs(parent);\n         int length = urls != null ? urls.length : 0;\n         for(int u = 0; u < length; u ++)\n         {\n            results.append(\"\\n....\");\n            results.append(urls[u]);\n         }\n         if( parent != null )\n            parent = parent.getParent();\n      }\n      CodeSource clazzCS = clazz.getProtectionDomain().getCodeSource();\n      if( clazzCS != null )\n      {\n         results.append(\"\\n++++CodeSource: \");\n         results.append(clazzCS);\n      }\n      else\n         results.append(\"\\n++++Null CodeSource\");\n\n      results.append(\"\\nImplemented Interfaces:\");\n      Class[] ifaces = clazz.getInterfaces();\n      for(int i = 0; i < ifaces.length; i ++)\n      {\n         Class iface = ifaces[i];\n         results.append(\"\\n++\");\n         results.append(iface);\n         results.append(\"(\");\n         results.append(Integer.toHexString(iface.hashCode()));\n         results.append(\")\");\n         ClassLoader loader = ifaces[i].getClassLoader();\n         results.append(\"\\n++++ClassLoader: \");\n         results.append(loader);\n         ProtectionDomain pd = ifaces[i].getProtectionDomain();\n         CodeSource cs = pd.getCodeSource();\n         if( cs != null )\n         {\n            results.append(\"\\n++++CodeSource: \");\n            results.append(cs);\n         }\n         else\n            results.append(\"\\n++++Null CodeSource\");\n      }\n   }",
        "variable": "cl",
        "reference": "the clazz",
        "explanation_by_ours": "the class loader for which to display the class information",
        "explanation_by_baseline": "the class.if("
    },
    {
        "id": 2954,
        "method": "protected void addPropertyListener(final BoundPropertyListener listener)\n   {\n            String name = makePropertyName(listener.getPropertyName());\n\n      // get the bound listener list for the property\n      List list = (List) boundListeners.get(name);\n\n      // if list is null, then add a new list\n      if (list == null)\n      {\n         list = new ArrayList();\n         boundListeners.put(name, list);\n      }\n\n      // if listener is not in the list already, then add it\n      if (!list.contains(listener))\n      {\n         list.add(listener);\n         // notify listener that is is bound\n         listener.propertyBound(this);\n      }\n   }",
        "variable": "name",
        "reference": "the bound property name",
        "explanation_by_ours": "name of the property",
        "explanation_by_baseline": "the property name for the"
    },
    {
        "id": 2955,
        "method": "protected void addPropertyListener(final BoundPropertyListener listener)\n   {\n      // get the bound property name\n      String name = makePropertyName(listener.getPropertyName());\n\n            List list = (List) boundListeners.get(name);\n\n      // if list is null, then add a new list\n      if (list == null)\n      {\n         list = new ArrayList();\n         boundListeners.put(name, list);\n      }\n\n      // if listener is not in the list already, then add it\n      if (!list.contains(listener))\n      {\n         list.add(listener);\n         // notify listener that is is bound\n         listener.propertyBound(this);\n      }\n   }",
        "variable": "list",
        "reference": "the bound listener list for the property",
        "explanation_by_ours": "list of listeners for the property",
        "explanation_by_baseline": "the bound listeners list//"
    },
    {
        "id": 2979,
        "method": "public static boolean loadAgent(String className, int num, AObjectCatalog agents) {\n\n        Class<?> aclass = loadClass(className, Agent.class);\n    if (aclass == null) {\n      return false;\n    }\n\n    // Save this agent type to the catalog of known agent types\n    AgentType atype = new AgentType(className);\n    atype.setAgentClass(aclass);\n    GlobalState.agentTypes.push(atype);\n\n    // Find the goals that this agent has\n    String[] goals = getGoalsFromAgentInfoAnnotation(aclass);\n    if (goals.length == 0) {\n      return false;\n    }\n\n    // First pass: get the goals and their plans (flat goal-plan list)\n    loadGoalPlanNodes(atype, goals);\n\n    // Second pass: complete the goal-plan hierarchy\n    completeGoalPlanHierarchy();\n\n    // Now create the specified number of instances of this agent type\n    createAgentsInCatalog(agents, atype, aclass, num);\n\n    // return success\n    return true;\n  }",
        "variable": "aclass",
        "reference": "the Agent class",
        "explanation_by_ours": "the agent class to load",
        "explanation_by_baseline": "the agent classreturn false"
    },
    {
        "id": 2981,
        "method": "public static boolean loadAgent(String className, int num, AObjectCatalog agents) {\n\n    // Load the Agent class\n    Class<?> aclass = loadClass(className, Agent.class);\n    if (aclass == null) {\n      return false;\n    }\n\n    // Save this agent type to the catalog of known agent types\n    AgentType atype = new AgentType(className);\n    atype.setAgentClass(aclass);\n    GlobalState.agentTypes.push(atype);\n\n        String[] goals = getGoalsFromAgentInfoAnnotation(aclass);\n    if (goals.length == 0) {\n      return false;\n    }\n\n    // First pass: get the goals and their plans (flat goal-plan list)\n    loadGoalPlanNodes(atype, goals);\n\n    // Second pass: complete the goal-plan hierarchy\n    completeGoalPlanHierarchy();\n\n    // Now create the specified number of instances of this agent type\n    createAgentsInCatalog(agents, atype, aclass, num);\n\n    // return success\n    return true;\n  }",
        "variable": "goals",
        "reference": "the goals that this agent has",
        "explanation_by_ours": "the list of goals that this agent has",
        "explanation_by_baseline": "the goals from the annotation"
    },
    {
        "id": 2982,
        "method": "private static boolean processPlansForGoal(GoalType gtype, String[] plans) {\n    for (int j = 0; j < plans.length; j++) {\n            Class<?> pclass = loadClass(plans[j], Plan.class);\n      if (pclass == null) {\n        return false;\n      }\n      // Found the plan class, so add this plan to the catalog of known plan types\n      logger.info(\"Found Plan \" + pclass.getName() + \" that handles Goal \" + gtype.getName());\n      PlanType ptype = new PlanType(pclass.getName());\n      ptype.setPlanClass(pclass);\n      GlobalState.planTypes.push(ptype);\n      // Set up the parent/child links between them (makings of a goal-plan tree)\n      ptype.addParent((byte) gtype.getId());\n      gtype.addChild((byte) ptype.getId());\n    }\n    return true;\n  }",
        "variable": "pclass",
        "reference": "the Plan class",
        "explanation_by_ours": "the plan class",
        "explanation_by_baseline": "the plan classif ("
    },
    {
        "id": 2985,
        "method": "@Override\n  public boolean createBeliefSet(int agentid, String name, BeliefSetField[] fields)\n      throws BeliefBaseException {\n    if (beliefsets.containsKey(name)) {\n      return false;\n    }\n        BeliefSet bs = new BeliefSet(beliefsets.size(), name, fields);\n    beliefsets.put(name, bs);\n    beliefsetsByID.put(bs.getId(), bs);\n    return true;\n  }",
        "variable": "bs",
        "reference": "the beliefset",
        "explanation_by_ours": "the new belief set",
        "explanation_by_baseline": "beliefSetbelie"
    },
    {
        "id": 2992,
        "method": "private boolean manageGoal(int agentIndex, Agent agent, Stack255 agentExecutionStack, Goal node) {\n        GoalType gtype = (GoalType) GlobalState.goalTypes.find(node.getClass().getName());\n    byte[] ptypes = gtype.getChildren();\n    assert (ptypes != null);\n    // Clear any previous plan bindings before adding any new ones\n    bindings.clear();\n    for (int p = 0; p < ptypes.length; p++) {\n      PlanType ptype = (PlanType) GlobalState.planTypes.get(ptypes[p]);\n\n      try {\n        // Create an object of this Plan type, so we can\n        // access its context condition\n        Plan planInstance =\n            (Plan) (ptype.getPlanClass().getConstructor(Agent.class, Goal.class, String.class)\n                .newInstance(GlobalState.agents.get(agentIndex), node, \"p\"));\n        // Clear previously buffered context results if any\n        agent.clearLastResults();\n        // Evaluate the context condition\n        if (planInstance.context()) {\n          // Get the results of context query just performed\n          Set<Belief> results = agent.getLastResults();\n          // Add the results to the bindings\n          bindings.add(planInstance, (results == null) ? null : new LinkedHashSet<Belief>(results));\n        }\n      } catch (NoSuchMethodException | SecurityException | InstantiationException\n          | IllegalAccessException | IllegalArgumentException | InvocationTargetException e) {\n        logger.error(\"Could not create plan object of type \" + ptype.getClass().getName(), e);\n      }\n    }\n    int numBindings = bindings.size();\n    if (numBindings == 0) {\n      // No plan options for this goal at this point in time, so move to the next agent\n      logger.debug(Log.logPrefix(agent.getId()) + \" has no applicable plans for goal \" + gtype\n          + \" and will continue to wait indefinitely\");\n      return false;\n    }\n    // Call the meta-level planning prior to plan selection\n    agent.notifyAgentPrePlanSelection(bindings);\n    // Pick a plan option using specified policy\n    Plan planInstance = bindings.selectPlan(GlobalConstant.PLAN_SELECTION_POLICY);\n    // Now push the plan on to the intention stack\n    synchronized (agentExecutionStack) {\n      logger.debug(Log.logPrefix(agent.getId()) + \" choose an instance of plan \"\n          + planInstance.getClass().getSimpleName() + \" to handle goal \"\n          + node.getClass().getSimpleName());\n      agentExecutionStack.push(planInstance);\n    }\n    return true;\n  }",
        "variable": "gtype",
        "reference": "the goal type",
        "explanation_by_ours": "the type of the goal that is currently being selected",
        "explanation_by_baseline": "the type of plan options"
    },
    {
        "id": 2993,
        "method": "private boolean manageGoal(int agentIndex, Agent agent, Stack255 agentExecutionStack, Goal node) {\n    // Get the goal type for this goal\n    GoalType gtype = (GoalType) GlobalState.goalTypes.find(node.getClass().getName());\n    byte[] ptypes = gtype.getChildren();\n    assert (ptypes != null);\n    // Clear any previous plan bindings before adding any new ones\n    bindings.clear();\n    for (int p = 0; p < ptypes.length; p++) {\n      PlanType ptype = (PlanType) GlobalState.planTypes.get(ptypes[p]);\n\n      try {\n        // Create an object of this Plan type, so we can\n        // access its context condition\n        Plan planInstance =\n            (Plan) (ptype.getPlanClass().getConstructor(Agent.class, Goal.class, String.class)\n                .newInstance(GlobalState.agents.get(agentIndex), node, \"p\"));\n        // Clear previously buffered context results if any\n        agent.clearLastResults();\n        // Evaluate the context condition\n        if (planInstance.context()) {\n                    Set<Belief> results = agent.getLastResults();\n          // Add the results to the bindings\n          bindings.add(planInstance, (results == null) ? null : new LinkedHashSet<Belief>(results));\n        }\n      } catch (NoSuchMethodException | SecurityException | InstantiationException\n          | IllegalAccessException | IllegalArgumentException | InvocationTargetException e) {\n        logger.error(\"Could not create plan object of type \" + ptype.getClass().getName(), e);\n      }\n    }\n    int numBindings = bindings.size();\n    if (numBindings == 0) {\n      // No plan options for this goal at this point in time, so move to the next agent\n      logger.debug(Log.logPrefix(agent.getId()) + \" has no applicable plans for goal \" + gtype\n          + \" and will continue to wait indefinitely\");\n      return false;\n    }\n    // Call the meta-level planning prior to plan selection\n    agent.notifyAgentPrePlanSelection(bindings);\n    // Pick a plan option using specified policy\n    Plan planInstance = bindings.selectPlan(GlobalConstant.PLAN_SELECTION_POLICY);\n    // Now push the plan on to the intention stack\n    synchronized (agentExecutionStack) {\n      logger.debug(Log.logPrefix(agent.getId()) + \" choose an instance of plan \"\n          + planInstance.getClass().getSimpleName() + \" to handle goal \"\n          + node.getClass().getSimpleName());\n      agentExecutionStack.push(planInstance);\n    }\n    return true;\n  }",
        "variable": "results",
        "reference": "the results of context query",
        "explanation_by_ours": "the results of the context query just performed",
        "explanation_by_baseline": "the results that we've"
    },
    {
        "id": 2996,
        "method": "public static void main(String[] args) {\n    // Parse the command line options\n    ArgumentsLoader.parse(args);\n\n        Config config = ArgumentsLoader.getConfig();\n\n    // Initialise the system with the given arguments\n    if (!init(config)) {\n      return;\n    }\n\n    // load all extensions\n    if (!Program.loadExtensions(config)) {\n      return;\n    }\n\n    // Start the engine\n    start(config);\n\n    // Wait until the agents become idle\n    waitUntilIdle();\n\n    // finish up\n    finish();\n  }",
        "variable": "config",
        "reference": "the configuration",
        "explanation_by_ours": "configuration object",
        "explanation_by_baseline": "the configuration{{"
    },
    {
        "id": 3040,
        "method": "public URL writeToTempFile() throws IOException {\n    final File tempConfigFile = File.createTempFile(\"brikar-tempconfig-\", \".properties\");\n    tempConfigFile.deleteOnExit();\n\n        final Properties props = new Properties();\n    props.putAll(properties);\n    try (final FileOutputStream fileOutputStream = new FileOutputStream(tempConfigFile)) {\n      props.store(fileOutputStream, \"[brikar-maintenance] TempConfiguration - Autogenerated properties\");\n    }\n\n    return tempConfigFile.toURI().toURL();\n  }",
        "variable": "props",
        "reference": "the properties",
        "explanation_by_ours": "the properties to write",
        "explanation_by_baseline": "tempConfigFile.deleteOnExit"
    },
    {
        "id": 3083,
        "method": "public final Map<String, Integer> makeJob(final URL pUrl,\n    final Map<String, Object> pAddParams) throws Exception {\n    String requestedDatabaseId = (String) pAddParams.get(\"requestedDatabaseId\");\n    String maxRecordsStr = (String) pAddParams.get(\"maxRecords\");\n    if (maxRecordsStr == null || maxRecordsStr.length() == 0) {\n      throw new ExceptionWithCode(ExceptionWithCode.WRONG_PARAMETER,\n        \"Where is no maxRecords!!!\");\n    }\n    int maxRecords = Integer.parseInt(maxRecordsStr);\n    Map<String, Integer> classesCounts = new LinkedHashMap<String, Integer>();\n    Integer classCount = 0;\n    boolean isDbPreparedBefore = false;\n    int databaseVersion = this.srvDatabase.getVersionDatabase();\n    for (Class<?> entityClass : this.mngSettings.getClasses()) {\n      int entitiesReceived = 0;\n      int firstRecord = 0;\n      do {\n                HttpsURLConnection urlConnection = (HttpsURLConnection) pUrl.openConnection();\n        if (!pUrl.getHost().equals(urlConnection.getURL().getHost())) {\n          throw new ExceptionWithCode(ExceptionWithCode.SOMETHING_WRONG,\n            \"You should sign-in in browser first!\");\n        }\n        OutputStreamWriter writer = null;\n        BufferedReader reader = null;\n        try {\n          urlConnection.setDoOutput(true);\n          urlConnection.setRequestMethod(\"POST\");\n          if (getCookies() != null) {\n            urlConnection.addRequestProperty(\"Cookie\", getCookies());\n          }\n          writer = new OutputStreamWriter(urlConnection\n            .getOutputStream(), Charset.forName(\"UTF-8\").newEncoder());\n          String nameFilterEntities = this.mngSettings.lazClsSts(entityClass)\n            .get(\"filter\");\n          String conditions = \"\";\n          if (nameFilterEntities != null) {\n            IFilterEntities filterEntities = this.filtersEntities\n              .get(nameFilterEntities);\n            if (filterEntities != null) {\n              String cond = filterEntities.makeFilter(entityClass, pAddParams);\n              if (cond != null) {\n                conditions = \" where \" + cond;\n              }\n            }\n          }\n          conditions += \" limit \" + maxRecords + \" offset \" + firstRecord;\n          String requestedDatabaseIdStr = \"\";\n          if (requestedDatabaseId != null) {\n            if (Integer.parseInt(requestedDatabaseId)\n              == getSrvDatabase().getIdDatabase()) {\n              throw new ExceptionWithCode(ExceptionWithCode.WRONG_PARAMETER,\n                \"requested_database_must_be_different\");\n            }\n            requestedDatabaseIdStr = \"&requestedDatabaseId=\"\n                + requestedDatabaseId;\n          }\n          writer.write(\"entityName=\" + entityClass.getCanonicalName()\n            + \"&conditions=\" + conditions + \"&requestingDatabaseVersion=\"\n              + databaseVersion + requestedDatabaseIdStr);\n          writer.write(\"&writerName=\" + pAddParams.get(\"writerName\"));\n          writer.flush();\n          if (HttpsURLConnection.HTTP_OK == urlConnection.getResponseCode()) {\n            reader = new BufferedReader(new InputStreamReader(urlConnection\n                .getInputStream(), Charset.forName(\"UTF-8\").newDecoder()));\n            if (!this.utilXml.readUntilStart(reader, \"message\")) {\n              throw new ExceptionWithCode(ExceptionWithCode.SOMETHING_WRONG,\n                \"Wrong XML response without message tag!!!\");\n            }\n            Map<String, String> msgAttrsMap = this.srvEntityReaderXml.\n              readAttributes(pAddParams, reader);\n            String error = msgAttrsMap.get(\"error\");\n            if (error != null) {\n              throw new ExceptionWithCode(ExceptionWithCode.SOMETHING_WRONG,\n                error);\n            }\n            String entitiesCountStr = msgAttrsMap.get(\"entitiesCount\");\n            if (entitiesCountStr == null) {\n              throw new ExceptionWithCode(ExceptionWithCode.SOMETHING_WRONG,\n                \"Wrong XML response without entitiesCount in message!!!\");\n            }\n            entitiesReceived = Integer.parseInt(entitiesCountStr);\n            if (entitiesReceived > 0) {\n              classCount += entitiesReceived;\n              this.logger.info(null, ReplicatorXmlHttp.class,\n                \"Try to parse entities total: \" + entitiesReceived + \" of \"\n                  + entityClass.getCanonicalName());\n              if (!isDbPreparedBefore) {\n                if (this.databasePrepearerBefore != null) {\n                  this.databasePrepearerBefore.make(pAddParams);\n                }\n                isDbPreparedBefore = true;\n              }\n              this.databaseReader.readAndStoreEntities(pAddParams, reader);\n              if (entitiesReceived == maxRecords) {\n                firstRecord += maxRecords;\n              } else {\n                firstRecord = 0;\n                entitiesReceived = 0;\n              }\n            } else {\n              firstRecord = 0;\n            }\n          } else {\n            throw new ExceptionWithCode(ExceptionWithCode.SOMETHING_WRONG,\n              \"Can't receive data!!! Response code=\" + urlConnection\n                .getResponseCode());\n          }\n        } finally {\n          if (reader != null) {\n            try {\n              reader.close();\n            } catch (Exception e) {\n              e.printStackTrace();\n            }\n          }\n          if (writer != null) {\n            try {\n              writer.close();\n            } catch (Exception e) {\n              e.printStackTrace();\n            }\n          }\n          urlConnection.disconnect();\n        }\n      } while (entitiesReceived > 0);\n      classesCounts.put(entityClass.getCanonicalName(), classCount);\n      classCount = 0;\n    }\n    if (this.databasePrepearerAfter != null) {\n      this.databasePrepearerAfter.make(pAddParams);\n    }\n    return classesCounts;\n  }",
        "variable": "urlConnection",
        "reference": "HttpsURLConnection",
        "explanation_by_ours": "- URL connection",
        "explanation_by_baseline": "check if thereif ("
    },
    {
        "id": 3089,
        "method": "private void calculateColumns()\n    {\n        //create the sorted list of points\n        GridPoint points[] = new GridPoint[areas.size() * 2];\n        int pi = 0;\n        for (Area area : areas)\n        {\n            points[pi] = new GridPoint(area.getX1(), area, true);\n            points[pi+1] = new GridPoint(area.getX2() + 1, area, false);\n            pi += 2;\n            //X2+1 ensures that the end of one box will be on the same point\n            //as the start of the following box\n        }\n        Arrays.sort(points);\n        \n        //calculate the number of columns\n        int cnt = 0;\n        int last = abspos.getX1();\n        for (int i = 0; i < points.length; i++)\n            if (!theSame(points[i].value, last))\n            { \n                last = points[i].value;\n                cnt++;\n            }\n        if (!theSame(last, abspos.getX2()))\n        \tcnt++; //last column finishes the whole area\n        width = cnt;\n        \n        //calculate the column widths and the layout\n        maxindent = 0;\n        minindent = -1;\n        cols = new int[width];\n        cnt = 0;\n        last = abspos.getX1();\n        for (int i = 0; i < points.length; i++)\n        {\n            if (!theSame(points[i].value, last)) \n            {\n                cols[cnt] = points[i].value - last;\n                last = points[i].value;\n                cnt++;\n            }\n            if (points[i].begin)\n            {\n                target.getPosition(points[i].area).setX1(cnt);\n                maxindent = cnt;\n                if (minindent == -1) minindent = maxindent;\n                //points[i].node.getArea().setX1(parent.getArea().getX1() + getColOfs(cnt));\n            }\n            else\n            {\n                Rectangular pos = target.getPosition(points[i].area); \n                pos.setX2(cnt-1);\n                if (pos.getX2() < pos.getX1())\n                    pos.setX2(pos.getX1());\n                //points[i].node.getArea().setX2(parent.getArea().getX1() + getColOfs(pos.getX2()+1));\n            }\n        }\n        if (!theSame(last, abspos.getX2()))\n        \tcols[cnt] = abspos.getX2() - last;\n        if (minindent == -1)\n            minindent = 0;\n    }",
        "variable": "points",
        "reference": "the sorted list of points",
        "explanation_by_ours": "the grid points",
        "explanation_by_baseline": "the grid pointsif ("
    },
    {
        "id": 3232,
        "method": "public ActionForward perform(ActionMapping mapping, ActionForm form, HttpServletRequest request,\n        HttpServletResponse response) throws IOException, ServletException\n    {\n        log.fine(\"perform: called\");\n\n        // Reference the SortForm as a SortForm rather than the generic ActionForm\n        SortForm sortForm = (SortForm) form;\n\n                HttpSession session = request.getSession();\n\n        // Get a reference to the application scope\n        ServletContext application = session.getServletContext();\n\n        log.fine(\"variables in the servlet context: \");\n\n        for (Enumeration e = application.getAttributeNames(); e.hasMoreElements();)\n        {\n            log.fine(e.nextElement().toString());\n        }\n\n        // Get a reference to the list to be sorted\n        List list = (List) session.getAttribute(sortForm.getList());\n\n        // Get a reference to the comparator from the application scope to use to perform the sort\n        Comparator comparator = (Comparator) application.getAttribute(sortForm.getComparator());\n\n        log.fine(\"comparator = \" + comparator);\n\n        // Get a reference to the current sort state (if there is one)\n        SortStateBean sortStateBean = (SortStateBean) session.getAttribute(sortForm.getSortState());\n\n        // Check if there is no sort state bean and create one if so\n        if (sortStateBean == null)\n        {\n            log.fine(\"There is no sort state bean\");\n\n            sortStateBean = new SortStateBean();\n        }\n\n        // Determine whether a forward or reverse sort is to be done\n        // If its reverse sorted, unsorted or not sorted by the current sort property then forward sort it\n        if (!sortStateBean.getState().equals(SortStateBean.FORWARD) ||\n                !sortStateBean.getSortProperty().equals(sortForm.getSortStateProperty()))\n        {\n            // Sort the list\n            Collections.sort(list, comparator);\n\n            // Update the current sort state\n            sortStateBean.setState(SortStateBean.FORWARD);\n        }\n\n        // If its already forward sorted then reverse sort it\n        else\n        {\n            // Sort the list\n            Collections.sort(list, comparator);\n\n            // Reverse the list\n            Collections.reverse(list);\n\n            // Update the current sort state\n            sortStateBean.setState(SortStateBean.REVERSE);\n        }\n\n        // Store the sorted list in the variable from which the original list was taken\n        session.setAttribute(sortForm.getList(), list);\n\n        // Store the new sort state, setting the property that has been sorted by in the sort state\n        sortStateBean.setSortProperty(sortForm.getSortStateProperty());\n        session.setAttribute(sortForm.getSortState(), sortStateBean);\n\n        // Forward to the success page\n        return (mapping.findForward(\"success\"));\n    }",
        "variable": "session",
        "reference": "a reference to the session scope",
        "explanation_by_ours": "the current session",
        "explanation_by_baseline": "a reference to the session"
    },
    {
        "id": 3233,
        "method": "public ActionForward perform(ActionMapping mapping, ActionForm form, HttpServletRequest request,\n        HttpServletResponse response) throws IOException, ServletException\n    {\n        log.fine(\"perform: called\");\n\n        // Reference the SortForm as a SortForm rather than the generic ActionForm\n        SortForm sortForm = (SortForm) form;\n\n        // Get a reference to the session scope\n        HttpSession session = request.getSession();\n\n                ServletContext application = session.getServletContext();\n\n        log.fine(\"variables in the servlet context: \");\n\n        for (Enumeration e = application.getAttributeNames(); e.hasMoreElements();)\n        {\n            log.fine(e.nextElement().toString());\n        }\n\n        // Get a reference to the list to be sorted\n        List list = (List) session.getAttribute(sortForm.getList());\n\n        // Get a reference to the comparator from the application scope to use to perform the sort\n        Comparator comparator = (Comparator) application.getAttribute(sortForm.getComparator());\n\n        log.fine(\"comparator = \" + comparator);\n\n        // Get a reference to the current sort state (if there is one)\n        SortStateBean sortStateBean = (SortStateBean) session.getAttribute(sortForm.getSortState());\n\n        // Check if there is no sort state bean and create one if so\n        if (sortStateBean == null)\n        {\n            log.fine(\"There is no sort state bean\");\n\n            sortStateBean = new SortStateBean();\n        }\n\n        // Determine whether a forward or reverse sort is to be done\n        // If its reverse sorted, unsorted or not sorted by the current sort property then forward sort it\n        if (!sortStateBean.getState().equals(SortStateBean.FORWARD) ||\n                !sortStateBean.getSortProperty().equals(sortForm.getSortStateProperty()))\n        {\n            // Sort the list\n            Collections.sort(list, comparator);\n\n            // Update the current sort state\n            sortStateBean.setState(SortStateBean.FORWARD);\n        }\n\n        // If its already forward sorted then reverse sort it\n        else\n        {\n            // Sort the list\n            Collections.sort(list, comparator);\n\n            // Reverse the list\n            Collections.reverse(list);\n\n            // Update the current sort state\n            sortStateBean.setState(SortStateBean.REVERSE);\n        }\n\n        // Store the sorted list in the variable from which the original list was taken\n        session.setAttribute(sortForm.getList(), list);\n\n        // Store the new sort state, setting the property that has been sorted by in the sort state\n        sortStateBean.setSortProperty(sortForm.getSortStateProperty());\n        session.setAttribute(sortForm.getSortState(), sortStateBean);\n\n        // Forward to the success page\n        return (mapping.findForward(\"success\"));\n    }",
        "variable": "application",
        "reference": "a reference to the application scope",
        "explanation_by_ours": "the servlet context of the current request",
        "explanation_by_baseline": "a reference to the application"
    },
    {
        "id": 3253,
        "method": "public SearchNode<O, T> findGoalPath() throws SearchNotExhaustiveException\n    {\n        // Keep running until the queue becomes empty or a goal state is found\n        while (!forwardQueue.isEmpty() || !reverseQueue.isEmpty())\n        {\n            // Only run the forward step of the search if the forward queue is not empty\n            if (!forwardQueue.isEmpty())\n            {\n                                SearchNode<O, T> currentForwardNode = forwardQueue.remove();\n\n                // Remove this node from the forward fringe map as it will soon be replaced by more fringe members\n                forwardFringe.remove(currentForwardNode.getState());\n\n                // Check the reverse fringe against the next forward node for a match.\n                if (reverseFringe.containsKey(currentForwardNode.getState()))\n                {\n                    // A path from start to the goal has been found. Walk backwards along the reverse path adding all\n                    // nodes encountered to the forward path until the goal is reached.\n                    return joinBothPaths(currentForwardNode, reverseFringe.get(currentForwardNode.getState()));\n                }\n\n                // There was no match so a path to the goal has not been found\n                else\n                {\n                    // Get all of the successor states to the current node\n                    Queue<SearchNode<O, T>> newStates = new LinkedList<SearchNode<O, T>>();\n\n                    currentForwardNode.expandSuccessors(newStates, false);\n\n                    // Expand all the successors to the current forward node into the buffer to be searched.\n                    forwardQueue.addAll(newStates);\n\n                    // Also add all the successors to the current forward fringe map.\n                    for (SearchNode<O, T> nextSearchNode : newStates)\n                    {\n                        forwardFringe.put(nextSearchNode.getState(), nextSearchNode);\n                    }\n                }\n            }\n\n            // Only run the reverse step of the search if the reverse queue is not empty\n            if (!reverseQueue.isEmpty())\n            {\n                // Extract the next node from the reverse queue\n                SearchNode<O, T> currentReverseNode = reverseQueue.remove();\n\n                // Remove this node from the reverse fringe set as it will soon be replaced by more fringe members\n                reverseFringe.remove(currentReverseNode.getState());\n\n                // Check the forward fringe against the next reverse node for a match.\n                if (forwardFringe.containsKey(currentReverseNode.getState()))\n                {\n                    // A path from start to goal has been found.\n                    // Walk backwards along the reverse path adding all nodes encountered to the foward path until the\n                    // goal is reached.\n                    return joinBothPaths(forwardFringe.get(currentReverseNode.getState()), currentReverseNode);\n                }\n\n                // There was no match so a path to the goal has not been found\n                else\n                {\n                    // Get all of the successor states to the current node (really predecessor state)\n                    Queue<SearchNode<O, T>> newStates = new LinkedList<SearchNode<O, T>>();\n\n                    currentReverseNode.expandSuccessors(newStates, false);\n\n                    // Expand all the successors to the current reverse node into the reverse buffer to be searched.\n                    reverseQueue.addAll(newStates);\n\n                    // Add all the successors to the current reverse fringe set\n                    for (SearchNode<O, T> nextSearchNode : newStates)\n                    {\n                        reverseFringe.put(nextSearchNode.getState(), nextSearchNode);\n                    }\n                }\n            }\n        }\n\n        // No goal state was found so return null\n        return null;\n    }",
        "variable": "currentForwardNode",
        "reference": "the next node from the forward queue",
        "explanation_by_ours": "the current node in the forward queue",
        "explanation_by_baseline": "the next node from forward"
    },
    {
        "id": 3255,
        "method": "public SearchNode<O, T> findGoalPath() throws SearchNotExhaustiveException\n    {\n        // Keep running until the queue becomes empty or a goal state is found\n        while (!forwardQueue.isEmpty() || !reverseQueue.isEmpty())\n        {\n            // Only run the forward step of the search if the forward queue is not empty\n            if (!forwardQueue.isEmpty())\n            {\n                // Extract the next node from the forward queue\n                SearchNode<O, T> currentForwardNode = forwardQueue.remove();\n\n                // Remove this node from the forward fringe map as it will soon be replaced by more fringe members\n                forwardFringe.remove(currentForwardNode.getState());\n\n                // Check the reverse fringe against the next forward node for a match.\n                if (reverseFringe.containsKey(currentForwardNode.getState()))\n                {\n                    // A path from start to the goal has been found. Walk backwards along the reverse path adding all\n                    // nodes encountered to the forward path until the goal is reached.\n                    return joinBothPaths(currentForwardNode, reverseFringe.get(currentForwardNode.getState()));\n                }\n\n                // There was no match so a path to the goal has not been found\n                else\n                {\n                    // Get all of the successor states to the current node\n                    Queue<SearchNode<O, T>> newStates = new LinkedList<SearchNode<O, T>>();\n\n                    currentForwardNode.expandSuccessors(newStates, false);\n\n                    // Expand all the successors to the current forward node into the buffer to be searched.\n                    forwardQueue.addAll(newStates);\n\n                    // Also add all the successors to the current forward fringe map.\n                    for (SearchNode<O, T> nextSearchNode : newStates)\n                    {\n                        forwardFringe.put(nextSearchNode.getState(), nextSearchNode);\n                    }\n                }\n            }\n\n            // Only run the reverse step of the search if the reverse queue is not empty\n            if (!reverseQueue.isEmpty())\n            {\n                                SearchNode<O, T> currentReverseNode = reverseQueue.remove();\n\n                // Remove this node from the reverse fringe set as it will soon be replaced by more fringe members\n                reverseFringe.remove(currentReverseNode.getState());\n\n                // Check the forward fringe against the next reverse node for a match.\n                if (forwardFringe.containsKey(currentReverseNode.getState()))\n                {\n                    // A path from start to goal has been found.\n                    // Walk backwards along the reverse path adding all nodes encountered to the foward path until the\n                    // goal is reached.\n                    return joinBothPaths(forwardFringe.get(currentReverseNode.getState()), currentReverseNode);\n                }\n\n                // There was no match so a path to the goal has not been found\n                else\n                {\n                    // Get all of the successor states to the current node (really predecessor state)\n                    Queue<SearchNode<O, T>> newStates = new LinkedList<SearchNode<O, T>>();\n\n                    currentReverseNode.expandSuccessors(newStates, false);\n\n                    // Expand all the successors to the current reverse node into the reverse buffer to be searched.\n                    reverseQueue.addAll(newStates);\n\n                    // Add all the successors to the current reverse fringe set\n                    for (SearchNode<O, T> nextSearchNode : newStates)\n                    {\n                        reverseFringe.put(nextSearchNode.getState(), nextSearchNode);\n                    }\n                }\n            }\n        }\n\n        // No goal state was found so return null\n        return null;\n    }",
        "variable": "currentReverseNode",
        "reference": "the next node from the reverse queue",
        "explanation_by_ours": "the current node in the reverse fringe",
        "explanation_by_baseline": "the next node from reverse"
    },
    {
        "id": 3361,
        "method": "public static Properties getProperties(File file) throws IOException\n    {\n        /*log.fine(\"getProperties(File): called\");*/\n\n                InputStream is = new FileInputStream(file);\n\n        // Create properties object loaded from the stream\n        Properties properties = getProperties(is);\n\n        // Close the file\n        is.close();\n\n        return properties;\n    }",
        "variable": "is",
        "reference": "an input stream",
        "explanation_by_ours": "the input stream to read the properties from",
        "explanation_by_baseline": "a stream public"
    },
    {
        "id": 3362,
        "method": "public static Properties getProperties(File file) throws IOException\n    {\n        /*log.fine(\"getProperties(File): called\");*/\n\n        // Open the file as an input stream\n        InputStream is = new FileInputStream(file);\n\n                Properties properties = getProperties(is);\n\n        // Close the file\n        is.close();\n\n        return properties;\n    }",
        "variable": "properties",
        "reference": "properties object loaded from the stream",
        "explanation_by_ours": "the properties object",
        "explanation_by_baseline": "the properties public"
    },
    {
        "id": 3398,
        "method": "public int expandSuccessors(Queue<SearchNode<O, T>> expandInto, boolean reverse) throws SearchNotExhaustiveException\n    {\n        // Used to keep count of the number of successors.\n        int numSuccessors = 0;\n\n        for (Iterator<Successor<O>> successors = getState().successors(reverse); successors.hasNext();)\n        {\n            numSuccessors++;\n\n                        Successor<O> next = successors.next();\n\n            // Check if a repeated state filter is to be applied\n            if (repeatedStateFilter != null)\n            {\n                // Filter the successor state and check if it should be accepted\n                if (repeatedStateFilter.evaluate((T) next.getState(), this))\n                {\n                    // Add the filtered state to the successors\n                    expandInto.offer(makeNode(next));\n                }\n            }\n\n            // No repeated state filter is to be applied so add the successor state\n            else\n            {\n                expandInto.offer(makeNode(next));\n            }\n        }\n\n        // Successors have been expanded.\n        expanded = true;\n\n        return numSuccessors;\n    }",
        "variable": "next",
        "reference": "the next successor state",
        "explanation_by_ours": "the next successor state",
        "explanation_by_baseline": "the next successor state."
    },
    {
        "id": 3460,
        "method": "public Iterator<Operator<String>> validOperators(boolean reverse)\n    {\n                List<Operator<String>> moves = new ArrayList<Operator<String>>(4);\n\n        // Check if the up move is valid\n        if (emptyY != 0)\n        {\n            moves.add(new OperatorImpl<String>(\"U\"));\n        }\n\n        // Check if the down move is valid\n        if (emptyY != 2)\n        {\n            moves.add(new OperatorImpl<String>(\"D\"));\n        }\n\n        // Check if the left move is valid\n        if (emptyX != 0)\n        {\n            moves.add(new OperatorImpl<String>(\"L\"));\n        }\n\n        // Check if the right move is valid\n        if (emptyX != 2)\n        {\n            moves.add(new OperatorImpl<String>(\"R\"));\n        }\n\n        return moves.iterator();\n    }",
        "variable": "moves",
        "reference": "a list of valid moves",
        "explanation_by_ours": "The list of valid operators.",
        "explanation_by_baseline": "all the valid operators in"
    },
    {
        "id": 3461,
        "method": "protected int swapTileToLocationCountingIllegal(char t, int x, int y)\n    {\n                int illegal = 0;\n\n        // Find out where the tile to move is\n        int tileX = getXForTile(t);\n        int tileY = getYForTile(t);\n\n        // Shift the tile into the correct column by repeatedly moving it left or right.\n        while (tileX != x)\n        {\n            if ((tileX - x) > 0)\n            {\n                if (swapTiles(tileX, tileY, tileX - 1, tileY))\n                {\n                    illegal++;\n                }\n\n                tileX--;\n            }\n            else\n            {\n                if (swapTiles(tileX, tileY, tileX + 1, tileY))\n                {\n                    illegal++;\n                }\n\n                tileX++;\n            }\n        }\n\n        // Shift the tile into the correct row by repeatedly moving it up or down.\n        while (tileY != y)\n        {\n            // Commented out because tiles never swap down the board during the solvability test because tiles are\n            // swapped into place left to right, top to bottom. The top row is always filled first so tiles cannot be\n            // swapped down into it. Then the next row is filled but ones from the row above are never swapped down\n            // into it because they are alrady in place and never move again and so on.\n            /* if (tileY - y > 0)\n             *{*/\n            if (swapTiles(tileX, tileY, tileX, tileY - 1))\n            {\n                illegal++;\n            }\n\n            tileY--;\n            /*}\n             * else { if (swapTiles(tileX, tileY, tileX, tileY + 1)) illegal++; tileY++;}*/\n        }\n\n        return illegal;\n    }",
        "variable": "illegal",
        "reference": "the count of illegal swaps",
        "explanation_by_ours": "The number of swaps that occurred.",
        "explanation_by_baseline": "the illegal tile count."
    },
    {
        "id": 3468,
        "method": "private static EightPuzzleState charListToState(List<Character> charList)\n    {\n                EightPuzzleState newState = new EightPuzzleState();\n\n        // Loop over the board inserting the characters into it from the character list\n        Iterator<Character> k = charList.iterator();\n\n        for (int j = 0; j < 3; j++)\n        {\n            for (int i = 0; i < 3; i++)\n            {\n                char nextChar = k.next();\n\n                // Check if this is the empty tile and if so then take note of its position\n                if (nextChar == 'E')\n                {\n                    newState.emptyX = i;\n                    newState.emptyY = j;\n                }\n\n                newState.board[j][i] = nextChar;\n            }\n        }\n\n        return newState;\n    }",
        "variable": "newState",
        "reference": "a new empty puzzle state",
        "explanation_by_ours": "the new puzzle state",
        "explanation_by_baseline": "a new state{"
    },
    {
        "id": 3485,
        "method": "public ActionForward execute(ActionMapping mapping, ActionForm form, HttpServletRequest request,\n        HttpServletResponse response) throws IOException, ServletException\n    {\n        log.fine(\"ActionForward perform(ActionMapping, ActionForm, HttpServletRequest, HttpServletResponse): called\");\n\n        // Build an ActionErrors object to hold any errors that occurr\n        ActionErrors errors = new ActionErrors();\n\n                HttpSession session = request.getSession();\n\n        // Use a try block to catch any errors that may occur\n        try\n        {\n            return executeWithErrorHandling(mapping, form, request, response, errors);\n        }\n\n        // Catch all exceptions here. This will forward to the error page in the event of\n        // any exception that falls through to this top level handler.\n        // Don't catch Throwable here as Errors should fall through to the JVM top level and will result in\n        // termination of the application.\n        catch (Exception t)\n        {\n            log.log(Level.WARNING, \"Caught a Throwable\", t);\n\n            // Don't Forward the error to the error handler to interpret it as a Struts error as the exception will\n            // automatically be translated by the error page.\n\n            // @todo Could add code here to check if there is a 'error' forward page defined. If there is then call\n            // the error handler to translate the throwable into Struts errors and then forward to the 'error' page.\n            // This would mean that the error page defined in web.xml would be the default unless an action explicitly\n            // defined an alternative 'error' forward.\n            // handleErrors(t, errors);\n\n            // Save all the error messages in the request so that they will be displayed\n            // request.setAttribute(Action.ERROR_KEY, errors);\n\n            // Rethrow the error as a ServletException here to cause forwarding to error page defined in web.xml\n            throw new WrappedStrutsServletException(t);\n        }\n    }",
        "variable": "session",
        "reference": "the reference to the session",
        "explanation_by_ours": "the HttpSession object that contains the information about the action being performed.",
        "explanation_by_baseline": "thethe error page"
    },
    {
        "id": 3539,
        "method": "public static String calculateRFC2104HMAC(String data, String key) \n\t  \tthrows java.security.SignatureException {\n\t    if (data == null) {\n\t      throw new IllegalArgumentException(\"String data == null\");\n\t    }\n\t    if (key == null) {\n\t      throw new IllegalArgumentException(\"String key == null\");\n\t    }\n\t\t  try {\n\t\t\t  // Get an hmac_sha1 key from the raw key bytes\n\t\t\t  byte[] keyBytes = key.getBytes(\"UTF-8\");\n\t\t\t  SecretKeySpec signingKey = new SecretKeySpec(keyBytes, HMAC_SHA1_ALGORITHM);\n\n\t\t\t  // Get an hmac_sha1 Mac instance and initialize with the signing key\n\t\t\t  Mac mac = Mac.getInstance(HMAC_SHA1_ALGORITHM);\n\t\t\t  mac.init(signingKey);\n\n\t\t\t  \t\t\t  byte[] rawHmac = mac.doFinal(data.getBytes(\"UTF-8\"));\n\n\t\t\t  // Convert raw bytes to encoding\n\t\t\t  return Base64.encodeBase64URLSafeString(rawHmac);\n\n\t\t  } catch (NoSuchAlgorithmException e) {\n\t\t\t  throw new SignatureException(\"Failed to generate HMAC : \" + e.getMessage(), e);\n\t\t  } catch (InvalidKeyException e) {\n\t\t\t  throw new SignatureException(\"Failed to generate HMAC : \" + e.getMessage(), e);\n\t\t  } catch (UnsupportedEncodingException e) {\n\t\t\t  throw new SignatureException(\"Failed to generate HMAC : \" + e.getMessage(), e);\n\t\t  }\n\t  }",
        "variable": "rawHmac",
        "reference": "the hmac on input data bytes",
        "explanation_by_ours": "The raw HMAC of the data",
        "explanation_by_baseline": "the hmac_sha1 digest"
    }
]