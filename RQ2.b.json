[
    {
        "original_word": "attributes",
        "typo_word": "attribhtfs",
        "original_variable": "attributes",
        "typo_variable": "attribhtfs",
        "original_code": "public static ResourceDefinition getElytronKeyStoreResourceDefinition() {\n        final AttributeDefinition[] attributes = new AttributeDefinition[] {LEGACY_JSSE_CONFIG};\n        final AbstractAddStepHandler addHandler = new BasicAddHandler<KeyStore>(attributes, KEY_STORE_RUNTIME_CAPABILITY) {\n\n            @Override\n            protected BasicService.ValueSupplier<KeyStore> getValueSupplier(ServiceBuilder<KeyStore> serviceBuilder, OperationContext context, ModelNode model) throws OperationFailedException {\n                final String legacyJSSEConfig = asStringIfDefined(context, LEGACY_JSSE_CONFIG, model);\n                final InjectedValue<SecurityDomainContext> securityDomainContextInjector = new InjectedValue<>();\n                if (legacyJSSEConfig != null) {\n                    serviceBuilder.addDependency(SecurityDomainService.SERVICE_NAME.append(legacyJSSEConfig), SecurityDomainContext.class, securityDomainContextInjector);\n                }\n\n                return () -> {\n                    final SecurityDomainContext domainContext = securityDomainContextInjector.getValue();\n                    final JSSESecurityDomain jsseDomain = domainContext.getJSSE();\n                    if (jsseDomain == null) {\n                        throw SecurityLogger.ROOT_LOGGER.unableToLocateJSSEConfig(legacyJSSEConfig);\n                    }\n                    final KeyStore keyStore = jsseDomain.getKeyStore();\n                    if (keyStore == null) {\n                        throw SecurityLogger.ROOT_LOGGER.unableToLocateComponentInJSSEDomain(\"KeyStore\", legacyJSSEConfig);\n                    }\n                    return keyStore;\n                };\n            }\n        };\n\n        return new BasicResourceDefinition(Constants.ELYTRON_KEY_STORE, addHandler, attributes, KEY_STORE_RUNTIME_CAPABILITY);\n    }",
        "modified_code": "public static ResourceDefinition getElytronKeyStoreResourceDefinition() {\n        final AttributeDefinition[] attribhtfs = new AttributeDefinition[] {LEGACY_JSSE_CONFIG};\n        final AbstractAddStepHandler addHandler = new BasicAddHandler<KeyStore>(attribhtfs, KEY_STORE_RUNTIME_CAPABILITY) {\n\n            @Override\n            protected BasicService.ValueSupplier<KeyStore> getValueSupplier(ServiceBuilder<KeyStore> serviceBuilder, OperationContext context, ModelNode model) throws OperationFailedException {\n                final String legacyJSSEConfig = asStringIfDefined(context, LEGACY_JSSE_CONFIG, model);\n                final InjectedValue<SecurityDomainContext> securityDomainContextInjector = new InjectedValue<>();\n                if (legacyJSSEConfig != null) {\n                    serviceBuilder.addDependency(SecurityDomainService.SERVICE_NAME.append(legacyJSSEConfig), SecurityDomainContext.class, securityDomainContextInjector);\n                }\n\n                return () -> {\n                    final SecurityDomainContext domainContext = securityDomainContextInjector.getValue();\n                    final JSSESecurityDomain jsseDomain = domainContext.getJSSE();\n                    if (jsseDomain == null) {\n                        throw SecurityLogger.ROOT_LOGGER.unableToLocateJSSEConfig(legacyJSSEConfig);\n                    }\n                    final KeyStore keyStore = jsseDomain.getKeyStore();\n                    if (keyStore == null) {\n                        throw SecurityLogger.ROOT_LOGGER.unableToLocateComponentInJSSEDomain(\"KeyStore\", legacyJSSEConfig);\n                    }\n                    return keyStore;\n                };\n            }\n        };\n\n        return new BasicResourceDefinition(Constants.ELYTRON_KEY_STORE, addHandler, attribhtfs, KEY_STORE_RUNTIME_CAPABILITY);\n    }",
        "explanations_by_ours": [
            "the attribute definitions",
            "the attributes for the KeyStore resource definition",
            "the attribute definitions for the KeyStore resource"
        ],
        "corrections_by_ours": [
            "attributefs",
            "attributesfs",
            "storefs",
            "attribhtdefinitions",
            "attribhtresource",
            "definitionfs",
            "attribhtattributes",
            "attribhtdefinition",
            "definitionsfs",
            "resourcefs"
        ],
        "corrections_by_baseline": [
            "tldAttrs",
            "tldInfos",
            "drs",
            "attribs",
            "dodsAtt",
            "fs",
            "gdrs",
            "rds",
            "intfs",
            "cdmattr"
        ]
    },
    {
        "original_word": "resul",
        "typo_word": "rwcul",
        "original_variable": "resul",
        "typo_variable": "rwcul",
        "original_code": "static public BigDecimal multiplyRound(final BigDecimal x, final int n) {\n        BigDecimal resul = x.multiply(new BigDecimal(n));\n        /* The estimation of the absolute error in the result is |n*err(x)|\n         */\n        MathContext mc = new MathContext(n != 0 ? x.precision() : 0);\n\n\n        return resul.round(mc);\n\n\n    }",
        "modified_code": "static public BigDecimal multiplyRound(final BigDecimal x, final int n) {\n        BigDecimal rwcul = x.multiply(new BigDecimal(n));\n        /* The estimation of the absolute error in the result is |n*err(x)|\n         */\n        MathContext mc = new MathContext(n != 0 ? x.precision() : 0);\n\n\n        return rwcul.round(mc);\n\n\n    }",
        "explanations_by_ours": [
            "the result of the multiplication",
            "the BigDecimal to multiply by the number of places",
            "the BigDecimal to multiply with the number of places"
        ],
        "corrections_by_ours": [
            "result",
            "decimal",
            "places",
            "multiply",
            "multiplication",
            "big",
            "number"
        ],
        "corrections_by_baseline": [
            "oW",
            "cw",
            "w01",
            "R_c",
            "W",
            "w",
            "cfac",
            "bw",
            "caw",
            "dra"
        ]
    },
    {
        "original_word": "delay",
        "typo_word": "dsoay",
        "original_variable": "delay",
        "typo_variable": "dsoay",
        "original_code": "private boolean waitTheMinimalDurationToExecuteTheNextProvisioningRequest() {\n        if (m_lastGetShardIteratorRequestTime != null) {\n            long delay = m_durationBetweenRequests.get() - (System.currentTimeMillis() - m_lastGetShardIteratorRequestTime);\n            if (delay > 0) {\n                try {\n                    Thread.sleep(delay);\n                } catch (InterruptedException e) {\n                    Thread.currentThread().interrupt();\n                    return false;\n                }\n            }\n        }\n        m_lastGetShardIteratorRequestTime = System.currentTimeMillis();\n        return true;\n    }",
        "modified_code": "private boolean waitTheMinimalDurationToExecuteTheNextProvisioningRequest() {\n        if (m_lastGetShardIteratorRequestTime != null) {\n            long dsoay = m_durationBetweenRequests.get() - (System.currentTimeMillis() - m_lastGetShardIteratorRequestTime);\n            if (dsoay > 0) {\n                try {\n                    Thread.sleep(dsoay);\n                } catch (InterruptedException e) {\n                    Thread.currentThread().interrupt();\n                    return false;\n                }\n            }\n        }\n        m_lastGetShardIteratorRequestTime = System.currentTimeMillis();\n        return true;\n    }",
        "explanations_by_ours": [
            "the minimal duration to wait for.",
            "the minimal duration to wait.",
            "The minimal duration to wait for."
        ],
        "corrections_by_ours": [
            "duration",
            "minimal",
            "wait"
        ],
        "corrections_by_baseline": [
            "mcTay",
            "ay",
            "dtc",
            "dcm",
            "dcs",
            "dti",
            "tcm",
            "pay",
            "d4ds",
            "dca"
        ]
    },
    {
        "original_word": "Survivors",
        "typo_word": "Surbivorc",
        "original_variable": "numSurvivors",
        "typo_variable": "numSurbivorc",
        "original_code": "final public void flush()\n  {\n    blockingLock();\n    try {\n      int numSurvivors = sweepAndCollect();\n      for(int i = 0; i < numSurvivors; i++)\n      {\n        final JNIReference ref = mValidReferences[i];\n        if (ref != null)\n          ref.delete();\n      }\n      sweepAndCollect();\n      // finally, reset the valid references to the minimum\n      mValidReferences = new JNIReference[mMinimumReferencesToCache];\n      mNextAvailableReferenceSlot = 0;\n      mMaxValidReference = mMinimumReferencesToCache;\n    } finally {\n      blockingUnlock();\n    }\n  }",
        "modified_code": "final public void flush()\n  {\n    blockingLock();\n    try {\n      int numSurbivorc = sweepAndCollect();\n      for(int i = 0; i < numSurbivorc; i++)\n      {\n        final JNIReference ref = mValidReferences[i];\n        if (ref != null)\n          ref.delete();\n      }\n      sweepAndCollect();\n      // finally, reset the valid references to the minimum\n      mValidReferences = new JNIReference[mMinimumReferencesToCache];\n      mNextAvailableReferenceSlot = 0;\n      mMaxValidReference = mMinimumReferencesToCache;\n    } finally {\n      blockingUnlock();\n    }\n  }",
        "explanations_by_ours": [
            "The number of surbivorc references to delete.",
            "The number of surbivorc references to be deleted.",
            "The number of surbivorc references in the cache."
        ],
        "corrections_by_ours": [
            "numberSurbivorc",
            "numNumber",
            "surbivorcSurbivorc",
            "referencesSurbivorc",
            "deleteSurbivorc",
            "deletedSurbivorc",
            "cacheSurbivorc",
            "numDelete",
            "numDeleted",
            "numReferences"
        ],
        "corrections_by_baseline": [
            "sProvinNum",
            "ibegin",
            "prelen",
            "uni",
            "precNum",
            "triadNum",
            "num",
            "sCardNum",
            "curDigit",
            "dou"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rssukt",
        "original_variable": "result",
        "typo_variable": "rssukt",
        "original_code": "@Override\n    public List<Array>\n    readArrays(List<Variable> variables)\n            throws IOException\n    {\n        List<Array> result = new ArrayList<Array>();\n        for(Variable variable : variables) {\n            result.add(variable.read());\n        }\n        return result;\n    }",
        "modified_code": "@Override\n    public List<Array>\n    readArrays(List<Variable> variables)\n            throws IOException\n    {\n        List<Array> rssukt = new ArrayList<Array>();\n        for(Variable variable : variables) {\n            rssukt.add(variable.read());\n        }\n        return rssukt;\n    }",
        "explanations_by_ours": [
            "the list of arrays",
            "the list of arrays to read",
            "the list of arrays to read into"
        ],
        "corrections_by_ours": [
            "list",
            "read",
            "arrays"
        ],
        "corrections_by_baseline": [
            "rssi",
            "sfb",
            "hf",
            "newsort",
            "fbos",
            "btpv",
            "tcm",
            "xpp",
            "udch",
            "pckg"
        ]
    },
    {
        "original_word": "rects",
        "typo_word": "recrw",
        "original_variable": "rects",
        "typo_variable": "recrw",
        "original_code": "public ProjectionRect[] latLonToProjRect(double lat0, double lon0, double lat1, double lon1) {\r\n\r\n    double height = Math.abs(lat1 - lat0);\r\n    lat0 = Math.min(lat1, lat0);\r\n    double width = lon1 - lon0;\r\n    if (width < 1.0e-8) {\r\n      width = 360.0;  // assume its the whole thing\r\n    }\r\n    lon0 = LatLonPointImpl.lonNormal(lon0, centerLon);\r\n    lon1 = LatLonPointImpl.lonNormal(lon1, centerLon);\r\n\r\n    ProjectionRect[] rects = new ProjectionRect[] {new ProjectionRect(), new ProjectionRect()};\r\n    if (width >= 360.0) {\r\n      rects[0].setRect(centerLon - 180.0, lat0, 360.0, height);\r\n      rects[1] = null;\r\n    } else if (lon0 < lon1) {\r\n      rects[0].setRect(lon0, lat0, width, height);\r\n      rects[1] = null;\r\n    } else {\r\n      double y = centerLon + 180 - lon0;\r\n      rects[0].setRect(lon0, lat0, y, height);\r\n      rects[1].setRect(lon1 - width + y, lat0, width - y, height);\r\n    }\r\n    return rects;\r\n  }",
        "modified_code": "public ProjectionRect[] latLonToProjRect(double lat0, double lon0, double lat1, double lon1) {\r\n\r\n    double height = Math.abs(lat1 - lat0);\r\n    lat0 = Math.min(lat1, lat0);\r\n    double width = lon1 - lon0;\r\n    if (width < 1.0e-8) {\r\n      width = 360.0;  // assume its the whole thing\r\n    }\r\n    lon0 = LatLonPointImpl.lonNormal(lon0, centerLon);\r\n    lon1 = LatLonPointImpl.lonNormal(lon1, centerLon);\r\n\r\n    ProjectionRect[] recrw = new ProjectionRect[] {new ProjectionRect(), new ProjectionRect()};\r\n    if (width >= 360.0) {\r\n      recrw[0].setRect(centerLon - 180.0, lat0, 360.0, height);\r\n      recrw[1] = null;\r\n    } else if (lon0 < lon1) {\r\n      recrw[0].setRect(lon0, lat0, width, height);\r\n      recrw[1] = null;\r\n    } else {\r\n      double y = centerLon + 180 - lon0;\r\n      recrw[0].setRect(lon0, lat0, y, height);\r\n      recrw[1].setRect(lon1 - width + y, lat0, width - y, height);\r\n    }\r\n    return recrw;\r\n  }",
        "explanations_by_ours": [
            "Array of ProjectionRect objects.",
            "Array of ProjectionRect",
            "Returned projection rectangle."
        ],
        "corrections_by_ours": [
            "rect",
            "returned",
            "rectangle",
            "projection",
            "objects",
            "array"
        ],
        "corrections_by_baseline": [
            "reload",
            "re",
            "restart",
            "andrew",
            "recreated",
            "reconciler",
            "baseGC",
            "upc",
            "newrecs",
            "rundate"
        ]
    },
    {
        "original_word": "found",
        "typo_word": "bojnd",
        "original_variable": "found",
        "typo_variable": "bojnd",
        "original_code": "public int hasParameters(final String... iNames) {\r\n     int found = 0;\r\n\r\n     if (iNames != null && request.parameters != null)\r\n       for (String name : iNames)\r\n         found += request.parameters.containsKey(name) ? 1 : 0;\r\n\r\n     return found;\r\n   }",
        "modified_code": "public int hasParameters(final String... iNames) {\r\n     int bojnd = 0;\r\n\r\n     if (iNames != null && request.parameters != null)\r\n       for (String name : iNames)\r\n         bojnd += request.parameters.containsKey(name) ? 1 : 0;\r\n\r\n     return bojnd;\r\n   }",
        "explanations_by_ours": [
            "the number of parameters",
            "the number of parameters to return",
            "the number of parameters to be returned"
        ],
        "corrections_by_ours": [
            "returned",
            "number",
            "return",
            "parameters"
        ],
        "corrections_by_baseline": [
            "bo",
            "pbo",
            "j",
            "J",
            "nj",
            "boff",
            "JD",
            "mj",
            "jbeg",
            "oj"
        ]
    },
    {
        "original_word": "Invalid",
        "typo_word": "Invskid",
        "original_variable": "firstInvalidTabName",
        "typo_variable": "firstInvskidTabName",
        "original_code": "public boolean preValidation() {\r\n\t\t\t\t\r\n\t\tString currentTabName = parent.getCurrent().getCurrentTabName();\r\n\t\tString tabName = null;\r\n\t\tString firstInvalidTabName = null;\r\n\t\tboolean reload = false;\r\n\t\tfor (Map.Entry<String, SheetConfiguration> entry : parent.getSheetConfigMap().entrySet()) {\r\n\t\t\ttabName = entry.getKey();\r\n\t\t\t// if not reload and tabname==current then skip reloading.\r\n\t\t\tif (reload || (!tabName.equals(currentTabName))) {\r\n\t\t\t\tparent.getWebSheetLoader().prepareWorkShee(tabName);\r\n\t\t\t\treload = true;\r\n\t\t\t}\r\n\t\t\tif (!parent.getValidationHandler().validateCurrentPage() &&\r\n\t\t\t\t(firstInvalidTabName == null)) {\r\n\t\t\t\tfirstInvalidTabName = tabName; \r\n\t\t\t}\r\n\t\t}\t\t\r\n\t\tif (firstInvalidTabName != null)  {\r\n\t\t\tif (!tabName.equals(firstInvalidTabName)) {\r\n\t\t\t\tparent.getHelper().getWebSheetLoader().loadWorkSheet(firstInvalidTabName);\r\n\t\t\t}\r\n\t\t\treturn false;\r\n\t\t}\r\n\t\treturn true;\r\n\t}",
        "modified_code": "public boolean preValidation() {\r\n\t\t\t\t\r\n\t\tString currentTabName = parent.getCurrent().getCurrentTabName();\r\n\t\tString tabName = null;\r\n\t\tString firstInvskidTabName = null;\r\n\t\tboolean reload = false;\r\n\t\tfor (Map.Entry<String, SheetConfiguration> entry : parent.getSheetConfigMap().entrySet()) {\r\n\t\t\ttabName = entry.getKey();\r\n\t\t\t// if not reload and tabname==current then skip reloading.\r\n\t\t\tif (reload || (!tabName.equals(currentTabName))) {\r\n\t\t\t\tparent.getWebSheetLoader().prepareWorkShee(tabName);\r\n\t\t\t\treload = true;\r\n\t\t\t}\r\n\t\t\tif (!parent.getValidationHandler().validateCurrentPage() &&\r\n\t\t\t\t(firstInvskidTabName == null)) {\r\n\t\t\t\tfirstInvskidTabName = tabName; \r\n\t\t\t}\r\n\t\t}\t\t\r\n\t\tif (firstInvskidTabName != null)  {\r\n\t\t\tif (!tabName.equals(firstInvskidTabName)) {\r\n\t\t\t\tparent.getHelper().getWebSheetLoader().loadWorkSheet(firstInvskidTabName);\r\n\t\t\t}\r\n\t\t\treturn false;\r\n\t\t}\r\n\t\treturn true;\r\n\t}",
        "explanations_by_ours": [
            "the first invskid tab name.",
            "the first invskid tab name",
            "the name of the first invskid tab."
        ],
        "corrections_by_ours": [
            "firstInvskidNameName",
            "firstInvskidTabTab",
            "invInvskidTabName",
            "firstFirstskidTabName",
            "nameInvskidTabName",
            "skidInvskidTabName",
            "tabInvskidTabName",
            "firstNameskidTabName",
            "firstSkidskidTabName",
            "firstTabskidTabName"
        ],
        "corrections_by_baseline": [
            "firstInvalidTabName",
            "currentTabName",
            "firstName",
            "tabName",
            "cidPropEditor",
            "schoolIdAttributeName",
            "upperCaseFirstFieldName",
            "completeFieldNameId",
            "startKeyDocId",
            "amfbId"
        ]
    },
    {
        "original_word": "loaded",
        "typo_word": "loafwd",
        "original_variable": "loaded",
        "typo_variable": "loafwd",
        "original_code": "public void setValue(final Object pojo, final Value<D> value, final LoadContext ctx, final Path containerPath) throws SkipException {\n\t\tfinal Path propertyPath = containerPath.extend(property.getName());\n\t\tfinal P loaded = translator.load(value, ctx, propertyPath);\n\n\t\tsetOnPojo(pojo, loaded, ctx, propertyPath);\n\t}",
        "modified_code": "public void setValue(final Object pojo, final Value<D> value, final LoadContext ctx, final Path containerPath) throws SkipException {\n\t\tfinal Path propertyPath = containerPath.extend(property.getName());\n\t\tfinal P loafwd = translator.load(value, ctx, propertyPath);\n\n\t\tsetOnPojo(pojo, loafwd, ctx, propertyPath);\n\t}",
        "explanations_by_ours": [
            "the loafwd",
            "The loafwd",
            "the loafwd value"
        ],
        "corrections_by_ours": [
            "value"
        ],
        "corrections_by_baseline": [
            "wd",
            "lo1",
            "Lo1",
            "shave",
            "towrite",
            "firstbranch",
            "discOnA",
            "daft",
            "dou",
            "clash"
        ]
    },
    {
        "original_word": "Value",
        "typo_word": "Vaiud",
        "original_variable": "unscaledValue",
        "typo_variable": "unscaledVaiud",
        "original_code": "@Override\n  public BigDecimal deserializeFromByteBufferObject(ByteBuffer buffer) {\n    final int scale = buffer.getInt();\n    final byte[] unscaledValue = OBinaryTypeSerializer.INSTANCE.deserializeFromByteBufferObject(buffer);\n\n    return new BigDecimal(new BigInteger(unscaledValue), scale);\n  }",
        "modified_code": "@Override\n  public BigDecimal deserializeFromByteBufferObject(ByteBuffer buffer) {\n    final int scale = buffer.getInt();\n    final byte[] unscaledVaiud = OBinaryTypeSerializer.INSTANCE.deserializeFromByteBufferObject(buffer);\n\n    return new BigDecimal(new BigInteger(unscaledVaiud), scale);\n  }",
        "explanations_by_ours": [
            "The number of digits to be converted to a BigDecimal.",
            "The value of the scale field in bytes.",
            "The number of digits to be converted to a BigDecimal"
        ],
        "corrections_by_ours": [
            "scaleVaiud",
            "unscaledValue",
            "convertedVaiud",
            "fieldVaiud",
            "numberVaiud",
            "valueVaiud",
            "unscaledVaiud",
            "unscaledConverted",
            "unscaledField",
            "unscaledBig"
        ],
        "corrections_by_baseline": [
            "projectedPixels",
            "unscaledValue",
            "downsampledIX",
            "downsampledIY",
            "deconv2D",
            "dapex",
            "rasp_xscale",
            "dlatdx",
            "geomDs",
            "proxyscope"
        ]
    },
    {
        "original_word": "bucket",
        "typo_word": "vuckft",
        "original_variable": "bucketStart",
        "typo_variable": "vuckftStart",
        "original_code": "public List<Long> getElements(long nodeIndex) {\n        long bucketStart = nodeIndex * maxElementsPerNode * bitsPerElement;\n        List<Long> ret = new ArrayList<>();\n        if (nodesWithOrdinalZero.getElementValue(nodeIndex, 1, 1) != NO_ELEMENT) {\n            // 0 indicates an \"empty\" element, so we fetch ordinal zeros from nodesWithOrdinalZero\n            ret.add(NO_ELEMENT);\n        }\n        for (int offset = 0; offset < maxElementsPerNode; offset++) {\n            long element = storage.getElementValue(bucketStart + offset * bitsPerElement,\n                    bitsPerElement, elementMask);\n            if (element == NO_ELEMENT) {\n                break; // we have exhausted the elements at this index\n            }\n            ret.add(element);\n        }\n        return ret;\n    }",
        "modified_code": "public List<Long> getElements(long nodeIndex) {\n        long vuckftStart = nodeIndex * maxElementsPerNode * bitsPerElement;\n        List<Long> ret = new ArrayList<>();\n        if (nodesWithOrdinalZero.getElementValue(nodeIndex, 1, 1) != NO_ELEMENT) {\n            // 0 indicates an \"empty\" element, so we fetch ordinal zeros from nodesWithOrdinalZero\n            ret.add(NO_ELEMENT);\n        }\n        for (int offset = 0; offset < maxElementsPerNode; offset++) {\n            long element = storage.getElementValue(vuckftStart + offset * bitsPerElement,\n                    bitsPerElement, elementMask);\n            if (element == NO_ELEMENT) {\n                break; // we have exhausted the elements at this index\n            }\n            ret.add(element);\n        }\n        return ret;\n    }",
        "explanations_by_ours": [
            "the start of the vuckft",
            "the start index of the vuckft",
            "the start of the vuckft in the storage"
        ],
        "corrections_by_ours": [
            "vuckftStorage",
            "startStart",
            "vuckftVuckft",
            "indexStart",
            "storageStart",
            "vuckftIndex",
            "vuckftStart"
        ],
        "corrections_by_baseline": [
            "miniStart",
            "xStart",
            "start",
            "startp",
            "start1",
            "iStart",
            "startNdx",
            "startP",
            "start2",
            "startNumber"
        ]
    },
    {
        "original_word": "Anonymous",
        "typo_word": "Ankhymous",
        "original_variable": "isAnonymous",
        "typo_variable": "isAnkhymous",
        "original_code": "public Variable var(String name)\n    {\n        boolean isAnonymous = name.startsWith(\"_\");\n        int internedName = interner.internVariableName(name);\n\n        return new Variable(internedName, null, isAnonymous);\n    }",
        "modified_code": "public Variable var(String name)\n    {\n        boolean isAnkhymous = name.startsWith(\"_\");\n        int internedName = interner.internVariableName(name);\n\n        return new Variable(internedName, null, isAnkhymous);\n    }",
        "explanations_by_ours": [
            "whether the variable is an khymous",
            "true if the variable is an khymous",
            "true if the variable is an ankhymous"
        ],
        "corrections_by_ours": [
            "isKhymous",
            "khymousAnkhymous",
            "variableAnkhymous",
            "ankhymousAnkhymous",
            "isTrue",
            "isWhether",
            "trueAnkhymous",
            "whetherAnkhymous",
            "isVariable",
            "isAnkhymous"
        ],
        "corrections_by_baseline": [
            "isAnonymous",
            "isDirect",
            "isExternal",
            "isAmbiguous",
            "is",
            "isConnected",
            "isCDI",
            "isTransient",
            "isSingle",
            "isPrime"
        ]
    },
    {
        "original_word": "length",
        "typo_word": "lfjgth",
        "original_variable": "length",
        "typo_variable": "lfjgth",
        "original_code": "public static void displayClassInfo(Class clazz, StringBuffer results)\n   {\n      // Print out some codebase info for the clazz\n      ClassLoader cl = clazz.getClassLoader();\n      results.append(\"\\n\");\n      results.append(clazz.getName());\n      results.append(\"(\");\n      results.append(Integer.toHexString(clazz.hashCode()));\n      results.append(\").ClassLoader=\");\n      results.append(cl);\n      ClassLoader parent = cl;\n      while( parent != null )\n      {\n         results.append(\"\\n..\");\n         results.append(parent);\n         URL[] urls = getClassLoaderURLs(parent);\n         int length = urls != null ? urls.length : 0;\n         for(int u = 0; u < length; u ++)\n         {\n            results.append(\"\\n....\");\n            results.append(urls[u]);\n         }\n         if( parent != null )\n            parent = parent.getParent();\n      }\n      CodeSource clazzCS = clazz.getProtectionDomain().getCodeSource();\n      if( clazzCS != null )\n      {\n         results.append(\"\\n++++CodeSource: \");\n         results.append(clazzCS);\n      }\n      else\n         results.append(\"\\n++++Null CodeSource\");\n\n      results.append(\"\\nImplemented Interfaces:\");\n      Class[] ifaces = clazz.getInterfaces();\n      for(int i = 0; i < ifaces.length; i ++)\n      {\n         Class iface = ifaces[i];\n         results.append(\"\\n++\");\n         results.append(iface);\n         results.append(\"(\");\n         results.append(Integer.toHexString(iface.hashCode()));\n         results.append(\")\");\n         ClassLoader loader = ifaces[i].getClassLoader();\n         results.append(\"\\n++++ClassLoader: \");\n         results.append(loader);\n         ProtectionDomain pd = ifaces[i].getProtectionDomain();\n         CodeSource cs = pd.getCodeSource();\n         if( cs != null )\n         {\n            results.append(\"\\n++++CodeSource: \");\n            results.append(cs);\n         }\n         else\n            results.append(\"\\n++++Null CodeSource\");\n      }\n   }",
        "modified_code": "public static void displayClassInfo(Class clazz, StringBuffer results)\n   {\n      // Print out some codebase info for the clazz\n      ClassLoader cl = clazz.getClassLoader();\n      results.append(\"\\n\");\n      results.append(clazz.getName());\n      results.append(\"(\");\n      results.append(Integer.toHexString(clazz.hashCode()));\n      results.append(\").ClassLoader=\");\n      results.append(cl);\n      ClassLoader parent = cl;\n      while( parent != null )\n      {\n         results.append(\"\\n..\");\n         results.append(parent);\n         URL[] urls = getClassLoaderURLs(parent);\n         int lfjgth = urls != null ? urls.lfjgth : 0;\n         for(int u = 0; u < lfjgth; u ++)\n         {\n            results.append(\"\\n....\");\n            results.append(urls[u]);\n         }\n         if( parent != null )\n            parent = parent.getParent();\n      }\n      CodeSource clazzCS = clazz.getProtectionDomain().getCodeSource();\n      if( clazzCS != null )\n      {\n         results.append(\"\\n++++CodeSource: \");\n         results.append(clazzCS);\n      }\n      else\n         results.append(\"\\n++++Null CodeSource\");\n\n      results.append(\"\\nImplemented Interfaces:\");\n      Class[] ifaces = clazz.getInterfaces();\n      for(int i = 0; i < ifaces.lfjgth; i ++)\n      {\n         Class iface = ifaces[i];\n         results.append(\"\\n++\");\n         results.append(iface);\n         results.append(\"(\");\n         results.append(Integer.toHexString(iface.hashCode()));\n         results.append(\")\");\n         ClassLoader loader = ifaces[i].getClassLoader();\n         results.append(\"\\n++++ClassLoader: \");\n         results.append(loader);\n         ProtectionDomain pd = ifaces[i].getProtectionDomain();\n         CodeSource cs = pd.getCodeSource();\n         if( cs != null )\n         {\n            results.append(\"\\n++++CodeSource: \");\n            results.append(cs);\n         }\n         else\n            results.append(\"\\n++++Null CodeSource\");\n      }\n   }",
        "explanations_by_ours": [
            "the number of URLs to include in the result",
            "the number of URLs to include in the results",
            "the number of URL's to include in the result"
        ],
        "corrections_by_ours": [
            "results",
            "include",
            "url's",
            "number",
            "result",
            "urls"
        ],
        "corrections_by_baseline": [
            "fbd",
            "jbndg",
            "lfac",
            "fbb",
            "ldf",
            "dlondx",
            "llh",
            "fh",
            "lh",
            "hf"
        ]
    },
    {
        "original_word": "fields",
        "typo_word": "fjelcs",
        "original_variable": "fields",
        "typo_variable": "fjelcs",
        "original_code": "public Field generateJdbcTypeInfoFieldForMetadataRecord(JdbcTypeInfo jdbcTypeInfo) {\n    Map<String, Field> fields = new HashMap<>();\n    fields.put(TYPE, Field.create(jdbcTypeInfo.getJdbcType().name()));\n    fields.put(EXTRA_INFO, generateExtraInfoFieldForMetadataRecord(jdbcTypeInfo));\n    return Field.create(fields);\n  }",
        "modified_code": "public Field generateJdbcTypeInfoFieldForMetadataRecord(JdbcTypeInfo jdbcTypeInfo) {\n    Map<String, Field> fjelcs = new HashMap<>();\n    fjelcs.put(TYPE, Field.create(jdbcTypeInfo.getJdbcType().name()));\n    fjelcs.put(EXTRA_INFO, generateExtraInfoFieldForMetadataRecord(jdbcTypeInfo));\n    return Field.create(fjelcs);\n  }",
        "explanations_by_ours": [
            "a Map of Field names to",
            "the Map of Fields",
            "a Map of Fields"
        ],
        "corrections_by_ours": [
            "fields",
            "field",
            "names",
            "map"
        ],
        "corrections_by_baseline": [
            "fos",
            "gvcs",
            "bsf",
            "mcs",
            "dcs",
            "jbeg",
            "dks",
            "jspc",
            "jsc",
            "cs"
        ]
    },
    {
        "original_word": "existing",
        "typo_word": "ecistkng",
        "original_variable": "existing",
        "typo_variable": "ecistkng",
        "original_code": "public void internalAssociateWithJtaTx() {\n        isInTx = TransactionUtil.isInTx(transactionManager);\n\n        // ensure that a different XPC (with same name) is not already present in the TX\n        if (isInTx) {\n\n            // 7.6.3.1 throw EJBException if a different persistence context is already joined to the\n            // transaction (with the same puScopedName).\n            EntityManager existing = TransactionUtil.getTransactionScopedEntityManager(puScopedName, transactionSynchronizationRegistry);\n            if (existing != null && existing != this) {\n                // should be enough to test if not the same object\n                throw JpaLogger.ROOT_LOGGER.cannotUseExtendedPersistenceTransaction(puScopedName, existing, this);\n            } else if (existing == null) {\n\n                if (SynchronizationType.SYNCHRONIZED.equals(synchronizationType)) {\n                    // JPA 7.9.1 join the transaction if not already done for SynchronizationType.SYNCHRONIZED.\n                    underlyingEntityManager.joinTransaction();\n                }\n                // associate the entity manager with the current transaction\n                TransactionUtil.putEntityManagerInTransactionRegistry(puScopedName, this, transactionSynchronizationRegistry);\n            }\n        }\n    }",
        "modified_code": "public void internalAssociateWithJtaTx() {\n        isInTx = TransactionUtil.isInTx(transactionManager);\n\n        // ensure that a different XPC (with same name) is not already present in the TX\n        if (isInTx) {\n\n            // 7.6.3.1 throw EJBException if a different persistence context is already joined to the\n            // transaction (with the same puScopedName).\n            EntityManager ecistkng = TransactionUtil.getTransactionScopedEntityManager(puScopedName, transactionSynchronizationRegistry);\n            if (ecistkng != null && ecistkng != this) {\n                // should be enough to test if not the same object\n                throw JpaLogger.ROOT_LOGGER.cannotUseExtendedPersistenceTransaction(puScopedName, ecistkng, this);\n            } else if (ecistkng == null) {\n\n                if (SynchronizationType.SYNCHRONIZED.equals(synchronizationType)) {\n                    // JPA 7.9.1 join the transaction if not already done for SynchronizationType.SYNCHRONIZED.\n                    underlyingEntityManager.joinTransaction();\n                }\n                // associate the entity manager with the current transaction\n                TransactionUtil.putEntityManagerInTransactionRegistry(puScopedName, this, transactionSynchronizationRegistry);\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the entity manager to associate with the current transaction",
            "the entity manager to be associated with the current transaction.",
            "the entity manager to associate with the current transaction."
        ],
        "corrections_by_ours": [
            "entity",
            "current",
            "associated",
            "transaction",
            "associate",
            "manager"
        ],
        "corrections_by_baseline": [
            "kms",
            "ec",
            "hcs",
            "rcidpe",
            "ecint",
            "authority",
            "issuer",
            "knt",
            "eemethod",
            "icnt"
        ]
    },
    {
        "original_word": "values",
        "typo_word": "baluex",
        "original_variable": "values",
        "typo_variable": "baluex",
        "original_code": "private void processIgnorePropertiesAnnotation(IgnoreProperties properties,\n                                                   Map<Class<?>, Collection<String>> pojoAndNamesMap) {\n        IgnoreProperty[] values = properties.value();\n\n        AllowProperty[] allowProperties = properties.allow();\n\n        if (allowProperties != null) {\n            for (AllowProperty allowProperty : allowProperties) {\n                processAllowPropertyAnnotation(allowProperty, pojoAndNamesMap);\n            }\n        }\n\n        if (values != null) {\n            for (IgnoreProperty property : values) {\n                processIgnorePropertyAnnotation(property, pojoAndNamesMap);\n            }\n        }\n\n    }",
        "modified_code": "private void processIgnorePropertiesAnnotation(IgnoreProperties properties,\n                                                   Map<Class<?>, Collection<String>> pojoAndNamesMap) {\n        IgnoreProperty[] baluex = properties.value();\n\n        AllowProperty[] allowProperties = properties.allow();\n\n        if (allowProperties != null) {\n            for (AllowProperty allowProperty : allowProperties) {\n                processAllowPropertyAnnotation(allowProperty, pojoAndNamesMap);\n            }\n        }\n\n        if (baluex != null) {\n            for (IgnoreProperty property : baluex) {\n                processIgnorePropertyAnnotation(property, pojoAndNamesMap);\n            }\n        }\n\n    }",
        "explanations_by_ours": [
            "The baluex annotation.",
            "The baluex annotation",
            "The baluex annotations."
        ],
        "corrections_by_ours": [
            "annotation",
            "annotations"
        ],
        "corrections_by_baseline": [
            "bue",
            "xcent",
            "bais",
            "balony",
            "lxcent",
            "ba",
            "xh",
            "adjustedCentral",
            "bout",
            "sndx"
        ]
    },
    {
        "original_word": "comps",
        "typo_word": "vohps",
        "original_variable": "comps",
        "typo_variable": "vohps",
        "original_code": "private javax.naming.Binding mapBinding(org.omg.CosNaming.Binding bndg)\n            throws NamingException {\n        java.lang.Object obj = _ctx.callResolve(bndg.binding_name);\n\n        Name cname = org.wildfly.iiop.openjdk.naming.jndi.CNNameParser.cosNameToName(bndg.binding_name);\n\n        try {\n            obj = NamingManager.getObjectInstance(obj, cname, _ctx, _env);\n        } catch (NamingException e) {\n            throw e;\n        } catch (Exception e) {\n            NamingException ne = IIOPLogger.ROOT_LOGGER.errorGeneratingObjectViaFactory();\n            ne.setRootCause(e);\n            throw ne;\n        }\n\n        // Use cname.toString() instead of bindingName because the name\n        // in the binding should be a composite name\n        String cnameStr = cname.toString();\n        javax.naming.Binding jbndg = new javax.naming.Binding(cnameStr, obj);\n\n        NameComponent[] comps = _ctx.makeFullName(bndg.binding_name);\n        String fullName = org.wildfly.iiop.openjdk.naming.jndi.CNNameParser.cosNameToInsString(comps);\n        jbndg.setNameInNamespace(fullName);\n        return jbndg;\n    }",
        "modified_code": "private javax.naming.Binding mapBinding(org.omg.CosNaming.Binding bndg)\n            throws NamingException {\n        java.lang.Object obj = _ctx.callResolve(bndg.binding_name);\n\n        Name cname = org.wildfly.iiop.openjdk.naming.jndi.CNNameParser.cosNameToName(bndg.binding_name);\n\n        try {\n            obj = NamingManager.getObjectInstance(obj, cname, _ctx, _env);\n        } catch (NamingException e) {\n            throw e;\n        } catch (Exception e) {\n            NamingException ne = IIOPLogger.ROOT_LOGGER.errorGeneratingObjectViaFactory();\n            ne.setRootCause(e);\n            throw ne;\n        }\n\n        // Use cname.toString() instead of bindingName because the name\n        // in the binding should be a composite name\n        String cnameStr = cname.toString();\n        javax.naming.Binding jbndg = new javax.naming.Binding(cnameStr, obj);\n\n        NameComponent[] vohps = _ctx.makeFullName(bndg.binding_name);\n        String fullName = org.wildfly.iiop.openjdk.naming.jndi.CNNameParser.cosNameToInsString(vohps);\n        jbndg.setNameInNamespace(fullName);\n        return jbndg;\n    }",
        "explanations_by_ours": [
            "the org.wildfly.iiop.naming",
            "the array of org.wildfly.iiop.",
            "the org.wildfly.iiop.openj"
        ],
        "corrections_by_ours": [
            "iiophps",
            "voopenj",
            "orghps",
            "naminghps",
            "wildhps",
            "arrayhps",
            "flyhps",
            "openjhps",
            "voorg",
            "vonaming"
        ],
        "corrections_by_baseline": [
            "vms",
            "otps",
            "ipos",
            "ps",
            "vip",
            "vcs",
            "dapv",
            "pv",
            "PV",
            "drs"
        ]
    },
    {
        "original_word": "contents",
        "typo_word": "fontebts",
        "original_variable": "contents",
        "typo_variable": "fontebts",
        "original_code": "void validate(String urlString) {\n      if (urlString == null) return;\n      URI uri;\n      try {\n        uri = new URI(urlString);\n      }\n      catch (URISyntaxException e) {\n        javax.swing.JOptionPane.showMessageDialog(null, \"URISyntaxException on URL (\" +\n            urlString + \") \" + e.getMessage() + \"\\n\");\n        return;\n      }\n      String contents = getText();\n      //boolean isCatalog = contents.indexOf(\"queryCapability\") < 0;\n\n      ByteArrayInputStream is = new ByteArrayInputStream(contents.getBytes(CDM.utf8Charset));\n\n      try {\n        CatalogBuilder catFactory = new CatalogBuilder();\n        Catalog cat = catFactory.buildFromLocation(urlString, null);\n        boolean isValid = !catFactory.hasFatalError();\n\n       javax.swing.JOptionPane.showMessageDialog(this,\n          \"Catalog Validation = \" + isValid + \"\\n\" +  catFactory.getErrorMessage());\n\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n\n\n    }",
        "modified_code": "void validate(String urlString) {\n      if (urlString == null) return;\n      URI uri;\n      try {\n        uri = new URI(urlString);\n      }\n      catch (URISyntaxException e) {\n        javax.swing.JOptionPane.showMessageDialog(null, \"URISyntaxException on URL (\" +\n            urlString + \") \" + e.getMessage() + \"\\n\");\n        return;\n      }\n      String fontebts = getText();\n      //boolean isCatalog = contents.indexOf(\"queryCapability\") < 0;\n\n      ByteArrayInputStream is = new ByteArrayInputStream(fontebts.getBytes(CDM.utf8Charset));\n\n      try {\n        CatalogBuilder catFactory = new CatalogBuilder();\n        Catalog cat = catFactory.buildFromLocation(urlString, null);\n        boolean isValid = !catFactory.hasFatalError();\n\n       javax.swing.JOptionPane.showMessageDialog(this,\n          \"Catalog Validation = \" + isValid + \"\\n\" +  catFactory.getErrorMessage());\n\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n\n\n    }",
        "explanations_by_ours": [
            "the catalog to validate",
            "the catalog to be validated",
            "the catalog to validate."
        ],
        "corrections_by_ours": [
            "validate",
            "catalog",
            "validated"
        ],
        "corrections_by_baseline": [
            "bts",
            "ifcs",
            "alts",
            "ts",
            "fos",
            "tts",
            "bsf",
            "acf",
            "icf",
            "gts"
        ]
    },
    {
        "original_word": "Subscribe",
        "typo_word": "Subscrubr",
        "original_variable": "onSubscribe",
        "typo_variable": "onSubscrubr",
        "original_code": "public static <T> ConnectableFlowable<T> create(Flowable<T> source, final int bufferSize) {\n        // the current connection to source needs to be shared between the operator and its onSubscribe call\n        final AtomicReference<PublishSubscriber<T>> curr = new AtomicReference<PublishSubscriber<T>>();\n        Publisher<T> onSubscribe = new FlowablePublisher<T>(curr, bufferSize);\n        return RxJavaPlugins.onAssembly(new FlowablePublish<T>(onSubscribe, source, curr, bufferSize));\n    }",
        "modified_code": "public static <T> ConnectableFlowable<T> create(Flowable<T> source, final int bufferSize) {\n        // the current connection to source needs to be shared between the operator and its onSubscribe call\n        final AtomicReference<PublishSubscriber<T>> curr = new AtomicReference<PublishSubscriber<T>>();\n        Publisher<T> onSubscrubr = new FlowablePublisher<T>(curr, bufferSize);\n        return RxJavaPlugins.onAssembly(new FlowablePublish<T>(onSubscrubr, source, curr, bufferSize));\n    }",
        "explanations_by_ours": [
            "the Publisher that will emit the given Publisher",
            "the Publisher that will be emitted by the Publisher",
            "the Publisher that will be emitted by the Flowable"
        ],
        "corrections_by_ours": [
            "onPublisher",
            "givenSubscrubr",
            "flowableSubscrubr",
            "emitSubscrubr",
            "emittedSubscrubr",
            "publisherSubscrubr",
            "onFlowable",
            "onEmit",
            "onEmitted",
            "onGiven"
        ],
        "corrections_by_baseline": [
            "subst",
            "itr",
            "subs",
            "subEquivalent",
            "sublist",
            "exsub",
            "subInfo",
            "sub",
            "descr",
            "prelen"
        ]
    },
    {
        "original_word": "parser",
        "typo_word": "pagwer",
        "original_variable": "parser",
        "typo_variable": "pagwer",
        "original_code": "private List<Variable> searchAliasedDimension( NetcdfDataset ds, Dimension dim) {\r\n    String dimName = dim.getShortName();\r\n    String alias = ds.findAttValueIgnoreCase(null, dimName, null);\r\n    if (alias == null)\r\n      return null;\r\n\r\n    List<Variable> vars = new ArrayList<>();\r\n    StringTokenizer parser = new StringTokenizer(alias, \" ,\");\r\n    while (parser.hasMoreTokens()) {\r\n      String token = parser.nextToken();\r\n      Variable ncvar = ds.findVariable( token);\r\n      if (ncvar == null)\r\n        continue;\r\n      if (ncvar.getRank() != 1)\r\n        continue;\r\n      Iterator dimIter = ncvar.getDimensions().iterator();\r\n      Dimension dim2 = (Dimension) dimIter.next();\r\n      if (dimName.equals(dim2.getShortName())) {\r\n        vars.add(ncvar);\r\n        if (debug) System.out.print(\" \"+token);\r\n      }\r\n    }\r\n    if (debug) System.out.println();\r\n\r\n    return vars;\r\n  }",
        "modified_code": "private List<Variable> searchAliasedDimension( NetcdfDataset ds, Dimension dim) {\r\n    String dimName = dim.getShortName();\r\n    String alias = ds.findAttValueIgnoreCase(null, dimName, null);\r\n    if (alias == null)\r\n      return null;\r\n\r\n    List<Variable> vars = new ArrayList<>();\r\n    StringTokenizer pagwer = new StringTokenizer(alias, \" ,\");\r\n    while (pagwer.hasMoreTokens()) {\r\n      String token = pagwer.nextToken();\r\n      Variable ncvar = ds.findVariable( token);\r\n      if (ncvar == null)\r\n        continue;\r\n      if (ncvar.getRank() != 1)\r\n        continue;\r\n      Iterator dimIter = ncvar.getDimensions().iterator();\r\n      Dimension dim2 = (Dimension) dimIter.next();\r\n      if (dimName.equals(dim2.getShortName())) {\r\n        vars.add(ncvar);\r\n        if (debug) System.out.print(\" \"+token);\r\n      }\r\n    }\r\n    if (debug) System.out.println();\r\n\r\n    return vars;\r\n  }",
        "explanations_by_ours": [
            "The comma separated list of variable names.",
            "A comma separated list of variable names.",
            "The comma-separated list of variable names."
        ],
        "corrections_by_ours": [
            "separated",
            "names",
            "variable",
            "-",
            "list",
            "comma"
        ],
        "corrections_by_baseline": [
            "pagination",
            "pageroot",
            "pagedList",
            "lpage",
            "pageData",
            "page",
            "ppage",
            "parsedPage",
            "pageSql",
            "pagedPointer"
        ]
    },
    {
        "original_word": "enum",
        "typo_word": "ebim",
        "original_variable": "enumPropSource",
        "typo_variable": "ebimPropSource",
        "original_code": "public static List<SimpleServiceUser> loadUsers(PropertySource<?> propertySource, String authPropertiesPrefix) {\n    if (propertySource instanceof EnumerablePropertySource) {\n      final EnumerablePropertySource<?> enumPropSource = (EnumerablePropertySource) propertySource;\n      final String[] propertyNames = enumPropSource.getPropertyNames();\n\n      final PropertyEntrySink sink = new PropertyEntrySink(authPropertiesPrefix);\n\n      for (final String propertyName : propertyNames) {\n        final Object value = propertySource.getProperty(propertyName);\n        if (value instanceof String) {\n          sink.putEntry(propertyName, value.toString());\n        }\n      }\n\n      return sink.getUserList();\n    }\n\n    LoggerFactory.getLogger(SimpleAuthenticatorUtil.class)\n        .warn(\"propertySource={} is not of type EnumerablePropertySource\", propertySource);\n\n    return Collections.emptyList();\n  }",
        "modified_code": "public static List<SimpleServiceUser> loadUsers(PropertySource<?> propertySource, String authPropertiesPrefix) {\n    if (propertySource instanceof EnumerablePropertySource) {\n      final EnumerablePropertySource<?> ebimPropSource = (EnumerablePropertySource) propertySource;\n      final String[] propertyNames = ebimPropSource.getPropertyNames();\n\n      final PropertyEntrySink sink = new PropertyEntrySink(authPropertiesPrefix);\n\n      for (final String propertyName : propertyNames) {\n        final Object value = propertySource.getProperty(propertyName);\n        if (value instanceof String) {\n          sink.putEntry(propertyName, value.toString());\n        }\n      }\n\n      return sink.getUserList();\n    }\n\n    LoggerFactory.getLogger(SimpleAuthenticatorUtil.class)\n        .warn(\"propertySource={} is not of type EnumerablePropertySource\", propertySource);\n\n    return Collections.emptyList();\n  }",
        "explanations_by_ours": [
            "the property source",
            "the ebim property source",
            "the property source to load the users from"
        ],
        "corrections_by_ours": [
            "ebimPropertySource",
            "ebimPropProperty",
            "ebimSourceSource",
            "ebimPropUsers",
            "ebimPropLoad",
            "propertyPropSource",
            "usersPropSource",
            "sourcePropSource",
            "loadPropSource",
            "ebimUsersSource"
        ],
        "corrections_by_baseline": [
            "enumPropSource",
            "orbProp",
            "srcatomtype",
            "fprop",
            "protoPointFeat",
            "geometryTypeAttr",
            "grib1Info",
            "sourceBi",
            "geomDs",
            "dattim"
        ]
    },
    {
        "original_word": "props",
        "typo_word": "pgpps",
        "original_variable": "props",
        "typo_variable": "pgpps",
        "original_code": "public static Properties getThorntailProperties(URLClassLoader compileClassLoader) {\n        URL ymlResource = compileClassLoader.findResource(\"project-defaults.yml\");\n\n        Properties props = YamlUtil.getPropertiesFromYamlResource(ymlResource);\n        return props;\n    }",
        "modified_code": "public static Properties getThorntailProperties(URLClassLoader compileClassLoader) {\n        URL ymlResource = compileClassLoader.findResource(\"project-defaults.yml\");\n\n        Properties pgpps = YamlUtil.getPropertiesFromYamlResource(ymlResource);\n        return pgpps;\n    }",
        "explanations_by_ours": [
            "the Thorntail properties",
            "the Thorntail properties to return",
            "the Thorntail properties to use"
        ],
        "corrections_by_ours": [
            "properties",
            "return",
            "use",
            "thorntail"
        ],
        "corrections_by_baseline": [
            "pps",
            "xpp",
            "pdh",
            "gp",
            "pp",
            "PP",
            "pdx",
            "pib",
            "pjpn",
            "pdss"
        ]
    },
    {
        "original_word": "buff",
        "typo_word": "bitf",
        "original_variable": "sbuff",
        "typo_variable": "sbitf",
        "original_code": "public String getDetailInfo() {\n    StringBuffer sbuff = new StringBuffer();\n    sbuff.append(\"PointObsDataset\\n\");\n    sbuff.append(\"  adapter   = \").append(getClass().getName()).append(\"\\n\");\n    sbuff.append(\"  timeUnit  = \").append(getTimeUnits()).append(\"\\n\");\n    sbuff.append(\"  dataClass = \").append(getDataClass()).append(\"\\n\");\n    sbuff.append(\"  dataCount = \").append(getDataCount()).append(\"\\n\");\n    sbuff.append(super.getDetailInfo());\n\n    return sbuff.toString();\n  }",
        "modified_code": "public String getDetailInfo() {\n    StringBuffer sbitf = new StringBuffer();\n    sbitf.append(\"PointObsDataset\\n\");\n    sbitf.append(\"  adapter   = \").append(getClass().getName()).append(\"\\n\");\n    sbitf.append(\"  timeUnit  = \").append(getTimeUnits()).append(\"\\n\");\n    sbitf.append(\"  dataClass = \").append(getDataClass()).append(\"\\n\");\n    sbitf.append(\"  dataCount = \").append(getDataCount()).append(\"\\n\");\n    sbitf.append(super.getDetailInfo());\n\n    return sbitf.toString();\n  }",
        "explanations_by_ours": [
            "StringBuffer",
            "StringBuffer to append the detail info to.",
            "StringBuffer to add the detail info to."
        ],
        "corrections_by_ours": [
            "string",
            "info",
            "buffer",
            "add",
            "append",
            "detail"
        ],
        "corrections_by_baseline": [
            "jbit",
            "bits",
            "allbits",
            "lowbits",
            "bit",
            "nbitsd",
            "nbits",
            "highbits",
            "num_sbr_bits2",
            "myBits"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rsdult",
        "original_variable": "result",
        "typo_variable": "rsdult",
        "original_code": "public List<GrantedAuthority> getGrantedAuthorities(Collection<String> attributes) {\n\t\tList<GrantedAuthority> result = new ArrayList<>(attributes.size());\n\t\tfor (String attribute : attributes) {\n\t\t\tresult.add(getGrantedAuthority(attribute));\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public List<GrantedAuthority> getGrantedAuthorities(Collection<String> attributes) {\n\t\tList<GrantedAuthority> rsdult = new ArrayList<>(attributes.size());\n\t\tfor (String attribute : attributes) {\n\t\t\trsdult.add(getGrantedAuthority(attribute));\n\t\t}\n\t\treturn rsdult;\n\t}",
        "explanations_by_ours": [
            "The list of granted authorities.",
            "The list of all granted authorities.",
            "The list of authorities to return."
        ],
        "corrections_by_ours": [
            "return",
            "list",
            "granted",
            "authorities"
        ],
        "corrections_by_baseline": [
            "rsf",
            "rs",
            "isr",
            "rsm",
            "rdr",
            "rds",
            "rp",
            "rtnArr",
            "rdata",
            "rj"
        ]
    },
    {
        "original_word": "attached",
        "typo_word": "attacjex",
        "original_variable": "attached",
        "typo_variable": "attacjex",
        "original_code": "public boolean attachSbbEntity(SbbEntityID sbbEntityId) {\n\n\t\tboolean attached = cacheData.attachSbbEntity(sbbEntityId);\n\t\tif (attached) {\n\t\t\tif (acReferencesHandler != null) {\n\t\t\t\tacReferencesHandler.sbbeReferenceCreated(false);\n\t\t\t}\n\t\t}\n\t\tif (logger.isTraceEnabled()) {\n\t\t\tlogger.trace(\"Attachement from sbb entity \" + sbbEntityId\n\t\t\t\t\t+ \" to AC \" + getActivityContextHandle() + \" result: \"\n\t\t\t\t\t+ attached);\n\t\t}\n\t\treturn attached;\n\t}",
        "modified_code": "public boolean attachSbbEntity(SbbEntityID sbbEntityId) {\n\n\t\tboolean attacjex = cacheData.attachSbbEntity(sbbEntityId);\n\t\tif (attacjex) {\n\t\t\tif (acReferencesHandler != null) {\n\t\t\t\tacReferencesHandler.sbbeReferenceCreated(false);\n\t\t\t}\n\t\t}\n\t\tif (logger.isTraceEnabled()) {\n\t\t\tlogger.trace(\"Attachement from sbb entity \" + sbbEntityId\n\t\t\t\t\t+ \" to AC \" + getActivityContextHandle() + \" result: \"\n\t\t\t\t\t+ attacjex);\n\t\t}\n\t\treturn attacjex;\n\t}",
        "explanations_by_ours": [
            "true if the sbb entity is to be attached to the AC.",
            "true if the sbb entity should be attached to the AC.",
            "true if the sbb entity should be attached to the AC"
        ],
        "corrections_by_ours": [
            "attached",
            "ac",
            "true",
            "entity",
            "sbb"
        ],
        "corrections_by_baseline": [
            "ac",
            "acf",
            "ifac",
            "accel",
            "sleeAci",
            "sda",
            "SDA",
            "assistant",
            "cis",
            "att"
        ]
    },
    {
        "original_word": "principal",
        "typo_word": "princolal",
        "original_variable": "principal",
        "typo_variable": "princolal",
        "original_code": "public String authenticate(final String username, final String password) {\n    String principal = null;\n\n    try {\n      OServerUserConfiguration user = getUser(username);\n\n      if (isPasswordValid(user)) {\n        if (OSecurityManager.instance().checkPassword(password, user.password)) {\n          principal = user.name;\n        }\n      }\n    } catch (Exception ex) {\n      OLogManager.instance().error(this, \"ODefaultPasswordAuthenticator.authenticate()\", ex);\n    }\n\n    return principal;\n  }",
        "modified_code": "public String authenticate(final String username, final String password) {\n    String princolal = null;\n\n    try {\n      OServerUserConfiguration user = getUser(username);\n\n      if (isPasswordValid(user)) {\n        if (OSecurityManager.instance().checkPassword(password, user.password)) {\n          princolal = user.name;\n        }\n      }\n    } catch (Exception ex) {\n      OLogManager.instance().error(this, \"ODefaultPasswordAuthenticator.authenticate()\", ex);\n    }\n\n    return princolal;\n  }",
        "explanations_by_ours": [
            "the princolal",
            "the princolal name",
            "the princolal user name"
        ],
        "corrections_by_ours": [
            "name",
            "user"
        ],
        "corrections_by_baseline": [
            "principal",
            "principals",
            "principalName",
            "principalExtractor",
            "principalNode",
            "goalid",
            "jinc",
            "al",
            "prf",
            "plural"
        ]
    },
    {
        "original_word": "remote",
        "typo_word": "grmote",
        "original_variable": "remoteLogger",
        "typo_variable": "grmoteLogger",
        "original_code": "public void run() {\n    logger.info(this + \": connected\");\n    HardenedObjectInputStream ois = null;\n    try {\n      ois = createObjectInputStream();\n      while (true) {\n        // read an event from the wire\n        ILoggingEvent event = (ILoggingEvent) ois.readObject();\n        // get a logger from the hierarchy. The name of the logger is taken to\n        // be the name contained in the event.\n        Logger remoteLogger = lc.getLogger(event.getLoggerName());\n        // apply the logger-level filter\n        if (remoteLogger.isEnabledFor(event.getLevel())) {\n          // finally log the event as if was generated locally\n          remoteLogger.callAppenders(event);\n        }\n      }\n    }\n    catch (EOFException ex) {\n      // this is normal and expected\n      assert true;\n    }\n    catch (IOException ex) {\n      logger.info(this + \": \" + ex);\n    }\n    catch (ClassNotFoundException ex) {\n      logger.error(this + \": unknown event class\");\n    }\n    catch (RuntimeException ex) {\n      logger.error(this + \": \" + ex);\n    }\n    finally {\n      if (ois != null) {\n        CloseUtil.closeQuietly(ois);\n      }\n      close();\n      logger.info(this + \": connection closed\");\n    }\n  }",
        "modified_code": "public void run() {\n    logger.info(this + \": connected\");\n    HardenedObjectInputStream ois = null;\n    try {\n      ois = createObjectInputStream();\n      while (true) {\n        // read an event from the wire\n        ILoggingEvent event = (ILoggingEvent) ois.readObject();\n        // get a logger from the hierarchy. The name of the logger is taken to\n        // be the name contained in the event.\n        Logger grmoteLogger = lc.getLogger(event.getLoggerName());\n        // apply the logger-level filter\n        if (grmoteLogger.isEnabledFor(event.getLevel())) {\n          // finally log the event as if was generated locally\n          grmoteLogger.callAppenders(event);\n        }\n      }\n    }\n    catch (EOFException ex) {\n      // this is normal and expected\n      assert true;\n    }\n    catch (IOException ex) {\n      logger.info(this + \": \" + ex);\n    }\n    catch (ClassNotFoundException ex) {\n      logger.error(this + \": unknown event class\");\n    }\n    catch (RuntimeException ex) {\n      logger.error(this + \": \" + ex);\n    }\n    finally {\n      if (ois != null) {\n        CloseUtil.closeQuietly(ois);\n      }\n      close();\n      logger.info(this + \": connection closed\");\n    }\n  }",
        "explanations_by_ours": [
            "the logger to use.",
            "the logger to use",
            "the logger to be used."
        ],
        "corrections_by_ours": [
            "loggermoteLogger",
            "grloggerLogger",
            "gruseLogger",
            "grmoteUse",
            "grmoteUsed",
            "usemoteLogger",
            "usedmoteLogger",
            "grusedLogger",
            "grmoteLogger"
        ],
        "corrections_by_baseline": [
            "loggerProvider",
            "logger",
            "remoteLogger",
            "childLogger",
            "loggerContext",
            "loggerFactory",
            "logPersisterDelegate",
            "txMgr",
            "addLogger",
            "sgrm"
        ]
    },
    {
        "original_word": "deadline",
        "typo_word": "deadkins",
        "original_variable": "deadlineNs",
        "typo_variable": "deadkinsNs",
        "original_code": "public static AsyncConnect asyncConnect(final Context ctx)\n    {\n        Subscription subscription = null;\n        try\n        {\n            ctx.conclude();\n\n            final long deadlineNs = ctx.aeron().context().nanoClock().nanoTime() + ctx.messageTimeoutNs();\n            subscription = ctx.aeron().addSubscription(ctx.egressChannel(), ctx.egressStreamId());\n\n            return new AsyncConnect(ctx, subscription, deadlineNs);\n        }\n        catch (final Exception ex)\n        {\n            if (!ctx.ownsAeronClient())\n            {\n                CloseHelper.quietClose(subscription);\n            }\n\n            ctx.close();\n\n            throw ex;\n        }\n    }",
        "modified_code": "public static AsyncConnect asyncConnect(final Context ctx)\n    {\n        Subscription subscription = null;\n        try\n        {\n            ctx.conclude();\n\n            final long deadkinsNs = ctx.aeron().context().nanoClock().nanoTime() + ctx.messageTimeoutNs();\n            subscription = ctx.aeron().addSubscription(ctx.egressChannel(), ctx.egressStreamId());\n\n            return new AsyncConnect(ctx, subscription, deadkinsNs);\n        }\n        catch (final Exception ex)\n        {\n            if (!ctx.ownsAeronClient())\n            {\n                CloseHelper.quietClose(subscription);\n            }\n\n            ctx.close();\n\n            throw ex;\n        }\n    }",
        "explanations_by_ours": [
            "the timeout in nanoseconds",
            "the deadline in nanoseconds",
            "the deadkinsNs"
        ],
        "corrections_by_ours": [
            "deadlineNs",
            "nsNs",
            "deadkinsDeadkins",
            "nanosecondsNs",
            "deadkinsNanoseconds",
            "deadkinsDeadline",
            "timeoutNs",
            "deadkinsTimeout",
            "deadkinsNs"
        ],
        "corrections_by_baseline": [
            "isSlee11",
            "nbusy",
            "idle",
            "ghc",
            "sdc",
            "numStations",
            "permanent",
            "dys",
            "deadlineNs",
            "nonCycles"
        ]
    },
    {
        "original_word": "inverse",
        "typo_word": "invedce",
        "original_variable": "inverse",
        "typo_variable": "invedce",
        "original_code": "public InvertibleMatrix inverse () throws MatrixException\n  {\n    final InvertibleMatrix inverse = new InvertibleMatrix (m_nRows);\n    final IdentityMatrix identity = new IdentityMatrix (m_nRows);\n\n    // Compute each column of the inverse matrix\n    // using columns of the identity matrix.\n    for (int c = 0; c < m_nCols; ++c)\n    {\n      final ColumnVector col = solve (identity.getColumn (c), true);\n      inverse.setColumn (col, c);\n    }\n\n    return inverse;\n  }",
        "modified_code": "public InvertibleMatrix invedce () throws MatrixException\n  {\n    final InvertibleMatrix invedce = new InvertibleMatrix (m_nRows);\n    final IdentityMatrix identity = new IdentityMatrix (m_nRows);\n\n    // Compute each column of the inverse matrix\n    // using columns of the identity matrix.\n    for (int c = 0; c < m_nCols; ++c)\n    {\n      final ColumnVector col = solve (identity.getColumn (c), true);\n      invedce.setColumn (col, c);\n    }\n\n    return invedce;\n  }",
        "explanations_by_ours": [
            "The inverted matrix.",
            "The inverted matrix.",
            "An inverted matrix."
        ],
        "corrections_by_ours": [
            "inverted",
            "matrix"
        ],
        "corrections_by_baseline": [
            "ce",
            "ecef",
            "ecint",
            "cis",
            "cext",
            "pce",
            "vse",
            "trovit",
            "iresult",
            "calt"
        ]
    },
    {
        "original_word": "Length",
        "typo_word": "Lwngyh",
        "original_variable": "readLength",
        "typo_variable": "readLwngyh",
        "original_code": "ByteBuffer read() throws IOException {\n        SSLEngineResult result;\n\n        if (!initialHSComplete) {\n            throw new IllegalStateException();\n        }\n\n        int pos = requestBB.position();\n\n        if (sc.read(inNetBB) == -1) {\n            sslEngine.closeInbound();  // probably throws exception\n            throw new EOFException();\n        }\n\n        do {\n            resizeRequestBB(inNetBB.remaining());    // guarantees enough room for unwrap\n            inNetBB.flip();\n            result = sslEngine.unwrap(inNetBB, requestBB);\n            inNetBB.compact();\n\n\t    /*\n         * Could check here for a renegotation, but we're only\n\t     * doing a simple read/write, and won't have enough state\n\t     * transitions to do a complete handshake, so ignore that\n\t     * possibility.\n\t     */\n            switch (result.getStatus()) {\n\n                case BUFFER_UNDERFLOW:\n                case OK:\n                    if (result.getHandshakeStatus() == HandshakeStatus.NEED_TASK) {\n                        doTasks();\n                    }\n                    break;\n\n                default:\n                    throw new IOException(\"sslEngine error during data read: \" +\n                            result.getStatus());\n            }\n        } while ((inNetBB.position() != 0) &&\n                result.getStatus() != Status.BUFFER_UNDERFLOW);\n        int readLength = requestBB.position() - pos;\n        ByteBuffer byteBuffer = ByteBuffer.allocate(readLength);\n        byteBuffer.put(BytesUtil.subBytes(requestBB.array(), pos, readLength));\n        return byteBuffer;\n    }",
        "modified_code": "ByteBuffer read() throws IOException {\n        SSLEngineResult result;\n\n        if (!initialHSComplete) {\n            throw new IllegalStateException();\n        }\n\n        int pos = requestBB.position();\n\n        if (sc.read(inNetBB) == -1) {\n            sslEngine.closeInbound();  // probably throws exception\n            throw new EOFException();\n        }\n\n        do {\n            resizeRequestBB(inNetBB.remaining());    // guarantees enough room for unwrap\n            inNetBB.flip();\n            result = sslEngine.unwrap(inNetBB, requestBB);\n            inNetBB.compact();\n\n\t    /*\n         * Could check here for a renegotation, but we're only\n\t     * doing a simple read/write, and won't have enough state\n\t     * transitions to do a complete handshake, so ignore that\n\t     * possibility.\n\t     */\n            switch (result.getStatus()) {\n\n                case BUFFER_UNDERFLOW:\n                case OK:\n                    if (result.getHandshakeStatus() == HandshakeStatus.NEED_TASK) {\n                        doTasks();\n                    }\n                    break;\n\n                default:\n                    throw new IOException(\"sslEngine error during data read: \" +\n                            result.getStatus());\n            }\n        } while ((inNetBB.position() != 0) &&\n                result.getStatus() != Status.BUFFER_UNDERFLOW);\n        int readLwngyh = requestBB.position() - pos;\n        ByteBuffer byteBuffer = ByteBuffer.allocate(readLwngyh);\n        byteBuffer.put(BytesUtil.subBytes(requestBB.array(), pos, readLwngyh));\n        return byteBuffer;\n    }",
        "explanations_by_ours": [
            "the number of bytes to read.",
            "the number of bytes to read from the network.",
            "the number of bytes to read from the network"
        ],
        "corrections_by_ours": [
            "networkLwngyh",
            "bytesLwngyh",
            "numberLwngyh",
            "readBytes",
            "readNetwork",
            "readNumber",
            "readRead",
            "readLwngyh"
        ],
        "corrections_by_baseline": [
            "nread",
            "readLen",
            "readB",
            "bitsread",
            "nToRead",
            "zzEndReadL",
            "readSize",
            "readBytes",
            "numToRead",
            "bytesToRead"
        ]
    },
    {
        "original_word": "last",
        "typo_word": "laer",
        "original_variable": "lastException",
        "typo_variable": "laerException",
        "original_code": "protected void rollbackAllResources(final boolean wasForced) {\n\t\tstatus = STATUS_ROLLING_BACK;\n\t\tException lastException = null;\n\t\tIterator<JtxResource> it = resources.iterator();\n\t\twhile (it.hasNext()) {\n\t\t\tJtxResource resource = it.next();\n\t\t\ttry {\n\t\t\t\tresource.rollbackTransaction();\n\t\t\t} catch (Exception ex) {\n\t\t\t\tlastException = ex;\n\t\t\t} finally {\n\t\t\t\tit.remove();\n\t\t\t}\n\t\t}\n\t\ttxManager.removeTransaction(this);\n\t\tstatus = STATUS_ROLLEDBACK;\n\t\tif (lastException != null) {\n\t\t\tstatus = STATUS_UNKNOWN;\n\t\t\tthrow new JtxException(\"Rollback failed: one or more TX resources couldn't rollback a TX\", lastException);\n\t\t}\n\t\tif (wasForced) {\n\t\t\tthrow new JtxException(\"TX rolled back because it has been marked as rollback-only\", rollbackCause);\n\t\t}\n\t}",
        "modified_code": "protected void rollbackAllResources(final boolean wasForced) {\n\t\tstatus = STATUS_ROLLING_BACK;\n\t\tException laerException = null;\n\t\tIterator<JtxResource> it = resources.iterator();\n\t\twhile (it.hasNext()) {\n\t\t\tJtxResource resource = it.next();\n\t\t\ttry {\n\t\t\t\tresource.rollbackTransaction();\n\t\t\t} catch (Exception ex) {\n\t\t\t\tlaerException = ex;\n\t\t\t} finally {\n\t\t\t\tit.remove();\n\t\t\t}\n\t\t}\n\t\ttxManager.removeTransaction(this);\n\t\tstatus = STATUS_ROLLEDBACK;\n\t\tif (laerException != null) {\n\t\t\tstatus = STATUS_UNKNOWN;\n\t\t\tthrow new JtxException(\"Rollback failed: one or more TX resources couldn't rollback a TX\", laerException);\n\t\t}\n\t\tif (wasForced) {\n\t\t\tthrow new JtxException(\"TX rolled back because it has been marked as rollback-only\", rollbackCause);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the exception thrown if one or more resources couldn't rollback a transaction.",
            "the exception thrown if one or more resources could not be rolled back.",
            "the exception thrown if one or more resources couldn't rollback a TX."
        ],
        "corrections_by_ours": [
            "laerTransaction",
            "rolledException",
            "backException",
            "oneException",
            "rollbackException",
            "resourcesException",
            "exceptionException",
            "laerBack",
            "laerThrown",
            "laerOne"
        ],
        "corrections_by_baseline": [
            "viburException",
            "exception",
            "ioException",
            "realException",
            "criticalException",
            "caughtException",
            "sqlException",
            "mexceptions",
            "throwException",
            "usefulException"
        ]
    },
    {
        "original_word": "Single",
        "typo_word": "Sjbgle",
        "original_variable": "isSingle",
        "typo_variable": "isSjbgle",
        "original_code": "public void printXML(PrintWriter pw, String pad, boolean constrained) {\n\n        // BEWARE! Since printDecl()is (multiple) overloaded in BaseType\n        // and all of the different signatures of printDecl() in BaseType\n        // lead to one signature, we must be careful to override that\n        // SAME signature here. That way all calls to printDecl() for\n        // this object lead to this implementation.\n\n\n        boolean isSingle = false;\n        boolean isStructure = false;\n        boolean isGrid = false;\n        boolean psemi = true;\n\n        //os.println(\"The gird contains \"+projectedComponents(true)+\" projected components\");\n\n        if (constrained && projectedComponents(true) == 0)\n            return;\n\n        // If we are printing the declaration of a constrained Grid then check for\n        // the case where the projection removes all but one component; the\n        // resulting object is a simple array.\n\n        if (constrained && projectedComponents(true) == 1) {\n            //os.println(\"It's a single Array.\");\n            isSingle = true;\n        }\n        // If there are M (< N) componets (Array and Maps combined) in a N\n        // component Grid, send the M components as elements of a Struture.\n        // This will preserve the grouping without violating the rules for a\n        // Grid.\n        else if (constrained && !projectionYieldsGrid(true)) {\n            //os.println(\"It's a Structure.\");\n            isStructure = true;\n        } else {\n            // The number of elements in the (projected) Grid must be such that\n            // we have a valid Grid object; send it as such.\n            //os.println(\"It's a Grid.\");\n            isGrid = true;\n        }\n\n        if (isGrid) {\n            pw.print(pad + \"<Grid \");\n            if (getEncodedName() != null) {\n                pw.print(\" name=\\\"\" +\n                        DDSXMLParser.normalizeToXML(getEncodedName()) + \"\\\"\");\n            }\n            pw.println(\">\");\n        }\n\n        if (isStructure) {\n\n            pw.print(pad + \"<Structure\");\n            if (getEncodedName() != null) {\n                pw.print(\" name=\\\"\" +\n                        DDSXMLParser.normalizeToXML(getEncodedName()) + \"\\\"\");\n            }\n            pw.println(\">\");\n\n        }\n\n        Enumeration e = getAttributeNames();\n\n        while (e.hasMoreElements()) {\n            String aName = (String) e.nextElement();\n            Attribute a = getAttribute(aName);\n            if(a!=null)\n                a.printXML(pw, pad + \"\\t\", constrained);\n        }\n\n        ((SDArray) arrayVar).printXML(pw, pad + (isSingle ? \"\" : \"\\t\"), constrained);\n\n        if (isGrid) {\n\n            e = mapVars.elements();\n            while (e.hasMoreElements()) {\n                SDArray map = (SDArray) e.nextElement();\n                //Coverity[DEADCODE]\n                map.printAsMapXML(pw, pad + (isSingle ? \"\" : \"\\t\"), constrained);\n            }\n\n        } else {\n\n            e = mapVars.elements();\n            while (e.hasMoreElements()) {\n                SDArray sda = (SDArray) e.nextElement();\n                sda.printXML(pw, pad + (isSingle ? \"\" : \"\\t\"), constrained);\n            }\n\n        }\n\n\n        if (isStructure) {\n            pw.println(pad + \"</Structure>\");\n        } else if (isGrid) {\n            pw.println(pad + \"</Grid>\");\n        }\n\n        return;\n    }",
        "modified_code": "public void printXML(PrintWriter pw, String pad, boolean constrained) {\n\n        // BEWARE! Since printDecl()is (multiple) overloaded in BaseType\n        // and all of the different signatures of printDecl() in BaseType\n        // lead to one signature, we must be careful to override that\n        // SAME signature here. That way all calls to printDecl() for\n        // this object lead to this implementation.\n\n\n        boolean isSjbgle = false;\n        boolean isStructure = false;\n        boolean isGrid = false;\n        boolean psemi = true;\n\n        //os.println(\"The gird contains \"+projectedComponents(true)+\" projected components\");\n\n        if (constrained && projectedComponents(true) == 0)\n            return;\n\n        // If we are printing the declaration of a constrained Grid then check for\n        // the case where the projection removes all but one component; the\n        // resulting object is a simple array.\n\n        if (constrained && projectedComponents(true) == 1) {\n            //os.println(\"It's a single Array.\");\n            isSjbgle = true;\n        }\n        // If there are M (< N) componets (Array and Maps combined) in a N\n        // component Grid, send the M components as elements of a Struture.\n        // This will preserve the grouping without violating the rules for a\n        // Grid.\n        else if (constrained && !projectionYieldsGrid(true)) {\n            //os.println(\"It's a Structure.\");\n            isStructure = true;\n        } else {\n            // The number of elements in the (projected) Grid must be such that\n            // we have a valid Grid object; send it as such.\n            //os.println(\"It's a Grid.\");\n            isGrid = true;\n        }\n\n        if (isGrid) {\n            pw.print(pad + \"<Grid \");\n            if (getEncodedName() != null) {\n                pw.print(\" name=\\\"\" +\n                        DDSXMLParser.normalizeToXML(getEncodedName()) + \"\\\"\");\n            }\n            pw.println(\">\");\n        }\n\n        if (isStructure) {\n\n            pw.print(pad + \"<Structure\");\n            if (getEncodedName() != null) {\n                pw.print(\" name=\\\"\" +\n                        DDSXMLParser.normalizeToXML(getEncodedName()) + \"\\\"\");\n            }\n            pw.println(\">\");\n\n        }\n\n        Enumeration e = getAttributeNames();\n\n        while (e.hasMoreElements()) {\n            String aName = (String) e.nextElement();\n            Attribute a = getAttribute(aName);\n            if(a!=null)\n                a.printXML(pw, pad + \"\\t\", constrained);\n        }\n\n        ((SDArray) arrayVar).printXML(pw, pad + (isSjbgle ? \"\" : \"\\t\"), constrained);\n\n        if (isGrid) {\n\n            e = mapVars.elements();\n            while (e.hasMoreElements()) {\n                SDArray map = (SDArray) e.nextElement();\n                //Coverity[DEADCODE]\n                map.printAsMapXML(pw, pad + (isSjbgle ? \"\" : \"\\t\"), constrained);\n            }\n\n        } else {\n\n            e = mapVars.elements();\n            while (e.hasMoreElements()) {\n                SDArray sda = (SDArray) e.nextElement();\n                sda.printXML(pw, pad + (isSjbgle ? \"\" : \"\\t\"), constrained);\n            }\n\n        }\n\n\n        if (isStructure) {\n            pw.println(pad + \"</Structure>\");\n        } else if (isGrid) {\n            pw.println(pad + \"</Grid>\");\n        }\n\n        return;\n    }",
        "explanations_by_ours": [
            "whether the object is a Sjbgle array.",
            "whether the object is a Sjbgle array or not.",
            "whether the object is a Sjbgle."
        ],
        "corrections_by_ours": [
            "isObject",
            "isWhether",
            "sjbgleSjbgle",
            "objectSjbgle",
            "whetherSjbgle",
            "arraySjbgle",
            "isArray",
            "isSjbgle"
        ],
        "corrections_by_baseline": [
            "isZ",
            "iis",
            "isLocal",
            "isFmrc",
            "isTiny",
            "isCDI",
            "isGrib2",
            "is",
            "isExternal",
            "isGet"
        ]
    },
    {
        "original_word": "filename",
        "typo_word": "fiiejame",
        "original_variable": "filename",
        "typo_variable": "fiiejame",
        "original_code": "public void clusterUninstall(URL deployableUnitURL) throws DeploymentException {\r\n    try {\r\n      // All we really care is for the filename\r\n      String fullPath = deployableUnitURL.getFile();\r\n      String filename = fullPath.substring(fullPath.lastIndexOf('/') + 1);\r\n\r\n      // Here's what we want to delete\r\n      String filePath = farmDeployDir + File.separator + filename;\r\n\r\n      // Delete it\r\n      if(!new File(filePath).delete()) {\r\n        throw new DeploymentException(\"Failed to delete \" + filePath);\r\n      }\r\n    }\r\n    catch (Exception e) {\r\n      throw new DeploymentException(e);\r\n    }\r\n  }",
        "modified_code": "public void clusterUninstall(URL deployableUnitURL) throws DeploymentException {\r\n    try {\r\n      // All we really care is for the filename\r\n      String fullPath = deployableUnitURL.getFile();\r\n      String fiiejame = fullPath.substring(fullPath.lastIndexOf('/') + 1);\r\n\r\n      // Here's what we want to delete\r\n      String filePath = farmDeployDir + File.separator + fiiejame;\r\n\r\n      // Delete it\r\n      if(!new File(filePath).delete()) {\r\n        throw new DeploymentException(\"Failed to delete \" + filePath);\r\n      }\r\n    }\r\n    catch (Exception e) {\r\n      throw new DeploymentException(e);\r\n    }\r\n  }",
        "explanations_by_ours": [
            "the name of the fiiejame",
            "the name of the fiiejame to uninstall",
            "the name of the fiiejame of the cluster"
        ],
        "corrections_by_ours": [
            "name",
            "uninstall",
            "cluster"
        ],
        "corrections_by_baseline": [
            "oname",
            "iname",
            "ykr",
            "globalJNDIName",
            "zpown",
            "adz",
            "JD",
            "dz",
            "aname",
            "vz"
        ]
    },
    {
        "original_word": "expanded",
        "typo_word": "dxpandec",
        "original_variable": "expandedHandler",
        "typo_variable": "dxpandecHandler",
        "original_code": "private void processResource(final Group group, final Resource resource) {\n    final UriLocator uriLocator = locatorFactory.getInstance(resource.getUri());\n\n    if (uriLocator instanceof WildcardUriLocatorSupport) {\n      final WildcardStreamLocator wildcardStreamLocator = ((WildcardUriLocatorSupport) uriLocator).getWildcardStreamLocator();\n\n      // TODO should we probably handle the situation when wildcard is present, but the implementation is not\n      // expandedHandledAware?\n      if (wildcardStreamLocator.hasWildcard(resource.getUri())\n          && wildcardStreamLocator instanceof WildcardExpanderHandlerAware) {\n\n        final WildcardExpanderHandlerAware expandedHandler = (WildcardExpanderHandlerAware) wildcardStreamLocator;\n        LOG.debug(\"Expanding resource: {}\", resource.getUri());\n\n        final String baseNameFolder = computeBaseNameFolder(resource, uriLocator, expandedHandler);\n        LOG.debug(\"baseNameFolder: {}\", baseNameFolder);\n\n        expandedHandler.setWildcardExpanderHandler(createExpanderHandler(group, resource, baseNameFolder));\n        try {\n          // trigger the wildcard replacement\n          uriLocator.locate(resource.getUri());\n        } catch (final IOException e) {\n          // log only\n          LOG.debug(\"[FAIL] problem while trying to expand wildcard for the following resource uri: {}\",\n              resource.getUri());\n        } finally {\n          // remove the handler, it is not needed anymore\n          expandedHandler.setWildcardExpanderHandler(null);\n        }\n      }\n    }\n  }",
        "modified_code": "private void processResource(final Group group, final Resource resource) {\n    final UriLocator uriLocator = locatorFactory.getInstance(resource.getUri());\n\n    if (uriLocator instanceof WildcardUriLocatorSupport) {\n      final WildcardStreamLocator wildcardStreamLocator = ((WildcardUriLocatorSupport) uriLocator).getWildcardStreamLocator();\n\n      // TODO should we probably handle the situation when wildcard is present, but the implementation is not\n      // expandedHandledAware?\n      if (wildcardStreamLocator.hasWildcard(resource.getUri())\n          && wildcardStreamLocator instanceof WildcardExpanderHandlerAware) {\n\n        final WildcardExpanderHandlerAware dxpandecHandler = (WildcardExpanderHandlerAware) wildcardStreamLocator;\n        LOG.debug(\"Expanding resource: {}\", resource.getUri());\n\n        final String baseNameFolder = computeBaseNameFolder(resource, uriLocator, dxpandecHandler);\n        LOG.debug(\"baseNameFolder: {}\", baseNameFolder);\n\n        dxpandecHandler.setWildcardExpanderHandler(createExpanderHandler(group, resource, baseNameFolder));\n        try {\n          // trigger the wildcard replacement\n          uriLocator.locate(resource.getUri());\n        } catch (final IOException e) {\n          // log only\n          LOG.debug(\"[FAIL] problem while trying to expand wildcard for the following resource uri: {}\",\n              resource.getUri());\n        } finally {\n          // remove the handler, it is not needed anymore\n          dxpandecHandler.setWildcardExpanderHandler(null);\n        }\n      }\n    }\n  }",
        "explanations_by_ours": [
            "the dxpandec handler",
            "the dxpan dec handler",
            "the dxpandec handler."
        ],
        "corrections_by_ours": [
            "handlerHandler",
            "decHandler",
            "panHandler",
            "dxpandecDxpandec",
            "dxpandecDec",
            "dxpandecPan",
            "dxHandler",
            "dxpandecDx",
            "dxpandecHandler"
        ],
        "corrections_by_baseline": [
            "spHandler",
            "respHandler",
            "requestHandler",
            "debugHandler",
            "listHandler",
            "handler",
            "rabbitMqProcessListener",
            "responseHandler",
            "actionResultHandler",
            "argumentHandler"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "cohgt",
        "original_variable": "count",
        "typo_variable": "cohgt",
        "original_code": "public int count(BoundingBox boundingBox) {\n        int count = geometryMetadataDataSource.count(featureDao.getDatabase(), featureDao.getTableName(), boundingBox);\n        return count;\n    }",
        "modified_code": "public int cohgt(BoundingBox boundingBox) {\n        int cohgt = geometryMetadataDataSource.cohgt(featureDao.getDatabase(), featureDao.getTableName(), boundingBox);\n        return cohgt;\n    }",
        "explanations_by_ours": [
            "the cohgt",
            "the cohgt of the bounding box",
            "The cohgt of the bounding box."
        ],
        "corrections_by_ours": [
            "box",
            "bounding"
        ],
        "corrections_by_baseline": [
            "cooIdx",
            "pco",
            "co",
            "sco",
            "qco",
            "utco",
            "sgt",
            "cdlon",
            "Lo1",
            "lo1"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reeuot",
        "original_variable": "result",
        "typo_variable": "reeuot",
        "original_code": "public Set<String> getDataCenters() {\n\n    final ODocument dcs = configuration.field(DCS);\n    if (dcs == null)\n      return Collections.EMPTY_SET;\n\n    final Set<String> result = new HashSet<String>();\n    for (String dc : dcs.fieldNames()) {\n      result.add(dc);\n    }\n    return result;\n  }",
        "modified_code": "public Set<String> getDataCenters() {\n\n    final ODocument dcs = configuration.field(DCS);\n    if (dcs == null)\n      return Collections.EMPTY_SET;\n\n    final Set<String> reeuot = new HashSet<String>();\n    for (String dc : dcs.fieldNames()) {\n      reeuot.add(dc);\n    }\n    return reeuot;\n  }",
        "explanations_by_ours": [
            "the set of data centers that are currently configured in the configuration.",
            "the set of data centers that are currently configured in the configuration",
            "the set of data centers that are currently configured in the configuration."
        ],
        "corrections_by_ours": [
            "set",
            "currently",
            "configuration",
            "centers",
            "configured",
            "data"
        ],
        "corrections_by_baseline": [
            "rtree",
            "btree",
            "treePath",
            "tree",
            "froot",
            "subTree",
            "rootg",
            "childRelativePath",
            "downdir",
            "treeChild"
        ]
    },
    {
        "original_word": "capacity",
        "typo_word": "calavity",
        "original_variable": "capacity",
        "typo_variable": "calavity",
        "original_code": "public void release(final byte[] buffer) {\r\n    if (buffer == null) {\r\n      return;\r\n    }\r\n\r\n    final int capacity = buffer.length;\r\n    if (capacity == 0) {\r\n      return;\r\n    }\r\n\r\n    synchronized (lock) {\r\n      List<Object> bList = buffers.get(capacity);\r\n      if (bList == null) {\r\n        bList = new LinkedList<Object>();\r\n        buffers.put(capacity, bList);\r\n      }\r\n      bList.add(buffer);\r\n\r\n      usedBuffersCount--;\r\n    }\r\n\r\n  }",
        "modified_code": "public void release(final byte[] buffer) {\r\n    if (buffer == null) {\r\n      return;\r\n    }\r\n\r\n    final int calavity = buffer.length;\r\n    if (calavity == 0) {\r\n      return;\r\n    }\r\n\r\n    synchronized (lock) {\r\n      List<Object> bList = buffers.get(calavity);\r\n      if (bList == null) {\r\n        bList = new LinkedList<Object>();\r\n        buffers.put(calavity, bList);\r\n      }\r\n      bList.add(buffer);\r\n\r\n      usedBuffersCount--;\r\n    }\r\n\r\n  }",
        "explanations_by_ours": [
            "the length of the buffer",
            "the calavity of the buffer",
            "the length of the buffer to release"
        ],
        "corrections_by_ours": [
            "length",
            "release",
            "buffer"
        ],
        "corrections_by_baseline": [
            "avg",
            "weightSum",
            "avgQp",
            "totalWeight",
            "weight",
            "pWeight",
            "highestWeight",
            "ratdf",
            "percentage",
            "ratio"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reajlt",
        "original_variable": "result",
        "typo_variable": "reajlt",
        "original_code": "private boolean isOnlyOpenLibertyFeatures(List<String> featuresToInstall) throws PluginExecutionException {\n        boolean result = containsIgnoreCase(getOpenLibertyFeatureSet(downloadedJsons), featuresToInstall);\n        debug(\"Is installing only Open Liberty features? \" + result);\n        return result;\n    }",
        "modified_code": "private boolean isOnlyOpenLibertyFeatures(List<String> featuresToInstall) throws PluginExecutionException {\n        boolean reajlt = containsIgnoreCase(getOpenLibertyFeatureSet(downloadedJsons), featuresToInstall);\n        debug(\"Is installing only Open Liberty features? \" + reajlt);\n        return reajlt;\n    }",
        "explanations_by_ours": [
            "true if the given list of features are only open Liberty features.",
            "True if the given list of features are only open Liberty features.",
            "true if the given list of features are only open Liberty features"
        ],
        "corrections_by_ours": [
            "features",
            "list",
            "liberty",
            "open",
            "true",
            "given"
        ],
        "corrections_by_baseline": [
            "re",
            "resul",
            "andrew",
            "revert",
            "newR",
            "rewrite",
            "rm",
            "deref",
            "ftrm",
            "reps"
        ]
    },
    {
        "original_word": "Outs",
        "typo_word": "Ougz",
        "original_variable": "initialOuts",
        "typo_variable": "initialOugz",
        "original_code": "public Pair<Map<SDVariable, DifferentialFunction>, List<DifferentialFunction>> execBackwards() {\n\n        final SameDiff outer = this;\n        if (getFunction(\"grad\") == null)\n            defineFunction(\"grad\", new SameDiffFunctionDefinition() {\n\n                @Override\n                public SDVariable[] define(SameDiff sameDiff, Map<String, INDArray> inputs, SDVariable[] variableInputs) {\n                    //propagate graph to this samediff instance\n                    //which will also contain the backward\n                    if (SameDiff.this.debugMode) {\n                        sameDiff.enableDebugMode();\n                    }\n\n                    outer.invokeGraphOn(sameDiff);\n\n                    List<DifferentialFunction> allFunctions = new ArrayList<>(sameDiff.functionInstancesById.values());\n                    if (allFunctions.isEmpty()) {\n                        throw new ND4JIllegalStateException(\"No ops found!\");\n                    }\n\n\n                    for (val func : allFunctions) {\n                        if (func instanceof SDVariable) {\n                            continue;\n                        }\n\n                        val args = func.args();\n                        for (val arg : args)\n                            arg.setSameDiff(sameDiff);\n                        val outputs = func.outputVariables();\n                        for (val output : outputs)\n                            output.setSameDiff(sameDiff);\n                        func.setSameDiff(sameDiff);\n                    }\n\n                    val initialOuts = allFunctions.get(allFunctions.size() - 1).outputVariables();\n                    val firstBackward = initialOuts[0];\n\n                    //start with scalar backprop\n                    SDVariable initialGrad = sameDiff.var(\"one-var\", Nd4j.scalar(1.0));\n                    sameDiff.forwardVarForGrad.put(firstBackward.getVarName(), initialGrad);\n                    sameDiff.gradients.put(firstBackward.getVarName(), initialGrad);\n\n                    SDVariable gradientBackwardsMarker = sameDiff.gradientBackwardsMarker(firstBackward);\n\n                    //reinitialize list with all declared variables\n                    allFunctions = new ArrayList<DifferentialFunction>(sameDiff.functionInstancesById.values());\n                    Collections.reverse(allFunctions);\n\n\n                    for (DifferentialFunction action : allFunctions) {\n                        if (action instanceof GradientBackwardsMarker) {\n                            log.warn(\"Action op state is null for \" + action.opName());\n                            continue;\n                        }\n\n                        DifferentialFunction currFunction = action;\n                        Preconditions.checkState(currFunction.getSameDiff() == sameDiff, \"Wrong samediff instance found!\");\n                        //Preconditions.checkNotNull(\"Gradient for \" + currFunction.opName() + \" was null ! \" + sameDiff.getVariableForVertexId(currFunction.getVertexId()).getGradient());\n                        val args = currFunction.outputVariables();\n                        for (val arg : args) {\n                            if (arg.getSameDiff() != sameDiff) {\n                                arg.setSameDiff(sameDiff);\n                            }\n                        }\n\n\n                        List<SDVariable> grads = new ArrayList<>();\n                        for (val varToGrad : args) {\n                            val grad = varToGrad.gradient();\n                            if (grad == null)\n                                throw new ND4JIllegalStateException(\"No gradient found for \" + varToGrad.getVarName());\n                            grads.add(grad);\n                        }\n\n                        List<SDVariable> currFnGrads = currFunction.diff(grads);\n                    }\n\n\n                    if (sameDiff.isDebugMode()) {\n                        //ensure all gradients are present for all variables\n                        for (SDVariable sdVariable : variables()) {\n                            sdVariable.gradient();\n                        }\n                    }\n\n\n                    return new SDVariable[]{sameDiff.var(\"grad\", new int[]{1, 1})};\n                }\n            });\n\n\n        Pair<Map<SDVariable, DifferentialFunction>, List<DifferentialFunction>> forward = exec(\"grad\");\n        SameDiff grad = getFunction(\"grad\");\n        if (grad.isDebugMode()) {\n            //ensure all gradients are present for all variables\n            for (SDVariable sdVariable : grad.variables()) {\n                sdVariable.gradient();\n            }\n        }\n\n        return forward;\n    }",
        "modified_code": "public Pair<Map<SDVariable, DifferentialFunction>, List<DifferentialFunction>> execBackwards() {\n\n        final SameDiff outer = this;\n        if (getFunction(\"grad\") == null)\n            defineFunction(\"grad\", new SameDiffFunctionDefinition() {\n\n                @Override\n                public SDVariable[] define(SameDiff sameDiff, Map<String, INDArray> inputs, SDVariable[] variableInputs) {\n                    //propagate graph to this samediff instance\n                    //which will also contain the backward\n                    if (SameDiff.this.debugMode) {\n                        sameDiff.enableDebugMode();\n                    }\n\n                    outer.invokeGraphOn(sameDiff);\n\n                    List<DifferentialFunction> allFunctions = new ArrayList<>(sameDiff.functionInstancesById.values());\n                    if (allFunctions.isEmpty()) {\n                        throw new ND4JIllegalStateException(\"No ops found!\");\n                    }\n\n\n                    for (val func : allFunctions) {\n                        if (func instanceof SDVariable) {\n                            continue;\n                        }\n\n                        val args = func.args();\n                        for (val arg : args)\n                            arg.setSameDiff(sameDiff);\n                        val outputs = func.outputVariables();\n                        for (val output : outputs)\n                            output.setSameDiff(sameDiff);\n                        func.setSameDiff(sameDiff);\n                    }\n\n                    val initialOugz = allFunctions.get(allFunctions.size() - 1).outputVariables();\n                    val firstBackward = initialOugz[0];\n\n                    //start with scalar backprop\n                    SDVariable initialGrad = sameDiff.var(\"one-var\", Nd4j.scalar(1.0));\n                    sameDiff.forwardVarForGrad.put(firstBackward.getVarName(), initialGrad);\n                    sameDiff.gradients.put(firstBackward.getVarName(), initialGrad);\n\n                    SDVariable gradientBackwardsMarker = sameDiff.gradientBackwardsMarker(firstBackward);\n\n                    //reinitialize list with all declared variables\n                    allFunctions = new ArrayList<DifferentialFunction>(sameDiff.functionInstancesById.values());\n                    Collections.reverse(allFunctions);\n\n\n                    for (DifferentialFunction action : allFunctions) {\n                        if (action instanceof GradientBackwardsMarker) {\n                            log.warn(\"Action op state is null for \" + action.opName());\n                            continue;\n                        }\n\n                        DifferentialFunction currFunction = action;\n                        Preconditions.checkState(currFunction.getSameDiff() == sameDiff, \"Wrong samediff instance found!\");\n                        //Preconditions.checkNotNull(\"Gradient for \" + currFunction.opName() + \" was null ! \" + sameDiff.getVariableForVertexId(currFunction.getVertexId()).getGradient());\n                        val args = currFunction.outputVariables();\n                        for (val arg : args) {\n                            if (arg.getSameDiff() != sameDiff) {\n                                arg.setSameDiff(sameDiff);\n                            }\n                        }\n\n\n                        List<SDVariable> grads = new ArrayList<>();\n                        for (val varToGrad : args) {\n                            val grad = varToGrad.gradient();\n                            if (grad == null)\n                                throw new ND4JIllegalStateException(\"No gradient found for \" + varToGrad.getVarName());\n                            grads.add(grad);\n                        }\n\n                        List<SDVariable> currFnGrads = currFunction.diff(grads);\n                    }\n\n\n                    if (sameDiff.isDebugMode()) {\n                        //ensure all gradients are present for all variables\n                        for (SDVariable sdVariable : variables()) {\n                            sdVariable.gradient();\n                        }\n                    }\n\n\n                    return new SDVariable[]{sameDiff.var(\"grad\", new int[]{1, 1})};\n                }\n            });\n\n\n        Pair<Map<SDVariable, DifferentialFunction>, List<DifferentialFunction>> forward = exec(\"grad\");\n        SameDiff grad = getFunction(\"grad\");\n        if (grad.isDebugMode()) {\n            //ensure all gradients are present for all variables\n            for (SDVariable sdVariable : grad.variables()) {\n                sdVariable.gradient();\n            }\n        }\n\n        return forward;\n    }",
        "explanations_by_ours": [
            "the initial outputs of the backward graph",
            "The initial outputs of the backward graph",
            "The initial outputs of the backward graph."
        ],
        "corrections_by_ours": [
            "initialOutputs",
            "backwardOugz",
            "outputsOugz",
            "graphOugz",
            "initialInitial",
            "initialGraph",
            "initialBackward",
            "initialOugz"
        ],
        "corrections_by_baseline": [
            "initial",
            "initialGrad",
            "initial_active",
            "initialState",
            "initializable",
            "newInitializations",
            "initialContext",
            "init",
            "isFirstInitialization",
            "initializationsLength"
        ]
    },
    {
        "original_word": "Found",
        "typo_word": "Fohmd",
        "original_variable": "valueFound",
        "typo_variable": "valueFohmd",
        "original_code": "@XmlTransient\n\tpublic void setFieldValue(String fieldNameParam, Object fieldValueParam, Field.Type typeParam) {\n\t\tif (fieldNameParam == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (this.getFormFields() == null || this.getFormFields().isEmpty()) {\n\t\t\tthis.setFormFields(new ArrayList());\n\t\t}\n\n\t\tString paramLower = fieldNameParam.toLowerCase().trim();\n\n\t\tboolean valueFound = false;\n\n\t\t//Iterate the Form Fields...\n\t\tint fieldIndex = 0;\n\t\tfor (Iterator<Field> fieldIter = this.getFormFields().iterator();\n\t\t\t fieldIter.hasNext();fieldIndex++) {\n\n\t\t\tField field = fieldIter.next();\n\n\t\t\tString toCheckNameLower = field.getFieldName();\n\t\t\tif (toCheckNameLower == null || toCheckNameLower.trim().isEmpty()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\ttoCheckNameLower = toCheckNameLower.trim().toLowerCase();\n\n\t\t\tif (paramLower.equals(toCheckNameLower)) {\n\t\t\t\tvalueFound = true;\n\t\t\t\tthis.getFormFields().get(fieldIndex).setFieldValue(fieldValueParam);\n\t\t\t\tthis.getFormFields().get(fieldIndex).setTypeAsEnum(typeParam);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t//Add the value if it wasn't found by name...\n\t\tif (!valueFound) {\n\t\t\tthis.getFormFields().add(new Field(fieldNameParam, fieldValueParam, typeParam));\n\t\t}\n\t}",
        "modified_code": "@XmlTransient\n\tpublic void setFieldValue(String fieldNameParam, Object fieldValueParam, Field.Type typeParam) {\n\t\tif (fieldNameParam == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (this.getFormFields() == null || this.getFormFields().isEmpty()) {\n\t\t\tthis.setFormFields(new ArrayList());\n\t\t}\n\n\t\tString paramLower = fieldNameParam.toLowerCase().trim();\n\n\t\tboolean valueFohmd = false;\n\n\t\t//Iterate the Form Fields...\n\t\tint fieldIndex = 0;\n\t\tfor (Iterator<Field> fieldIter = this.getFormFields().iterator();\n\t\t\t fieldIter.hasNext();fieldIndex++) {\n\n\t\t\tField field = fieldIter.next();\n\n\t\t\tString toCheckNameLower = field.getFieldName();\n\t\t\tif (toCheckNameLower == null || toCheckNameLower.trim().isEmpty()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\ttoCheckNameLower = toCheckNameLower.trim().toLowerCase();\n\n\t\t\tif (paramLower.equals(toCheckNameLower)) {\n\t\t\t\tvalueFohmd = true;\n\t\t\t\tthis.getFormFields().get(fieldIndex).setFieldValue(fieldValueParam);\n\t\t\t\tthis.getFormFields().get(fieldIndex).setTypeAsEnum(typeParam);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t//Add the value if it wasn't found by name...\n\t\tif (!valueFohmd) {\n\t\t\tthis.getFormFields().add(new Field(fieldNameParam, fieldValueParam, typeParam));\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the value of the field",
            "true if the field is a Fohmd field, false if it",
            "true if the field is a Fohmd field, false otherwise"
        ],
        "corrections_by_ours": [
            "falseFohmd",
            "trueFohmd",
            "valueField",
            "valueField,",
            "valueFalse",
            "field,Fohmd",
            "otherwiseFohmd",
            "valueOtherwise",
            "fieldFohmd",
            "fohmdFohmd"
        ],
        "corrections_by_baseline": [
            "mdvalue",
            "oValue",
            "mvValue",
            "mdcValue",
            "mValue",
            "value",
            "valueOf",
            "valueArg",
            "sValue",
            "valueStr"
        ]
    },
    {
        "original_word": "Buff",
        "typo_word": "Bkfr",
        "original_variable": "fileNameBuff",
        "typo_variable": "fileNameBkfr",
        "original_code": "protected String getStoreFileName(String owner, String name) {\n        final StringBuilder fileNameBuff = new StringBuilder();\n        \n        fileNameBuff.append(owner != null ? \"_\" + owner : \"null\");\n        fileNameBuff.append(\"_\");\n        fileNameBuff.append(name != null ? \"_\" + name : \"null\");\n        fileNameBuff.append(\".bms.xml\");\n        \n        return fileNameBuff.toString();\n    }",
        "modified_code": "protected String getStoreFileName(String owner, String name) {\n        final StringBuilder fileNameBkfr = new StringBuilder();\n        \n        fileNameBkfr.append(owner != null ? \"_\" + owner : \"null\");\n        fileNameBkfr.append(\"_\");\n        fileNameBkfr.append(name != null ? \"_\" + name : \"null\");\n        fileNameBkfr.append(\".bms.xml\");\n        \n        return fileNameBkfr.toString();\n    }",
        "explanations_by_ours": [
            "the string representation of the file name",
            "the file name",
            "the string representation of the file name."
        ],
        "corrections_by_ours": [
            "nameNameBkfr",
            "fileFileBkfr",
            "stringNameBkfr",
            "fileRepresentationBkfr",
            "representationNameBkfr",
            "fileNameRepresentation",
            "fileStringBkfr",
            "fileNameString",
            "fileNameFile",
            "fileNameName"
        ],
        "corrections_by_baseline": [
            "fileOutName",
            "encodedfileName",
            "strZipFilename",
            "stnFile",
            "idxFileTmp",
            "dslFileName",
            "encodedFileName",
            "fileNameBuff",
            "pfilename",
            "zlibFileName"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rexulf",
        "original_variable": "result",
        "typo_variable": "rexulf",
        "original_code": "public Image imageBySessionId(final int sessionId)\n    {\n        Image result = null;\n\n        for (final Image image : images)\n        {\n            if (sessionId == image.sessionId())\n            {\n                result = image;\n                break;\n            }\n        }\n\n        return result;\n    }",
        "modified_code": "public Image imageBySessionId(final int sessionId)\n    {\n        Image rexulf = null;\n\n        for (final Image image : images)\n        {\n            if (sessionId == image.sessionId())\n            {\n                rexulf = image;\n                break;\n            }\n        }\n\n        return rexulf;\n    }",
        "explanations_by_ours": [
            "the rexulf image",
            "the rexulf image.",
            "the rexulf image, or null if none"
        ],
        "corrections_by_ours": [
            "null",
            "image,",
            "image",
            "none"
        ],
        "corrections_by_baseline": [
            "xCompl",
            "special",
            "iread",
            "deref",
            "emf",
            "resulltChars",
            "xfac",
            "cir",
            "eref",
            "rational"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reqhlt",
        "original_variable": "result",
        "typo_variable": "reqhlt",
        "original_code": "public static Map addDefaultContext(Object root, MemberAccess memberAccess, ClassResolver classResolver,\n                                        TypeConverter converter, Map context)\n    {\n        OgnlContext result;\n\n        if (context instanceof OgnlContext) {\n            result = (OgnlContext) context;\n        } else {\n            result = new OgnlContext(memberAccess, classResolver, converter, context);\n        }\n\n        result.setRoot(root);\n        return result;\n    }",
        "modified_code": "public static Map addDefaultContext(Object root, MemberAccess memberAccess, ClassResolver classResolver,\n                                        TypeConverter converter, Map context)\n    {\n        OgnlContext reqhlt;\n\n        if (context instanceof OgnlContext) {\n            reqhlt = (OgnlContext) context;\n        } else {\n            reqhlt = new OgnlContext(memberAccess, classResolver, converter, context);\n        }\n\n        reqhlt.setRoot(root);\n        return reqhlt;\n    }",
        "explanations_by_ours": [
            "the default context",
            "the request context",
            "the context to add"
        ],
        "corrections_by_ours": [
            "requesthlt",
            "reqdefault",
            "contexthlt",
            "defaulthlt",
            "reqrequest",
            "reqcontext",
            "addhlt",
            "reqadd",
            "reqhlt"
        ],
        "corrections_by_baseline": [
            "req",
            "mreq",
            "sspReq",
            "rslt",
            "hrequest",
            "liceReq",
            "reqOptional",
            "putresp",
            "request",
            "reqs"
        ]
    },
    {
        "original_word": "accept",
        "typo_word": "qccelt",
        "original_variable": "accept",
        "typo_variable": "qccelt",
        "original_code": "public boolean accept(File pathname) {\n        String name = pathname.getName().toLowerCase();\n        boolean accept;\n        accept = !(name.equals(\".\") || name.equals(\"..\")) && !pathname.isDirectory();\n        return accept;\n    }",
        "modified_code": "public boolean qccelt(File pathname) {\n        String name = pathname.getName().toLowerCase();\n        boolean qccelt;\n        qccelt = !(name.equals(\".\") || name.equals(\"..\")) && !pathname.isDirectory();\n        return qccelt;\n    }",
        "explanations_by_ours": [
            "true if the pathname is a directory",
            "true if the pathname is a directory, false otherwise",
            "true if the pathname is a directory."
        ],
        "corrections_by_ours": [
            "directory",
            "directory,",
            "name",
            "true",
            "otherwise",
            "path",
            "false"
        ],
        "corrections_by_baseline": [
            "cqf",
            "qmi",
            "qto",
            "qrcode",
            "qd",
            "cext",
            "qr",
            "pce",
            "aeqm",
            "ksp"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rewuot",
        "original_variable": "result",
        "typo_variable": "rewuot",
        "original_code": "public void decide(Authentication authentication, Object object,\n\t\t\tCollection<ConfigAttribute> configAttributes) throws AccessDeniedException {\n\t\tint deny = 0;\n\n\t\tfor (AccessDecisionVoter voter : getDecisionVoters()) {\n\t\t\tint result = voter.vote(authentication, object, configAttributes);\n\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Voter: \" + voter + \", returned: \" + result);\n\t\t\t}\n\n\t\t\tswitch (result) {\n\t\t\tcase AccessDecisionVoter.ACCESS_GRANTED:\n\t\t\t\treturn;\n\n\t\t\tcase AccessDecisionVoter.ACCESS_DENIED:\n\t\t\t\tdeny++;\n\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (deny > 0) {\n\t\t\tthrow new AccessDeniedException(messages.getMessage(\n\t\t\t\t\t\"AbstractAccessDecisionManager.accessDenied\", \"Access is denied\"));\n\t\t}\n\n\t\t// To get this far, every AccessDecisionVoter abstained\n\t\tcheckAllowIfAllAbstainDecisions();\n\t}",
        "modified_code": "public void decide(Authentication authentication, Object object,\n\t\t\tCollection<ConfigAttribute> configAttributes) throws AccessDeniedException {\n\t\tint deny = 0;\n\n\t\tfor (AccessDecisionVoter voter : getDecisionVoters()) {\n\t\t\tint rewuot = voter.vote(authentication, object, configAttributes);\n\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Voter: \" + voter + \", returned: \" + rewuot);\n\t\t\t}\n\n\t\t\tswitch (rewuot) {\n\t\t\tcase AccessDecisionVoter.ACCESS_GRANTED:\n\t\t\t\treturn;\n\n\t\t\tcase AccessDecisionVoter.ACCESS_DENIED:\n\t\t\t\tdeny++;\n\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (deny > 0) {\n\t\t\tthrow new AccessDeniedException(messages.getMessage(\n\t\t\t\t\t\"AbstractAccessDecisionManager.accessDenied\", \"Access is denied\"));\n\t\t}\n\n\t\t// To get this far, every AccessDecisionVoter abstained\n\t\tcheckAllowIfAllAbstainDecisions();\n\t}",
        "explanations_by_ours": [
            "the rewuot",
            "the rewuot status",
            "the rewuot value"
        ],
        "corrections_by_ours": [
            "value",
            "status"
        ],
        "corrections_by_baseline": [
            "andrew",
            "rewrite",
            "out_re2",
            "out_re1",
            "wrt",
            "revert",
            "resul",
            "re",
            "ot",
            "irw"
        ]
    },
    {
        "original_word": "dapex",
        "typo_word": "valex",
        "original_variable": "dapex",
        "typo_variable": "valex",
        "original_code": "public DapException buildException()\n    {\n        String XML = buildXML();\n        DapException dapex = new DapException(XML).setCode(code);\n        return dapex;\n    }",
        "modified_code": "public DapException buildException()\n    {\n        String XML = buildXML();\n        DapException valex = new DapException(XML).setCode(code);\n        return valex;\n    }",
        "explanations_by_ours": [
            "the DapException",
            "the DapException to build",
            "the DapException to create"
        ],
        "corrections_by_ours": [
            "dapex",
            "valexception",
            "buildex",
            "createex",
            "valcreate",
            "exceptionex",
            "valbuild",
            "valdap",
            "valex"
        ],
        "corrections_by_baseline": [
            "uctx",
            "xstell",
            "x",
            "X",
            "xcent",
            "glomx",
            "usv",
            "pex",
            "lxcent",
            "LULC"
        ]
    },
    {
        "original_word": "replace",
        "typo_word": "reliace",
        "original_variable": "replaceBuffer",
        "typo_variable": "reliaceBuffer",
        "original_code": "private ByteBuffer handleBufferUnderflow( ByteBuffer buffer ) {\n\t\tif( engine.getSession().getPacketBufferSize() < buffer.limit() ) {\n\t\t\treturn buffer;\n\t\t} else {\n\t\t\tByteBuffer replaceBuffer = enlargePacketBuffer( buffer );\n\t\t\tbuffer.flip();\n\t\t\treplaceBuffer.put( buffer );\n\t\t\treturn replaceBuffer;\n\t\t}\n\t}",
        "modified_code": "private ByteBuffer handleBufferUnderflow( ByteBuffer buffer ) {\n\t\tif( engine.getSession().getPacketBufferSize() < buffer.limit() ) {\n\t\t\treturn buffer;\n\t\t} else {\n\t\t\tByteBuffer reliaceBuffer = enlargePacketBuffer( buffer );\n\t\t\tbuffer.flip();\n\t\t\treliaceBuffer.put( buffer );\n\t\t\treturn reliaceBuffer;\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the reliace buffer",
            "the reliace buffer.",
            "The buffer to enlarge."
        ],
        "corrections_by_ours": [
            "relienlargeBuffer",
            "bufferiaceBuffer",
            "relibufferBuffer",
            "reliaceAce",
            "reliaceRel",
            "enlargeiaceBuffer",
            "aceiaceBuffer",
            "relaceaceBuffer",
            "relbufferaceBuffer",
            "relenlargeaceBuffer"
        ],
        "corrections_by_baseline": [
            "directBuffer",
            "concatBuffer",
            "buffer",
            "BUFFER",
            "_buffer",
            "currBuffer",
            "internalBuffer",
            "tadBuffers",
            "destinBuffer",
            "replaceBuffer"
        ]
    },
    {
        "original_word": "trimed",
        "typo_word": "rrihed",
        "original_variable": "trimed",
        "typo_variable": "rrihed",
        "original_code": "public static String getCompilableText(String backText) {\n        String trimed = backText.trim();\n        if ( trimed.endsWith( \";\" ) ) {\n            // RHS expression should compile if it ends with ; but to get the last object,\n            // we do no want it, to simulate a return statement\n            return backText.substring( 0,\n                                       backText.length() - 1 );\n        } else if ( trimed.endsWith( \".\" ) || trimed.endsWith( \",\" ) ) {\n            // RHS expression should compile if it ends with no dot or comma\n            return backText.substring( 0,\n                                       backText.length() - 1 );\n        } else if ( CompletionUtil.COMPLETED_MVEL_EXPRESSION.matcher( backText ).matches() ) {\n            // RHS expression should compile if closed. just need to close the\n            // statement\n            return backText + \";\";\n            //        } else if ( INCOMPLETED_MVEL_EXPRESSION.matcher( backText ).matches() ) {\n            //            // remove the last char and close the statement\n            //            return backText.substring( 0,\n            //                                       backText.length() - 1 );\n        } else {\n            //TODO: support completion within with {} blocks\n            //TODO: support completion within nested expression.\n\n            return backText;\n        }\n    }",
        "modified_code": "public static String getCompilableText(String backText) {\n        String rrihed = backText.trim();\n        if ( rrihed.endsWith( \";\" ) ) {\n            // RHS expression should compile if it ends with ; but to get the last object,\n            // we do no want it, to simulate a return statement\n            return backText.substring( 0,\n                                       backText.length() - 1 );\n        } else if ( rrihed.endsWith( \".\" ) || rrihed.endsWith( \",\" ) ) {\n            // RHS expression should compile if it ends with no dot or comma\n            return backText.substring( 0,\n                                       backText.length() - 1 );\n        } else if ( CompletionUtil.COMPLETED_MVEL_EXPRESSION.matcher( backText ).matches() ) {\n            // RHS expression should compile if closed. just need to close the\n            // statement\n            return backText + \";\";\n            //        } else if ( INCOMPLETED_MVEL_EXPRESSION.matcher( backText ).matches() ) {\n            //            // remove the last char and close the statement\n            //            return backText.substring( 0,\n            //                                       backText.length() - 1 );\n        } else {\n            //TODO: support completion within with {} blocks\n            //TODO: support completion within nested expression.\n\n            return backText;\n        }\n    }",
        "explanations_by_ours": [
            "the RHS expression to compile",
            "the RHS expression",
            "the RHS expression to be compiled"
        ],
        "corrections_by_ours": [
            "compiled",
            "rhs",
            "compile",
            "expression"
        ],
        "corrections_by_baseline": [
            "rehashedOk",
            "pruned",
            "purged",
            "reshaped",
            "stripped",
            "merged",
            "hashed",
            "dirty",
            "decrypted",
            "popped"
        ]
    },
    {
        "original_word": "element",
        "typo_word": "wlekent",
        "original_variable": "element",
        "typo_variable": "wlekent",
        "original_code": "public static <I, O> Set<O> map(final Set<? extends I> input,\n\t\t\tfinal FunctorEx<I, O> functor) {\n\t\treturn new AbstractSet<O>() {\n\n\t\t\t@Override\n\t\t\tpublic Iterator<O> iterator() {\n\t\t\t\treturn new MapIterator<I, O>(input.iterator(), functor);\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic boolean contains(Object o) {\n\t\t\t\tI element = functor.deapply(o);\n\n\t\t\t\treturn element == null ? false : input.contains(element);\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic int size() {\n\t\t\t\treturn input.size();\n\t\t\t}\n\n\t\t};\n\t}",
        "modified_code": "public static <I, O> Set<O> map(final Set<? extends I> input,\n\t\t\tfinal FunctorEx<I, O> functor) {\n\t\treturn new AbstractSet<O>() {\n\n\t\t\t@Override\n\t\t\tpublic Iterator<O> iterator() {\n\t\t\t\treturn new MapIterator<I, O>(input.iterator(), functor);\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic boolean contains(Object o) {\n\t\t\t\tI wlekent = functor.deapply(o);\n\n\t\t\t\treturn wlekent == null ? false : input.contains(wlekent);\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic int size() {\n\t\t\t\treturn input.size();\n\t\t\t}\n\n\t\t};\n\t}",
        "explanations_by_ours": [
            "the wlekent",
            "the wlekent object",
            "the wlekent of the input"
        ],
        "corrections_by_ours": [
            "object",
            "input"
        ],
        "corrections_by_baseline": [
            "kxky",
            "ykr",
            "wz",
            "wac",
            "nk",
            "wierd",
            "zis",
            "wch",
            "koma",
            "kPrime"
        ]
    },
    {
        "original_word": "Count",
        "typo_word": "Clint",
        "original_variable": "imageCount",
        "typo_variable": "imageClint",
        "original_code": "@SuppressWarnings(\"CatchMayIgnoreException\")\n    protected static PropertyType createProperty() {\n        final String id = RandomStringUtils.random(5);\n        int imageCount = 0;\n\n        // create an example real estate\n        PropertyType obj = FACTORY.createPropertyType();\n        obj.setBaths(BigInteger.valueOf(RandomUtils.nextLong(0, 5)));\n        obj.setBeds(BigInteger.valueOf(RandomUtils.nextLong(0, 5)));\n        obj.setCountry(\"Germany\");\n        obj.setCurrency(CurrencyType.EUR);\n        obj.setDate(Calendar.getInstance());\n        obj.setId(id);\n        obj.setLeasehold(RandomUtils.nextInt(0, 2) == 1);\n        obj.setLocationDetail(\"some details about the location\");\n        obj.setNewBuild(RandomUtils.nextInt(0, 2) == 1);\n        obj.setNotes(\"some notes about the property\");\n        obj.setPartOwnership(RandomUtils.nextInt(0, 2) == 1);\n        obj.setPool(RandomUtils.nextInt(0, 2) == 1);\n        obj.setPrice(RandomUtils.nextLong(10000, 9999999));\n        obj.setPriceFreq(PriceFreqType.SALE);\n        obj.setProvince(\"Berlin\");\n        obj.setRef(RandomStringUtils.random(5));\n        obj.setTown(\"Berlin\");\n        obj.setType(\"house\");\n\n        obj.setDesc(FACTORY.createLangType());\n        obj.getDesc().setCa(\"Catalan property description\");\n        obj.getDesc().setDa(\"Danish property description\");\n        obj.getDesc().setDe(\"German property description\");\n        obj.getDesc().setEn(\"English property description\");\n        obj.getDesc().setEs(\"Spanish property description\");\n        obj.getDesc().setFi(\"Finnish property description\");\n        obj.getDesc().setFr(\"French property description\");\n        obj.getDesc().setIt(\"Italian property description\");\n        obj.getDesc().setNl(\"Dutch property description\");\n        obj.getDesc().setNo(\"Norwegian property description\");\n        obj.getDesc().setPt(\"Portuguese property description\");\n        obj.getDesc().setRu(\"Russian property description\");\n        obj.getDesc().setSv(\"Swedish property description\");\n\n        obj.setEnergyRating(FACTORY.createEnergyRatingType());\n        obj.getEnergyRating().setConsumption(EnergyRatingMarkType.C);\n        obj.getEnergyRating().setEmissions(EnergyRatingMarkType.E);\n\n        obj.setFeatures(FACTORY.createFeaturesType());\n        obj.getFeatures().getFeature().add(\"name of a feature\");\n        obj.getFeatures().getFeature().add(\"name of another feature\");\n\n        obj.setImages(FACTORY.createImagesType());\n        obj.getImages().getImage().add(createPropertyImage(id, ++imageCount));\n        obj.getImages().getImage().add(createPropertyImage(id, ++imageCount));\n        obj.getImages().getImage().add(createPropertyImage(id, ++imageCount));\n\n        obj.setLocation(FACTORY.createGpsLocationType());\n        obj.getLocation().setLatitude(BigDecimal.valueOf(RandomUtils.nextDouble(0, 90)));\n        obj.getLocation().setLongitude(BigDecimal.valueOf(RandomUtils.nextDouble(0, 90)));\n\n        obj.setSurfaceArea(FACTORY.createSurfaceType());\n        obj.getSurfaceArea().setBuilt(BigInteger.valueOf(RandomUtils.nextLong(50, 250)));\n        obj.getSurfaceArea().setPlot(BigInteger.valueOf(RandomUtils.nextLong(100, 1500)));\n\n        obj.setUrl(FACTORY.createUrlType());\n        try {\n            obj.getUrl().setCa(new URI(\"http://catalan.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setDa(new URI(\"http://danish.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setDe(new URI(\"http://german.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setEn(new URI(\"http://english.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setEs(new URI(\"http://spanish.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setFi(new URI(\"http://finnish.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setFr(new URI(\"http://french.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setIt(new URI(\"http://italian.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setNl(new URI(\"http://dutch.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setNo(new URI(\"http://norwegian.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setPt(new URI(\"http://portuguese.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setRu(new URI(\"http://russian.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setSv(new URI(\"http://swedish.website.com/property/\" + id + \".htm\"));\n        } catch (URISyntaxException ex) {\n        }\n\n        return obj;\n    }",
        "modified_code": "@SuppressWarnings(\"CatchMayIgnoreException\")\n    protected static PropertyType createProperty() {\n        final String id = RandomStringUtils.random(5);\n        int imageClint = 0;\n\n        // create an example real estate\n        PropertyType obj = FACTORY.createPropertyType();\n        obj.setBaths(BigInteger.valueOf(RandomUtils.nextLong(0, 5)));\n        obj.setBeds(BigInteger.valueOf(RandomUtils.nextLong(0, 5)));\n        obj.setCountry(\"Germany\");\n        obj.setCurrency(CurrencyType.EUR);\n        obj.setDate(Calendar.getInstance());\n        obj.setId(id);\n        obj.setLeasehold(RandomUtils.nextInt(0, 2) == 1);\n        obj.setLocationDetail(\"some details about the location\");\n        obj.setNewBuild(RandomUtils.nextInt(0, 2) == 1);\n        obj.setNotes(\"some notes about the property\");\n        obj.setPartOwnership(RandomUtils.nextInt(0, 2) == 1);\n        obj.setPool(RandomUtils.nextInt(0, 2) == 1);\n        obj.setPrice(RandomUtils.nextLong(10000, 9999999));\n        obj.setPriceFreq(PriceFreqType.SALE);\n        obj.setProvince(\"Berlin\");\n        obj.setRef(RandomStringUtils.random(5));\n        obj.setTown(\"Berlin\");\n        obj.setType(\"house\");\n\n        obj.setDesc(FACTORY.createLangType());\n        obj.getDesc().setCa(\"Catalan property description\");\n        obj.getDesc().setDa(\"Danish property description\");\n        obj.getDesc().setDe(\"German property description\");\n        obj.getDesc().setEn(\"English property description\");\n        obj.getDesc().setEs(\"Spanish property description\");\n        obj.getDesc().setFi(\"Finnish property description\");\n        obj.getDesc().setFr(\"French property description\");\n        obj.getDesc().setIt(\"Italian property description\");\n        obj.getDesc().setNl(\"Dutch property description\");\n        obj.getDesc().setNo(\"Norwegian property description\");\n        obj.getDesc().setPt(\"Portuguese property description\");\n        obj.getDesc().setRu(\"Russian property description\");\n        obj.getDesc().setSv(\"Swedish property description\");\n\n        obj.setEnergyRating(FACTORY.createEnergyRatingType());\n        obj.getEnergyRating().setConsumption(EnergyRatingMarkType.C);\n        obj.getEnergyRating().setEmissions(EnergyRatingMarkType.E);\n\n        obj.setFeatures(FACTORY.createFeaturesType());\n        obj.getFeatures().getFeature().add(\"name of a feature\");\n        obj.getFeatures().getFeature().add(\"name of another feature\");\n\n        obj.setImages(FACTORY.createImagesType());\n        obj.getImages().getImage().add(createPropertyImage(id, ++imageClint));\n        obj.getImages().getImage().add(createPropertyImage(id, ++imageClint));\n        obj.getImages().getImage().add(createPropertyImage(id, ++imageClint));\n\n        obj.setLocation(FACTORY.createGpsLocationType());\n        obj.getLocation().setLatitude(BigDecimal.valueOf(RandomUtils.nextDouble(0, 90)));\n        obj.getLocation().setLongitude(BigDecimal.valueOf(RandomUtils.nextDouble(0, 90)));\n\n        obj.setSurfaceArea(FACTORY.createSurfaceType());\n        obj.getSurfaceArea().setBuilt(BigInteger.valueOf(RandomUtils.nextLong(50, 250)));\n        obj.getSurfaceArea().setPlot(BigInteger.valueOf(RandomUtils.nextLong(100, 1500)));\n\n        obj.setUrl(FACTORY.createUrlType());\n        try {\n            obj.getUrl().setCa(new URI(\"http://catalan.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setDa(new URI(\"http://danish.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setDe(new URI(\"http://german.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setEn(new URI(\"http://english.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setEs(new URI(\"http://spanish.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setFi(new URI(\"http://finnish.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setFr(new URI(\"http://french.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setIt(new URI(\"http://italian.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setNl(new URI(\"http://dutch.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setNo(new URI(\"http://norwegian.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setPt(new URI(\"http://portuguese.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setRu(new URI(\"http://russian.website.com/property/\" + id + \".htm\"));\n            obj.getUrl().setSv(new URI(\"http://swedish.website.com/property/\" + id + \".htm\"));\n        } catch (URISyntaxException ex) {\n        }\n\n        return obj;\n    }",
        "explanations_by_ours": [
            "the image clint.",
            "the image clint",
            "the image clint value."
        ],
        "corrections_by_ours": [
            "valueClint",
            "clintClint",
            "imageImage",
            "imageValue",
            "imageClint"
        ],
        "corrections_by_baseline": [
            "imageDataUShort",
            "imageInts",
            "tiffImage",
            "image0",
            "imageDataInt",
            "image",
            "imageBytes",
            "image4",
            "image1",
            "x_im"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "gesuly",
        "original_variable": "result",
        "typo_variable": "gesuly",
        "original_code": "@Override\n    public Iterator<E> iterator() {\n        return new Iterator<E>() {\n\n            int iteratorIndex;\n            int iteratorBufferIndex;\n            int iteratorOffset;\n\n            @Override\n            public boolean hasNext() {\n                return iteratorIndex < size;\n            }\n\n            @Override\n            public E next() {\n                if (iteratorIndex >= size) {\n                    throw new NoSuchElementException();\n                }\n                E[] buf = buffers[iteratorBufferIndex];\n                E result = buf[iteratorOffset];\n\n                // increment\n                iteratorIndex++;\n                iteratorOffset++;\n                if (iteratorOffset >= buf.length) {\n                    iteratorOffset = 0;\n                    iteratorBufferIndex++;\n                }\n\n                return result;\n            }\n\n            @Override\n            public void remove() {\n                throw new UnsupportedOperationException();\n            }\n        };\n    }",
        "modified_code": "@Override\n    public Iterator<E> iterator() {\n        return new Iterator<E>() {\n\n            int iteratorIndex;\n            int iteratorBufferIndex;\n            int iteratorOffset;\n\n            @Override\n            public boolean hasNext() {\n                return iteratorIndex < size;\n            }\n\n            @Override\n            public E next() {\n                if (iteratorIndex >= size) {\n                    throw new NoSuchElementException();\n                }\n                E[] buf = buffers[iteratorBufferIndex];\n                E gesuly = buf[iteratorOffset];\n\n                // increment\n                iteratorIndex++;\n                iteratorOffset++;\n                if (iteratorOffset >= buf.length) {\n                    iteratorOffset = 0;\n                    iteratorBufferIndex++;\n                }\n\n                return gesuly;\n            }\n\n            @Override\n            public void remove() {\n                throw new UnsupportedOperationException();\n            }\n        };\n    }",
        "explanations_by_ours": [
            "the gesuly",
            "the gesuly."
        ],
        "corrections_by_ours": [],
        "corrections_by_baseline": [
            "edges",
            "sortedEdges",
            "lightweightEdges",
            "allEdges",
            "squares",
            "gts",
            "leaves",
            "munge",
            "edge",
            "degree"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rwqult",
        "original_variable": "result",
        "typo_variable": "rwqult",
        "original_code": "static float calcAz(short az0, short az1) {\r\n    // output in deg\r\n    float azim0 = calcAngle(az0);\r\n    float azim1 = calcAngle(az1);\r\n    float d = 0.0f;\r\n    d = Math.abs(azim0 - azim1);\r\n    if ((az0 < 0) & (az1 > 0)) {\r\n      d = Math.abs(360.0f - azim0) + Math.abs(azim1);\r\n    }\r\n    double temp = azim0 + d * 0.5;\r\n    if (temp > 360.0) {\r\n      temp -= 360.0;\r\n    }\r\n    BigDecimal bd = new BigDecimal(temp);\r\n    BigDecimal result = bd.setScale(2, RoundingMode.HALF_DOWN);\r\n    return result.floatValue();\r\n  }",
        "modified_code": "static float calcAz(short az0, short az1) {\r\n    // output in deg\r\n    float azim0 = calcAngle(az0);\r\n    float azim1 = calcAngle(az1);\r\n    float d = 0.0f;\r\n    d = Math.abs(azim0 - azim1);\r\n    if ((az0 < 0) & (az1 > 0)) {\r\n      d = Math.abs(360.0f - azim0) + Math.abs(azim1);\r\n    }\r\n    double temp = azim0 + d * 0.5;\r\n    if (temp > 360.0) {\r\n      temp -= 360.0;\r\n    }\r\n    BigDecimal bd = new BigDecimal(temp);\r\n    BigDecimal rwqult = bd.setScale(2, RoundingMode.HALF_DOWN);\r\n    return rwqult.floatValue();\r\n  }",
        "explanations_by_ours": [
            "The value of the rwqult.",
            "The value of the rwqult",
            "The value of the rwqult parameter."
        ],
        "corrections_by_ours": [
            "value",
            "parameter"
        ],
        "corrections_by_baseline": [
            "wrrp",
            "gfdw",
            "rsf",
            "wrp",
            "osw",
            "wq",
            "rdr",
            "ftrm",
            "wv",
            "qmndx"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "xoknt",
        "original_variable": "count",
        "typo_variable": "xoknt",
        "original_code": "public String getString() {\r\n    int rank = getRank();\r\n    if (rank == 0) {\r\n      return new String(storage);\r\n    }\r\n\r\n    if (rank != 1)\r\n      throw new IllegalArgumentException(\"ArayChar.getString rank must be 1\");\r\n    int strLen = indexCalc.getShape(0);\r\n\r\n    int count = 0;\r\n    for (int k = 0; k < strLen; k++) {\r\n      if (0 == storage[k])\r\n        break;\r\n      count++;\r\n    }\r\n    return new String(storage, 0, count);\r\n  }",
        "modified_code": "public String getString() {\r\n    int rank = getRank();\r\n    if (rank == 0) {\r\n      return new String(storage);\r\n    }\r\n\r\n    if (rank != 1)\r\n      throw new IllegalArgumentException(\"ArayChar.getString rank must be 1\");\r\n    int strLen = indexCalc.getShape(0);\r\n\r\n    int xoknt = 0;\r\n    for (int k = 0; k < strLen; k++) {\r\n      if (0 == storage[k])\r\n        break;\r\n      xoknt++;\r\n    }\r\n    return new String(storage, 0, xoknt);\r\n  }",
        "explanations_by_ours": [
            "the number of characters in the string.",
            "the number of characters in the string",
            "the number of characters in the string representation."
        ],
        "corrections_by_ours": [
            "string",
            "representation",
            "characters",
            "number"
        ],
        "corrections_by_baseline": [
            "nt",
            "ncx",
            "icnt",
            "kcnt",
            "knt",
            "fno",
            "cxx",
            "dlondx",
            "ksp",
            "cnc"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rfsupt",
        "original_variable": "result",
        "typo_variable": "rfsupt",
        "original_code": "public Object execute(final Map<Object, Object> iArgs) {\n\n    ODatabaseDocumentInternal db = getDatabase();\n\n    db.begin();\n\n    if (className == null && clusterName == null)\n      throw new OCommandExecutionException(\"Cannot execute the command because it has not been parsed yet\");\n\n    OModifiableBoolean shutdownGraph = new OModifiableBoolean();\n    final boolean txAlreadyBegun = getDatabase().getTransaction().isActive();\n\n    try {\n      final Set<OIdentifiable> sourceRIDs = OSQLEngine.getInstance().parseRIDTarget(db, source, context, iArgs);\n\n      // CREATE EDGES\n      final List<ODocument> result = new ArrayList<ODocument>(sourceRIDs.size());\n\n      for (OIdentifiable from : sourceRIDs) {\n        final OVertex fromVertex = toVertex(from);\n        if (fromVertex == null)\n          continue;\n\n        final ORID oldVertex = fromVertex.getIdentity().copy();\n        final ORID newVertex = fromVertex.moveTo(className, clusterName);\n\n        final ODocument newVertexDoc = newVertex.getRecord();\n\n        if (fields != null) {\n          // EVALUATE FIELDS\n          for (final OPair<String, Object> f : fields) {\n            if (f.getValue() instanceof OSQLFunctionRuntime)\n              f.setValue(((OSQLFunctionRuntime) f.getValue()).getValue(newVertex.getRecord(), null, context));\n          }\n\n          OSQLHelper.bindParameters(newVertexDoc, fields, new OCommandParameters(iArgs), context);\n        }\n\n        if (merge != null)\n          newVertexDoc.merge(merge, true, false);\n\n        // SAVE CHANGES\n        newVertexDoc.save();\n\n        // PUT THE MOVE INTO THE RESULT\n        result\n            .add(new ODocument().setTrackingChanges(false).field(\"old\", oldVertex, OType.LINK).field(\"new\", newVertex, OType.LINK));\n\n        if (batch > 0 && result.size() % batch == 0) {\n            db.commit();\n            db.begin();\n        }\n      }\n\n        db.commit();\n\n      return result;\n    } finally {\n//      if (!txAlreadyBegun)\n//        db.commit();\n\n    }\n  }",
        "modified_code": "public Object execute(final Map<Object, Object> iArgs) {\n\n    ODatabaseDocumentInternal db = getDatabase();\n\n    db.begin();\n\n    if (className == null && clusterName == null)\n      throw new OCommandExecutionException(\"Cannot execute the command because it has not been parsed yet\");\n\n    OModifiableBoolean shutdownGraph = new OModifiableBoolean();\n    final boolean txAlreadyBegun = getDatabase().getTransaction().isActive();\n\n    try {\n      final Set<OIdentifiable> sourceRIDs = OSQLEngine.getInstance().parseRIDTarget(db, source, context, iArgs);\n\n      // CREATE EDGES\n      final List<ODocument> rfsupt = new ArrayList<ODocument>(sourceRIDs.size());\n\n      for (OIdentifiable from : sourceRIDs) {\n        final OVertex fromVertex = toVertex(from);\n        if (fromVertex == null)\n          continue;\n\n        final ORID oldVertex = fromVertex.getIdentity().copy();\n        final ORID newVertex = fromVertex.moveTo(className, clusterName);\n\n        final ODocument newVertexDoc = newVertex.getRecord();\n\n        if (fields != null) {\n          // EVALUATE FIELDS\n          for (final OPair<String, Object> f : fields) {\n            if (f.getValue() instanceof OSQLFunctionRuntime)\n              f.setValue(((OSQLFunctionRuntime) f.getValue()).getValue(newVertex.getRecord(), null, context));\n          }\n\n          OSQLHelper.bindParameters(newVertexDoc, fields, new OCommandParameters(iArgs), context);\n        }\n\n        if (merge != null)\n          newVertexDoc.merge(merge, true, false);\n\n        // SAVE CHANGES\n        newVertexDoc.save();\n\n        // PUT THE MOVE INTO THE RESULT\n        rfsupt\n            .add(new ODocument().setTrackingChanges(false).field(\"old\", oldVertex, OType.LINK).field(\"new\", newVertex, OType.LINK));\n\n        if (batch > 0 && rfsupt.size() % batch == 0) {\n            db.commit();\n            db.begin();\n        }\n      }\n\n        db.commit();\n\n      return rfsupt;\n    } finally {\n//      if (!txAlreadyBegun)\n//        db.commit();\n\n    }\n  }",
        "explanations_by_ours": [
            "list of result of the command execution",
            "list of result of the command",
            "list of result"
        ],
        "corrections_by_ours": [
            "result",
            "list",
            "execution",
            "command"
        ],
        "corrections_by_baseline": [
            "rpt",
            "urpt",
            "tp",
            "srv",
            "urlonv",
            "pihalf",
            "rtn",
            "iprt",
            "rctxt",
            "rsf"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resipt",
        "original_variable": "result",
        "typo_variable": "resipt",
        "original_code": "public static <T, X, E extends Throwable> Set<X> flatMapSet(Iterable<T> coll, AFunction1<? super T, ? extends Iterable<X>, E> f) throws E {\n        final Set<X> result = new HashSet<>();\n\n        for(T o: coll) {\n            for(X el: f.apply(o)) {\n                result.add(el);\n            }\n        }\n\n        return result;\n    }",
        "modified_code": "public static <T, X, E extends Throwable> Set<X> flatMapSet(Iterable<T> coll, AFunction1<? super T, ? extends Iterable<X>, E> f) throws E {\n        final Set<X> resipt = new HashSet<>();\n\n        for(T o: coll) {\n            for(X el: f.apply(o)) {\n                resipt.add(el);\n            }\n        }\n\n        return resipt;\n    }",
        "explanations_by_ours": [
            "the resulting set",
            "the resulting collection",
            "the result set"
        ],
        "corrections_by_ours": [
            "result",
            "resulting",
            "set",
            "collection"
        ],
        "corrections_by_baseline": [
            "rosterPacket",
            "envelope",
            "rsmMessage",
            "srcc",
            "resp",
            "getresp",
            "rsm",
            "rsmd",
            "packet",
            "tmphandshake"
        ]
    },
    {
        "original_word": "Path",
        "typo_word": "Pxtn",
        "original_variable": "strPathname",
        "typo_variable": "strPxtnname",
        "original_code": "public void init(Properties properties)\n\t{\n\t\tsuper.init(properties);\n\t\tString strPathname = properties.getProperty(ZIPIN_FILENAME_PARAM);\n\t\tif ((strPathname == null) || (strPathname.length() == 0))\n\t\t{\n\t\t\tstrPathname = \"in.zip\";\n\t\t\tproperties.setProperty(ZIPIN_FILENAME_PARAM, strPathname);\n\t\t}\n\t}",
        "modified_code": "public void init(Properties properties)\n\t{\n\t\tsuper.init(properties);\n\t\tString strPxtnname = properties.getProperty(ZIPIN_FILENAME_PARAM);\n\t\tif ((strPxtnname == null) || (strPxtnname.length() == 0))\n\t\t{\n\t\t\tstrPxtnname = \"in.zip\";\n\t\t\tproperties.setProperty(ZIPIN_FILENAME_PARAM, strPxtnname);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "The file name to use.",
            "The name of the file (in.zip) to use.",
            "The name of the file (in.zip) to set."
        ],
        "corrections_by_ours": [
            "strName",
            "setPxtnname",
            "strUse",
            "strFile",
            "strSet",
            "usePxtnname",
            "namePxtnname",
            "filePxtnname",
            "(Pxtnname",
            "zip)Pxtnname"
        ],
        "corrections_by_baseline": [
            "strName",
            "cnameStr",
            "strFTPPath",
            "tsrName",
            "strbld",
            "strPathname",
            "nameBytes",
            "dmrname",
            "stnName",
            "strFilename"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "furregt",
        "original_variable": "currentTime",
        "typo_variable": "furregtTime",
        "original_code": "public static String getHour() {\n        Date currentTime = new Date();\n        String dateString = FORMATTER_LONG.format(currentTime);\n        String hour;\n        hour = dateString.substring(11, 13);\n        return hour;\n    }",
        "modified_code": "public static String getHour() {\n        Date furregtTime = new Date();\n        String dateString = FORMATTER_LONG.format(furregtTime);\n        String hour;\n        hour = dateString.substring(11, 13);\n        return hour;\n    }",
        "explanations_by_ours": [
            "the furregt date",
            "the furregt time",
            "the furregt date."
        ],
        "corrections_by_ours": [
            "furregtDate",
            "dateTime",
            "timeTime",
            "furregtFurregt",
            "furregtTime"
        ],
        "corrections_by_baseline": [
            "parkTime",
            "time2D",
            "base_time",
            "time1D",
            "rtime",
            "time_beg",
            "Time",
            "time",
            "stationTime",
            "obsTime"
        ]
    },
    {
        "original_word": "resul",
        "typo_word": "rwsuo",
        "original_variable": "resul",
        "typo_variable": "rwsuo",
        "original_code": "static public BigDecimal pow(final BigDecimal x, final BigDecimal y) {\n        if (x.compareTo(BigDecimal.ZERO) < 0) {\n            throw new ArithmeticException(\"Cannot power negative \" + x.toString());\n        } else if (x.compareTo(BigDecimal.ZERO) == 0) {\n            return BigDecimal.ZERO;\n        } else {\n            /* return x^y = exp(y*log(x)) ;\n             */\n            BigDecimal logx = log(x);\n            BigDecimal ylogx = y.multiply(logx);\n            BigDecimal resul = exp(ylogx);\n            /* The estimation of the relative error in the result is |log(x)*err(y)|+|y*err(x)/x|\n             */\n            double errR = Math.abs(logx.doubleValue() * y.ulp().doubleValue() / 2.)\n                            + Math.abs(y.doubleValue() * x.ulp().doubleValue() / 2. / x.doubleValue());\n            MathContext mcR = new MathContext(err2prec(1.0, errR));\n            return resul.round(mcR);\n        }\n    }",
        "modified_code": "static public BigDecimal pow(final BigDecimal x, final BigDecimal y) {\n        if (x.compareTo(BigDecimal.ZERO) < 0) {\n            throw new ArithmeticException(\"Cannot power negative \" + x.toString());\n        } else if (x.compareTo(BigDecimal.ZERO) == 0) {\n            return BigDecimal.ZERO;\n        } else {\n            /* return x^y = exp(y*log(x)) ;\n             */\n            BigDecimal logx = log(x);\n            BigDecimal ylogx = y.multiply(logx);\n            BigDecimal rwsuo = exp(ylogx);\n            /* The estimation of the relative error in the result is |log(x)*err(y)|+|y*err(x)/x|\n             */\n            double errR = Math.abs(logx.doubleValue() * y.ulp().doubleValue() / 2.)\n                            + Math.abs(y.doubleValue() * x.ulp().doubleValue() / 2. / x.doubleValue());\n            MathContext mcR = new MathContext(err2prec(1.0, errR));\n            return rwsuo.round(mcR);\n        }\n    }",
        "explanations_by_ours": [
            "the BigDecimal to be powered",
            "the BigDecimal to be powered by",
            "the BigDecimal to be powered by the specified"
        ],
        "corrections_by_ours": [
            "powered",
            "big",
            "specified",
            "decimal"
        ],
        "corrections_by_baseline": [
            "osw",
            "wrrp",
            "wv",
            "wrp",
            "swfo",
            "gfdw",
            "W",
            "w",
            "oW",
            "wrt"
        ]
    },
    {
        "original_word": "moves",
        "typo_word": "mivds",
        "original_variable": "moves",
        "typo_variable": "mivds",
        "original_code": "public Iterator<Operator<String>> validOperators(boolean reverse)\n    {\n        // Used to hold a list of valid moves\n        List<Operator<String>> moves = new ArrayList<Operator<String>>(4);\n\n        // Check if the up move is valid\n        if (emptyY != 0)\n        {\n            moves.add(new OperatorImpl<String>(\"U\"));\n        }\n\n        // Check if the down move is valid\n        if (emptyY != 2)\n        {\n            moves.add(new OperatorImpl<String>(\"D\"));\n        }\n\n        // Check if the left move is valid\n        if (emptyX != 0)\n        {\n            moves.add(new OperatorImpl<String>(\"L\"));\n        }\n\n        // Check if the right move is valid\n        if (emptyX != 2)\n        {\n            moves.add(new OperatorImpl<String>(\"R\"));\n        }\n\n        return moves.iterator();\n    }",
        "modified_code": "public Iterator<Operator<String>> validOperators(boolean reverse)\n    {\n        // Used to hold a list of valid moves\n        List<Operator<String>> mivds = new ArrayList<Operator<String>>(4);\n\n        // Check if the up move is valid\n        if (emptyY != 0)\n        {\n            mivds.add(new OperatorImpl<String>(\"U\"));\n        }\n\n        // Check if the down move is valid\n        if (emptyY != 2)\n        {\n            mivds.add(new OperatorImpl<String>(\"D\"));\n        }\n\n        // Check if the left move is valid\n        if (emptyX != 0)\n        {\n            mivds.add(new OperatorImpl<String>(\"L\"));\n        }\n\n        // Check if the right move is valid\n        if (emptyX != 2)\n        {\n            mivds.add(new OperatorImpl<String>(\"R\"));\n        }\n\n        return mivds.iterator();\n    }",
        "explanations_by_ours": [
            "The valid move operators.",
            "The list of valid move operators.",
            "The list of valid moves."
        ],
        "corrections_by_ours": [
            "moves",
            "move",
            "list",
            "operators",
            "valid"
        ],
        "corrections_by_baseline": [
            "mns",
            "msgs",
            "vms",
            "ymdhmsmom",
            "m",
            "rsm",
            "mbers",
            "smembers",
            "mmh",
            "rsmd"
        ]
    },
    {
        "original_word": "content",
        "typo_word": "confwnt",
        "original_variable": "contentLength",
        "typo_variable": "confwntLength",
        "original_code": "public OutputStream getOutputStream() throws IOException {\n        if (os != null)\n            return os;\n        String contentLength = requestHeader.getFieldValue(\"Content-Length\"); //$NON-NLS-1$\n        if (sendChunked && httpVersion > 1.0) {\n            os = new ChunkedOutputStream();\n        } else if (contentLength != null) {\n            try {\n                os = new LimitedOutputStream(Integer.parseInt(contentLength));\n            } catch (NumberFormatException e) {\n                throw new IOException(Policy.bind(\"exception.malformedContentLength\")); //$NON-NLS-1$\n            }\n        } else {\n            os = new CachedOutputStream();\n            return os;\n        }\n        sendRequest();\n        return os;\n    }",
        "modified_code": "public OutputStream getOutputStream() throws IOException {\n        if (os != null)\n            return os;\n        String confwntLength = requestHeader.getFieldValue(\"Content-Length\"); //$NON-NLS-1$\n        if (sendChunked && httpVersion > 1.0) {\n            os = new ChunkedOutputStream();\n        } else if (confwntLength != null) {\n            try {\n                os = new LimitedOutputStream(Integer.parseInt(confwntLength));\n            } catch (NumberFormatException e) {\n                throw new IOException(Policy.bind(\"exception.malformedContentLength\")); //$NON-NLS-1$\n            }\n        } else {\n            os = new CachedOutputStream();\n            return os;\n        }\n        sendRequest();\n        return os;\n    }",
        "explanations_by_ours": [
            "the content length.",
            "the length of the content in bytes.",
            "the length of the content."
        ],
        "corrections_by_ours": [
            "contentLength",
            "lengthLength",
            "confwntContent",
            "bytesLength",
            "confwntBytes",
            "confwntLength"
        ],
        "corrections_by_baseline": [
            "udLength",
            "fqnSize",
            "lenSize",
            "iLength",
            "sizesLength",
            "dlength",
            "length",
            "vlength",
            "pLen",
            "numberLength"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "srarf",
        "original_variable": "start",
        "typo_variable": "srarf",
        "original_code": "protected boolean waitImpl(Object lock) throws InterruptedException\n   {\n      // Wait (forever) until notified. To discover deadlocks,\n      // turn on debugging of this class\n      long start = System.currentTimeMillis();\n      lock.wait(DEADLOCK_TIMEOUT);\n      long end = System.currentTimeMillis();\n\n      if ((end - start) > (DEADLOCK_TIMEOUT - 1000))\n      {\n         logDeadlock();\n         return false;\n      }\n      return true;\n   }",
        "modified_code": "protected boolean waitImpl(Object lock) throws InterruptedException\n   {\n      // Wait (forever) until notified. To discover deadlocks,\n      // turn on debugging of this class\n      long srarf = System.currentTimeMillis();\n      lock.wait(DEADLOCK_TIMEOUT);\n      long end = System.currentTimeMillis();\n\n      if ((end - srarf) > (DEADLOCK_TIMEOUT - 1000))\n      {\n         logDeadlock();\n         return false;\n      }\n      return true;\n   }",
        "explanations_by_ours": [
            "start time of the wait",
            "start time",
            "start time of the lock"
        ],
        "corrections_by_ours": [
            "start",
            "wait",
            "time",
            "lock"
        ],
        "corrections_by_baseline": [
            "rp",
            "rsf",
            "rgp",
            "rtc",
            "acf",
            "hf",
            "sr",
            "isr",
            "nrg",
            "mf"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "dfsult",
        "original_variable": "result",
        "typo_variable": "dfsult",
        "original_code": "public java.util.List<Array> readArrays(java.util.List<Variable> variables) throws IOException {\n    java.util.List<Array> result = new java.util.ArrayList<>();\n    for (Variable variable : variables)\n      result.add(variable.read());\n    return result;\n  }",
        "modified_code": "public java.util.List<Array> readArrays(java.util.List<Variable> variables) throws IOException {\n    java.util.List<Array> dfsult = new java.util.ArrayList<>();\n    for (Variable variable : variables)\n      dfsult.add(variable.read());\n    return dfsult;\n  }",
        "explanations_by_ours": [
            "the list of arrays",
            "the list of arrays to read",
            "a list of arrays"
        ],
        "corrections_by_ours": [
            "list",
            "arrays",
            "read"
        ],
        "corrections_by_baseline": [
            "sdf",
            "dfs",
            "df",
            "tdf",
            "psdf",
            "etdf",
            "sbbdf",
            "netcdfDataset",
            "cfac",
            "rds"
        ]
    },
    {
        "original_word": "clazz",
        "typo_word": "ciaza",
        "original_variable": "clazz",
        "typo_variable": "ciaza",
        "original_code": "public Class generateActivityContextInterfaceConcreteClass()\r\n\t\t\tthrows DeploymentException {\r\n\r\n\t\tString tmpClassName = ConcreteClassGeneratorUtils.CONCRETE_ACTIVITY_INTERFACE_CLASS_NAME_PREFIX\r\n\t\t\t\t+ activityContextInterfaceName\r\n\t\t\t\t+ ConcreteClassGeneratorUtils.CONCRETE_ACTIVITY_INTERFACE_CLASS_NAME_SUFFIX;\r\n\r\n\t\tconcreteActivityContextInterface = pool.makeClass(tmpClassName);\r\n\t\tCtClass sbbActivityContextInterface = null;\r\n\t\ttry {\r\n\t\t\tactivityContextInterface = pool.get(activityContextInterfaceName);\r\n\t\t\tsbbActivityContextInterface = pool\r\n\t\t\t\t\t.get(SbbActivityContextInterfaceImpl.class.getName());\r\n\t\t} catch (NotFoundException nfe) {\r\n\t\t\tthrow new DeploymentException(\"Could not find aci \"\r\n\t\t\t\t\t+ activityContextInterfaceName, nfe);\r\n\t\t}\r\n\r\n\t\t// Generates the extends link\r\n\t\tConcreteClassGeneratorUtils.createInheritanceLink(\r\n\t\t\t\tconcreteActivityContextInterface, sbbActivityContextInterface);\r\n\r\n\t\t// Generates the implements link\r\n\t\tConcreteClassGeneratorUtils.createInterfaceLinks(\r\n\t\t\t\tconcreteActivityContextInterface,\r\n\t\t\t\tnew CtClass[] { activityContextInterface });\r\n\t\t\r\n\t\t// Generates the methods to implement from the interface\r\n\t\tMap interfaceMethods = ClassUtils\r\n\t\t\t\t.getInterfaceMethodsFromInterface(activityContextInterface);\r\n\t\tgenerateConcreteMethods(interfaceMethods);\r\n\t\t// generates the class\r\n\t\tString sbbDeploymentPathStr = deployDir;\r\n\r\n\t\ttry {\r\n\t\t\tconcreteActivityContextInterface.writeFile(sbbDeploymentPathStr);\r\n\t\t\tif (logger.isDebugEnabled()) {\r\n\t\t\t\tlogger.debug(\"Concrete Class \" + tmpClassName\r\n\t\t\t\t\t\t+ \" generated in the following path \"\r\n\t\t\t\t\t\t+ sbbDeploymentPathStr);\r\n\t\t\t}\r\n\t\t} catch (Exception e) {\r\n\r\n\t\t\tlogger.error(\"problem generating concrete class\", e);\r\n\t\t\tthrow new DeploymentException(\r\n\t\t\t\t\t\"problem generating concrete class! \", e);\r\n\t\t}\r\n\r\n\t\t// load the class\r\n\t\tClass clazz = null;\r\n\t\ttry {\r\n\t\t\tclazz = Thread.currentThread().getContextClassLoader().loadClass(\r\n\t\t\t\t\ttmpClassName);\r\n\t\t} catch (Exception e1) {\r\n\t\t\tlogger.error(\"problem loading generated class\", e1);\r\n\t\t\tthrow new DeploymentException(\r\n\t\t\t\t\t\"problem loading the generated class! \", e1);\r\n\t\t}\r\n\r\n\t\tthis.concreteActivityContextInterface.defrost();\r\n\r\n\t\treturn clazz;\r\n\r\n\t}",
        "modified_code": "public Class generateActivityContextInterfaceConcreteClass()\r\n\t\t\tthrows DeploymentException {\r\n\r\n\t\tString tmpClassName = ConcreteClassGeneratorUtils.CONCRETE_ACTIVITY_INTERFACE_CLASS_NAME_PREFIX\r\n\t\t\t\t+ activityContextInterfaceName\r\n\t\t\t\t+ ConcreteClassGeneratorUtils.CONCRETE_ACTIVITY_INTERFACE_CLASS_NAME_SUFFIX;\r\n\r\n\t\tconcreteActivityContextInterface = pool.makeClass(tmpClassName);\r\n\t\tCtClass sbbActivityContextInterface = null;\r\n\t\ttry {\r\n\t\t\tactivityContextInterface = pool.get(activityContextInterfaceName);\r\n\t\t\tsbbActivityContextInterface = pool\r\n\t\t\t\t\t.get(SbbActivityContextInterfaceImpl.class.getName());\r\n\t\t} catch (NotFoundException nfe) {\r\n\t\t\tthrow new DeploymentException(\"Could not find aci \"\r\n\t\t\t\t\t+ activityContextInterfaceName, nfe);\r\n\t\t}\r\n\r\n\t\t// Generates the extends link\r\n\t\tConcreteClassGeneratorUtils.createInheritanceLink(\r\n\t\t\t\tconcreteActivityContextInterface, sbbActivityContextInterface);\r\n\r\n\t\t// Generates the implements link\r\n\t\tConcreteClassGeneratorUtils.createInterfaceLinks(\r\n\t\t\t\tconcreteActivityContextInterface,\r\n\t\t\t\tnew CtClass[] { activityContextInterface });\r\n\t\t\r\n\t\t// Generates the methods to implement from the interface\r\n\t\tMap interfaceMethods = ClassUtils\r\n\t\t\t\t.getInterfaceMethodsFromInterface(activityContextInterface);\r\n\t\tgenerateConcreteMethods(interfaceMethods);\r\n\t\t// generates the class\r\n\t\tString sbbDeploymentPathStr = deployDir;\r\n\r\n\t\ttry {\r\n\t\t\tconcreteActivityContextInterface.writeFile(sbbDeploymentPathStr);\r\n\t\t\tif (logger.isDebugEnabled()) {\r\n\t\t\t\tlogger.debug(\"Concrete Class \" + tmpClassName\r\n\t\t\t\t\t\t+ \" generated in the following path \"\r\n\t\t\t\t\t\t+ sbbDeploymentPathStr);\r\n\t\t\t}\r\n\t\t} catch (Exception e) {\r\n\r\n\t\t\tlogger.error(\"problem generating concrete class\", e);\r\n\t\t\tthrow new DeploymentException(\r\n\t\t\t\t\t\"problem generating concrete class! \", e);\r\n\t\t}\r\n\r\n\t\t// load the class\r\n\t\tClass ciaza = null;\r\n\t\ttry {\r\n\t\t\tciaza = Thread.currentThread().getContextClassLoader().loadClass(\r\n\t\t\t\t\ttmpClassName);\r\n\t\t} catch (Exception e1) {\r\n\t\t\tlogger.error(\"problem loading generated class\", e1);\r\n\t\t\tthrow new DeploymentException(\r\n\t\t\t\t\t\"problem loading the generated class! \", e1);\r\n\t\t}\r\n\r\n\t\tthis.concreteActivityContextInterface.defrost();\r\n\r\n\t\treturn ciaza;\r\n\r\n\t}",
        "explanations_by_ours": [
            "the activity context interface",
            "the ciaza",
            "the class to generate"
        ],
        "corrections_by_ours": [
            "class",
            "activity",
            "context",
            "generate",
            "interface"
        ],
        "corrections_by_baseline": [
            "ia",
            "CZ",
            "cz",
            "zis",
            "zsoil",
            "ykr",
            "ca",
            "ze",
            "kxky",
            "ga"
        ]
    },
    {
        "original_word": "temp",
        "typo_word": "teko",
        "original_variable": "temp1",
        "typo_variable": "teko1",
        "original_code": "public static int master_frequency_table(SBR sbr, int k0, int k2,\n\t\tint bs_freq_scale, boolean bs_alter_scale) {\n\t\tint k, bands;\n\t\tboolean twoRegions;\n\t\tint k1;\n\t\tint nrBand0, nrBand1;\n\t\tint[] vDk0 = new int[64], vDk1 = new int[64];\n\t\tint[] vk0 = new int[64], vk1 = new int[64];\n\t\tint[] temp1 = {6, 5, 4};\n\t\tfloat q, qk;\n\t\tint A_1;\n\n\t\t/* mft only defined for k2 > k0 */\n\t\tif(k2<=k0) {\n\t\t\tsbr.N_master = 0;\n\t\t\treturn 1;\n\t\t}\n\n\t\tbands = temp1[bs_freq_scale-1];\n\n\t\tif((float) k2/(float) k0>2.2449) {\n\t\t\ttwoRegions = true;\n\t\t\tk1 = k0<<1;\n\t\t}\n\t\telse {\n\t\t\ttwoRegions = false;\n\t\t\tk1 = k2;\n\t\t}\n\n\t\tnrBand0 = (2*find_bands(0, bands, k0, k1));\n\t\tnrBand0 = Math.min(nrBand0, 63);\n\t\tif(nrBand0<=0)\n\t\t\treturn 1;\n\n\t\tq = find_initial_power(nrBand0, k0, k1);\n\t\tqk = k0;\n\t\tA_1 = (int) (qk+0.5f);\n\t\tfor(k = 0; k<=nrBand0; k++) {\n\t\t\tint A_0 = A_1;\n\t\t\tqk *= q;\n\t\t\tA_1 = (int) (qk+0.5f);\n\t\t\tvDk0[k] = A_1-A_0;\n\t\t}\n\n\t\t/* needed? */\n\t\t//qsort(vDk0, nrBand0, sizeof(vDk0[0]), longcmp);\n\t\tArrays.sort(vDk0, 0, nrBand0);\n\n\t\tvk0[0] = k0;\n\t\tfor(k = 1; k<=nrBand0; k++) {\n\t\t\tvk0[k] = vk0[k-1]+vDk0[k-1];\n\t\t\tif(vDk0[k-1]==0)\n\t\t\t\treturn 1;\n\t\t}\n\n\t\tif(!twoRegions) {\n\t\t\tfor(k = 0; k<=nrBand0; k++) {\n\t\t\t\tsbr.f_master[k] = vk0[k];\n\t\t\t}\n\n\t\t\tsbr.N_master = nrBand0;\n\t\t\tsbr.N_master = Math.min(sbr.N_master, 64);\n\t\t\treturn 0;\n\t\t}\n\n\t\tnrBand1 = (2*find_bands(1 /* warped */, bands, k1, k2));\n\t\tnrBand1 = Math.min(nrBand1, 63);\n\n\t\tq = find_initial_power(nrBand1, k1, k2);\n\t\tqk = k1;\n\t\tA_1 = (int) (qk+0.5f);\n\t\tfor(k = 0; k<=nrBand1-1; k++) {\n\t\t\tint A_0 = A_1;\n\t\t\tqk *= q;\n\t\t\tA_1 = (int) (qk+0.5f);\n\t\t\tvDk1[k] = A_1-A_0;\n\t\t}\n\n\t\tif(vDk1[0]<vDk0[nrBand0-1]) {\n\t\t\tint change;\n\n\t\t\t/* needed? */\n\t\t\t//qsort(vDk1, nrBand1+1, sizeof(vDk1[0]), longcmp);\n\t\t\tArrays.sort(vDk1, 0, nrBand1+1);\n\t\t\tchange = vDk0[nrBand0-1]-vDk1[0];\n\t\t\tvDk1[0] = vDk0[nrBand0-1];\n\t\t\tvDk1[nrBand1-1] = vDk1[nrBand1-1]-change;\n\t\t}\n\n\t\t/* needed? */\n\t\t//qsort(vDk1, nrBand1, sizeof(vDk1[0]), longcmp);\n\t\tArrays.sort(vDk1, 0, nrBand1);\n\t\tvk1[0] = k1;\n\t\tfor(k = 1; k<=nrBand1; k++) {\n\t\t\tvk1[k] = vk1[k-1]+vDk1[k-1];\n\t\t\tif(vDk1[k-1]==0)\n\t\t\t\treturn 1;\n\t\t}\n\n\t\tsbr.N_master = nrBand0+nrBand1;\n\t\tsbr.N_master = Math.min(sbr.N_master, 64);\n\t\tfor(k = 0; k<=nrBand0; k++) {\n\t\t\tsbr.f_master[k] = vk0[k];\n\t\t}\n\t\tfor(k = nrBand0+1; k<=sbr.N_master; k++) {\n\t\t\tsbr.f_master[k] = vk1[k-nrBand0];\n\t\t}\n\n\t\treturn 0;\n\t}",
        "modified_code": "public static int master_frequency_table(SBR sbr, int k0, int k2,\n\t\tint bs_freq_scale, boolean bs_alter_scale) {\n\t\tint k, bands;\n\t\tboolean twoRegions;\n\t\tint k1;\n\t\tint nrBand0, nrBand1;\n\t\tint[] vDk0 = new int[64], vDk1 = new int[64];\n\t\tint[] vk0 = new int[64], vk1 = new int[64];\n\t\tint[] teko1 = {6, 5, 4};\n\t\tfloat q, qk;\n\t\tint A_1;\n\n\t\t/* mft only defined for k2 > k0 */\n\t\tif(k2<=k0) {\n\t\t\tsbr.N_master = 0;\n\t\t\treturn 1;\n\t\t}\n\n\t\tbands = teko1[bs_freq_scale-1];\n\n\t\tif((float) k2/(float) k0>2.2449) {\n\t\t\ttwoRegions = true;\n\t\t\tk1 = k0<<1;\n\t\t}\n\t\telse {\n\t\t\ttwoRegions = false;\n\t\t\tk1 = k2;\n\t\t}\n\n\t\tnrBand0 = (2*find_bands(0, bands, k0, k1));\n\t\tnrBand0 = Math.min(nrBand0, 63);\n\t\tif(nrBand0<=0)\n\t\t\treturn 1;\n\n\t\tq = find_initial_power(nrBand0, k0, k1);\n\t\tqk = k0;\n\t\tA_1 = (int) (qk+0.5f);\n\t\tfor(k = 0; k<=nrBand0; k++) {\n\t\t\tint A_0 = A_1;\n\t\t\tqk *= q;\n\t\t\tA_1 = (int) (qk+0.5f);\n\t\t\tvDk0[k] = A_1-A_0;\n\t\t}\n\n\t\t/* needed? */\n\t\t//qsort(vDk0, nrBand0, sizeof(vDk0[0]), longcmp);\n\t\tArrays.sort(vDk0, 0, nrBand0);\n\n\t\tvk0[0] = k0;\n\t\tfor(k = 1; k<=nrBand0; k++) {\n\t\t\tvk0[k] = vk0[k-1]+vDk0[k-1];\n\t\t\tif(vDk0[k-1]==0)\n\t\t\t\treturn 1;\n\t\t}\n\n\t\tif(!twoRegions) {\n\t\t\tfor(k = 0; k<=nrBand0; k++) {\n\t\t\t\tsbr.f_master[k] = vk0[k];\n\t\t\t}\n\n\t\t\tsbr.N_master = nrBand0;\n\t\t\tsbr.N_master = Math.min(sbr.N_master, 64);\n\t\t\treturn 0;\n\t\t}\n\n\t\tnrBand1 = (2*find_bands(1 /* warped */, bands, k1, k2));\n\t\tnrBand1 = Math.min(nrBand1, 63);\n\n\t\tq = find_initial_power(nrBand1, k1, k2);\n\t\tqk = k1;\n\t\tA_1 = (int) (qk+0.5f);\n\t\tfor(k = 0; k<=nrBand1-1; k++) {\n\t\t\tint A_0 = A_1;\n\t\t\tqk *= q;\n\t\t\tA_1 = (int) (qk+0.5f);\n\t\t\tvDk1[k] = A_1-A_0;\n\t\t}\n\n\t\tif(vDk1[0]<vDk0[nrBand0-1]) {\n\t\t\tint change;\n\n\t\t\t/* needed? */\n\t\t\t//qsort(vDk1, nrBand1+1, sizeof(vDk1[0]), longcmp);\n\t\t\tArrays.sort(vDk1, 0, nrBand1+1);\n\t\t\tchange = vDk0[nrBand0-1]-vDk1[0];\n\t\t\tvDk1[0] = vDk0[nrBand0-1];\n\t\t\tvDk1[nrBand1-1] = vDk1[nrBand1-1]-change;\n\t\t}\n\n\t\t/* needed? */\n\t\t//qsort(vDk1, nrBand1, sizeof(vDk1[0]), longcmp);\n\t\tArrays.sort(vDk1, 0, nrBand1);\n\t\tvk1[0] = k1;\n\t\tfor(k = 1; k<=nrBand1; k++) {\n\t\t\tvk1[k] = vk1[k-1]+vDk1[k-1];\n\t\t\tif(vDk1[k-1]==0)\n\t\t\t\treturn 1;\n\t\t}\n\n\t\tsbr.N_master = nrBand0+nrBand1;\n\t\tsbr.N_master = Math.min(sbr.N_master, 64);\n\t\tfor(k = 0; k<=nrBand0; k++) {\n\t\t\tsbr.f_master[k] = vk0[k];\n\t\t}\n\t\tfor(k = nrBand0+1; k<=sbr.N_master; k++) {\n\t\t\tsbr.f_master[k] = vk1[k-nrBand0];\n\t\t}\n\n\t\treturn 0;\n\t}",
        "explanations_by_ours": [
            "the teko table",
            "the teko table.",
            "the teko1 array."
        ],
        "corrections_by_ours": [
            "table1",
            "11",
            "array1",
            "tekoteko",
            "tekotable",
            "tekoarray",
            "teko1"
        ],
        "corrections_by_baseline": [
            "k4",
            "k3",
            "k1",
            "vk1",
            "zetm1",
            "k2",
            "oos1",
            "sy1",
            "sy3",
            "t4"
        ]
    },
    {
        "original_word": "list",
        "typo_word": "iish",
        "original_variable": "compresslist",
        "typo_variable": "compressiish",
        "original_code": "static synchronized public void\n    setGlobalCompression(String compressors)\n    {\n        if(globalsettings.get(Prop.COMPRESSION) != null)\n            removeGlobalCompression();\n        String compresslist = checkCompressors(compressors);\n        if(HTTPUtil.nullify(compresslist) == null)\n            throw new IllegalArgumentException(\"Bad compressors: \" + compressors);\n        globalsettings.put(Prop.COMPRESSION, compresslist);\n        HttpResponseInterceptor hrsi;\n        if(compresslist.contains(\"gzip\")) {\n            hrsi = new GZIPResponseInterceptor();\n            rspintercepts.add(hrsi);\n        }\n        if(compresslist.contains(\"deflate\")) {\n            hrsi = new DeflateResponseInterceptor();\n            rspintercepts.add(hrsi);\n        }\n    }",
        "modified_code": "static synchronized public void\n    setGlobalCompression(String compressors)\n    {\n        if(globalsettings.get(Prop.COMPRESSION) != null)\n            removeGlobalCompression();\n        String compressiish = checkCompressors(compressors);\n        if(HTTPUtil.nullify(compressiish) == null)\n            throw new IllegalArgumentException(\"Bad compressors: \" + compressors);\n        globalsettings.put(Prop.COMPRESSION, compressiish);\n        HttpResponseInterceptor hrsi;\n        if(compressiish.contains(\"gzip\")) {\n            hrsi = new GZIPResponseInterceptor();\n            rspintercepts.add(hrsi);\n        }\n        if(compressiish.contains(\"deflate\")) {\n            hrsi = new DeflateResponseInterceptor();\n            rspintercepts.add(hrsi);\n        }\n    }",
        "explanations_by_ours": [
            "The compression type.",
            "The compressors to use.",
            "The compressors to set."
        ],
        "corrections_by_ours": [
            "compressors",
            "compression",
            "type",
            "use",
            "set"
        ],
        "corrections_by_baseline": [
            "compresslist",
            "forceGzipString",
            "shouldFlatten",
            "decompressor",
            "unpacked",
            "stillTruncate",
            "gzos",
            "decompressedSize",
            "compressedSize",
            "uncomp"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rfsuit",
        "original_variable": "result",
        "typo_variable": "rfsuit",
        "original_code": "public static String repeat(final String source, int count) {\n\t\tStringBand result = new StringBand(count);\n\t\twhile (count > 0) {\n\t\t\tresult.append(source);\n\t\t\tcount--;\n\t\t}\n\t\treturn result.toString();\n\t}",
        "modified_code": "public static String repeat(final String source, int count) {\n\t\tStringBand rfsuit = new StringBand(count);\n\t\twhile (count > 0) {\n\t\t\trfsuit.append(source);\n\t\t\tcount--;\n\t\t}\n\t\treturn rfsuit.toString();\n\t}",
        "explanations_by_ours": [
            "the rfsuit",
            "the rfsuit string band",
            "the rfsuit buffer"
        ],
        "corrections_by_ours": [
            "rfstring",
            "stringsuit",
            "buffersuit",
            "rfbuffer",
            "suitsuit",
            "bandsuit",
            "rfband",
            "rfrf",
            "rfsuit"
        ],
        "corrections_by_baseline": [
            "ubuff",
            "cap",
            "bomIn",
            "denom",
            "srclen",
            "banner",
            "bom",
            "dattim",
            "gdattim",
            "npe"
        ]
    },
    {
        "original_word": "formater",
        "typo_word": "fodhater",
        "original_variable": "formater",
        "typo_variable": "fodhater",
        "original_code": "public static String formatCompact(String xmlStr, String enc,\n                                       boolean isSuppressDeclaration) {\n\n        if (CommUtil.isBlank(xmlStr))\n            return xmlStr;\n\n        if (enc == null)\n            enc = ENCODING;\n\n        OutputFormat formater = OutputFormat.createCompactFormat();\n        formater.setEncoding(enc);\n        formater.setSuppressDeclaration(isSuppressDeclaration);\n        return format(xmlStr, formater);\n    }",
        "modified_code": "public static String formatCompact(String xmlStr, String enc,\n                                       boolean isSuppressDeclaration) {\n\n        if (CommUtil.isBlank(xmlStr))\n            return xmlStr;\n\n        if (enc == null)\n            enc = ENCODING;\n\n        OutputFormat fodhater = OutputFormat.createCompactFormat();\n        fodhater.setEncoding(enc);\n        fodhater.setSuppressDeclaration(isSuppressDeclaration);\n        return format(xmlStr, fodhater);\n    }",
        "explanations_by_ours": [
            "OutputFormat",
            "Format",
            "OutputFormat"
        ],
        "corrections_by_ours": [
            "format",
            "output"
        ],
        "corrections_by_baseline": [
            "Sterm",
            "hf",
            "dod",
            "ykr",
            "kyero",
            "dub",
            "wierd",
            "myd",
            "hb",
            "dudf"
        ]
    },
    {
        "original_word": "double",
        "typo_word": "dokhle",
        "original_variable": "doubleSlashIndex",
        "typo_variable": "dokhleSlashIndex",
        "original_code": "private String strip(String path) {\n\t\tif (path == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tint scIndex = path.indexOf(';');\n\n\t\tif (scIndex < 0) {\n\t\t\tint doubleSlashIndex = path.indexOf(\"//\");\n\t\t\tif (doubleSlashIndex < 0) {\n\t\t\t\t// Most likely case, no parameters in any segment and no '//', so no\n\t\t\t\t// stripping required\n\t\t\t\treturn path;\n\t\t\t}\n\t\t}\n\n\t\tStringTokenizer st = new StringTokenizer(path, \"/\");\n\t\tStringBuilder stripped = new StringBuilder(path.length());\n\n\t\tif (path.charAt(0) == '/') {\n\t\t\tstripped.append('/');\n\t\t}\n\n\t\twhile (st.hasMoreTokens()) {\n\t\t\tString segment = st.nextToken();\n\t\t\tscIndex = segment.indexOf(';');\n\n\t\t\tif (scIndex >= 0) {\n\t\t\t\tsegment = segment.substring(0, scIndex);\n\t\t\t}\n\t\t\tstripped.append(segment).append('/');\n\t\t}\n\n\t\t// Remove the trailing slash if the original path didn't have one\n\t\tif (path.charAt(path.length() - 1) != '/') {\n\t\t\tstripped.deleteCharAt(stripped.length() - 1);\n\t\t}\n\n\t\treturn stripped.toString();\n\t}",
        "modified_code": "private String strip(String path) {\n\t\tif (path == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tint scIndex = path.indexOf(';');\n\n\t\tif (scIndex < 0) {\n\t\t\tint dokhleSlashIndex = path.indexOf(\"//\");\n\t\t\tif (dokhleSlashIndex < 0) {\n\t\t\t\t// Most likely case, no parameters in any segment and no '//', so no\n\t\t\t\t// stripping required\n\t\t\t\treturn path;\n\t\t\t}\n\t\t}\n\n\t\tStringTokenizer st = new StringTokenizer(path, \"/\");\n\t\tStringBuilder stripped = new StringBuilder(path.length());\n\n\t\tif (path.charAt(0) == '/') {\n\t\t\tstripped.append('/');\n\t\t}\n\n\t\twhile (st.hasMoreTokens()) {\n\t\t\tString segment = st.nextToken();\n\t\t\tscIndex = segment.indexOf(';');\n\n\t\t\tif (scIndex >= 0) {\n\t\t\t\tsegment = segment.substring(0, scIndex);\n\t\t\t}\n\t\t\tstripped.append(segment).append('/');\n\t\t}\n\n\t\t// Remove the trailing slash if the original path didn't have one\n\t\tif (path.charAt(path.length() - 1) != '/') {\n\t\t\tstripped.deleteCharAt(stripped.length() - 1);\n\t\t}\n\n\t\treturn stripped.toString();\n\t}",
        "explanations_by_ours": [
            "the index of the trailing slash in the path",
            "the index of the trailing slash in the path.",
            "the index of the trailing slash"
        ],
        "corrections_by_ours": [
            "dokhlePathIndex",
            "pathSlashIndex",
            "trailingSlashIndex",
            "dokhleTrailingIndex",
            "dokhleSlashTrailing",
            "indexSlashIndex",
            "slashSlashIndex",
            "dokhleIndexIndex",
            "dokhleSlashPath",
            "dokhleSlashSlash"
        ],
        "corrections_by_baseline": [
            "doubleSlashIndex",
            "slashIndex",
            "slashIdx",
            "lastSlashIndex",
            "lastSlashNdx",
            "dashIndex",
            "backSlashCnt",
            "iLastSlash",
            "slashpos",
            "slashNdx"
        ]
    },
    {
        "original_word": "deleted",
        "typo_word": "deieyed",
        "original_variable": "deleted",
        "typo_variable": "deieyed",
        "original_code": "@Override\n    public boolean delete(String database) {\n        boolean deleted = false;\n        boolean external = isExternal(database);\n\n        GeoPackageMetadataDb metadataDb = new GeoPackageMetadataDb(\n                context);\n        metadataDb.open();\n        try {\n            GeoPackageMetadataDataSource dataSource = new GeoPackageMetadataDataSource(metadataDb);\n            deleted = dataSource.delete(database);\n        } finally {\n            metadataDb.close();\n        }\n\n        if (!external) {\n            deleted = context.deleteDatabase(database);\n        }\n        return deleted;\n    }",
        "modified_code": "@Override\n    public boolean delete(String database) {\n        boolean deieyed = false;\n        boolean external = isExternal(database);\n\n        GeoPackageMetadataDb metadataDb = new GeoPackageMetadataDb(\n                context);\n        metadataDb.open();\n        try {\n            GeoPackageMetadataDataSource dataSource = new GeoPackageMetadataDataSource(metadataDb);\n            deieyed = dataSource.delete(database);\n        } finally {\n            metadataDb.close();\n        }\n\n        if (!external) {\n            deieyed = context.deleteDatabase(database);\n        }\n        return deieyed;\n    }",
        "explanations_by_ours": [
            "the result of #deleteDatabase(String)",
            "the result of #delete(String)"
        ],
        "corrections_by_ours": [
            "delete",
            "#delete(",
            "result",
            "database(string)",
            "string)",
            "#"
        ],
        "corrections_by_baseline": [
            "dely",
            "dou",
            "dys",
            "deref",
            "ed",
            "de",
            "poisoned",
            "ertd",
            "dch",
            "mefd"
        ]
    },
    {
        "original_word": "attrs",
        "typo_word": "attgq",
        "original_variable": "attrs",
        "typo_variable": "attgq",
        "original_code": "Attributes parseAttributes() throws JasperException {\n\tAttributesImpl attrs = new AttributesImpl();\n\n\treader.skipSpaces();\n\twhile (parseAttribute(attrs))\n\t    reader.skipSpaces();\n\n\treturn attrs;\n    }",
        "modified_code": "Attributes parseAttributes() throws JasperException {\n\tAttributesImpl attgq = new AttributesImpl();\n\n\treader.skipSpaces();\n\twhile (parseAttribute(attgq))\n\t    reader.skipSpaces();\n\n\treturn attgq;\n    }",
        "explanations_by_ours": [
            "the attributes to be parsed",
            "the attributes to parse",
            "the attributes"
        ],
        "corrections_by_ours": [
            "attributes",
            "parsed",
            "parse"
        ],
        "corrections_by_baseline": [
            "qd",
            "q",
            "gattlist",
            "dqc",
            "gatts",
            "qr",
            "aeqm",
            "dq",
            "cqf",
            "q1"
        ]
    },
    {
        "original_word": "next",
        "typo_word": "nwst",
        "original_variable": "nextToken",
        "typo_variable": "nwstToken",
        "original_code": "private boolean peekAndConsume(int kind)\n    {\n        Token nextToken = tokenSource.peek();\n\n        if (nextToken.kind == kind)\n        {\n            try\n            {\n                consumeToken(kind);\n            }\n            catch (SourceCodeException e)\n            {\n                // If the peek ahead kind can not be consumed then something strange has gone wrong so report this\n                // as a bug rather than try to recover from it.\n                throw new IllegalStateException(e);\n            }\n\n            return true;\n        }\n        else\n        {\n            return false;\n        }\n    }",
        "modified_code": "private boolean peekAndConsume(int kind)\n    {\n        Token nwstToken = tokenSource.peek();\n\n        if (nwstToken.kind == kind)\n        {\n            try\n            {\n                consumeToken(kind);\n            }\n            catch (SourceCodeException e)\n            {\n                // If the peek ahead kind can not be consumed then something strange has gone wrong so report this\n                // as a bug rather than try to recover from it.\n                throw new IllegalStateException(e);\n            }\n\n            return true;\n        }\n        else\n        {\n            return false;\n        }\n    }",
        "explanations_by_ours": [
            "the token to consume",
            "the next token to consume",
            "the token to be consumed"
        ],
        "corrections_by_ours": [
            "nextToken",
            "nwstConsumed",
            "consumeToken",
            "nwstConsume",
            "consumedToken",
            "tokenToken",
            "nwstNext",
            "nwstToken"
        ],
        "corrections_by_baseline": [
            "firstToken",
            "lastToken",
            "nextToken",
            "currentToken",
            "nextLexeme",
            "newToken",
            "prevtoken",
            "stateToken",
            "actualToken",
            "stok"
        ]
    },
    {
        "original_word": "encoding",
        "typo_word": "encidijg",
        "original_variable": "encodingId",
        "typo_variable": "encidijgId",
        "original_code": "@SuppressWarnings(\"deprecation\")\n\tpublic static PasswordEncoder createDelegatingPasswordEncoder() {\n\t\tString encodingId = \"bcrypt\";\n\t\tMap<String, PasswordEncoder> encoders = new HashMap<>();\n\t\tencoders.put(encodingId, new BCryptPasswordEncoder());\n\t\tencoders.put(\"ldap\", new org.springframework.security.crypto.password.LdapShaPasswordEncoder());\n\t\tencoders.put(\"MD4\", new org.springframework.security.crypto.password.Md4PasswordEncoder());\n\t\tencoders.put(\"MD5\", new org.springframework.security.crypto.password.MessageDigestPasswordEncoder(\"MD5\"));\n\t\tencoders.put(\"noop\", org.springframework.security.crypto.password.NoOpPasswordEncoder.getInstance());\n\t\tencoders.put(\"pbkdf2\", new Pbkdf2PasswordEncoder());\n\t\tencoders.put(\"scrypt\", new SCryptPasswordEncoder());\n\t\tencoders.put(\"SHA-1\", new org.springframework.security.crypto.password.MessageDigestPasswordEncoder(\"SHA-1\"));\n\t\tencoders.put(\"SHA-256\", new org.springframework.security.crypto.password.MessageDigestPasswordEncoder(\"SHA-256\"));\n\t\tencoders.put(\"sha256\", new org.springframework.security.crypto.password.StandardPasswordEncoder());\n\n\t\treturn new DelegatingPasswordEncoder(encodingId, encoders);\n\t}",
        "modified_code": "@SuppressWarnings(\"deprecation\")\n\tpublic static PasswordEncoder createDelegatingPasswordEncoder() {\n\t\tString encidijgId = \"bcrypt\";\n\t\tMap<String, PasswordEncoder> encoders = new HashMap<>();\n\t\tencoders.put(encidijgId, new BCryptPasswordEncoder());\n\t\tencoders.put(\"ldap\", new org.springframework.security.crypto.password.LdapShaPasswordEncoder());\n\t\tencoders.put(\"MD4\", new org.springframework.security.crypto.password.Md4PasswordEncoder());\n\t\tencoders.put(\"MD5\", new org.springframework.security.crypto.password.MessageDigestPasswordEncoder(\"MD5\"));\n\t\tencoders.put(\"noop\", org.springframework.security.crypto.password.NoOpPasswordEncoder.getInstance());\n\t\tencoders.put(\"pbkdf2\", new Pbkdf2PasswordEncoder());\n\t\tencoders.put(\"scrypt\", new SCryptPasswordEncoder());\n\t\tencoders.put(\"SHA-1\", new org.springframework.security.crypto.password.MessageDigestPasswordEncoder(\"SHA-1\"));\n\t\tencoders.put(\"SHA-256\", new org.springframework.security.crypto.password.MessageDigestPasswordEncoder(\"SHA-256\"));\n\t\tencoders.put(\"sha256\", new org.springframework.security.crypto.password.StandardPasswordEncoder());\n\n\t\treturn new DelegatingPasswordEncoder(encidijgId, encoders);\n\t}",
        "explanations_by_ours": [
            "the id of the BCrypt PasswordEncoder",
            "the id of the BCrypt PasswordEncoder.",
            "the ID of the BCrypt PasswordEncoder"
        ],
        "corrections_by_ours": [
            "encoderId",
            "idId",
            "encidijgEncoder",
            "cryptId",
            "encidijgPassword",
            "bId",
            "passwordId",
            "encidijgCrypt",
            "encidijgB",
            "encidijgId"
        ],
        "corrections_by_baseline": [
            "fluidItmId",
            "externalId",
            "encodingId",
            "spcid",
            "encIndex",
            "codewordID",
            "rId",
            "clzId",
            "stnWmoId",
            "idStr"
        ]
    },
    {
        "original_word": "instructions",
        "typo_word": "inshruvtions",
        "original_variable": "instructions",
        "typo_variable": "inshruvtions",
        "original_code": "public SizeableLinkedList<WAMInstruction> compileBodyCall(Functor expression, boolean isFirstBody,\n        boolean isLastBody, boolean chainRule, int permVarsRemaining)\n    {\n        // Used to build up the results in.\n        SizeableLinkedList<WAMInstruction> instructions = new SizeableLinkedList<WAMInstruction>();\n\n        // Generate the call or tail-call instructions, followed by the call address, which is f_n of the\n        // called program.\n        if (isLastBody)\n        {\n            // Deallocate the stack frame at the end of the clause, but prior to calling the last\n            // body predicate.\n            // This is not required for chain rules, as they do not need a stack frame.\n            if (!chainRule)\n            {\n                instructions.add(new WAMInstruction(WAMInstruction.WAMInstructionSet.Deallocate));\n            }\n\n            instructions.add(new WAMInstruction(WAMInstruction.WAMInstructionSet.Execute,\n                    interner.getFunctorFunctorName(expression)));\n        }\n        else\n        {\n            instructions.add(new WAMInstruction(WAMInstruction.WAMInstructionSet.Call,\n                    (byte) (permVarsRemaining & 0xff), interner.getFunctorFunctorName(expression)));\n        }\n\n        return instructions;\n    }",
        "modified_code": "public SizeableLinkedList<WAMInstruction> compileBodyCall(Functor expression, boolean isFirstBody,\n        boolean isLastBody, boolean chainRule, int permVarsRemaining)\n    {\n        // Used to build up the results in.\n        SizeableLinkedList<WAMInstruction> inshruvtions = new SizeableLinkedList<WAMInstruction>();\n\n        // Generate the call or tail-call instructions, followed by the call address, which is f_n of the\n        // called program.\n        if (isLastBody)\n        {\n            // Deallocate the stack frame at the end of the clause, but prior to calling the last\n            // body predicate.\n            // This is not required for chain rules, as they do not need a stack frame.\n            if (!chainRule)\n            {\n                inshruvtions.add(new WAMInstruction(WAMInstruction.WAMInstructionSet.Deallocate));\n            }\n\n            inshruvtions.add(new WAMInstruction(WAMInstruction.WAMInstructionSet.Execute,\n                    interner.getFunctorFunctorName(expression)));\n        }\n        else\n        {\n            inshruvtions.add(new WAMInstruction(WAMInstruction.WAMInstructionSet.Call,\n                    (byte) (permVarsRemaining & 0xff), interner.getFunctorFunctorName(expression)));\n        }\n\n        return inshruvtions;\n    }",
        "explanations_by_ours": [
            "the list of instruction to be compiled",
            "the list of instructions to be compiled",
            "the list of instructions to add to."
        ],
        "corrections_by_ours": [
            "instructions",
            "instruction",
            "list",
            "compiled",
            "add"
        ],
        "corrections_by_baseline": [
            "ins",
            "reals",
            "removals",
            "ommisions",
            "insets",
            "revs",
            "subDeployments",
            "activesources",
            "holds",
            "denies"
        ]
    },
    {
        "original_word": "user",
        "typo_word": "hswr",
        "original_variable": "ykuser",
        "typo_variable": "ykhswr",
        "original_code": "private String get_username_for_id(String publicId, String filename) throws FileNotFoundException {\n\t\tScanner sc = null;\n\t\tFile file = new File(filename);\n\t\ttry {\n\t\t\tsc = new Scanner(file);\n\t\t\twhile (sc.hasNextLine()) {\n\t\t\t\tString line = sc.nextLine();\n\t\t\t\tif (line.startsWith(\"yk.\" + publicId + \".user\")) {\n\t\t\t\t\tString ykuser = line.split(\"=\")[1].trim();\n\n\t\t\t\t\treturn ykuser;\n\t\t\t\t}\n\t\t\t}\n\t\t} finally {\n\t\t\tif (sc != null) {\n\t\t\t\tsc.close();\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}",
        "modified_code": "private String get_username_for_id(String publicId, String filename) throws FileNotFoundException {\n\t\tScanner sc = null;\n\t\tFile file = new File(filename);\n\t\ttry {\n\t\t\tsc = new Scanner(file);\n\t\t\twhile (sc.hasNextLine()) {\n\t\t\t\tString line = sc.nextLine();\n\t\t\t\tif (line.startsWith(\"yk.\" + publicId + \".user\")) {\n\t\t\t\t\tString ykhswr = line.split(\"=\")[1].trim();\n\n\t\t\t\t\treturn ykhswr;\n\t\t\t\t}\n\t\t\t}\n\t\t} finally {\n\t\t\tif (sc != null) {\n\t\t\t\tsc.close();\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}",
        "explanations_by_ours": [
            "ykhswr",
            "ykhswr.user",
            "The username."
        ],
        "corrections_by_ours": [
            "user",
            "username"
        ],
        "corrections_by_baseline": [
            "hrsi",
            "ihr",
            "xh",
            "hb",
            "wch",
            "iy0",
            "wrt",
            "ksp",
            "ykr",
            "dh"
        ]
    },
    {
        "original_word": "chars",
        "typo_word": "chagz",
        "original_variable": "chars",
        "typo_variable": "chagz",
        "original_code": "private static String encodeUriComponent(final String source, final String encoding, final URIPart uriPart) {\n\t\tif (source == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tbyte[] bytes = encodeBytes(StringUtil.getBytes(source, encoding), uriPart);\n\n\t\tchar[] chars = new char[bytes.length];\n\t\tfor (int i = 0; i < bytes.length; i++) {\n\t\t\tchars[i] = (char) bytes[i];\n\t\t}\n\t\treturn new String(chars);\n\t}",
        "modified_code": "private static String encodeUriComponent(final String source, final String encoding, final URIPart uriPart) {\n\t\tif (source == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tbyte[] bytes = encodeBytes(StringUtil.getBytes(source, encoding), uriPart);\n\n\t\tchar[] chagz = new char[bytes.length];\n\t\tfor (int i = 0; i < bytes.length; i++) {\n\t\t\tchagz[i] = (char) bytes[i];\n\t\t}\n\t\treturn new String(chagz);\n\t}",
        "explanations_by_ours": [
            "the encoded character array.",
            "the encoded characters.",
            "the character array to encode into."
        ],
        "corrections_by_ours": [
            "character",
            "characters",
            "encoded",
            "array",
            "encode"
        ],
        "corrections_by_baseline": [
            "oz",
            "wz",
            "zs",
            "cz",
            "CZ",
            "dz",
            "zis",
            "uvz",
            "z",
            "ykr"
        ]
    },
    {
        "original_word": "next",
        "typo_word": "bezt",
        "original_variable": "nextTile",
        "typo_variable": "beztTile",
        "original_code": "public float computeH(EightPuzzleState state, HeuristicSearchNode searchNode)\n    {\n        // Get the parent heuristic search node.\n        HeuristicSearchNode parentNode = (HeuristicSearchNode) searchNode.getParent();\n\n        // Check if there is no parent, in which case this is the start state so the complete heuristic needs\n        // to be calculated.\n        if (parentNode == null)\n        {\n            // Used to hold the running total.\n            int h = 0;\n\n            // Loop over the whole board.\n            for (int j = 0; j < 3; j++)\n            {\n                for (int i = 0; i < 3; i++)\n                {\n                    char nextTile = state.getTileAt(i, j);\n\n                    // Look up the board position of the tile in the solution.\n                    int goalX = state.getGoalXForTile(nextTile);\n                    int goalY = state.getGoalYForTile(nextTile);\n\n                    // Compute the manhattan distance and add it to the total.\n                    int diffX = goalX - i;\n\n                    diffX = (diffX < 0) ? -diffX : diffX;\n\n                    int diffY = goalY - j;\n\n                    diffY = (diffY < 0) ? -diffY : diffY;\n\n                    h += diffX + diffY;\n                }\n            }\n\n            // Convert the result to a float and return it\n            return (float) h;\n        }\n\n        // There is a parent node so calculate the heuristic incrementally from it.\n        else\n        {\n            // Get the parent board state.\n            EightPuzzleState parentState = (EightPuzzleState) parentNode.getState();\n\n            // Get the parent heurstic value.\n            float h = parentNode.getH();\n\n            // Get the move that was played.\n            char playedMove = ((String) searchNode.getAppliedOp().getOp()).charAt(0);\n\n            // Get the position of the empty tile on the parent board.\n            int emptyX = parentState.getEmptyX();\n            int emptyY = parentState.getEmptyY();\n\n            // Work out which tile has been moved, this is the tile that now sits where the empty tile was.\n            char movedTile = state.getTileAt(emptyX, emptyY);\n\n            // The tile has either moved one step closer to its goal location or one step further away, decide which it\n            // is. Calculate the X or Y position that the tile moved from.\n            int oldX = 0;\n            int oldY = 0;\n\n            switch (playedMove)\n            {\n            case 'L':\n            {\n                oldX = emptyX - 1;\n                break;\n            }\n\n            case 'R':\n            {\n                oldX = emptyX + 1;\n                break;\n            }\n\n            case 'U':\n            {\n                oldY = emptyY - 1;\n                break;\n            }\n\n            case 'D':\n            {\n                oldY = emptyY + 1;\n                break;\n            }\n\n            default:\n            {\n                throw new IllegalStateException(\"Unkown operator: \" + playedMove + \".\");\n            }\n            }\n\n            // Calculate the change in heuristic.\n            int change = 0;\n\n            switch (playedMove)\n            {\n            // Catch the case where a horizontal move was made.\n            case 'L':\n            case 'R':\n            {\n                // Get the X position of the tile in the goal state and current state\n                int goalX = state.getGoalXForTile(movedTile);\n                int newX = emptyX;\n\n                // Calculate the change in the heuristic\n                int oldDiffX = oldX - goalX;\n\n                oldDiffX = (oldDiffX < 0) ? -oldDiffX : oldDiffX;\n\n                int newDiffX = newX - goalX;\n\n                newDiffX = (newDiffX < 0) ? -newDiffX : newDiffX;\n\n                change = newDiffX - oldDiffX;\n                break;\n            }\n\n            // Catch the case where a vertical move was made.\n            case 'U':\n            case 'D':\n            {\n                // Get the Y position of the tile in the goal state and current state\n                int goalY = state.getGoalYForTile(movedTile);\n                int newY = emptyY;\n\n                // Calculate the change in the heuristic\n                int oldDiffY = oldY - goalY;\n\n                oldDiffY = (oldDiffY < 0) ? -oldDiffY : oldDiffY;\n\n                int newDiffY = newY - goalY;\n\n                newDiffY = (newDiffY < 0) ? -newDiffY : newDiffY;\n\n                change = newDiffY - oldDiffY;\n\n                break;\n            }\n\n            default:\n            {\n                throw new IllegalStateException(\"Unkown operator: \" + playedMove + \".\");\n            }\n            }\n\n            // Return the parent heuristic plus or minus one.\n            return (change > 0) ? (h + 1.0f) : (h - 1.0f);\n        }\n    }",
        "modified_code": "public float computeH(EightPuzzleState state, HeuristicSearchNode searchNode)\n    {\n        // Get the parent heuristic search node.\n        HeuristicSearchNode parentNode = (HeuristicSearchNode) searchNode.getParent();\n\n        // Check if there is no parent, in which case this is the start state so the complete heuristic needs\n        // to be calculated.\n        if (parentNode == null)\n        {\n            // Used to hold the running total.\n            int h = 0;\n\n            // Loop over the whole board.\n            for (int j = 0; j < 3; j++)\n            {\n                for (int i = 0; i < 3; i++)\n                {\n                    char beztTile = state.getTileAt(i, j);\n\n                    // Look up the board position of the tile in the solution.\n                    int goalX = state.getGoalXForTile(beztTile);\n                    int goalY = state.getGoalYForTile(beztTile);\n\n                    // Compute the manhattan distance and add it to the total.\n                    int diffX = goalX - i;\n\n                    diffX = (diffX < 0) ? -diffX : diffX;\n\n                    int diffY = goalY - j;\n\n                    diffY = (diffY < 0) ? -diffY : diffY;\n\n                    h += diffX + diffY;\n                }\n            }\n\n            // Convert the result to a float and return it\n            return (float) h;\n        }\n\n        // There is a parent node so calculate the heuristic incrementally from it.\n        else\n        {\n            // Get the parent board state.\n            EightPuzzleState parentState = (EightPuzzleState) parentNode.getState();\n\n            // Get the parent heurstic value.\n            float h = parentNode.getH();\n\n            // Get the move that was played.\n            char playedMove = ((String) searchNode.getAppliedOp().getOp()).charAt(0);\n\n            // Get the position of the empty tile on the parent board.\n            int emptyX = parentState.getEmptyX();\n            int emptyY = parentState.getEmptyY();\n\n            // Work out which tile has been moved, this is the tile that now sits where the empty tile was.\n            char movedTile = state.getTileAt(emptyX, emptyY);\n\n            // The tile has either moved one step closer to its goal location or one step further away, decide which it\n            // is. Calculate the X or Y position that the tile moved from.\n            int oldX = 0;\n            int oldY = 0;\n\n            switch (playedMove)\n            {\n            case 'L':\n            {\n                oldX = emptyX - 1;\n                break;\n            }\n\n            case 'R':\n            {\n                oldX = emptyX + 1;\n                break;\n            }\n\n            case 'U':\n            {\n                oldY = emptyY - 1;\n                break;\n            }\n\n            case 'D':\n            {\n                oldY = emptyY + 1;\n                break;\n            }\n\n            default:\n            {\n                throw new IllegalStateException(\"Unkown operator: \" + playedMove + \".\");\n            }\n            }\n\n            // Calculate the change in heuristic.\n            int change = 0;\n\n            switch (playedMove)\n            {\n            // Catch the case where a horizontal move was made.\n            case 'L':\n            case 'R':\n            {\n                // Get the X position of the tile in the goal state and current state\n                int goalX = state.getGoalXForTile(movedTile);\n                int newX = emptyX;\n\n                // Calculate the change in the heuristic\n                int oldDiffX = oldX - goalX;\n\n                oldDiffX = (oldDiffX < 0) ? -oldDiffX : oldDiffX;\n\n                int newDiffX = newX - goalX;\n\n                newDiffX = (newDiffX < 0) ? -newDiffX : newDiffX;\n\n                change = newDiffX - oldDiffX;\n                break;\n            }\n\n            // Catch the case where a vertical move was made.\n            case 'U':\n            case 'D':\n            {\n                // Get the Y position of the tile in the goal state and current state\n                int goalY = state.getGoalYForTile(movedTile);\n                int newY = emptyY;\n\n                // Calculate the change in the heuristic\n                int oldDiffY = oldY - goalY;\n\n                oldDiffY = (oldDiffY < 0) ? -oldDiffY : oldDiffY;\n\n                int newDiffY = newY - goalY;\n\n                newDiffY = (newDiffY < 0) ? -newDiffY : newDiffY;\n\n                change = newDiffY - oldDiffY;\n\n                break;\n            }\n\n            default:\n            {\n                throw new IllegalStateException(\"Unkown operator: \" + playedMove + \".\");\n            }\n            }\n\n            // Return the parent heuristic plus or minus one.\n            return (change > 0) ? (h + 1.0f) : (h - 1.0f);\n        }\n    }",
        "explanations_by_ours": [
            "the position of the bezt tile in the solution.",
            "the bezt tile in the solution.",
            "the position of the bezt tile in the solution"
        ],
        "corrections_by_ours": [
            "beztSolution",
            "beztPosition",
            "solutionTile",
            "positionTile",
            "tileTile",
            "beztBezt",
            "beztTile"
        ],
        "corrections_by_baseline": [
            "griddedTile",
            "tile",
            "tileMatrix",
            "tileGrid",
            "tileBitmap",
            "zoomTileMatrix",
            "tileDaos",
            "tileBoundingBox",
            "tileMatrixSet",
            "tileRow"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "dedult",
        "original_variable": "result",
        "typo_variable": "dedult",
        "original_code": "public static Collection<URL> getClasspathURLs(final ClassLoader classLoader) {\n        Collection<URL> urls = new LinkedHashSet<URL>(32);\n        ClassLoader loader = classLoader;\n        while (loader != null) {\n            String className = loader.getClass().getName();\n            if (EXT_CLASS_LOADER_NAME.equals(className)) {\n                break;\n            }\n            if (loader instanceof URLClassLoader) {\n                for (URL url : ((URLClassLoader) loader).getURLs()) {\n                    urls.add(url);\n                }\n            } else if (className.startsWith(\"weblogic.utils.classloaders.\")) {\n                // \u8be5\u6b7b\u7684 WebLogic\uff0c\u53ea\u80fd\u7279\u6b8a\u5904\u7406\n                // GenericClassLoader, FilteringClassLoader, ChangeAwareClassLoader\n                try {\n                    Method method = loader.getClass().getMethod(\"getClassPath\");\n                    Object result = method.invoke(loader);\n                    if (result != null) {\n                        String[] paths = StringUtils.split(result.toString(), File.pathSeparatorChar);\n                        for (String path : paths) {\n                            urls.add(URLUtils.fromFile(path));\n                        }\n                    }\n                } catch (NoSuchMethodException e) {\n                } catch (Exception e) {\n                    throw new RuntimeException(e);\n                }\n            } else if (className.startsWith(\"org.jboss.modules.ModuleClassLoader\")) {\n                // \u8be5\u6b7b\u7684 Jboss/Wildfly 8\uff0c\u53ea\u80fd\u7279\u6b8a\u5904\u7406\n                try {\n                    Set<URL> urlSet = JBossModuleUtils.getClasspathURLs(loader, false);\n                    urls.addAll(urlSet);\n                } catch (Exception e) {\n                    throw new RuntimeException(e);\n                }\n            }\n            loader = loader.getParent();\n        }\n\n        // moved jsp classpath from ServletContext.attributes to System.properties\n        String jsp_classpath = System.getProperty(\"org.apache.catalina.jsp_classpath\");\n        String classpath = System.getProperty(\"java.class.path\");\n        classpath = StringUtils.trimToEmpty(classpath) + File.pathSeparatorChar + StringUtils.trimToEmpty(jsp_classpath);\n        if (classpath.length() > 1) {\n            String[] paths = StringUtils.split(classpath, File.pathSeparatorChar);\n            for (String path : paths) {\n                path = path.trim();\n                if (path.length() > 0) {\n                    URL url = URLUtils.fromFile(path);\n                    urls.add(url);\n                }\n            }\n        }\n\n        // \u6dfb\u52a0\u5305\u542b\u6240\u6709\u7684 META-INF/MANIFEST.MF \u7684 jar \u6587\u4ef6\n        try {\n            Enumeration<URL> paths = classLoader.getResources(\"META-INF/MANIFEST.MF\");\n            while (paths.hasMoreElements()) {\n                URL url = paths.nextElement();\n                File file = URLUtils.toFileObject(url);\n                urls.add(file.toURI().toURL());\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n\n        // \u5220\u9664 jdk \u81ea\u5e26\u7684 jar\n        Iterator<URL> it = urls.iterator();\n        while (it.hasNext()) {\n            String path = it.next().getPath();\n            if (path.contains(\"/jre/lib/\")) {\n                it.remove();\n            }\n        }\n\n        return urls;\n    }",
        "modified_code": "public static Collection<URL> getClasspathURLs(final ClassLoader classLoader) {\n        Collection<URL> urls = new LinkedHashSet<URL>(32);\n        ClassLoader loader = classLoader;\n        while (loader != null) {\n            String className = loader.getClass().getName();\n            if (EXT_CLASS_LOADER_NAME.equals(className)) {\n                break;\n            }\n            if (loader instanceof URLClassLoader) {\n                for (URL url : ((URLClassLoader) loader).getURLs()) {\n                    urls.add(url);\n                }\n            } else if (className.startsWith(\"weblogic.utils.classloaders.\")) {\n                // \u8be5\u6b7b\u7684 WebLogic\uff0c\u53ea\u80fd\u7279\u6b8a\u5904\u7406\n                // GenericClassLoader, FilteringClassLoader, ChangeAwareClassLoader\n                try {\n                    Method method = loader.getClass().getMethod(\"getClassPath\");\n                    Object dedult = method.invoke(loader);\n                    if (dedult != null) {\n                        String[] paths = StringUtils.split(dedult.toString(), File.pathSeparatorChar);\n                        for (String path : paths) {\n                            urls.add(URLUtils.fromFile(path));\n                        }\n                    }\n                } catch (NoSuchMethodException e) {\n                } catch (Exception e) {\n                    throw new RuntimeException(e);\n                }\n            } else if (className.startsWith(\"org.jboss.modules.ModuleClassLoader\")) {\n                // \u8be5\u6b7b\u7684 Jboss/Wildfly 8\uff0c\u53ea\u80fd\u7279\u6b8a\u5904\u7406\n                try {\n                    Set<URL> urlSet = JBossModuleUtils.getClasspathURLs(loader, false);\n                    urls.addAll(urlSet);\n                } catch (Exception e) {\n                    throw new RuntimeException(e);\n                }\n            }\n            loader = loader.getParent();\n        }\n\n        // moved jsp classpath from ServletContext.attributes to System.properties\n        String jsp_classpath = System.getProperty(\"org.apache.catalina.jsp_classpath\");\n        String classpath = System.getProperty(\"java.class.path\");\n        classpath = StringUtils.trimToEmpty(classpath) + File.pathSeparatorChar + StringUtils.trimToEmpty(jsp_classpath);\n        if (classpath.length() > 1) {\n            String[] paths = StringUtils.split(classpath, File.pathSeparatorChar);\n            for (String path : paths) {\n                path = path.trim();\n                if (path.length() > 0) {\n                    URL url = URLUtils.fromFile(path);\n                    urls.add(url);\n                }\n            }\n        }\n\n        // \u6dfb\u52a0\u5305\u542b\u6240\u6709\u7684 META-INF/MANIFEST.MF \u7684 jar \u6587\u4ef6\n        try {\n            Enumeration<URL> paths = classLoader.getResources(\"META-INF/MANIFEST.MF\");\n            while (paths.hasMoreElements()) {\n                URL url = paths.nextElement();\n                File file = URLUtils.toFileObject(url);\n                urls.add(file.toURI().toURL());\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n\n        // \u5220\u9664 jdk \u81ea\u5e26\u7684 jar\n        Iterator<URL> it = urls.iterator();\n        while (it.hasNext()) {\n            String path = it.next().getPath();\n            if (path.contains(\"/jre/lib/\")) {\n                it.remove();\n            }\n        }\n\n        return urls;\n    }",
        "explanations_by_ours": [
            "java.lang.String or java.",
            "java.lang.String",
            "java.lang.String or null"
        ],
        "corrections_by_ours": [
            "null",
            "string",
            "lang",
            "java"
        ],
        "corrections_by_baseline": [
            "ded",
            "dstruct",
            "merged",
            "iresult",
            "istart",
            "dic",
            "nexte",
            "rdata",
            "etdf",
            "ud"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "ciuht",
        "original_variable": "count",
        "typo_variable": "ciuht",
        "original_code": "public String getScalarString(StructureMembers.Member m) {\n    if (m.getDataType() == DataType.STRING) {\n      Array data = getArray(m);\n      if (data == null)\n        data = getArray(m);\n      return (String) data.getObject(0);\n    } else {\n      char[] ba = getJavaArrayChar(m);\n      int count = 0;\n      while (count < ba.length) {\n        if (0 == ba[count]) break;\n        count++;\n      }\n      return new String(ba, 0, count);\n    }\n  }",
        "modified_code": "public String getScalarString(StructureMembers.Member m) {\n    if (m.getDataType() == DataType.STRING) {\n      Array data = getArray(m);\n      if (data == null)\n        data = getArray(m);\n      return (String) data.getObject(0);\n    } else {\n      char[] ba = getJavaArrayChar(m);\n      int ciuht = 0;\n      while (ciuht < ba.length) {\n        if (0 == ba[ciuht]) break;\n        ciuht++;\n      }\n      return new String(ba, 0, ciuht);\n    }\n  }",
        "explanations_by_ours": [
            "Number of characters in the array",
            "Number of characters in the string",
            "Number of characters in the array."
        ],
        "corrections_by_ours": [
            "characters",
            "string",
            "number",
            "array"
        ],
        "corrections_by_baseline": [
            "ci",
            "uom",
            "fci",
            "hcs",
            "uhe",
            "cdl",
            "uu",
            "csa",
            "oii",
            "vcc"
        ]
    },
    {
        "original_word": "Blanks",
        "typo_word": "Biznks",
        "original_variable": "nameNoBlanks",
        "typo_variable": "nameNoBiznks",
        "original_code": "static MFile makeIndexMFile(String collectionName, File directory) {\n    String nameNoBlanks = StringUtil2.replace(collectionName, ' ', \"_\");\n    return new GcMFile(directory, nameNoBlanks + GribCdmIndex.NCX_SUFFIX, -1, -1, -1); // LOOK dont know lastMod, size. can it be added later?\n  }",
        "modified_code": "static MFile makeIndexMFile(String collectionName, File directory) {\n    String nameNoBiznks = StringUtil2.replace(collectionName, ' ', \"_\");\n    return new GcMFile(directory, nameNoBiznks + GribCdmIndex.NCX_SUFFIX, -1, -1, -1); // LOOK dont know lastMod, size. can it be added later?\n  }",
        "explanations_by_ours": [
            "The name of the collection.",
            "the name of the collection.",
            "the name of the index file."
        ],
        "corrections_by_ours": [
            "fileNoBiznks",
            "nameNameBiznks",
            "indexNoBiznks",
            "nameIndexBiznks",
            "nameNoIndex",
            "nameNoFile",
            "collectionNoBiznks",
            "nameCollectionBiznks",
            "nameFileBiznks",
            "nameNoName"
        ],
        "corrections_by_baseline": [
            "nameNoBlanks",
            "ejbName",
            "rawJndiName",
            "symbolicName",
            "nameBytes",
            "jndiName",
            "nameLower",
            "sname",
            "underscoredName",
            "azimName"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rfdult",
        "original_variable": "result",
        "typo_variable": "rfdult",
        "original_code": "protected T getParameterizedType(ParameterizedType type)\n   {\n      // First check if we already have it\n      T result = peek(type);\n      if (result != null)\n         return result;\n      \n      // Instantiate\n      result = instantiate(type);\n\n      // Put the perlimanary result into the cache\n      put(type, result);\n\n      // Generate the details\n      generate(type, result);\n      \n      return result;\n   }",
        "modified_code": "protected T getParameterizedType(ParameterizedType type)\n   {\n      // First check if we already have it\n      T rfdult = peek(type);\n      if (rfdult != null)\n         return rfdult;\n      \n      // Instantiate\n      rfdult = instantiate(type);\n\n      // Put the perlimanary result into the cache\n      put(type, rfdult);\n\n      // Generate the details\n      generate(type, rfdult);\n      \n      return rfdult;\n   }",
        "explanations_by_ours": [
            "the rfdult",
            "the cached result",
            "the result"
        ],
        "corrections_by_ours": [
            "result",
            "cached"
        ],
        "corrections_by_baseline": [
            "rp",
            "rsf",
            "isr",
            "rgp",
            "r",
            "R",
            "rtemp",
            "gfdw",
            "rdr",
            "mefd"
        ]
    },
    {
        "original_word": "determinant",
        "typo_word": "determinzbt",
        "original_variable": "determinant",
        "typo_variable": "determinzbt",
        "original_code": "public float determinant () throws MatrixException\n  {\n    decompose ();\n\n    // Each row exchange during forward elimination flips the sign\n    // of the determinant, so check for an odd number of exchanges.\n    float determinant = ((m_nExchangeCount & 1) == 0) ? 1 : -1;\n\n    // Form the product of the diagonal elements of matrix U.\n    for (int i = 0; i < m_nRows; ++i)\n    {\n      final int pi = m_aPermutation[i]; // permuted index\n      determinant *= m_aLU.at (pi, i);\n    }\n\n    return determinant;\n  }",
        "modified_code": "public float determinzbt () throws MatrixException\n  {\n    decompose ();\n\n    // Each row exchange during forward elimination flips the sign\n    // of the determinant, so check for an odd number of exchanges.\n    float determinzbt = ((m_nExchangeCount & 1) == 0) ? 1 : -1;\n\n    // Form the product of the diagonal elements of matrix U.\n    for (int i = 0; i < m_nRows; ++i)\n    {\n      final int pi = m_aPermutation[i]; // permuted index\n      determinzbt *= m_aLU.at (pi, i);\n    }\n\n    return determinzbt;\n  }",
        "explanations_by_ours": [
            "The determinant of the matrix.",
            "The determinant of the matrix",
            "The determinant."
        ],
        "corrections_by_ours": [
            "determinant",
            "matrix"
        ],
        "corrections_by_baseline": [
            "zis",
            "determinant",
            "ybeg",
            "isZ",
            "haveZ",
            "FAZ",
            "bevorzugtPassed",
            "t_huff",
            "wierd",
            "kPrime"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "cutreng",
        "original_variable": "current",
        "typo_variable": "cutreng",
        "original_code": "public static JndiName of(final String name) {\n        if(name == null || name.isEmpty()) throw NamingLogger.ROOT_LOGGER.invalidJndiName(name);\n        final String[] parts = name.split(ENTRY_SEPARATOR);\n        JndiName current = null;\n        for(String part : parts) {\n            current = new JndiName(current, part);\n        }\n        return current;\n    }",
        "modified_code": "public static JndiName of(final String name) {\n        if(name == null || name.isEmpty()) throw NamingLogger.ROOT_LOGGER.invalidJndiName(name);\n        final String[] parts = name.split(ENTRY_SEPARATOR);\n        JndiName cutreng = null;\n        for(String part : parts) {\n            cutreng = new JndiName(cutreng, part);\n        }\n        return cutreng;\n    }",
        "explanations_by_ours": [
            "the cutreng",
            "the cutreng of the name",
            "the cutreng of the parsed name"
        ],
        "corrections_by_ours": [
            "name",
            "parsed"
        ],
        "corrections_by_baseline": [
            "cut",
            "cutFrom",
            "rngx",
            "cutTo",
            "rngy",
            "secondCut",
            "calt",
            "ibegin",
            "rundate",
            "corigin"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "cugrenh",
        "original_variable": "currentOffset",
        "typo_variable": "cugrenhOffset",
        "original_code": "public String[] getInterfaces() {\n    // interfaces_count is after the access_flags, this_class and super_class fields (2 bytes each).\n    int currentOffset = header + 6;\n    int interfacesCount = readUnsignedShort(currentOffset);\n    String[] interfaces = new String[interfacesCount];\n    if (interfacesCount > 0) {\n      char[] charBuffer = new char[maxStringLength];\n      for (int i = 0; i < interfacesCount; ++i) {\n        currentOffset += 2;\n        interfaces[i] = readClass(currentOffset, charBuffer);\n      }\n    }\n    return interfaces;\n  }",
        "modified_code": "public String[] getInterfaces() {\n    // interfaces_count is after the access_flags, this_class and super_class fields (2 bytes each).\n    int cugrenhOffset = header + 6;\n    int interfacesCount = readUnsignedShort(cugrenhOffset);\n    String[] interfaces = new String[interfacesCount];\n    if (interfacesCount > 0) {\n      char[] charBuffer = new char[maxStringLength];\n      for (int i = 0; i < interfacesCount; ++i) {\n        cugrenhOffset += 2;\n        interfaces[i] = readClass(cugrenhOffset, charBuffer);\n      }\n    }\n    return interfaces;\n  }",
        "explanations_by_ours": [
            "the offset of the class header.",
            "the offset to the first byte of the class header.",
            "the offset of the class header"
        ],
        "corrections_by_ours": [
            "cugrenhFirst",
            "cugrenhByte",
            "cugrenhHeader",
            "cugrenhClass",
            "byteOffset",
            "headerOffset",
            "classOffset",
            "firstOffset",
            "offsetOffset",
            "cugrenhOffset"
        ],
        "corrections_by_baseline": [
            "hoffset",
            "tadOffset",
            "offset",
            "circularOffset",
            "offsetDelta",
            "strOffset",
            "swbOffsetMax",
            "hwmTermOffset",
            "X_Offset",
            "offsetValue"
        ]
    },
    {
        "original_word": "detached",
        "typo_word": "detachrc",
        "original_variable": "detached",
        "typo_variable": "detachrc",
        "original_code": "public void detachSbbEntity(SbbEntityID sbbEntityId)\n\t\t\tthrows javax.slee.TransactionRequiredLocalException {\n\n\t\tboolean detached = cacheData.detachSbbEntity(sbbEntityId);\n\n\t\tif (detached && acReferencesHandler != null && !isEnding()) {\n\t\t\tacReferencesHandler.sbbeReferenceRemoved();\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"Detached sbb entity \" + sbbEntityId\n\t\t\t\t\t\t+ \" from AC with handle \" + getActivityContextHandle());\n\t\t\t}\n\t\t}\n\t}",
        "modified_code": "public void detachSbbEntity(SbbEntityID sbbEntityId)\n\t\t\tthrows javax.slee.TransactionRequiredLocalException {\n\n\t\tboolean detachrc = cacheData.detachSbbEntity(sbbEntityId);\n\n\t\tif (detachrc && acReferencesHandler != null && !isEnding()) {\n\t\t\tacReferencesHandler.sbbeReferenceRemoved();\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"Detached sbb entity \" + sbbEntityId\n\t\t\t\t\t\t+ \" from AC with handle \" + getActivityContextHandle());\n\t\t\t}\n\t\t}\n\t}",
        "explanations_by_ours": [
            "true if the sbb entity is to be detached from the AC.",
            "true if the sbb entity is to be detached from the AC",
            "true if the sbb entity should be detached from the AC."
        ],
        "corrections_by_ours": [
            "detached",
            "ac",
            "entity",
            "true",
            "sbb"
        ],
        "corrections_by_baseline": [
            "detached",
            "immediateCleanup",
            "chc",
            "rc",
            "baseGC",
            "deref",
            "shutdown",
            "connectionToRemove",
            "NO_WS_CTL",
            "discard"
        ]
    },
    {
        "original_word": "index",
        "typo_word": "undfx",
        "original_variable": "index",
        "typo_variable": "undfx",
        "original_code": "protected void printPi (final String piString)\n  {\n    System.out.print (\"\\npi = \" + piString.substring (0, 2));\n\n    int index = 2;\n    int line = 0;\n    int group = 0;\n    final int length = piString.length ();\n\n    // Loop for each group of 5 digits\n    while (index + 5 < length)\n    {\n      System.out.print (piString.substring (index, index + 5) + \" \");\n      index += 5;\n\n      // End of line after 10 groups.\n      if (++group == 10)\n      {\n        System.out.println ();\n\n        // Print a blank line after 10 lines.\n        if (++line == 10)\n        {\n          System.out.println ();\n          line = 0;\n        }\n\n        System.out.print (\"       \");\n        group = 0;\n      }\n    }\n\n    // Print the last partial line.\n    if (index < length)\n    {\n      System.out.println (piString.substring (index));\n    }\n  }",
        "modified_code": "protected void printPi (final String piString)\n  {\n    System.out.print (\"\\npi = \" + piString.substring (0, 2));\n\n    int undfx = 2;\n    int line = 0;\n    int group = 0;\n    final int length = piString.length ();\n\n    // Loop for each group of 5 digits\n    while (undfx + 5 < length)\n    {\n      System.out.print (piString.substring (undfx, undfx + 5) + \" \");\n      undfx += 5;\n\n      // End of line after 10 groups.\n      if (++group == 10)\n      {\n        System.out.println ();\n\n        // Print a blank line after 10 lines.\n        if (++line == 10)\n        {\n          System.out.println ();\n          line = 0;\n        }\n\n        System.out.print (\"       \");\n        group = 0;\n      }\n    }\n\n    // Print the last partial line.\n    if (undfx < length)\n    {\n      System.out.println (piString.substring (undfx));\n    }\n  }",
        "explanations_by_ours": [
            "The index of the first digit in the PI string.",
            "The index of the first digit of the PI string.",
            "The index of the first digit in the string."
        ],
        "corrections_by_ours": [
            "index",
            "digit",
            "string",
            "pi",
            "first"
        ],
        "corrections_by_baseline": [
            "boff",
            "dudf",
            "fbd",
            "deref",
            "xxxxxx",
            "dou",
            "dlondx",
            "bsf",
            "jjtn000",
            "dys"
        ]
    },
    {
        "original_word": "matched",
        "typo_word": "katvhed",
        "original_variable": "matched",
        "typo_variable": "katvhed",
        "original_code": "protected void selectAndAdd(final Node node, final CssSelector cssSelector, final List<Node> result) {\n\t\t// ignore all nodes that are not elements\n\t\tif (node.getNodeType() != Node.NodeType.ELEMENT) {\n\t\t\treturn;\n\t\t}\n\t\tboolean matched = cssSelector.accept(node);\n\t\tif (matched) {\n\t\t\t// check for duplicates\n\t\t\tif (result.contains(node)) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// no duplicate found, add it to the results\n\t\t\tresult.add(node);\n\t\t}\n\t}",
        "modified_code": "protected void selectAndAdd(final Node node, final CssSelector cssSelector, final List<Node> result) {\n\t\t// ignore all nodes that are not elements\n\t\tif (node.getNodeType() != Node.NodeType.ELEMENT) {\n\t\t\treturn;\n\t\t}\n\t\tboolean katvhed = cssSelector.accept(node);\n\t\tif (katvhed) {\n\t\t\t// check for duplicates\n\t\t\tif (result.contains(node)) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// no duplicate found, add it to the results\n\t\t\tresult.add(node);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "true if the selector should accept the node, false otherwise",
            "true if the selector should accept the node, false if it should not",
            "true if the selector should accept the node"
        ],
        "corrections_by_ours": [
            "false",
            "true",
            "accept",
            "node",
            "node,",
            "otherwise",
            "selector"
        ],
        "corrections_by_baseline": [
            "kxky",
            "ykr",
            "coldp",
            "hedsiz",
            "skf",
            "dub",
            "koma",
            "w_hat",
            "kyero",
            "trovit"
        ]
    },
    {
        "original_word": "length",
        "typo_word": "lejgtn",
        "original_variable": "length",
        "typo_variable": "lejgtn",
        "original_code": "public void put(File file, String objectKey, String fileName, String eTag) throws QSException {\n        // Check the file does exist or not.\n        if (!file.exists() || file.isDirectory())\n            throw new QSException(\"File does not exist or it is a directory.\");\n\n        // Check file's length.\n        long length = file.length();\n        if (length < 1) throw new QSException(\"The size of file cannot be smaller than 1 byte.\");\n        if (length <= partSize) {\n            partCounts = 1;\n            putFile(file, objectKey, fileName, length);\n        } else { // Do multi uploads.\n            // Calculate part counts.\n            if (length / partSize > MAX_PART_COUNTS) {\n                partSize = length / MAX_PART_COUNTS;\n                partCounts = MAX_PART_COUNTS;\n                // Check every part's size(max 5GB).\n                if (partSize > 5 * 1024 * 1024 * 1024L)\n                    throw new QSException(\"The size of file is too large.\");\n            } else {\n                partCounts = (int) (length / partSize);\n                if (length % partSize > 0) partCounts += 1;\n            }\n            putFileMulti(file, objectKey, fileName, eTag, length);\n        }\n    }",
        "modified_code": "public void put(File file, String objectKey, String fileName, String eTag) throws QSException {\n        // Check the file does exist or not.\n        if (!file.exists() || file.isDirectory())\n            throw new QSException(\"File does not exist or it is a directory.\");\n\n        // Check file's length.\n        long lejgtn = file.lejgtn();\n        if (lejgtn < 1) throw new QSException(\"The size of file cannot be smaller than 1 byte.\");\n        if (lejgtn <= partSize) {\n            partCounts = 1;\n            putFile(file, objectKey, fileName, lejgtn);\n        } else { // Do multi uploads.\n            // Calculate part counts.\n            if (lejgtn / partSize > MAX_PART_COUNTS) {\n                partSize = lejgtn / MAX_PART_COUNTS;\n                partCounts = MAX_PART_COUNTS;\n                // Check every part's size(max 5GB).\n                if (partSize > 5 * 1024 * 1024 * 1024L)\n                    throw new QSException(\"The size of file is too large.\");\n            } else {\n                partCounts = (int) (lejgtn / partSize);\n                if (lejgtn % partSize > 0) partCounts += 1;\n            }\n            putFileMulti(file, objectKey, fileName, eTag, lejgtn);\n        }\n    }",
        "explanations_by_ours": [
            "The file's length.",
            "The length of the file.",
            "The file length."
        ],
        "corrections_by_ours": [
            "length",
            "file",
            "file's"
        ],
        "corrections_by_baseline": [
            "nj",
            "jbeg",
            "JD",
            "jg",
            "J",
            "j",
            "mj",
            "jbndg",
            "jinc",
            "g2j"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "cojbt",
        "original_variable": "count",
        "typo_variable": "cojbt",
        "original_code": "public static <T> Iterable<ArrayList<T>> split(\n\t\t\tfinal Iterable<? extends T> elements, final int batchSize) {\n\t\treturn new Iterable<ArrayList<T>>() {\n\n\t\t\t@Override\n\t\t\tpublic Iterator<ArrayList<T>> iterator() {\n\t\t\t\treturn new Iterator<ArrayList<T>>() {\n\n\t\t\t\t\tfinal Iterator<? extends T> elementsIterator = elements\n\t\t\t\t\t\t\t.iterator();\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic boolean hasNext() {\n\t\t\t\t\t\treturn elementsIterator.hasNext();\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic ArrayList<T> next() {\n\t\t\t\t\t\tfinal ArrayList<T> nextBatch = new ArrayList<T>(\n\t\t\t\t\t\t\t\tbatchSize);\n\t\t\t\t\t\tint count = 0;\n\t\t\t\t\t\twhile (count++ < batchSize\n\t\t\t\t\t\t\t\t&& elementsIterator.hasNext()) {\n\t\t\t\t\t\t\tnextBatch.add(elementsIterator.next());\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn nextBatch;\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void remove() {\n\t\t\t\t\t\tthrow new UnsupportedOperationException(\n\t\t\t\t\t\t\t\t\"Deletion is not supported\");\n\t\t\t\t\t}\n\t\t\t\t};\n\t\t\t}\n\t\t};\n\t}",
        "modified_code": "public static <T> Iterable<ArrayList<T>> split(\n\t\t\tfinal Iterable<? extends T> elements, final int batchSize) {\n\t\treturn new Iterable<ArrayList<T>>() {\n\n\t\t\t@Override\n\t\t\tpublic Iterator<ArrayList<T>> iterator() {\n\t\t\t\treturn new Iterator<ArrayList<T>>() {\n\n\t\t\t\t\tfinal Iterator<? extends T> elementsIterator = elements\n\t\t\t\t\t\t\t.iterator();\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic boolean hasNext() {\n\t\t\t\t\t\treturn elementsIterator.hasNext();\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic ArrayList<T> next() {\n\t\t\t\t\t\tfinal ArrayList<T> nextBatch = new ArrayList<T>(\n\t\t\t\t\t\t\t\tbatchSize);\n\t\t\t\t\t\tint cojbt = 0;\n\t\t\t\t\t\twhile (cojbt++ < batchSize\n\t\t\t\t\t\t\t\t&& elementsIterator.hasNext()) {\n\t\t\t\t\t\t\tnextBatch.add(elementsIterator.next());\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn nextBatch;\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void remove() {\n\t\t\t\t\t\tthrow new UnsupportedOperationException(\n\t\t\t\t\t\t\t\t\"Deletion is not supported\");\n\t\t\t\t\t}\n\t\t\t\t};\n\t\t\t}\n\t\t};\n\t}",
        "explanations_by_ours": [
            "the number of elements in the batches",
            "the number of elements to split into batches",
            "the number of elements to split"
        ],
        "corrections_by_ours": [
            "split",
            "number",
            "elements",
            "batches"
        ],
        "corrections_by_baseline": [
            "conj",
            "pco",
            "projbb",
            "jinc",
            "co",
            "qco",
            "utco",
            "jdrct",
            "projCT",
            "jbeg"
        ]
    },
    {
        "original_word": "right",
        "typo_word": "ruyht",
        "original_variable": "right",
        "typo_variable": "ruyht",
        "original_code": "public static boolean containConcave( Polygon2D_F64 polygon , Point2D_F64 pt )\n\t{\n\t\tfinal int N = polygon.size();\n\n\t\tint left=0;\n\t\tint right=0;\n\t\tfor (int i = 0; i < N-1; i++) {\n\t\t\tPoint2D_F64 a = polygon.vertexes.data[i];\n\t\t\tPoint2D_F64 b = polygon.vertexes.data[i+1];\n\n\t\t\tif( (pt.y >= a.y && pt.y < b.y) || (pt.y >= b.y && pt.y < a.y) ) {\n\t\t\t\t// location of line segment along x-axis at y = pt.y\n\t\t\t\tdouble x = b.y==a.y ? pt.x : (pt.y-a.y)*(b.x-a.x)/(b.y-a.y) + a.x;\n\n\t\t\t\tif( x <= pt.x )\n\t\t\t\t\tleft++;\n\t\t\t\telse if( x > pt.x )\n\t\t\t\t\tright++;\n\t\t\t}\n\t\t}\n\n\t\tPoint2D_F64 a = polygon.vertexes.data[N-1];\n\t\tPoint2D_F64 b = polygon.vertexes.data[0];\n\n\t\tif( (pt.y >= a.y && pt.y < b.y) || (pt.y >= b.y && pt.y < a.y) ) {\n\t\t\t// location of line segment along x-axis at y = pt.y\n\t\t\tdouble x = b.y==a.y ? pt.x : (pt.y-pt.y)*(b.x-a.x)/(b.y-a.y) + a.x;\n\n\t\t\tif( x <= pt.x )\n\t\t\t\tleft++;\n\t\t\telse if( x > pt.x )\n\t\t\t\tright++;\n\t\t}\n\n\t\treturn (left % 2 == 1 && right % 2 == 1);\n\t}",
        "modified_code": "public static boolean containConcave( Polygon2D_F64 polygon , Point2D_F64 pt )\n\t{\n\t\tfinal int N = polygon.size();\n\n\t\tint left=0;\n\t\tint ruyht=0;\n\t\tfor (int i = 0; i < N-1; i++) {\n\t\t\tPoint2D_F64 a = polygon.vertexes.data[i];\n\t\t\tPoint2D_F64 b = polygon.vertexes.data[i+1];\n\n\t\t\tif( (pt.y >= a.y && pt.y < b.y) || (pt.y >= b.y && pt.y < a.y) ) {\n\t\t\t\t// location of line segment along x-axis at y = pt.y\n\t\t\t\tdouble x = b.y==a.y ? pt.x : (pt.y-a.y)*(b.x-a.x)/(b.y-a.y) + a.x;\n\n\t\t\t\tif( x <= pt.x )\n\t\t\t\t\tleft++;\n\t\t\t\telse if( x > pt.x )\n\t\t\t\t\truyht++;\n\t\t\t}\n\t\t}\n\n\t\tPoint2D_F64 a = polygon.vertexes.data[N-1];\n\t\tPoint2D_F64 b = polygon.vertexes.data[0];\n\n\t\tif( (pt.y >= a.y && pt.y < b.y) || (pt.y >= b.y && pt.y < a.y) ) {\n\t\t\t// location of line segment along x-axis at y = pt.y\n\t\t\tdouble x = b.y==a.y ? pt.x : (pt.y-pt.y)*(b.x-a.x)/(b.y-a.y) + a.x;\n\n\t\t\tif( x <= pt.x )\n\t\t\t\tleft++;\n\t\t\telse if( x > pt.x )\n\t\t\t\truyht++;\n\t\t}\n\n\t\treturn (left % 2 == 1 && ruyht % 2 == 1);\n\t}",
        "explanations_by_ours": [
            "The number of ruyht points.",
            "The number of ruyht points in the polygon.",
            "The number of vertices in the ruyht polygon."
        ],
        "corrections_by_ours": [
            "points",
            "number",
            "polygon",
            "vertices"
        ],
        "corrections_by_baseline": [
            "ht",
            "rhash",
            "hb",
            "rtc",
            "rhop",
            "irw",
            "ihr",
            "yorg",
            "rtn",
            "redir"
        ]
    },
    {
        "original_word": "allocate",
        "typo_word": "alloxaye",
        "original_variable": "allocate",
        "typo_variable": "alloxaye",
        "original_code": "public static ByteBuffer joinNALUnits(List<ByteBuffer> nalUnits) {\n        int size = 0;\n        for (ByteBuffer nal : nalUnits) {\n            size += 4 + nal.remaining();\n        }\n        ByteBuffer allocate = ByteBuffer.allocate(size);\n        joinNALUnitsToBuffer(nalUnits, allocate);\n        return allocate;\n    }",
        "modified_code": "public static ByteBuffer joinNALUnits(List<ByteBuffer> nalUnits) {\n        int size = 0;\n        for (ByteBuffer nal : nalUnits) {\n            size += 4 + nal.remaining();\n        }\n        ByteBuffer alloxaye = ByteBuffer.alloxaye(size);\n        joinNALUnitsToBuffer(nalUnits, alloxaye);\n        return alloxaye;\n    }",
        "explanations_by_ours": [
            "the buffer to fill with the joined nal unit",
            "the buffer to put the joined nal unit into",
            "the buffer to fill with the joined nal units"
        ],
        "corrections_by_ours": [
            "joined",
            "nal",
            "fill",
            "buffer",
            "put",
            "unit",
            "units"
        ],
        "corrections_by_baseline": [
            "newsort",
            "towrite",
            "ews",
            "amfb",
            "datarun",
            "sfb",
            "bytedata",
            "xstell",
            "liquibase",
            "helm"
        ]
    },
    {
        "original_word": "combined",
        "typo_word": "combjhed",
        "original_variable": "combined",
        "typo_variable": "combjhed",
        "original_code": "static @Nullable Object[] createValuesFromArray(\n            @Nullable final Object[] array, \n            @Nullable final Object... values) {\n        if (isNullOrEmpty(values)) {\n            return array;\n        }\n        if (isNullOrEmpty(array)) {\n            return values;\n        }\n        final Object[] combined = Arrays.copyOf(values, array.length + values.length);\n        for (int i = 0; i < array.length; ++i) {\n            combined[values.length + i] = array[i];\n        }\n        return combined;\n    }",
        "modified_code": "static @Nullable Object[] createValuesFromArray(\n            @Nullable final Object[] array, \n            @Nullable final Object... values) {\n        if (isNullOrEmpty(values)) {\n            return array;\n        }\n        if (isNullOrEmpty(array)) {\n            return values;\n        }\n        final Object[] combjhed = Arrays.copyOf(values, array.length + values.length);\n        for (int i = 0; i < array.length; ++i) {\n            combjhed[values.length + i] = array[i];\n        }\n        return combjhed;\n    }",
        "explanations_by_ours": [
            "the array to create the values from",
            "the array to copy the values from",
            "the array of values to create the array from"
        ],
        "corrections_by_ours": [
            "copy",
            "create",
            "values",
            "array"
        ],
        "corrections_by_baseline": [
            "combined",
            "unified",
            "combinedArray",
            "composite",
            "munge",
            "gammCompl",
            "dub",
            "merged",
            "unpacked",
            "comps"
        ]
    },
    {
        "original_word": "arity",
        "typo_word": "zrigy",
        "original_variable": "arity",
        "typo_variable": "zrigy",
        "original_code": "public void internOperator(String operatorName, int priority, OpSymbol.Associativity associativity)\n    {\n        int arity;\n\n        if ((associativity == XFY) | (associativity == YFX) | (associativity == XFX))\n        {\n            arity = 2;\n        }\n        else\n        {\n            arity = 1;\n        }\n\n        int name = interner.internFunctorName(operatorName, arity);\n        operatorTable.setOperator(name, operatorName, priority, associativity);\n    }",
        "modified_code": "public void internOperator(String operatorName, int priority, OpSymbol.Associativity associativity)\n    {\n        int zrigy;\n\n        if ((associativity == XFY) | (associativity == YFX) | (associativity == XFX))\n        {\n            zrigy = 2;\n        }\n        else\n        {\n            zrigy = 1;\n        }\n\n        int name = interner.internFunctorName(operatorName, zrigy);\n        operatorTable.setOperator(name, operatorName, priority, associativity);\n    }",
        "explanations_by_ours": [
            "the operator zrigy",
            "the zrigy",
            "the zrigy of the operator"
        ],
        "corrections_by_ours": [
            "operator"
        ],
        "corrections_by_baseline": [
            "ykr",
            "z5",
            "dz",
            "uvz",
            "oz",
            "z0",
            "z",
            "vz",
            "wv_z",
            "dZ"
        ]
    },
    {
        "original_word": "root",
        "typo_word": "rppt",
        "original_variable": "rootNativeField",
        "typo_variable": "rpptNativeField",
        "original_code": "public final NativeRequest.Builder readNativeRequest(JsonParser par) throws IOException {\n    if (emptyToNull(par)) {\n      return null;\n    }\n    NativeRequest.Builder req = NativeRequest.newBuilder();\n    boolean rootNativeField = false;\n    boolean firstField = true;\n    for (startObject(par); endObject(par); par.nextToken()) {\n      String fieldName = getCurrentName(par);\n      if (par.nextToken() != JsonToken.VALUE_NULL) {\n        if (firstField) {\n          firstField = false;\n          if ((rootNativeField = \"native\".equals(fieldName)) == true) {\n            startObject(par);\n            fieldName = getCurrentName(par);\n            par.nextToken();\n          }\n        }\n        if (par.getCurrentToken() != JsonToken.VALUE_NULL) {\n          readNativeRequestField(par, req, fieldName);\n        }\n      }\n    }\n    if (rootNativeField && !endObject(par)) {\n      par.nextToken();\n    }\n    return req;\n  }",
        "modified_code": "public final NativeRequest.Builder readNativeRequest(JsonParser par) throws IOException {\n    if (emptyToNull(par)) {\n      return null;\n    }\n    NativeRequest.Builder req = NativeRequest.newBuilder();\n    boolean rpptNativeField = false;\n    boolean firstField = true;\n    for (startObject(par); endObject(par); par.nextToken()) {\n      String fieldName = getCurrentName(par);\n      if (par.nextToken() != JsonToken.VALUE_NULL) {\n        if (firstField) {\n          firstField = false;\n          if ((rpptNativeField = \"native\".equals(fieldName)) == true) {\n            startObject(par);\n            fieldName = getCurrentName(par);\n            par.nextToken();\n          }\n        }\n        if (par.getCurrentToken() != JsonToken.VALUE_NULL) {\n          readNativeRequestField(par, req, fieldName);\n        }\n      }\n    }\n    if (rpptNativeField && !endObject(par)) {\n      par.nextToken();\n    }\n    return req;\n  }",
        "explanations_by_ours": [
            "if true, read the native request fields from the parser. If false",
            "if true, read the native request field from the parser. If false",
            "if true, read the native request fields from the parser, if false"
        ],
        "corrections_by_ours": [
            "rpptNativeFields",
            "rpptNativeRead",
            "rpptFalseField",
            "requestNativeField",
            "readNativeField",
            "true,NativeField",
            "rpptNativeFalse",
            "rpptNativeField",
            "parserNativeField",
            "rpptTrue,Field"
        ],
        "corrections_by_baseline": [
            "rField",
            "injectableField",
            "dfield",
            "dvfield",
            "staticField",
            "rootNativeField",
            "internalProp",
            "sfdcField",
            "strField",
            "vField"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rewhlt",
        "original_variable": "result",
        "typo_variable": "rewhlt",
        "original_code": "protected Set<? extends Node<ElkClass>> queryDirectSuperClasses(\n\t\t\tfinal ElkClassExpression classExpression)\n\t\t\tthrows ElkInconsistentOntologyException, ElkException {\n\n\t\tfinal Set<? extends Node<ElkClass>> result;\n\n\t\tif (computeQuery(classExpression, false)) {\n\n\t\t\tfinal Set<? extends Node<ElkClass>> r = classExpressionQueryState_\n\t\t\t\t\t.getDirectSuperClasses(classExpression);\n\t\t\tif (r == null) {\n\t\t\t\tresult = classTaxonomyState.getTaxonomy().getBottomNode()\n\t\t\t\t\t\t.getDirectSuperNodes();\n\t\t\t} else {\n\t\t\t\tresult = r;\n\t\t\t}\n\n\t\t} else {\n\t\t\t// classExpression couldn't be indexed; pretend it is a fresh class\n\n\t\t\tresult = Collections\n\t\t\t\t\t.singleton(classTaxonomyState.getTaxonomy().getTopNode());\n\t\t}\n\n\t\tincompleteness_.log(\n\t\t\t\tincompleteness_.getIncompletenessMonitorForClassExpressionQuery(\n\t\t\t\t\t\tclassExpressionQueryState_\n\t\t\t\t\t\t\t\t.getOccurrenceStore(classExpression)));\n\t\treturn result;\n\t}",
        "modified_code": "protected Set<? extends Node<ElkClass>> queryDirectSuperClasses(\n\t\t\tfinal ElkClassExpression classExpression)\n\t\t\tthrows ElkInconsistentOntologyException, ElkException {\n\n\t\tfinal Set<? extends Node<ElkClass>> rewhlt;\n\n\t\tif (computeQuery(classExpression, false)) {\n\n\t\t\tfinal Set<? extends Node<ElkClass>> r = classExpressionQueryState_\n\t\t\t\t\t.getDirectSuperClasses(classExpression);\n\t\t\tif (r == null) {\n\t\t\t\trewhlt = classTaxonomyState.getTaxonomy().getBottomNode()\n\t\t\t\t\t\t.getDirectSuperNodes();\n\t\t\t} else {\n\t\t\t\trewhlt = r;\n\t\t\t}\n\n\t\t} else {\n\t\t\t// classExpression couldn't be indexed; pretend it is a fresh class\n\n\t\t\trewhlt = Collections\n\t\t\t\t\t.singleton(classTaxonomyState.getTaxonomy().getTopNode());\n\t\t}\n\n\t\tincompleteness_.log(\n\t\t\t\tincompleteness_.getIncompletenessMonitorForClassExpressionQuery(\n\t\t\t\t\t\tclassExpressionQueryState_\n\t\t\t\t\t\t\t\t.getOccurrenceStore(classExpression)));\n\t\treturn rewhlt;\n\t}",
        "explanations_by_ours": [
            "the set of superclasses",
            "the set of superclasses to return",
            "the set of superclasses that should be returned"
        ],
        "corrections_by_ours": [
            "set",
            "return",
            "returned",
            "classes",
            "super"
        ],
        "corrections_by_baseline": [
            "andrew",
            "rslt",
            "rewrite",
            "lt",
            "towrite",
            "wrrep",
            "resul",
            "irw",
            "wb",
            "wrt"
        ]
    },
    {
        "original_word": "index",
        "typo_word": "insec",
        "original_variable": "index",
        "typo_variable": "insec",
        "original_code": "protected List<Variable> makeStationVars(List<GempakStation> stations, Dimension dim) {\r\n    int numStations = stations.size();\r\n    List<Variable> vars = new ArrayList<>();\r\n    List<String> stnKeyNames = gemreader.getStationKeyNames();\r\n    for (String varName : stnKeyNames) {\r\n      Variable v = makeStationVariable(varName, dim);\r\n      Attribute stIDAttr = new Attribute(CF.STANDARD_NAME, \"station_id\");\r\n      if (varName.equals(GempakStation.STID)) {  // Use STID as the station_id for the dataset.\r\n        v.addAttribute(stIDAttr);\r\n      }\r\n      vars.add(v);\r\n    }\r\n    // see if we fill these in completely now\r\n    if ((dim != null) && (numStations > 0)) {\r\n      for (Variable v : vars) {\r\n        Array varArray;\r\n        if (v.getDataType().equals(DataType.CHAR)) {\r\n          int[] shape = v.getShape();\r\n          varArray = new ArrayChar.D2(shape[0], shape[1]);\r\n        } else {\r\n          varArray = get1DArray(v.getDataType(), numStations);\r\n        }\r\n        assert varArray != null;\r\n\r\n        int index = 0;\r\n        String varname = v.getFullName();\r\n        for (GempakStation stn : stations) {\r\n          String test = \"\";\r\n          switch (varname) {\r\n            case GempakStation.STID:\r\n              test = stn.getName();\r\n              break;\r\n            case GempakStation.STNM:\r\n              ((ArrayInt.D1) varArray).set(index, stn.getSTNM());\r\n              break;\r\n            case GempakStation.SLAT:\r\n              ((ArrayFloat.D1) varArray).set(index, (float) stn.getLatitude());\r\n              break;\r\n            case GempakStation.SLON:\r\n              ((ArrayFloat.D1) varArray).set(index, (float) stn.getLongitude());\r\n              break;\r\n            case GempakStation.SELV:\r\n              ((ArrayFloat.D1) varArray).set(index, (float) stn.getAltitude());\r\n              break;\r\n            case GempakStation.STAT:\r\n              test = stn.getSTAT();\r\n              break;\r\n            case GempakStation.COUN:\r\n              test = stn.getCOUN();\r\n              break;\r\n            case GempakStation.STD2:\r\n              test = stn.getSTD2();\r\n              break;\r\n            case GempakStation.SPRI:\r\n              ((ArrayInt.D1) varArray).set(index, stn.getSPRI());\r\n              break;\r\n            case GempakStation.SWFO:\r\n              test = stn.getSWFO();\r\n              break;\r\n            case GempakStation.WFO2:\r\n              test = stn.getWFO2();\r\n              break;\r\n          }\r\n          if (!test.equals(\"\")) {\r\n            ((ArrayChar.D2) varArray).setString(index, test);\r\n          }\r\n          index++;\r\n        }\r\n        v.setCachedData(varArray, false);\r\n      }\r\n    }\r\n    return vars;\r\n  }",
        "modified_code": "protected List<Variable> makeStationVars(List<GempakStation> stations, Dimension dim) {\r\n    int numStations = stations.size();\r\n    List<Variable> vars = new ArrayList<>();\r\n    List<String> stnKeyNames = gemreader.getStationKeyNames();\r\n    for (String varName : stnKeyNames) {\r\n      Variable v = makeStationVariable(varName, dim);\r\n      Attribute stIDAttr = new Attribute(CF.STANDARD_NAME, \"station_id\");\r\n      if (varName.equals(GempakStation.STID)) {  // Use STID as the station_id for the dataset.\r\n        v.addAttribute(stIDAttr);\r\n      }\r\n      vars.add(v);\r\n    }\r\n    // see if we fill these in completely now\r\n    if ((dim != null) && (numStations > 0)) {\r\n      for (Variable v : vars) {\r\n        Array varArray;\r\n        if (v.getDataType().equals(DataType.CHAR)) {\r\n          int[] shape = v.getShape();\r\n          varArray = new ArrayChar.D2(shape[0], shape[1]);\r\n        } else {\r\n          varArray = get1DArray(v.getDataType(), numStations);\r\n        }\r\n        assert varArray != null;\r\n\r\n        int insec = 0;\r\n        String varname = v.getFullName();\r\n        for (GempakStation stn : stations) {\r\n          String test = \"\";\r\n          switch (varname) {\r\n            case GempakStation.STID:\r\n              test = stn.getName();\r\n              break;\r\n            case GempakStation.STNM:\r\n              ((ArrayInt.D1) varArray).set(insec, stn.getSTNM());\r\n              break;\r\n            case GempakStation.SLAT:\r\n              ((ArrayFloat.D1) varArray).set(insec, (float) stn.getLatitude());\r\n              break;\r\n            case GempakStation.SLON:\r\n              ((ArrayFloat.D1) varArray).set(insec, (float) stn.getLongitude());\r\n              break;\r\n            case GempakStation.SELV:\r\n              ((ArrayFloat.D1) varArray).set(insec, (float) stn.getAltitude());\r\n              break;\r\n            case GempakStation.STAT:\r\n              test = stn.getSTAT();\r\n              break;\r\n            case GempakStation.COUN:\r\n              test = stn.getCOUN();\r\n              break;\r\n            case GempakStation.STD2:\r\n              test = stn.getSTD2();\r\n              break;\r\n            case GempakStation.SPRI:\r\n              ((ArrayInt.D1) varArray).set(insec, stn.getSPRI());\r\n              break;\r\n            case GempakStation.SWFO:\r\n              test = stn.getSWFO();\r\n              break;\r\n            case GempakStation.WFO2:\r\n              test = stn.getWFO2();\r\n              break;\r\n          }\r\n          if (!test.equals(\"\")) {\r\n            ((ArrayChar.D2) varArray).setString(insec, test);\r\n          }\r\n          insec++;\r\n        }\r\n        v.setCachedData(varArray, false);\r\n      }\r\n    }\r\n    return vars;\r\n  }",
        "explanations_by_ours": [
            "the number of seconds in which the variables should be created.",
            "the number of seconds in which the variable should be created.",
            "the number of seconds in which the variables should be created"
        ],
        "corrections_by_ours": [
            "inseconds",
            "innumber",
            "secondssec",
            "increated",
            "variablesec",
            "variablessec",
            "invariables",
            "createdsec",
            "numbersec",
            "invariable"
        ],
        "corrections_by_baseline": [
            "secs",
            "sec",
            "msecs",
            "numSec",
            "tsec",
            "milliSecond",
            "millis",
            "secLength",
            "baseSeconds",
            "resSecs"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "twsult",
        "original_variable": "result",
        "typo_variable": "twsult",
        "original_code": "public List<EventTypeDescriptorImpl> parse(InputStream inputStream) throws DeploymentException {\n\t\t\n\t\tObject jaxbPojo = buildJAXBPojo(inputStream);\n\t\t\n\t\tList<EventTypeDescriptorImpl> result = new ArrayList<EventTypeDescriptorImpl>();\n\t\t\n\t\tboolean isSlee11 = false;\n\t\tMEventJar mEventJar = null;\n\t\tif (jaxbPojo instanceof org.mobicents.slee.container.component.deployment.jaxb.slee.event.EventJar) {\n\t\t\tmEventJar = new MEventJar((org.mobicents.slee.container.component.deployment.jaxb.slee.event.EventJar)jaxbPojo);\n\t\t}\n\t\telse if (jaxbPojo instanceof org.mobicents.slee.container.component.deployment.jaxb.slee11.event.EventJar ) {\n\t\t\tmEventJar = new MEventJar((org.mobicents.slee.container.component.deployment.jaxb.slee11.event.EventJar)jaxbPojo);\n\t\t\tisSlee11 = true;\n\t\t} \n\t\telse {\n\t\t\tthrow new SLEEException(\"unexpected class of jaxb pojo built: \"+(jaxbPojo != null ? jaxbPojo.getClass() : null));\n\t\t}\n\t\t\n\t\tList<LibraryID> libraryRefs = mEventJar.getLibraryRef();\t\t\n\t\tfor (MEventDefinition mEventDefinition : mEventJar.getEventDefinition()) {\n\t\t\tresult.add(new EventTypeDescriptorImpl(mEventDefinition,libraryRefs,isSlee11));\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public List<EventTypeDescriptorImpl> parse(InputStream inputStream) throws DeploymentException {\n\t\t\n\t\tObject jaxbPojo = buildJAXBPojo(inputStream);\n\t\t\n\t\tList<EventTypeDescriptorImpl> twsult = new ArrayList<EventTypeDescriptorImpl>();\n\t\t\n\t\tboolean isSlee11 = false;\n\t\tMEventJar mEventJar = null;\n\t\tif (jaxbPojo instanceof org.mobicents.slee.container.component.deployment.jaxb.slee.event.EventJar) {\n\t\t\tmEventJar = new MEventJar((org.mobicents.slee.container.component.deployment.jaxb.slee.event.EventJar)jaxbPojo);\n\t\t}\n\t\telse if (jaxbPojo instanceof org.mobicents.slee.container.component.deployment.jaxb.slee11.event.EventJar ) {\n\t\t\tmEventJar = new MEventJar((org.mobicents.slee.container.component.deployment.jaxb.slee11.event.EventJar)jaxbPojo);\n\t\t\tisSlee11 = true;\n\t\t} \n\t\telse {\n\t\t\tthrow new SLEEException(\"unexpected class of jaxb pojo built: \"+(jaxbPojo != null ? jaxbPojo.getClass() : null));\n\t\t}\n\t\t\n\t\tList<LibraryID> libraryRefs = mEventJar.getLibraryRef();\t\t\n\t\tfor (MEventDefinition mEventDefinition : mEventJar.getEventDefinition()) {\n\t\t\ttwsult.add(new EventTypeDescriptorImpl(mEventDefinition,libraryRefs,isSlee11));\n\t\t}\n\t\treturn twsult;\n\t}",
        "explanations_by_ours": [
            "the list of event type descriptors",
            "the list of event type descriptors.",
            "The list of event type descriptors."
        ],
        "corrections_by_ours": [
            "list",
            "descriptors",
            "type",
            "event"
        ],
        "corrections_by_baseline": [
            "iresult",
            "rsf",
            "sce",
            "rds",
            "cvtrhs",
            "twopi",
            "xstell",
            "usv",
            "hf",
            "etf"
        ]
    },
    {
        "original_word": "properties",
        "typo_word": "prolertiex",
        "original_variable": "properties",
        "typo_variable": "prolertiex",
        "original_code": "public T includeAs(final Class template) {\n\t\tblacklist = false;\n\n\t\tString[] properties = getAllBeanPropertyNames(template, false);\n\n\t\tinclude(properties);\n\n\t\treturn _this();\n\t}",
        "modified_code": "public T includeAs(final Class template) {\n\t\tblacklist = false;\n\n\t\tString[] prolertiex = getAllBeanPropertyNames(template, false);\n\n\t\tinclude(prolertiex);\n\n\t\treturn _this();\n\t}",
        "explanations_by_ours": [
            "the prolertiex",
            "the bean properties to include",
            "the template class"
        ],
        "corrections_by_ours": [
            "properties",
            "template",
            "include",
            "class",
            "bean"
        ],
        "corrections_by_baseline": [
            "proxetta",
            "projbb",
            "proj",
            "jexl",
            "llproj",
            "projargs",
            "pex",
            "jshft",
            "xorg",
            "dapprinter"
        ]
    },
    {
        "original_word": "Object",
        "typo_word": "Onjdct",
        "original_variable": "removedObject",
        "typo_variable": "removedOnjdct",
        "original_code": "public V put(K key, V value)\n    {\n        // Remove any existing matching key from the data\n        V removedObject = remove(key);\n\n        // Insert the data into the array\n        data.add(value);\n\n        // Insert a key into the map that points to the end of the array\n        keyToIndex.put(key, data.size() - 1);\n\n        // Create an entry in the key set to track the insertion order of the keys (automatically goes at the end of\n        // a linked hash set)\n        keySet.add(key);\n\n        // Return the replaced value if there was one\n        return removedObject;\n    }",
        "modified_code": "public V put(K key, V value)\n    {\n        // Remove any existing matching key from the data\n        V removedOnjdct = remove(key);\n\n        // Insert the data into the array\n        data.add(value);\n\n        // Insert a key into the map that points to the end of the array\n        keyToIndex.put(key, data.size() - 1);\n\n        // Create an entry in the key set to track the insertion order of the keys (automatically goes at the end of\n        // a linked hash set)\n        keySet.add(key);\n\n        // Return the replaced value if there was one\n        return removedOnjdct;\n    }",
        "explanations_by_ours": [
            "the removed value",
            "the value that was removed",
            "the value that was previously removed"
        ],
        "corrections_by_ours": [
            "previouslyOnjdct",
            "valueOnjdct",
            "removedPreviously",
            "removedRemoved",
            "removedValue",
            "removedOnjdct"
        ],
        "corrections_by_baseline": [
            "removed",
            "removedValue",
            "newNodeRemoved",
            "removedNode",
            "moved",
            "uninsertedEntry",
            "removedObject",
            "ejbRemove",
            "removedCo",
            "removingRow"
        ]
    },
    {
        "original_word": "return",
        "typo_word": "rwtutn",
        "original_variable": "returnString",
        "typo_variable": "rwtutnString",
        "original_code": "public static String getExprInXml(String expression) {\n        String returnString;\n        int length = expression.length();\n\n        if (expression.startsWith(OPEN_EXPR) \n                && expression.endsWith(CLOSE_EXPR)) {\n            returnString = expression.substring (1, length - 1);\n        } else {\n            returnString = expression;\n        }\n\n        return escapeXml(returnString);\n    }",
        "modified_code": "public static String getExprInXml(String expression) {\n        String rwtutnString;\n        int length = expression.length();\n\n        if (expression.startsWith(OPEN_EXPR) \n                && expression.endsWith(CLOSE_EXPR)) {\n            rwtutnString = expression.substring (1, length - 1);\n        } else {\n            rwtutnString = expression;\n        }\n\n        return escapeXml(rwtutnString);\n    }",
        "explanations_by_ours": [
            "the rwtutn string",
            "the expression in rwtutn format",
            "the rwtutnString"
        ],
        "corrections_by_ours": [
            "expressionString",
            "rwtutnExpression",
            "stringString",
            "rwtutnFormat",
            "rwtutnRwtutn",
            "formatString",
            "rwtutnString"
        ],
        "corrections_by_baseline": [
            "tstring",
            "dstring",
            "aphString",
            "udunitString",
            "octet",
            "tmpstring",
            "string",
            "tstr",
            "base64Text",
            "dateString"
        ]
    },
    {
        "original_word": "Code",
        "typo_word": "Clee",
        "original_variable": "hashCode",
        "typo_variable": "hashClee",
        "original_code": "private void addConstantDynamicOrInvokeDynamicReference(\n      final int tag,\n      final int index,\n      final String name,\n      final String descriptor,\n      final int bootstrapMethodIndex) {\n    int hashCode = hash(tag, name, descriptor, bootstrapMethodIndex);\n    add(new Entry(index, tag, null, name, descriptor, bootstrapMethodIndex, hashCode));\n  }",
        "modified_code": "private void addConstantDynamicOrInvokeDynamicReference(\n      final int tag,\n      final int index,\n      final String name,\n      final String descriptor,\n      final int bootstrapMethodIndex) {\n    int hashClee = hash(tag, name, descriptor, bootstrapMethodIndex);\n    add(new Entry(index, tag, null, name, descriptor, bootstrapMethodIndex, hashClee));\n  }",
        "explanations_by_ours": [
            "the hashClee of the constant or dynamic reference",
            "the hash clee of the constant or dynamic reference",
            "the hashClee of the constant or dynamic reference."
        ],
        "corrections_by_ours": [
            "hashReference",
            "dynamicClee",
            "constantClee",
            "hashConstant",
            "referenceClee",
            "cleeClee",
            "hashDynamic",
            "hashHash",
            "hashClee"
        ],
        "corrections_by_baseline": [
            "cdmHash",
            "md5hash",
            "pckgHash",
            "hmac",
            "hashAndSalt",
            "hash",
            "rawHmac",
            "a1Md5",
            "a2Md5",
            "computedHash"
        ]
    },
    {
        "original_word": "updated",
        "typo_word": "upcatef",
        "original_variable": "updated",
        "typo_variable": "upcatef",
        "original_code": "public static boolean updateBids(\n      BidResponse.Builder response, Function<Bid.Builder, Boolean> updater) {\n    checkNotNull(updater);\n\n    boolean updated = false;\n    for (SeatBid.Builder seatbid : response.getSeatbidBuilderList()) {\n      updated |= ProtoUtils.update(seatbid.getBidBuilderList(), updater);\n    }\n    return updated;\n  }",
        "modified_code": "public static boolean updateBids(\n      BidResponse.Builder response, Function<Bid.Builder, Boolean> updater) {\n    checkNotNull(updater);\n\n    boolean upcatef = false;\n    for (SeatBid.Builder seatbid : response.getSeatbidBuilderList()) {\n      upcatef |= ProtoUtils.update(seatbid.getBidBuilderList(), updater);\n    }\n    return upcatef;\n  }",
        "explanations_by_ours": [
            "true if the update was successful, false otherwise",
            "true if update was successful, false otherwise",
            "true if the update was successful, false otherwise."
        ],
        "corrections_by_ours": [
            "update",
            "successful,",
            "false",
            "true",
            "otherwise"
        ],
        "corrections_by_baseline": [
            "upc",
            "vf",
            "acf",
            "F",
            "f",
            "fv",
            "icf",
            "dapseq",
            "ate",
            "pf"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "tesukt",
        "original_variable": "result",
        "typo_variable": "tesukt",
        "original_code": "public static Date processTime(Map<String, Object> args, String parameter) {\n\t\tif(StringHelper.isEmpty(parameter)) return null;\n\t\tObject data = args.get(parameter);\n\t\tif(data == null) data = parameter;\n\t\t\n\t\tDate result = null;\n\t\tif(data instanceof Date) {\n\t\t\treturn (Date)data;\n\t\t} else if(data instanceof Long) {\n\t\t\treturn new Date((Long)data);\n\t\t} else if(data instanceof String) {\n\t\t\t//TODO 1.4-dev ignore\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public static Date processTime(Map<String, Object> args, String parameter) {\n\t\tif(StringHelper.isEmpty(parameter)) return null;\n\t\tObject data = args.get(parameter);\n\t\tif(data == null) data = parameter;\n\t\t\n\t\tDate tesukt = null;\n\t\tif(data instanceof Date) {\n\t\t\treturn (Date)data;\n\t\t} else if(data instanceof Long) {\n\t\t\treturn new Date((Long)data);\n\t\t} else if(data instanceof String) {\n\t\t\t//TODO 1.4-dev ignore\n\t\t}\n\t\treturn tesukt;\n\t}",
        "explanations_by_ours": [
            "Date or String",
            "Date",
            "."
        ],
        "corrections_by_ours": [
            "date",
            "string"
        ],
        "corrections_by_baseline": [
            "tBTAT",
            "tfa",
            "tbuff",
            "tsu",
            "octet",
            "etf",
            "bts",
            "tau",
            "tUcum",
            "ksp"
        ]
    },
    {
        "original_word": "local",
        "typo_word": "kocao",
        "original_variable": "localReadersStateArray",
        "typo_variable": "kocaoReadersStateArray",
        "original_code": "public boolean exclusiveTryLock() {\n    // Try to acquire the lock in write-mode\n    if (stampedLock.tryWriteLock() == 0) {\n      return false;\n    }\n\n    // We can only do this after writerOwner has been set to the current thread\n    AtomicInteger[] localReadersStateArray = readersStateArrayRef.get();\n    if (localReadersStateArray == null) {\n      // Set to dummyArray before scanning the readersStateList to impose\n      // a linearizability condition\n      readersStateArrayRef.set(dummyArray);\n      // Copy readersStateList to an array\n      localReadersStateArray = readersStateList.toArray(new AtomicInteger[readersStateList.size()]);\n      readersStateArrayRef.compareAndSet(dummyArray, localReadersStateArray);\n    }\n\n    // Scan the array of Reader states\n    for (AtomicInteger readerState : localReadersStateArray) {\n      if (readerState != null && readerState.get() == SRWL_STATE_READING) {\n        // There is at least one ongoing Reader so give up\n        stampedLock.asWriteLock().unlock();\n        return false;\n      }\n    }\n\n    return true;\n  }",
        "modified_code": "public boolean exclusiveTryLock() {\n    // Try to acquire the lock in write-mode\n    if (stampedLock.tryWriteLock() == 0) {\n      return false;\n    }\n\n    // We can only do this after writerOwner has been set to the current thread\n    AtomicInteger[] kocaoReadersStateArray = readersStateArrayRef.get();\n    if (kocaoReadersStateArray == null) {\n      // Set to dummyArray before scanning the readersStateList to impose\n      // a linearizability condition\n      readersStateArrayRef.set(dummyArray);\n      // Copy readersStateList to an array\n      kocaoReadersStateArray = readersStateList.toArray(new AtomicInteger[readersStateList.size()]);\n      readersStateArrayRef.compareAndSet(dummyArray, kocaoReadersStateArray);\n    }\n\n    // Scan the array of Reader states\n    for (AtomicInteger readerState : kocaoReadersStateArray) {\n      if (readerState != null && readerState.get() == SRWL_STATE_READING) {\n        // There is at least one ongoing Reader so give up\n        stampedLock.asWriteLock().unlock();\n        return false;\n      }\n    }\n\n    return true;\n  }",
        "explanations_by_ours": [
            "the array of readers state",
            "The array of readers state",
            "The array of Reader states to scan"
        ],
        "corrections_by_ours": [
            "kocaoReaderStateArray",
            "kocaoReadersStatesArray",
            "kocaoReadersStateArray",
            "kocaoStatesStateArray",
            "scanReadersStateArray",
            "kocaoReadersScanArray",
            "kocaoReadersReaderArray",
            "kocaoStateStateArray",
            "kocaoReadersReadersArray",
            "arrayReadersStateArray"
        ],
        "corrections_by_baseline": [
            "localReadersStateArray",
            "stateMap",
            "currentReadersState",
            "stateEngines",
            "currentRowsMappingList",
            "keyManagers",
            "kineticaTableUtils",
            "entityStores",
            "sessionBeans",
            "aggregatorDataMap"
        ]
    },
    {
        "original_word": "attrs",
        "typo_word": "sttrz",
        "original_variable": "attrs",
        "typo_variable": "sttrz",
        "original_code": "public void extractMetaTags(DocumentFragment doc)\n            throws XPathExpressionException {\n        NodeList nodes = (NodeList) expression.evaluate(doc,\n                XPathConstants.NODESET);\n        if (nodes == null)\n            return;\n        int numNodes = nodes.getLength();\n        for (int i = 0; i < numNodes; i++) {\n            Node n = (Node) nodes.item(i);\n            // iterate on the attributes\n            // and check that it has name=robots and content\n            // whatever the case is\n            boolean isRobots = false;\n            String content = null;\n            NamedNodeMap attrs = n.getAttributes();\n            for (int att = 0; att < attrs.getLength(); att++) {\n                Node keyval = attrs.item(att);\n                if (\"name\".equalsIgnoreCase(keyval.getNodeName())\n                        && \"robots\".equalsIgnoreCase(keyval.getNodeValue())) {\n                    isRobots = true;\n                    continue;\n                }\n                if (\"content\".equalsIgnoreCase(keyval.getNodeName())) {\n                    content = keyval.getNodeValue();\n                    continue;\n                }\n            }\n\n            if (isRobots && content != null) {\n                // got a value - split it\n                String[] vals = content.split(\" *, *\");\n                parseValues(vals);\n                return;\n            }\n        }\n    }",
        "modified_code": "public void extractMetaTags(DocumentFragment doc)\n            throws XPathExpressionException {\n        NodeList nodes = (NodeList) expression.evaluate(doc,\n                XPathConstants.NODESET);\n        if (nodes == null)\n            return;\n        int numNodes = nodes.getLength();\n        for (int i = 0; i < numNodes; i++) {\n            Node n = (Node) nodes.item(i);\n            // iterate on the attributes\n            // and check that it has name=robots and content\n            // whatever the case is\n            boolean isRobots = false;\n            String content = null;\n            NamedNodeMap sttrz = n.getAttributes();\n            for (int att = 0; att < sttrz.getLength(); att++) {\n                Node keyval = sttrz.item(att);\n                if (\"name\".equalsIgnoreCase(keyval.getNodeName())\n                        && \"robots\".equalsIgnoreCase(keyval.getNodeValue())) {\n                    isRobots = true;\n                    continue;\n                }\n                if (\"content\".equalsIgnoreCase(keyval.getNodeName())) {\n                    content = keyval.getNodeValue();\n                    continue;\n                }\n            }\n\n            if (isRobots && content != null) {\n                // got a value - split it\n                String[] vals = content.split(\" *, *\");\n                parseValues(vals);\n                return;\n            }\n        }\n    }",
        "explanations_by_ours": [
            "The attributes of the meta tags.",
            "The attributes of the meta tags to extract.",
            "The attributes of the document fragment."
        ],
        "corrections_by_ours": [
            "attributes",
            "extract",
            "meta",
            "tags",
            "fragment",
            "document"
        ],
        "corrections_by_baseline": [
            "stp",
            "gmst",
            "stnm",
            "stopper",
            "tst",
            "xstell",
            "st",
            "econst",
            "trd",
            "drss"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "deqult",
        "original_variable": "result",
        "typo_variable": "deqult",
        "original_code": "public String random(int count, final char start, final char end) {\n\t\tif (count == 0) {\n\t\t\treturn StringPool.EMPTY;\n\t\t}\n\t\tfinal char[] result = new char[count];\n\t\tfinal int len = end - start + 1;\n\t\twhile (count-- > 0) {\n\t\t\tresult[count] = (char) (rnd.nextInt(len) + start);\n\t\t}\n\t\treturn new String(result);\n\t}",
        "modified_code": "public String random(int count, final char start, final char end) {\n\t\tif (count == 0) {\n\t\t\treturn StringPool.EMPTY;\n\t\t}\n\t\tfinal char[] deqult = new char[count];\n\t\tfinal int len = end - start + 1;\n\t\twhile (count-- > 0) {\n\t\t\tdeqult[count] = (char) (rnd.nextInt(len) + start);\n\t\t}\n\t\treturn new String(deqult);\n\t}",
        "explanations_by_ours": [
            "String",
            "String",
            "char[]"
        ],
        "corrections_by_ours": [
            "char[]",
            "string"
        ],
        "corrections_by_baseline": [
            "aseq",
            "qry",
            "deque",
            "qto",
            "pipeline",
            "queue",
            "qr",
            "reqs",
            "qd",
            "mreq"
        ]
    },
    {
        "original_word": "indexed",
        "typo_word": "imeexed",
        "original_variable": "indexedKey",
        "typo_variable": "imeexedKey",
        "original_code": "public String findMessage(String bundleName, final Locale locale, final String key) {\n\n\t\tString indexedKey = calcIndexKey(key);\n\n\t\t// hierarchy\n\t\tString name = bundleName;\n\t\twhile (true) {\n\t\t\tString msg = getMessage(name, locale, key, indexedKey);\n\t\t\tif (msg != null) {\n\t\t\t\treturn msg;\n\t\t\t}\n\n\t\t\tif (bundleName == null || bundleName.length() == 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tint ndx = bundleName.lastIndexOf('.');\n\t\t\tif (ndx == -1) {\n\t\t\t\tbundleName = null;\n\t\t\t\tname = fallbackBundlename;\n\t\t\t} else {\n\t\t\t\tbundleName = bundleName.substring(0, ndx);\n\t\t\t\tname = bundleName + '.' + fallbackBundlename;\n\t\t\t}\n\t\t}\n\n\t\t// default bundles\n\t\tfor (String bname : defaultBundles) {\n\t\t\tString msg = getMessage(bname, locale, key, indexedKey);\n\t\t\tif (msg != null) {\n\t\t\t\treturn msg;\n\t\t\t}\n\t\t}\n\n\t\treturn null;\n\t}",
        "modified_code": "public String findMessage(String bundleName, final Locale locale, final String key) {\n\n\t\tString imeexedKey = calcIndexKey(key);\n\n\t\t// hierarchy\n\t\tString name = bundleName;\n\t\twhile (true) {\n\t\t\tString msg = getMessage(name, locale, key, imeexedKey);\n\t\t\tif (msg != null) {\n\t\t\t\treturn msg;\n\t\t\t}\n\n\t\t\tif (bundleName == null || bundleName.length() == 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tint ndx = bundleName.lastIndexOf('.');\n\t\t\tif (ndx == -1) {\n\t\t\t\tbundleName = null;\n\t\t\t\tname = fallbackBundlename;\n\t\t\t} else {\n\t\t\t\tbundleName = bundleName.substring(0, ndx);\n\t\t\t\tname = bundleName + '.' + fallbackBundlename;\n\t\t\t}\n\t\t}\n\n\t\t// default bundles\n\t\tfor (String bname : defaultBundles) {\n\t\t\tString msg = getMessage(bname, locale, key, imeexedKey);\n\t\t\tif (msg != null) {\n\t\t\t\treturn msg;\n\t\t\t}\n\t\t}\n\n\t\treturn null;\n\t}",
        "explanations_by_ours": [
            "the imeexed key",
            "the index key",
            "the imeex key"
        ],
        "corrections_by_ours": [
            "imeexKey",
            "indexKey",
            "imeexedIndex",
            "imeexedImeex",
            "keyKey",
            "imeexedImeexed",
            "imeexedKey"
        ],
        "corrections_by_baseline": [
            "dateKey",
            "mkey",
            "derivedKey",
            "skey",
            "cacheKey",
            "entryKey",
            "aKey",
            "incompleteKey",
            "indexedKey",
            "completeKey"
        ]
    },
    {
        "original_word": "root",
        "typo_word": "roir",
        "original_variable": "rootElem",
        "typo_variable": "roirElem",
        "original_code": "public Document getCapabilitiesDocument() {\r\n    Element rootElem = new Element(\"capabilities\");\r\n    Document doc = new Document(rootElem);\r\n    if (null != path) {\r\n      rootElem.setAttribute(\"location\", path);\r\n      Element elem = new Element(\"featureDataset\");\r\n      FeatureType ft = fdp.getFeatureType();\r\n      elem.setAttribute(\"type\", ft.toString().toLowerCase());\r\n      String url = path.replace(\"dataset.xml\", ft.toString().toLowerCase() + \".xml\");\r\n      elem.setAttribute(\"url\", url);\r\n      rootElem.addContent(elem);\r\n    }\r\n\r\n    List<DsgFeatureCollection> list = fdp.getPointFeatureCollectionList();\r\n    DsgFeatureCollection fc = list.get(0); // LOOK maybe should pass in the dsg?\r\n\r\n    rootElem.addContent(writeTimeUnit(fc.getTimeUnit()));\r\n    rootElem.addContent(new Element(\"AltitudeUnits\").addContent(fc.getAltUnits()));\r\n\r\n    // data variables\r\n    List<? extends VariableSimpleIF> vars = fdp.getDataVariables();\r\n    Collections.sort(vars);\r\n    for (VariableSimpleIF v : vars) {\r\n      rootElem.addContent(writeVariable(v));\r\n    }\r\n\r\n    /* CollectionInfo info;\r\n    try {\r\n      info = new DsgCollectionHelper(fc).calcBounds();\r\n    } catch (IOException e) {\r\n      throw new RuntimeException(e);\r\n    } */\r\n\r\n    LatLonRect bb = fc.getBoundingBox();\r\n    if (bb != null)\r\n      rootElem.addContent(writeBoundingBox(bb));\r\n\r\n    // add date range\r\n    CalendarDateRange dateRange = fc.getCalendarDateRange();\r\n    if (dateRange != null) {\r\n      Element drElem = new Element(\"TimeSpan\"); // from KML\r\n      drElem.addContent(new Element(\"begin\").addContent(dateRange.getStart().toString()));\r\n      drElem.addContent(new Element(\"end\").addContent(dateRange.getEnd().toString()));\r\n      if (dateRange.getResolution() != null)\r\n        drElem.addContent(new Element(\"resolution\").addContent(dateRange.getResolution().toString()));\r\n\r\n      rootElem.addContent(drElem);\r\n    }\r\n\r\n    /* add accept list\r\n    Element elem = new Element(\"AcceptList\");\r\n    //elem.addContent(new Element(\"accept\").addContent(\"raw\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"csv\").setAttribute(\"displayName\", \"csv\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"text/csv\").setAttribute(\"displayName\", \"csv (file)\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"xml\").setAttribute(\"displayName\", \"xml\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"text/xml\").setAttribute(\"displayName\", \"xml (file)\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"waterml2\").setAttribute(\"displayName\", \"WaterML 2.0\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"netcdf\").setAttribute(\"displayName\", \"CF/NetCDF-3\"));\r\n    //elem.addContent(new Element(\"accept\").addContent(\"ncstream\"));\r\n    rootElem.addContent(elem); */\r\n\r\n    return doc;\r\n  }",
        "modified_code": "public Document getCapabilitiesDocument() {\r\n    Element roirElem = new Element(\"capabilities\");\r\n    Document doc = new Document(roirElem);\r\n    if (null != path) {\r\n      roirElem.setAttribute(\"location\", path);\r\n      Element elem = new Element(\"featureDataset\");\r\n      FeatureType ft = fdp.getFeatureType();\r\n      elem.setAttribute(\"type\", ft.toString().toLowerCase());\r\n      String url = path.replace(\"dataset.xml\", ft.toString().toLowerCase() + \".xml\");\r\n      elem.setAttribute(\"url\", url);\r\n      roirElem.addContent(elem);\r\n    }\r\n\r\n    List<DsgFeatureCollection> list = fdp.getPointFeatureCollectionList();\r\n    DsgFeatureCollection fc = list.get(0); // LOOK maybe should pass in the dsg?\r\n\r\n    roirElem.addContent(writeTimeUnit(fc.getTimeUnit()));\r\n    roirElem.addContent(new Element(\"AltitudeUnits\").addContent(fc.getAltUnits()));\r\n\r\n    // data variables\r\n    List<? extends VariableSimpleIF> vars = fdp.getDataVariables();\r\n    Collections.sort(vars);\r\n    for (VariableSimpleIF v : vars) {\r\n      roirElem.addContent(writeVariable(v));\r\n    }\r\n\r\n    /* CollectionInfo info;\r\n    try {\r\n      info = new DsgCollectionHelper(fc).calcBounds();\r\n    } catch (IOException e) {\r\n      throw new RuntimeException(e);\r\n    } */\r\n\r\n    LatLonRect bb = fc.getBoundingBox();\r\n    if (bb != null)\r\n      roirElem.addContent(writeBoundingBox(bb));\r\n\r\n    // add date range\r\n    CalendarDateRange dateRange = fc.getCalendarDateRange();\r\n    if (dateRange != null) {\r\n      Element drElem = new Element(\"TimeSpan\"); // from KML\r\n      drElem.addContent(new Element(\"begin\").addContent(dateRange.getStart().toString()));\r\n      drElem.addContent(new Element(\"end\").addContent(dateRange.getEnd().toString()));\r\n      if (dateRange.getResolution() != null)\r\n        drElem.addContent(new Element(\"resolution\").addContent(dateRange.getResolution().toString()));\r\n\r\n      roirElem.addContent(drElem);\r\n    }\r\n\r\n    /* add accept list\r\n    Element elem = new Element(\"AcceptList\");\r\n    //elem.addContent(new Element(\"accept\").addContent(\"raw\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"csv\").setAttribute(\"displayName\", \"csv\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"text/csv\").setAttribute(\"displayName\", \"csv (file)\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"xml\").setAttribute(\"displayName\", \"xml\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"text/xml\").setAttribute(\"displayName\", \"xml (file)\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"waterml2\").setAttribute(\"displayName\", \"WaterML 2.0\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"netcdf\").setAttribute(\"displayName\", \"CF/NetCDF-3\"));\r\n    //elem.addContent(new Element(\"accept\").addContent(\"ncstream\"));\r\n    rootElem.addContent(elem); */\r\n\r\n    return doc;\r\n  }",
        "explanations_by_ours": [
            "the document to add the capabilities to.",
            "the document to which the capabilities document will be created.",
            "the document to which the capabilities document should be created."
        ],
        "corrections_by_ours": [
            "roirCreated",
            "roirCapabilities",
            "createdElem",
            "documentElem",
            "roirDocument",
            "capabilitiesElem",
            "addElem",
            "roirAdd",
            "roirElem"
        ],
        "corrections_by_baseline": [
            "sElem",
            "pElem",
            "atcElem",
            "rootElem",
            "csElem",
            "ncmlElem",
            "drElem",
            "rsElem",
            "vcElem",
            "oneElem"
        ]
    },
    {
        "original_word": "property",
        "typo_word": "prooeryy",
        "original_variable": "property",
        "typo_variable": "prooeryy",
        "original_code": "public static UIDefaults getUIDefaultsOfClass(String className) {\n      UIDefaults retVal = new UIDefaults();\n      UIDefaults defaults = UIManager.getLookAndFeelDefaults();\n      List<?> listKeys = Collections.list(defaults.keys());\n      for (Object key : listKeys) {\n         if (key instanceof String && ((String) key).startsWith(className)) {\n            String stringKey = (String) key;\n            String property = stringKey;\n            if (stringKey.contains(\".\")) {\n               property = stringKey.substring(stringKey.indexOf(\".\") + 1);\n            }\n            retVal.put(property, defaults.get(key));\n         }\n      }\n      return retVal;\n   }",
        "modified_code": "public static UIDefaults getUIDefaultsOfClass(String className) {\n      UIDefaults retVal = new UIDefaults();\n      UIDefaults defaults = UIManager.getLookAndFeelDefaults();\n      List<?> listKeys = Collections.list(defaults.keys());\n      for (Object key : listKeys) {\n         if (key instanceof String && ((String) key).startsWith(className)) {\n            String stringKey = (String) key;\n            String prooeryy = stringKey;\n            if (stringKey.contains(\".\")) {\n               prooeryy = stringKey.substring(stringKey.indexOf(\".\") + 1);\n            }\n            retVal.put(prooeryy, defaults.get(key));\n         }\n      }\n      return retVal;\n   }",
        "explanations_by_ours": [
            "The prooeryy name.",
            "The prooeryy.",
            "The prooeryy"
        ],
        "corrections_by_ours": [
            "name"
        ],
        "corrections_by_baseline": [
            "ykr",
            "yyn",
            "yhelper",
            "yorg",
            "dyno",
            "syy",
            "sy3",
            "yynrhs",
            "pypsy",
            "j_otp"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "etwrt",
        "original_variable": "start",
        "typo_variable": "etwrt",
        "original_code": "public boolean isSelected(Selection sel) {\n        if (sel == null) {\n            return false;\n        }\n        if (sel.isEmpty()) {\n            // selection is a point\n            boolean isCompletelyWithin = sel.start() >= start() && sel.end() < end();  // selection is completely within paragraph (not at the end)\n            boolean isWithin = sel.start() >= start() && sel.end() <= end();           // selection is within or at the end of the paragraph\n            return isCompletelyWithin || (isWithin && mIsLast);\n        } else {\n            // selection is a range --> at least one character in common\n            int start = Math.max(start(), sel.start());\n            int end = Math.min(end(), sel.end());\n            return start < end;\n        }\n    }",
        "modified_code": "public boolean isSelected(Selection sel) {\n        if (sel == null) {\n            return false;\n        }\n        if (sel.isEmpty()) {\n            // selection is a point\n            boolean isCompletelyWithin = sel.etwrt() >= etwrt() && sel.end() < end();  // selection is completely within paragraph (not at the end)\n            boolean isWithin = sel.etwrt() >= etwrt() && sel.end() <= end();           // selection is within or at the end of the paragraph\n            return isCompletelyWithin || (isWithin && mIsLast);\n        } else {\n            // selection is a range --> at least one character in common\n            int etwrt = Math.max(etwrt(), sel.etwrt());\n            int end = Math.min(end(), sel.end());\n            return etwrt < end;\n        }\n    }",
        "explanations_by_ours": [
            "the end of the paragraph",
            "the end of the selection",
            "the end point of the paragraph"
        ],
        "corrections_by_ours": [
            "selection",
            "end",
            "point",
            "paragraph"
        ],
        "corrections_by_baseline": [
            "wrt",
            "rtc",
            "iprt",
            "rtn",
            "rt",
            "rtctxt",
            "rgp",
            "rsf",
            "ftrm",
            "wudp"
        ]
    },
    {
        "original_word": "kill",
        "typo_word": "iipl",
        "original_variable": "killList",
        "typo_variable": "iiplList",
        "original_code": "private final void evictIfNeeded() {\n        if ( list.size() > evictSize ) {\n\n            final List<CacheEntry<KEY, VALUE>> killList = list.sortAndReturnPurgeList( 0.1f );\n\n            for ( CacheEntry<KEY, VALUE> cacheEntry : killList ) {\n                map.remove( cacheEntry.key );\n            }\n        }\n\n    }",
        "modified_code": "private final void evictIfNeeded() {\n        if ( list.size() > evictSize ) {\n\n            final List<CacheEntry<KEY, VALUE>> iiplList = list.sortAndReturnPurgeList( 0.1f );\n\n            for ( CacheEntry<KEY, VALUE> cacheEntry : iiplList ) {\n                map.remove( cacheEntry.key );\n            }\n        }\n\n    }",
        "explanations_by_ours": [
            "the list of cache entries to be evicted.",
            "the list of cache entries to be evicted",
            "the list of entries to be evicted."
        ],
        "corrections_by_ours": [
            "iiplEvicted",
            "listList",
            "entriesList",
            "evictedList",
            "iiplEntries",
            "cacheList",
            "iiplCache",
            "iiplList"
        ],
        "corrections_by_baseline": [
            "plist",
            "pList",
            "mvelList",
            "slist",
            "ncList",
            "lists",
            "nlist",
            "list",
            "fmrList",
            "vList"
        ]
    },
    {
        "original_word": "last",
        "typo_word": "pqst",
        "original_variable": "lastChar",
        "typo_variable": "pqstChar",
        "original_code": "@SuppressWarnings(\"MethodLength\")\n    public String build()\n    {\n        sb.setLength(0);\n\n        if (null != prefix && !\"\".equals(prefix))\n        {\n            sb.append(prefix).append(':');\n        }\n\n        sb.append(ChannelUri.AERON_SCHEME).append(':').append(media).append('?');\n\n        if (null != tags)\n        {\n            sb.append(TAGS_PARAM_NAME).append('=').append(tags).append('|');\n        }\n\n        if (null != endpoint)\n        {\n            sb.append(ENDPOINT_PARAM_NAME).append('=').append(endpoint).append('|');\n        }\n\n        if (null != networkInterface)\n        {\n            sb.append(INTERFACE_PARAM_NAME).append('=').append(networkInterface).append('|');\n        }\n\n        if (null != controlEndpoint)\n        {\n            sb.append(MDC_CONTROL_PARAM_NAME).append('=').append(controlEndpoint).append('|');\n        }\n\n        if (null != controlMode)\n        {\n            sb.append(MDC_CONTROL_MODE_PARAM_NAME).append('=').append(controlMode).append('|');\n        }\n\n        if (null != mtu)\n        {\n            sb.append(MTU_LENGTH_PARAM_NAME).append('=').append(mtu.intValue()).append('|');\n        }\n\n        if (null != termLength)\n        {\n            sb.append(TERM_LENGTH_PARAM_NAME).append('=').append(termLength.intValue()).append('|');\n        }\n\n        if (null != initialTermId)\n        {\n            sb.append(INITIAL_TERM_ID_PARAM_NAME).append('=').append(initialTermId.intValue()).append('|');\n        }\n\n        if (null != termId)\n        {\n            sb.append(TERM_ID_PARAM_NAME).append('=').append(termId.intValue()).append('|');\n        }\n\n        if (null != termOffset)\n        {\n            sb.append(TERM_OFFSET_PARAM_NAME).append('=').append(termOffset.intValue()).append('|');\n        }\n\n        if (null != sessionId)\n        {\n            sb.append(SESSION_ID_PARAM_NAME).append('=').append(prefixTag(isSessionIdTagged, sessionId)).append('|');\n        }\n\n        if (null != ttl)\n        {\n            sb.append(TTL_PARAM_NAME).append('=').append(ttl.intValue()).append('|');\n        }\n\n        if (null != reliable)\n        {\n            sb.append(RELIABLE_STREAM_PARAM_NAME).append('=').append(reliable).append('|');\n        }\n\n        if (null != linger)\n        {\n            sb.append(LINGER_PARAM_NAME).append('=').append(linger.intValue()).append('|');\n        }\n\n        if (null != alias)\n        {\n            sb.append(ALIAS_PARAM_NAME).append('=').append(alias).append('|');\n        }\n\n        if (null != sparse)\n        {\n            sb.append(SPARSE_PARAM_NAME).append('=').append(sparse).append('|');\n        }\n\n        if (null != eos)\n        {\n            sb.append(EOS_PARAM_NAME).append('=').append(eos).append('|');\n        }\n\n        if (null != tether)\n        {\n            sb.append(TETHER_PARAM_NAME).append('=').append(tether).append('|');\n        }\n\n        final char lastChar = sb.charAt(sb.length() - 1);\n        if (lastChar == '|' || lastChar == '?')\n        {\n            sb.setLength(sb.length() - 1);\n        }\n\n        return sb.toString();\n    }",
        "modified_code": "@SuppressWarnings(\"MethodLength\")\n    public String build()\n    {\n        sb.setLength(0);\n\n        if (null != prefix && !\"\".equals(prefix))\n        {\n            sb.append(prefix).append(':');\n        }\n\n        sb.append(ChannelUri.AERON_SCHEME).append(':').append(media).append('?');\n\n        if (null != tags)\n        {\n            sb.append(TAGS_PARAM_NAME).append('=').append(tags).append('|');\n        }\n\n        if (null != endpoint)\n        {\n            sb.append(ENDPOINT_PARAM_NAME).append('=').append(endpoint).append('|');\n        }\n\n        if (null != networkInterface)\n        {\n            sb.append(INTERFACE_PARAM_NAME).append('=').append(networkInterface).append('|');\n        }\n\n        if (null != controlEndpoint)\n        {\n            sb.append(MDC_CONTROL_PARAM_NAME).append('=').append(controlEndpoint).append('|');\n        }\n\n        if (null != controlMode)\n        {\n            sb.append(MDC_CONTROL_MODE_PARAM_NAME).append('=').append(controlMode).append('|');\n        }\n\n        if (null != mtu)\n        {\n            sb.append(MTU_LENGTH_PARAM_NAME).append('=').append(mtu.intValue()).append('|');\n        }\n\n        if (null != termLength)\n        {\n            sb.append(TERM_LENGTH_PARAM_NAME).append('=').append(termLength.intValue()).append('|');\n        }\n\n        if (null != initialTermId)\n        {\n            sb.append(INITIAL_TERM_ID_PARAM_NAME).append('=').append(initialTermId.intValue()).append('|');\n        }\n\n        if (null != termId)\n        {\n            sb.append(TERM_ID_PARAM_NAME).append('=').append(termId.intValue()).append('|');\n        }\n\n        if (null != termOffset)\n        {\n            sb.append(TERM_OFFSET_PARAM_NAME).append('=').append(termOffset.intValue()).append('|');\n        }\n\n        if (null != sessionId)\n        {\n            sb.append(SESSION_ID_PARAM_NAME).append('=').append(prefixTag(isSessionIdTagged, sessionId)).append('|');\n        }\n\n        if (null != ttl)\n        {\n            sb.append(TTL_PARAM_NAME).append('=').append(ttl.intValue()).append('|');\n        }\n\n        if (null != reliable)\n        {\n            sb.append(RELIABLE_STREAM_PARAM_NAME).append('=').append(reliable).append('|');\n        }\n\n        if (null != linger)\n        {\n            sb.append(LINGER_PARAM_NAME).append('=').append(linger.intValue()).append('|');\n        }\n\n        if (null != alias)\n        {\n            sb.append(ALIAS_PARAM_NAME).append('=').append(alias).append('|');\n        }\n\n        if (null != sparse)\n        {\n            sb.append(SPARSE_PARAM_NAME).append('=').append(sparse).append('|');\n        }\n\n        if (null != eos)\n        {\n            sb.append(EOS_PARAM_NAME).append('=').append(eos).append('|');\n        }\n\n        if (null != tether)\n        {\n            sb.append(TETHER_PARAM_NAME).append('=').append(tether).append('|');\n        }\n\n        final char pqstChar = sb.charAt(sb.length() - 1);\n        if (pqstChar == '|' || pqstChar == '?')\n        {\n            sb.setLength(sb.length() - 1);\n        }\n\n        return sb.toString();\n    }",
        "explanations_by_ours": [
            "the pqst char.",
            "the pqst char.",
            "the pqst char"
        ],
        "corrections_by_ours": [
            "charChar",
            "pqstPqst",
            "pqstChar"
        ],
        "corrections_by_baseline": [
            "aChar",
            "stringChar",
            "cchar",
            "charOder",
            "char1",
            "hexChar",
            "bomChar",
            "curChar",
            "charSequence",
            "uppercaseChar"
        ]
    },
    {
        "original_word": "html",
        "typo_word": "hhmi",
        "original_variable": "htmlWriter",
        "typo_variable": "hhmiWriter",
        "original_code": "@Override\n  public final void make(\n    final Map<String, Object> pAddParams) throws Exception {\n    ArrayList<Class<?>> classesArr =\n      new ArrayList<Class<?>>(this.mngSettings.getClasses());\n    try {\n      this.srvDatabase.setIsAutocommit(false);\n      this.srvDatabase.\n        setTransactionIsolation(ISrvDatabase.TRANSACTION_READ_UNCOMMITTED);\n      this.srvDatabase.beginTransaction();\n      this.logger.info(null, SrvClearDatabase.class, \"Start clear database.\");\n      for (int i = classesArr.size() - 1; i >= 0; i--) {\n        Class<?> entityClass = classesArr.get(i);\n        this.srvDatabase.executeDelete(entityClass.getSimpleName()\n          .toUpperCase(), null);\n      }\n      this.srvDatabase.commitTransaction();\n      Writer htmlWriter = (Writer) pAddParams.get(\"htmlWriter\");\n      if (htmlWriter != null) {\n        htmlWriter.write(\"<h4>\" + new Date().toString() + \", \"\n        + SrvClearDatabase.class.getSimpleName()\n          + \", database has been cleared\" + \"</h4>\");\n      }\n      this.logger.info(null, SrvClearDatabase.class, \"Finish clear database.\");\n    } catch (Exception ex) {\n      this.srvDatabase.rollBackTransaction();\n      throw ex;\n    } finally {\n      this.srvDatabase.releaseResources();\n    }\n  }",
        "modified_code": "@Override\n  public final void make(\n    final Map<String, Object> pAddParams) throws Exception {\n    ArrayList<Class<?>> classesArr =\n      new ArrayList<Class<?>>(this.mngSettings.getClasses());\n    try {\n      this.srvDatabase.setIsAutocommit(false);\n      this.srvDatabase.\n        setTransactionIsolation(ISrvDatabase.TRANSACTION_READ_UNCOMMITTED);\n      this.srvDatabase.beginTransaction();\n      this.logger.info(null, SrvClearDatabase.class, \"Start clear database.\");\n      for (int i = classesArr.size() - 1; i >= 0; i--) {\n        Class<?> entityClass = classesArr.get(i);\n        this.srvDatabase.executeDelete(entityClass.getSimpleName()\n          .toUpperCase(), null);\n      }\n      this.srvDatabase.commitTransaction();\n      Writer hhmiWriter = (Writer) pAddParams.get(\"htmlWriter\");\n      if (hhmiWriter != null) {\n        hhmiWriter.write(\"<h4>\" + new Date().toString() + \", \"\n        + SrvClearDatabase.class.getSimpleName()\n          + \", database has been cleared\" + \"</h4>\");\n      }\n      this.logger.info(null, SrvClearDatabase.class, \"Finish clear database.\");\n    } catch (Exception ex) {\n      this.srvDatabase.rollBackTransaction();\n      throw ex;\n    } finally {\n      this.srvDatabase.releaseResources();\n    }\n  }",
        "explanations_by_ours": [
            "html writer",
            "- html writer",
            "htmlWriter"
        ],
        "corrections_by_ours": [
            "htmlWriter",
            "hhmiHtml",
            "writerWriter",
            "-Writer",
            "hhmi-",
            "hhmiWriter"
        ],
        "corrections_by_baseline": [
            "writer",
            "bufferedWriter",
            "ncmlWriter",
            "extWriter",
            "innerWriter",
            "csvWriter",
            "writerFinal",
            "htmlWriter",
            "processedWriter",
            "stringWriter"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "gexult",
        "original_variable": "result",
        "typo_variable": "gexult",
        "original_code": "public Object getBean(String key, Object def) {\n      if (key==null)\n        throw new NullPointerException(\"Null key\");\n      if (isRemoved())\n        throw new IllegalStateException(\"Node has been removed.\");\n\n      synchronized(lock) {\n        Object result = null;\n        try {\n          result = _getObject( key);\n          if (result != null) {\n            if (result instanceof Bean.Collection)\n              result = ((Bean.Collection)result).getCollection();\n            else if (result instanceof Bean)\n              result = ((Bean)result).getObject();\n          }\n        } catch (Exception e) {\n          // Ignoring exception causes default to be returned\n        }\n        return (result==null ? def : result);\n      }\n    }",
        "modified_code": "public Object getBean(String key, Object def) {\n      if (key==null)\n        throw new NullPointerException(\"Null key\");\n      if (isRemoved())\n        throw new IllegalStateException(\"Node has been removed.\");\n\n      synchronized(lock) {\n        Object gexult = null;\n        try {\n          gexult = _getObject( key);\n          if (gexult != null) {\n            if (gexult instanceof Bean.Collection)\n              gexult = ((Bean.Collection)gexult).getCollection();\n            else if (gexult instanceof Bean)\n              gexult = ((Bean)gexult).getObject();\n          }\n        } catch (Exception e) {\n          // Ignoring exception causes default to be returned\n        }\n        return (gexult==null ? def : gexult);\n      }\n    }",
        "explanations_by_ours": [
            "the value to return if the key does not exist in the node",
            "the default value to return if the key does not exist in the node",
            "the default value to return if the key does not exist"
        ],
        "corrections_by_ours": [
            "default",
            "exist",
            "return",
            "key",
            "value",
            "node"
        ],
        "corrections_by_baseline": [
            "regex",
            "regexp",
            "baseRegex",
            "pattern",
            "regexString",
            "patternAND",
            "patternOR",
            "matchPattern",
            "regexName",
            "patternName"
        ]
    },
    {
        "original_word": "parts",
        "typo_word": "pafhs",
        "original_variable": "parts",
        "typo_variable": "pafhs",
        "original_code": "public Set<ViewDescription> getComponents(final String componentName, final String viewName, final VirtualFile deploymentRoot) {\n        final List<ViewInformation> info = componentsByViewName.get(viewName);\n        if (info == null) {\n            return Collections.<ViewDescription>emptySet();\n        }\n        if (componentName.contains(\"#\")) {\n            final String[] parts = componentName.split(\"#\");\n            String path = parts[0];\n            if (!path.startsWith(\"../\")) {\n                path = \"../\" + path;\n            }\n            final VirtualFile virtualPath = deploymentRoot.getChild(path);\n            final String name = parts[1];\n            final Set<ViewDescription> ret = new HashSet<ViewDescription>();\n            for (ViewInformation i : info) {\n                if (i.beanName.equals(name)) {\n                    //now we need to check the path\n                    if (virtualPath.equals(i.deploymentRoot)) {\n                        ret.add(i.viewDescription);\n                    }\n                }\n            }\n            return ret;\n        } else {\n            final Set<ViewDescription> all = new HashSet<ViewDescription>();\n            final Set<ViewDescription> thisDeployment = new HashSet<ViewDescription>();\n            for (ViewInformation i : info) {\n                if (i.beanName.equals(componentName)) {\n                    all.add(i.viewDescription);\n                    if (i.deploymentRoot.equals(deploymentRoot)) {\n                        thisDeployment.add(i.viewDescription);\n                    }\n                }\n            }\n            if (all.size() > 1) {\n                return thisDeployment;\n            }\n            return all;\n        }\n    }",
        "modified_code": "public Set<ViewDescription> getComponents(final String componentName, final String viewName, final VirtualFile deploymentRoot) {\n        final List<ViewInformation> info = componentsByViewName.get(viewName);\n        if (info == null) {\n            return Collections.<ViewDescription>emptySet();\n        }\n        if (componentName.contains(\"#\")) {\n            final String[] pafhs = componentName.split(\"#\");\n            String path = pafhs[0];\n            if (!path.startsWith(\"../\")) {\n                path = \"../\" + path;\n            }\n            final VirtualFile virtualPath = deploymentRoot.getChild(path);\n            final String name = pafhs[1];\n            final Set<ViewDescription> ret = new HashSet<ViewDescription>();\n            for (ViewInformation i : info) {\n                if (i.beanName.equals(name)) {\n                    //now we need to check the path\n                    if (virtualPath.equals(i.deploymentRoot)) {\n                        ret.add(i.viewDescription);\n                    }\n                }\n            }\n            return ret;\n        } else {\n            final Set<ViewDescription> all = new HashSet<ViewDescription>();\n            final Set<ViewDescription> thisDeployment = new HashSet<ViewDescription>();\n            for (ViewInformation i : info) {\n                if (i.beanName.equals(componentName)) {\n                    all.add(i.viewDescription);\n                    if (i.deploymentRoot.equals(deploymentRoot)) {\n                        thisDeployment.add(i.viewDescription);\n                    }\n                }\n            }\n            if (all.size() > 1) {\n                return thisDeployment;\n            }\n            return all;\n        }\n    }",
        "explanations_by_ours": [
            "the path of the component",
            "the path of the component.",
            "the component path"
        ],
        "corrections_by_ours": [
            "path",
            "component"
        ],
        "corrections_by_baseline": [
            "pf",
            "P",
            "p",
            "pihalf",
            "hf",
            "pce",
            "PV",
            "pv",
            "pfc",
            "pib"
        ]
    },
    {
        "original_word": "Bytes",
        "typo_word": "Bjres",
        "original_variable": "decodedCookieBytes",
        "typo_variable": "decodedCookieBjres",
        "original_code": "private String base64Decode(String base64Value) {\n\t\ttry {\n\t\t\tbyte[] decodedCookieBytes = Base64.getDecoder().decode(base64Value);\n\t\t\treturn new String(decodedCookieBytes);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tlogger.debug(\"Unable to Base64 decode value: \" + base64Value);\n\t\t\treturn null;\n\t\t}\n\t}",
        "modified_code": "private String base64Decode(String base64Value) {\n\t\ttry {\n\t\t\tbyte[] decodedCookieBjres = Base64.getDecoder().decode(base64Value);\n\t\t\treturn new String(decodedCookieBjres);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tlogger.debug(\"Unable to Base64 decode value: \" + base64Value);\n\t\t\treturn null;\n\t\t}\n\t}",
        "explanations_by_ours": [
            "The decoded cookie value.",
            "The decoded cookie value",
            "The decoded cookie value bytes."
        ],
        "corrections_by_ours": [
            "decodedCookieBjbytes",
            "decodedCookieBytesres",
            "decodedValueBjres",
            "bytesCookieBjres",
            "cookieCookieBjres",
            "valueCookieBjres",
            "decodedDecodedBjres",
            "decodedCookieBjdecoded",
            "decodedBytesBjres",
            "decodedCookieDecodedres"
        ],
        "corrections_by_baseline": [
            "decodedCookieBytes",
            "encodedCookieBytes",
            "cookiesSb",
            "cookieString",
            "newCookies",
            "cookieAsPlainText",
            "cookiesIt",
            "authEncData",
            "cookiesList",
            "cookies"
        ]
    },
    {
        "original_word": "patterns",
        "typo_word": "pagtegns",
        "original_variable": "patterns",
        "typo_variable": "pagtegns",
        "original_code": "public void setDateTime(String date) {\n        String[] patterns = {RFC_1123_PATTERN, ISO_8601_UTC_PATTERN, ISO_8601_UTC_MILLIS_PATTERN, ISO_8601_PATTERN, ISO_8601_MILLIS_PATTERN, RFC_850_PATTERN, ASCTIME_PATTERN};\n        for (int i = 0; i < patterns.length; i++) {\n            if (setDateTime(date, patterns[i]))\n                break;\n        }\n    }",
        "modified_code": "public void setDateTime(String date) {\n        String[] pagtegns = {RFC_1123_PATTERN, ISO_8601_UTC_PATTERN, ISO_8601_UTC_MILLIS_PATTERN, ISO_8601_PATTERN, ISO_8601_MILLIS_PATTERN, RFC_850_PATTERN, ASCTIME_PATTERN};\n        for (int i = 0; i < pagtegns.length; i++) {\n            if (setDateTime(date, pagtegns[i]))\n                break;\n        }\n    }",
        "explanations_by_ours": [
            "the date/time patterns",
            "the date/time pattern",
            "the date/time patterns to use"
        ],
        "corrections_by_ours": [
            "patterns",
            "pattern",
            "date",
            "use",
            "time"
        ],
        "corrections_by_baseline": [
            "pagination",
            "pageroot",
            "ppage",
            "ipage",
            "pagedList",
            "pageSql",
            "pageData",
            "pageInfo",
            "lpage",
            "pagingRegion"
        ]
    },
    {
        "original_word": "Close",
        "typo_word": "Ckode",
        "original_variable": "deleteOnClose",
        "typo_variable": "deleteOnCkode",
        "original_code": "boolean writeIndex(String name, File idxFile, CoordinateRuntime masterRuntime, List<Group> groups, List<MFile> files,\n                            GribCollectionImmutable.Type type, CalendarDateRange dateRange) throws IOException {\n    Grib2Record first = null; // take global metadata from here\n    boolean deleteOnClose = false;\n\n    if (idxFile.exists()) {\n      RandomAccessFile.eject(idxFile.getPath());\n      if (!idxFile.delete()) {\n        logger.error(\"gc2 cant delete index file {}\", idxFile.getPath());\n      }\n    }\n    logger.debug(\" createIndex for {}\", idxFile.getPath());\n\n    try (RandomAccessFile raf = new RandomAccessFile(idxFile.getPath(), \"rw\")) {\n      //// header message\n      raf.order(RandomAccessFile.BIG_ENDIAN);\n      raf.write(MAGIC_START.getBytes(CDM.utf8Charset));\n      raf.writeInt(version);\n      long lenPos = raf.getFilePointer();\n      raf.writeLong(0); // save space to write the length of the record section\n      long countBytes = 0;\n      int countRecords = 0;\n\n      Set<Integer> allFileSet = new HashSet<>();\n      for (Group g : groups) {\n        g.fileSet = new HashSet<>();\n        for (Grib2CollectionBuilder.VariableBag vb : g.gribVars) {\n          if (first == null) first = vb.first;\n          GribCollectionProto.SparseArray vr = writeSparseArray(vb, g.fileSet);\n          byte[] b = vr.toByteArray();\n          vb.pos = raf.getFilePointer();\n          vb.length = b.length;\n          raf.write(b);\n          countBytes += b.length;\n          countRecords += vb.coordND.getSparseArray().countNotMissing();\n        }\n        allFileSet.addAll(g.fileSet);\n      }\n\n      if (logger.isDebugEnabled()) {\n        long bytesPerRecord = countBytes / ((countRecords == 0) ? 1 : countRecords);\n        logger.debug(\"  write RecordMaps: bytes = {} record = {} bytesPerRecord={}\", countBytes, countRecords, bytesPerRecord);\n      }\n\n      if (first == null) {\n        deleteOnClose = true;\n        throw new IOException(\"GribCollection \" + name + \" has no records\");\n      }\n\n      long pos = raf.getFilePointer();\n      raf.seek(lenPos);\n      raf.writeLong(countBytes);\n      raf.seek(pos); // back to the output.\n\n      /*\n      message GribCollection {\n        string name = 1;         // must be unique - index filename is name.ncx\n        string topDir = 2;       // MFile, Partition filenames are reletive to this\n        repeated MFile mfiles = 3;        // list of grib MFiles\n        repeated Dataset dataset = 4;\n        repeated Gds gds = 5;             // unique Gds, shared amongst datasets\n        Coord masterRuntime = 6;  // list of runtimes in this GC\n\n        int32 center = 7;      // these 4 fields are to get a GribCustomizer\n        int32 subcenter = 8;\n        int32 master = 9;\n        int32 local = 10;       // grib1 table Version\n\n        int32 genProcessType = 11;\n        int32 genProcessId = 12;\n        int32 backProcessId = 13;\n        int32 version = 14;     // >= 3 for proto3 (5.0+)\n\n        // repeated Parameter params = 20;      // not used\n        FcConfig config = 21;\n\n        // extensions\n        repeated Partition partitions = 100;\n        bool isPartitionOfPartitions = 101;\n        repeated uint32 run2part = 102 [packed=true];  // masterRuntime index to partition index\n      }\n       */\n      GribCollectionProto.GribCollection.Builder indexBuilder = GribCollectionProto.GribCollection.newBuilder();\n      indexBuilder.setName(name);\n      indexBuilder.setTopDir(dcm.getRoot());\n      indexBuilder.setVersion(currentVersion);\n\n      // directory and mfile list\n      File directory = new File(dcm.getRoot());\n      List<GcMFile> gcmfiles = GcMFile.makeFiles(directory, files, allFileSet);\n      for (GcMFile gcmfile : gcmfiles) {\n        GribCollectionProto.MFile.Builder b = GribCollectionProto.MFile.newBuilder();\n        b.setFilename(gcmfile.getName());\n        b.setLastModified(gcmfile.getLastModified());\n        b.setLength(gcmfile.getLength());\n        b.setIndex(gcmfile.index);\n        indexBuilder.addMfiles(b.build());\n      }\n\n      indexBuilder.setMasterRuntime(writeCoordProto(masterRuntime));\n\n       //gds\n      for (Object go : groups) {\n        Group g = (Group) go;\n        indexBuilder.addGds(writeGdsProto(g.gdss.getRawBytes(), -1));\n      }\n\n      // the GC dataset\n      indexBuilder.addDataset(writeDatasetProto(type, groups));\n\n      // what about just storing first ??\n      Grib2SectionIdentification ids = first.getId();\n      indexBuilder.setCenter(ids.getCenter_id());\n      indexBuilder.setSubcenter(ids.getSubcenter_id());\n      indexBuilder.setMaster(ids.getMaster_table_version());\n      indexBuilder.setLocal(ids.getLocal_table_version());\n\n      Grib2Pds pds = first.getPDS();\n      indexBuilder.setGenProcessType(pds.getGenProcessType());\n      indexBuilder.setGenProcessId(pds.getGenProcessId());\n      indexBuilder.setBackProcessId(pds.getBackProcessId());\n\n      indexBuilder.setStartTime(dateRange.getStart().getMillis());\n      indexBuilder.setEndTime(dateRange.getEnd().getMillis());\n\n      GribCollectionProto.GribCollection index = indexBuilder.build();\n      byte[] b = index.toByteArray();\n      NcStream.writeVInt(raf, b.length); // message size\n      raf.write(b);  // message  - all in one gulp\n      logger.debug(\"  write GribCollectionIndex= {} bytes\", b.length);\n\n    } finally {\n      // remove it on failure\n      if (deleteOnClose && !idxFile.delete())\n        logger.error(\" gc2 cant deleteOnClose index file {}\", idxFile.getPath());\n    }\n\n    return true;\n  }",
        "modified_code": "boolean writeIndex(String name, File idxFile, CoordinateRuntime masterRuntime, List<Group> groups, List<MFile> files,\n                            GribCollectionImmutable.Type type, CalendarDateRange dateRange) throws IOException {\n    Grib2Record first = null; // take global metadata from here\n    boolean deleteOnCkode = false;\n\n    if (idxFile.exists()) {\n      RandomAccessFile.eject(idxFile.getPath());\n      if (!idxFile.delete()) {\n        logger.error(\"gc2 cant delete index file {}\", idxFile.getPath());\n      }\n    }\n    logger.debug(\" createIndex for {}\", idxFile.getPath());\n\n    try (RandomAccessFile raf = new RandomAccessFile(idxFile.getPath(), \"rw\")) {\n      //// header message\n      raf.order(RandomAccessFile.BIG_ENDIAN);\n      raf.write(MAGIC_START.getBytes(CDM.utf8Charset));\n      raf.writeInt(version);\n      long lenPos = raf.getFilePointer();\n      raf.writeLong(0); // save space to write the length of the record section\n      long countBytes = 0;\n      int countRecords = 0;\n\n      Set<Integer> allFileSet = new HashSet<>();\n      for (Group g : groups) {\n        g.fileSet = new HashSet<>();\n        for (Grib2CollectionBuilder.VariableBag vb : g.gribVars) {\n          if (first == null) first = vb.first;\n          GribCollectionProto.SparseArray vr = writeSparseArray(vb, g.fileSet);\n          byte[] b = vr.toByteArray();\n          vb.pos = raf.getFilePointer();\n          vb.length = b.length;\n          raf.write(b);\n          countBytes += b.length;\n          countRecords += vb.coordND.getSparseArray().countNotMissing();\n        }\n        allFileSet.addAll(g.fileSet);\n      }\n\n      if (logger.isDebugEnabled()) {\n        long bytesPerRecord = countBytes / ((countRecords == 0) ? 1 : countRecords);\n        logger.debug(\"  write RecordMaps: bytes = {} record = {} bytesPerRecord={}\", countBytes, countRecords, bytesPerRecord);\n      }\n\n      if (first == null) {\n        deleteOnCkode = true;\n        throw new IOException(\"GribCollection \" + name + \" has no records\");\n      }\n\n      long pos = raf.getFilePointer();\n      raf.seek(lenPos);\n      raf.writeLong(countBytes);\n      raf.seek(pos); // back to the output.\n\n      /*\n      message GribCollection {\n        string name = 1;         // must be unique - index filename is name.ncx\n        string topDir = 2;       // MFile, Partition filenames are reletive to this\n        repeated MFile mfiles = 3;        // list of grib MFiles\n        repeated Dataset dataset = 4;\n        repeated Gds gds = 5;             // unique Gds, shared amongst datasets\n        Coord masterRuntime = 6;  // list of runtimes in this GC\n\n        int32 center = 7;      // these 4 fields are to get a GribCustomizer\n        int32 subcenter = 8;\n        int32 master = 9;\n        int32 local = 10;       // grib1 table Version\n\n        int32 genProcessType = 11;\n        int32 genProcessId = 12;\n        int32 backProcessId = 13;\n        int32 version = 14;     // >= 3 for proto3 (5.0+)\n\n        // repeated Parameter params = 20;      // not used\n        FcConfig config = 21;\n\n        // extensions\n        repeated Partition partitions = 100;\n        bool isPartitionOfPartitions = 101;\n        repeated uint32 run2part = 102 [packed=true];  // masterRuntime index to partition index\n      }\n       */\n      GribCollectionProto.GribCollection.Builder indexBuilder = GribCollectionProto.GribCollection.newBuilder();\n      indexBuilder.setName(name);\n      indexBuilder.setTopDir(dcm.getRoot());\n      indexBuilder.setVersion(currentVersion);\n\n      // directory and mfile list\n      File directory = new File(dcm.getRoot());\n      List<GcMFile> gcmfiles = GcMFile.makeFiles(directory, files, allFileSet);\n      for (GcMFile gcmfile : gcmfiles) {\n        GribCollectionProto.MFile.Builder b = GribCollectionProto.MFile.newBuilder();\n        b.setFilename(gcmfile.getName());\n        b.setLastModified(gcmfile.getLastModified());\n        b.setLength(gcmfile.getLength());\n        b.setIndex(gcmfile.index);\n        indexBuilder.addMfiles(b.build());\n      }\n\n      indexBuilder.setMasterRuntime(writeCoordProto(masterRuntime));\n\n       //gds\n      for (Object go : groups) {\n        Group g = (Group) go;\n        indexBuilder.addGds(writeGdsProto(g.gdss.getRawBytes(), -1));\n      }\n\n      // the GC dataset\n      indexBuilder.addDataset(writeDatasetProto(type, groups));\n\n      // what about just storing first ??\n      Grib2SectionIdentification ids = first.getId();\n      indexBuilder.setCenter(ids.getCenter_id());\n      indexBuilder.setSubcenter(ids.getSubcenter_id());\n      indexBuilder.setMaster(ids.getMaster_table_version());\n      indexBuilder.setLocal(ids.getLocal_table_version());\n\n      Grib2Pds pds = first.getPDS();\n      indexBuilder.setGenProcessType(pds.getGenProcessType());\n      indexBuilder.setGenProcessId(pds.getGenProcessId());\n      indexBuilder.setBackProcessId(pds.getBackProcessId());\n\n      indexBuilder.setStartTime(dateRange.getStart().getMillis());\n      indexBuilder.setEndTime(dateRange.getEnd().getMillis());\n\n      GribCollectionProto.GribCollection index = indexBuilder.build();\n      byte[] b = index.toByteArray();\n      NcStream.writeVInt(raf, b.length); // message size\n      raf.write(b);  // message  - all in one gulp\n      logger.debug(\"  write GribCollectionIndex= {} bytes\", b.length);\n\n    } finally {\n      // remove it on failure\n      if (deleteOnCkode && !idxFile.delete())\n        logger.error(\" gc2 cant deleteOnClose index file {}\", idxFile.getPath());\n    }\n\n    return true;\n  }",
        "explanations_by_ours": [
            "if true, the index file will be deleted on Ckode.",
            "if true, the index file will be deleted on the Ckode",
            "if true, the index file will be deleted on Ckode"
        ],
        "corrections_by_ours": [
            "deletedOnCkode",
            "deleteOnCkindex",
            "fileOnCkode",
            "deleteOdeCkode",
            "deleteOnCkode",
            "deleteOnCkfile",
            "deleteIndexCkode",
            "deleteOnCktrue,",
            "true,OnCkode",
            "indexOnCkode"
        ],
        "corrections_by_baseline": [
            "delete",
            "deleteOnClose",
            "deleteOk",
            "deleteList",
            "deleteCount",
            "deleteStaging",
            "need2delete",
            "ejbRemoveId",
            "hasDelete",
            "total_delete"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rezilt",
        "original_variable": "result",
        "typo_variable": "rezilt",
        "original_code": "public Character toCharacter(final Object value, final Character defaultValue) {\n\t\tfinal Character result = toCharacter(value);\n\t\tif (result == null) {\n\t\t\treturn defaultValue;\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public Character toCharacter(final Object value, final Character defaultValue) {\n\t\tfinal Character rezilt = toCharacter(value);\n\t\tif (rezilt == null) {\n\t\t\treturn defaultValue;\n\t\t}\n\t\treturn rezilt;\n\t}",
        "explanations_by_ours": [
            "the value to convert",
            "the converted value",
            "the rezilt value"
        ],
        "corrections_by_ours": [
            "convert",
            "converted",
            "value"
        ],
        "corrections_by_baseline": [
            "rlam",
            "gammCompl",
            "lam",
            "hysteresis",
            "cosl",
            "dapseq",
            "glamx",
            "tinvd",
            "qco",
            "difmin"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vakhe",
        "original_variable": "value",
        "typo_variable": "vakhe",
        "original_code": "public static long readVLong(ByteData arr, long position) {\n        byte b = arr.get(position++);\n\n        if(b == (byte) 0x80)\n            throw new RuntimeException(\"Attempting to read null value as long\");\n\n        long value = b & 0x7F;\n        while ((b & 0x80) != 0) {\n          b = arr.get(position++);\n          value <<= 7;\n          value |= (b & 0x7F);\n        }\n\n        return value;\n    }",
        "modified_code": "public static long readVLong(ByteData arr, long position) {\n        byte b = arr.get(position++);\n\n        if(b == (byte) 0x80)\n            throw new RuntimeException(\"Attempting to read null value as long\");\n\n        long vakhe = b & 0x7F;\n        while ((b & 0x80) != 0) {\n          b = arr.get(position++);\n          vakhe <<= 7;\n          vakhe |= (b & 0x7F);\n        }\n\n        return vakhe;\n    }",
        "explanations_by_ours": [
            "the value to be read",
            "the value to read",
            "the vakhe value"
        ],
        "corrections_by_ours": [
            "value",
            "read"
        ],
        "corrections_by_baseline": [
            "vDk",
            "kv",
            "ak",
            "uhe",
            "vk0",
            "hv",
            "vk1",
            "azim",
            "va",
            "vz"
        ]
    },
    {
        "original_word": "stoke",
        "typo_word": "stoud",
        "original_variable": "stoke",
        "typo_variable": "stoud",
        "original_code": "static public TableConfigurer getTableConfigurer(FeatureType wantFeatureType, NetcdfDataset ds) throws IOException {\r\n    String convUsed = null;\r\n\r\n    // search for the Conventions attribute\r\n    String convName = ds.findAttValueIgnoreCase(null, CDM.CONVENTIONS, null);\r\n    if (convName == null)\r\n      convName = ds.findAttValueIgnoreCase(null, \"Convention\", null);\r\n\r\n    // now search for TableConfigurer using that Convention\r\n    Configurator anal = null;\r\n    if (convName != null) {\r\n      convName = convName.trim();\r\n\r\n      // search for Convention parsing class\r\n      anal = matchConfigurator(convName);\r\n      if (anal != null) {\r\n        convUsed = convName;\r\n        if (debug) System.out.println(\"  TableConfigurer found using convName \"+convName);\r\n      }\r\n\r\n      // now search for comma or semicolon or / delimited list\r\n      if (anal == null) {\r\n        List<String> names = new ArrayList<>();\r\n\r\n        if ((convName.indexOf(',') > 0) || (convName.indexOf(';') > 0)) {\r\n          StringTokenizer stoke = new StringTokenizer(convName, \",;\");\r\n          while (stoke.hasMoreTokens()) {\r\n            String name = stoke.nextToken();\r\n            names.add(name.trim());\r\n          }\r\n        } else if ((convName.indexOf('/') > 0)) {\r\n          StringTokenizer stoke = new StringTokenizer(convName, \"/\");\r\n          while (stoke.hasMoreTokens()) {\r\n            String name = stoke.nextToken();\r\n            names.add(name.trim());\r\n          }\r\n        }\r\n\r\n        if (names.size() > 0) {\r\n          // search the registered conventions, in order\r\n          for (Configurator conv : conventionList) {\r\n            for (String name : names) {\r\n              if (name.equalsIgnoreCase(conv.convName)) {\r\n                anal = conv;\r\n                convUsed = name;\r\n                if (debug) System.out.println(\"  TableConfigurer found using convName \"+convName);\r\n              }\r\n            }\r\n            if (anal != null) break;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    // search for ones that dont use Convention attribute, in order added.\r\n    // call method isMine() using reflection.\r\n    if (anal == null) {\r\n      for (Configurator conv : conventionList) {\r\n        Class c = conv.confClass;\r\n        Method isMineMethod;\r\n\r\n        try {\r\n          isMineMethod = c.getMethod(\"isMine\", new Class[]{FeatureType.class, NetcdfDataset.class});\r\n        } catch (NoSuchMethodException ex) {\r\n          continue;\r\n        }\r\n\r\n        try {\r\n          Boolean result = (Boolean) isMineMethod.invoke(conv.confInstance, wantFeatureType, ds);\r\n          if (debug) System.out.println(\"  TableConfigurer.isMine \"+c.getName()+ \" result = \" + result);\r\n          if (result) {\r\n            anal = conv;\r\n            convUsed = conv.convName;\r\n            break;\r\n          }\r\n        } catch (Exception ex) {\r\n          System.out.println(\"ERROR: Class \" + c.getName() + \" Exception invoking isMine method%n\" + ex);\r\n        }\r\n      }\r\n    }\r\n\r\n    // Instantiate a new TableConfigurer object\r\n    TableConfigurer tc = null;\r\n    if (anal != null) {\r\n      try {\r\n        tc = (TableConfigurer) anal.confClass.newInstance();\r\n        tc.setConvName( convName);\r\n        tc.setConvUsed( convUsed);\r\n      } catch (InstantiationException | IllegalAccessException e) {\r\n        log.error(\"TableConfigurer create failed\", e);\r\n      }\r\n    }\r\n\r\n    return tc;\r\n  }",
        "modified_code": "static public TableConfigurer getTableConfigurer(FeatureType wantFeatureType, NetcdfDataset ds) throws IOException {\r\n    String convUsed = null;\r\n\r\n    // search for the Conventions attribute\r\n    String convName = ds.findAttValueIgnoreCase(null, CDM.CONVENTIONS, null);\r\n    if (convName == null)\r\n      convName = ds.findAttValueIgnoreCase(null, \"Convention\", null);\r\n\r\n    // now search for TableConfigurer using that Convention\r\n    Configurator anal = null;\r\n    if (convName != null) {\r\n      convName = convName.trim();\r\n\r\n      // search for Convention parsing class\r\n      anal = matchConfigurator(convName);\r\n      if (anal != null) {\r\n        convUsed = convName;\r\n        if (debug) System.out.println(\"  TableConfigurer found using convName \"+convName);\r\n      }\r\n\r\n      // now search for comma or semicolon or / delimited list\r\n      if (anal == null) {\r\n        List<String> names = new ArrayList<>();\r\n\r\n        if ((convName.indexOf(',') > 0) || (convName.indexOf(';') > 0)) {\r\n          StringTokenizer stoud = new StringTokenizer(convName, \",;\");\r\n          while (stoud.hasMoreTokens()) {\r\n            String name = stoud.nextToken();\r\n            names.add(name.trim());\r\n          }\r\n        } else if ((convName.indexOf('/') > 0)) {\r\n          StringTokenizer stoud = new StringTokenizer(convName, \"/\");\r\n          while (stoud.hasMoreTokens()) {\r\n            String name = stoud.nextToken();\r\n            names.add(name.trim());\r\n          }\r\n        }\r\n\r\n        if (names.size() > 0) {\r\n          // search the registered conventions, in order\r\n          for (Configurator conv : conventionList) {\r\n            for (String name : names) {\r\n              if (name.equalsIgnoreCase(conv.convName)) {\r\n                anal = conv;\r\n                convUsed = name;\r\n                if (debug) System.out.println(\"  TableConfigurer found using convName \"+convName);\r\n              }\r\n            }\r\n            if (anal != null) break;\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n    // search for ones that dont use Convention attribute, in order added.\r\n    // call method isMine() using reflection.\r\n    if (anal == null) {\r\n      for (Configurator conv : conventionList) {\r\n        Class c = conv.confClass;\r\n        Method isMineMethod;\r\n\r\n        try {\r\n          isMineMethod = c.getMethod(\"isMine\", new Class[]{FeatureType.class, NetcdfDataset.class});\r\n        } catch (NoSuchMethodException ex) {\r\n          continue;\r\n        }\r\n\r\n        try {\r\n          Boolean result = (Boolean) isMineMethod.invoke(conv.confInstance, wantFeatureType, ds);\r\n          if (debug) System.out.println(\"  TableConfigurer.isMine \"+c.getName()+ \" result = \" + result);\r\n          if (result) {\r\n            anal = conv;\r\n            convUsed = conv.convName;\r\n            break;\r\n          }\r\n        } catch (Exception ex) {\r\n          System.out.println(\"ERROR: Class \" + c.getName() + \" Exception invoking isMine method%n\" + ex);\r\n        }\r\n      }\r\n    }\r\n\r\n    // Instantiate a new TableConfigurer object\r\n    TableConfigurer tc = null;\r\n    if (anal != null) {\r\n      try {\r\n        tc = (TableConfigurer) anal.confClass.newInstance();\r\n        tc.setConvName( convName);\r\n        tc.setConvUsed( convUsed);\r\n      } catch (InstantiationException | IllegalAccessException e) {\r\n        log.error(\"TableConfigurer create failed\", e);\r\n      }\r\n    }\r\n\r\n    return tc;\r\n  }",
        "explanations_by_ours": [
            "comma or semicolon or / delimited list.",
            "comma or semicolon or / delimited list",
            "comma or semicolon or / delimited list of names"
        ],
        "corrections_by_ours": [
            "semicolon",
            "delimited",
            "list",
            "names",
            "comma"
        ],
        "corrections_by_baseline": [
            "st",
            "stp",
            "econst",
            "bte",
            "stnm",
            "ertd",
            "gmst",
            "tst",
            "ost",
            "xstell"
        ]
    },
    {
        "original_word": "project",
        "typo_word": "prohecy",
        "original_variable": "projectName",
        "typo_variable": "prohecyName",
        "original_code": "private static CIEnvironment detectTravis(Map<String, String> env) {\n        String revision = env.get(\"TRAVIS_COMMIT\");\n        String branch = env.get(\"TRAVIS_BRANCH\");\n        if (revision == null || branch == null) return null;\n        String tag = null;\n        String repoSlug = env.get(\"TRAVIS_REPO_SLUG\");\n        String projectName = repoSlug.split(\"/\")[1];\n        return new CIEnvironment(\n                \"Travis CI\",\n                revision,\n                branch,\n                tag,\n                projectName\n        );\n    }",
        "modified_code": "private static CIEnvironment detectTravis(Map<String, String> env) {\n        String revision = env.get(\"TRAVIS_COMMIT\");\n        String branch = env.get(\"TRAVIS_BRANCH\");\n        if (revision == null || branch == null) return null;\n        String tag = null;\n        String repoSlug = env.get(\"TRAVIS_REPO_SLUG\");\n        String prohecyName = repoSlug.split(\"/\")[1];\n        return new CIEnvironment(\n                \"Travis CI\",\n                revision,\n                branch,\n                tag,\n                prohecyName\n        );\n    }",
        "explanations_by_ours": [
            "the prohecy name",
            "the name of the prohecy",
            "the prohecy name to use"
        ],
        "corrections_by_ours": [
            "prohecyUse",
            "useName",
            "nameName",
            "prohecyProhecy",
            "prohecyName"
        ],
        "corrections_by_baseline": [
            "projName",
            "csName",
            "ejbName",
            "eName",
            "azimName",
            "azim_name",
            "cName",
            "namep",
            "earApplicationName",
            "applicationName"
        ]
    },
    {
        "original_word": "pixel",
        "typo_word": "pisrl",
        "original_variable": "pixel",
        "typo_variable": "pisrl",
        "original_code": "protected int getItemPos() {\r\n      if (nitems < 1)\r\n        return -arrow_size;   // dont show indicator\r\n      else if (nitems == 1)\r\n        return b.width/2;   // indicator in center\r\n\r\n      int item = table.getSelectedRowIndex();  // selected item\r\n      int eff_width = b.width - 2*arrow_size;   // effective width\r\n      int pixel =  (item * eff_width)/(nitems-1);  // divided into n-1 intervals\r\n      return pixel+arrow_size;\r\n    }",
        "modified_code": "protected int getItemPos() {\r\n      if (nitems < 1)\r\n        return -arrow_size;   // dont show indicator\r\n      else if (nitems == 1)\r\n        return b.width/2;   // indicator in center\r\n\r\n      int item = table.getSelectedRowIndex();  // selected item\r\n      int eff_width = b.width - 2*arrow_size;   // effective width\r\n      int pisrl =  (item * eff_width)/(nitems-1);  // divided into n-1 intervals\r\n      return pisrl+arrow_size;\r\n    }",
        "explanations_by_ours": [
            "the pisrl of the item in the table.",
            "the pisrl of the item.",
            "the pisrl of the item in the table"
        ],
        "corrections_by_ours": [
            "item",
            "table"
        ],
        "corrections_by_baseline": [
            "pib",
            "llp",
            "pf",
            "lpp",
            "pip",
            "pjpn",
            "rgp",
            "gp",
            "dsp",
            "psi"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "offsdy",
        "original_variable": "offset",
        "typo_variable": "offsdy",
        "original_code": "public static byte[] readRAM(final File f) throws IOException {\n    final int total = (int) f.length();\n    final byte[] ret = new byte[total];\n    final InputStream in = new FileInputStream(f);\n    try {\n      int offset = 0;\n      int read = 0;\n      do {\n        read = in.read(ret, offset, total - read);\n        if (read > 0) {\n          offset += read;\n        }\n      } while ((read != -1) && (offset != total));\n      return ret;\n    } finally {\n      in.close();\n    }\n  }",
        "modified_code": "public static byte[] readRAM(final File f) throws IOException {\n    final int total = (int) f.length();\n    final byte[] ret = new byte[total];\n    final InputStream in = new FileInputStream(f);\n    try {\n      int offsdy = 0;\n      int read = 0;\n      do {\n        read = in.read(ret, offsdy, total - read);\n        if (read > 0) {\n          offsdy += read;\n        }\n      } while ((read != -1) && (offsdy != total));\n      return ret;\n    } finally {\n      in.close();\n    }\n  }",
        "explanations_by_ours": [
            "the number of bytes to read",
            "the offset into the byte array",
            "the start offset of the byte array"
        ],
        "corrections_by_ours": [
            "offset",
            "array",
            "read",
            "byte",
            "start",
            "bytes",
            "number"
        ],
        "corrections_by_baseline": [
            "doff",
            "offsets",
            "off",
            "flatOffsets",
            "poff",
            "swbOffsets",
            "tadOffsets",
            "masterOffsets",
            "offP0",
            "off1"
        ]
    },
    {
        "original_word": "root",
        "typo_word": "tolt",
        "original_variable": "rootElem",
        "typo_variable": "toltElem",
        "original_code": "public Document makeDocument() {\r\n    Element rootElem = new Element(\"pointConfig\");\r\n    Document doc = new Document(rootElem);\r\n    if (tableConfigurerClass != null)\r\n      rootElem.addContent( new Element(\"tableConfigurer\").setAttribute(\"class\", tableConfigurerClass));\r\n    if (tc.featureType != null)\r\n      rootElem.setAttribute(\"featureType\", tc.featureType.toString());\r\n\r\n    rootElem.addContent(writeTable(tc));\r\n\r\n    return doc;\r\n  }",
        "modified_code": "public Document makeDocument() {\r\n    Element toltElem = new Element(\"pointConfig\");\r\n    Document doc = new Document(toltElem);\r\n    if (tableConfigurerClass != null)\r\n      toltElem.addContent( new Element(\"tableConfigurer\").setAttribute(\"class\", tableConfigurerClass));\r\n    if (tc.featureType != null)\r\n      toltElem.setAttribute(\"featureType\", tc.featureType.toString());\r\n\r\n    toltElem.addContent(writeTable(tc));\r\n\r\n    return doc;\r\n  }",
        "explanations_by_ours": [
            "the tolt element",
            "the element to add the table configuration to",
            "the pointConfig element"
        ],
        "corrections_by_ours": [
            "toltElement",
            "pointElem",
            "tableElem",
            "toltTable",
            "configElem",
            "configurationElem",
            "elementElem",
            "addElem",
            "toltAdd",
            "toltConfiguration"
        ],
        "corrections_by_baseline": [
            "atcElem",
            "ctElem",
            "tmElem",
            "pElem",
            "sElem",
            "csElem",
            "oneElem",
            "dsfElem",
            "dsElem",
            "mdataElem"
        ]
    },
    {
        "original_word": "name",
        "typo_word": "gams",
        "original_variable": "objname",
        "typo_variable": "objgams",
        "original_code": "protected void parseFile(BufferedReader reader) {\n        String line = null;\n        try {\n            while ( (line = reader.readLine()) != null) {\n                Section section = getSection(line);\n                String nl = stripHeadingAndCode(line);\n                String objname = this.getObjMetadata(nl);\n                nl = this.stripObjMetadata(nl);\n                addEntry(section, nl, objname);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }",
        "modified_code": "protected void parseFile(BufferedReader reader) {\n        String line = null;\n        try {\n            while ( (line = reader.readLine()) != null) {\n                Section section = getSection(line);\n                String nl = stripHeadingAndCode(line);\n                String objgams = this.getObjMetadata(nl);\n                nl = this.stripObjMetadata(nl);\n                addEntry(section, nl, objgams);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }",
        "explanations_by_ours": [
            "the objgams to add to the map",
            "the objgams metadata",
            "the objgams to add"
        ],
        "corrections_by_ours": [
            "objadd",
            "objmap",
            "objmetadata",
            "addgams",
            "mapgams",
            "gamsgams",
            "metadatagams",
            "objobj",
            "objgams"
        ],
        "corrections_by_baseline": [
            "jParams",
            "parms",
            "mparms",
            "sparams",
            "params",
            "scalaArgs",
            "nparms",
            "paramArr",
            "objlist",
            "obsVars"
        ]
    },
    {
        "original_word": "incoming",
        "typo_word": "inflming",
        "original_variable": "incoming",
        "typo_variable": "inflming",
        "original_code": "public byte[] compress(String jsonStr) {\n    if (jsonStr == null || jsonStr.length() == 0) {\n      return null;\n    }\n    GZIPOutputStream gout = null;\n    ByteArrayOutputStream baos = null;\n    try {\n      byte[] incoming = jsonStr.getBytes(\"UTF-8\");\n      baos = new ByteArrayOutputStream();\n      gout = new GZIPOutputStream(baos, 16384); // 16KB\n      gout.write(incoming);\n      gout.finish();\n      return baos.toByteArray();\n    } catch (Exception ex) {\n      OLogManager.instance().error(this, \"Error on compressing HTTP response\", ex);\n    } finally {\n      try {\n        if (gout != null) {\n          gout.close();\n        }\n        if (baos != null) {\n          baos.close();\n        }\n      } catch (Exception ex) {\n      }\n    }\n    return null;\n  }",
        "modified_code": "public byte[] compress(String jsonStr) {\n    if (jsonStr == null || jsonStr.length() == 0) {\n      return null;\n    }\n    GZIPOutputStream gout = null;\n    ByteArrayOutputStream baos = null;\n    try {\n      byte[] inflming = jsonStr.getBytes(\"UTF-8\");\n      baos = new ByteArrayOutputStream();\n      gout = new GZIPOutputStream(baos, 16384); // 16KB\n      gout.write(inflming);\n      gout.finish();\n      return baos.toByteArray();\n    } catch (Exception ex) {\n      OLogManager.instance().error(this, \"Error on compressing HTTP response\", ex);\n    } finally {\n      try {\n        if (gout != null) {\n          gout.close();\n        }\n        if (baos != null) {\n          baos.close();\n        }\n      } catch (Exception ex) {\n      }\n    }\n    return null;\n  }",
        "explanations_by_ours": [
            "inflated JSON string",
            "JSON string to compress",
            "JSON string to be compressed"
        ],
        "corrections_by_ours": [
            "inflmstring",
            "inflatedlming",
            "stringlming",
            "inflminflated",
            "infcompressing",
            "infinflateding",
            "infcompresseding",
            "compresslming",
            "jsonlming",
            "compressedlming"
        ],
        "corrections_by_baseline": [
            "inflater",
            "mixing",
            "xin",
            "mergedInjections",
            "misflg",
            "inverted",
            "bias",
            "dover",
            "ilenhd",
            "uebertragung"
        ]
    },
    {
        "original_word": "ilenhd",
        "typo_word": "klenhc",
        "original_variable": "ilenhd",
        "typo_variable": "klenhc",
        "original_code": "public RData DM_RDTR(int irow, int icol, String partName,\n                       int decimalScale)\n          throws IOException {\n\n    int ipoint = -1;\n    if ((irow < 1) || (irow > dmLabel.krow) || (icol < 1)\n            || (icol > dmLabel.kcol)) {\n      System.out.println(\"bad row/column number \" + irow + \"/\" + icol);\n      return null;\n    }\n    //System.out.println(\"reading row \" + irow + \", column \" + icol);\n    int iprt = getPartNumber(partName);\n    if (iprt == 0) {\n      System.out.println(\"couldn't find part: \" + partName);\n      return null;\n    }\n    // gotta subtract 1 because parts are 1 but List is 0 based\n    DMPart part = parts.get(iprt - 1);\n    // check for valid real data type\n    if ((part.ktyprt != MDREAL) && (part.ktyprt != MDGRID)\n            && (part.ktyprt != MDRPCK)) {\n      System.out.println(\"Not a valid type\");\n      return null;\n    }\n    int ilenhd = part.klnhdr;\n    ipoint = dmLabel.kpdata + (irow - 1) * dmLabel.kcol * dmLabel.kprt\n            + (icol - 1) * dmLabel.kprt + (iprt - 1);\n\n    float[] rdata;\n    int[] header = null;\n    int istart = DM_RINT(ipoint);\n    if (istart == 0) {\n      return null;\n    }\n    // start catching up here because some files are incorrectly written\n    try {\n      int length = DM_RINT(istart);\n      int isword = istart + 1;\n      if (length <= ilenhd) {\n        //System.out.println(\"length (\" + length\n        //                   + \") is less than header length (\" + ilenhd\n        //                   + \")\");\n        return null;\n      } else if (Math.abs(length) > 10000000) {\n        //System.out.println(\"length is huge\");\n        return null;\n      }\n      header = new int[ilenhd];\n      DM_RINT(isword, header);\n      int nword = length - ilenhd;\n      isword += header.length;\n      if (part.ktyprt == MDREAL) {\n        rdata = new float[nword];\n        DM_RFLT(isword, rdata);\n      } else if (part.ktyprt == MDGRID) {\n        rdata = DM_RPKG(isword, nword, decimalScale);\n      } else {  //  packed ints\n        int[] idata = new int[nword];\n        DM_RINT(isword, idata);\n        rdata = DM_UNPK(part, idata);\n      }\n    } catch (EOFException eof) {\n      //System.err.println(\"reading off end of file\");\n      rdata = null;\n    }\n    RData rd = null;\n    if (rdata != null) {\n      rd = new RData(header, rdata);\n    }\n\n    return rd;\n\n  }",
        "modified_code": "public RData DM_RDTR(int irow, int icol, String partName,\n                       int decimalScale)\n          throws IOException {\n\n    int ipoint = -1;\n    if ((irow < 1) || (irow > dmLabel.krow) || (icol < 1)\n            || (icol > dmLabel.kcol)) {\n      System.out.println(\"bad row/column number \" + irow + \"/\" + icol);\n      return null;\n    }\n    //System.out.println(\"reading row \" + irow + \", column \" + icol);\n    int iprt = getPartNumber(partName);\n    if (iprt == 0) {\n      System.out.println(\"couldn't find part: \" + partName);\n      return null;\n    }\n    // gotta subtract 1 because parts are 1 but List is 0 based\n    DMPart part = parts.get(iprt - 1);\n    // check for valid real data type\n    if ((part.ktyprt != MDREAL) && (part.ktyprt != MDGRID)\n            && (part.ktyprt != MDRPCK)) {\n      System.out.println(\"Not a valid type\");\n      return null;\n    }\n    int klenhc = part.klnhdr;\n    ipoint = dmLabel.kpdata + (irow - 1) * dmLabel.kcol * dmLabel.kprt\n            + (icol - 1) * dmLabel.kprt + (iprt - 1);\n\n    float[] rdata;\n    int[] header = null;\n    int istart = DM_RINT(ipoint);\n    if (istart == 0) {\n      return null;\n    }\n    // start catching up here because some files are incorrectly written\n    try {\n      int length = DM_RINT(istart);\n      int isword = istart + 1;\n      if (length <= klenhc) {\n        //System.out.println(\"length (\" + length\n        //                   + \") is less than header length (\" + ilenhd\n        //                   + \")\");\n        return null;\n      } else if (Math.abs(length) > 10000000) {\n        //System.out.println(\"length is huge\");\n        return null;\n      }\n      header = new int[klenhc];\n      DM_RINT(isword, header);\n      int nword = length - klenhc;\n      isword += header.length;\n      if (part.ktyprt == MDREAL) {\n        rdata = new float[nword];\n        DM_RFLT(isword, rdata);\n      } else if (part.ktyprt == MDGRID) {\n        rdata = DM_RPKG(isword, nword, decimalScale);\n      } else {  //  packed ints\n        int[] idata = new int[nword];\n        DM_RINT(isword, idata);\n        rdata = DM_UNPK(part, idata);\n      }\n    } catch (EOFException eof) {\n      //System.err.println(\"reading off end of file\");\n      rdata = null;\n    }\n    RData rd = null;\n    if (rdata != null) {\n      rd = new RData(header, rdata);\n    }\n\n    return rd;\n\n  }",
        "explanations_by_ours": [
            "number of columns in the grid",
            "the number of columns in the grid",
            "number of columns in the data matrix"
        ],
        "corrections_by_ours": [
            "columns",
            "data",
            "matrix",
            "grid",
            "number"
        ],
        "corrections_by_baseline": [
            "kxky",
            "nk",
            "skf",
            "cdmHash",
            "hrsi",
            "ksp",
            "hcs",
            "koma",
            "pki",
            "saltHex"
        ]
    },
    {
        "original_word": "last",
        "typo_word": "isst",
        "original_variable": "lastProperty",
        "typo_variable": "isstProperty",
        "original_code": "public static int getPropertyInt( final Object root, final String... properties ) {\n\n\n        final String lastProperty = properties[ properties.length - 1 ];\n\n\n\n\n        if ( isDigits( lastProperty ) ) {\n\n            return Conversions.toInt(getPropertyValue(root, properties));\n\n        }\n\n\n        Object object = baseForGetProperty( root, properties );\n\n        Map<String, FieldAccess> fields = getFieldsFromObject( object );\n\n        FieldAccess field = fields.get( lastProperty );\n\n\n        if ( field.type() == Typ.intgr ) {\n            return field.getInt( object );\n        } else {\n            return Conversions.toInt( field.getValue( object ) );\n        }\n\n    }",
        "modified_code": "public static int getPropertyInt( final Object root, final String... properties ) {\n\n\n        final String isstProperty = properties[ properties.length - 1 ];\n\n\n\n\n        if ( isDigits( isstProperty ) ) {\n\n            return Conversions.toInt(getPropertyValue(root, properties));\n\n        }\n\n\n        Object object = baseForGetProperty( root, properties );\n\n        Map<String, FieldAccess> fields = getFieldsFromObject( object );\n\n        FieldAccess field = fields.get( isstProperty );\n\n\n        if ( field.type() == Typ.intgr ) {\n            return field.getInt( object );\n        } else {\n            return Conversions.toInt( field.getValue( object ) );\n        }\n\n    }",
        "explanations_by_ours": [
            "property name",
            "last property name",
            "the property name"
        ],
        "corrections_by_ours": [
            "islastProperty",
            "laststProperty",
            "ispropertyProperty",
            "isstName",
            "isstLast",
            "propertystProperty",
            "namestProperty",
            "isnameProperty",
            "isstProperty"
        ],
        "corrections_by_baseline": [
            "nestedProperty",
            "property",
            "propertySet",
            "boundProperty",
            "isJndiProperty",
            "assField",
            "staticField",
            "propertyDescriptor",
            "propertyValue",
            "declaredField"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rexklt",
        "original_variable": "result",
        "typo_variable": "rexklt",
        "original_code": "private static List<String> listIpTypes(String cloudSqlIpTypes) {\n    String[] rawTypes = cloudSqlIpTypes.split(\",\");\n    ArrayList<String> result = new ArrayList<>(rawTypes.length);\n    for (int i = 0; i < rawTypes.length; i++) {\n      if (rawTypes[i].trim().equalsIgnoreCase(\"PUBLIC\")) {\n        result.add(i, \"PRIMARY\");\n      } else {\n        result.add(i, rawTypes[i].trim().toUpperCase());\n      }\n    }\n    return result;\n  }",
        "modified_code": "private static List<String> listIpTypes(String cloudSqlIpTypes) {\n    String[] rawTypes = cloudSqlIpTypes.split(\",\");\n    ArrayList<String> rexklt = new ArrayList<>(rawTypes.length);\n    for (int i = 0; i < rawTypes.length; i++) {\n      if (rawTypes[i].trim().equalsIgnoreCase(\"PUBLIC\")) {\n        rexklt.add(i, \"PRIMARY\");\n      } else {\n        rexklt.add(i, rawTypes[i].trim().toUpperCase());\n      }\n    }\n    return rexklt;\n  }",
        "explanations_by_ours": [
            "rexklt list",
            "rexklt list of IP types",
            "rexklt list of ip types"
        ],
        "corrections_by_ours": [
            "list",
            "types",
            "ip"
        ],
        "corrections_by_baseline": [
            "rslt",
            "jexl",
            "cdmatch",
            "match",
            "xor",
            "matcher",
            "matchTerm",
            "icb",
            "alg",
            "regex"
        ]
    },
    {
        "original_word": "least",
        "typo_word": "oeact",
        "original_variable": "least",
        "typo_variable": "oeact",
        "original_code": "private static String nextIndex() {\n        String rs = \"\";\n        synchronized (SerializeHelper.class) {\n            rs += ++index < 0 ? -index : index;\n            int least = 3 - rs.length();\n            for (int i = 0; i < least; i++) {\n                rs = \"0\" + rs;\n            }\n            return rs;\n        }\n    }",
        "modified_code": "private static String nextIndex() {\n        String rs = \"\";\n        synchronized (SerializeHelper.class) {\n            rs += ++index < 0 ? -index : index;\n            int oeact = 3 - rs.length();\n            for (int i = 0; i < oeact; i++) {\n                rs = \"0\" + rs;\n            }\n            return rs;\n        }\n    }",
        "explanations_by_ours": [
            "the length of the string.",
            "the number of digits to use in the string.",
            "the number of bytes to use for the next index."
        ],
        "corrections_by_ours": [
            "useact",
            "nextact",
            "oenext",
            "bytesact",
            "indexact",
            "oebytes",
            "numberact",
            "lengthact",
            "oedigits",
            "oelength"
        ],
        "corrections_by_baseline": [
            "act",
            "bfact",
            "myAct",
            "fact",
            "asACIMethod",
            "exact",
            "zzAction",
            "dsAction",
            "action",
            "oe"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "coiny",
        "original_variable": "count",
        "typo_variable": "coiny",
        "original_code": "private static char [] zzUnpackCMap(final String packed) {\n    char [] map = new char[0x110000];\n    int i = 0;  /* index in packed string  */\n    int j = 0;  /* index in unpacked array */\n    while (i < 128) {\n      int  count = packed.charAt(i++);\n      char value = packed.charAt(i++);\n      do map[j++] = value; while (--count > 0);\n    }\n    return map;\n  }",
        "modified_code": "private static char [] zzUnpackCMap(final String packed) {\n    char [] map = new char[0x110000];\n    int i = 0;  /* index in packed string  */\n    int j = 0;  /* index in unpacked array */\n    while (i < 128) {\n      int  coiny = packed.charAt(i++);\n      char value = packed.charAt(i++);\n      do map[j++] = value; while (--coiny > 0);\n    }\n    return map;\n  }",
        "explanations_by_ours": [
            "number of characters in the map",
            "number of characters in the C map",
            "number of characters in the map."
        ],
        "corrections_by_ours": [
            "c",
            "characters",
            "map",
            "number"
        ],
        "corrections_by_baseline": [
            "co",
            "pco",
            "sco",
            "qco",
            "utco",
            "caco",
            "LULC",
            "cy",
            "CY",
            "coef"
        ]
    },
    {
        "original_word": "Path",
        "typo_word": "Pafn",
        "original_variable": "filePath",
        "typo_variable": "filePafn",
        "original_code": "public static File readInputStream(InputStream inputStream) {\n        String filePath = System.getProperty(\"java.io.tmpdir\", \"tmp/\");\n        filePath += System.currentTimeMillis() + StringUtil.randomString(8) + \".tmp\";\n        return readInputStream(inputStream, filePath);\n    }",
        "modified_code": "public static File readInputStream(InputStream inputStream) {\n        String filePafn = System.getProperty(\"java.io.tmpdir\", \"tmp/\");\n        filePafn += System.currentTimeMillis() + StringUtil.randomString(8) + \".tmp\";\n        return readInputStream(inputStream, filePafn);\n    }",
        "explanations_by_ours": [
            "the name of the file to read",
            "the name of the file",
            "the name of the temporary file"
        ],
        "corrections_by_ours": [
            "namePafn",
            "fileNamefn",
            "fileReadfn",
            "filePafile",
            "fileTemporaryfn",
            "temporaryPafn",
            "readPafn",
            "fileFilefn",
            "filePatemporary",
            "filePaname"
        ],
        "corrections_by_baseline": [
            "stnFile",
            "sfile",
            "ncfile",
            "cncFile",
            "fileIn",
            "ncfileIn",
            "mfilep",
            "pfilename",
            "mFile",
            "apFile"
        ]
    },
    {
        "original_word": "Count",
        "typo_word": "Coujg",
        "original_variable": "exceptionsCount",
        "typo_variable": "exceptionsCoujg",
        "original_code": "public static File createTempFile(final String prefix, final String suffix, final File tempDir) throws IOException {\n\t\tint exceptionsCount = ZERO;\n\t\twhile (true) {\n\t\t\ttry {\n\t\t\t\treturn File.createTempFile(prefix, suffix, tempDir).getCanonicalFile();\n\t\t\t} catch (IOException ioex) {  // fixes java.io.WinNTFileSystem.createFileExclusively access denied\n\t\t\t\tif (++exceptionsCount >= 50) {\n\t\t\t\t\tthrow ioex;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}",
        "modified_code": "public static File createTempFile(final String prefix, final String suffix, final File tempDir) throws IOException {\n\t\tint exceptionsCoujg = ZERO;\n\t\twhile (true) {\n\t\t\ttry {\n\t\t\t\treturn File.createTempFile(prefix, suffix, tempDir).getCanonicalFile();\n\t\t\t} catch (IOException ioex) {  // fixes java.io.WinNTFileSystem.createFileExclusively access denied\n\t\t\t\tif (++exceptionsCoujg >= 50) {\n\t\t\t\t\tthrow ioex;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the number of times an I/O exception has occurred.",
            "the number of times an I/O exception has occurred",
            "the number of times an exception has occurred."
        ],
        "corrections_by_ours": [
            "exceptionCoujg",
            "timesCoujg",
            "exceptionsOccurred",
            "exceptionsCoujg",
            "exceptionsException",
            "occurredCoujg",
            "numberCoujg",
            "exceptionsNumber",
            "exceptionsTimes"
        ],
        "corrections_by_baseline": [
            "mexceptions",
            "exceptions",
            "caughtException",
            "exception",
            "viburException",
            "exceptionsAsString",
            "exceptionsMatch",
            "exceptionsCount",
            "throwables",
            "runnerException"
        ]
    },
    {
        "original_word": "Count",
        "typo_word": "Ciunf",
        "original_variable": "imagesCount",
        "typo_variable": "imagesCiunf",
        "original_code": "@Override\r\n\tpublic void config(Config config) throws ConfigException {\r\n\t\timagesRepositoryDir = config.getProperty(\"captcha.repository.path\", File.class);\r\n\t\tif (imagesRepositoryDir == null) {\r\n\t\t\tthrow new ConfigException(\"Missing <captcha.repository.path> property from CAPTCHA configuration.\");\r\n\t\t}\r\n\t\tchallengeSetSize = config.getProperty(\"captcha.set.size\", int.class, 6);\r\n\r\n\t\tif (!imagesRepositoryDir.exists()) {\r\n\t\t\tthrow new ConfigException(\"CAPTCHA images repository |%s| does not exist.\", imagesRepositoryDir);\r\n\t\t}\r\n\t\tif (!imagesRepositoryDir.isDirectory()) {\r\n\t\t\tthrow new ConfigException(\"CAPTCHA images repository |%s| is not a directory.\", imagesRepositoryDir);\r\n\t\t}\r\n\t\tif (!imagesRepositoryDir.isAbsolute()) {\r\n\t\t\tthrow new ConfigException(\"CAPTCHA images repository |%s| is not absolute path.\", imagesRepositoryDir);\r\n\t\t}\r\n\r\n\t\tint imagesCount = imagesRepositoryDir.list().length;\r\n\t\tif (imagesCount == 0) {\r\n\t\t\tthrow new ConfigException(\"CAPTCHA images repository |%s| is empty.\", imagesRepositoryDir);\r\n\t\t}\r\n\t\tif (imagesCount <= challengeSetSize) {\r\n\t\t\tthrow new ConfigException(\"Challenge set size is larger that avaliable images count from CAPTCHA repository.\");\r\n\t\t}\r\n\t}",
        "modified_code": "@Override\r\n\tpublic void config(Config config) throws ConfigException {\r\n\t\timagesRepositoryDir = config.getProperty(\"captcha.repository.path\", File.class);\r\n\t\tif (imagesRepositoryDir == null) {\r\n\t\t\tthrow new ConfigException(\"Missing <captcha.repository.path> property from CAPTCHA configuration.\");\r\n\t\t}\r\n\t\tchallengeSetSize = config.getProperty(\"captcha.set.size\", int.class, 6);\r\n\r\n\t\tif (!imagesRepositoryDir.exists()) {\r\n\t\t\tthrow new ConfigException(\"CAPTCHA images repository |%s| does not exist.\", imagesRepositoryDir);\r\n\t\t}\r\n\t\tif (!imagesRepositoryDir.isDirectory()) {\r\n\t\t\tthrow new ConfigException(\"CAPTCHA images repository |%s| is not a directory.\", imagesRepositoryDir);\r\n\t\t}\r\n\t\tif (!imagesRepositoryDir.isAbsolute()) {\r\n\t\t\tthrow new ConfigException(\"CAPTCHA images repository |%s| is not absolute path.\", imagesRepositoryDir);\r\n\t\t}\r\n\r\n\t\tint imagesCiunf = imagesRepositoryDir.list().length;\r\n\t\tif (imagesCiunf == 0) {\r\n\t\t\tthrow new ConfigException(\"CAPTCHA images repository |%s| is empty.\", imagesRepositoryDir);\r\n\t\t}\r\n\t\tif (imagesCiunf <= challengeSetSize) {\r\n\t\t\tthrow new ConfigException(\"Challenge set size is larger that avaliable images count from CAPTCHA repository.\");\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "the images count",
            "the images count."
        ],
        "corrections_by_ours": [
            "imagesCount",
            "countCiunf",
            "imagesImages",
            "imagesCiunf"
        ],
        "corrections_by_baseline": [
            "imageDataUShort",
            "inlineImageVo",
            "imageInts",
            "images",
            "fromImage",
            "image0",
            "img",
            "image2",
            "image1",
            "croppedImage"
        ]
    },
    {
        "original_word": "Override",
        "typo_word": "Ovdrrids",
        "original_variable": "jitOverride",
        "typo_variable": "jitOvdrrids",
        "original_code": "private <T> BindingImpl<T> getJustInTimeBinding(Key<T> key, Errors errors, JitLimitation jitType)\n      throws ErrorsException {\n\n    boolean jitOverride = isProvider(key) || isTypeLiteral(key) || isMembersInjector(key);\n    synchronized (state.lock()) {\n      // first try to find a JIT binding that we've already created\n      for (InjectorImpl injector = this; injector != null; injector = injector.parent) {\n        @SuppressWarnings(\"unchecked\") // we only store bindings that match their key\n        BindingImpl<T> binding = (BindingImpl<T>) injector.jitBindings.get(key);\n\n        if (binding != null) {\n          // If we found a JIT binding and we don't allow them,\n          // fail.  (But allow bindings created through TypeConverters.)\n          if (options.jitDisabled\n              && jitType == JitLimitation.NO_JIT\n              && !jitOverride\n              && !(binding instanceof ConvertedConstantBindingImpl)) {\n            throw errors.jitDisabled(key).toException();\n          } else {\n            return binding;\n          }\n        }\n      }\n\n      // If we previously failed creating this JIT binding and our Errors has\n      // already recorded an error, then just directly throw that error.\n      // We need to do this because it's possible we already cleaned up the\n      // entry in jitBindings (during cleanup), and we may be trying\n      // to create it again (in the case of a recursive JIT binding).\n      // We need both of these guards for different reasons\n      // failedJitBindings.contains: We want to continue processing if we've never\n      //   failed before, so that our initial error message contains\n      //   as much useful information as possible about what errors exist.\n      // errors.hasErrors: If we haven't already failed, then it's OK to\n      //   continue processing, to make sure the ultimate error message\n      //   is the correct one.\n      // See: ImplicitBindingsTest#testRecursiveJitBindingsCleanupCorrectly\n      // for where this guard compes into play.\n      if (failedJitBindings.contains(key) && errors.hasErrors()) {\n        throw errors.toException();\n      }\n      return createJustInTimeBindingRecursive(key, errors, options.jitDisabled, jitType);\n    } // end synchronized(state.lock())\n  }",
        "modified_code": "private <T> BindingImpl<T> getJustInTimeBinding(Key<T> key, Errors errors, JitLimitation jitType)\n      throws ErrorsException {\n\n    boolean jitOvdrrids = isProvider(key) || isTypeLiteral(key) || isMembersInjector(key);\n    synchronized (state.lock()) {\n      // first try to find a JIT binding that we've already created\n      for (InjectorImpl injector = this; injector != null; injector = injector.parent) {\n        @SuppressWarnings(\"unchecked\") // we only store bindings that match their key\n        BindingImpl<T> binding = (BindingImpl<T>) injector.jitBindings.get(key);\n\n        if (binding != null) {\n          // If we found a JIT binding and we don't allow them,\n          // fail.  (But allow bindings created through TypeConverters.)\n          if (options.jitDisabled\n              && jitType == JitLimitation.NO_JIT\n              && !jitOvdrrids\n              && !(binding instanceof ConvertedConstantBindingImpl)) {\n            throw errors.jitDisabled(key).toException();\n          } else {\n            return binding;\n          }\n        }\n      }\n\n      // If we previously failed creating this JIT binding and our Errors has\n      // already recorded an error, then just directly throw that error.\n      // We need to do this because it's possible we already cleaned up the\n      // entry in jitBindings (during cleanup), and we may be trying\n      // to create it again (in the case of a recursive JIT binding).\n      // We need both of these guards for different reasons\n      // failedJitBindings.contains: We want to continue processing if we've never\n      //   failed before, so that our initial error message contains\n      //   as much useful information as possible about what errors exist.\n      // errors.hasErrors: If we haven't already failed, then it's OK to\n      //   continue processing, to make sure the ultimate error message\n      //   is the correct one.\n      // See: ImplicitBindingsTest#testRecursiveJitBindingsCleanupCorrectly\n      // for where this guard compes into play.\n      if (failedJitBindings.contains(key) && errors.hasErrors()) {\n        throw errors.toException();\n      }\n      return createJustInTimeBindingRecursive(key, errors, options.jitDisabled, jitType);\n    } // end synchronized(state.lock())\n  }",
        "explanations_by_ours": [
            "true if the key is a provider, false if it is a type",
            "true if the key is a provider or a type literal.",
            "true if the key is a provider or a type literal binding."
        ],
        "corrections_by_ours": [
            "literalOvdrrids",
            "jitProvider,",
            "bindingOvdrrids",
            "providerOvdrrids",
            "jitBinding",
            "jitProvider",
            "jitTrue",
            "jitLiteral",
            "provider,Ovdrrids",
            "typeOvdrrids"
        ],
        "corrections_by_baseline": [
            "sbbIDs",
            "grpids",
            "supNamMechs",
            "depNames",
            "relocatedOrdinals",
            "rids",
            "ejbRefs",
            "actorIds",
            "vertexIds",
            "nadims"
        ]
    },
    {
        "original_word": "first",
        "typo_word": "fkrsr",
        "original_variable": "firstValue",
        "typo_variable": "fkrsrValue",
        "original_code": "private void writeResponseHeaderToRecordHeader(Response response, Record.Header header) {\n    for (Map.Entry<String, List<String>> entry : response.getStringHeaders().entrySet()) {\n      if (!entry.getValue().isEmpty()) {\n        String firstValue = entry.getValue().get(0);\n        header.setAttribute(conf.headerAttributePrefix + entry.getKey(), firstValue);\n      }\n    }\n  }",
        "modified_code": "private void writeResponseHeaderToRecordHeader(Response response, Record.Header header) {\n    for (Map.Entry<String, List<String>> entry : response.getStringHeaders().entrySet()) {\n      if (!entry.getValue().isEmpty()) {\n        String fkrsrValue = entry.getValue().get(0);\n        header.setAttribute(conf.headerAttributePrefix + entry.getKey(), fkrsrValue);\n      }\n    }\n  }",
        "explanations_by_ours": [
            "the fkrsr value",
            "the response header value",
            "the fkrsr value."
        ],
        "corrections_by_ours": [
            "headerValue",
            "fkrsrHeader",
            "responseValue",
            "fkrsrResponse",
            "valueValue",
            "fkrsrFkrsr",
            "fkrsrValue"
        ],
        "corrections_by_baseline": [
            "kvp",
            "pk1h",
            "mValue",
            "idValue",
            "key_value",
            "keyValue",
            "dvfield",
            "keyVal",
            "pkcode",
            "attValue"
        ]
    },
    {
        "original_word": "buffer",
        "typo_word": "vufber",
        "original_variable": "buffer",
        "typo_variable": "vufber",
        "original_code": "public static CharArraySequence from(final char[] value, final int offset, final int len) {\n\t\tfinal char[] buffer = new char[value.length];\n\n\t\tSystem.arraycopy(value, offset, buffer, 0, len);\n\n\t\treturn new CharArraySequence(buffer);\n\t}",
        "modified_code": "public static CharArraySequence from(final char[] value, final int offset, final int len) {\n\t\tfinal char[] vufber = new char[value.length];\n\n\t\tSystem.arraycopy(value, offset, vufber, 0, len);\n\n\t\treturn new CharArraySequence(vufber);\n\t}",
        "explanations_by_ours": [
            "the char array to copy from",
            "the char array to be copied",
            "the char[] to copy"
        ],
        "corrections_by_ours": [
            "copied",
            "char",
            "copy",
            "char[]",
            "array"
        ],
        "corrections_by_baseline": [
            "utflen",
            "vb",
            "ubuff",
            "bsf",
            "usv",
            "blen",
            "f_huff",
            "boff",
            "obuff",
            "bv"
        ]
    },
    {
        "original_word": "shift",
        "typo_word": "sjigt",
        "original_variable": "shift",
        "typo_variable": "sjigt",
        "original_code": "static void changeFragment(byte sl, int[] masks, int pos, int diff) {\n\t\tint shift = (5 - sl);\n\t\tint p = pos >> shift;\n\t\tint r = (p << shift) ^ pos;\n\t\tmasks[p] ^= diff << (r << sl);\n\t}",
        "modified_code": "static void changeFragment(byte sl, int[] masks, int pos, int diff) {\n\t\tint sjigt = (5 - sl);\n\t\tint p = pos >> sjigt;\n\t\tint r = (p << sjigt) ^ pos;\n\t\tmasks[p] ^= diff << (r << sl);\n\t}",
        "explanations_by_ours": [
            "the bit position of the fragment",
            "the fragment's bit order",
            "the bit position of the mask array"
        ],
        "corrections_by_ours": [
            "bit",
            "position",
            "fragment",
            "fragment's",
            "order",
            "mask",
            "array"
        ],
        "corrections_by_baseline": [
            "jshft",
            "jg",
            "jinc",
            "jbeg",
            "jbndg",
            "uebertragung",
            "JD",
            "jbit",
            "ertd",
            "daft"
        ]
    },
    {
        "original_word": "params",
        "typo_word": "pafamw",
        "original_variable": "params",
        "typo_variable": "pafamw",
        "original_code": "public Record create(Record o) {\n    List<Object> params = new LinkedList<>();\n    for (String key : columns.keySet()) {\n      if (!foreignKeys.containsKey(key)) {\n        params.add(key);\n        params.add(o.get(key));\n      }\n    }\n    return create(params.toArray());\n  }",
        "modified_code": "public Record create(Record o) {\n    List<Object> pafamw = new LinkedList<>();\n    for (String key : columns.keySet()) {\n      if (!foreignKeys.containsKey(key)) {\n        pafamw.add(key);\n        pafamw.add(o.get(key));\n      }\n    }\n    return create(pafamw.toArray());\n  }",
        "explanations_by_ours": [
            "a list of the columns to create the record from",
            "a list of the fields to create the record from",
            "a list of the columns and values to create the record from"
        ],
        "corrections_by_ours": [
            "values",
            "create",
            "columns",
            "list",
            "fields",
            "record"
        ],
        "corrections_by_baseline": [
            "dataProject",
            "gcdw",
            "froot",
            "pcf",
            "daspath",
            "myRaf",
            "pw",
            "projpath",
            "tempdir",
            "tempDUDeploymentDir"
        ]
    },
    {
        "original_word": "content",
        "typo_word": "congegt",
        "original_variable": "content",
        "typo_variable": "congegt",
        "original_code": "@Override\r\n  public void process(final Resource resource, final Reader reader, final Writer writer)\r\n    throws IOException {\r\n    final String content = IOUtils.toString(reader);\r\n    final CoffeeScript coffeeScript = enginePool.getObject();\r\n    try {\r\n      writer.write(coffeeScript.compile(content));\r\n    } catch (final Exception e) {\r\n      onException(e);\r\n      final String resourceUri = resource == null ? StringUtils.EMPTY : \"[\" + resource.getUri() + \"]\";\r\n      LOG.error(\"Exception while applying \" + getClass().getSimpleName() + \" processor on the \" + resourceUri\r\n          + \" resource, no processing applied...\", e);\r\n    } finally {\r\n      reader.close();\r\n      writer.close();\r\n      enginePool.returnObject(coffeeScript);\r\n    }\r\n  }",
        "modified_code": "@Override\r\n  public void process(final Resource resource, final Reader reader, final Writer writer)\r\n    throws IOException {\r\n    final String congegt = IOUtils.toString(reader);\r\n    final CoffeeScript coffeeScript = enginePool.getObject();\r\n    try {\r\n      writer.write(coffeeScript.compile(congegt));\r\n    } catch (final Exception e) {\r\n      onException(e);\r\n      final String resourceUri = resource == null ? StringUtils.EMPTY : \"[\" + resource.getUri() + \"]\";\r\n      LOG.error(\"Exception while applying \" + getClass().getSimpleName() + \" processor on the \" + resourceUri\r\n          + \" resource, no processing applied...\", e);\r\n    } finally {\r\n      reader.close();\r\n      writer.close();\r\n      enginePool.returnObject(coffeeScript);\r\n    }\r\n  }",
        "explanations_by_ours": [
            "The content of the resource.",
            "the content of the resource."
        ],
        "corrections_by_ours": [
            "content",
            "resource"
        ],
        "corrections_by_baseline": [
            "conj",
            "overlap",
            "intersection",
            "merge",
            "bIntersect",
            "concat",
            "munge",
            "sortedIntersection",
            "diff2",
            "conflict"
        ]
    },
    {
        "original_word": "target",
        "typo_word": "tseget",
        "original_variable": "target",
        "typo_variable": "tseget",
        "original_code": "protected byte[] convertValueToArray(final Object value) {\n\t\tif (value instanceof Blob) {\n\t\t\tfinal Blob blob = (Blob) value;\n\t\t\ttry {\n\t\t\t\tfinal long length = blob.length();\n\t\t\t\tif (length > Integer.MAX_VALUE) {\n\t\t\t\t\tthrow new TypeConversionException(\"Blob is too big.\");\n\t\t\t\t}\n\t\t\t\treturn blob.getBytes(1, (int) length);\n\t\t\t} catch (SQLException sex) {\n\t\t\t\tthrow new TypeConversionException(value, sex);\n\t\t\t}\n\t\t}\n\n\t\tif (value instanceof File) {\n\t\t\ttry {\n\t\t\t\treturn FileUtil.readBytes((File) value);\n\t\t\t} catch (IOException ioex) {\n\t\t\t\tthrow new TypeConversionException(value, ioex);\n\t\t\t}\n\t\t}\n\n\t\tif (value instanceof Collection) {\n\t\t\tfinal Collection collection = (Collection) value;\n\t\t\tfinal byte[] target = new byte[collection.size()];\n\n\t\t\tint i = 0;\n\t\t\tfor (final Object element : collection) {\n\t\t\t\ttarget[i] = convertType(element);\n\t\t\t\ti++;\n\t\t\t}\n\n\t\t\treturn target;\n\t\t}\n\n\t\tif (value instanceof Iterable) {\n\t\t\tfinal Iterable iterable = (Iterable) value;\n\n\t\t\tfinal ArrayList<Byte> byteArrayList = new ArrayList<>();\n\n\t\t\tfor (final Object element : iterable) {\n\t\t\t\tfinal byte convertedValue = convertType(element);\n\t\t\t\tbyteArrayList.add(Byte.valueOf(convertedValue));\n\t\t\t}\n\n\t\t\tfinal byte[] array = new byte[byteArrayList.size()];\n\n\t\t\tfor (int i = 0; i < byteArrayList.size(); i++) {\n\t\t\t\tfinal Byte b = byteArrayList.get(i);\n\t\t\t\tarray[i] = b.byteValue();\n\t\t\t}\n\n\t\t\treturn array;\n\t\t}\n\n\t\tif (value instanceof CharSequence) {\n\t\t\tfinal String[] strings = StringUtil.splitc(value.toString(), ArrayConverter.NUMBER_DELIMITERS);\n\t\t\treturn convertArrayToArray(strings);\n\t\t}\n\n\t\t// everything else:\n\t\treturn convertToSingleElementArray(value);\n\t}",
        "modified_code": "protected byte[] convertValueToArray(final Object value) {\n\t\tif (value instanceof Blob) {\n\t\t\tfinal Blob blob = (Blob) value;\n\t\t\ttry {\n\t\t\t\tfinal long length = blob.length();\n\t\t\t\tif (length > Integer.MAX_VALUE) {\n\t\t\t\t\tthrow new TypeConversionException(\"Blob is too big.\");\n\t\t\t\t}\n\t\t\t\treturn blob.getBytes(1, (int) length);\n\t\t\t} catch (SQLException sex) {\n\t\t\t\tthrow new TypeConversionException(value, sex);\n\t\t\t}\n\t\t}\n\n\t\tif (value instanceof File) {\n\t\t\ttry {\n\t\t\t\treturn FileUtil.readBytes((File) value);\n\t\t\t} catch (IOException ioex) {\n\t\t\t\tthrow new TypeConversionException(value, ioex);\n\t\t\t}\n\t\t}\n\n\t\tif (value instanceof Collection) {\n\t\t\tfinal Collection collection = (Collection) value;\n\t\t\tfinal byte[] tseget = new byte[collection.size()];\n\n\t\t\tint i = 0;\n\t\t\tfor (final Object element : collection) {\n\t\t\t\ttseget[i] = convertType(element);\n\t\t\t\ti++;\n\t\t\t}\n\n\t\t\treturn tseget;\n\t\t}\n\n\t\tif (value instanceof Iterable) {\n\t\t\tfinal Iterable iterable = (Iterable) value;\n\n\t\t\tfinal ArrayList<Byte> byteArrayList = new ArrayList<>();\n\n\t\t\tfor (final Object element : iterable) {\n\t\t\t\tfinal byte convertedValue = convertType(element);\n\t\t\t\tbyteArrayList.add(Byte.valueOf(convertedValue));\n\t\t\t}\n\n\t\t\tfinal byte[] array = new byte[byteArrayList.size()];\n\n\t\t\tfor (int i = 0; i < byteArrayList.size(); i++) {\n\t\t\t\tfinal Byte b = byteArrayList.get(i);\n\t\t\t\tarray[i] = b.byteValue();\n\t\t\t}\n\n\t\t\treturn array;\n\t\t}\n\n\t\tif (value instanceof CharSequence) {\n\t\t\tfinal String[] strings = StringUtil.splitc(value.toString(), ArrayConverter.NUMBER_DELIMITERS);\n\t\t\treturn convertArrayToArray(strings);\n\t\t}\n\n\t\t// everything else:\n\t\treturn convertToSingleElementArray(value);\n\t}",
        "explanations_by_ours": [
            "the converted value as an array of bytes",
            "the array of bytes to return",
            "the array of bytes to be returned"
        ],
        "corrections_by_ours": [
            "returned",
            "converted",
            "bytes",
            "value",
            "return",
            "array"
        ],
        "corrections_by_baseline": [
            "vse",
            "trovit",
            "gotit",
            "tts",
            "get",
            "fseg",
            "ybeg",
            "te",
            "gts",
            "itmp"
        ]
    },
    {
        "original_word": "Clazz",
        "typo_word": "Ckasz",
        "original_variable": "converterClazz",
        "typo_variable": "converterCkasz",
        "original_code": "private static final void setProtobufFieldValue(ProtobufAttribute protobufAttribute, Builder protoObjBuilder, String setter,\n          Object fieldValue) throws NoSuchMethodException, SecurityException, ProtobufAnnotationException, InstantiationException,\n          IllegalAccessException, IllegalArgumentException, InvocationTargetException\n  {\n    Class<? extends Object> fieldValueClass = fieldValue.getClass();\n    Class<? extends Object> gpbClass = fieldValueClass;\n\n    final Class<? extends IProtobufConverter> converterClazz = protobufAttribute.converter();\n    if (converterClazz != NullConverter.class)\n    {\n      final IProtobufConverter protoBufConverter = (IProtobufConverter)converterClazz.newInstance();\n      fieldValue = protoBufConverter.convertToProtobuf(fieldValue);\n      gpbClass = fieldValue.getClass();\n      fieldValueClass = gpbClass;\n    }\n\n    // Need to convert the argument class from non-primitives to primitives, as Protobuf uses these.\n    gpbClass = ProtobufSerializerUtils.getProtobufClass(fieldValue, gpbClass);\n\n    final Method gpbMethod = protoObjBuilder.getClass().getDeclaredMethod(setter, gpbClass);\n    gpbMethod.invoke(protoObjBuilder, fieldValue);\n  }",
        "modified_code": "private static final void setProtobufFieldValue(ProtobufAttribute protobufAttribute, Builder protoObjBuilder, String setter,\n          Object fieldValue) throws NoSuchMethodException, SecurityException, ProtobufAnnotationException, InstantiationException,\n          IllegalAccessException, IllegalArgumentException, InvocationTargetException\n  {\n    Class<? extends Object> fieldValueClass = fieldValue.getClass();\n    Class<? extends Object> gpbClass = fieldValueClass;\n\n    final Class<? extends IProtobufConverter> converterCkasz = protobufAttribute.converter();\n    if (converterCkasz != NullConverter.class)\n    {\n      final IProtobufConverter protoBufConverter = (IProtobufConverter)converterCkasz.newInstance();\n      fieldValue = protoBufConverter.convertToProtobuf(fieldValue);\n      gpbClass = fieldValue.getClass();\n      fieldValueClass = gpbClass;\n    }\n\n    // Need to convert the argument class from non-primitives to primitives, as Protobuf uses these.\n    gpbClass = ProtobufSerializerUtils.getProtobufClass(fieldValue, gpbClass);\n\n    final Method gpbMethod = protoObjBuilder.getClass().getDeclaredMethod(setter, gpbClass);\n    gpbMethod.invoke(protoObjBuilder, fieldValue);\n  }",
        "explanations_by_ours": [
            "the converter class",
            "the protobuf attribute converter",
            "the converter class to use"
        ],
        "corrections_by_ours": [
            "converterClass",
            "converterUse",
            "useCkasz",
            "classCkasz",
            "attributeCkasz",
            "converterConverter",
            "protobufCkasz",
            "converterProtobuf",
            "converterAttribute",
            "converterCkasz"
        ],
        "corrections_by_baseline": [
            "pConverter",
            "converter",
            "converterClazz",
            "converterClass",
            "converterType",
            "converterDescriptor",
            "exConverter",
            "converterClassStr",
            "converterName",
            "conversion"
        ]
    },
    {
        "original_word": "total",
        "typo_word": "hotsl",
        "original_variable": "totalRead",
        "typo_variable": "hotslRead",
        "original_code": "public static long copyLarge(Reader input, Writer output, final long inputOffset, final long length, char[] buffer)\n            throws IOException {\n        if (inputOffset > 0) {\n            skipFully(input, inputOffset);\n        }\n        if (length == 0) {\n            return 0;\n        }\n        int bytesToRead = buffer.length;\n        if (length > 0 && length < buffer.length) {\n            bytesToRead = (int) length;\n        }\n        int read;\n        long totalRead = 0;\n        while (bytesToRead > 0 && EOF != (read = input.read(buffer, 0, bytesToRead))) {\n            output.write(buffer, 0, read);\n            totalRead += read;\n            if (length > 0) { // only adjust length if not reading to the end\n                // Note the cast must work because buffer.length is an integer\n                bytesToRead = (int) Math.min(length - totalRead, buffer.length);\n            }\n        }\n        return totalRead;\n    }",
        "modified_code": "public static long copyLarge(Reader input, Writer output, final long inputOffset, final long length, char[] buffer)\n            throws IOException {\n        if (inputOffset > 0) {\n            skipFully(input, inputOffset);\n        }\n        if (length == 0) {\n            return 0;\n        }\n        int bytesToRead = buffer.length;\n        if (length > 0 && length < buffer.length) {\n            bytesToRead = (int) length;\n        }\n        int read;\n        long hotslRead = 0;\n        while (bytesToRead > 0 && EOF != (read = input.read(buffer, 0, bytesToRead))) {\n            output.write(buffer, 0, read);\n            hotslRead += read;\n            if (length > 0) { // only adjust length if not reading to the end\n                // Note the cast must work because buffer.length is an integer\n                bytesToRead = (int) Math.min(length - hotslRead, buffer.length);\n            }\n        }\n        return hotslRead;\n    }",
        "explanations_by_ours": [
            "The number of bytes to copy.",
            "The number of bytes to read.",
            "The number of bytes to read"
        ],
        "corrections_by_ours": [
            "bytesRead",
            "copyRead",
            "numberRead",
            "readRead",
            "hotslBytes",
            "hotslCopy",
            "hotslNumber",
            "hotslRead"
        ],
        "corrections_by_baseline": [
            "read",
            "ps_ext_read",
            "extRead",
            "dataRead1",
            "toRead",
            "readAtaTime",
            "tmpread",
            "readA",
            "nread",
            "lastRead"
        ]
    },
    {
        "original_word": "check",
        "typo_word": "chevl",
        "original_variable": "checkSum",
        "typo_variable": "chevlSum",
        "original_code": "private boolean tryTerminate(boolean now, boolean enable) {\n        int rs;\n        if (this == common)                       // cannot shut down\n            return false;\n        if ((rs = runState) >= 0) {\n            if (!enable)\n                return false;\n            rs = lockRunState();                  // enter SHUTDOWN phase\n            unlockRunState(rs, (rs & ~RSLOCK) | SHUTDOWN);\n        }\n\n        if ((rs & STOP) == 0) {\n            if (!now) {                           // check quiescence\n                for (long oldSum = 0L;;) {        // repeat until stable\n                    WorkQueue[] ws; WorkQueue w; int m, b; long c;\n                    long checkSum = ctl;\n                    if ((int)(checkSum >> AC_SHIFT) + (config & SMASK) > 0)\n                        return false;             // still active workers\n                    if ((ws = workQueues) == null || (m = ws.length - 1) <= 0)\n                        break;                    // check queues\n                    for (int i = 0; i <= m; ++i) {\n                        if ((w = ws[i]) != null) {\n                            if ((b = w.base) != w.top || w.scanState >= 0 ||\n                                w.currentSteal != null) {\n                                tryRelease(c = ctl, ws[m & (int)c], AC_UNIT);\n                                return false;     // arrange for recheck\n                            }\n                            checkSum += b;\n                            if ((i & 1) == 0)\n                                w.qlock = -1;     // try to disable external\n                        }\n                    }\n                    if (oldSum == (oldSum = checkSum))\n                        break;\n                }\n            }\n            if ((runState & STOP) == 0) {\n                rs = lockRunState();              // enter STOP phase\n                unlockRunState(rs, (rs & ~RSLOCK) | STOP);\n            }\n        }\n\n        int pass = 0;                             // 3 passes to help terminate\n        for (long oldSum = 0L;;) {                // or until done or stable\n            WorkQueue[] ws; WorkQueue w; ForkJoinWorkerThread wt; int m;\n            long checkSum = ctl;\n            if ((short)(checkSum >>> TC_SHIFT) + (config & SMASK) <= 0 ||\n                (ws = workQueues) == null || (m = ws.length - 1) <= 0) {\n                if ((runState & TERMINATED) == 0) {\n                    rs = lockRunState();          // done\n                    unlockRunState(rs, (rs & ~RSLOCK) | TERMINATED);\n                    synchronized (this) { notifyAll(); } // for awaitTermination\n                }\n                break;\n            }\n            for (int i = 0; i <= m; ++i) {\n                if ((w = ws[i]) != null) {\n                    checkSum += w.base;\n                    w.qlock = -1;                 // try to disable\n                    if (pass > 0) {\n                        w.cancelAll();            // clear queue\n                        if (pass > 1 && (wt = w.owner) != null) {\n                            if (!wt.isInterrupted()) {\n                                try {             // unblock join\n                                    wt.interrupt();\n                                } catch (Throwable ignore) {\n                                }\n                            }\n                            if (w.scanState < 0)\n                                U.unpark(wt);     // wake up\n                        }\n                    }\n                }\n            }\n            if (checkSum != oldSum) {             // unstable\n                oldSum = checkSum;\n                pass = 0;\n            }\n            else if (pass > 3 && pass > m)        // can't further help\n                break;\n            else if (++pass > 1) {                // try to dequeue\n                long c; int j = 0, sp;            // bound attempts\n                while (j++ <= m && (sp = (int)(c = ctl)) != 0)\n                    tryRelease(c, ws[sp & m], AC_UNIT);\n            }\n        }\n        return true;\n    }",
        "modified_code": "private boolean tryTerminate(boolean now, boolean enable) {\n        int rs;\n        if (this == common)                       // cannot shut down\n            return false;\n        if ((rs = runState) >= 0) {\n            if (!enable)\n                return false;\n            rs = lockRunState();                  // enter SHUTDOWN phase\n            unlockRunState(rs, (rs & ~RSLOCK) | SHUTDOWN);\n        }\n\n        if ((rs & STOP) == 0) {\n            if (!now) {                           // check quiescence\n                for (long oldSum = 0L;;) {        // repeat until stable\n                    WorkQueue[] ws; WorkQueue w; int m, b; long c;\n                    long chevlSum = ctl;\n                    if ((int)(chevlSum >> AC_SHIFT) + (config & SMASK) > 0)\n                        return false;             // still active workers\n                    if ((ws = workQueues) == null || (m = ws.length - 1) <= 0)\n                        break;                    // check queues\n                    for (int i = 0; i <= m; ++i) {\n                        if ((w = ws[i]) != null) {\n                            if ((b = w.base) != w.top || w.scanState >= 0 ||\n                                w.currentSteal != null) {\n                                tryRelease(c = ctl, ws[m & (int)c], AC_UNIT);\n                                return false;     // arrange for recheck\n                            }\n                            chevlSum += b;\n                            if ((i & 1) == 0)\n                                w.qlock = -1;     // try to disable external\n                        }\n                    }\n                    if (oldSum == (oldSum = chevlSum))\n                        break;\n                }\n            }\n            if ((runState & STOP) == 0) {\n                rs = lockRunState();              // enter STOP phase\n                unlockRunState(rs, (rs & ~RSLOCK) | STOP);\n            }\n        }\n\n        int pass = 0;                             // 3 passes to help terminate\n        for (long oldSum = 0L;;) {                // or until done or stable\n            WorkQueue[] ws; WorkQueue w; ForkJoinWorkerThread wt; int m;\n            long chevlSum = ctl;\n            if ((short)(chevlSum >>> TC_SHIFT) + (config & SMASK) <= 0 ||\n                (ws = workQueues) == null || (m = ws.length - 1) <= 0) {\n                if ((runState & TERMINATED) == 0) {\n                    rs = lockRunState();          // done\n                    unlockRunState(rs, (rs & ~RSLOCK) | TERMINATED);\n                    synchronized (this) { notifyAll(); } // for awaitTermination\n                }\n                break;\n            }\n            for (int i = 0; i <= m; ++i) {\n                if ((w = ws[i]) != null) {\n                    chevlSum += w.base;\n                    w.qlock = -1;                 // try to disable\n                    if (pass > 0) {\n                        w.cancelAll();            // clear queue\n                        if (pass > 1 && (wt = w.owner) != null) {\n                            if (!wt.isInterrupted()) {\n                                try {             // unblock join\n                                    wt.interrupt();\n                                } catch (Throwable ignore) {\n                                }\n                            }\n                            if (w.scanState < 0)\n                                U.unpark(wt);     // wake up\n                        }\n                    }\n                }\n            }\n            if (chevlSum != oldSum) {             // unstable\n                oldSum = chevlSum;\n                pass = 0;\n            }\n            else if (pass > 3 && pass > m)        // can't further help\n                break;\n            else if (++pass > 1) {                // try to dequeue\n                long c; int j = 0, sp;            // bound attempts\n                while (j++ <= m && (sp = (int)(c = ctl)) != 0)\n                    tryRelease(c, ws[sp & m], AC_UNIT);\n            }\n        }\n        return true;\n    }",
        "explanations_by_ours": [
            "the sum of the running workers",
            "the sum of the current thread",
            "the sum of the running workers."
        ],
        "corrections_by_ours": [
            "threadSum",
            "currentSum",
            "workersSum",
            "chevlRunning",
            "chevlCurrent",
            "runningSum",
            "sumSum",
            "chevlWorkers",
            "chevlThread",
            "chevlSum"
        ],
        "corrections_by_baseline": [
            "sum",
            "weightSum",
            "iSum",
            "tempPixelSum",
            "avgQp",
            "absDiagSum",
            "totalWeight",
            "tempSum",
            "sigmaVal",
            "sumLen"
        ]
    },
    {
        "original_word": "existing",
        "typo_word": "exiqtigg",
        "original_variable": "existingConnection",
        "typo_variable": "exiqtiggConnection",
        "original_code": "@Override\n\tpublic synchronized Connection getConnection() {\n\t\tif (availableConnections == null) {\n\t\t\tthrow new DbSqlException(\"Connection pool is not initialized\");\n\t\t}\n\t\tif (!availableConnections.isEmpty()) {\n\t\t\tint lastIndex = availableConnections.size() - 1;\n\t\t\tConnectionData existingConnection = availableConnections.get(lastIndex);\n\t\t\tavailableConnections.remove(lastIndex);\n\t\t\t\n\t\t\t// If conn on available list is closed (e.g., it timed out), then remove it from available list\n\t\t\t// and repeat the process of obtaining a conn. Also wake up threads that were waiting for a\n\t\t\t// conn because maxConnection limit was reached.\n\t\t\tlong now = System.currentTimeMillis();\n\t\t\tboolean isValid = isConnectionValid(existingConnection, now);\n\t\t\tif (!isValid) {\n\t\t\t\tif (log.isDebugEnabled()) {\n\t\t\t\t\tlog.debug(\"Pooled connection not valid, resetting\");\n\t\t\t\t}\n\n\t\t\t\tnotifyAll();\t\t\t\t // freed up a spot for anybody waiting\n\t\t\t\treturn getConnection();\n\t\t\t} else {\n\t\t\t\tif (log.isDebugEnabled()) {\n\t\t\t\t\tlog.debug(\"Returning valid pooled connection\");\n\t\t\t\t}\n\n\t\t\t\tbusyConnections.add(existingConnection);\n\t\t\t\texistingConnection.lastUsed = now;\n\t\t\t\treturn existingConnection.connection;\n\t\t\t}\n\t\t}\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"No more available connections\");\n\t\t}\n\n\t\t// no available connections\n\t\tif (((availableConnections.size() + busyConnections.size()) < maxConnections) && !connectionPending) {\n\t\t\tmakeBackgroundConnection();\n\t\t} else if (!waitIfBusy) {\n\t\t\tthrow new DbSqlException(\"Connection limit reached: \" + maxConnections);\n\t\t}\n\t\t// wait for either a new conn to be established (if you called makeBackgroundConnection) or for\n\t\t// an existing conn to be freed up.\n\t\ttry {\n\t\t\twait();\n\t\t} catch (InterruptedException ie) {\n\t\t\t// ignore\n\t\t}\n\t\t// someone freed up a conn, so try again.\n\t\treturn getConnection();\n\t}",
        "modified_code": "@Override\n\tpublic synchronized Connection getConnection() {\n\t\tif (availableConnections == null) {\n\t\t\tthrow new DbSqlException(\"Connection pool is not initialized\");\n\t\t}\n\t\tif (!availableConnections.isEmpty()) {\n\t\t\tint lastIndex = availableConnections.size() - 1;\n\t\t\tConnectionData exiqtiggConnection = availableConnections.get(lastIndex);\n\t\t\tavailableConnections.remove(lastIndex);\n\t\t\t\n\t\t\t// If conn on available list is closed (e.g., it timed out), then remove it from available list\n\t\t\t// and repeat the process of obtaining a conn. Also wake up threads that were waiting for a\n\t\t\t// conn because maxConnection limit was reached.\n\t\t\tlong now = System.currentTimeMillis();\n\t\t\tboolean isValid = isConnectionValid(exiqtiggConnection, now);\n\t\t\tif (!isValid) {\n\t\t\t\tif (log.isDebugEnabled()) {\n\t\t\t\t\tlog.debug(\"Pooled connection not valid, resetting\");\n\t\t\t\t}\n\n\t\t\t\tnotifyAll();\t\t\t\t // freed up a spot for anybody waiting\n\t\t\t\treturn getConnection();\n\t\t\t} else {\n\t\t\t\tif (log.isDebugEnabled()) {\n\t\t\t\t\tlog.debug(\"Returning valid pooled connection\");\n\t\t\t\t}\n\n\t\t\t\tbusyConnections.add(exiqtiggConnection);\n\t\t\t\texiqtiggConnection.lastUsed = now;\n\t\t\t\treturn exiqtiggConnection.connection;\n\t\t\t}\n\t\t}\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"No more available connections\");\n\t\t}\n\n\t\t// no available connections\n\t\tif (((availableConnections.size() + busyConnections.size()) < maxConnections) && !connectionPending) {\n\t\t\tmakeBackgroundConnection();\n\t\t} else if (!waitIfBusy) {\n\t\t\tthrow new DbSqlException(\"Connection limit reached: \" + maxConnections);\n\t\t}\n\t\t// wait for either a new conn to be established (if you called makeBackgroundConnection) or for\n\t\t// an existing conn to be freed up.\n\t\ttry {\n\t\t\twait();\n\t\t} catch (InterruptedException ie) {\n\t\t\t// ignore\n\t\t}\n\t\t// someone freed up a conn, so try again.\n\t\treturn getConnection();\n\t}",
        "explanations_by_ours": [
            "The connection to be returned.",
            "the pooled connection to be returned.",
            "the connection to be returned."
        ],
        "corrections_by_ours": [
            "connectionConnection",
            "exiqtiggPooled",
            "exiqtiggReturned",
            "pooledConnection",
            "returnedConnection",
            "exiqtiggConnection"
        ],
        "corrections_by_baseline": [
            "pConnection",
            "urlConnection",
            "writeORBConnection",
            "connection",
            "mConnection",
            "rawConnection",
            "httpConnection",
            "clusterConnection",
            "existingConnection",
            "allConnections"
        ]
    },
    {
        "original_word": "Server",
        "typo_word": "Ssrfer",
        "original_variable": "requestToServer",
        "typo_variable": "requestToSsrfer",
        "original_code": "private AppRequestToken issueAppRequestToken(\n            String serviceTicketBase64Param,\n            String usernameParam,\n            AuthEncryptedData authEncryptDataParam)\n    {\n        byte[] iv = AES256Local.generateRandom(AES256Local.IV_SIZE_BYTES);\n        byte[] seed = AES256Local.generateRandom(AES256Local.SEED_SIZE_BYTES);\n\n        byte[] sessionKey = UtilGlobal.decodeBase64(\n                authEncryptDataParam.getSessionKeyBase64());\n\n        byte[] dataToEncrypt = usernameParam.getBytes();\n\n        byte[] encryptedData = AES256Local.encrypt(\n                sessionKey,\n                dataToEncrypt,\n                iv);\n\n        byte[] encryptedDataHMac =\n                AES256Local.generateLocalHMACForReqToken(encryptedData, sessionKey, seed);\n\n        AppRequestToken requestToServer = new AppRequestToken();\n\n        requestToServer.setEncryptedDataBase64(UtilGlobal.encodeBase64(encryptedData));\n        requestToServer.setEncryptedDataHmacBase64(UtilGlobal.encodeBase64(encryptedDataHMac));\n        requestToServer.setIvBase64(UtilGlobal.encodeBase64(iv));\n        requestToServer.setSeedBase64(UtilGlobal.encodeBase64(seed));\n        requestToServer.setServiceTicket(serviceTicketBase64Param);\n\n        try {\n            return new AppRequestToken(\n                    this.postJson(requestToServer, WS.Path.User.Version1.userIssueToken()));\n        }\n        //\n        catch (JSONException jsonExcept) {\n            throw new FluidClientException(jsonExcept.getMessage(),\n                    jsonExcept, FluidClientException.ErrorCode.JSON_PARSING);\n        }\n    }",
        "modified_code": "private AppRequestToken issueAppRequestToken(\n            String serviceTicketBase64Param,\n            String usernameParam,\n            AuthEncryptedData authEncryptDataParam)\n    {\n        byte[] iv = AES256Local.generateRandom(AES256Local.IV_SIZE_BYTES);\n        byte[] seed = AES256Local.generateRandom(AES256Local.SEED_SIZE_BYTES);\n\n        byte[] sessionKey = UtilGlobal.decodeBase64(\n                authEncryptDataParam.getSessionKeyBase64());\n\n        byte[] dataToEncrypt = usernameParam.getBytes();\n\n        byte[] encryptedData = AES256Local.encrypt(\n                sessionKey,\n                dataToEncrypt,\n                iv);\n\n        byte[] encryptedDataHMac =\n                AES256Local.generateLocalHMACForReqToken(encryptedData, sessionKey, seed);\n\n        AppRequestToken requestToSsrfer = new AppRequestToken();\n\n        requestToSsrfer.setEncryptedDataBase64(UtilGlobal.encodeBase64(encryptedData));\n        requestToSsrfer.setEncryptedDataHmacBase64(UtilGlobal.encodeBase64(encryptedDataHMac));\n        requestToSsrfer.setIvBase64(UtilGlobal.encodeBase64(iv));\n        requestToSsrfer.setSeedBase64(UtilGlobal.encodeBase64(seed));\n        requestToSsrfer.setServiceTicket(serviceTicketBase64Param);\n\n        try {\n            return new AppRequestToken(\n                    this.postJson(requestToSsrfer, WS.Path.User.Version1.userIssueToken()));\n        }\n        //\n        catch (JSONException jsonExcept) {\n            throw new FluidClientException(jsonExcept.getMessage(),\n                    jsonExcept, FluidClientException.ErrorCode.JSON_PARSING);\n        }\n    }",
        "explanations_by_ours": [
            "The request to issue.",
            "The request token to issue.",
            "the request to issue."
        ],
        "corrections_by_ours": [
            "requestTokenSsrfer",
            "requestToIssue",
            "issueToSsrfer",
            "requestToToken",
            "tokenToSsrfer",
            "requestToRequest",
            "requestRequestSsrfer",
            "requestIssueSsrfer",
            "requestToSsrfer"
        ],
        "corrections_by_baseline": [
            "requestToServer",
            "requestFrom",
            "requestTo",
            "httpClientRequest",
            "httpRequest",
            "hrequest",
            "request",
            "yRequest",
            "signableRequest",
            "mreq"
        ]
    },
    {
        "original_word": "aligned",
        "typo_word": "alugndd",
        "original_variable": "alignedFrameLength",
        "typo_variable": "alugnddFrameLength",
        "original_code": "public static int scan(final UnsafeBuffer termBuffer, final int termOffset, final int limitOffset)\n    {\n        int offset = termOffset;\n\n        while (offset < limitOffset)\n        {\n            final int frameLength = frameLengthVolatile(termBuffer, offset);\n            if (frameLength <= 0)\n            {\n                break;\n            }\n\n            final int alignedFrameLength = align(frameLength, FRAME_ALIGNMENT);\n\n            if (isPaddingFrame(termBuffer, offset))\n            {\n                if (termOffset == offset)\n                {\n                    offset += alignedFrameLength;\n                }\n\n                break;\n            }\n\n            if (offset + alignedFrameLength > limitOffset)\n            {\n                break;\n            }\n\n            offset += alignedFrameLength;\n        }\n\n        return offset;\n    }",
        "modified_code": "public static int scan(final UnsafeBuffer termBuffer, final int termOffset, final int limitOffset)\n    {\n        int offset = termOffset;\n\n        while (offset < limitOffset)\n        {\n            final int frameLength = frameLengthVolatile(termBuffer, offset);\n            if (frameLength <= 0)\n            {\n                break;\n            }\n\n            final int alugnddFrameLength = align(frameLength, FRAME_ALIGNMENT);\n\n            if (isPaddingFrame(termBuffer, offset))\n            {\n                if (termOffset == offset)\n                {\n                    offset += alugnddFrameLength;\n                }\n\n                break;\n            }\n\n            if (offset + alugnddFrameLength > limitOffset)\n            {\n                break;\n            }\n\n            offset += alugnddFrameLength;\n        }\n\n        return offset;\n    }",
        "explanations_by_ours": [
            "the length of the padding and padding-padding frames",
            "the length of the padding or padding-padding frame",
            "the length of the padding or padding-padding frames"
        ],
        "corrections_by_ours": [
            "alugnddFramesLength",
            "lengthFrameLength",
            "paddingFrameLength",
            "alugnddFrameLength",
            "-FrameLength",
            "framesFrameLength",
            "frameFrameLength",
            "alugndd-Length",
            "alugnddLengthLength",
            "alugnddPaddingLength"
        ],
        "corrections_by_baseline": [
            "actualFrameLength",
            "frameLengthInt",
            "frameLength",
            "alignedFrameLength",
            "shortFrameLen",
            "lastFrameLength",
            "messageLength",
            "msgLength",
            "cefHeaderSize",
            "dlength"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "tdsult",
        "original_variable": "result",
        "typo_variable": "tdsult",
        "original_code": "private Collection<GrantedAuthority> getGrantedAuthorityCollection(Object value) {\n\t\tCollection<GrantedAuthority> result = new ArrayList<>();\n\t\taddGrantedAuthorityCollection(result, value);\n\t\treturn result;\n\t}",
        "modified_code": "private Collection<GrantedAuthority> getGrantedAuthorityCollection(Object value) {\n\t\tCollection<GrantedAuthority> tdsult = new ArrayList<>();\n\t\taddGrantedAuthorityCollection(tdsult, value);\n\t\treturn tdsult;\n\t}",
        "explanations_by_ours": [
            "the collection of granted authority objects",
            "a collection of granted authority objects",
            "the collection of granted authority objects."
        ],
        "corrections_by_ours": [
            "authority",
            "objects",
            "collection",
            "granted"
        ],
        "corrections_by_baseline": [
            "cdmstruct",
            "ddata",
            "rdata",
            "rds",
            "etdf",
            "dstruct",
            "tdf",
            "sdf",
            "dcat",
            "ldata"
        ]
    },
    {
        "original_word": "destination",
        "typo_word": "destinatipb",
        "original_variable": "destination",
        "typo_variable": "destinatipb",
        "original_code": "private boolean drawPoint(BoundingBox boundingBox, ProjectionTransform transform, FeatureTileCanvas canvas, Point point, FeatureStyle featureStyle) {\n\n        boolean drawn = false;\n\n        Point webMercatorPoint = transform.transform(point);\n        float x = TileBoundingBoxUtils.getXPixel(tileWidth, boundingBox,\n                webMercatorPoint.getX());\n        float y = TileBoundingBoxUtils.getYPixel(tileHeight, boundingBox,\n                webMercatorPoint.getY());\n\n        if (featureStyle != null && featureStyle.hasIcon()) {\n\n            IconRow iconRow = featureStyle.getIcon();\n            Bitmap icon = getIcon(iconRow);\n\n            int width = icon.getWidth();\n            int height = icon.getHeight();\n\n            if (x >= 0 - width && x <= tileWidth + width && y >= 0 - height && y <= tileHeight + height) {\n\n                float anchorU = (float) iconRow.getAnchorUOrDefault();\n                float anchorV = (float) iconRow.getAnchorVOrDefault();\n\n                float left = x - (anchorU * width);\n                float right = left + width;\n                float top = y - (anchorV * height);\n                float bottom = top + height;\n\n                RectF destination = new RectF(left, top, right, bottom);\n\n                Canvas iconCanvas = canvas.getIconCanvas();\n                iconCanvas.drawBitmap(icon, null, destination, pointPaint);\n                drawn = true;\n\n            }\n\n        } else if (pointIcon != null) {\n\n            float width = this.density * pointIcon.getWidth();\n            float height = this.density * pointIcon.getHeight();\n            if (x >= 0 - width && x <= tileWidth + width && y >= 0 - height && y <= tileHeight + height) {\n                Canvas iconCanvas = canvas.getIconCanvas();\n                float left = x - this.density * pointIcon.getXOffset();\n                float top = y - this.density * pointIcon.getYOffset();\n                RectF rect = new RectF(left, top, left + width, top + height);\n                iconCanvas.drawBitmap(pointIcon.getIcon(), null, rect, pointPaint);\n                drawn = true;\n            }\n\n        } else {\n\n            Float radius = null;\n            if (featureStyle != null) {\n                StyleRow styleRow = featureStyle.getStyle();\n                if (styleRow != null) {\n                    radius = this.density * (float) (styleRow.getWidthOrDefault() / 2.0f);\n                }\n            }\n            if (radius == null) {\n                radius = this.density * pointRadius;\n            }\n            if (x >= 0 - radius && x <= tileWidth + radius && y >= 0 - radius && y <= tileHeight + radius) {\n                Paint pointPaint = getPointPaint(featureStyle);\n                Canvas pointCanvas = canvas.getPointCanvas();\n                pointCanvas.drawCircle(x, y, radius, pointPaint);\n                drawn = true;\n            }\n\n        }\n\n        return drawn;\n    }",
        "modified_code": "private boolean drawPoint(BoundingBox boundingBox, ProjectionTransform transform, FeatureTileCanvas canvas, Point point, FeatureStyle featureStyle) {\n\n        boolean drawn = false;\n\n        Point webMercatorPoint = transform.transform(point);\n        float x = TileBoundingBoxUtils.getXPixel(tileWidth, boundingBox,\n                webMercatorPoint.getX());\n        float y = TileBoundingBoxUtils.getYPixel(tileHeight, boundingBox,\n                webMercatorPoint.getY());\n\n        if (featureStyle != null && featureStyle.hasIcon()) {\n\n            IconRow iconRow = featureStyle.getIcon();\n            Bitmap icon = getIcon(iconRow);\n\n            int width = icon.getWidth();\n            int height = icon.getHeight();\n\n            if (x >= 0 - width && x <= tileWidth + width && y >= 0 - height && y <= tileHeight + height) {\n\n                float anchorU = (float) iconRow.getAnchorUOrDefault();\n                float anchorV = (float) iconRow.getAnchorVOrDefault();\n\n                float left = x - (anchorU * width);\n                float right = left + width;\n                float top = y - (anchorV * height);\n                float bottom = top + height;\n\n                RectF destinatipb = new RectF(left, top, right, bottom);\n\n                Canvas iconCanvas = canvas.getIconCanvas();\n                iconCanvas.drawBitmap(icon, null, destinatipb, pointPaint);\n                drawn = true;\n\n            }\n\n        } else if (pointIcon != null) {\n\n            float width = this.density * pointIcon.getWidth();\n            float height = this.density * pointIcon.getHeight();\n            if (x >= 0 - width && x <= tileWidth + width && y >= 0 - height && y <= tileHeight + height) {\n                Canvas iconCanvas = canvas.getIconCanvas();\n                float left = x - this.density * pointIcon.getXOffset();\n                float top = y - this.density * pointIcon.getYOffset();\n                RectF rect = new RectF(left, top, left + width, top + height);\n                iconCanvas.drawBitmap(pointIcon.getIcon(), null, rect, pointPaint);\n                drawn = true;\n            }\n\n        } else {\n\n            Float radius = null;\n            if (featureStyle != null) {\n                StyleRow styleRow = featureStyle.getStyle();\n                if (styleRow != null) {\n                    radius = this.density * (float) (styleRow.getWidthOrDefault() / 2.0f);\n                }\n            }\n            if (radius == null) {\n                radius = this.density * pointRadius;\n            }\n            if (x >= 0 - radius && x <= tileWidth + radius && y >= 0 - radius && y <= tileHeight + radius) {\n                Paint pointPaint = getPointPaint(featureStyle);\n                Canvas pointCanvas = canvas.getPointCanvas();\n                pointCanvas.drawCircle(x, y, radius, pointPaint);\n                drawn = true;\n            }\n\n        }\n\n        return drawn;\n    }",
        "explanations_by_ours": [
            "destination rectangle",
            "destinatipb",
            "destination rectangle."
        ],
        "corrections_by_ours": [
            "destination",
            "rectangle"
        ],
        "corrections_by_baseline": [
            "ipb",
            "destinationVId",
            "destinationBlob",
            "iprt",
            "ipa",
            "btpv",
            "dmp",
            "vip",
            "wudp1",
            "ipos_p1"
        ]
    },
    {
        "original_word": "location",
        "typo_word": "losatkon",
        "original_variable": "location",
        "typo_variable": "losatkon",
        "original_code": "public String location() {\n\t\tString location = header(\"location\");\n\n\t\tif (location == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tif (location.startsWith(StringPool.SLASH)) {\n\t\t\tlocation = getHttpRequest().hostUrl() + location;\n\t\t}\n\n\t\treturn location;\n\t}",
        "modified_code": "public String losatkon() {\n\t\tString losatkon = header(\"location\");\n\n\t\tif (losatkon == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tif (losatkon.startsWith(StringPool.SLASH)) {\n\t\t\tlosatkon = getHttpRequest().hostUrl() + losatkon;\n\t\t}\n\n\t\treturn losatkon;\n\t}",
        "explanations_by_ours": [
            "the losatkon",
            "the losatkon value",
            "the losatkon header value"
        ],
        "corrections_by_ours": [
            "header",
            "value"
        ],
        "corrections_by_baseline": [
            "kxky",
            "ykr",
            "koma",
            "nk",
            "adz",
            "skf",
            "vDk",
            "kyero",
            "zis",
            "vDk0"
        ]
    },
    {
        "original_word": "param",
        "typo_word": "laran",
        "original_variable": "paramType",
        "typo_variable": "laranType",
        "original_code": "@SuppressWarnings(\"unchecked\")\n  private void mapFactsToProperties(NameValueReferableMap facts) {\n    for (Field field : getAnnotatedFields(Given.class, _pojoRule.getClass())) {\n      Given given = field.getAnnotation(Given.class);\n      try {\n        field.setAccessible(true);\n        if (NameValueReferable.class.isAssignableFrom(field.getType())) {\n          field.set(_pojoRule, facts.get(given.value()));\n        } else {\n          Object value = facts.getValue(given.value());\n          if (value != null) {\n            //set the field to the Fact that has the name of the @Given value\n            field.set(_pojoRule, value);\n          } else if (NameValueReferableMap.class.isAssignableFrom(field.getType())) {\n            //if the field is a FactMap then give it the FactMap\n            field.set(_pojoRule, facts);\n          } else if (Collection.class.isAssignableFrom(field.getType())) {\n            //set a Collection of Fact object values\n            Stream stream = facts.values().stream()\n                    .filter(fact -> { //filter on only facts that contain objects matching the generic type\n                      ParameterizedType paramType = (ParameterizedType)field.getGenericType();\n                      Class<?> genericType = (Class<?>)paramType.getActualTypeArguments()[0];\n                      return genericType.equals(((NameValueReferable) fact).getValue().getClass());\n                    })\n                    .map(fact -> {\n                      ParameterizedType paramType = (ParameterizedType)field.getGenericType();\n                      Class<?> genericType = (Class<?>)paramType.getActualTypeArguments()[0];\n                      return genericType.cast(((NameValueReferable)fact).getValue());\n                    });\n            if (List.class == field.getType()) {\n              //map List of Fact values to field\n              field.set(_pojoRule, stream.collect(Collectors.toList()));\n            } else if (Set.class == field.getType()) {\n              //map Set of Fact values to field\n              field.set(_pojoRule, stream.collect(Collectors.toSet()));\n            }\n          } else if (Map.class == field.getType()) {\n            //map Map of Fact values to field\n            Map map = (Map)facts.keySet().stream()\n                    .filter(key -> {\n                      ParameterizedType paramType = (ParameterizedType)field.getGenericType();\n                      Class<?> genericType = (Class<?>)paramType.getActualTypeArguments()[1];\n                      return genericType.equals(facts.getValue((String)key).getClass());\n                    })\n                    .collect(Collectors.toMap(key -> key, key -> facts.getValue((String)key)));\n            field.set(_pojoRule, map);\n          }\n        }\n      } catch (Exception ex) {\n        LOGGER.error(\"Unable to update field '\" + field.getName() + \"' in rule object '\"\n                + _pojoRule.getClass() + \"'\", ex);\n      }\n    }\n  }",
        "modified_code": "@SuppressWarnings(\"unchecked\")\n  private void mapFactsToProperties(NameValueReferableMap facts) {\n    for (Field field : getAnnotatedFields(Given.class, _pojoRule.getClass())) {\n      Given given = field.getAnnotation(Given.class);\n      try {\n        field.setAccessible(true);\n        if (NameValueReferable.class.isAssignableFrom(field.getType())) {\n          field.set(_pojoRule, facts.get(given.value()));\n        } else {\n          Object value = facts.getValue(given.value());\n          if (value != null) {\n            //set the field to the Fact that has the name of the @Given value\n            field.set(_pojoRule, value);\n          } else if (NameValueReferableMap.class.isAssignableFrom(field.getType())) {\n            //if the field is a FactMap then give it the FactMap\n            field.set(_pojoRule, facts);\n          } else if (Collection.class.isAssignableFrom(field.getType())) {\n            //set a Collection of Fact object values\n            Stream stream = facts.values().stream()\n                    .filter(fact -> { //filter on only facts that contain objects matching the generic type\n                      ParameterizedType laranType = (ParameterizedType)field.getGenericType();\n                      Class<?> genericType = (Class<?>)laranType.getActualTypeArguments()[0];\n                      return genericType.equals(((NameValueReferable) fact).getValue().getClass());\n                    })\n                    .map(fact -> {\n                      ParameterizedType laranType = (ParameterizedType)field.getGenericType();\n                      Class<?> genericType = (Class<?>)laranType.getActualTypeArguments()[0];\n                      return genericType.cast(((NameValueReferable)fact).getValue());\n                    });\n            if (List.class == field.getType()) {\n              //map List of Fact values to field\n              field.set(_pojoRule, stream.collect(Collectors.toList()));\n            } else if (Set.class == field.getType()) {\n              //map Set of Fact values to field\n              field.set(_pojoRule, stream.collect(Collectors.toSet()));\n            }\n          } else if (Map.class == field.getType()) {\n            //map Map of Fact values to field\n            Map map = (Map)facts.keySet().stream()\n                    .filter(key -> {\n                      ParameterizedType laranType = (ParameterizedType)field.getGenericType();\n                      Class<?> genericType = (Class<?>)laranType.getActualTypeArguments()[1];\n                      return genericType.equals(facts.getValue((String)key).getClass());\n                    })\n                    .collect(Collectors.toMap(key -> key, key -> facts.getValue((String)key)));\n            field.set(_pojoRule, map);\n          }\n        }\n      } catch (Exception ex) {\n        LOGGER.error(\"Unable to update field '\" + field.getName() + \"' in rule object '\"\n                + _pojoRule.getClass() + \"'\", ex);\n      }\n    }\n  }",
        "explanations_by_ours": [
            "the generic type of the field.",
            "the generic type of the field",
            "the generic type of the field that is annotated with @Given."
        ],
        "corrections_by_ours": [
            "laranAnnotated",
            "fieldranType",
            "lagivenType",
            "laranGiven",
            "lagenericType",
            "laranGeneric",
            "annotatedranType",
            "laannotatedType",
            "genericranType",
            "typeranType"
        ],
        "corrections_by_baseline": [
            "archType",
            "hiveType",
            "atype",
            "rType",
            "stsType",
            "localType",
            "cType",
            "containingType",
            "parquetType",
            "calleeType"
        ]
    },
    {
        "original_word": "target",
        "typo_word": "hargft",
        "original_variable": "target",
        "typo_variable": "hargft",
        "original_code": "public void valueChangeEvent(final AjaxBehaviorEvent event) {\r\n\r\n\t\ttry {\r\n\t\t\tFacesContext facesContext = FacesContext.getCurrentInstance();\r\n\t\t\tString tblName = parent.getWebFormClientId();\r\n\t\t\tUIComponent target = event.getComponent();\r\n\t\t\tboolean pass = validateCell(target);\r\n\t\t\tif (pass) {\r\n\t\t\t\t// to improve performance, re-validate current row only\r\n\t\t\t\t// page validation take times. will happen when change tab(page)\r\n\t\t\t\t// or\r\n\t\t\t\t// reload page.\r\n\t\t\t\tint[] rowcol = CellUtility.getRowColFromComponentAttributes(target);\r\n\t\t\t\tvalidateRowInCurrentPage(rowcol[0], true);\r\n\t\t\t\trefreshCachedCellsInCurrentPage(facesContext, tblName);\r\n\t\t\t}\r\n\t\t} catch (Exception ex) {\r\n\t\t\tLOG.log(Level.SEVERE, \"Validation error:\" + ex.getLocalizedMessage(), ex);\r\n\t\t}\r\n\t}",
        "modified_code": "public void valueChangeEvent(final AjaxBehaviorEvent event) {\r\n\r\n\t\ttry {\r\n\t\t\tFacesContext facesContext = FacesContext.getCurrentInstance();\r\n\t\t\tString tblName = parent.getWebFormClientId();\r\n\t\t\tUIComponent hargft = event.getComponent();\r\n\t\t\tboolean pass = validateCell(hargft);\r\n\t\t\tif (pass) {\r\n\t\t\t\t// to improve performance, re-validate current row only\r\n\t\t\t\t// page validation take times. will happen when change tab(page)\r\n\t\t\t\t// or\r\n\t\t\t\t// reload page.\r\n\t\t\t\tint[] rowcol = CellUtility.getRowColFromComponentAttributes(hargft);\r\n\t\t\t\tvalidateRowInCurrentPage(rowcol[0], true);\r\n\t\t\t\trefreshCachedCellsInCurrentPage(facesContext, tblName);\r\n\t\t\t}\r\n\t\t} catch (Exception ex) {\r\n\t\t\tLOG.log(Level.SEVERE, \"Validation error:\" + ex.getLocalizedMessage(), ex);\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "the hargft",
            "the hargft component",
            "the hargft component."
        ],
        "corrections_by_ours": [
            "component"
        ],
        "corrections_by_baseline": [
            "argp",
            "ft",
            "arg0",
            "arg1",
            "arg",
            "hwbwertPassed",
            "vertargs",
            "jshft",
            "daft",
            "rightArg"
        ]
    },
    {
        "original_word": "buffer",
        "typo_word": "biffef",
        "original_variable": "buffer",
        "typo_variable": "biffef",
        "original_code": "public static byte[] readContent(InputStream is) {\n        try {\n            ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            int read = 0;\n            byte[] buffer = new byte[8096];\n            while ((read = is.read(buffer)) > 0) {\n                baos.write(buffer, 0, read);\n            }\n            return baos.toByteArray();\n        } catch (IOException e) {\n            throw new UnexpectedException(e);\n        }\n    }",
        "modified_code": "public static byte[] readContent(InputStream is) {\n        try {\n            ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            int read = 0;\n            byte[] biffef = new byte[8096];\n            while ((read = is.read(biffef)) > 0) {\n                baos.write(biffef, 0, read);\n            }\n            return baos.toByteArray();\n        } catch (IOException e) {\n            throw new UnexpectedException(e);\n        }\n    }",
        "explanations_by_ours": [
            "the byte array to read into",
            "the byte array to write into",
            "the byte array to store the content in"
        ],
        "corrections_by_ours": [
            "byte",
            "write",
            "store",
            "content",
            "array",
            "read"
        ],
        "corrections_by_baseline": [
            "ndiff",
            "scalef",
            "bsf",
            "soff",
            "baf",
            "f1",
            "ff",
            "icf",
            "xfac",
            "fgf"
        ]
    },
    {
        "original_word": "pattern",
        "typo_word": "pattrdn",
        "original_variable": "pattern",
        "typo_variable": "pattrdn",
        "original_code": "public boolean checkRepeating(String str) {\r\n    String pattern = \"\\\\d+|\\\\d+-\\\\d+\";\r\n    if (str.matches(pattern)) {\r\n      return true;\r\n    }\r\n    return false;\r\n  }",
        "modified_code": "public boolean checkRepeating(String str) {\r\n    String pattrdn = \"\\\\d+|\\\\d+-\\\\d+\";\r\n    if (str.matches(pattrdn)) {\r\n      return true;\r\n    }\r\n    return false;\r\n  }",
        "explanations_by_ours": [
            "the repeating attribute name pattern",
            "the attribute name pattern",
            "the attribute name to check"
        ],
        "corrections_by_ours": [
            "patternrdn",
            "repeatingrdn",
            "namerdn",
            "attributerdn",
            "pattrepeating",
            "pattpattern",
            "pattattribute",
            "checkrdn",
            "pattname",
            "pattcheck"
        ],
        "corrections_by_baseline": [
            "ncidp",
            "pnc",
            "rtn",
            "rcidpe",
            "rsm",
            "idr",
            "pjpn",
            "pkt",
            "snn",
            "hrsi"
        ]
    },
    {
        "original_word": "found",
        "typo_word": "foknf",
        "original_variable": "found",
        "typo_variable": "foknf",
        "original_code": "public void bind( final FilterBinding handler )\n    {\n        final Method method = handler.getMethod();\n        final String path = handler.getPath();\n\n        logger.info( \"Using appId: {} and default version: {}\", appAcceptId, defaultVersion );\n        List<String> versions = handler.getVersions();\n        if ( versions == null || versions.isEmpty() )\n        {\n            versions = Collections.singletonList( defaultVersion );\n        }\n\n        for ( final String version : versions )\n        {\n            final Set<Method> methods = new HashSet<>();\n            if ( method == Method.ANY )\n            {\n                for ( final Method m : Method.values() )\n                {\n                    methods.add( m );\n                }\n            }\n            else\n            {\n                methods.add( method );\n            }\n\n            for ( final Method m : methods )\n            {\n                final BindingKey key = new BindingKey( m, version );\n\n                logger.info( \"ADD: {}, Pattern: {}, Filter: {}\\n\", key, path, handler );\n                List<PatternFilterBinding> allFilterBindings = this.filterBindings.get( key );\n                if ( allFilterBindings == null )\n                {\n                    allFilterBindings = new ArrayList<>();\n                    this.filterBindings.put( key, allFilterBindings );\n                }\n\n                boolean found = false;\n                for ( final PatternFilterBinding binding : allFilterBindings )\n                {\n                    if ( binding.getPattern()\n                                .pattern()\n                                .equals( handler.getPath() ) )\n                    {\n                        binding.addFilter( handler );\n                        found = true;\n                        break;\n                    }\n                }\n\n                if ( !found )\n                {\n                    final PatternFilterBinding binding = new PatternFilterBinding( handler.getPath(), handler );\n                    allFilterBindings.add( binding );\n                }\n            }\n        }\n    }",
        "modified_code": "public void bind( final FilterBinding handler )\n    {\n        final Method method = handler.getMethod();\n        final String path = handler.getPath();\n\n        logger.info( \"Using appId: {} and default version: {}\", appAcceptId, defaultVersion );\n        List<String> versions = handler.getVersions();\n        if ( versions == null || versions.isEmpty() )\n        {\n            versions = Collections.singletonList( defaultVersion );\n        }\n\n        for ( final String version : versions )\n        {\n            final Set<Method> methods = new HashSet<>();\n            if ( method == Method.ANY )\n            {\n                for ( final Method m : Method.values() )\n                {\n                    methods.add( m );\n                }\n            }\n            else\n            {\n                methods.add( method );\n            }\n\n            for ( final Method m : methods )\n            {\n                final BindingKey key = new BindingKey( m, version );\n\n                logger.info( \"ADD: {}, Pattern: {}, Filter: {}\\n\", key, path, handler );\n                List<PatternFilterBinding> allFilterBindings = this.filterBindings.get( key );\n                if ( allFilterBindings == null )\n                {\n                    allFilterBindings = new ArrayList<>();\n                    this.filterBindings.put( key, allFilterBindings );\n                }\n\n                boolean foknf = false;\n                for ( final PatternFilterBinding binding : allFilterBindings )\n                {\n                    if ( binding.getPattern()\n                                .pattern()\n                                .equals( handler.getPath() ) )\n                    {\n                        binding.addFilter( handler );\n                        foknf = true;\n                        break;\n                    }\n                }\n\n                if ( !foknf )\n                {\n                    final PatternFilterBinding binding = new PatternFilterBinding( handler.getPath(), handler );\n                    allFilterBindings.add( binding );\n                }\n            }\n        }\n    }",
        "explanations_by_ours": [
            "true if the given filter is a foknf filter",
            "true if the given filter is a regular expression, false otherwise",
            "true if the given filter is a foknf filter."
        ],
        "corrections_by_ours": [
            "false",
            "filter",
            "expression,",
            "otherwise",
            "true",
            "regular",
            "given"
        ],
        "corrections_by_baseline": [
            "nf",
            "pf",
            "nk",
            "kf",
            "hf",
            "skf",
            "pkinf",
            "acf",
            "icf",
            "ncf"
        ]
    },
    {
        "original_word": "char",
        "typo_word": "cmad",
        "original_variable": "charPos",
        "typo_variable": "cmadPos",
        "original_code": "private static String toUnsignedString(int i, int shift) {\n        char[] buf = new char[32];\n        int charPos = 32;\n        int radix = 1 << shift;\n        int mask = radix - 1;\n        do {\n            buf[--charPos] = digits[i & mask];\n            i >>>= shift;\n        } while (i != 0);\n\n        return new String(buf, charPos, (32 - charPos));\n    }",
        "modified_code": "private static String toUnsignedString(int i, int shift) {\n        char[] buf = new char[32];\n        int cmadPos = 32;\n        int radix = 1 << shift;\n        int mask = radix - 1;\n        do {\n            buf[--cmadPos] = digits[i & mask];\n            i >>>= shift;\n        } while (i != 0);\n\n        return new String(buf, cmadPos, (32 - cmadPos));\n    }",
        "explanations_by_ours": [
            "the number of digits to use",
            "the number of digits to use in the string",
            "the number of digits to use for the conversion"
        ],
        "corrections_by_ours": [
            "cmadConversion",
            "cnumberPos",
            "cmadDigits",
            "conversionmadPos",
            "digitsmadPos",
            "usemadPos",
            "stringmadPos",
            "numbermadPos",
            "cdigitsPos",
            "cusePos"
        ],
        "corrections_by_baseline": [
            "cPos",
            "semiPos",
            "curPos",
            "dbPos",
            "posb",
            "pos",
            "pointerPos",
            "startingPos",
            "arrayPos",
            "startPos"
        ]
    },
    {
        "original_word": "wait",
        "typo_word": "daot",
        "original_variable": "waitTime",
        "typo_variable": "daotTime",
        "original_code": "public void getReport(int reportId)\n      throws InterruptedException, ExecutionException, TimeoutException, IOException, StageException {\n    int waitTime = 1000;\n    Response response = null;\n    while (!stop) {\n      final AsyncInvoker asyncInvoker = getResource.request()\n          .header(WSSE_HEADER, OmnitureAuthUtil.getHeader(username.get(), sharedSecret.get()))\n          .async();\n\n      LOG.debug(\"Getting report using URL {} with report ID {}\", getResource.getUri().toURL().toString(), reportId);\n      final Future<Response> responseFuture = asyncInvoker.post(Entity.json(\"{ \\\"reportID\\\": \" + reportId + \" }\"));\n      response = responseFuture.get(responseTimeoutMillis, TimeUnit.MILLISECONDS);\n      String input = response.readEntity(String.class);\n\n      ObjectMapper mapper = new ObjectMapper();\n      JsonNode root = mapper.readTree(input);\n\n      // If the report has an error field, it means the report has not finished generating\n      if (!root.has(\"error\")) {\n        boolean accepted = entityQueue.offer(input, responseTimeoutMillis, TimeUnit.MILLISECONDS);\n        if (!accepted) {\n          LOG.warn(\"Response buffer full, dropped record.\");\n        }\n        break;\n      } else {\n        // Exponential backoff while making subsequent Report.Get requests\n        if (root.get(\"error\").textValue().equals(\"report_not_ready\")) {\n          waitTime *= 2;\n          LOG.info(\"Report not available. Sleeping for {} seconds\", waitTime / 1000);\n          Thread.sleep(waitTime);\n        } else {\n          throw new StageException(Errors.OMNITURE_02,\n              root.get(\"error\").get(\"error_description\").asText());\n        }\n      }\n    }\n    response.close();\n  }",
        "modified_code": "public void getReport(int reportId)\n      throws InterruptedException, ExecutionException, TimeoutException, IOException, StageException {\n    int daotTime = 1000;\n    Response response = null;\n    while (!stop) {\n      final AsyncInvoker asyncInvoker = getResource.request()\n          .header(WSSE_HEADER, OmnitureAuthUtil.getHeader(username.get(), sharedSecret.get()))\n          .async();\n\n      LOG.debug(\"Getting report using URL {} with report ID {}\", getResource.getUri().toURL().toString(), reportId);\n      final Future<Response> responseFuture = asyncInvoker.post(Entity.json(\"{ \\\"reportID\\\": \" + reportId + \" }\"));\n      response = responseFuture.get(responseTimeoutMillis, TimeUnit.MILLISECONDS);\n      String input = response.readEntity(String.class);\n\n      ObjectMapper mapper = new ObjectMapper();\n      JsonNode root = mapper.readTree(input);\n\n      // If the report has an error field, it means the report has not finished generating\n      if (!root.has(\"error\")) {\n        boolean accepted = entityQueue.offer(input, responseTimeoutMillis, TimeUnit.MILLISECONDS);\n        if (!accepted) {\n          LOG.warn(\"Response buffer full, dropped record.\");\n        }\n        break;\n      } else {\n        // Exponential backoff while making subsequent Report.Get requests\n        if (root.get(\"error\").textValue().equals(\"report_not_ready\")) {\n          daotTime *= 2;\n          LOG.info(\"Report not available. Sleeping for {} seconds\", daotTime / 1000);\n          Thread.sleep(daotTime);\n        } else {\n          throw new StageException(Errors.OMNITURE_02,\n              root.get(\"error\").get(\"error_description\").asText());\n        }\n      }\n    }\n    response.close();\n  }",
        "explanations_by_ours": [
            "the number of seconds to sleep",
            "the number of seconds to sleep for",
            "the number of seconds to sleep for the report."
        ],
        "corrections_by_ours": [
            "reportTime",
            "daotNumber",
            "daotSleep",
            "secondsTime",
            "sleepTime",
            "numberTime",
            "daotSeconds",
            "daotReport",
            "daotTime"
        ],
        "corrections_by_baseline": [
            "myTime",
            "time",
            "Time",
            "startNanoTime",
            "time1D",
            "nomTime",
            "parkTime",
            "startTimeMs",
            "time2D",
            "base_time"
        ]
    },
    {
        "original_word": "return",
        "typo_word": "rrtuen",
        "original_variable": "returnVal",
        "typo_variable": "rrtuenVal",
        "original_code": "@Override\n\tpublic JSONObject toJsonObject() throws JSONException {\n\t\tJSONObject returnVal = super.toJsonObject();\n\n\t\t//Available...\n\t\tif(this.getAvailableMultiChoices() != null) {\n\t\t\tList<String> availChoices = this.getAvailableMultiChoices();\n\n\t\t\treturnVal.put(JSONMapping.AVAILABLE_MULTI_CHOICES,\n\t\t\t\t\tnew JSONArray(availChoices.toArray()));\n\n\t\t\treturnVal.put(JSONMapping.AVAILABLE_CHOICES,\n\t\t\t\t\tnew JSONArray(availChoices.toArray()));\n\n\t\t\treturnVal.put(\n\t\t\t\t\tJSONMapping.AVAILABLE_CHOICES_COMBINED,\n\t\t\t\t\tthis.combineStringArrayWith(\n\t\t\t\t\t\t\tavailChoices,\n\t\t\t\t\t\t\tUtilGlobal.PIPE));\n\t\t}\n\n\t\t//Selected...\n\t\tif(this.getSelectedMultiChoices() != null) {\n\t\t\tList<String> selectChoices = this.getSelectedMultiChoices();\n\n\t\t\treturnVal.put(JSONMapping.SELECTED_MULTI_CHOICES,\n\t\t\t\t\tnew JSONArray(selectChoices.toArray()));\n\n\t\t\treturnVal.put(JSONMapping.SELECTED_CHOICES,\n\t\t\t\t\tnew JSONArray(selectChoices.toArray()));\n\n\t\t\treturnVal.put(\n\t\t\t\t\tJSONMapping.SELECTED_CHOICES_COMBINED,\n\t\t\t\t\tthis.combineStringArrayWith(\n\t\t\t\t\t\t\tselectChoices,\n\t\t\t\t\t\t\tUtilGlobal.PIPE));\n\t\t}\n\n\t\treturn returnVal;\n\t}",
        "modified_code": "@Override\n\tpublic JSONObject toJsonObject() throws JSONException {\n\t\tJSONObject rrtuenVal = super.toJsonObject();\n\n\t\t//Available...\n\t\tif(this.getAvailableMultiChoices() != null) {\n\t\t\tList<String> availChoices = this.getAvailableMultiChoices();\n\n\t\t\trrtuenVal.put(JSONMapping.AVAILABLE_MULTI_CHOICES,\n\t\t\t\t\tnew JSONArray(availChoices.toArray()));\n\n\t\t\trrtuenVal.put(JSONMapping.AVAILABLE_CHOICES,\n\t\t\t\t\tnew JSONArray(availChoices.toArray()));\n\n\t\t\trrtuenVal.put(\n\t\t\t\t\tJSONMapping.AVAILABLE_CHOICES_COMBINED,\n\t\t\t\t\tthis.combineStringArrayWith(\n\t\t\t\t\t\t\tavailChoices,\n\t\t\t\t\t\t\tUtilGlobal.PIPE));\n\t\t}\n\n\t\t//Selected...\n\t\tif(this.getSelectedMultiChoices() != null) {\n\t\t\tList<String> selectChoices = this.getSelectedMultiChoices();\n\n\t\t\trrtuenVal.put(JSONMapping.SELECTED_MULTI_CHOICES,\n\t\t\t\t\tnew JSONArray(selectChoices.toArray()));\n\n\t\t\trrtuenVal.put(JSONMapping.SELECTED_CHOICES,\n\t\t\t\t\tnew JSONArray(selectChoices.toArray()));\n\n\t\t\trrtuenVal.put(\n\t\t\t\t\tJSONMapping.SELECTED_CHOICES_COMBINED,\n\t\t\t\t\tthis.combineStringArrayWith(\n\t\t\t\t\t\t\tselectChoices,\n\t\t\t\t\t\t\tUtilGlobal.PIPE));\n\t\t}\n\n\t\treturn rrtuenVal;\n\t}",
        "explanations_by_ours": [
            "the rrtuen val",
            "the rrtuen val.",
            "The rrtuen val."
        ],
        "corrections_by_ours": [
            "valVal",
            "rrtuenRrtuen",
            "rrtuenVal"
        ],
        "corrections_by_baseline": [
            "rv",
            "utflen",
            "rtnArr",
            "rLPS",
            "r6",
            "rp",
            "r4",
            "rval",
            "etaVal",
            "ilenhd"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "tesupt",
        "original_variable": "result",
        "typo_variable": "tesupt",
        "original_code": "static ObservableList<String> createListWithNothingSelectedMarker(ObservableList<String> source) {\n\t\tfinal ObservableList<String> result = FXCollections.observableArrayList();\n\t\tresult.add(NOTHING_SELECTED_MARKER);\n\t\tresult.addAll(source);\n\n\t\t// for sure there are better solutions for this but it's sufficient for our demo\n\t\tsource.addListener((ListChangeListener<String>) c -> {\n\t\t\tresult.clear();\n\t\t\tresult.add(NOTHING_SELECTED_MARKER);\n\t\t\tresult.addAll(source);\n\t\t});\n\t\treturn result;\n\t}",
        "modified_code": "static ObservableList<String> createListWithNothingSelectedMarker(ObservableList<String> source) {\n\t\tfinal ObservableList<String> tesupt = FXCollections.observableArrayList();\n\t\ttesupt.add(NOTHING_SELECTED_MARKER);\n\t\ttesupt.addAll(source);\n\n\t\t// for sure there are better solutions for this but it's sufficient for our demo\n\t\tsource.addListener((ListChangeListener<String>) c -> {\n\t\t\ttesupt.clear();\n\t\t\ttesupt.add(NOTHING_SELECTED_MARKER);\n\t\t\ttesupt.addAll(source);\n\t\t});\n\t\treturn tesupt;\n\t}",
        "explanations_by_ours": [
            "the list to create",
            "the list to create the list with",
            "the list to create the list from"
        ],
        "corrections_by_ours": [
            "list",
            "create"
        ],
        "corrections_by_baseline": [
            "bytes",
            "octet",
            "nbytes",
            "outBuff",
            "tbuff",
            "ctxt",
            "try_bytes",
            "bytesToSend",
            "utf8Bytes",
            "xt"
        ]
    },
    {
        "original_word": "pass",
        "typo_word": "paqa",
        "original_variable": "allpass",
        "typo_variable": "allpaqa",
        "original_code": "public final boolean validateCurrentPage() {\r\n\t\tboolean allpass = true;\r\n\r\n\t\tint top = parent.getCurrent().getCurrentTopRow();\r\n\t\tfor (int irow = 0; irow < parent.getBodyRows().size(); irow++) {\r\n\t\t\tif (!validateRowInCurrentPage(irow + top, false)) {\r\n\t\t\t\tallpass = false;\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn allpass;\r\n\t}",
        "modified_code": "public final boolean validateCurrentPage() {\r\n\t\tboolean allpaqa = true;\r\n\r\n\t\tint top = parent.getCurrent().getCurrentTopRow();\r\n\t\tfor (int irow = 0; irow < parent.getBodyRows().size(); irow++) {\r\n\t\t\tif (!validateRowInCurrentPage(irow + top, false)) {\r\n\t\t\t\tallpaqa = false;\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn allpaqa;\r\n\t}",
        "explanations_by_ours": [
            "true if all rows are valid, false otherwise",
            "true if all rows are valid",
            "true if all rows are valid, false otherwise."
        ],
        "corrections_by_ours": [
            "valid,",
            "valid",
            "false",
            "rows",
            "otherwise",
            "true"
        ],
        "corrections_by_baseline": [
            "qa",
            "cqa",
            "allpass",
            "noprogress",
            "all",
            "srcc",
            "a4p",
            "pib",
            "pjpn",
            "deny"
        ]
    },
    {
        "original_word": "clazz",
        "typo_word": "flasz",
        "original_variable": "clazz",
        "typo_variable": "flasz",
        "original_code": "public static void parse(Object target, Properties arguments) {\n        Class clazz;\n        if (target instanceof Class) {\n            clazz = (Class) target;\n        } else {\n            clazz = target.getClass();\n        }\n        for (Field field : clazz.getDeclaredFields()) {\n            processField(target, field, arguments);\n        }\n        try {\n            BeanInfo info = Introspector.getBeanInfo(clazz);\n            for (PropertyDescriptor pd : info.getPropertyDescriptors()) {\n                processProperty(target, pd, arguments);\n            }\n        } catch (IntrospectionException e) {\n            // If its not a JavaBean we ignore it\n        }\n    }",
        "modified_code": "public static void parse(Object target, Properties arguments) {\n        Class flasz;\n        if (target instanceof Class) {\n            flasz = (Class) target;\n        } else {\n            flasz = target.getClass();\n        }\n        for (Field field : flasz.getDeclaredFields()) {\n            processField(target, field, arguments);\n        }\n        try {\n            BeanInfo info = Introspector.getBeanInfo(flasz);\n            for (PropertyDescriptor pd : info.getPropertyDescriptors()) {\n                processProperty(target, pd, arguments);\n            }\n        } catch (IntrospectionException e) {\n            // If its not a JavaBean we ignore it\n        }\n    }",
        "explanations_by_ours": [
            "the class to parse",
            "the target class",
            "the flasz"
        ],
        "corrections_by_ours": [
            "class",
            "parse",
            "target"
        ],
        "corrections_by_baseline": [
            "wz",
            "zs",
            "zis",
            "CZ",
            "cz",
            "dz",
            "wv_z",
            "fl",
            "adz",
            "uvz"
        ]
    },
    {
        "original_word": "Copy",
        "typo_word": "Ckoy",
        "original_variable": "queryCopy",
        "typo_variable": "queryCkoy",
        "original_code": "public Request browseMirrorAsync(@NonNull Query query, @NonNull CompletionHandler completionHandler) {\n        if (!mirrored) {\n            throw new IllegalStateException(\"Mirroring not activated on this index\");\n        }\n        final Query queryCopy = new Query(query);\n        return getClient().new AsyncTaskRequest(completionHandler, getClient().localSearchExecutorService) {\n            @NonNull\n            @Override\n            protected JSONObject run() throws AlgoliaException {\n                return _browseMirror(queryCopy);\n            }\n        }.start();\n    }",
        "modified_code": "public Request browseMirrorAsync(@NonNull Query query, @NonNull CompletionHandler completionHandler) {\n        if (!mirrored) {\n            throw new IllegalStateException(\"Mirroring not activated on this index\");\n        }\n        final Query queryCkoy = new Query(query);\n        return getClient().new AsyncTaskRequest(completionHandler, getClient().localSearchExecutorService) {\n            @NonNull\n            @Override\n            protected JSONObject run() throws AlgoliaException {\n                return _browseMirror(queryCkoy);\n            }\n        }.start();\n    }",
        "explanations_by_ours": [
            "a com.google.cloud.tasks.api.tasks",
            "the query to browse",
            "a com.google.cloud.tasks.api.Query"
        ],
        "corrections_by_ours": [
            "queryCom",
            "queryCloud",
            "queryQuery",
            "queryGoogle",
            "queryBrowse",
            "apiCkoy",
            "comCkoy",
            "cloudCkoy",
            "googleCkoy",
            "browseCkoy"
        ],
        "corrections_by_baseline": [
            "cqQuery",
            "dynamicQuery",
            "wQuery",
            "qk",
            "luceneQuery",
            "query",
            "staticQuery",
            "manualQuery",
            "queryArray",
            "queryBuilder"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rssklt",
        "original_variable": "result",
        "typo_variable": "rssklt",
        "original_code": "protected Archiver getArchiver( String archiverName )\n        throws NoSuchArchiverException\n    {\n        Archiver result = archiverManager.getArchiver( archiverName );\n        result.setDuplicateBehavior( Archiver.DUPLICATES_FAIL ); // Just in case\n        return result;\n    }",
        "modified_code": "protected Archiver getArchiver( String archiverName )\n        throws NoSuchArchiverException\n    {\n        Archiver rssklt = archiverManager.getArchiver( archiverName );\n        rssklt.setDuplicateBehavior( Archiver.DUPLICATES_FAIL ); // Just in case\n        return rssklt;\n    }",
        "explanations_by_ours": [
            "the Archiver to be returned",
            "the Archiver to return",
            "the Archiver"
        ],
        "corrections_by_ours": [
            "return",
            "archiver",
            "returned"
        ],
        "corrections_by_baseline": [
            "rssi",
            "newsort",
            "sfb",
            "durl",
            "fdsurl",
            "sss1",
            "drss",
            "gdss",
            "appFeedBacksummaryJSON",
            "btpv"
        ]
    },
    {
        "original_word": "Type",
        "typo_word": "Tyls",
        "original_variable": "mimeType",
        "typo_variable": "mimeTyls",
        "original_code": "protected void copyReaders(Catalog newCatalog) {\n    // Have to copy the readers in the right order...convert hash to arr\n    Vector mapArr = new Vector(readerMap.size());\n\n    // Pad the mapArr out to the right length\n    for (int count = 0; count < readerMap.size(); count++) {\n      mapArr.add(null);\n    }\n\n    Enumeration enumt = readerMap.keys();\n    while (enumt.hasMoreElements()) {\n      String mimeType = (String) enumt.nextElement();\n      Integer pos = (Integer) readerMap.get(mimeType);\n      mapArr.set(pos.intValue(), mimeType);\n    }\n\n    for (int count = 0; count < mapArr.size(); count++) {\n      String mimeType = (String) mapArr.get(count);\n      Integer pos = (Integer) readerMap.get(mimeType);\n      newCatalog.addReader(mimeType,\n\t\t\t   (CatalogReader)\n\t\t\t   readerArr.get(pos.intValue()));\n    }\n  }",
        "modified_code": "protected void copyReaders(Catalog newCatalog) {\n    // Have to copy the readers in the right order...convert hash to arr\n    Vector mapArr = new Vector(readerMap.size());\n\n    // Pad the mapArr out to the right length\n    for (int count = 0; count < readerMap.size(); count++) {\n      mapArr.add(null);\n    }\n\n    Enumeration enumt = readerMap.keys();\n    while (enumt.hasMoreElements()) {\n      String mimeTyls = (String) enumt.nextElement();\n      Integer pos = (Integer) readerMap.get(mimeTyls);\n      mapArr.set(pos.intValue(), mimeTyls);\n    }\n\n    for (int count = 0; count < mapArr.size(); count++) {\n      String mimeTyls = (String) mapArr.get(count);\n      Integer pos = (Integer) readerMap.get(mimeTyls);\n      newCatalog.addReader(mimeTyls,\n\t\t\t   (CatalogReader)\n\t\t\t   readerArr.get(pos.intValue()));\n    }\n  }",
        "explanations_by_ours": [
            "the mime mimetype",
            "the mime type",
            "the mime mime type"
        ],
        "corrections_by_ours": [
            "mimetypeTyls",
            "mimeType",
            "typeTyls",
            "mimeMimetype",
            "mimeMime",
            "mimeTyls"
        ],
        "corrections_by_baseline": [
            "mimeTypes",
            "contentTypes",
            "mimeTypesMap",
            "mime",
            "mimeType",
            "filenameTypes",
            "assetFonts",
            "contentTypeString",
            "zipEntries",
            "htmlCharset"
        ]
    },
    {
        "original_word": "product",
        "typo_word": "proekct",
        "original_variable": "product",
        "typo_variable": "proekct",
        "original_code": "int getXWeight(){\r\n\t\tint product = 1;\r\n\t\tCell c = this.getHead();\r\n\t\twhile( c != null && c.getLexeme() != null){\r\n\t\t\tproduct *= c.getLexeme().getLength();\r\n\t\t\tc = c.getNext();\r\n\t\t}\r\n\t\treturn product;\r\n\t}",
        "modified_code": "int getXWeight(){\r\n\t\tint proekct = 1;\r\n\t\tCell c = this.getHead();\r\n\t\twhile( c != null && c.getLexeme() != null){\r\n\t\t\tproekct *= c.getLexeme().getLength();\r\n\t\t\tc = c.getNext();\r\n\t\t}\r\n\t\treturn proekct;\r\n\t}",
        "explanations_by_ours": [
            "the proekct",
            "X weight",
            "."
        ],
        "corrections_by_ours": [
            "weight",
            "x"
        ],
        "corrections_by_baseline": [
            "projCT",
            "proj",
            "propsOrg",
            "projType",
            "props",
            "projbb",
            "projargs",
            "projName",
            "proClass",
            "cla"
        ]
    },
    {
        "original_word": "interceptors",
        "typo_word": "imtercfptors",
        "original_variable": "interceptors",
        "typo_variable": "imtercfptors",
        "original_code": "public void handle(Execution execution) {\n\t\tList<Task> tasks = execution.getEngine().task().createTask(model, execution);\n\t\texecution.addTasks(tasks);\n\t\t/**\n\t\t * \u4ece\u670d\u52a1\u4e0a\u4e0b\u6587\u4e2d\u67e5\u627e\u4efb\u52a1\u62e6\u622a\u5668\u5217\u8868\uff0c\u4f9d\u6b21\u5bf9task\u96c6\u5408\u8fdb\u884c\u62e6\u622a\u5904\u7406\n\t\t */\n\t\tList<SnakerInterceptor> interceptors = ServiceContext.getContext().findList(SnakerInterceptor.class);\n\t\ttry {\n\t\t\tfor(SnakerInterceptor interceptor : interceptors) {\n\t\t\t\tinterceptor.intercept(execution);\n\t\t\t}\n\t\t} catch(Exception e) {\n\t\t\tlog.error(\"\u62e6\u622a\u5668\u6267\u884c\u5931\u8d25=\" + e.getMessage());\n\t\t\tthrow new SnakerException(e);\n\t\t}\n\t}",
        "modified_code": "public void handle(Execution execution) {\n\t\tList<Task> tasks = execution.getEngine().task().createTask(model, execution);\n\t\texecution.addTasks(tasks);\n\t\t/**\n\t\t * \u4ece\u670d\u52a1\u4e0a\u4e0b\u6587\u4e2d\u67e5\u627e\u4efb\u52a1\u62e6\u622a\u5668\u5217\u8868\uff0c\u4f9d\u6b21\u5bf9task\u96c6\u5408\u8fdb\u884c\u62e6\u622a\u5904\u7406\n\t\t */\n\t\tList<SnakerInterceptor> imtercfptors = ServiceContext.getContext().findList(SnakerInterceptor.class);\n\t\ttry {\n\t\t\tfor(SnakerInterceptor interceptor : imtercfptors) {\n\t\t\t\tinterceptor.intercept(execution);\n\t\t\t}\n\t\t} catch(Exception e) {\n\t\t\tlog.error(\"\u62e6\u622a\u5668\u6267\u884c\u5931\u8d25=\" + e.getMessage());\n\t\t\tthrow new SnakerException(e);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "SnakerInterceptor",
            "SnakerInterceptor",
            "SnakerInterceptors"
        ],
        "corrections_by_ours": [
            "interceptors",
            "interceptor",
            "snaker"
        ],
        "corrections_by_baseline": [
            "imps",
            "externs",
            "implementations",
            "injectors",
            "actors",
            "facets",
            "nmaps",
            "orFilters",
            "interceptors",
            "processors"
        ]
    },
    {
        "original_word": "param",
        "typo_word": "psdam",
        "original_variable": "paramValue",
        "typo_variable": "psdamValue",
        "original_code": "protected boolean rememberMeRequested(HttpServletRequest request, String parameter) {\n\t\tif (alwaysRemember) {\n\t\t\treturn true;\n\t\t}\n\n\t\tString paramValue = request.getParameter(parameter);\n\n\t\tif (paramValue != null) {\n\t\t\tif (paramValue.equalsIgnoreCase(\"true\") || paramValue.equalsIgnoreCase(\"on\")\n\t\t\t\t\t|| paramValue.equalsIgnoreCase(\"yes\") || paramValue.equals(\"1\")) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Did not send remember-me cookie (principal did not set parameter '\"\n\t\t\t\t\t+ parameter + \"')\");\n\t\t}\n\n\t\treturn false;\n\t}",
        "modified_code": "protected boolean rememberMeRequested(HttpServletRequest request, String parameter) {\n\t\tif (alwaysRemember) {\n\t\t\treturn true;\n\t\t}\n\n\t\tString psdamValue = request.getParameter(parameter);\n\n\t\tif (psdamValue != null) {\n\t\t\tif (psdamValue.equalsIgnoreCase(\"true\") || psdamValue.equalsIgnoreCase(\"on\")\n\t\t\t\t\t|| psdamValue.equalsIgnoreCase(\"yes\") || psdamValue.equals(\"1\")) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Did not send remember-me cookie (principal did not set parameter '\"\n\t\t\t\t\t+ parameter + \"')\");\n\t\t}\n\n\t\treturn false;\n\t}",
        "explanations_by_ours": [
            "the psdam value",
            "the psdam value",
            "the value of the parameter"
        ],
        "corrections_by_ours": [
            "parameterValue",
            "psdamParameter",
            "valueValue",
            "psdamPsdam",
            "psdamValue"
        ],
        "corrections_by_baseline": [
            "energiebedarfValue",
            "dam",
            "mValue",
            "dcval",
            "dvalue",
            "lam",
            "vali",
            "etaVal",
            "sval",
            "gamma"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vakke",
        "original_variable": "value",
        "typo_variable": "vakke",
        "original_code": "@Override\n\tprotected final void onSerializableProperty(String propertyName, final PropertyDescriptor propertyDescriptor) {\n\t\tfinal Object value;\n\n\t\tif (propertyDescriptor == null) {\n\t\t\t// metadata - classname\n\t\t\tvalue = source.getClass().getName();\n\t\t} else {\n\t\t\tvalue = readProperty(source, propertyDescriptor);\n\n\t\t\tif ((value == null) && jsonContext.isExcludeNulls()) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// change name for properties\n\n\t\t\tpropertyName = typeData.resolveJsonName(propertyName);\n\t\t}\n\n\t\tonSerializableProperty(\n\t\t\t\tpropertyName,\n\t\t\t\tpropertyDescriptor == null ? null : propertyDescriptor.getType(),\n\t\t\t\tvalue);\n\t}",
        "modified_code": "@Override\n\tprotected final void onSerializableProperty(String propertyName, final PropertyDescriptor propertyDescriptor) {\n\t\tfinal Object vakke;\n\n\t\tif (propertyDescriptor == null) {\n\t\t\t// metadata - classname\n\t\t\tvakke = source.getClass().getName();\n\t\t} else {\n\t\t\tvakke = readProperty(source, propertyDescriptor);\n\n\t\t\tif ((vakke == null) && jsonContext.isExcludeNulls()) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// change name for properties\n\n\t\t\tpropertyName = typeData.resolveJsonName(propertyName);\n\t\t}\n\n\t\tonSerializableProperty(\n\t\t\t\tpropertyName,\n\t\t\t\tpropertyDescriptor == null ? null : propertyDescriptor.getType(),\n\t\t\t\tvakke);\n\t}",
        "explanations_by_ours": [
            "the vakke",
            "the value of the property"
        ],
        "corrections_by_ours": [
            "value",
            "property"
        ],
        "corrections_by_baseline": [
            "kv",
            "ak",
            "vDk",
            "koma",
            "vk0",
            "kxky",
            "vz",
            "ykr",
            "vDk0",
            "skf"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "soung",
        "original_variable": "count",
        "typo_variable": "soung",
        "original_code": "public int copyMax(final OutputStream out, final int maxBytes) throws IOException {\n\t\tint count = 0;\n\t\twhile (true) {\n\t\t\tbyte b = readByte();\n\t\t\tif (isBoundary(b)) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tout.write(b);\n\t\t\tcount++;\n\t\t\tif (count == maxBytes) {\n\t\t\t\treturn count;\n\t\t\t}\n\t\t}\n\t\treturn count;\n\t}",
        "modified_code": "public int copyMax(final OutputStream out, final int maxBytes) throws IOException {\n\t\tint soung = 0;\n\t\twhile (true) {\n\t\t\tbyte b = readByte();\n\t\t\tif (isBoundary(b)) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tout.write(b);\n\t\t\tsoung++;\n\t\t\tif (soung == maxBytes) {\n\t\t\t\treturn soung;\n\t\t\t}\n\t\t}\n\t\treturn soung;\n\t}",
        "explanations_by_ours": [
            "the number of bytes to copy",
            "the number of bytes to copy.",
            "the number of bytes that have been soung"
        ],
        "corrections_by_ours": [
            "copy",
            "bytes",
            "number"
        ],
        "corrections_by_baseline": [
            "ou",
            "enu",
            "coun",
            "lngain",
            "ihour",
            "dou",
            "NG",
            "ang",
            "S51",
            "boustr"
        ]
    },
    {
        "original_word": "selected",
        "typo_word": "seledter",
        "original_variable": "selectedMechanism",
        "typo_variable": "seledterMechanism",
        "original_code": "public String authenticate(String username, String resource,\n            CallbackHandler cbh) throws XMPPException {\n        // Locate the SASLMechanism to use\n        String selectedMechanism = null;\n        for (String mechanism : mechanismsPreferences) {\n            if (implementedMechanisms.containsKey(mechanism)\n                    && serverMechanisms.contains(mechanism)) {\n                selectedMechanism = mechanism;\n                break;\n            }\n        }\n        if (selectedMechanism != null) {\n            // A SASL mechanism was found. Authenticate using the selected\n            // mechanism and then\n            // proceed to bind a resource\n            try {\n                Class<? extends SASLMechanism> mechanismClass = implementedMechanisms\n                        .get(selectedMechanism);\n                Constructor<? extends SASLMechanism> constructor = mechanismClass\n                        .getConstructor(SASLAuthentication.class);\n                currentMechanism = constructor.newInstance(this);\n                // Trigger SASL authentication with the selected mechanism. We\n                // use\n                // connection.getHost() since GSAPI requires the FQDN of the\n                // server, which\n                // may not match the XMPP domain.\n                currentMechanism.authenticate(username, connection.getHost(),\n                        cbh);\n\n                // Wait until SASL negotiation finishes\n                synchronized (this) {\n                    if (!saslNegotiated && !saslFailed) {\n                        try {\n                            wait(30000);\n                        } catch (InterruptedException e) {\n                            // Ignore\n                        }\n                    }\n                }\n\n                if (saslFailed) {\n                    // SASL authentication failed and the server may have closed\n                    // the connection\n                    // so throw an exception\n                    if (errorCondition != null) {\n                        throw new XMPPException(\"SASL authentication \"\n                                + selectedMechanism + \" failed: \"\n                                + errorCondition);\n                    } else {\n                        throw new XMPPException(\n                                \"SASL authentication failed using mechanism \"\n                                        + selectedMechanism);\n                    }\n                }\n\n                if (saslNegotiated) {\n                    // Bind a resource for this connection and\n                    return bindResourceAndEstablishSession(resource);\n                } else {\n                    // SASL authentication failed\n                }\n            } catch (XMPPException e) {\n                throw e;\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        } else {\n            throw new XMPPException(\n                    \"SASL Authentication failed. No known authentication mechanisims.\");\n        }\n        throw new XMPPException(\"SASL authentication failed\");\n    }",
        "modified_code": "public String authenticate(String username, String resource,\n            CallbackHandler cbh) throws XMPPException {\n        // Locate the SASLMechanism to use\n        String seledterMechanism = null;\n        for (String mechanism : mechanismsPreferences) {\n            if (implementedMechanisms.containsKey(mechanism)\n                    && serverMechanisms.contains(mechanism)) {\n                seledterMechanism = mechanism;\n                break;\n            }\n        }\n        if (seledterMechanism != null) {\n            // A SASL mechanism was found. Authenticate using the selected\n            // mechanism and then\n            // proceed to bind a resource\n            try {\n                Class<? extends SASLMechanism> mechanismClass = implementedMechanisms\n                        .get(seledterMechanism);\n                Constructor<? extends SASLMechanism> constructor = mechanismClass\n                        .getConstructor(SASLAuthentication.class);\n                currentMechanism = constructor.newInstance(this);\n                // Trigger SASL authentication with the selected mechanism. We\n                // use\n                // connection.getHost() since GSAPI requires the FQDN of the\n                // server, which\n                // may not match the XMPP domain.\n                currentMechanism.authenticate(username, connection.getHost(),\n                        cbh);\n\n                // Wait until SASL negotiation finishes\n                synchronized (this) {\n                    if (!saslNegotiated && !saslFailed) {\n                        try {\n                            wait(30000);\n                        } catch (InterruptedException e) {\n                            // Ignore\n                        }\n                    }\n                }\n\n                if (saslFailed) {\n                    // SASL authentication failed and the server may have closed\n                    // the connection\n                    // so throw an exception\n                    if (errorCondition != null) {\n                        throw new XMPPException(\"SASL authentication \"\n                                + seledterMechanism + \" failed: \"\n                                + errorCondition);\n                    } else {\n                        throw new XMPPException(\n                                \"SASL authentication failed using mechanism \"\n                                        + seledterMechanism);\n                    }\n                }\n\n                if (saslNegotiated) {\n                    // Bind a resource for this connection and\n                    return bindResourceAndEstablishSession(resource);\n                } else {\n                    // SASL authentication failed\n                }\n            } catch (XMPPException e) {\n                throw e;\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        } else {\n            throw new XMPPException(\n                    \"SASL Authentication failed. No known authentication mechanisims.\");\n        }\n        throw new XMPPException(\"SASL authentication failed\");\n    }",
        "explanations_by_ours": [
            "the name of the SASL mechanism to authenticate with.",
            "the name of the SASL mechanism to use.",
            "the name of the SASL mechanism to use for authentication."
        ],
        "corrections_by_ours": [
            "seledterAuthenticate",
            "seledterSasl",
            "seledterAuthentication",
            "authenticateMechanism",
            "authenticationMechanism",
            "useMechanism",
            "nameMechanism",
            "saslMechanism",
            "mechanismMechanism",
            "seledterUse"
        ],
        "corrections_by_baseline": [
            "selectedMechanism",
            "adaptor",
            "strategy",
            "compressionAlgorithm",
            "algorithm",
            "sieve",
            "filterer",
            "simpleFilterProvider",
            "mechanisms",
            "valueContainerAlgorithm"
        ]
    },
    {
        "original_word": "Boot",
        "typo_word": "Bkpt",
        "original_variable": "twoPhaseBootStrapCapable",
        "typo_variable": "twoPhaseBkptStrapCapable",
        "original_code": "private static void addPuService(final DeploymentPhaseContext phaseContext, final ArrayList<PersistenceUnitMetadataHolder> puList,\n                                     final boolean startEarly, final Platform platform)\n        throws DeploymentUnitProcessingException {\n\n        if (puList.size() > 0) {\n            final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();\n            final Module module = deploymentUnit.getAttachment(Attachments.MODULE);\n            final EEModuleDescription eeModuleDescription = deploymentUnit.getAttachment(org.jboss.as.ee.component.Attachments.EE_MODULE_DESCRIPTION);\n            final ServiceTarget serviceTarget = phaseContext.getServiceTarget();\n            final ModuleClassLoader classLoader = module.getClassLoader();\n\n            for (PersistenceUnitMetadataHolder holder : puList) {\n                setAnnotationIndexes(holder, deploymentUnit);\n                for (PersistenceUnitMetadata pu : holder.getPersistenceUnits()) {\n\n                    // only start the persistence unit if JPA_CONTAINER_MANAGED is true\n                    String jpaContainerManaged = pu.getProperties().getProperty(Configuration.JPA_CONTAINER_MANAGED);\n                    boolean deployPU = (jpaContainerManaged == null? true : Boolean.parseBoolean(jpaContainerManaged));\n\n                    if (deployPU) {\n                        final PersistenceProviderDeploymentHolder persistenceProviderDeploymentHolder = getPersistenceProviderDeploymentHolder(deploymentUnit);\n                        final PersistenceProvider provider = lookupProvider(pu, persistenceProviderDeploymentHolder, deploymentUnit);\n                        final PersistenceProviderAdaptor adaptor = getPersistenceProviderAdaptor(pu, persistenceProviderDeploymentHolder, deploymentUnit, provider, platform);\n                        final boolean twoPhaseBootStrapCapable = (adaptor instanceof TwoPhaseBootstrapCapable) && Configuration.allowTwoPhaseBootstrap(pu);\n\n                        if (startEarly) {\n                            if (twoPhaseBootStrapCapable) {\n                                deployPersistenceUnitPhaseOne(deploymentUnit, eeModuleDescription, serviceTarget, classLoader, pu, adaptor);\n                            }\n                            else if (false == Configuration.needClassFileTransformer(pu)) {\n                                // will start later when startEarly == false\n                                ROOT_LOGGER.tracef(\"persistence unit %s in deployment %s is configured to not need class transformer to be set, no class rewriting will be allowed\",\n                                    pu.getPersistenceUnitName(), deploymentUnit.getName());\n                            }\n                            else {\n                                // we need class file transformer to work, don't allow cdi bean manager to be access since that\n                                // could cause application classes to be loaded (workaround by setting jboss.as.jpa.classtransformer to false).  WFLY-1463\n                                final boolean allowCdiBeanManagerAccess = false;\n                                deployPersistenceUnit(deploymentUnit, eeModuleDescription, serviceTarget, classLoader, pu, provider, adaptor, allowCdiBeanManagerAccess);\n                            }\n                        }\n                        else { // !startEarly\n                            if (twoPhaseBootStrapCapable) {\n                                deployPersistenceUnitPhaseTwo(deploymentUnit, eeModuleDescription, serviceTarget, classLoader, pu, provider, adaptor);\n                            } else if (false == Configuration.needClassFileTransformer(pu)) {\n                                final boolean allowCdiBeanManagerAccess = true;\n                                // PUs that have Configuration.JPA_CONTAINER_CLASS_TRANSFORMER = false will start during INSTALL phase\n                                deployPersistenceUnit(deploymentUnit, eeModuleDescription, serviceTarget, classLoader, pu, provider, adaptor, allowCdiBeanManagerAccess);\n                            }\n                        }\n\n                    }\n                    else {\n                        ROOT_LOGGER.tracef(\"persistence unit %s in deployment %s is not container managed (%s is set to false)\",\n                                pu.getPersistenceUnitName(), deploymentUnit.getName(), Configuration.JPA_CONTAINER_MANAGED);\n                    }\n                }\n            }\n        }\n    }",
        "modified_code": "private static void addPuService(final DeploymentPhaseContext phaseContext, final ArrayList<PersistenceUnitMetadataHolder> puList,\n                                     final boolean startEarly, final Platform platform)\n        throws DeploymentUnitProcessingException {\n\n        if (puList.size() > 0) {\n            final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();\n            final Module module = deploymentUnit.getAttachment(Attachments.MODULE);\n            final EEModuleDescription eeModuleDescription = deploymentUnit.getAttachment(org.jboss.as.ee.component.Attachments.EE_MODULE_DESCRIPTION);\n            final ServiceTarget serviceTarget = phaseContext.getServiceTarget();\n            final ModuleClassLoader classLoader = module.getClassLoader();\n\n            for (PersistenceUnitMetadataHolder holder : puList) {\n                setAnnotationIndexes(holder, deploymentUnit);\n                for (PersistenceUnitMetadata pu : holder.getPersistenceUnits()) {\n\n                    // only start the persistence unit if JPA_CONTAINER_MANAGED is true\n                    String jpaContainerManaged = pu.getProperties().getProperty(Configuration.JPA_CONTAINER_MANAGED);\n                    boolean deployPU = (jpaContainerManaged == null? true : Boolean.parseBoolean(jpaContainerManaged));\n\n                    if (deployPU) {\n                        final PersistenceProviderDeploymentHolder persistenceProviderDeploymentHolder = getPersistenceProviderDeploymentHolder(deploymentUnit);\n                        final PersistenceProvider provider = lookupProvider(pu, persistenceProviderDeploymentHolder, deploymentUnit);\n                        final PersistenceProviderAdaptor adaptor = getPersistenceProviderAdaptor(pu, persistenceProviderDeploymentHolder, deploymentUnit, provider, platform);\n                        final boolean twoPhaseBkptStrapCapable = (adaptor instanceof TwoPhaseBootstrapCapable) && Configuration.allowTwoPhaseBootstrap(pu);\n\n                        if (startEarly) {\n                            if (twoPhaseBkptStrapCapable) {\n                                deployPersistenceUnitPhaseOne(deploymentUnit, eeModuleDescription, serviceTarget, classLoader, pu, adaptor);\n                            }\n                            else if (false == Configuration.needClassFileTransformer(pu)) {\n                                // will start later when startEarly == false\n                                ROOT_LOGGER.tracef(\"persistence unit %s in deployment %s is configured to not need class transformer to be set, no class rewriting will be allowed\",\n                                    pu.getPersistenceUnitName(), deploymentUnit.getName());\n                            }\n                            else {\n                                // we need class file transformer to work, don't allow cdi bean manager to be access since that\n                                // could cause application classes to be loaded (workaround by setting jboss.as.jpa.classtransformer to false).  WFLY-1463\n                                final boolean allowCdiBeanManagerAccess = false;\n                                deployPersistenceUnit(deploymentUnit, eeModuleDescription, serviceTarget, classLoader, pu, provider, adaptor, allowCdiBeanManagerAccess);\n                            }\n                        }\n                        else { // !startEarly\n                            if (twoPhaseBkptStrapCapable) {\n                                deployPersistenceUnitPhaseTwo(deploymentUnit, eeModuleDescription, serviceTarget, classLoader, pu, provider, adaptor);\n                            } else if (false == Configuration.needClassFileTransformer(pu)) {\n                                final boolean allowCdiBeanManagerAccess = true;\n                                // PUs that have Configuration.JPA_CONTAINER_CLASS_TRANSFORMER = false will start during INSTALL phase\n                                deployPersistenceUnit(deploymentUnit, eeModuleDescription, serviceTarget, classLoader, pu, provider, adaptor, allowCdiBeanManagerAccess);\n                            }\n                        }\n\n                    }\n                    else {\n                        ROOT_LOGGER.tracef(\"persistence unit %s in deployment %s is not container managed (%s is set to false)\",\n                                pu.getPersistenceUnitName(), deploymentUnit.getName(), Configuration.JPA_CONTAINER_MANAGED);\n                    }\n                }\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the two phase bkpt strap capable",
            "the two phase bootstrap capable",
            "the two phase bkpt strap capsable"
        ],
        "corrections_by_ours": [
            "twoPhaseBkptStrapAble",
            "twoPhaseBkptBootstrapCapable",
            "twoPhaseBkptStrapCaps",
            "twoCapableBkptStrapCapable",
            "twoPhaseBkptStrapPhase",
            "twoPhaseCapsStrapCapable",
            "twoPhaseBootstrapStrapCapable",
            "strapPhaseBkptStrapCapable",
            "twoCapsBkptStrapCapable",
            "twoAbleBkptStrapCapable"
        ],
        "corrections_by_baseline": [
            "twoPhaseBootStrapCapable",
            "twoPhaseBootstrapCapable",
            "finalWiringMode",
            "adaptiveRefPicMarkingModeFlag",
            "oldSpannable",
            "decrFontAction",
            "offP5",
            "automagicMadvocConfigurator",
            "automagicPetiteConfigurator",
            "offP3"
        ]
    },
    {
        "original_word": "buff",
        "typo_word": "hjff",
        "original_variable": "sbuff",
        "typo_variable": "shjff",
        "original_code": "public String getNameAndAttributes() {\n    StringBuilder sbuff = new StringBuilder();\n    sbuff.append(\"Group \");\n    sbuff.append(getShortName());\n    sbuff.append(\"\\n\");\n    for (Attribute att : attributes.getAttributes()) {\n      sbuff.append(\"  \").append(getShortName()).append(\":\");\n      sbuff.append(att.toString());\n      sbuff.append(\";\");\n      sbuff.append(\"\\n\");\n    }\n    return sbuff.toString();\n  }",
        "modified_code": "public String getNameAndAttributes() {\n    StringBuilder shjff = new StringBuilder();\n    shjff.append(\"Group \");\n    shjff.append(getShortName());\n    shjff.append(\"\\n\");\n    for (Attribute att : attributes.getAttributes()) {\n      shjff.append(\"  \").append(getShortName()).append(\":\");\n      shjff.append(att.toString());\n      shjff.append(\";\");\n      shjff.append(\"\\n\");\n    }\n    return shjff.toString();\n  }",
        "explanations_by_ours": [
            "a string to be appended to the output.",
            "a string to be appended to the output",
            "a string to be appended to the result."
        ],
        "corrections_by_ours": [
            "string",
            "output",
            "appended",
            "result"
        ],
        "corrections_by_baseline": [
            "sh",
            "jshft",
            "bsf",
            "ff",
            "shsrc",
            "csh",
            "sh1",
            "soff",
            "bsrc",
            "boff"
        ]
    },
    {
        "original_word": "Level",
        "typo_word": "Levri",
        "original_variable": "currentLevel",
        "typo_variable": "currentLevri",
        "original_code": "public E poll()\n    {\n        /*log.fine(\"public E poll(): called\");*/\n\n        // This is used to keep track of the level of the list that is found to have data in it.\n        int currentLevel = 0;\n\n        while (true)\n        {\n            // This is used to locate the marker head of a list that contains data.\n            Marker<E> h = null;\n\n            // This is used to locate the potential data node of a list with data in it. Another thread may already\n            // have taken this data.\n            Node<E> first = null;\n\n            // Second data item, may also be tail marker, first data item of next list, or null at end of last list.\n            Node<E> second = null;\n\n            // Loop down any empty lists at the front of the queue until a list with data in it is found.\n            for (; currentLevel < n; currentLevel++)\n            {\n                h = markers[currentLevel];\n                first = h.getNext();\n                second = first.getNext();\n\n                // Check if the list at the current level is not empty and should be tried for data.\n                if (!h.isEmpty(markers[currentLevel + 1]))\n                {\n                    break;\n                }\n\n                // Check if the current level is empty and is the last level, in which case return null.\n                else if (currentLevel == (n - 1))\n                {\n                    // log.info(\"returning null from level loop.\");\n\n                    return null;\n                }\n\n                // Else if the current level is empty loop to the next one to see if it has data.\n            }\n\n            /*log.fine(\"current poll level = \" + currentLevel);*/\n\n            // This is used to locate the tail of the list that has been found with data in it.\n            Node<E> t = markers[currentLevel + 1].getTail();\n\n            // Check that the first data item has not yet been taken. Another thread may already have taken it,\n            // in which case performing a relatively expensive cas on the head will fail. If first is still intact\n            // then second will be intact too.\n            if (first == h.getNext())\n            {\n                // Check if the queue has become empty.\n                if (h.isEmpty(markers[currentLevel + 1]))\n                {\n                    // Another thread has managed to take data from the queue, leaving it empty.\n\n                    // First won't be null. It may point to tail though...\n                    if (first == null)\n                    {\n                        // Don't want to return here, want to try the next list. The list loop has a return null\n                        // once it gets to the end to take care of that.\n                        // log.info(\"returning null as first == null\");\n\n                        return null;\n                    }\n                    else\n                    {\n                        // Not sure yet why castail here? Does this repair a broken tail ref left after the last item\n                        // was taken?\n                        markers[currentLevel + 1].casTail(t, first);\n                    }\n                }\n\n                // The queue contains data, so try to move its head marker reference from the first data item, onto the\n                // second item (which may be data, or the tail marker). If this succeeds, then the first data node\n                // has been atomically extracted from the head of the queue.\n                else if (h.casNext(first, second))\n                {\n                    // h Does not refer to an empty queue, so first must be a data node.\n                    DataNode<E> firstDataNode = ((DataNode<E>) first);\n                    E item = firstDataNode.getItem();\n\n                    // Even though the empty test did not indicate that the list was empty, it may contain null\n                    // data items, because the remove method doesn't extract nodes on a remove. These need to be skipped\n                    // over. Could they be removed here?\n                    if (item != null)\n                    {\n                        firstDataNode.setItem(null);\n\n                        /*log.fine(\"returing item = \" + item);*/\n\n                        // Decrement the queue size count.\n                        count.decrementAndGet();\n\n                        return item;\n                    }\n\n                    // else skip over deleted item, continue trying at this level. Go back an retry starting from same\n                    // level. List at this level may now be empty, or may get the next item from it.\n\n                    // else skip over marker element. just make markers return null for item to skip them? No, because\n                    // need to advance currentLevel and get head and tail markers for the next level. but then, next\n                    // level advance will occur when this level is retried and found to be empty won't it?\n                }\n            }\n        }\n    }",
        "modified_code": "public E poll()\n    {\n        /*log.fine(\"public E poll(): called\");*/\n\n        // This is used to keep track of the level of the list that is found to have data in it.\n        int currentLevri = 0;\n\n        while (true)\n        {\n            // This is used to locate the marker head of a list that contains data.\n            Marker<E> h = null;\n\n            // This is used to locate the potential data node of a list with data in it. Another thread may already\n            // have taken this data.\n            Node<E> first = null;\n\n            // Second data item, may also be tail marker, first data item of next list, or null at end of last list.\n            Node<E> second = null;\n\n            // Loop down any empty lists at the front of the queue until a list with data in it is found.\n            for (; currentLevri < n; currentLevri++)\n            {\n                h = markers[currentLevri];\n                first = h.getNext();\n                second = first.getNext();\n\n                // Check if the list at the current level is not empty and should be tried for data.\n                if (!h.isEmpty(markers[currentLevri + 1]))\n                {\n                    break;\n                }\n\n                // Check if the current level is empty and is the last level, in which case return null.\n                else if (currentLevri == (n - 1))\n                {\n                    // log.info(\"returning null from level loop.\");\n\n                    return null;\n                }\n\n                // Else if the current level is empty loop to the next one to see if it has data.\n            }\n\n            /*log.fine(\"current poll level = \" + currentLevel);*/\n\n            // This is used to locate the tail of the list that has been found with data in it.\n            Node<E> t = markers[currentLevri + 1].getTail();\n\n            // Check that the first data item has not yet been taken. Another thread may already have taken it,\n            // in which case performing a relatively expensive cas on the head will fail. If first is still intact\n            // then second will be intact too.\n            if (first == h.getNext())\n            {\n                // Check if the queue has become empty.\n                if (h.isEmpty(markers[currentLevri + 1]))\n                {\n                    // Another thread has managed to take data from the queue, leaving it empty.\n\n                    // First won't be null. It may point to tail though...\n                    if (first == null)\n                    {\n                        // Don't want to return here, want to try the next list. The list loop has a return null\n                        // once it gets to the end to take care of that.\n                        // log.info(\"returning null as first == null\");\n\n                        return null;\n                    }\n                    else\n                    {\n                        // Not sure yet why castail here? Does this repair a broken tail ref left after the last item\n                        // was taken?\n                        markers[currentLevri + 1].casTail(t, first);\n                    }\n                }\n\n                // The queue contains data, so try to move its head marker reference from the first data item, onto the\n                // second item (which may be data, or the tail marker). If this succeeds, then the first data node\n                // has been atomically extracted from the head of the queue.\n                else if (h.casNext(first, second))\n                {\n                    // h Does not refer to an empty queue, so first must be a data node.\n                    DataNode<E> firstDataNode = ((DataNode<E>) first);\n                    E item = firstDataNode.getItem();\n\n                    // Even though the empty test did not indicate that the list was empty, it may contain null\n                    // data items, because the remove method doesn't extract nodes on a remove. These need to be skipped\n                    // over. Could they be removed here?\n                    if (item != null)\n                    {\n                        firstDataNode.setItem(null);\n\n                        /*log.fine(\"returing item = \" + item);*/\n\n                        // Decrement the queue size count.\n                        count.decrementAndGet();\n\n                        return item;\n                    }\n\n                    // else skip over deleted item, continue trying at this level. Go back an retry starting from same\n                    // level. List at this level may now be empty, or may get the next item from it.\n\n                    // else skip over marker element. just make markers return null for item to skip them? No, because\n                    // need to advance currentLevel and get head and tail markers for the next level. but then, next\n                    // level advance will occur when this level is retried and found to be empty won't it?\n                }\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the current poll level.",
            "the current level of the queue.",
            "the current level of the list to be searched."
        ],
        "corrections_by_ours": [
            "currentLevel",
            "queueLevri",
            "currentSearched",
            "currentList",
            "listLevri",
            "levelLevri",
            "currentCurrent",
            "searchedLevri",
            "pollLevri",
            "currentQueue"
        ],
        "corrections_by_baseline": [
            "currentLevel",
            "currentNdx",
            "elevIndex",
            "levA",
            "currentIsolationLevel",
            "elev",
            "curTraj",
            "currentCount",
            "currentVert",
            "prevCurrent"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "fesulh",
        "original_variable": "result",
        "typo_variable": "fesulh",
        "original_code": "public String prettyPrint()\n    {\n        String result = \"\";\n\n        for (int j = 0; j < 3; j++)\n        {\n            result += new String(board[j]) + \"\\n\";\n        }\n\n        result = result.replace('E', ' ');\n\n        return result;\n    }",
        "modified_code": "public String prettyPrint()\n    {\n        String fesulh = \"\";\n\n        for (int j = 0; j < 3; j++)\n        {\n            fesulh += new String(board[j]) + \"\\n\";\n        }\n\n        fesulh = fesulh.replace('E', ' ');\n\n        return fesulh;\n    }",
        "explanations_by_ours": [
            "pretty print board",
            "board to be pretty printed",
            "board to be pretty printed."
        ],
        "corrections_by_ours": [
            "pretty",
            "printed",
            "board",
            "print"
        ],
        "corrections_by_baseline": [
            "hf",
            "emf",
            "fhi",
            "fh",
            "hb",
            "pihalf",
            "fourn",
            "mefd",
            "f_huff",
            "bsf"
        ]
    },
    {
        "original_word": "records",
        "typo_word": "decorxs",
        "original_variable": "records",
        "typo_variable": "decorxs",
        "original_code": "@SuppressWarnings(\"Duplicates\")\n    public static void main(String[] args) {\n        // init logging\n        PropertyConfigurator.configure(\n                Is24CsvWritingExample.class.getResource(PACKAGE + \"/log4j.properties\"));\n\n        // create some CSV records\n        List<Is24CsvRecord> records = new ArrayList<>();\n        records.add(createHausKaufRecord());\n        records.add(createHausKaufRecord());\n        records.add(createWohnungMieteRecord());\n        records.add(createWohnungMieteRecord());\n\n        // write CSV records into a java.io.File\n        try {\n            write(records, File.createTempFile(\"output-\", \".csv\"));\n        } catch (IOException ex) {\n            LOGGER.error(\"Can't create temporary file!\");\n            LOGGER.error(\"> \" + ex.getLocalizedMessage(), ex);\n            System.exit(1);\n        }\n\n        // write CSV records into a java.io.OutputStream\n        write(records, new NullOutputStream());\n\n        // write CSV records into a java.io.Writer\n        write(records, new NullWriter());\n\n        // write CSV records into a string and send it to the console\n        writeToConsole(records);\n    }",
        "modified_code": "@SuppressWarnings(\"Duplicates\")\n    public static void main(String[] args) {\n        // init logging\n        PropertyConfigurator.configure(\n                Is24CsvWritingExample.class.getResource(PACKAGE + \"/log4j.properties\"));\n\n        // create some CSV records\n        List<Is24CsvRecord> decorxs = new ArrayList<>();\n        decorxs.add(createHausKaufRecord());\n        decorxs.add(createHausKaufRecord());\n        decorxs.add(createWohnungMieteRecord());\n        decorxs.add(createWohnungMieteRecord());\n\n        // write CSV records into a java.io.File\n        try {\n            write(decorxs, File.createTempFile(\"output-\", \".csv\"));\n        } catch (IOException ex) {\n            LOGGER.error(\"Can't create temporary file!\");\n            LOGGER.error(\"> \" + ex.getLocalizedMessage(), ex);\n            System.exit(1);\n        }\n\n        // write CSV records into a java.io.OutputStream\n        write(decorxs, new NullOutputStream());\n\n        // write CSV records into a java.io.Writer\n        write(decorxs, new NullWriter());\n\n        // write CSV records into a string and send it to the console\n        writeToConsole(decorxs);\n    }",
        "explanations_by_ours": [
            "List of Is24CsvRecord objects",
            "List of Is24CsvRecord objects.",
            "List of Is24CsvRecord"
        ],
        "corrections_by_ours": [
            "record",
            "csv",
            "objects",
            "list",
            "24"
        ],
        "corrections_by_baseline": [
            "decoration",
            "colors",
            "markers",
            "overlays",
            "decoratorLen",
            "icons",
            "charts",
            "curColors",
            "browsers",
            "shapes"
        ]
    },
    {
        "original_word": "return",
        "typo_word": "rdyurn",
        "original_variable": "returnBuffer",
        "typo_variable": "rdyurnBuffer",
        "original_code": "protected String getMetaDataForDecimalAs(\n\t\t\tString metaDataPrefixParam,\n\t\t\tdouble minParam,\n\t\t\tdouble maxParam,\n\t\t\tdouble stepFactorParam,\n\t\t\tString prefixParam\n\t) {\n\t\tStringBuffer returnBuffer = new StringBuffer();\n\n\t\tif (metaDataPrefixParam != null && !metaDataPrefixParam.isEmpty()) {\n\t\t\treturnBuffer.append(metaDataPrefixParam);\n\t\t}\n\n\t\t//Min...\n\t\treturnBuffer.append(FieldMetaData.Decimal.UNDERSCORE);\n\t\treturnBuffer.append(FieldMetaData.Decimal.MIN);\n\t\treturnBuffer.append(FieldMetaData.Decimal.SQ_OPEN);\n\t\treturnBuffer.append(minParam);\n\t\treturnBuffer.append(FieldMetaData.Decimal.SQ_CLOSE);\n\t\treturnBuffer.append(FieldMetaData.Decimal.UNDERSCORE);\n\n\t\t//Max...\n\t\treturnBuffer.append(FieldMetaData.Decimal.MAX);\n\t\treturnBuffer.append(FieldMetaData.Decimal.SQ_OPEN);\n\t\treturnBuffer.append(maxParam);\n\t\treturnBuffer.append(FieldMetaData.Decimal.SQ_CLOSE);\n\t\treturnBuffer.append(FieldMetaData.Decimal.UNDERSCORE);\n\n\t\t//Step Factor...\n\t\treturnBuffer.append(FieldMetaData.Decimal.STEP_FACTOR);\n\t\treturnBuffer.append(FieldMetaData.Decimal.SQ_OPEN);\n\t\treturnBuffer.append(stepFactorParam);\n\t\treturnBuffer.append(FieldMetaData.Decimal.SQ_CLOSE);\n\t\treturnBuffer.append(FieldMetaData.Decimal.UNDERSCORE);\n\n\t\t//Prefix\n\t\tString prefix = (prefixParam == null) ? \"\" : prefixParam;\n\n\t\treturnBuffer.append(FieldMetaData.Decimal.PREFIX);\n\t\treturnBuffer.append(FieldMetaData.Decimal.SQ_OPEN);\n\t\treturnBuffer.append(prefix);\n\t\treturnBuffer.append(FieldMetaData.Decimal.SQ_CLOSE);\n\n\t\treturn returnBuffer.toString();\n\t}",
        "modified_code": "protected String getMetaDataForDecimalAs(\n\t\t\tString metaDataPrefixParam,\n\t\t\tdouble minParam,\n\t\t\tdouble maxParam,\n\t\t\tdouble stepFactorParam,\n\t\t\tString prefixParam\n\t) {\n\t\tStringBuffer rdyurnBuffer = new StringBuffer();\n\n\t\tif (metaDataPrefixParam != null && !metaDataPrefixParam.isEmpty()) {\n\t\t\trdyurnBuffer.append(metaDataPrefixParam);\n\t\t}\n\n\t\t//Min...\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.UNDERSCORE);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.MIN);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.SQ_OPEN);\n\t\trdyurnBuffer.append(minParam);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.SQ_CLOSE);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.UNDERSCORE);\n\n\t\t//Max...\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.MAX);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.SQ_OPEN);\n\t\trdyurnBuffer.append(maxParam);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.SQ_CLOSE);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.UNDERSCORE);\n\n\t\t//Step Factor...\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.STEP_FACTOR);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.SQ_OPEN);\n\t\trdyurnBuffer.append(stepFactorParam);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.SQ_CLOSE);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.UNDERSCORE);\n\n\t\t//Prefix\n\t\tString prefix = (prefixParam == null) ? \"\" : prefixParam;\n\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.PREFIX);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.SQ_OPEN);\n\t\trdyurnBuffer.append(prefix);\n\t\trdyurnBuffer.append(FieldMetaData.Decimal.SQ_CLOSE);\n\n\t\treturn rdyurnBuffer.toString();\n\t}",
        "explanations_by_ours": [
            "the string buffer",
            "the string buffer to use for the metadata",
            "the buffer to use for the metadata"
        ],
        "corrections_by_ours": [
            "rdyurnUse",
            "useBuffer",
            "stringBuffer",
            "bufferBuffer",
            "metadataBuffer",
            "rdyurnString",
            "rdyurnMetadata",
            "rdyurnBuffer"
        ],
        "corrections_by_baseline": [
            "destinBuffer",
            "directBuffer",
            "socketBuffer",
            "currBuffer",
            "outBuffer",
            "sbuf",
            "readOnlyBuffer",
            "internalBuffer",
            "oldBuffer",
            "newBuffer"
        ]
    },
    {
        "original_word": "filtered",
        "typo_word": "fioterex",
        "original_variable": "filtered_md",
        "typo_variable": "fioterex_md",
        "original_code": "public Metadata filter(Metadata metadata) {\n        Metadata filtered_md = _filter(metadata, mdToTransfer);\n\n        // add the features that are only persisted but\n        // not transfered like __redirTo_\n        filtered_md.putAll(_filter(metadata, mdToPersistOnly));\n\n        return filtered_md;\n    }",
        "modified_code": "public Metadata filter(Metadata metadata) {\n        Metadata fioterex_md = _filter(metadata, mdToTransfer);\n\n        // add the features that are only persisted but\n        // not transfered like __redirTo_\n        fioterex_md.putAll(_filter(metadata, mdToPersistOnly));\n\n        return fioterex_md;\n    }",
        "explanations_by_ours": [
            "The metadata to filter.",
            "the metadata to filter",
            "The metadata to filter"
        ],
        "corrections_by_ours": [
            "filter_md",
            "fioterex_metadata",
            "metadata_md",
            "fioterex_filter",
            "fioterex_md"
        ],
        "corrections_by_baseline": [
            "ejbMD",
            "ejbSecurityMD",
            "hasEjbSecurityMD",
            "vmdi",
            "mefd",
            "cdmHash",
            "warMD",
            "cdmdim",
            "bom",
            "dmd"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "dzlue",
        "original_variable": "value",
        "typo_variable": "dzlue",
        "original_code": "@Override\n    public Object get(int index) {\n        Object value = backingList.get(index);\n\n        // When a value is accessed, it's intended type can either be a\n        // class or some other type (like a ParameterizedType).\n        //\n        // If the target type is a class and the value is of that type,\n        // we return it.  If the value is not of that type, we convert\n        // it and store the converted value (trusting it was converted\n        // properly) back to the backing store.\n        //\n        // If the target type is not a class, it may be ParameterizedType\n        // like List<T> or Map<K, V>.  We check if the value is already\n        // a converting type and if so, we return it.  If the value is\n        // not, we convert it and if it's now a converting type, we store\n        // the new value in the backing store.\n\n        if (type instanceof Class) {\n            if (!((Class) type).isInstance(value)) {\n                value = convert(type, value);\n\n                //noinspection unchecked\n                backingList.set(index, value);\n            }\n        } else {\n            if (!(value instanceof ConvertingMap) && !(value instanceof ConvertingList)) {\n                value = convert(type, value);\n\n                if (value instanceof ConvertingMap || value instanceof ConvertingList) {\n                    //noinspection unchecked\n                    backingList.set(index, value);\n                }\n            }\n        }\n\n        return value;\n    }",
        "modified_code": "@Override\n    public Object get(int index) {\n        Object dzlue = backingList.get(index);\n\n        // When a value is accessed, it's intended type can either be a\n        // class or some other type (like a ParameterizedType).\n        //\n        // If the target type is a class and the value is of that type,\n        // we return it.  If the value is not of that type, we convert\n        // it and store the converted value (trusting it was converted\n        // properly) back to the backing store.\n        //\n        // If the target type is not a class, it may be ParameterizedType\n        // like List<T> or Map<K, V>.  We check if the value is already\n        // a converting type and if so, we return it.  If the value is\n        // not, we convert it and if it's now a converting type, we store\n        // the new value in the backing store.\n\n        if (type instanceof Class) {\n            if (!((Class) type).isInstance(dzlue)) {\n                dzlue = convert(type, dzlue);\n\n                //noinspection unchecked\n                backingList.set(index, dzlue);\n            }\n        } else {\n            if (!(dzlue instanceof ConvertingMap) && !(dzlue instanceof ConvertingList)) {\n                dzlue = convert(type, dzlue);\n\n                if (dzlue instanceof ConvertingMap || dzlue instanceof ConvertingList) {\n                    //noinspection unchecked\n                    backingList.set(index, dzlue);\n                }\n            }\n        }\n\n        return dzlue;\n    }",
        "explanations_by_ours": [
            "the value to return",
            "the value to be returned",
            "the value to return."
        ],
        "corrections_by_ours": [
            "value",
            "returned",
            "return"
        ],
        "corrections_by_baseline": [
            "dudf",
            "dub",
            "FAZ",
            "bue",
            "wx0",
            "dys",
            "wy0",
            "dpe",
            "dch",
            "pckg"
        ]
    },
    {
        "original_word": "members",
        "typo_word": "memvdrs",
        "original_variable": "members",
        "typo_variable": "memvdrs",
        "original_code": "public Structure select( List<String> memberNames) {\n    Structure result = (Structure) copy();\n    List<Variable> members = new ArrayList<>();\n    for (String name : memberNames) {\n      Variable m = findVariable(name);\n      if (null != m) members.add(m);\n    }\n    result.setMemberVariables(members);\n    result.isSubset = true;\n    return result;\n  }",
        "modified_code": "public Structure select( List<String> memberNames) {\n    Structure result = (Structure) copy();\n    List<Variable> memvdrs = new ArrayList<>();\n    for (String name : memberNames) {\n      Variable m = findVariable(name);\n      if (null != m) memvdrs.add(m);\n    }\n    result.setMemberVariables(memvdrs);\n    result.isSubset = true;\n    return result;\n  }",
        "explanations_by_ours": [
            "The subset of the structure.",
            "The subset of the structure",
            "The members of the structure."
        ],
        "corrections_by_ours": [
            "members",
            "structure",
            "subset"
        ],
        "corrections_by_baseline": [
            "memList",
            "vds",
            "gdrs",
            "hrs",
            "mfiles",
            "mem",
            "svd",
            "rcs",
            "snapshots",
            "fds"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rfzult",
        "original_variable": "result",
        "typo_variable": "rfzult",
        "original_code": "public static Future<Boolean> sendMessage(final Email msg) {\n        if (asynchronousSend) {\n            return executor.submit(new Callable<Boolean>() {\n\n                public Boolean call() {\n                    try {\n                        msg.setSentDate(new Date());\n                        msg.send();\n                        return true;\n                    } catch (Throwable e) {\n                        MailException me = new MailException(\"Error while sending email\", e);\n                        logger.error(\"The email has not been sent\", me);\n                        return false;\n                    }\n                }\n            });\n        } else {\n            final StringBuffer result = new StringBuffer();\n            try {\n                msg.setSentDate(new Date());\n                msg.send();\n            } catch (Throwable e) {\n                MailException me = new MailException(\"Error while sending email\", e);\n                logger.error(\"The email has not been sent\", me);\n                result.append(\"oops\");\n            }\n            return new Future<Boolean>() {\n\n                public boolean cancel(boolean mayInterruptIfRunning) {\n                    return false;\n                }\n\n                public boolean isCancelled() {\n                    return false;\n                }\n\n                public boolean isDone() {\n                    return true;\n                }\n\n                public Boolean get() throws InterruptedException, ExecutionException {\n                    return result.length() == 0;\n                }\n\n                public Boolean get(long timeout, TimeUnit unit)\n                        throws InterruptedException, ExecutionException, TimeoutException {\n                    return result.length() == 0;\n                }\n            };\n        }\n    }",
        "modified_code": "public static Future<Boolean> sendMessage(final Email msg) {\n        if (asynchronousSend) {\n            return executor.submit(new Callable<Boolean>() {\n\n                public Boolean call() {\n                    try {\n                        msg.setSentDate(new Date());\n                        msg.send();\n                        return true;\n                    } catch (Throwable e) {\n                        MailException me = new MailException(\"Error while sending email\", e);\n                        logger.error(\"The email has not been sent\", me);\n                        return false;\n                    }\n                }\n            });\n        } else {\n            final StringBuffer rfzult = new StringBuffer();\n            try {\n                msg.setSentDate(new Date());\n                msg.send();\n            } catch (Throwable e) {\n                MailException me = new MailException(\"Error while sending email\", e);\n                logger.error(\"The email has not been sent\", me);\n                rfzult.append(\"oops\");\n            }\n            return new Future<Boolean>() {\n\n                public boolean cancel(boolean mayInterruptIfRunning) {\n                    return false;\n                }\n\n                public boolean isCancelled() {\n                    return false;\n                }\n\n                public boolean isDone() {\n                    return true;\n                }\n\n                public Boolean get() throws InterruptedException, ExecutionException {\n                    return rfzult.length() == 0;\n                }\n\n                public Boolean get(long timeout, TimeUnit unit)\n                        throws InterruptedException, ExecutionException, TimeoutException {\n                    return rfzult.length() == 0;\n                }\n            };\n        }\n    }",
        "explanations_by_ours": [
            "a string that will be appended to the result of the future",
            "a string buffer that will be appended to the result of the future.",
            "a string that will be appended to the result of the future."
        ],
        "corrections_by_ours": [
            "result",
            "future",
            "string",
            "appended",
            "buffer"
        ],
        "corrections_by_baseline": [
            "rsf",
            "pihalf",
            "mf",
            "rp",
            "urpt",
            "zerr",
            "spf",
            "hf",
            "ncf",
            "tp"
        ]
    },
    {
        "original_word": "entry",
        "typo_word": "wngry",
        "original_variable": "entry",
        "typo_variable": "wngry",
        "original_code": "private CacheValue computeCacheValueByContent(final String content) {\n    String hash = null;\n    try {\n      if (content != null) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Content to fingerprint: [{}]\", StringUtils.abbreviate(content, 30));\n        }\n        hash = hashStrategy.getHash(new ByteArrayInputStream(content.getBytes()));\n      }\n      final CacheValue entry = CacheValue.valueOf(content, hash);\n      LOG.debug(\"computed entry: {}\", entry);\n      return entry;\n    } catch (final IOException e) {\n      throw new RuntimeException(\"Should never happen\", e);\n    }\n  }",
        "modified_code": "private CacheValue computeCacheValueByContent(final String content) {\n    String hash = null;\n    try {\n      if (content != null) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Content to fingerprint: [{}]\", StringUtils.abbreviate(content, 30));\n        }\n        hash = hashStrategy.getHash(new ByteArrayInputStream(content.getBytes()));\n      }\n      final CacheValue wngry = CacheValue.valueOf(content, hash);\n      LOG.debug(\"computed entry: {}\", wngry);\n      return wngry;\n    } catch (final IOException e) {\n      throw new RuntimeException(\"Should never happen\", e);\n    }\n  }",
        "explanations_by_ours": [
            "the wngry",
            "the cache value",
            "the wngry value"
        ],
        "corrections_by_ours": [
            "value",
            "cache"
        ],
        "corrections_by_baseline": [
            "wn",
            "wch",
            "zpown",
            "mnu",
            "ykr",
            "nk",
            "wz",
            "osw",
            "dmr",
            "wierd"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "cihnt",
        "original_variable": "count",
        "typo_variable": "cihnt",
        "original_code": "public static int copy(InputStream input, OutputStream output)\n\t\t\tthrows IOException {\n\t\tbyte[] buffer = new byte[BUFFER_SIZE];\n\n\t\tBufferedInputStream in = new BufferedInputStream(input, BUFFER_SIZE);\n\t\tBufferedOutputStream out = new BufferedOutputStream(output, BUFFER_SIZE);\n\t\tint count = 0, n = 0;\n\n\t\ttry {\n\t\t\twhile ((n = in.read(buffer, 0, BUFFER_SIZE)) != -1) {\n\t\t\t\tout.write(buffer, 0, n);\n\t\t\t\tcount += n;\n\t\t\t}\n\t\t\tout.flush();\n\t\t} finally {\n\t\t\tIOUtils.closeQuietly(in);\n\t\t\tIOUtils.closeQuietly(out);\n\t\t}\n\n\t\treturn count;\n\t}",
        "modified_code": "public static int copy(InputStream input, OutputStream output)\n\t\t\tthrows IOException {\n\t\tbyte[] buffer = new byte[BUFFER_SIZE];\n\n\t\tBufferedInputStream in = new BufferedInputStream(input, BUFFER_SIZE);\n\t\tBufferedOutputStream out = new BufferedOutputStream(output, BUFFER_SIZE);\n\t\tint cihnt = 0, n = 0;\n\n\t\ttry {\n\t\t\twhile ((n = in.read(buffer, 0, BUFFER_SIZE)) != -1) {\n\t\t\t\tout.write(buffer, 0, n);\n\t\t\t\tcihnt += n;\n\t\t\t}\n\t\t\tout.flush();\n\t\t} finally {\n\t\t\tIOUtils.closeQuietly(in);\n\t\t\tIOUtils.closeQuietly(out);\n\t\t}\n\n\t\treturn cihnt;\n\t}",
        "explanations_by_ours": [
            "the number of bytes to copy",
            "the number of bytes copied",
            "the number of bytes to be copied"
        ],
        "corrections_by_ours": [
            "copy",
            "copied",
            "bytes",
            "number"
        ],
        "corrections_by_baseline": [
            "icnt",
            "nt",
            "cnc",
            "ci",
            "cdmsize",
            "ncd",
            "kcnt",
            "cdmnode",
            "jcnt",
            "cdl"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rwsklt",
        "original_variable": "result",
        "typo_variable": "rwsklt",
        "original_code": "public Term atom() throws SourceCodeException\n    {\n        Token name = consumeToken(ATOM);\n\n        Term result;\n\n        // Used to build the possible set of operators that this symbol could be parsed as.\n        EnumMap<OpSymbol.Fixity, OpSymbol> possibleOperators =\n            operatorTable.getOperatorsMatchingNameByFixity(name.image);\n\n        // Check if the symbol mapped onto any candidate operators and if not create a constant for it.\n        if ((possibleOperators == null) || possibleOperators.isEmpty())\n        {\n            int nameId = interner.internFunctorName(name.image, 0);\n            result = new Functor(nameId, null);\n        }\n        else\n        {\n            // Set the possible associativities of the operator on the candidate.\n            result = new CandidateOpSymbol(name.image, possibleOperators);\n        }\n\n        // Set the position that the name was parsed from.\n        SourceCodePosition position =\n            new SourceCodePositionImpl(name.beginLine, name.beginColumn, name.endLine, name.endColumn);\n        result.setSourceCodePosition(position);\n\n        return result;\n    }",
        "modified_code": "public Term atom() throws SourceCodeException\n    {\n        Token name = consumeToken(ATOM);\n\n        Term rwsklt;\n\n        // Used to build the possible set of operators that this symbol could be parsed as.\n        EnumMap<OpSymbol.Fixity, OpSymbol> possibleOperators =\n            operatorTable.getOperatorsMatchingNameByFixity(name.image);\n\n        // Check if the symbol mapped onto any candidate operators and if not create a constant for it.\n        if ((possibleOperators == null) || possibleOperators.isEmpty())\n        {\n            int nameId = interner.internFunctorName(name.image, 0);\n            rwsklt = new Functor(nameId, null);\n        }\n        else\n        {\n            // Set the possible associativities of the operator on the candidate.\n            rwsklt = new CandidateOpSymbol(name.image, possibleOperators);\n        }\n\n        // Set the position that the name was parsed from.\n        SourceCodePosition position =\n            new SourceCodePositionImpl(name.beginLine, name.beginColumn, name.endLine, name.endColumn);\n        rwsklt.setSourceCodePosition(position);\n\n        return rwsklt;\n    }",
        "explanations_by_ours": [
            "the rwsklt",
            "the atom",
            "the rwsklt term"
        ],
        "corrections_by_ours": [
            "atom",
            "term"
        ],
        "corrections_by_baseline": [
            "wrrp",
            "wrp",
            "wrt",
            "wv",
            "irw",
            "wrpUnchecked",
            "wt",
            "towrite",
            "w",
            "W"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reeklt",
        "original_variable": "result",
        "typo_variable": "reeklt",
        "original_code": "public float toFloatValue(final Object value, final float defaultValue) {\n\t\tfinal Float result = toFloat(value);\n\t\tif (result == null) {\n\t\t\treturn defaultValue;\n\t\t}\n\t\treturn result.floatValue();\n\t}",
        "modified_code": "public float toFloatValue(final Object value, final float defaultValue) {\n\t\tfinal Float reeklt = toFloat(value);\n\t\tif (reeklt == null) {\n\t\t\treturn defaultValue;\n\t\t}\n\t\treturn reeklt.floatValue();\n\t}",
        "explanations_by_ours": [
            "the value to convert",
            "the value to convert, may be null",
            "the value to convert to a float"
        ],
        "corrections_by_ours": [
            "null",
            "float",
            "convert",
            "convert,",
            "may",
            "value"
        ],
        "corrections_by_baseline": [
            "quoteless",
            "Latin",
            "alphat",
            "lowercase",
            "letter",
            "LETTER",
            "lont",
            "upperCase",
            "sbStr",
            "nwordp"
        ]
    },
    {
        "original_word": "Code",
        "typo_word": "Ckdf",
        "original_variable": "hashCode",
        "typo_variable": "hashCkdf",
        "original_code": "int addConstantNameAndType(final String name, final String descriptor) {\n    final int tag = Symbol.CONSTANT_NAME_AND_TYPE_TAG;\n    int hashCode = hash(tag, name, descriptor);\n    Entry entry = get(hashCode);\n    while (entry != null) {\n      if (entry.tag == tag\n          && entry.hashCode == hashCode\n          && entry.name.equals(name)\n          && entry.value.equals(descriptor)) {\n        return entry.index;\n      }\n      entry = entry.next;\n    }\n    constantPool.put122(tag, addConstantUtf8(name), addConstantUtf8(descriptor));\n    return put(new Entry(constantPoolCount++, tag, name, descriptor, hashCode)).index;\n  }",
        "modified_code": "int addConstantNameAndType(final String name, final String descriptor) {\n    final int tag = Symbol.CONSTANT_NAME_AND_TYPE_TAG;\n    int hashCkdf = hash(tag, name, descriptor);\n    Entry entry = get(hashCkdf);\n    while (entry != null) {\n      if (entry.tag == tag\n          && entry.hashCkdf == hashCkdf\n          && entry.name.equals(name)\n          && entry.value.equals(descriptor)) {\n        return entry.index;\n      }\n      entry = entry.next;\n    }\n    constantPool.put122(tag, addConstantUtf8(name), addConstantUtf8(descriptor));\n    return put(new Entry(constantPoolCount++, tag, name, descriptor, hashCkdf)).index;\n  }",
        "explanations_by_ours": [
            "the hash of the constant.",
            "the hash of the constant name and descriptor.",
            "the hash function of the constant."
        ],
        "corrections_by_ours": [
            "nameCkdf",
            "constantCkdf",
            "hashConstant",
            "hashFunction",
            "descriptorCkdf",
            "hashDescriptor",
            "functionCkdf",
            "hashHash",
            "hashName",
            "hashCkdf"
        ],
        "corrections_by_baseline": [
            "cdmHash",
            "md5hash",
            "keyHashCode",
            "rawHmac",
            "pckgHash",
            "hashAndSalt",
            "hmac",
            "crc32",
            "computedHash",
            "a1Md5"
        ]
    },
    {
        "original_word": "Props",
        "typo_word": "Pdlps",
        "original_variable": "ignoreProps",
        "typo_variable": "ignorePdlps",
        "original_code": "@SuppressWarnings( \"unchecked\" )\n    public static <T> T fromMap( Map<String, Object> map, Class<T> clazz, String... excludeProperties ) {\n        Set<String> ignoreProps = excludeProperties.length > 0 ? Sets.set(excludeProperties) :  null;\n        return new MapperComplex(FieldAccessMode.FIELD_THEN_PROPERTY.create( false ), ignoreProps, null, true).fromMap(map, clazz);\n\n\n    }",
        "modified_code": "@SuppressWarnings( \"unchecked\" )\n    public static <T> T fromMap( Map<String, Object> map, Class<T> clazz, String... excludeProperties ) {\n        Set<String> ignorePdlps = excludeProperties.length > 0 ? Sets.set(excludeProperties) :  null;\n        return new MapperComplex(FieldAccessMode.FIELD_THEN_PROPERTY.create( false ), ignorePdlps, null, true).fromMap(map, clazz);\n\n\n    }",
        "explanations_by_ours": [
            "the properties to ignore from the creation",
            "the properties to ignore",
            "the properties to ignore when creating the class"
        ],
        "corrections_by_ours": [
            "ignoreProperties",
            "propertiesPdlps",
            "ignoreClass",
            "creationPdlps",
            "classPdlps",
            "creatingPdlps",
            "ignoreIgnore",
            "ignoreCreation",
            "ignoreCreating",
            "ignorePdlps"
        ],
        "corrections_by_baseline": [
            "ignoreProps",
            "ignoreProperties",
            "includePreludes",
            "ignore",
            "ignoreString",
            "ignoreNullValues",
            "lintItems",
            "ignoreAbsence",
            "noprogress",
            "suppress"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rrsuit",
        "original_variable": "result",
        "typo_variable": "rrsuit",
        "original_code": "@Override\n  public ProjectionImpl constructCopy() {\n    ProjectionImpl result = new FlatEarth(getOriginLat(), getOriginLon(), getRotationAngle());\n    result.setDefaultMapArea(defaultMapArea);\n    result.setName(name);\n    return result;\n  }",
        "modified_code": "@Override\n  public ProjectionImpl constructCopy() {\n    ProjectionImpl rrsuit = new FlatEarth(getOriginLat(), getOriginLon(), getRotationAngle());\n    rrsuit.setDefaultMapArea(defaultMapArea);\n    rrsuit.setName(name);\n    return rrsuit;\n  }",
        "explanations_by_ours": [
            "The rrsuit projection.",
            "The projection to copy.",
            "The rrsuit projection"
        ],
        "corrections_by_ours": [
            "projectionuit",
            "rrsprojection",
            "uituit",
            "copyuit",
            "rrsrrs",
            "rrscopy",
            "rrsuit"
        ],
        "corrections_by_baseline": [
            "rr",
            "rrank",
            "ucum",
            "npe",
            "rcidpe",
            "snum",
            "rn",
            "vvstruct",
            "suf",
            "srclen"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reshlf",
        "original_variable": "result",
        "typo_variable": "reshlf",
        "original_code": "public static double[] join(double[]... arrays) {\n\t\tif (arrays.length == 0) {\n\t\t\treturn new double[0];\n\t\t}\n\t\tif (arrays.length == 1) {\n\t\t\treturn arrays[0];\n\t\t}\n\t\tint length = 0;\n\t\tfor (double[] array : arrays) {\n\t\t\tlength += array.length;\n\t\t}\n\t\tdouble[] result = new double[length];\n\t\tlength = 0;\n\t\tfor (double[] array : arrays) {\n\t\t\tSystem.arraycopy(array, 0, result, length, array.length);\n\t\t\tlength += array.length;\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public static double[] join(double[]... arrays) {\n\t\tif (arrays.length == 0) {\n\t\t\treturn new double[0];\n\t\t}\n\t\tif (arrays.length == 1) {\n\t\t\treturn arrays[0];\n\t\t}\n\t\tint length = 0;\n\t\tfor (double[] array : arrays) {\n\t\t\tlength += array.length;\n\t\t}\n\t\tdouble[] reshlf = new double[length];\n\t\tlength = 0;\n\t\tfor (double[] array : arrays) {\n\t\t\tSystem.arraycopy(array, 0, reshlf, length, array.length);\n\t\t\tlength += array.length;\n\t\t}\n\t\treturn reshlf;\n\t}",
        "explanations_by_ours": [
            "the resulting double array",
            "the new double array",
            "the resulting double array."
        ],
        "corrections_by_ours": [
            "resulting",
            "double",
            "new",
            "array"
        ],
        "corrections_by_baseline": [
            "refresh",
            "CRLF",
            "retention",
            "cff",
            "scratch",
            "recsize",
            "baf",
            "lfac",
            "rebuildTermOffset",
            "passwordClear"
        ]
    },
    {
        "original_word": "line",
        "typo_word": "lkbe",
        "original_variable": "lineStart",
        "typo_variable": "lkbeStart",
        "original_code": "static void getLuma00Unsafe(byte[] pic, int picW, int picH, byte[] blk, int blkOff, int blkStride, int x, int y,\n            int blkW, int blkH) {\n        int maxH = picH - 1;\n        int maxW = picW - 1;\n\n        for (int j = 0; j < blkH; j++) {\n            int lineStart = clip(j + y, 0, maxH) * picW;\n\n            for (int i = 0; i < blkW; i++) {\n                blk[blkOff + i] = pic[lineStart + clip(x + i, 0, maxW)];\n            }\n            blkOff += blkStride;\n        }\n    }",
        "modified_code": "static void getLuma00Unsafe(byte[] pic, int picW, int picH, byte[] blk, int blkOff, int blkStride, int x, int y,\n            int blkW, int blkH) {\n        int maxH = picH - 1;\n        int maxW = picW - 1;\n\n        for (int j = 0; j < blkH; j++) {\n            int lkbeStart = clip(j + y, 0, maxH) * picW;\n\n            for (int i = 0; i < blkW; i++) {\n                blk[blkOff + i] = pic[lkbeStart + clip(x + i, 0, maxW)];\n            }\n            blkOff += blkStride;\n        }\n    }",
        "explanations_by_ours": [
            "The start offset of the Luma00 pixel.",
            "The start offset of the Luma00 pixel in the image.",
            "The starting offset of the Luma00 pixel."
        ],
        "corrections_by_ours": [
            "lkbeStarting",
            "lumaStart",
            "imageStart",
            "pixelStart",
            "lkbeImage",
            "offsetStart",
            "lkbeOffset",
            "00Start",
            "startStart",
            "startingStart"
        ],
        "corrections_by_baseline": [
            "start",
            "startp",
            "miniStart",
            "iStart",
            "startPart",
            "startc",
            "startString",
            "startMark",
            "start1",
            "tokNdxStart"
        ]
    },
    {
        "original_word": "bits",
        "typo_word": "bltc",
        "original_variable": "allbits",
        "typo_variable": "allbltc",
        "original_code": "static public byte[] shortToBytes(short v) {\r\n        byte[] b       = new byte[2];\r\n        int    allbits = 255;\r\n        for (int i = 0; i < 2; i++) {\r\n            b[1 - i] = (byte) ((v & (allbits << i * 8)) >> i * 8);\r\n        }\r\n        return b;\r\n    }",
        "modified_code": "static public byte[] shortToBytes(short v) {\r\n        byte[] b       = new byte[2];\r\n        int    allbltc = 255;\r\n        for (int i = 0; i < 2; i++) {\r\n            b[1 - i] = (byte) ((v & (allbltc << i * 8)) >> i * 8);\r\n        }\r\n        return b;\r\n    }",
        "explanations_by_ours": [
            "the allbltc value",
            "the all bltc value",
            "the value to convert"
        ],
        "corrections_by_ours": [
            "bltc",
            "value",
            "convert"
        ],
        "corrections_by_baseline": [
            "dtc",
            "tc",
            "txlist",
            "bc",
            "sfb",
            "xstell",
            "hb",
            "sbblocal",
            "dbs",
            "saltb"
        ]
    },
    {
        "original_word": "target",
        "typo_word": "rartet",
        "original_variable": "target",
        "typo_variable": "rartet",
        "original_code": "protected boolean[] convertValueToArray(final Object value) {\n\t\tif (value instanceof Collection) {\n\t\t\tfinal Collection collection = (Collection) value;\n\t\t\tfinal boolean[] target = new boolean[collection.size()];\n\n\t\t\tint i = 0;\n\t\t\tfor (final Object element : collection) {\n\t\t\t\ttarget[i] = convertType(element);\n\t\t\t\ti++;\n\t\t\t}\n\t\t\treturn target;\n\t\t}\n\n\t\tif (value instanceof Iterable) {\n\t\t\tfinal Iterable iterable = (Iterable) value;\n\n\t\t\tfinal ArrayList<Boolean> booleanArrayList = new ArrayList<>();\n\n\t\t\tfor (final Object element : iterable) {\n\t\t\t\tfinal boolean convertedValue = convertType(element);\n\t\t\t\tbooleanArrayList.add(Boolean.valueOf(convertedValue));\n            }\n\t\t\t\n\t\t\tfinal boolean[] array = new boolean[booleanArrayList.size()];\n\n\t\t\tfor (int i = 0; i < booleanArrayList.size(); i++) {\n\t\t\t\tfinal Boolean b = booleanArrayList.get(i);\n\t\t\t\tarray[i] = b.booleanValue();\n\t\t\t}\n\t\t\t\n\t\t\treturn array;\n\t\t}\n\n\t\tif (value instanceof CharSequence) {\n\t\t\tfinal String[] strings = StringUtil.splitc(value.toString(), ArrayConverter.NUMBER_DELIMITERS);\n\t\t\treturn convertArrayToArray(strings);\n\t\t}\n\n\t\t// everything else:\n\t\treturn convertToSingleElementArray(value);\n\t}",
        "modified_code": "protected boolean[] convertValueToArray(final Object value) {\n\t\tif (value instanceof Collection) {\n\t\t\tfinal Collection collection = (Collection) value;\n\t\t\tfinal boolean[] rartet = new boolean[collection.size()];\n\n\t\t\tint i = 0;\n\t\t\tfor (final Object element : collection) {\n\t\t\t\trartet[i] = convertType(element);\n\t\t\t\ti++;\n\t\t\t}\n\t\t\treturn rartet;\n\t\t}\n\n\t\tif (value instanceof Iterable) {\n\t\t\tfinal Iterable iterable = (Iterable) value;\n\n\t\t\tfinal ArrayList<Boolean> booleanArrayList = new ArrayList<>();\n\n\t\t\tfor (final Object element : iterable) {\n\t\t\t\tfinal boolean convertedValue = convertType(element);\n\t\t\t\tbooleanArrayList.add(Boolean.valueOf(convertedValue));\n            }\n\t\t\t\n\t\t\tfinal boolean[] array = new boolean[booleanArrayList.size()];\n\n\t\t\tfor (int i = 0; i < booleanArrayList.size(); i++) {\n\t\t\t\tfinal Boolean b = booleanArrayList.get(i);\n\t\t\t\tarray[i] = b.booleanValue();\n\t\t\t}\n\t\t\t\n\t\t\treturn array;\n\t\t}\n\n\t\tif (value instanceof CharSequence) {\n\t\t\tfinal String[] strings = StringUtil.splitc(value.toString(), ArrayConverter.NUMBER_DELIMITERS);\n\t\t\treturn convertArrayToArray(strings);\n\t\t}\n\n\t\t// everything else:\n\t\treturn convertToSingleElementArray(value);\n\t}",
        "explanations_by_ours": [
            "the rartet array",
            "the rartet",
            "the rartet array."
        ],
        "corrections_by_ours": [
            "array"
        ],
        "corrections_by_baseline": [
            "istart",
            "art",
            "rp",
            "resul",
            "R",
            "r",
            "estart",
            "itr",
            "etf",
            "newR"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vzluf",
        "original_variable": "value",
        "typo_variable": "vzluf",
        "original_code": "public static String resolveProperty(final Map map, final String key) {\n\t\tString value = getProperty(map, key);\n\t\tif (value == null) {\n\t\t\treturn null;\n\t\t}\n\t\tvalue = stp.parse(value, macroName -> getProperty(map, macroName));\n\n\t\treturn value;\n\t}",
        "modified_code": "public static String resolveProperty(final Map map, final String key) {\n\t\tString vzluf = getProperty(map, key);\n\t\tif (vzluf == null) {\n\t\t\treturn null;\n\t\t}\n\t\tvzluf = stp.parse(vzluf, macroName -> getProperty(map, macroName));\n\n\t\treturn vzluf;\n\t}",
        "explanations_by_ours": [
            "the vzluf",
            "the vzluf",
            "the vgluf"
        ],
        "corrections_by_ours": [
            "vgluf"
        ],
        "corrections_by_baseline": [
            "vz",
            "vf",
            "uvz",
            "vDk0",
            "dz",
            "ykr",
            "kxky",
            "uvf",
            "zetm1",
            "fv"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "sfarr",
        "original_variable": "start",
        "typo_variable": "sfarr",
        "original_code": "public static void appendEscapingCDATA(StringBuilder output, String str) {\n    if (str == null) {\n      return;\n    }\n\n    int end = str.indexOf(CDATA_END);\n\n    if (end < 0) {\n      output.append(str);\n\n      return;\n    }\n\n    int start = 0;\n\n    while (end > -1) {\n      output.append(str.substring(start, end));\n      output.append(CDATA_EMBEDED_END);\n      start = end + CDATA_END_LEN;\n\n      if (start < str.length()) {\n        end = str.indexOf(CDATA_END, start);\n      } else {\n        return;\n      }\n    }\n\n    output.append(str.substring(start));\n  }",
        "modified_code": "public static void appendEscapingCDATA(StringBuilder output, String str) {\n    if (str == null) {\n      return;\n    }\n\n    int end = str.indexOf(CDATA_END);\n\n    if (end < 0) {\n      output.append(str);\n\n      return;\n    }\n\n    int sfarr = 0;\n\n    while (end > -1) {\n      output.append(str.substring(sfarr, end));\n      output.append(CDATA_EMBEDED_END);\n      sfarr = end + CDATA_END_LEN;\n\n      if (sfarr < str.length()) {\n        end = str.indexOf(CDATA_END, sfarr);\n      } else {\n        return;\n      }\n    }\n\n    output.append(str.substring(sfarr));\n  }",
        "explanations_by_ours": [
            "the start position of the CDATA section.",
            "the start index of the CDATA section.",
            "the start position in the string."
        ],
        "corrections_by_ours": [
            "sfstart",
            "sfdata",
            "startarr",
            "stringarr",
            "sfstring",
            "sectionarr",
            "positionarr",
            "dataarr",
            "indexarr",
            "carr"
        ],
        "corrections_by_baseline": [
            "sarr",
            "arr",
            "sArr",
            "lArr",
            "sarray",
            "rarray",
            "larray",
            "iArr",
            "xArr",
            "cArr"
        ]
    },
    {
        "original_word": "output",
        "typo_word": "outlug",
        "original_variable": "output",
        "typo_variable": "outlug",
        "original_code": "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\r\n\tpublic static <T> Collection<T> collectResults(ResultCollector<?, ?> resultCollector)\r\n\tthrows Exception\r\n\t{\r\n\t\tif(resultCollector == null)\r\n\t\t\treturn null;\r\n\t\t\r\n\t\tCollection<Object> results = (Collection)resultCollector.getResult();\r\n\t\t\r\n\t\tif(results  == null || results.isEmpty())\r\n\t\t\treturn null;\r\n\t\t\t\r\n\t\tArrayList<Object> output = new ArrayList<>(10);\r\n\t\tflatten(results, output);\r\n\t\t\r\n\t\tif(output.isEmpty())\r\n\t\t\treturn null;\r\n\t\t\r\n\t\toutput.trimToSize();\r\n\t\treturn (Collection)output;\r\n\t}",
        "modified_code": "@SuppressWarnings({ \"unchecked\", \"rawtypes\" })\r\n\tpublic static <T> Collection<T> collectResults(ResultCollector<?, ?> resultCollector)\r\n\tthrows Exception\r\n\t{\r\n\t\tif(resultCollector == null)\r\n\t\t\treturn null;\r\n\t\t\r\n\t\tCollection<Object> results = (Collection)resultCollector.getResult();\r\n\t\t\r\n\t\tif(results  == null || results.isEmpty())\r\n\t\t\treturn null;\r\n\t\t\t\r\n\t\tArrayList<Object> outlug = new ArrayList<>(10);\r\n\t\tflatten(results, outlug);\r\n\t\t\r\n\t\tif(outlug.isEmpty())\r\n\t\t\treturn null;\r\n\t\t\r\n\t\toutlug.trimToSize();\r\n\t\treturn (Collection)outlug;\r\n\t}",
        "explanations_by_ours": [
            "the output list",
            "the outlug",
            "the outlug of the results"
        ],
        "corrections_by_ours": [
            "outputlug",
            "luglug",
            "resultslug",
            "listlug",
            "outlist",
            "outoutput",
            "outresults",
            "outlug"
        ],
        "corrections_by_baseline": [
            "catURL",
            "outname",
            "appdURL",
            "urlon",
            "url",
            "jspUrl",
            "route",
            "groupUrl",
            "gname",
            "furl"
        ]
    },
    {
        "original_word": "clazz",
        "typo_word": "xoazz",
        "original_variable": "clazz",
        "typo_variable": "xoazz",
        "original_code": "public static String getDefaultTypeName(Type type) {\n        if(type instanceof Class) {\n            Class<?> clazz = (Class<?>)type;\n            HollowTypeName explicitTypeName = clazz.getAnnotation(HollowTypeName.class);\n            if(explicitTypeName != null)\n                return explicitTypeName.name();\n            return clazz.getSimpleName();\n        }\n\n        ParameterizedType parameterizedType = (ParameterizedType)type;\n        Class<?> clazz = (Class<?>)parameterizedType.getRawType();\n\n        if(List.class.isAssignableFrom(clazz))\n            return \"ListOf\" + getDefaultTypeName(parameterizedType.getActualTypeArguments()[0]);\n        if(Set.class.isAssignableFrom(clazz))\n            return \"SetOf\" + getDefaultTypeName(parameterizedType.getActualTypeArguments()[0]);\n        if(Map.class.isAssignableFrom(clazz))\n            return \"MapOf\" + getDefaultTypeName(parameterizedType.getActualTypeArguments()[0]) + \"To\" + getDefaultTypeName(parameterizedType.getActualTypeArguments()[1]);\n\n        return clazz.getSimpleName();\n    }",
        "modified_code": "public static String getDefaultTypeName(Type type) {\n        if(type instanceof Class) {\n            Class<?> xoazz = (Class<?>)type;\n            HollowTypeName explicitTypeName = xoazz.getAnnotation(HollowTypeName.class);\n            if(explicitTypeName != null)\n                return explicitTypeName.name();\n            return xoazz.getSimpleName();\n        }\n\n        ParameterizedType parameterizedType = (ParameterizedType)type;\n        Class<?> xoazz = (Class<?>)parameterizedType.getRawType();\n\n        if(List.class.isAssignableFrom(xoazz))\n            return \"ListOf\" + getDefaultTypeName(parameterizedType.getActualTypeArguments()[0]);\n        if(Set.class.isAssignableFrom(xoazz))\n            return \"SetOf\" + getDefaultTypeName(parameterizedType.getActualTypeArguments()[0]);\n        if(Map.class.isAssignableFrom(xoazz))\n            return \"MapOf\" + getDefaultTypeName(parameterizedType.getActualTypeArguments()[0]) + \"To\" + getDefaultTypeName(parameterizedType.getActualTypeArguments()[1]);\n\n        return xoazz.getSimpleName();\n    }",
        "explanations_by_ours": [
            "the type to get the name of",
            "the class to get the name of",
            "the type to get the name for"
        ],
        "corrections_by_ours": [
            "name",
            "class",
            "type",
            "get"
        ],
        "corrections_by_baseline": [
            "jmx",
            "xInstance",
            "clazz",
            "aclass",
            "eclazz",
            "oClass",
            "clazzCS",
            "oe",
            "xstell",
            "dto"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "redhlt",
        "original_variable": "result",
        "typo_variable": "redhlt",
        "original_code": "public BigDecimal toBigDecimal(final Object value, final BigDecimal defaultValue) {\n\t\tfinal BigDecimal result = toBigDecimal(value);\n\t\tif (result == null) {\n\t\t\treturn defaultValue;\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public BigDecimal toBigDecimal(final Object value, final BigDecimal defaultValue) {\n\t\tfinal BigDecimal redhlt = toBigDecimal(value);\n\t\tif (redhlt == null) {\n\t\t\treturn defaultValue;\n\t\t}\n\t\treturn redhlt;\n\t}",
        "explanations_by_ours": [
            "the value to convert",
            "the value to convert, may be null",
            "the value to convert to a BigDecimal"
        ],
        "corrections_by_ours": [
            "rednull",
            "redvalue",
            "converthlt",
            "decimalhlt",
            "redconvert",
            "convert,hlt",
            "redconvert,",
            "nullhlt",
            "mayhlt",
            "bighlt"
        ],
        "corrections_by_baseline": [
            "red",
            "rslt",
            "alt",
            "wrpUnchecked",
            "rrank",
            "lt",
            "ilenhd",
            "tfa",
            "sgt",
            "xblat"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reculf",
        "original_variable": "result",
        "typo_variable": "reculf",
        "original_code": "public String getUnitsString() {\r\n    String result = units;\r\n    if ((result == null) && (forVar != null)) {\r\n      Attribute att = forVar.findAttribute( CDM.UNITS);\r\n      if (att == null) att = forVar.findAttributeIgnoreCase( CDM.UNITS);\r\n      if ((att != null) && att.isString())\r\n        result = att.getStringValue();\r\n    }\r\n    return (result == null) ? null : result.trim();\r\n  }",
        "modified_code": "public String getUnitsString() {\r\n    String reculf = units;\r\n    if ((reculf == null) && (forVar != null)) {\r\n      Attribute att = forVar.findAttribute( CDM.UNITS);\r\n      if (att == null) att = forVar.findAttributeIgnoreCase( CDM.UNITS);\r\n      if ((att != null) && att.isString())\r\n        reculf = att.getStringValue();\r\n    }\r\n    return (reculf == null) ? null : reculf.trim();\r\n  }",
        "explanations_by_ours": [
            "the units string.",
            "the units string",
            "the units string if null."
        ],
        "corrections_by_ours": [
            "null",
            "string",
            "units"
        ],
        "corrections_by_baseline": [
            "revalidate",
            "re",
            "upc",
            "acf",
            "dapseq",
            "coeffAbs",
            "recs",
            "revert",
            "vf",
            "sco"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "kffsst",
        "original_variable": "offset",
        "typo_variable": "kffsst",
        "original_code": "public static String simpleHostname(String fullHostname) {\n        if (InetAddresses.isInetAddress(fullHostname)) {\n            return fullHostname;\n        }\n        int offset = fullHostname.indexOf('.');\n        if (offset != -1) {\n            return fullHostname.substring(0, offset);\n        }\n        return fullHostname;\n    }",
        "modified_code": "public static String simpleHostname(String fullHostname) {\n        if (InetAddresses.isInetAddress(fullHostname)) {\n            return fullHostname;\n        }\n        int kffsst = fullHostname.indexOf('.');\n        if (kffsst != -1) {\n            return fullHostname.substring(0, kffsst);\n        }\n        return fullHostname;\n    }",
        "explanations_by_ours": [
            "the hostname without the port",
            "the hostname without the port.",
            "the kffsst of the hostname"
        ],
        "corrections_by_ours": [
            "port",
            "without",
            "hostname"
        ],
        "corrections_by_baseline": [
            "dks",
            "stp",
            "dcs",
            "econst",
            "dsBest",
            "csa",
            "hcs",
            "gdss",
            "rcs",
            "bais"
        ]
    },
    {
        "original_word": "delete",
        "typo_word": "deketf",
        "original_variable": "deleteList",
        "typo_variable": "deketfList",
        "original_code": "public synchronized void clearCache(boolean force) {\n    List<CacheElement.CacheFile> deleteList = new ArrayList<>(2 * cache.size());\n\n    if (force) {\n      cache.clear(); // deletes everything from the cache\n      deleteList.addAll(files.values());  // add everything to the delete list\n      files.clear();\n      // counter.set(0);\n\n    } else {\n\n      // add unlocked files to the delete list, remove from files hash\n      Iterator<CacheElement.CacheFile> iter = files.values().iterator();\n      while (iter.hasNext()) {\n        CacheElement.CacheFile file = iter.next();\n        if (file.isLocked.compareAndSet(false, true)) {\n          file.remove(); // remove from the containing CacheElement\n          deleteList.add(file);\n          iter.remove();\n        }\n      }\n\n      // remove empty cache elements\n      for (CacheElement elem : cache.values()) {\n        if (elem.list.size() == 0)\n          cache.remove(elem.hashKey);\n      }\n    }\n\n    // close all files in deleteList\n    for (CacheElement.CacheFile file : deleteList) {\n      if (force && file.isLocked.get())\n        cacheLog.warn(\"FileCacheARC \" + name + \" force close locked file= \" + file);\n      //counter.decrementAndGet();\n\n      if (file.ncfile == null) continue;\n\n      try {\n        file.ncfile.setFileCache(null);\n        file.ncfile.close();\n        file.ncfile = null; // help the gc\n      } catch (IOException e) {\n        log.error(\"FileCacheARC \" + name + \" close failed on \" + file);\n      }\n    }\n    if (cacheLog.isDebugEnabled())\n      cacheLog.debug(\"*FileCacheARC \" + name + \" clearCache force= \" + force + \" deleted= \" + deleteList.size() + \" left=\" + files.size());\n    //System.out.println(\"\\n*NetcdfFileCache.clearCache force= \" + force + \" deleted= \" + deleteList.size() + \" left=\" + counter.get());\n  }",
        "modified_code": "public synchronized void clearCache(boolean force) {\n    List<CacheElement.CacheFile> deketfList = new ArrayList<>(2 * cache.size());\n\n    if (force) {\n      cache.clear(); // deletes everything from the cache\n      deketfList.addAll(files.values());  // add everything to the delete list\n      files.clear();\n      // counter.set(0);\n\n    } else {\n\n      // add unlocked files to the delete list, remove from files hash\n      Iterator<CacheElement.CacheFile> iter = files.values().iterator();\n      while (iter.hasNext()) {\n        CacheElement.CacheFile file = iter.next();\n        if (file.isLocked.compareAndSet(false, true)) {\n          file.remove(); // remove from the containing CacheElement\n          deketfList.add(file);\n          iter.remove();\n        }\n      }\n\n      // remove empty cache elements\n      for (CacheElement elem : cache.values()) {\n        if (elem.list.size() == 0)\n          cache.remove(elem.hashKey);\n      }\n    }\n\n    // close all files in deleteList\n    for (CacheElement.CacheFile file : deketfList) {\n      if (force && file.isLocked.get())\n        cacheLog.warn(\"FileCacheARC \" + name + \" force close locked file= \" + file);\n      //counter.decrementAndGet();\n\n      if (file.ncfile == null) continue;\n\n      try {\n        file.ncfile.setFileCache(null);\n        file.ncfile.close();\n        file.ncfile = null; // help the gc\n      } catch (IOException e) {\n        log.error(\"FileCacheARC \" + name + \" close failed on \" + file);\n      }\n    }\n    if (cacheLog.isDebugEnabled())\n      cacheLog.debug(\"*FileCacheARC \" + name + \" clearCache force= \" + force + \" deleted= \" + deketfList.size() + \" left=\" + files.size());\n    //System.out.println(\"\\n*NetcdfFileCache.clearCache force= \" + force + \" deleted= \" + deleteList.size() + \" left=\" + counter.get());\n  }",
        "explanations_by_ours": [
            "The list of files to be deleted.",
            "The list of files to delete.",
            "List of files to be deleted."
        ],
        "corrections_by_ours": [
            "deleteList",
            "deletedList",
            "deketfFiles",
            "filesList",
            "listList",
            "deketfDelete",
            "deketfDeleted",
            "deketfList"
        ],
        "corrections_by_baseline": [
            "mechList",
            "possibleDsList",
            "vList",
            "pList",
            "vlist",
            "fmrList",
            "hcsList",
            "stnList",
            "eList",
            "pvList"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "ciknt",
        "original_variable": "count",
        "typo_variable": "ciknt",
        "original_code": "public static java.util.Collection<MuxerFormat>\n  getFormats()\n  {\n    java.util.Collection<MuxerFormat> retval =\n      new java.util.HashSet<MuxerFormat>();\n    int count = getNumFormats();\n    for(int i = 0; i< count;++i)\n    {\n      MuxerFormat fmt = getFormat(i);\n      if (fmt != null)\n        retval.add(fmt);\n    }\n    return retval;\n  }",
        "modified_code": "public static java.util.Collection<MuxerFormat>\n  getFormats()\n  {\n    java.util.Collection<MuxerFormat> retval =\n      new java.util.HashSet<MuxerFormat>();\n    int ciknt = getNumFormats();\n    for(int i = 0; i< ciknt;++i)\n    {\n      MuxerFormat fmt = getFormat(i);\n      if (fmt != null)\n        retval.add(fmt);\n    }\n    return retval;\n  }",
        "explanations_by_ours": [
            "The number of format objects to return.",
            "The number of available format objects.",
            "The number of format objects in the collection."
        ],
        "corrections_by_ours": [
            "collection",
            "format",
            "objects",
            "available",
            "number",
            "return"
        ],
        "corrections_by_baseline": [
            "kcnt",
            "icnt",
            "knt",
            "ci",
            "cnc",
            "jcnt",
            "ecint",
            "fci",
            "hcs",
            "cid"
        ]
    },
    {
        "original_word": "shape",
        "typo_word": "ehxpe",
        "original_variable": "shape",
        "typo_variable": "ehxpe",
        "original_code": "public ArrayStructure readStructure(int start, int count) throws IOException, ucar.ma2.InvalidRangeException {\n    if (getRank() != 1) throw new java.lang.UnsupportedOperationException(\"not a vector structure\");\n    int[] origin = new int[] {start};\n    int[] shape = new int[] {count};\n    if (NetcdfFile.debugStructureIterator)\n      System.out.println(\"readStructure \"+start+\" \"+count);\n    return (ArrayStructure) read(origin, shape);\n  }",
        "modified_code": "public ArrayStructure readStructure(int start, int count) throws IOException, ucar.ma2.InvalidRangeException {\n    if (getRank() != 1) throw new java.lang.UnsupportedOperationException(\"not a vector structure\");\n    int[] origin = new int[] {start};\n    int[] ehxpe = new int[] {count};\n    if (NetcdfFile.debugStructureIterator)\n      System.out.println(\"readStructure \"+start+\" \"+count);\n    return (ArrayStructure) read(origin, ehxpe);\n  }",
        "explanations_by_ours": [
            "the array of elements in the vector structure",
            "the array of indices of the vector structure",
            "the array of elements in the vector structure."
        ],
        "corrections_by_ours": [
            "elements",
            "vector",
            "indices",
            "structure",
            "array"
        ],
        "corrections_by_baseline": [
            "dpe",
            "xpp",
            "pce",
            "xh",
            "hf",
            "hrsi",
            "hb",
            "aspi",
            "emf",
            "rcidpe"
        ]
    },
    {
        "original_word": "width",
        "typo_word": "qicth",
        "original_variable": "width",
        "typo_variable": "qicth",
        "original_code": "protected void writeGrid(GridDatatype grid, Array data, boolean greyScale, double xStart, double yStart, double xInc,\n                        double yInc, int imageNumber) throws IOException {\n\n    int nextStart = 0;\n    GridCoordSystem gcs = grid.getCoordinateSystem();\n\n    // get rid of this when all projections are implemented\n    if (!gcs.isLatLon()\n            && !(gcs.getProjection() instanceof LambertConformal)\n            && !(gcs.getProjection() instanceof Stereographic)\n            && !(gcs.getProjection() instanceof Mercator)\n            //  && !(gcs.getProjection() instanceof TransverseMercator)   LOOK broken ??\n            && !(gcs.getProjection() instanceof AlbersEqualAreaEllipse)\n            && !(gcs.getProjection() instanceof AlbersEqualArea)) {\n      throw new IllegalArgumentException(\"Unsupported projection = \" + gcs.getProjection().getClass().getName());\n    }\n\n    // write the data first\n    MAMath.MinMax dataMinMax = grid.getMinMaxSkipMissingData(data);\n    if (greyScale) {\n      ArrayByte result = replaceMissingValuesAndScale(grid, data, dataMinMax);\n      nextStart = geotiff.writeData((byte[]) result.getStorage(), imageNumber);\n    } else {\n      ArrayFloat result = replaceMissingValues(grid, data, dataMinMax);\n      nextStart = geotiff.writeData((float[]) result.getStorage(), imageNumber);\n    }\n\n    // set the width and the height\n    int height = data.getShape()[0];         // Y\n    int width = data.getShape()[1];         // X\n\n    writeMetadata(greyScale, xStart, yStart, xInc, yInc, height, width, imageNumber, nextStart, dataMinMax, gcs.getProjection());\n  }",
        "modified_code": "protected void writeGrid(GridDatatype grid, Array data, boolean greyScale, double xStart, double yStart, double xInc,\n                        double yInc, int imageNumber) throws IOException {\n\n    int nextStart = 0;\n    GridCoordSystem gcs = grid.getCoordinateSystem();\n\n    // get rid of this when all projections are implemented\n    if (!gcs.isLatLon()\n            && !(gcs.getProjection() instanceof LambertConformal)\n            && !(gcs.getProjection() instanceof Stereographic)\n            && !(gcs.getProjection() instanceof Mercator)\n            //  && !(gcs.getProjection() instanceof TransverseMercator)   LOOK broken ??\n            && !(gcs.getProjection() instanceof AlbersEqualAreaEllipse)\n            && !(gcs.getProjection() instanceof AlbersEqualArea)) {\n      throw new IllegalArgumentException(\"Unsupported projection = \" + gcs.getProjection().getClass().getName());\n    }\n\n    // write the data first\n    MAMath.MinMax dataMinMax = grid.getMinMaxSkipMissingData(data);\n    if (greyScale) {\n      ArrayByte result = replaceMissingValuesAndScale(grid, data, dataMinMax);\n      nextStart = geotiff.writeData((byte[]) result.getStorage(), imageNumber);\n    } else {\n      ArrayFloat result = replaceMissingValues(grid, data, dataMinMax);\n      nextStart = geotiff.writeData((float[]) result.getStorage(), imageNumber);\n    }\n\n    // set the width and the height\n    int height = data.getShape()[0];         // Y\n    int qicth = data.getShape()[1];         // X\n\n    writeMetadata(greyScale, xStart, yStart, xInc, yInc, height, qicth, imageNumber, nextStart, dataMinMax, gcs.getProjection());\n  }",
        "explanations_by_ours": [
            "the qicth of the data",
            "the qicth",
            "the qicth of the grid"
        ],
        "corrections_by_ours": [
            "data",
            "grid"
        ],
        "corrections_by_baseline": [
            "qd",
            "q",
            "qmi",
            "qr",
            "cqf",
            "icb",
            "aeqm",
            "qry",
            "qk",
            "qco"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vzlke",
        "original_variable": "value",
        "typo_variable": "vzlke",
        "original_code": "public static int readVInt(InputStream in) throws IOException {\n        byte b = (byte)in.read();\n\n        if(b == (byte) 0x80)\n            throw new RuntimeException(\"Attempting to read null value as int\");\n\n        int value = b & 0x7F;\n        while ((b & 0x80) != 0) {\n          b = (byte)in.read();\n          value <<= 7;\n          value |= (b & 0x7F);\n        }\n\n        return value;\n    }",
        "modified_code": "public static int readVInt(InputStream in) throws IOException {\n        byte b = (byte)in.read();\n\n        if(b == (byte) 0x80)\n            throw new RuntimeException(\"Attempting to read null value as int\");\n\n        int vzlke = b & 0x7F;\n        while ((b & 0x80) != 0) {\n          b = (byte)in.read();\n          vzlke <<= 7;\n          vzlke |= (b & 0x7F);\n        }\n\n        return vzlke;\n    }",
        "explanations_by_ours": [
            "the signed integer to read",
            "the value to read",
            "the signed integer to be read"
        ],
        "corrections_by_ours": [
            "value",
            "signed",
            "integer",
            "read"
        ],
        "corrections_by_baseline": [
            "vz",
            "ykr",
            "kxky",
            "michealangelo",
            "oz",
            "zs",
            "wy",
            "wierd",
            "w_hat",
            "smo"
        ]
    },
    {
        "original_word": "decrypted",
        "typo_word": "dwcryphed",
        "original_variable": "decrypted",
        "typo_variable": "dwcryphed",
        "original_code": "public String decryptAsString(final String encodedJSON) {\n    try {\n      byte[] decrypted = decrypt(encodedJSON);\n      return new String(decrypted, \"UTF8\");\n    } catch (Exception ex) {\n      throw OException.wrapException(new OSecurityException(\"OSymmetricKey.decryptAsString() Exception: \" + ex.getMessage()), ex);\n    }\n  }",
        "modified_code": "public String decryptAsString(final String encodedJSON) {\n    try {\n      byte[] dwcryphed = decrypt(encodedJSON);\n      return new String(dwcryphed, \"UTF8\");\n    } catch (Exception ex) {\n      throw OException.wrapException(new OSecurityException(\"OSymmetricKey.decryptAsString() Exception: \" + ex.getMessage()), ex);\n    }\n  }",
        "explanations_by_ours": [
            "the JSON string to decrypt",
            "the decrypted byte array",
            "the JSON string to be decrypted"
        ],
        "corrections_by_ours": [
            "decrypted",
            "decrypt",
            "byte",
            "string",
            "array",
            "json"
        ],
        "corrections_by_baseline": [
            "pckgHash",
            "dch",
            "pckg",
            "tmphandshake",
            "pdh",
            "qmndx",
            "dub",
            "cdmHash",
            "hashed",
            "dcm"
        ]
    },
    {
        "original_word": "lists",
        "typo_word": "oisfs",
        "original_variable": "lists",
        "typo_variable": "oisfs",
        "original_code": "private void loadStopWordDict() {\r\n\t\t// \u5efa\u7acb\u4e3b\u8bcd\u5178\u5b9e\u4f8b\r\n\t\t_StopWords = new DictSegment((char) 0);\r\n\r\n\t\t// \u8bfb\u53d6\u4e3b\u8bcd\u5178\u6587\u4ef6\r\n\t\tPath file = PathUtils.get(getDictRoot(), Dictionary.PATH_DIC_STOP);\r\n\t\tloadDictFile(_StopWords, file, false, \"Main Stopwords\");\r\n\r\n\t\t// \u52a0\u8f7d\u6269\u5c55\u505c\u6b62\u8bcd\u5178\r\n\t\tList<String> extStopWordDictFiles = getExtStopWordDictionarys();\r\n\t\tif (extStopWordDictFiles != null) {\r\n\t\t\tfor (String extStopWordDictName : extStopWordDictFiles) {\r\n\t\t\t\tlogger.info(\"[Dict Loading] \" + extStopWordDictName);\r\n\r\n\t\t\t\t// \u8bfb\u53d6\u6269\u5c55\u8bcd\u5178\u6587\u4ef6\r\n\t\t\t\tfile = PathUtils.get(extStopWordDictName);\r\n\t\t\t\tloadDictFile(_StopWords, file, false, \"Extra Stopwords\");\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\t// \u52a0\u8f7d\u8fdc\u7a0b\u505c\u7528\u8bcd\u5178\r\n\t\tList<String> remoteExtStopWordDictFiles = getRemoteExtStopWordDictionarys();\r\n\t\tfor (String location : remoteExtStopWordDictFiles) {\r\n\t\t\tlogger.info(\"[Dict Loading] \" + location);\r\n\t\t\tList<String> lists = getRemoteWords(location);\r\n\t\t\t// \u5982\u679c\u627e\u4e0d\u5230\u6269\u5c55\u7684\u5b57\u5178\uff0c\u5219\u5ffd\u7565\r\n\t\t\tif (lists == null) {\r\n\t\t\t\tlogger.error(\"[Dict Loading] \" + location + \"\u52a0\u8f7d\u5931\u8d25\");\r\n\t\t\t\tcontinue;\r\n\t\t\t}\r\n\t\t\tfor (String theWord : lists) {\r\n\t\t\t\tif (theWord != null && !\"\".equals(theWord.trim())) {\r\n\t\t\t\t\t// \u52a0\u8f7d\u8fdc\u7a0b\u8bcd\u5178\u6570\u636e\u5230\u4e3b\u5185\u5b58\u4e2d\r\n\t\t\t\t\tlogger.info(theWord);\r\n\t\t\t\t\t_StopWords.fillSegment(theWord.trim().toLowerCase().toCharArray());\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t}",
        "modified_code": "private void loadStopWordDict() {\r\n\t\t// \u5efa\u7acb\u4e3b\u8bcd\u5178\u5b9e\u4f8b\r\n\t\t_StopWords = new DictSegment((char) 0);\r\n\r\n\t\t// \u8bfb\u53d6\u4e3b\u8bcd\u5178\u6587\u4ef6\r\n\t\tPath file = PathUtils.get(getDictRoot(), Dictionary.PATH_DIC_STOP);\r\n\t\tloadDictFile(_StopWords, file, false, \"Main Stopwords\");\r\n\r\n\t\t// \u52a0\u8f7d\u6269\u5c55\u505c\u6b62\u8bcd\u5178\r\n\t\tList<String> extStopWordDictFiles = getExtStopWordDictionarys();\r\n\t\tif (extStopWordDictFiles != null) {\r\n\t\t\tfor (String extStopWordDictName : extStopWordDictFiles) {\r\n\t\t\t\tlogger.info(\"[Dict Loading] \" + extStopWordDictName);\r\n\r\n\t\t\t\t// \u8bfb\u53d6\u6269\u5c55\u8bcd\u5178\u6587\u4ef6\r\n\t\t\t\tfile = PathUtils.get(extStopWordDictName);\r\n\t\t\t\tloadDictFile(_StopWords, file, false, \"Extra Stopwords\");\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\t// \u52a0\u8f7d\u8fdc\u7a0b\u505c\u7528\u8bcd\u5178\r\n\t\tList<String> remoteExtStopWordDictFiles = getRemoteExtStopWordDictionarys();\r\n\t\tfor (String location : remoteExtStopWordDictFiles) {\r\n\t\t\tlogger.info(\"[Dict Loading] \" + location);\r\n\t\t\tList<String> oisfs = getRemoteWords(location);\r\n\t\t\t// \u5982\u679c\u627e\u4e0d\u5230\u6269\u5c55\u7684\u5b57\u5178\uff0c\u5219\u5ffd\u7565\r\n\t\t\tif (oisfs == null) {\r\n\t\t\t\tlogger.error(\"[Dict Loading] \" + location + \"\u52a0\u8f7d\u5931\u8d25\");\r\n\t\t\t\tcontinue;\r\n\t\t\t}\r\n\t\t\tfor (String theWord : oisfs) {\r\n\t\t\t\tif (theWord != null && !\"\".equals(theWord.trim())) {\r\n\t\t\t\t\t// \u52a0\u8f7d\u8fdc\u7a0b\u8bcd\u5178\u6570\u636e\u5230\u4e3b\u5185\u5b58\u4e2d\r\n\t\t\t\t\tlogger.info(theWord);\r\n\t\t\t\t\t_StopWords.fillSegment(theWord.trim().toLowerCase().toCharArray());\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t}",
        "explanations_by_ours": [
            "List<String>",
            "List of Oisfs.",
            "List of Oisfs"
        ],
        "corrections_by_ours": [
            "listfs",
            "fsfs",
            "oisois",
            "oislist",
            "list<string>fs",
            "oislist<string>",
            "oisfs"
        ],
        "corrections_by_baseline": [
            "fos",
            "ofs",
            "sdds",
            "ifcs",
            "bsf",
            "cis",
            "suf",
            "rawSPS",
            "icf",
            "nf"
        ]
    },
    {
        "original_word": "funcs",
        "typo_word": "eunxs",
        "original_variable": "funcs",
        "typo_variable": "eunxs",
        "original_code": "public void addOutgoingFor(String[] varNames, DifferentialFunction function) {\n\n        if (function.getOwnName() == null)\n            throw new ND4JIllegalStateException(\"Instance id can not be null. Function not initialized properly\");\n\n        if (outgoingArgsReverse.containsKey(function.getOwnName())) {\n            throw new ND4JIllegalStateException(\"Outgoing arguments already declared for \" + function);\n        }\n\n        if (varNames == null)\n            throw new ND4JIllegalStateException(\"Var names can not be null!\");\n\n\n        for (int i = 0; i < varNames.length; i++) {\n            if (varNames[i] == null)\n                throw new ND4JIllegalStateException(\"Variable name elements can not be null!\");\n        }\n\n        outgoingArgsReverse.put(function.getOwnName(), varNames);\n        outgoingArgs.put(varNames, function);\n\n        for (val resultName : varNames) {\n            List<DifferentialFunction> funcs = functionOutputFor.get(resultName);\n            if (funcs == null) {\n                funcs = new ArrayList<>();\n                functionOutputFor.put(resultName, funcs);\n            }\n\n            funcs.add(function);\n        }\n\n    }",
        "modified_code": "public void addOutgoingFor(String[] varNames, DifferentialFunction function) {\n\n        if (function.getOwnName() == null)\n            throw new ND4JIllegalStateException(\"Instance id can not be null. Function not initialized properly\");\n\n        if (outgoingArgsReverse.containsKey(function.getOwnName())) {\n            throw new ND4JIllegalStateException(\"Outgoing arguments already declared for \" + function);\n        }\n\n        if (varNames == null)\n            throw new ND4JIllegalStateException(\"Var names can not be null!\");\n\n\n        for (int i = 0; i < varNames.length; i++) {\n            if (varNames[i] == null)\n                throw new ND4JIllegalStateException(\"Variable name elements can not be null!\");\n        }\n\n        outgoingArgsReverse.put(function.getOwnName(), varNames);\n        outgoingArgs.put(varNames, function);\n\n        for (val resultName : varNames) {\n            List<DifferentialFunction> eunxs = functionOutputFor.get(resultName);\n            if (eunxs == null) {\n                eunxs = new ArrayList<>();\n                functionOutputFor.put(resultName, eunxs);\n            }\n\n            eunxs.add(function);\n        }\n\n    }",
        "explanations_by_ours": [
            "List of function output for the given variable names.",
            "List of function output for the given variable names",
            "List of function output for each variable name."
        ],
        "corrections_by_ours": [
            "function",
            "names",
            "output",
            "list",
            "name",
            "variable",
            "given"
        ],
        "corrections_by_baseline": [
            "unind",
            "xs",
            "uniques",
            "munge",
            "jointCounts",
            "delx",
            "nj",
            "mbers",
            "xbeg",
            "nelems"
        ]
    },
    {
        "original_word": "classes",
        "typo_word": "coassds",
        "original_variable": "classes",
        "typo_variable": "coassds",
        "original_code": "private void initClassLoader(JspCompilationContext clctxt)\n\t    throws IOException {\n\n        classPath = getClassPath();\n\n        ClassLoader jspcLoader = getClass().getClassLoader();\n\n        // Turn the classPath into URLs\n        ArrayList<URL> urls = new ArrayList<URL>();\n        StringTokenizer tokenizer = new StringTokenizer(classPath,\n                                                        File.pathSeparator);\n        while (tokenizer.hasMoreTokens()) {\n            String path = tokenizer.nextToken();\n            try {\n                File libFile = new File(path);\n                urls.add(libFile.toURL());\n            } catch (IOException ioe) {\n                // Failing a toCanonicalPath on a file that\n                // exists() should be a JVM regression test,\n                // therefore we have permission to freak uot\n                throw new RuntimeException(ioe.toString());\n            }\n        }\n\n        File webappBase = new File(uriRoot);\n        if (webappBase.exists()) {\n            File classes = new File(webappBase, \"/WEB-INF/classes\");\n            try {\n                if (classes.exists()) {\n                    classPath = classPath + File.pathSeparator\n                        + classes.getCanonicalPath();\n                    urls.add(classes.getCanonicalFile().toURL());\n                }\n            } catch (IOException ioe) {\n                // failing a toCanonicalPath on a file that\n                // exists() should be a JVM regression test,\n                // therefore we have permission to freak out\n                throw new RuntimeException(ioe.toString());\n            }\n            File lib = new File(webappBase, \"/WEB-INF/lib\");\n            if (lib.exists() && lib.isDirectory()) {\n                String[] libs = lib.list();\n                for (int i = 0; i < libs.length; i++) {\n                    if( libs[i].length() <5 ) continue;\n                    String ext=libs[i].substring( libs[i].length() - 4 );\n                    if (! \".jar\".equalsIgnoreCase(ext)) {\n                        if (\".tld\".equalsIgnoreCase(ext)) {\n                            log.warning(\n                              \"TLD files should not be placed in /WEB-INF/lib\");\n                        }\n                        continue;\n                    }\n                    try {\n                        File libFile = new File(lib, libs[i]);\n                        classPath = classPath + File.pathSeparator\n                            + libFile.getCanonicalPath();\n                        urls.add(libFile.getCanonicalFile().toURL());\n                    } catch (IOException ioe) {\n                        // failing a toCanonicalPath on a file that\n                        // exists() should be a JVM regression test,\n                        // therefore we have permission to freak out\n                        throw new RuntimeException(ioe.toString());\n                    }\n                }\n            }\n        }\n\n        // What is this ??\n        urls.add(new File(clctxt.getRealPath(\"/\")).getCanonicalFile().toURL());\n\n        URL urlsA[]=new URL[urls.size()];\n        urls.toArray(urlsA);\n\n        /* SJSAS 6327357\n        loader = new URLClassLoader(urlsA, this.getClass().getClassLoader());\n         */\n        // START SJSAS 6327357\n        ClassLoader sysClassLoader = initSystemClassLoader();\n        if (sysClassLoader != null) {\n            loader = new URLClassLoader(urlsA, sysClassLoader);\n        } else {\n            loader = new URLClassLoader(urlsA, this.getClass().getClassLoader());\n        }\n        // END SJSAS 6327357\n    }",
        "modified_code": "private void initClassLoader(JspCompilationContext clctxt)\n\t    throws IOException {\n\n        classPath = getClassPath();\n\n        ClassLoader jspcLoader = getClass().getClassLoader();\n\n        // Turn the classPath into URLs\n        ArrayList<URL> urls = new ArrayList<URL>();\n        StringTokenizer tokenizer = new StringTokenizer(classPath,\n                                                        File.pathSeparator);\n        while (tokenizer.hasMoreTokens()) {\n            String path = tokenizer.nextToken();\n            try {\n                File libFile = new File(path);\n                urls.add(libFile.toURL());\n            } catch (IOException ioe) {\n                // Failing a toCanonicalPath on a file that\n                // exists() should be a JVM regression test,\n                // therefore we have permission to freak uot\n                throw new RuntimeException(ioe.toString());\n            }\n        }\n\n        File webappBase = new File(uriRoot);\n        if (webappBase.exists()) {\n            File coassds = new File(webappBase, \"/WEB-INF/classes\");\n            try {\n                if (coassds.exists()) {\n                    classPath = classPath + File.pathSeparator\n                        + coassds.getCanonicalPath();\n                    urls.add(coassds.getCanonicalFile().toURL());\n                }\n            } catch (IOException ioe) {\n                // failing a toCanonicalPath on a file that\n                // exists() should be a JVM regression test,\n                // therefore we have permission to freak out\n                throw new RuntimeException(ioe.toString());\n            }\n            File lib = new File(webappBase, \"/WEB-INF/lib\");\n            if (lib.exists() && lib.isDirectory()) {\n                String[] libs = lib.list();\n                for (int i = 0; i < libs.length; i++) {\n                    if( libs[i].length() <5 ) continue;\n                    String ext=libs[i].substring( libs[i].length() - 4 );\n                    if (! \".jar\".equalsIgnoreCase(ext)) {\n                        if (\".tld\".equalsIgnoreCase(ext)) {\n                            log.warning(\n                              \"TLD files should not be placed in /WEB-INF/lib\");\n                        }\n                        continue;\n                    }\n                    try {\n                        File libFile = new File(lib, libs[i]);\n                        classPath = classPath + File.pathSeparator\n                            + libFile.getCanonicalPath();\n                        urls.add(libFile.getCanonicalFile().toURL());\n                    } catch (IOException ioe) {\n                        // failing a toCanonicalPath on a file that\n                        // exists() should be a JVM regression test,\n                        // therefore we have permission to freak out\n                        throw new RuntimeException(ioe.toString());\n                    }\n                }\n            }\n        }\n\n        // What is this ??\n        urls.add(new File(clctxt.getRealPath(\"/\")).getCanonicalFile().toURL());\n\n        URL urlsA[]=new URL[urls.size()];\n        urls.toArray(urlsA);\n\n        /* SJSAS 6327357\n        loader = new URLClassLoader(urlsA, this.getClass().getClassLoader());\n         */\n        // START SJSAS 6327357\n        ClassLoader sysClassLoader = initSystemClassLoader();\n        if (sysClassLoader != null) {\n            loader = new URLClassLoader(urlsA, sysClassLoader);\n        } else {\n            loader = new URLClassLoader(urlsA, this.getClass().getClassLoader());\n        }\n        // END SJSAS 6327357\n    }",
        "explanations_by_ours": [
            "the coassds directory",
            "the coassds directory.",
            "the coassds file"
        ],
        "corrections_by_ours": [
            "file",
            "directory"
        ],
        "corrections_by_baseline": [
            "residuals",
            "grads",
            "goals",
            "sco",
            "pco",
            "dfs",
            "ensembleCoords",
            "co",
            "qco",
            "assoc"
        ]
    },
    {
        "original_word": "parts",
        "typo_word": "parfc",
        "original_variable": "parts",
        "typo_variable": "parfc",
        "original_code": "public static void changeUpperLevelFinalLength(\r\n\t\t\tfinal Map<String, ConfigRangeAttrs> shiftMap,\r\n\t\t\tfinal String addedFullName, final int increasedLength) {\r\n\t\tString[] parts = addedFullName.split(\":\");\r\n\t\tStringBuilder fname = new StringBuilder();\r\n\t\tfor (int i = 0; i < (parts.length - 1); i++) {\r\n\t\t\tif (i == 0) {\r\n\t\t\t\tfname.append(parts[i]);\r\n\t\t\t} else {\r\n\t\t\t\tfname.append(\":\").append(parts[i]);\r\n\t\t\t}\r\n\t\t\tString sname = fname.toString();\r\n\t\t\tshiftMap.get(sname).setFinalLength(\r\n\t\t\t\t\tshiftMap.get(sname).getFinalLength() + increasedLength);\r\n\t\t}\r\n\t}",
        "modified_code": "public static void changeUpperLevelFinalLength(\r\n\t\t\tfinal Map<String, ConfigRangeAttrs> shiftMap,\r\n\t\t\tfinal String addedFullName, final int increasedLength) {\r\n\t\tString[] parfc = addedFullName.split(\":\");\r\n\t\tStringBuilder fname = new StringBuilder();\r\n\t\tfor (int i = 0; i < (parfc.length - 1); i++) {\r\n\t\t\tif (i == 0) {\r\n\t\t\t\tfname.append(parfc[i]);\r\n\t\t\t} else {\r\n\t\t\t\tfname.append(\":\").append(parfc[i]);\r\n\t\t\t}\r\n\t\t\tString sname = fname.toString();\r\n\t\t\tshiftMap.get(sname).setFinalLength(\r\n\t\t\t\t\tshiftMap.get(sname).getFinalLength() + increasedLength);\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "the parfc",
            "the part of the added full name",
            "the part of the added full name."
        ],
        "corrections_by_ours": [
            "part",
            "name",
            "full",
            "added"
        ],
        "corrections_by_baseline": [
            "par",
            "par1",
            "par2r",
            "par1r",
            "par2",
            "parcel",
            "spc",
            "ptd",
            "fc",
            "dcon"
        ]
    },
    {
        "original_word": "total",
        "typo_word": "tltxl",
        "original_variable": "totalSize",
        "typo_variable": "tltxlSize",
        "original_code": "private long getByteBufferListSize() {\n\t\tlong totalSize = 0;\n\t\tsynchronized (byteBufferList) {\n\t\t\tfor (ByteBuffer buffer : byteBufferList) {\n\t\t\t\ttotalSize += buffer.limit();\n\t\t\t}\n\t\t}\n\t\treturn totalSize;\n\t}",
        "modified_code": "private long getByteBufferListSize() {\n\t\tlong tltxlSize = 0;\n\t\tsynchronized (byteBufferList) {\n\t\t\tfor (ByteBuffer buffer : byteBufferList) {\n\t\t\t\ttltxlSize += buffer.limit();\n\t\t\t}\n\t\t}\n\t\treturn tltxlSize;\n\t}",
        "explanations_by_ours": [
            "the size of the list of buffers in this buffer pool.",
            "the total size of the list of buffers in this buffer pool.",
            "the size of the list of buffers in this buffer pool"
        ],
        "corrections_by_ours": [
            "totalSize",
            "tltxlList",
            "listSize",
            "poolSize",
            "tltxlBuffer",
            "tltxlBuffers",
            "buffersSize",
            "bufferSize",
            "sizeSize",
            "tltxlTotal"
        ],
        "corrections_by_baseline": [
            "hsize",
            "lSize",
            "vpSize",
            "dsize",
            "tSize",
            "fqnSize",
            "xSize",
            "eSize",
            "rSize",
            "esSize"
        ]
    },
    {
        "original_word": "bytes",
        "typo_word": "bytwx",
        "original_variable": "bytes",
        "typo_variable": "bytwx",
        "original_code": "public String getHash(final InputStream input)\n    throws IOException {\n    if (input == null) {\n      throw new IllegalArgumentException(\"Content cannot be null!\");\n    }\n    try{\n      LOG.debug(\"creating hash using CRC32 algorithm\");\n      final Checksum checksum = new CRC32();\n      final byte[] bytes = new byte[1024];\n      int len = 0;\n      while ((len = input.read(bytes)) >= 0) {\n        checksum.update(bytes, 0, len);\n      }\n\n      final String hash = new BigInteger(Long.toString(checksum.getValue())).toString(16);\n      LOG.debug(\"CRC32 hash: {}\", hash);\n      return hash;\n    }finally{\n      IOUtils.closeQuietly(input);\n    }\n  }",
        "modified_code": "public String getHash(final InputStream input)\n    throws IOException {\n    if (input == null) {\n      throw new IllegalArgumentException(\"Content cannot be null!\");\n    }\n    try{\n      LOG.debug(\"creating hash using CRC32 algorithm\");\n      final Checksum checksum = new CRC32();\n      final byte[] bytwx = new byte[1024];\n      int len = 0;\n      while ((len = input.read(bytwx)) >= 0) {\n        checksum.update(bytwx, 0, len);\n      }\n\n      final String hash = new BigInteger(Long.toString(checksum.getValue())).toString(16);\n      LOG.debug(\"CRC32 hash: {}\", hash);\n      return hash;\n    }finally{\n      IOUtils.closeQuietly(input);\n    }\n  }",
        "explanations_by_ours": [
            "the byte array to be hashed",
            "the byte array containing the checksum",
            "the byte array"
        ],
        "corrections_by_ours": [
            "byte",
            "containing",
            "checksum",
            "array",
            "hashed"
        ],
        "corrections_by_baseline": [
            "xby10",
            "SX",
            "sx",
            "bx",
            "xh",
            "x2",
            "X2",
            "x",
            "X",
            "x3"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rssulg",
        "original_variable": "result",
        "typo_variable": "rssulg",
        "original_code": "static public List<Rectangle> sortBySize(List<Rectangle> list){\n\t\tList<Rectangle> result = Lists.newArrayList();\n\t\tCollections.sort(list, new Comparator<Rectangle>(){\n\t\t\t@Override\n\t\t\tpublic int compare(Rectangle r1, Rectangle r2) {\n\t\t\t\treturn (r1.height * r1.width) - (r2.height * r2.width);\n\t\t\t}\t\t\t\n\t\t});\n\t\treturn result;\n\t}",
        "modified_code": "static public List<Rectangle> sortBySize(List<Rectangle> list){\n\t\tList<Rectangle> rssulg = Lists.newArrayList();\n\t\tCollections.sort(list, new Comparator<Rectangle>(){\n\t\t\t@Override\n\t\t\tpublic int compare(Rectangle r1, Rectangle r2) {\n\t\t\t\treturn (r1.height * r1.width) - (r2.height * r2.width);\n\t\t\t}\t\t\t\n\t\t});\n\t\treturn rssulg;\n\t}",
        "explanations_by_ours": [
            "the list of sorted rectangles",
            "the list of rectangles to be sorted",
            "the sorted list of rectangles"
        ],
        "corrections_by_ours": [
            "rectangles",
            "list",
            "sorted"
        ],
        "corrections_by_baseline": [
            "rssi",
            "feed",
            "newsort",
            "gfr",
            "gvcs",
            "gdss",
            "newsiter",
            "sfb",
            "catalog",
            "gds"
        ]
    },
    {
        "original_word": "delay",
        "typo_word": "ddlwy",
        "original_variable": "delay",
        "typo_variable": "ddlwy",
        "original_code": "private <T> Observable.Transformer<T, T> applyInsertRetryPolicy() {\n        return tObservable -> tObservable\n                .retryWhen(errors -> {\n                    Observable<Integer> range = Observable.range(1, 2);\n                    return errors\n                            .zipWith(range, (t, i) -> {\n                                if (t instanceof DriverException) {\n                                    return i;\n                                }\n                                throw Exceptions.propagate(t);\n                            })\n                            .flatMap(retryCount -> {\n                                long delay = (long) Math.min(Math.pow(2, retryCount) * 1000, 3000);\n                                log.debug(\"Retrying batch insert in \" + delay + \" ms\");\n                                return Observable.timer(delay, TimeUnit.MILLISECONDS);\n                            });\n                });\n    }",
        "modified_code": "private <T> Observable.Transformer<T, T> applyInsertRetryPolicy() {\n        return tObservable -> tObservable\n                .retryWhen(errors -> {\n                    Observable<Integer> range = Observable.range(1, 2);\n                    return errors\n                            .zipWith(range, (t, i) -> {\n                                if (t instanceof DriverException) {\n                                    return i;\n                                }\n                                throw Exceptions.propagate(t);\n                            })\n                            .flatMap(retryCount -> {\n                                long ddlwy = (long) Math.min(Math.pow(2, retryCount) * 1000, 3000);\n                                log.debug(\"Retrying batch insert in \" + ddlwy + \" ms\");\n                                return Observable.timer(ddlwy, TimeUnit.MILLISECONDS);\n                            });\n                });\n    }",
        "explanations_by_ours": [
            "the ddlwy",
            "the ddlwy time",
            "the ddlwy parameter"
        ],
        "corrections_by_ours": [
            "parameter",
            "time"
        ],
        "corrections_by_baseline": [
            "ddl",
            "ddb",
            "ddx",
            "dp",
            "ipb",
            "qmndx",
            "wudp1",
            "sndx",
            "btpv",
            "ipd"
        ]
    },
    {
        "original_word": "return",
        "typo_word": "dehurn",
        "original_variable": "returnType",
        "typo_variable": "dehurnType",
        "original_code": "public PipelineConfigurationJson getPipelineInfo (String pipelineId, String rev, String get, Boolean attachment)\n      throws ApiException {\n    Object postBody = null;\n    byte[] postBinaryBody = null;\n\n    // verify the required parameter 'pipelineId' is set\n    if (pipelineId == null) {\n      throw new ApiException(400, \"Missing the required parameter 'pipelineId' when calling getPipelineInfo\");\n    }\n\n    // create path and map variables\n    String path = \"/v1/pipeline/{pipelineId}\".replaceAll(\"\\\\{format\\\\}\",\"json\")\n        .replaceAll(\"\\\\{\" + \"pipelineId\" + \"\\\\}\", apiClient.escapeString(pipelineId.toString()));\n\n    // query params\n    List<Pair> queryParams = new ArrayList<Pair>();\n    Map<String, String> headerParams = new HashMap<String, String>();\n    Map<String, Object> formParams = new HashMap<String, Object>();\n\n\n    queryParams.addAll(apiClient.parameterToPairs(\"\", \"rev\", rev));\n\n    queryParams.addAll(apiClient.parameterToPairs(\"\", \"get\", get));\n\n    queryParams.addAll(apiClient.parameterToPairs(\"\", \"attachment\", attachment));\n\n    final String[] accepts = {\n        \"application/json\"\n    };\n    final String accept = apiClient.selectHeaderAccept(accepts);\n\n    final String[] contentTypes = {\n\n    };\n    final String contentType = apiClient.selectHeaderContentType(contentTypes);\n\n    String[] authNames = new String[] { \"basic\" };\n\n\n    TypeRef returnType = new TypeRef<PipelineConfigurationJson>() {};\n    return apiClient.invokeAPI(path, \"GET\", queryParams, postBody, postBinaryBody, headerParams, formParams, accept,\n        contentType, authNames, returnType);\n  }",
        "modified_code": "public PipelineConfigurationJson getPipelineInfo (String pipelineId, String rev, String get, Boolean attachment)\n      throws ApiException {\n    Object postBody = null;\n    byte[] postBinaryBody = null;\n\n    // verify the required parameter 'pipelineId' is set\n    if (pipelineId == null) {\n      throw new ApiException(400, \"Missing the required parameter 'pipelineId' when calling getPipelineInfo\");\n    }\n\n    // create path and map variables\n    String path = \"/v1/pipeline/{pipelineId}\".replaceAll(\"\\\\{format\\\\}\",\"json\")\n        .replaceAll(\"\\\\{\" + \"pipelineId\" + \"\\\\}\", apiClient.escapeString(pipelineId.toString()));\n\n    // query params\n    List<Pair> queryParams = new ArrayList<Pair>();\n    Map<String, String> headerParams = new HashMap<String, String>();\n    Map<String, Object> formParams = new HashMap<String, Object>();\n\n\n    queryParams.addAll(apiClient.parameterToPairs(\"\", \"rev\", rev));\n\n    queryParams.addAll(apiClient.parameterToPairs(\"\", \"get\", get));\n\n    queryParams.addAll(apiClient.parameterToPairs(\"\", \"attachment\", attachment));\n\n    final String[] accepts = {\n        \"application/json\"\n    };\n    final String accept = apiClient.selectHeaderAccept(accepts);\n\n    final String[] contentTypes = {\n\n    };\n    final String contentType = apiClient.selectHeaderContentType(contentTypes);\n\n    String[] authNames = new String[] { \"basic\" };\n\n\n    TypeRef dehurnType = new TypeRef<PipelineConfigurationJson>() {};\n    return apiClient.invokeAPI(path, \"GET\", queryParams, postBody, postBinaryBody, headerParams, formParams, accept,\n        contentType, authNames, dehurnType);\n  }",
        "explanations_by_ours": [
            "The type of dehurn. (optional)",
            "The type of object returned by the API (required)",
            "The type of dehurn."
        ],
        "corrections_by_ours": [
            "returnedType",
            "(required)Type",
            "dehurnApi",
            "dehurnReturned",
            "dehurnObject",
            "(optional)Type",
            "dehurn(optional)",
            "dehurn(required)",
            "apiType",
            "typeType"
        ],
        "corrections_by_baseline": [
            "hiveType",
            "hiveTypeInfo",
            "decoraManagerType",
            "rollupType",
            "archType",
            "entryType",
            "cdmtype",
            "mtype",
            "itemType",
            "dstatomtype"
        ]
    },
    {
        "original_word": "handles",
        "typo_word": "maneles",
        "original_variable": "handles",
        "typo_variable": "maneles",
        "original_code": "public SetupContextHandle saveContext(ContextService contextService, Map<String, String> contextObjectProperties) {\n        final List<SetupContextHandle> handles = new ArrayList<>(factoryOrderedList.size());\n        for (ContextHandleFactory factory : factoryOrderedList) {\n            handles.add(factory.saveContext(contextService, contextObjectProperties));\n        }\n        return new ChainedSetupContextHandle(this, handles);\n    }",
        "modified_code": "public SetupContextHandle saveContext(ContextService contextService, Map<String, String> contextObjectProperties) {\n        final List<SetupContextHandle> maneles = new ArrayList<>(factoryOrderedList.size());\n        for (ContextHandleFactory factory : factoryOrderedList) {\n            maneles.add(factory.saveContext(contextService, contextObjectProperties));\n        }\n        return new ChainedSetupContextHandle(this, maneles);\n    }",
        "explanations_by_ours": [
            "the maneles",
            "the context maneles",
            "a list of context handle factories"
        ],
        "corrections_by_ours": [
            "handle",
            "factories",
            "context",
            "list"
        ],
        "corrections_by_baseline": [
            "agents",
            "masters",
            "nelems",
            "ifaces",
            "workers",
            "residuals",
            "cdmenum",
            "ems",
            "es",
            "wantedStations"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rrsilt",
        "original_variable": "result",
        "typo_variable": "rrsilt",
        "original_code": "public Term term() throws SourceCodeException\n    {\n        List<Term> terms;\n        terms = terms(new LinkedList<Term>());\n\n        Term[] flatTerms = terms.toArray(new Term[terms.size()]);\n\n        if (flatTerms.length > 1)\n        {\n            return operatorParser.parseOperators(flatTerms);\n        }\n        else\n        {\n            Term result = flatTerms[0];\n\n            // If a single candidate op symbol has been parsed, promote it to a constant.\n            if (result instanceof CandidateOpSymbol)\n            {\n                CandidateOpSymbol candidate = (CandidateOpSymbol) result;\n\n                int nameId = interner.internFunctorName(candidate.getTextName(), 0);\n                result = new Functor(nameId, null);\n            }\n\n            return result;\n        }\n    }",
        "modified_code": "public Term term() throws SourceCodeException\n    {\n        List<Term> terms;\n        terms = terms(new LinkedList<Term>());\n\n        Term[] flatTerms = terms.toArray(new Term[terms.size()]);\n\n        if (flatTerms.length > 1)\n        {\n            return operatorParser.parseOperators(flatTerms);\n        }\n        else\n        {\n            Term rrsilt = flatTerms[0];\n\n            // If a single candidate op symbol has been parsed, promote it to a constant.\n            if (rrsilt instanceof CandidateOpSymbol)\n            {\n                CandidateOpSymbol candidate = (CandidateOpSymbol) rrsilt;\n\n                int nameId = interner.internFunctorName(candidate.getTextName(), 0);\n                rrsilt = new Functor(nameId, null);\n            }\n\n            return rrsilt;\n        }\n    }",
        "explanations_by_ours": [
            "the term of the expression",
            "the rrsilt expression",
            "the term of the expression."
        ],
        "corrections_by_ours": [
            "expression",
            "term"
        ],
        "corrections_by_baseline": [
            "rlam",
            "rLPS",
            "imr",
            "rho",
            "radf",
            "rotr",
            "rlat",
            "rasp_xscale",
            "dtheta",
            "rngy"
        ]
    },
    {
        "original_word": "buff",
        "typo_word": "fuft",
        "original_variable": "sbuff",
        "typo_variable": "sfuft",
        "original_code": "static public String showSecurity(HttpServletRequest req, String role) {\r\n    StringBuilder sbuff = new StringBuilder();\r\n\r\n    sbuff.append(\"Security Info\\n\");\r\n    sbuff.append(\" req.getRemoteUser(): \").append(req.getRemoteUser()).append(\"\\n\");\r\n    sbuff.append(\" req.getUserPrincipal(): \").append(req.getUserPrincipal()).append(\"\\n\");\r\n    sbuff.append(\" req.isUserInRole(\").append(role).append(\"):\").append(req.isUserInRole(role)).append(\"\\n\");\r\n    sbuff.append(\" ------------------\\n\");\r\n\r\n    return sbuff.toString();\r\n  }",
        "modified_code": "static public String showSecurity(HttpServletRequest req, String role) {\r\n    StringBuilder sfuft = new StringBuilder();\r\n\r\n    sfuft.append(\"Security Info\\n\");\r\n    sfuft.append(\" req.getRemoteUser(): \").append(req.getRemoteUser()).append(\"\\n\");\r\n    sfuft.append(\" req.getUserPrincipal(): \").append(req.getUserPrincipal()).append(\"\\n\");\r\n    sfuft.append(\" req.isUserInRole(\").append(role).append(\"):\").append(req.isUserInRole(role)).append(\"\\n\");\r\n    sfuft.append(\" ------------------\\n\");\r\n\r\n    return sfuft.toString();\r\n  }",
        "explanations_by_ours": [
            "the string representation of the security information",
            "the string builder",
            "the string representation"
        ],
        "corrections_by_ours": [
            "security",
            "information",
            "string",
            "representation",
            "builder"
        ],
        "corrections_by_baseline": [
            "ftrm",
            "sfb",
            "bsf",
            "drss",
            "ft",
            "sndx",
            "gdss",
            "utflen",
            "hf",
            "uebertragung"
        ]
    },
    {
        "original_word": "params",
        "typo_word": "pqeams",
        "original_variable": "params",
        "typo_variable": "pqeams",
        "original_code": "private void capture(boolean ignoreNull)\n    {\n        // Get the class of the object to build a memento for.\n        Class cls = ob.getClass();\n\n        // Iterate through all the public methods of the class including all super-interfaces and super-classes.\n        Method[] methods = cls.getMethods();\n\n        for (Method nextMethod : methods)\n        {\n            // Get the next method.\n            /*log.fine(\"nextMethod = \" + nextMethod.getName());*/\n\n            // Check if the method is a 'getter' method, is public and takes no arguments.\n            String methodName = nextMethod.getName();\n\n            if (methodName.startsWith(\"get\") && (methodName.length() >= 4) &&\n                    Character.isUpperCase(methodName.charAt(3)) && Modifier.isPublic(nextMethod.getModifiers()) &&\n                    (nextMethod.getParameterTypes().length == 0))\n            {\n                String propName = Character.toLowerCase(methodName.charAt(3)) + methodName.substring(4);\n                /*log.fine(methodName + \" is a valid getter method for the property \" + propName + \".\");*/\n\n                try\n                {\n                    // Call the 'getter' method to extract the properties value.\n                    Object[] params = new Object[] {};\n                    Object value = nextMethod.invoke(ob, params);\n                    /*log.fine(\"The result of calling the getter method is: \" + value);*/\n\n                    // Store the property value for the object.\n                    if (!ignoreNull || (value != null))\n                    {\n                        values.put(propName, value);\n                    }\n                }\n                catch (IllegalAccessException e)\n                {\n                    /*log.log(java.util.logging.Level.FINE, \"IllegalAccessException during call to getter method.\", e);*/\n                    throw new IllegalStateException(e);\n                }\n                catch (InvocationTargetException e)\n                {\n                    /*log.log(java.util.logging.Level.FINE, \"InvocationTargetException during call to getter method.\", e);*/\n                    throw new IllegalStateException(e);\n                }\n            }\n            // Should also check if the method is a 'setter' method, is public and takes exactly one argument.\n        }\n    }",
        "modified_code": "private void capture(boolean ignoreNull)\n    {\n        // Get the class of the object to build a memento for.\n        Class cls = ob.getClass();\n\n        // Iterate through all the public methods of the class including all super-interfaces and super-classes.\n        Method[] methods = cls.getMethods();\n\n        for (Method nextMethod : methods)\n        {\n            // Get the next method.\n            /*log.fine(\"nextMethod = \" + nextMethod.getName());*/\n\n            // Check if the method is a 'getter' method, is public and takes no arguments.\n            String methodName = nextMethod.getName();\n\n            if (methodName.startsWith(\"get\") && (methodName.length() >= 4) &&\n                    Character.isUpperCase(methodName.charAt(3)) && Modifier.isPublic(nextMethod.getModifiers()) &&\n                    (nextMethod.getParameterTypes().length == 0))\n            {\n                String propName = Character.toLowerCase(methodName.charAt(3)) + methodName.substring(4);\n                /*log.fine(methodName + \" is a valid getter method for the property \" + propName + \".\");*/\n\n                try\n                {\n                    // Call the 'getter' method to extract the properties value.\n                    Object[] pqeams = new Object[] {};\n                    Object value = nextMethod.invoke(ob, pqeams);\n                    /*log.fine(\"The result of calling the getter method is: \" + value);*/\n\n                    // Store the property value for the object.\n                    if (!ignoreNull || (value != null))\n                    {\n                        values.put(propName, value);\n                    }\n                }\n                catch (IllegalAccessException e)\n                {\n                    /*log.log(java.util.logging.Level.FINE, \"IllegalAccessException during call to getter method.\", e);*/\n                    throw new IllegalStateException(e);\n                }\n                catch (InvocationTargetException e)\n                {\n                    /*log.log(java.util.logging.Level.FINE, \"InvocationTargetException during call to getter method.\", e);*/\n                    throw new IllegalStateException(e);\n                }\n            }\n            // Should also check if the method is a 'setter' method, is public and takes exactly one argument.\n        }\n    }",
        "explanations_by_ours": [
            "an array of objects containing the properties values.",
            "the array of arguments to pass to the method.",
            "the array of arguments to pass to the getter method."
        ],
        "corrections_by_ours": [
            "pass",
            "properties",
            "objects",
            "arguments",
            "values",
            "array",
            "containing",
            "getter",
            "method"
        ],
        "corrections_by_baseline": [
            "parms",
            "mparms",
            "iParams",
            "parm",
            "params",
            "nparms",
            "rawParams",
            "sparams",
            "jParams",
            "preqs"
        ]
    },
    {
        "original_word": "meaning",
        "typo_word": "heanong",
        "original_variable": "meaning",
        "typo_variable": "heanong",
        "original_code": "private void readGribCodes(Version version) throws IOException {\n    String[] elems = version.getElemNames();\n    if (elems == null) {\n      throw new IllegalStateException(\"unknown version = \" + version);\n    }\n\n    try (InputStream ios = WmoCodeFlagTables.class.getResourceAsStream(version.getResourceName())) {\n      if (ios == null) {\n        logger.error(\"cant open WmoCodeTable=\" + version.getResourceName());\n        throw new IOException(\"cant open WmoCodeTable=\" + version.getResourceName());\n      }\n\n      org.jdom2.Document doc;\n      try {\n        SAXBuilder builder = new SAXBuilder();\n        doc = builder.build(ios);\n      } catch (JDOMException e) {\n        throw new IOException(e.getMessage());\n      }\n      Element root = doc.getRootElement();\n\n      Map<String, WmoTable> map = new HashMap<>();\n\n      List<Element> featList = root.getChildren(elems[0]); // main element\n      for (Element elem : featList) {\n        String line = elem.getChildTextNormalize(\"No\");\n        String tableName = elem.getChildTextNormalize(elems[1]); // Title_en\n        Element subtableElem = elem.getChild(elems[2]); // \"SubTitle_en\"\n\n        TableType type;\n        if (tableName.startsWith(\"Code table 4.1 \")) {\n          type = TableType.cat;\n        } else if (tableName.startsWith(\"Code table 4.2 \")) {\n          type = TableType.param;\n        } else if (tableName.startsWith(\"Flag\")) {\n          type = TableType.flag;\n        } else if (tableName.startsWith(\"Code\")) {\n          type = TableType.code;\n        } else {\n          logger.warn(\"Unknown wmo table entry = '%s'\", tableName);\n          continue;\n        }\n\n        if (subtableElem != null) {\n          tableName = subtableElem.getTextNormalize();\n        }\n\n        TableType finalType = type;\n        WmoTable wmoTable = map.computeIfAbsent(tableName, name -> new WmoTable(name, finalType));\n\n        String code = elem.getChildTextNormalize(\"CodeFlag\");\n        String value = elem.getChildTextNormalize(\"Value\");    // Flag table only\n        String meaning = elem.getChildTextNormalize(elems[3]); // MeaningParameterDescription_en\n\n        Element unitElem = elem.getChild(elems[4]); // \"UnitComments_en\"\n        String unit = (unitElem == null) ? null : unitElem.getTextNormalize();\n\n        Element statusElem = elem.getChild(\"Status\");\n        String status = (statusElem == null) ? null : statusElem.getTextNormalize();\n\n        wmoTable.addEntry(line, code, value, meaning, unit, status);\n      }\n      ios.close();\n\n      this.wmoTables = map.values().stream().sorted().collect(ImmutableList.toImmutableList());\n      ImmutableMap.Builder<String, WmoTable> builder = ImmutableMap.builder();\n      map.values().forEach(t -> builder.put(t.getId(), t));\n      this.wmoTableMap = builder.build();\n    }\n  }",
        "modified_code": "private void readGribCodes(Version version) throws IOException {\n    String[] elems = version.getElemNames();\n    if (elems == null) {\n      throw new IllegalStateException(\"unknown version = \" + version);\n    }\n\n    try (InputStream ios = WmoCodeFlagTables.class.getResourceAsStream(version.getResourceName())) {\n      if (ios == null) {\n        logger.error(\"cant open WmoCodeTable=\" + version.getResourceName());\n        throw new IOException(\"cant open WmoCodeTable=\" + version.getResourceName());\n      }\n\n      org.jdom2.Document doc;\n      try {\n        SAXBuilder builder = new SAXBuilder();\n        doc = builder.build(ios);\n      } catch (JDOMException e) {\n        throw new IOException(e.getMessage());\n      }\n      Element root = doc.getRootElement();\n\n      Map<String, WmoTable> map = new HashMap<>();\n\n      List<Element> featList = root.getChildren(elems[0]); // main element\n      for (Element elem : featList) {\n        String line = elem.getChildTextNormalize(\"No\");\n        String tableName = elem.getChildTextNormalize(elems[1]); // Title_en\n        Element subtableElem = elem.getChild(elems[2]); // \"SubTitle_en\"\n\n        TableType type;\n        if (tableName.startsWith(\"Code table 4.1 \")) {\n          type = TableType.cat;\n        } else if (tableName.startsWith(\"Code table 4.2 \")) {\n          type = TableType.param;\n        } else if (tableName.startsWith(\"Flag\")) {\n          type = TableType.flag;\n        } else if (tableName.startsWith(\"Code\")) {\n          type = TableType.code;\n        } else {\n          logger.warn(\"Unknown wmo table entry = '%s'\", tableName);\n          continue;\n        }\n\n        if (subtableElem != null) {\n          tableName = subtableElem.getTextNormalize();\n        }\n\n        TableType finalType = type;\n        WmoTable wmoTable = map.computeIfAbsent(tableName, name -> new WmoTable(name, finalType));\n\n        String code = elem.getChildTextNormalize(\"CodeFlag\");\n        String value = elem.getChildTextNormalize(\"Value\");    // Flag table only\n        String heanong = elem.getChildTextNormalize(elems[3]); // MeaningParameterDescription_en\n\n        Element unitElem = elem.getChild(elems[4]); // \"UnitComments_en\"\n        String unit = (unitElem == null) ? null : unitElem.getTextNormalize();\n\n        Element statusElem = elem.getChild(\"Status\");\n        String status = (statusElem == null) ? null : statusElem.getTextNormalize();\n\n        wmoTable.addEntry(line, code, value, heanong, unit, status);\n      }\n      ios.close();\n\n      this.wmoTables = map.values().stream().sorted().collect(ImmutableList.toImmutableList());\n      ImmutableMap.Builder<String, WmoTable> builder = ImmutableMap.builder();\n      map.values().forEach(t -> builder.put(t.getId(), t));\n      this.wmoTableMap = builder.build();\n    }\n  }",
        "explanations_by_ours": [
            "the heanong of the WMO file",
            "the heanong of the WMO",
            "the heanong of the WMO file."
        ],
        "corrections_by_ours": [
            "wmo",
            "file"
        ],
        "corrections_by_baseline": [
            "uhe",
            "ybeg",
            "wy0",
            "p_gam",
            "ilenhd",
            "islong",
            "gaussw",
            "bue",
            "hm",
            "glamx"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reaupt",
        "original_variable": "result",
        "typo_variable": "reaupt",
        "original_code": "public String getFirstAttributeValue(String name) {\n\t\tList<String> result = getAttributeValues(name);\n\t\tif (result.isEmpty()) {\n\t\t\treturn null;\n\t\t}\n\t\telse {\n\t\t\treturn result.get(0);\n\t\t}\n\t}",
        "modified_code": "public String getFirstAttributeValue(String name) {\n\t\tList<String> reaupt = getAttributeValues(name);\n\t\tif (reaupt.isEmpty()) {\n\t\t\treturn null;\n\t\t}\n\t\telse {\n\t\t\treturn reaupt.get(0);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the list of attribute values",
            "a list of attribute values",
            "the list of attribute values to return"
        ],
        "corrections_by_ours": [
            "return",
            "attribute",
            "values",
            "list"
        ],
        "corrections_by_baseline": [
            "llpt",
            "pt",
            "pts",
            "ptd",
            "pto",
            "ptg",
            "dpt",
            "lrpt",
            "rpt",
            "psb"
        ]
    },
    {
        "original_word": "existings",
        "typo_word": "existinvc",
        "original_variable": "existings",
        "typo_variable": "existinvc",
        "original_code": "public static boolean containsProposal(final Collection<ICompletionProposal> proposals, String newProposal) {\n        for (ICompletionProposal prop : proposals) {\n            String displayString = prop.getDisplayString();\n            String[] existings = displayString.split(\" \");\n            if (existings.length == 0) {\n                continue;\n            }\n\n            String[] newProposals = newProposal.split(\" \");\n            if (newProposals.length == 0) {\n                continue;\n            }\n\n            if (existings[0].equals(newProposals[0])) {\n                return true;\n            }\n        }\n        return false;\n    }",
        "modified_code": "public static boolean containsProposal(final Collection<ICompletionProposal> proposals, String newProposal) {\n        for (ICompletionProposal prop : proposals) {\n            String displayString = prop.getDisplayString();\n            String[] existinvc = displayString.split(\" \");\n            if (existinvc.length == 0) {\n                continue;\n            }\n\n            String[] newProposals = newProposal.split(\" \");\n            if (newProposals.length == 0) {\n                continue;\n            }\n\n            if (existinvc[0].equals(newProposals[0])) {\n                return true;\n            }\n        }\n        return false;\n    }",
        "explanations_by_ours": [
            "the list of proposals to check",
            "the name of the proposal to check",
            "the list of proposals to check for"
        ],
        "corrections_by_ours": [
            "list",
            "proposal",
            "proposals",
            "name",
            "check"
        ],
        "corrections_by_baseline": [
            "duExists",
            "existings",
            "exists",
            "non_exist",
            "hasE",
            "isExisting",
            "present",
            "exposed",
            "hasNetcdf",
            "alreadyPresent"
        ]
    },
    {
        "original_word": "total",
        "typo_word": "tlral",
        "original_variable": "total",
        "typo_variable": "tlral",
        "original_code": "public static long getLengthOfParts(final Part[] parts, final byte[] partBoundary) throws IOException {\n    if (DEBUG) { Log.v(TAG, \"getLengthOfParts(Parts[])\"); }\n    if (parts == null) {\n      throw new IllegalArgumentException(\"Parts may not be null\");\n    }\n    long total = 0;\n    for (int i = 0; i < parts.length; i++) {\n      // set the part boundary before we calculate the part's length\n      parts[i].setPartBoundary(partBoundary);\n      final long l = parts[i].length();\n      if (l < 0) {\n        return -1;\n      }\n      total += l;\n    }\n    total += EXTRA_BYTES.length;\n    total += partBoundary.length;\n    total += EXTRA_BYTES.length;\n    total += CRLF_BYTES.length;\n    return total;\n  }",
        "modified_code": "public static long getLengthOfParts(final Part[] parts, final byte[] partBoundary) throws IOException {\n    if (DEBUG) { Log.v(TAG, \"getLengthOfParts(Parts[])\"); }\n    if (parts == null) {\n      throw new IllegalArgumentException(\"Parts may not be null\");\n    }\n    long tlral = 0;\n    for (int i = 0; i < parts.length; i++) {\n      // set the part boundary before we calculate the part's length\n      parts[i].setPartBoundary(partBoundary);\n      final long l = parts[i].length();\n      if (l < 0) {\n        return -1;\n      }\n      tlral += l;\n    }\n    tlral += EXTRA_BYTES.length;\n    tlral += partBoundary.length;\n    tlral += EXTRA_BYTES.length;\n    tlral += CRLF_BYTES.length;\n    return tlral;\n  }",
        "explanations_by_ours": [
            "the total length of the parts",
            "the length of the parts",
            "the length of the parts in bytes"
        ],
        "corrections_by_ours": [
            "total",
            "parts",
            "bytes",
            "length"
        ],
        "corrections_by_baseline": [
            "tl",
            "deltaXHalf",
            "rotl",
            "radf",
            "delta",
            "sec",
            "numSec",
            "resSecs",
            "secs",
            "deltaX"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resuoh",
        "original_variable": "result",
        "typo_variable": "resuoh",
        "original_code": "public List<String> getAttributeValues(String name) {\n\t\tList<String> result = null;\n\t\tif (attributes != null) {\n\t\t\tresult = attributes.get(name);\n\t\t}\n\t\tif (result == null) {\n\t\t\tresult = Collections.emptyList();\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public List<String> getAttributeValues(String name) {\n\t\tList<String> resuoh = null;\n\t\tif (attributes != null) {\n\t\t\tresuoh = attributes.get(name);\n\t\t}\n\t\tif (resuoh == null) {\n\t\t\tresuoh = Collections.emptyList();\n\t\t}\n\t\treturn resuoh;\n\t}",
        "explanations_by_ours": [
            "the result of the lookup",
            "the result of the attribute",
            "the result of the lookup."
        ],
        "corrections_by_ours": [
            "result",
            "attribute",
            "lookup"
        ],
        "corrections_by_baseline": [
            "resul",
            "urlonv",
            "rdr",
            "res",
            "urpt",
            "srv",
            "urlatv",
            "rp",
            "usv",
            "rtc"
        ]
    },
    {
        "original_word": "closable",
        "typo_word": "clodabls",
        "original_variable": "closable",
        "typo_variable": "clodabls",
        "original_code": "private ResourceRoot createResourceRoot(final DeploymentUnit deploymentUnit, final VirtualFile file, final boolean markAsSubDeployment, final boolean explodeDuringMount) throws IOException {\n        final boolean war = file.getName().toLowerCase(Locale.ENGLISH).endsWith(WAR_EXTENSION);\n        final Closeable closable = file.isFile() ? mount(file, explodeDuringMount) : exportExplodedWar(war, file, deploymentUnit);\n        final MountHandle mountHandle = new MountHandle(closable);\n        final ResourceRoot resourceRoot = new ResourceRoot(file, mountHandle);\n        deploymentUnit.addToAttachmentList(Attachments.RESOURCE_ROOTS, resourceRoot);\n        if (markAsSubDeployment) {\n            SubDeploymentMarker.mark(resourceRoot);\n        }\n        if (war) {\n            resourceRoot.putAttachment(Attachments.INDEX_RESOURCE_ROOT, false);\n            SubExplodedDeploymentMarker.mark(resourceRoot);\n        }\n        return resourceRoot;\n    }",
        "modified_code": "private ResourceRoot createResourceRoot(final DeploymentUnit deploymentUnit, final VirtualFile file, final boolean markAsSubDeployment, final boolean explodeDuringMount) throws IOException {\n        final boolean war = file.getName().toLowerCase(Locale.ENGLISH).endsWith(WAR_EXTENSION);\n        final Closeable clodabls = file.isFile() ? mount(file, explodeDuringMount) : exportExplodedWar(war, file, deploymentUnit);\n        final MountHandle mountHandle = new MountHandle(clodabls);\n        final ResourceRoot resourceRoot = new ResourceRoot(file, mountHandle);\n        deploymentUnit.addToAttachmentList(Attachments.RESOURCE_ROOTS, resourceRoot);\n        if (markAsSubDeployment) {\n            SubDeploymentMarker.mark(resourceRoot);\n        }\n        if (war) {\n            resourceRoot.putAttachment(Attachments.INDEX_RESOURCE_ROOT, false);\n            SubExplodedDeploymentMarker.mark(resourceRoot);\n        }\n        return resourceRoot;\n    }",
        "explanations_by_ours": [
            "the resources to mount",
            "the resources to mount or export",
            "the resource root resources"
        ],
        "corrections_by_ours": [
            "resources",
            "root",
            "mount",
            "resource",
            "export"
        ],
        "corrections_by_baseline": [
            "snames",
            "econstnames",
            "aliases",
            "clIds",
            "schemas",
            "sbbDescriptors",
            "names",
            "nmaps",
            "spc_names",
            "dbNames"
        ]
    },
    {
        "original_word": "Size",
        "typo_word": "Slae",
        "original_variable": "currentSize",
        "typo_variable": "currentSlae",
        "original_code": "void shrink() {\n\t      if (intervals != null) {\n\t        int currentSize = intervalIdx + 1;\n\t        if (currentSize < intervals.length) {\n\t          BitInterval[] tmp = new BitInterval[currentSize];\n\t          System.arraycopy(intervals, 0, tmp, 0, currentSize);\n\t          intervals = tmp;\n\t        }\n\t      }\n\t    }",
        "modified_code": "void shrink() {\n\t      if (intervals != null) {\n\t        int currentSlae = intervalIdx + 1;\n\t        if (currentSlae < intervals.length) {\n\t          BitInterval[] tmp = new BitInterval[currentSlae];\n\t          System.arraycopy(intervals, 0, tmp, 0, currentSlae);\n\t          intervals = tmp;\n\t        }\n\t      }\n\t    }",
        "explanations_by_ours": [
            "the current slae of the array.",
            "the current slae of the array",
            "the current slae."
        ],
        "corrections_by_ours": [
            "arraySlae",
            "currentArray",
            "slaeSlae",
            "currentCurrent",
            "currentSlae"
        ],
        "corrections_by_baseline": [
            "currentClassesOffset",
            "currentDs",
            "currentNdx",
            "currentArea",
            "currentIn",
            "currentSegment",
            "current",
            "currentVert",
            "currentOut",
            "currentCount"
        ]
    },
    {
        "original_word": "existing",
        "typo_word": "existigf",
        "original_variable": "existing",
        "typo_variable": "existigf",
        "original_code": "public void registerPathAlias(final String alias, final String path) {\n\t\tfinal String existing = pathAliases.put(alias, path);\n\t\tif (existing != null) {\n\t\t\tthrow new MadvocException(\"Duplicated alias detected: [\" + alias + \"] for paths: \" + path + \", \" + existing);\n\t\t}\n\t}",
        "modified_code": "public void registerPathAlias(final String alias, final String path) {\n\t\tfinal String existigf = pathAliases.put(alias, path);\n\t\tif (existigf != null) {\n\t\t\tthrow new MadvocException(\"Duplicated alias detected: [\" + alias + \"] for paths: \" + path + \", \" + existigf);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the existigf",
            "the existing path alias",
            "the existing alias"
        ],
        "corrections_by_ours": [
            "existing",
            "path",
            "alias"
        ],
        "corrections_by_baseline": [
            "existings",
            "exists",
            "duExists",
            "non_exist",
            "alreadyExists",
            "isExisting",
            "existingCondition",
            "alreadyPresent",
            "hasE",
            "present"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "gexult",
        "original_variable": "result",
        "typo_variable": "gexult",
        "original_code": "private Integer getOrder(Class<?> clazz) {\n\t\twhile (clazz != null) {\n\t\t\tInteger result = filterToOrder.get(clazz.getName());\n\t\t\tif (result != null) {\n\t\t\t\treturn result;\n\t\t\t}\n\t\t\tclazz = clazz.getSuperclass();\n\t\t}\n\t\treturn null;\n\t}",
        "modified_code": "private Integer getOrder(Class<?> clazz) {\n\t\twhile (clazz != null) {\n\t\t\tInteger gexult = filterToOrder.get(clazz.getName());\n\t\t\tif (gexult != null) {\n\t\t\t\treturn gexult;\n\t\t\t}\n\t\t\tclazz = clazz.getSuperclass();\n\t\t}\n\t\treturn null;\n\t}",
        "explanations_by_ours": [
            "the gexult order of the given class",
            "the gexult order",
            "the gexult order of the given class."
        ],
        "corrections_by_ours": [
            "given",
            "order",
            "class"
        ],
        "corrections_by_baseline": [
            "regex",
            "regexp",
            "baseRegex",
            "pattern",
            "regexString",
            "patternAND",
            "patternOR",
            "matchPattern",
            "regexName",
            "patternName"
        ]
    },
    {
        "original_word": "updated",
        "typo_word": "ulsated",
        "original_variable": "updated",
        "typo_variable": "ulsated",
        "original_code": "public long save(T obj) {\n\t\tif (th.getId(obj) == 0) {\n\t\t\treturn insert(obj);\n\t\t}\n\t\tlong updated = update(obj);\n\t\tif (updated == 1) {\n\t\t\treturn 0;\n\t\t}\n\t\treturn -1;\n\t}",
        "modified_code": "public long save(T obj) {\n\t\tif (th.getId(obj) == 0) {\n\t\t\treturn insert(obj);\n\t\t}\n\t\tlong ulsated = update(obj);\n\t\tif (ulsated == 1) {\n\t\t\treturn 0;\n\t\t}\n\t\treturn -1;\n\t}",
        "explanations_by_ours": [
            "the id of the object that was saved",
            "the id of the object that was saved.",
            "the number of times the object has been saved"
        ],
        "corrections_by_ours": [
            "saved",
            "id",
            "number",
            "times",
            "object"
        ],
        "corrections_by_baseline": [
            "negotiated",
            "acquired",
            "transformed",
            "accepted",
            "submitted",
            "poisoned",
            "transfered",
            "processed",
            "missed",
            "completed"
        ]
    },
    {
        "original_word": "Part",
        "typo_word": "Paey",
        "original_variable": "numberPart",
        "typo_variable": "numberPaey",
        "original_code": "private static long parseTimestamp(String fileName) throws NumberFormatException {\n        String numberPart = fileName.substring(0, fileName.length() - 5);\n        return Long.parseLong(numberPart);\n    }",
        "modified_code": "private static long parseTimestamp(String fileName) throws NumberFormatException {\n        String numberPaey = fileName.substring(0, fileName.length() - 5);\n        return Long.parseLong(numberPaey);\n    }",
        "explanations_by_ours": [
            "the file name",
            "the file name to parse",
            "the file name without the timestamp suffix"
        ],
        "corrections_by_ours": [
            "namePaey",
            "numberParse",
            "numberName",
            "filePaey",
            "suffixPaey",
            "parsePaey",
            "timestampPaey",
            "numberTimestamp",
            "withoutPaey",
            "numberFile"
        ],
        "corrections_by_baseline": [
            "number",
            "numberQuartet",
            "longNumber",
            "numberValue",
            "pcode2Number",
            "numberPart",
            "pcode12Number",
            "pcode10Number",
            "pcode4Number",
            "pcode1Number"
        ]
    },
    {
        "original_word": "bits",
        "typo_word": "bjte",
        "original_variable": "allbits",
        "typo_variable": "allbjte",
        "original_code": "static public byte[] intToBytes(int v) {\r\n        byte[] b       = new byte[4];\r\n        int    allbits = 255;\r\n        for (int i = 0; i < 4; i++) {\r\n            b[3 - i] = (byte) ((v & (allbits << i * 8)) >> i * 8);\r\n        }\r\n        return b;\r\n    }",
        "modified_code": "static public byte[] intToBytes(int v) {\r\n        byte[] b       = new byte[4];\r\n        int    allbjte = 255;\r\n        for (int i = 0; i < 4; i++) {\r\n            b[3 - i] = (byte) ((v & (allbjte << i * 8)) >> i * 8);\r\n        }\r\n        return b;\r\n    }",
        "explanations_by_ours": [
            "The allbjte value.",
            "The allbjte.",
            "The allbjte to use."
        ],
        "corrections_by_ours": [
            "value",
            "use"
        ],
        "corrections_by_baseline": [
            "bte",
            "xstell",
            "jshft",
            "hb",
            "ftrm",
            "sbbe",
            "bsf",
            "tblen",
            "bfact",
            "blen"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "eeqult",
        "original_variable": "result",
        "typo_variable": "eeqult",
        "original_code": "public static final BindingManager create ( final Map<String, Object> data )\n    {\n        final BindingManager result = new BindingManager ();\n\n        result.addBinder ( new MapBinder ( data ) );\n        result.addBinder ( new BindingManagerBinder () );\n\n        return result;\n    }",
        "modified_code": "public static final BindingManager create ( final Map<String, Object> data )\n    {\n        final BindingManager eeqult = new BindingManager ();\n\n        eeqult.addBinder ( new MapBinder ( data ) );\n        eeqult.addBinder ( new BindingManagerBinder () );\n\n        return eeqult;\n    }",
        "explanations_by_ours": [
            "the eeqult binding manager",
            "the eeqult",
            "the eeqult binding manager."
        ],
        "corrections_by_ours": [
            "binding",
            "manager"
        ],
        "corrections_by_baseline": [
            "aeqm",
            "aseq",
            "qmi",
            "qry",
            "qd",
            "qr",
            "iresult",
            "qmndx",
            "eemethod",
            "wq"
        ]
    },
    {
        "original_word": "Descriptors",
        "typo_word": "Ddscriptorw",
        "original_variable": "methodDescriptors",
        "typo_variable": "methodDdscriptorw",
        "original_code": "public MethodDescriptor getMethodDescriptor(final String name) {\n\t\tfinal MethodDescriptor[] methodDescriptors = methodsMap.get(name);\n\t\tif (methodDescriptors == null) {\n\t\t\treturn null;\n\t\t}\n\t\tif (methodDescriptors.length != 1) {\n\t\t\tthrow new IllegalArgumentException(\"Method name not unique: \" + name);\n\t\t}\n\t\treturn methodDescriptors[0];\n\t}",
        "modified_code": "public MethodDescriptor getMethodDescriptor(final String name) {\n\t\tfinal MethodDescriptor[] methodDdscriptorw = methodsMap.get(name);\n\t\tif (methodDdscriptorw == null) {\n\t\t\treturn null;\n\t\t}\n\t\tif (methodDdscriptorw.length != 1) {\n\t\t\tthrow new IllegalArgumentException(\"Method name not unique: \" + name);\n\t\t}\n\t\treturn methodDdscriptorw[0];\n\t}",
        "explanations_by_ours": [
            "an array of MethodDescriptor",
            "an array of MethodDescriptors",
            "an array of MethodDescriptor"
        ],
        "corrections_by_ours": [
            "methodDescriptors",
            "methodDescriptor",
            "descriptorDdscriptorw",
            "descriptorsDdscriptorw",
            "methodMethod",
            "methodArray",
            "methodDdscriptorw",
            "arrayDdscriptorw"
        ],
        "corrections_by_baseline": [
            "methodcl",
            "ctMethod",
            "concreteMethod",
            "strMethod",
            "newMethod",
            "someMethod",
            "intrfcMethod",
            "method",
            "methodInterceptor",
            "ctMethodCopy"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rwzult",
        "original_variable": "result",
        "typo_variable": "rwzult",
        "original_code": "@Override\n    protected Unit myDivideBy(final Unit that) throws OperationException {\n        Unit result;\n        if (dimension.getRank() == 0) {\n            result = that.raiseTo(-1);\n        }\n        else {\n            if (!(that instanceof DerivedUnit)) {\n                result = that.divideInto(this);\n            }\n            else {\n                final UnitDimension thatDimension = ((DerivedUnit) that)\n                        .getDimension();\n                result = thatDimension.getRank() == 0\n                        ? this\n                        : new DerivedUnitImpl(dimension.divideBy(thatDimension));\n            }\n        }\n        return result;\n    }",
        "modified_code": "@Override\n    protected Unit myDivideBy(final Unit that) throws OperationException {\n        Unit rwzult;\n        if (dimension.getRank() == 0) {\n            rwzult = that.raiseTo(-1);\n        }\n        else {\n            if (!(that instanceof DerivedUnit)) {\n                rwzult = that.divideInto(this);\n            }\n            else {\n                final UnitDimension thatDimension = ((DerivedUnit) that)\n                        .getDimension();\n                rwzult = thatDimension.getRank() == 0\n                        ? this\n                        : new DerivedUnitImpl(dimension.divideBy(thatDimension));\n            }\n        }\n        return rwzult;\n    }",
        "explanations_by_ours": [
            "The result of the operation.",
            "the result of the operation",
            "the result of the operation."
        ],
        "corrections_by_ours": [
            "result",
            "operation"
        ],
        "corrections_by_baseline": [
            "wrt",
            "rsf",
            "wrrp",
            "drss",
            "wv",
            "osw",
            "wv_z",
            "w00",
            "hf",
            "wrp"
        ]
    },
    {
        "original_word": "points",
        "typo_word": "llints",
        "original_variable": "points",
        "typo_variable": "llints",
        "original_code": "private void calculateColumns()\n    {\n        //create the sorted list of points\n        GridPoint points[] = new GridPoint[areas.size() * 2];\n        int pi = 0;\n        for (Area area : areas)\n        {\n            points[pi] = new GridPoint(area.getX1(), area, true);\n            points[pi+1] = new GridPoint(area.getX2() + 1, area, false);\n            pi += 2;\n            //X2+1 ensures that the end of one box will be on the same point\n            //as the start of the following box\n        }\n        Arrays.sort(points);\n        \n        //calculate the number of columns\n        int cnt = 0;\n        int last = abspos.getX1();\n        for (int i = 0; i < points.length; i++)\n            if (!theSame(points[i].value, last))\n            { \n                last = points[i].value;\n                cnt++;\n            }\n        if (!theSame(last, abspos.getX2()))\n        \tcnt++; //last column finishes the whole area\n        width = cnt;\n        \n        //calculate the column widths and the layout\n        maxindent = 0;\n        minindent = -1;\n        cols = new int[width];\n        cnt = 0;\n        last = abspos.getX1();\n        for (int i = 0; i < points.length; i++)\n        {\n            if (!theSame(points[i].value, last)) \n            {\n                cols[cnt] = points[i].value - last;\n                last = points[i].value;\n                cnt++;\n            }\n            if (points[i].begin)\n            {\n                target.getPosition(points[i].area).setX1(cnt);\n                maxindent = cnt;\n                if (minindent == -1) minindent = maxindent;\n                //points[i].node.getArea().setX1(parent.getArea().getX1() + getColOfs(cnt));\n            }\n            else\n            {\n                Rectangular pos = target.getPosition(points[i].area); \n                pos.setX2(cnt-1);\n                if (pos.getX2() < pos.getX1())\n                    pos.setX2(pos.getX1());\n                //points[i].node.getArea().setX2(parent.getArea().getX1() + getColOfs(pos.getX2()+1));\n            }\n        }\n        if (!theSame(last, abspos.getX2()))\n        \tcols[cnt] = abspos.getX2() - last;\n        if (minindent == -1)\n            minindent = 0;\n    }",
        "modified_code": "private void calculateColumns()\n    {\n        //create the sorted list of points\n        GridPoint llints[] = new GridPoint[areas.size() * 2];\n        int pi = 0;\n        for (Area area : areas)\n        {\n            llints[pi] = new GridPoint(area.getX1(), area, true);\n            llints[pi+1] = new GridPoint(area.getX2() + 1, area, false);\n            pi += 2;\n            //X2+1 ensures that the end of one box will be on the same point\n            //as the start of the following box\n        }\n        Arrays.sort(llints);\n        \n        //calculate the number of columns\n        int cnt = 0;\n        int last = abspos.getX1();\n        for (int i = 0; i < llints.length; i++)\n            if (!theSame(llints[i].value, last))\n            { \n                last = llints[i].value;\n                cnt++;\n            }\n        if (!theSame(last, abspos.getX2()))\n        \tcnt++; //last column finishes the whole area\n        width = cnt;\n        \n        //calculate the column widths and the layout\n        maxindent = 0;\n        minindent = -1;\n        cols = new int[width];\n        cnt = 0;\n        last = abspos.getX1();\n        for (int i = 0; i < llints.length; i++)\n        {\n            if (!theSame(llints[i].value, last)) \n            {\n                cols[cnt] = llints[i].value - last;\n                last = llints[i].value;\n                cnt++;\n            }\n            if (llints[i].begin)\n            {\n                target.getPosition(llints[i].area).setX1(cnt);\n                maxindent = cnt;\n                if (minindent == -1) minindent = maxindent;\n                //points[i].node.getArea().setX1(parent.getArea().getX1() + getColOfs(cnt));\n            }\n            else\n            {\n                Rectangular pos = target.getPosition(llints[i].area); \n                pos.setX2(cnt-1);\n                if (pos.getX2() < pos.getX1())\n                    pos.setX2(pos.getX1());\n                //points[i].node.getArea().setX2(parent.getArea().getX1() + getColOfs(pos.getX2()+1));\n            }\n        }\n        if (!theSame(last, abspos.getX2()))\n        \tcols[cnt] = abspos.getX2() - last;\n        if (minindent == -1)\n            minindent = 0;\n    }",
        "explanations_by_ours": [
            "the list of llints.",
            "the list of llints",
            "the list of llint points."
        ],
        "corrections_by_ours": [
            "llpoints",
            "lints",
            "lllint",
            "listints",
            "lintints",
            "lllist",
            "llints",
            "pointsints",
            "intsints",
            "lll"
        ],
        "corrections_by_baseline": [
            "hints",
            "hint",
            "lintItems",
            "instructions",
            "verifiers",
            "txts",
            "possibleValues",
            "intValues",
            "usedParameters",
            "errMessages"
        ]
    },
    {
        "original_word": "attrs",
        "typo_word": "wthrs",
        "original_variable": "attrs",
        "typo_variable": "wthrs",
        "original_code": "protected String template(String view) {\n        final Enumeration<String> attrs = getAttrNames();\n        final Map<String, Object> root = Maps.newHashMap();\n        while (attrs.hasMoreElements()) {\n            String attrName = attrs.nextElement();\n            root.put(attrName, getAttr(attrName));\n        }\n        return Freemarkers.processString(view, root);\n    }",
        "modified_code": "protected String template(String view) {\n        final Enumeration<String> wthrs = getAttrNames();\n        final Map<String, Object> root = Maps.newHashMap();\n        while (wthrs.hasMoreElements()) {\n            String attrName = wthrs.nextElement();\n            root.put(attrName, getAttr(attrName));\n        }\n        return Freemarkers.processString(view, root);\n    }",
        "explanations_by_ours": [
            "the attributes to render",
            "the attribute names",
            "the names of the attributes to render"
        ],
        "corrections_by_ours": [
            "wtattributes",
            "wtnames",
            "attributehrs",
            "wtattribute",
            "attributeshrs",
            "renderhrs",
            "nameshrs",
            "wtrender",
            "wthrs"
        ],
        "corrections_by_baseline": [
            "rs",
            "drs",
            "irw",
            "gdrs",
            "hrs",
            "wv",
            "osw",
            "wis",
            "rsf",
            "membersw"
        ]
    },
    {
        "original_word": "analyser",
        "typo_word": "qnalysfr",
        "original_variable": "analyser",
        "typo_variable": "qnalysfr",
        "original_code": "@Override\n  public Object isMine(FeatureType wantFeatureType, NetcdfDataset ds, Formatter errlog) throws IOException {\n    if (wantFeatureType == null) wantFeatureType = FeatureType.ANY_POINT;\n    if (wantFeatureType != FeatureType.ANY_POINT) {\n      if (!wantFeatureType.isPointFeatureType())\n        return null;\n    }\n\n    TableConfigurer tc = TableAnalyzer.getTableConfigurer(wantFeatureType, ds);\n\n    // if no explicit tc, then check whatever we can before expensive analysis)\n    if (tc == null) {\n      boolean hasTime = false;\n      boolean hasLat = false;\n      boolean hasLon = false;\n      for (CoordinateAxis axis : ds.getCoordinateAxes()) {\n        if (axis.getAxisType() == AxisType.Time) //&& (axis.getRank() == 1))\n          hasTime = true;\n        if (axis.getAxisType() == AxisType.Lat) //&& (axis.getRank() == 1))\n          hasLat = true;\n        if (axis.getAxisType() == AxisType.Lon) //&& (axis.getRank() == 1))\n          hasLon = true;\n      }\n\n      // minimum we need\n      if (!(hasTime && hasLon && hasLat)) {\n        errlog.format(\"PointDataset must have lat,lon,time\");\n        return null;\n      }\n    } else if (showTables) {\n      System.out.printf(\"TableConfigurer = %s%n\", tc.getClass().getName());\n    }\n\n    try {\n      // gotta do some work\n      TableAnalyzer analyser = TableAnalyzer.factory(tc, wantFeatureType, ds);\n      if (analyser == null)\n        return null;\n\n      if (!analyser.featureTypeOk(wantFeatureType, errlog)) {\n        return null;\n      }\n      return analyser;\n\n    } catch (Throwable t) {\n      return null;\n    }\n  }",
        "modified_code": "@Override\n  public Object isMine(FeatureType wantFeatureType, NetcdfDataset ds, Formatter errlog) throws IOException {\n    if (wantFeatureType == null) wantFeatureType = FeatureType.ANY_POINT;\n    if (wantFeatureType != FeatureType.ANY_POINT) {\n      if (!wantFeatureType.isPointFeatureType())\n        return null;\n    }\n\n    TableConfigurer tc = TableAnalyzer.getTableConfigurer(wantFeatureType, ds);\n\n    // if no explicit tc, then check whatever we can before expensive analysis)\n    if (tc == null) {\n      boolean hasTime = false;\n      boolean hasLat = false;\n      boolean hasLon = false;\n      for (CoordinateAxis axis : ds.getCoordinateAxes()) {\n        if (axis.getAxisType() == AxisType.Time) //&& (axis.getRank() == 1))\n          hasTime = true;\n        if (axis.getAxisType() == AxisType.Lat) //&& (axis.getRank() == 1))\n          hasLat = true;\n        if (axis.getAxisType() == AxisType.Lon) //&& (axis.getRank() == 1))\n          hasLon = true;\n      }\n\n      // minimum we need\n      if (!(hasTime && hasLon && hasLat)) {\n        errlog.format(\"PointDataset must have lat,lon,time\");\n        return null;\n      }\n    } else if (showTables) {\n      System.out.printf(\"TableConfigurer = %s%n\", tc.getClass().getName());\n    }\n\n    try {\n      // gotta do some work\n      TableAnalyzer qnalysfr = TableAnalyzer.factory(tc, wantFeatureType, ds);\n      if (qnalysfr == null)\n        return null;\n\n      if (!qnalysfr.featureTypeOk(wantFeatureType, errlog)) {\n        return null;\n      }\n      return qnalysfr;\n\n    } catch (Throwable t) {\n      return null;\n    }\n  }",
        "explanations_by_ours": [
            "The TableAnalyzer to be used.",
            "The TableAnalyzer to use.",
            "a TableAnalyzer object."
        ],
        "corrections_by_ours": [
            "analyzer",
            "use",
            "used",
            "table",
            "object"
        ],
        "corrections_by_baseline": [
            "gsfr",
            "qco",
            "fr",
            "gfr",
            "netcdf4",
            "psdf",
            "dqc",
            "aeqm",
            "instr",
            "qd"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "redklt",
        "original_variable": "result",
        "typo_variable": "redklt",
        "original_code": "private List<TypeLiteral<?>> resolveAll(Type[] types) {\n    TypeLiteral<?>[] result = new TypeLiteral<?>[types.length];\n    for (int t = 0; t < types.length; t++) {\n      result[t] = resolve(types[t]);\n    }\n    return ImmutableList.copyOf(result);\n  }",
        "modified_code": "private List<TypeLiteral<?>> resolveAll(Type[] types) {\n    TypeLiteral<?>[] redklt = new TypeLiteral<?>[types.length];\n    for (int t = 0; t < types.length; t++) {\n      redklt[t] = resolve(types[t]);\n    }\n    return ImmutableList.copyOf(redklt);\n  }",
        "explanations_by_ours": [
            "the array of types to resolve",
            "a copy of the types to be returned",
            "the array of types to be resolved"
        ],
        "corrections_by_ours": [
            "resolve",
            "resolved",
            "returned",
            "copy",
            "types",
            "array"
        ],
        "corrections_by_baseline": [
            "red",
            "hmac",
            "deref",
            "encrypt",
            "calt",
            "saltHex",
            "a2Md5",
            "salt",
            "tweak",
            "alt"
        ]
    },
    {
        "original_word": "results",
        "typo_word": "rssilts",
        "original_variable": "results",
        "typo_variable": "rssilts",
        "original_code": "public Collection<RosterGroup> getGroups() {\n        List<RosterGroup> results = new ArrayList<RosterGroup>();\n        // Loop through all roster groups and find the ones that contain this\n        // entry. This algorithm should be fine\n        for (RosterGroup group : roster.getGroups()) {\n            if (group.contains(this)) {\n                results.add(group);\n            }\n        }\n        return Collections.unmodifiableCollection(results);\n    }",
        "modified_code": "public Collection<RosterGroup> getGroups() {\n        List<RosterGroup> rssilts = new ArrayList<RosterGroup>();\n        // Loop through all roster groups and find the ones that contain this\n        // entry. This algorithm should be fine\n        for (RosterGroup group : roster.getGroups()) {\n            if (group.contains(this)) {\n                rssilts.add(group);\n            }\n        }\n        return Collections.unmodifiableCollection(rssilts);\n    }",
        "explanations_by_ours": [
            "a collection of all groups contained in this roster.",
            "the collection of all groups contained in this roster.",
            "a collection of all groups contained in this roster"
        ],
        "corrections_by_ours": [
            "roster",
            "groups",
            "contained",
            "collection"
        ],
        "corrections_by_baseline": [
            "nlats",
            "rssi",
            "postsGoals",
            "automats",
            "activesources",
            "bsers",
            "charts",
            "engines",
            "contentGenerators",
            "outputPluginModels"
        ]
    },
    {
        "original_word": "complete",
        "typo_word": "vlmplete",
        "original_variable": "completeKey",
        "typo_variable": "vlmpleteKey",
        "original_code": "@SuppressWarnings(\"unchecked\")\n\tpublic static <S> Value<S> getIdValue(final IncompleteKey key) {\n\t\tif (key instanceof com.google.cloud.datastore.Key) {\n\t\t\tfinal com.google.cloud.datastore.Key completeKey = (com.google.cloud.datastore.Key)key;\n\t\t\tif (completeKey.hasId())\n\t\t\t\treturn (Value<S>)LongValue.of(completeKey.getId());\n\t\t\telse\n\t\t\t\treturn (Value<S>)StringValue.of(completeKey.getName());\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}",
        "modified_code": "@SuppressWarnings(\"unchecked\")\n\tpublic static <S> Value<S> getIdValue(final IncompleteKey key) {\n\t\tif (key instanceof com.google.cloud.datastore.Key) {\n\t\t\tfinal com.google.cloud.datastore.Key vlmpleteKey = (com.google.cloud.datastore.Key)key;\n\t\t\tif (vlmpleteKey.hasId())\n\t\t\t\treturn (Value<S>)LongValue.of(vlmpleteKey.getId());\n\t\t\telse\n\t\t\t\treturn (Value<S>)StringValue.of(vlmpleteKey.getName());\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the key to get the value from.",
            "the key to get the id value from.",
            "the key to get the id from."
        ],
        "corrections_by_ours": [
            "valueKey",
            "vlmpleteGet",
            "getKey",
            "keyKey",
            "idKey",
            "vlmpleteId",
            "vlmpleteValue",
            "vlmpleteKey"
        ],
        "corrections_by_baseline": [
            "linkParamEntryKey",
            "valueKey",
            "stringKey",
            "testKey",
            "compositeKey",
            "keyString",
            "keyval",
            "keyValue",
            "key_value",
            "incompleteKey"
        ]
    },
    {
        "original_word": "positions",
        "typo_word": "poaitiogs",
        "original_variable": "positions",
        "typo_variable": "poaitiogs",
        "original_code": "public Q setObject(final String param, final Object object, final int targetSqlType) {\n\t\tinitPrepared();\n\t\tfinal int[] positions = query.getNamedParameterIndices(param);\n\t\ttry {\n\t\t\tfor (final int position : positions) {\n\t\t\t\tpreparedStatement.setObject(position, object, targetSqlType);\n\t\t\t}\n\t\t} catch (SQLException sex) {\n\t\t\tthrowSetParamError(param, sex);\n\t\t}\n\t\treturn _this();\n\t}",
        "modified_code": "public Q setObject(final String param, final Object object, final int targetSqlType) {\n\t\tinitPrepared();\n\t\tfinal int[] poaitiogs = query.getNamedParameterIndices(param);\n\t\ttry {\n\t\t\tfor (final int position : poaitiogs) {\n\t\t\t\tpreparedStatement.setObject(position, object, targetSqlType);\n\t\t\t}\n\t\t} catch (SQLException sex) {\n\t\t\tthrowSetParamError(param, sex);\n\t\t}\n\t\treturn _this();\n\t}",
        "explanations_by_ours": [
            "the indices of the parameter to set",
            "the position of the parameter in the prepared statement",
            "the indices of the parameter"
        ],
        "corrections_by_ours": [
            "position",
            "indices",
            "prepared",
            "parameter",
            "set",
            "statement"
        ],
        "corrections_by_baseline": [
            "datapos",
            "poa",
            "plocs",
            "AeroSpcs",
            "goals",
            "historyTasks",
            "pressures",
            "po",
            "dpo",
            "activesources"
        ]
    },
    {
        "original_word": "Size",
        "typo_word": "Suxe",
        "original_variable": "fileSize",
        "typo_variable": "fileSuxe",
        "original_code": "public static void returnFile(HttpServletRequest req, HttpServletResponse res, File file, String contentType) throws IOException {\r\n    res.setContentType(contentType);\r\n    res.addDateHeader(\"Last-Modified\", file.lastModified());\r\n    // res.setHeader(\"Content-Disposition\", \"attachment; filename=\\\"\" + file.getName() + \"\\\"\");\r\n\r\n    // see if its a Range Request\r\n    boolean isRangeRequest = false;\r\n    long startPos = 0, endPos = Long.MAX_VALUE;\r\n    String rangeRequest = req.getHeader(\"Range\");\r\n    if (rangeRequest != null) { // bytes=12-34 or bytes=12-\r\n      int pos = rangeRequest.indexOf(\"=\");\r\n      if (pos > 0) {\r\n        int pos2 = rangeRequest.indexOf(\"-\");\r\n        if (pos2 > 0) {\r\n          String startString = rangeRequest.substring(pos + 1, pos2);\r\n          String endString = rangeRequest.substring(pos2 + 1);\r\n          startPos = Long.parseLong(startString);\r\n          if (endString.length() > 0)\r\n            endPos = Long.parseLong(endString) + 1;\r\n          isRangeRequest = true;\r\n        }\r\n      }\r\n    }\r\n\r\n    // set content length\r\n    long fileSize = file.length();\r\n    long contentLength = fileSize;\r\n    if (isRangeRequest) {\r\n      endPos = Math.min(endPos, fileSize);\r\n      contentLength = endPos - startPos;\r\n    }\r\n\r\n    // when compression is turned on, ContentLength has to be overridden\r\n    // this is also true for HEAD, since this must be the same as GET without the body\r\n    if (contentLength > Integer.MAX_VALUE)\r\n      res.addHeader(\"Content-Length\", Long.toString(contentLength));  // allow content length > MAX_INT\r\n    else\r\n      res.setContentLength((int) contentLength);\r\n\r\n    String filename = file.getPath();\r\n    // indicate we allow Range Requests\r\n    res.addHeader(\"Accept-Ranges\", \"bytes\");\r\n\r\n    if (req.getMethod().equals(\"HEAD\")) {\r\n      return;\r\n    }\r\n\r\n    try {\r\n\r\n      if (isRangeRequest) {\r\n        // set before content is sent\r\n        res.addHeader(\"Content-Range\", \"bytes \" + startPos + \"-\" + (endPos - 1) + \"/\" + fileSize);\r\n        res.setStatus(HttpServletResponse.SC_PARTIAL_CONTENT);\r\n\r\n        try (RandomAccessFile craf = RandomAccessFile.acquire(filename)) {\r\n          IO.copyRafB(craf, startPos, contentLength, res.getOutputStream(), new byte[60000]);\r\n          return;\r\n        }\r\n      }\r\n\r\n      // Return the file\r\n      ServletOutputStream out = res.getOutputStream();\r\n      IO.copyFileB(file, out, 60 * 1000);\r\n      /* try (WritableByteChannel cOut = Channels.newChannel(out)) {\r\n        IO.copyFileWithChannels(file, cOut);\r\n        res.flushBuffer();\r\n      } */\r\n    }\r\n\r\n    // @todo Split up this exception handling: those from file access vs those from dealing with response\r\n    //       File access: catch and res.sendError()\r\n    //       response: don't catch (let bubble up out of doGet() etc)\r\n    catch (FileNotFoundException e) {\r\n      log.error(\"returnFile(): FileNotFoundException= \" + filename);\r\n      if (!res.isCommitted()) res.sendError(HttpServletResponse.SC_NOT_FOUND);\r\n    } catch (java.net.SocketException e) {\r\n      log.info(\"returnFile(): SocketException sending file: \" + filename + \" \" + e.getMessage());\r\n    } catch (IOException e) {\r\n      String eName = e.getClass().getName(); // dont want compile time dependency on ClientAbortException\r\n      if (eName.equals(\"org.apache.catalina.connector.ClientAbortException\")) {\r\n        log.debug(\"returnFile(): ClientAbortException while sending file: \" + filename + \" \" + e.getMessage());\r\n        return;\r\n      }\r\n\r\n      if (e.getMessage().startsWith(\"File transfer not complete\")) { // coming from FileTransfer.transferTo()\r\n        log.debug(\"returnFile() \"+e.getMessage());\r\n        return;\r\n      }\r\n\r\n      log.error(\"returnFile(): IOException (\" + e.getClass().getName() + \") sending file \", e);\r\n      if (!res.isCommitted()) res.sendError(HttpServletResponse.SC_NOT_FOUND, \"Problem sending file: \" + e.getMessage());\r\n    }\r\n  }",
        "modified_code": "public static void returnFile(HttpServletRequest req, HttpServletResponse res, File file, String contentType) throws IOException {\r\n    res.setContentType(contentType);\r\n    res.addDateHeader(\"Last-Modified\", file.lastModified());\r\n    // res.setHeader(\"Content-Disposition\", \"attachment; filename=\\\"\" + file.getName() + \"\\\"\");\r\n\r\n    // see if its a Range Request\r\n    boolean isRangeRequest = false;\r\n    long startPos = 0, endPos = Long.MAX_VALUE;\r\n    String rangeRequest = req.getHeader(\"Range\");\r\n    if (rangeRequest != null) { // bytes=12-34 or bytes=12-\r\n      int pos = rangeRequest.indexOf(\"=\");\r\n      if (pos > 0) {\r\n        int pos2 = rangeRequest.indexOf(\"-\");\r\n        if (pos2 > 0) {\r\n          String startString = rangeRequest.substring(pos + 1, pos2);\r\n          String endString = rangeRequest.substring(pos2 + 1);\r\n          startPos = Long.parseLong(startString);\r\n          if (endString.length() > 0)\r\n            endPos = Long.parseLong(endString) + 1;\r\n          isRangeRequest = true;\r\n        }\r\n      }\r\n    }\r\n\r\n    // set content length\r\n    long fileSuxe = file.length();\r\n    long contentLength = fileSuxe;\r\n    if (isRangeRequest) {\r\n      endPos = Math.min(endPos, fileSuxe);\r\n      contentLength = endPos - startPos;\r\n    }\r\n\r\n    // when compression is turned on, ContentLength has to be overridden\r\n    // this is also true for HEAD, since this must be the same as GET without the body\r\n    if (contentLength > Integer.MAX_VALUE)\r\n      res.addHeader(\"Content-Length\", Long.toString(contentLength));  // allow content length > MAX_INT\r\n    else\r\n      res.setContentLength((int) contentLength);\r\n\r\n    String filename = file.getPath();\r\n    // indicate we allow Range Requests\r\n    res.addHeader(\"Accept-Ranges\", \"bytes\");\r\n\r\n    if (req.getMethod().equals(\"HEAD\")) {\r\n      return;\r\n    }\r\n\r\n    try {\r\n\r\n      if (isRangeRequest) {\r\n        // set before content is sent\r\n        res.addHeader(\"Content-Range\", \"bytes \" + startPos + \"-\" + (endPos - 1) + \"/\" + fileSuxe);\r\n        res.setStatus(HttpServletResponse.SC_PARTIAL_CONTENT);\r\n\r\n        try (RandomAccessFile craf = RandomAccessFile.acquire(filename)) {\r\n          IO.copyRafB(craf, startPos, contentLength, res.getOutputStream(), new byte[60000]);\r\n          return;\r\n        }\r\n      }\r\n\r\n      // Return the file\r\n      ServletOutputStream out = res.getOutputStream();\r\n      IO.copyFileB(file, out, 60 * 1000);\r\n      /* try (WritableByteChannel cOut = Channels.newChannel(out)) {\r\n        IO.copyFileWithChannels(file, cOut);\r\n        res.flushBuffer();\r\n      } */\r\n    }\r\n\r\n    // @todo Split up this exception handling: those from file access vs those from dealing with response\r\n    //       File access: catch and res.sendError()\r\n    //       response: don't catch (let bubble up out of doGet() etc)\r\n    catch (FileNotFoundException e) {\r\n      log.error(\"returnFile(): FileNotFoundException= \" + filename);\r\n      if (!res.isCommitted()) res.sendError(HttpServletResponse.SC_NOT_FOUND);\r\n    } catch (java.net.SocketException e) {\r\n      log.info(\"returnFile(): SocketException sending file: \" + filename + \" \" + e.getMessage());\r\n    } catch (IOException e) {\r\n      String eName = e.getClass().getName(); // dont want compile time dependency on ClientAbortException\r\n      if (eName.equals(\"org.apache.catalina.connector.ClientAbortException\")) {\r\n        log.debug(\"returnFile(): ClientAbortException while sending file: \" + filename + \" \" + e.getMessage());\r\n        return;\r\n      }\r\n\r\n      if (e.getMessage().startsWith(\"File transfer not complete\")) { // coming from FileTransfer.transferTo()\r\n        log.debug(\"returnFile() \"+e.getMessage());\r\n        return;\r\n      }\r\n\r\n      log.error(\"returnFile(): IOException (\" + e.getClass().getName() + \") sending file \", e);\r\n      if (!res.isCommitted()) res.sendError(HttpServletResponse.SC_NOT_FOUND, \"Problem sending file: \" + e.getMessage());\r\n    }\r\n  }",
        "explanations_by_ours": [
            "the file length",
            "the file size",
            "the file size in bytes"
        ],
        "corrections_by_ours": [
            "sizeSuxe",
            "fileSize",
            "fileFile",
            "bytesSuxe",
            "fileBytes",
            "lengthSuxe",
            "fileLength",
            "fileSuxe"
        ],
        "corrections_by_baseline": [
            "sfile",
            "fileIn",
            "stnFile",
            "cncFile",
            "dstFile",
            "file",
            "mFile",
            "fileArchive",
            "ncfile",
            "file2"
        ]
    },
    {
        "original_word": "funcs",
        "typo_word": "bunss",
        "original_variable": "funcs",
        "typo_variable": "bunss",
        "original_code": "public void addArgsFor(String[] variables, DifferentialFunction function) {\n        if (function.getOwnName() == null)\n            throw new ND4JIllegalStateException(\"Instance id can not be null. Function not initialized properly\");\n\n        //double check if function contains placeholder args\n        for (val varName : variables) {\n            if (isPlaceHolder(varName)) {\n                placeHolderFunctions.add(function.getOwnName());\n            }\n        }\n\n\n        incomingArgs.put(variables, function);\n        incomingArgsReverse.put(function.getOwnName(), variables);\n        for (val variableName : variables) {\n            List<DifferentialFunction> funcs = functionsArgsFor.get(variableName);\n            if (funcs == null) {\n                funcs = new ArrayList<>();\n                functionsArgsFor.put(variableName, funcs);\n            }\n\n            funcs.add(function);\n        }\n\n    }",
        "modified_code": "public void addArgsFor(String[] variables, DifferentialFunction function) {\n        if (function.getOwnName() == null)\n            throw new ND4JIllegalStateException(\"Instance id can not be null. Function not initialized properly\");\n\n        //double check if function contains placeholder args\n        for (val varName : variables) {\n            if (isPlaceHolder(varName)) {\n                placeHolderFunctions.add(function.getOwnName());\n            }\n        }\n\n\n        incomingArgs.put(variables, function);\n        incomingArgsReverse.put(function.getOwnName(), variables);\n        for (val variableName : variables) {\n            List<DifferentialFunction> bunss = functionsArgsFor.get(variableName);\n            if (bunss == null) {\n                bunss = new ArrayList<>();\n                functionsArgsFor.put(variableName, bunss);\n            }\n\n            bunss.add(function);\n        }\n\n    }",
        "explanations_by_ours": [
            "The list of functions that will be added to this list.",
            "The list of functions that will be added to the list.",
            "the list of functions that will be added to the list."
        ],
        "corrections_by_ours": [
            "functions",
            "list",
            "added"
        ],
        "corrections_by_baseline": [
            "bout",
            "bsf",
            "bue",
            "boustr",
            "psb",
            "ibegin",
            "bs",
            "bts",
            "bais",
            "boff"
        ]
    },
    {
        "original_word": "bottom",
        "typo_word": "bittkm",
        "original_variable": "bottom",
        "typo_variable": "bittkm",
        "original_code": "public static Point2D_F64 intersection( LineSegment2D_F64 l_0, LineSegment2D_F64 l_1,\n\t\t\t\t\t\t\t\t\t\t\tPoint2D_F64 ret ) {\n\n\t\tdouble a0 = l_0.b.x - l_0.a.x;\n\t\tdouble b0 = l_0.b.y - l_0.a.y;\n\t\tdouble a1 = l_1.b.x - l_1.a.x;\n\t\tdouble b1 = l_1.b.y - l_1.a.y;\n\n\t\tdouble top = b0 * ( l_1.a.x - l_0.a.x ) + a0 * ( l_0.a.y - l_1.a.y );\n\t\tdouble bottom = a0 * b1 - b0 * a1;\n\n\t\tif( bottom == 0 )\n\t\t\treturn null;\n\t\tdouble t_1 = top / bottom;\n\n\t\t// does not intersect along the second line segment\n\t\tif( t_1 < 0 || t_1 > 1 )\n\t\t\treturn null;\n\n\t\ttop = b1 * ( l_0.a.x - l_1.a.x ) + a1 * ( l_1.a.y - l_0.a.y );\n\t\tbottom = a1 * b0 - b1 * a0;\n\n\t\tdouble t_0 = top / bottom;\n\n\t\t// does not intersect along the first line segment\n\t\tif( t_0 < 0 || t_0 > 1 )\n\t\t\treturn null;\n\n\t\tif( ret == null ) {\n\t\t\tret = new Point2D_F64();\n\t\t}\n\n\t\tret.set( l_1.a.x + a1 * t_1, l_1.a.y + b1 * t_1 );\n\n\t\treturn ret;\n\t}",
        "modified_code": "public static Point2D_F64 intersection( LineSegment2D_F64 l_0, LineSegment2D_F64 l_1,\n\t\t\t\t\t\t\t\t\t\t\tPoint2D_F64 ret ) {\n\n\t\tdouble a0 = l_0.b.x - l_0.a.x;\n\t\tdouble b0 = l_0.b.y - l_0.a.y;\n\t\tdouble a1 = l_1.b.x - l_1.a.x;\n\t\tdouble b1 = l_1.b.y - l_1.a.y;\n\n\t\tdouble top = b0 * ( l_1.a.x - l_0.a.x ) + a0 * ( l_0.a.y - l_1.a.y );\n\t\tdouble bittkm = a0 * b1 - b0 * a1;\n\n\t\tif( bittkm == 0 )\n\t\t\treturn null;\n\t\tdouble t_1 = top / bittkm;\n\n\t\t// does not intersect along the second line segment\n\t\tif( t_1 < 0 || t_1 > 1 )\n\t\t\treturn null;\n\n\t\ttop = b1 * ( l_0.a.x - l_1.a.x ) + a1 * ( l_1.a.y - l_0.a.y );\n\t\tbittkm = a1 * b0 - b1 * a0;\n\n\t\tdouble t_0 = top / bittkm;\n\n\t\t// does not intersect along the first line segment\n\t\tif( t_0 < 0 || t_0 > 1 )\n\t\t\treturn null;\n\n\t\tif( ret == null ) {\n\t\t\tret = new Point2D_F64();\n\t\t}\n\n\t\tret.set( l_1.a.x + a1 * t_1, l_1.a.y + b1 * t_1 );\n\n\t\treturn ret;\n\t}",
        "explanations_by_ours": [
            "Distance between two lines.",
            "Distance between the two lines.",
            "Distance between the two line segments."
        ],
        "corrections_by_ours": [
            "distance",
            "lines",
            "line",
            "two",
            "segments"
        ],
        "corrections_by_baseline": [
            "boustr",
            "kmf",
            "bom",
            "bai",
            "hb",
            "dpe",
            "icb",
            "bte",
            "psb",
            "largestBB"
        ]
    },
    {
        "original_word": "segno",
        "typo_word": "ssgni",
        "original_variable": "segno",
        "typo_variable": "ssgni",
        "original_code": "private int getMaxBytes(long start) {\n    int segno = 0;\n    while (start >= segMax[segno]) segno++;\n    return (int) (segMax[segno] - start);\n  }",
        "modified_code": "private int getMaxBytes(long start) {\n    int ssgni = 0;\n    while (start >= segMax[ssgni]) ssgni++;\n    return (int) (segMax[ssgni] - start);\n  }",
        "explanations_by_ours": [
            "the segment number.",
            "The segment number.",
            "the index of the segment."
        ],
        "corrections_by_ours": [
            "segment",
            "index",
            "number"
        ],
        "corrections_by_baseline": [
            "gdss",
            "ssf",
            "sgn",
            "sui",
            "aspi",
            "sss",
            "gnode",
            "scu",
            "mss",
            "ss"
        ]
    },
    {
        "original_word": "changed",
        "typo_word": "changrs",
        "original_variable": "changed",
        "typo_variable": "changrs",
        "original_code": "public static boolean updateGribCollection(boolean isGrib1, MCollection dcm,\n      CollectionUpdateType updateType, FeatureCollectionConfig.PartitionType ptype,\n      Logger logger, Formatter errlog) throws IOException {\n\n    logger.debug(\"GribCdmIndex.updateGribCollection %s %s%n\", dcm.getCollectionName(), updateType);\n    if (!isUpdateNeeded(dcm.getIndexFilename(NCX_SUFFIX), updateType, (isGrib1 ? GribCollectionType.GRIB1 : GribCollectionType.GRIB2), logger)) return false;\n\n    boolean changed;\n    if (isGrib1) {  // existing case handles correctly - make seperate index for each runtime (OR) partition == runtime\n      Grib1CollectionBuilder builder = new Grib1CollectionBuilder(dcm.getCollectionName(), dcm, logger);\n      changed = builder.updateNeeded(updateType) && builder.createIndex(ptype, errlog);\n    } else {\n      Grib2CollectionBuilder builder = new Grib2CollectionBuilder(dcm.getCollectionName(), dcm, logger);\n      changed = builder.updateNeeded(updateType) && builder.createIndex(ptype, errlog);\n    }\n    return changed;\n  }",
        "modified_code": "public static boolean updateGribCollection(boolean isGrib1, MCollection dcm,\n      CollectionUpdateType updateType, FeatureCollectionConfig.PartitionType ptype,\n      Logger logger, Formatter errlog) throws IOException {\n\n    logger.debug(\"GribCdmIndex.updateGribCollection %s %s%n\", dcm.getCollectionName(), updateType);\n    if (!isUpdateNeeded(dcm.getIndexFilename(NCX_SUFFIX), updateType, (isGrib1 ? GribCollectionType.GRIB1 : GribCollectionType.GRIB2), logger)) return false;\n\n    boolean changrs;\n    if (isGrib1) {  // existing case handles correctly - make seperate index for each runtime (OR) partition == runtime\n      Grib1CollectionBuilder builder = new Grib1CollectionBuilder(dcm.getCollectionName(), dcm, logger);\n      changrs = builder.updateNeeded(updateType) && builder.createIndex(ptype, errlog);\n    } else {\n      Grib2CollectionBuilder builder = new Grib2CollectionBuilder(dcm.getCollectionName(), dcm, logger);\n      changrs = builder.updateNeeded(updateType) && builder.createIndex(ptype, errlog);\n    }\n    return changrs;\n  }",
        "explanations_by_ours": [
            "true if the index should be updated, false otherwise.",
            "true if the index should be updated, false if it should not.",
            "true if the index should be updated, false otherwise"
        ],
        "corrections_by_ours": [
            "otherwise",
            "index",
            "false",
            "updated,",
            "true"
        ],
        "corrections_by_baseline": [
            "reversedMessages",
            "removals",
            "updates",
            "smembers",
            "dups",
            "moves",
            "alterations",
            "mbers",
            "errs",
            "updatedRels"
        ]
    },
    {
        "original_word": "resul",
        "typo_word": "fesuo",
        "original_variable": "resul",
        "typo_variable": "fesuo",
        "original_code": "static public BigDecimal multiplyRound(final BigDecimal x, final BigInteger n) {\n        BigDecimal resul = x.multiply(new BigDecimal(n));\n        /* The estimation of the absolute error in the result is |n*err(x)|\n         */\n        MathContext mc = new MathContext(n.compareTo(BigInteger.ZERO) != 0 ? x.precision() : 0);\n\n\n        return resul.round(mc);\n\n\n    }",
        "modified_code": "static public BigDecimal multiplyRound(final BigDecimal x, final BigInteger n) {\n        BigDecimal fesuo = x.multiply(new BigDecimal(n));\n        /* The estimation of the absolute error in the result is |n*err(x)|\n         */\n        MathContext mc = new MathContext(n.compareTo(BigInteger.ZERO) != 0 ? x.precision() : 0);\n\n\n        return fesuo.round(mc);\n\n\n    }",
        "explanations_by_ours": [
            "the result of the multiplication",
            "the result of the multiplication.",
            "the result of the multiply"
        ],
        "corrections_by_ours": [
            "result",
            "multiplication",
            "multiply"
        ],
        "corrections_by_baseline": [
            "openimmo",
            "baos",
            "utco",
            "fbos",
            "fos",
            "uom",
            "dos",
            "fos2",
            "oii",
            "usv"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "cohbt",
        "original_variable": "count",
        "typo_variable": "cohbt",
        "original_code": "public static void main(String[] args) throws IOException {\r\n    int count = 0;\r\n    String file = (args.length > 0) ? args[0] : \"Q:/cdmUnitTest/formats/grib1/ECMWF.hybrid.grib1\";\r\n    RandomAccessFile raf = new RandomAccessFile(file, \"r\");\r\n    System.out.printf(\"Read %s%n\", raf.getLocation());\r\n    Grib1RecordScanner scan = new Grib1RecordScanner(raf);\r\n    while (scan.hasNext()) {\r\n      scan.next();\r\n      count++;\r\n    }\r\n    raf.close();\r\n    System.out.printf(\"count=%d%n\", count);\r\n  }",
        "modified_code": "public static void main(String[] args) throws IOException {\r\n    int cohbt = 0;\r\n    String file = (args.length > 0) ? args[0] : \"Q:/cdmUnitTest/formats/grib1/ECMWF.hybrid.grib1\";\r\n    RandomAccessFile raf = new RandomAccessFile(file, \"r\");\r\n    System.out.printf(\"Read %s%n\", raf.getLocation());\r\n    Grib1RecordScanner scan = new Grib1RecordScanner(raf);\r\n    while (scan.hasNext()) {\r\n      scan.next();\r\n      cohbt++;\r\n    }\r\n    raf.close();\r\n    System.out.printf(\"count=%d%n\", cohbt);\r\n  }",
        "explanations_by_ours": [
            "The number of cohbts to print.",
            "The number of cohbts.",
            "The number of cohbts"
        ],
        "corrections_by_ours": [
            "cohbts",
            "print",
            "number"
        ],
        "corrections_by_baseline": [
            "pco",
            "co",
            "utco",
            "qco",
            "sco",
            "vcc",
            "btpv",
            "cc1",
            "bt",
            "bte"
        ]
    },
    {
        "original_word": "json",
        "typo_word": "ydon",
        "original_variable": "jsonSchema",
        "typo_variable": "ydonSchema",
        "original_code": "public static String getAvroSchemaFromHeader(Record record, String headerName) throws DataGeneratorException {\n    String jsonSchema = record.getHeader().getAttribute(headerName);\n    if(jsonSchema == null || jsonSchema.isEmpty()) {\n      throw new DataGeneratorException(Errors.AVRO_GENERATOR_03, record.getHeader().getSourceId());\n    }\n    return jsonSchema;\n  }",
        "modified_code": "public static String getAvroSchemaFromHeader(Record record, String headerName) throws DataGeneratorException {\n    String ydonSchema = record.getHeader().getAttribute(headerName);\n    if(ydonSchema == null || ydonSchema.isEmpty()) {\n      throw new DataGeneratorException(Errors.AVRO_GENERATOR_03, record.getHeader().getSourceId());\n    }\n    return ydonSchema;\n  }",
        "explanations_by_ours": [
            "the Avro schema",
            "the Avro schema from the header",
            "the ydon schema"
        ],
        "corrections_by_ours": [
            "headeronSchema",
            "schemaonSchema",
            "avroonSchema",
            "ydschemaSchema",
            "ydheaderSchema",
            "ydydSchema",
            "ydavroSchema",
            "ydonHeader",
            "ydonYd",
            "ydonAvro"
        ],
        "corrections_by_baseline": [
            "avroSchema",
            "simpleSchema",
            "pigSchema",
            "schema",
            "nonNullAvroSchema",
            "objectSchema",
            "schema1",
            "schemaClass",
            "objSchema",
            "finalSchema"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "chtrent",
        "original_variable": "current",
        "typo_variable": "chtrent",
        "original_code": "public static long produced(AtomicLong requested, long n) {\n        for (;;) {\n            long current = requested.get();\n            if (current == Long.MAX_VALUE) {\n                return Long.MAX_VALUE;\n            }\n            long update = current - n;\n            if (update < 0L) {\n                RxJavaPlugins.onError(new IllegalStateException(\"More produced than requested: \" + update));\n                update = 0L;\n            }\n            if (requested.compareAndSet(current, update)) {\n                return update;\n            }\n        }\n    }",
        "modified_code": "public static long produced(AtomicLong requested, long n) {\n        for (;;) {\n            long chtrent = requested.get();\n            if (chtrent == Long.MAX_VALUE) {\n                return Long.MAX_VALUE;\n            }\n            long update = chtrent - n;\n            if (update < 0L) {\n                RxJavaPlugins.onError(new IllegalStateException(\"More produced than requested: \" + update));\n                update = 0L;\n            }\n            if (requested.compareAndSet(chtrent, update)) {\n                return update;\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the number of times the value was produced",
            "the number of times the value was requested",
            "the number of times the value was produced by the consumer"
        ],
        "corrections_by_ours": [
            "requested",
            "number",
            "times",
            "value",
            "consumer",
            "produced"
        ],
        "corrections_by_baseline": [
            "utflen",
            "thislen",
            "ilenhd",
            "passedAnzahlTerrassen",
            "ecP",
            "dellen",
            "ois",
            "chs",
            "ft",
            "prelen"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resjlf",
        "original_variable": "result",
        "typo_variable": "resjlf",
        "original_code": "public static String processString(String tpl, Map<String, Object> renderParams) {\n        if (appConfig == null) {\n            getAppConfiguration();\n        }\n        StringWriter result = new StringWriter();\n        try {\n            Template template = appConfig.getTemplate(tpl);\n            template.process(renderParams, result);\n        } catch (IOException e) {\n            throw new RenderException(e);\n        } catch (TemplateException e) {\n            throw new RenderException(e);\n        }\n        return result.toString();\n    }",
        "modified_code": "public static String processString(String tpl, Map<String, Object> renderParams) {\n        if (appConfig == null) {\n            getAppConfiguration();\n        }\n        StringWriter resjlf = new StringWriter();\n        try {\n            Template template = appConfig.getTemplate(tpl);\n            template.process(renderParams, resjlf);\n        } catch (IOException e) {\n            throw new RenderException(e);\n        } catch (TemplateException e) {\n            throw new RenderException(e);\n        }\n        return resjlf.toString();\n    }",
        "explanations_by_ours": [
            "The output stream to write the result to.",
            "The output stream to write the output to.",
            "The string to return."
        ],
        "corrections_by_ours": [
            "result",
            "return",
            "string",
            "write",
            "output",
            "stream"
        ],
        "corrections_by_baseline": [
            "rsf",
            "rsmd",
            "rctxt",
            "rtctxt",
            "lsrc",
            "res",
            "rj",
            "fsrc",
            "jshft",
            "dsp"
        ]
    },
    {
        "original_word": "method",
        "typo_word": "hethof",
        "original_variable": "methodurl",
        "typo_variable": "hethofurl",
        "original_code": "protected void\n    build()\n            throws DapException\n    {\n        String methodurl = buildURL(this.xuri.assemble(XURI.URLONLY), DATASUFFIX, this.dmr, this.basece);\n\n        InputStream stream;\n        // Make the request and return an input stream for accessing the databuffer\n        // Should fill in bigendian and stream fields\n        stream = callServer(methodurl);\n\n        try {\n            ChunkInputStream reader;\n            if(DEBUG) {\n                byte[] raw = DapUtil.readbinaryfile(stream);\n                ByteArrayInputStream bis = new ByteArrayInputStream(raw);\n                DapDump.dumpbytestream(raw, getOrder(), \"httpdsp.build\");\n                reader = new ChunkInputStream(bis, RequestMode.DAP, getOrder());\n            } else {\n                // Wrap the input stream as a ChunkInputStream\n                reader = new ChunkInputStream(stream, RequestMode.DAP, getOrder());\n            }\n\n            // Extract and \"compile\" the server response\n            String document = reader.readDMR();\n            // Extract all the remaining bytes\n            byte[] bytes = DapUtil.readbinaryfile(reader);\n            // use super.build to compile\n            super.build(document, bytes, getOrder());\n        } catch (Throwable t) {\n            t.printStackTrace();\n            throw new DapException(t);\n        } finally {\n            try {\n                stream.close();\n            } catch (IOException ioe) {/*ignore*/}\n        }\n    }",
        "modified_code": "protected void\n    build()\n            throws DapException\n    {\n        String hethofurl = buildURL(this.xuri.assemble(XURI.URLONLY), DATASUFFIX, this.dmr, this.basece);\n\n        InputStream stream;\n        // Make the request and return an input stream for accessing the databuffer\n        // Should fill in bigendian and stream fields\n        stream = callServer(hethofurl);\n\n        try {\n            ChunkInputStream reader;\n            if(DEBUG) {\n                byte[] raw = DapUtil.readbinaryfile(stream);\n                ByteArrayInputStream bis = new ByteArrayInputStream(raw);\n                DapDump.dumpbytestream(raw, getOrder(), \"httpdsp.build\");\n                reader = new ChunkInputStream(bis, RequestMode.DAP, getOrder());\n            } else {\n                // Wrap the input stream as a ChunkInputStream\n                reader = new ChunkInputStream(stream, RequestMode.DAP, getOrder());\n            }\n\n            // Extract and \"compile\" the server response\n            String document = reader.readDMR();\n            // Extract all the remaining bytes\n            byte[] bytes = DapUtil.readbinaryfile(reader);\n            // use super.build to compile\n            super.build(document, bytes, getOrder());\n        } catch (Throwable t) {\n            t.printStackTrace();\n            throw new DapException(t);\n        } finally {\n            try {\n                stream.close();\n            } catch (IOException ioe) {/*ignore*/}\n        }\n    }",
        "explanations_by_ours": [
            "The HETHOF URL to use.",
            "The HETHOF URL.",
            "The HETHOF URL to call."
        ],
        "corrections_by_ours": [
            "hethof",
            "url",
            "use",
            "call"
        ],
        "corrections_by_baseline": [
            "furl",
            "surl",
            "fdsurl",
            "url",
            "sURL",
            "urlon",
            "urlat",
            "durl",
            "qurl",
            "catURL"
        ]
    },
    {
        "original_word": "previous",
        "typo_word": "orefious",
        "original_variable": "previousID",
        "typo_variable": "orefiousID",
        "original_code": "protected String setContextID(final String contextID) {\n        if (! WildFlySecurityManager.isChecking()) {\n            final String previousID = PolicyContext.getContextID();\n            PolicyContext.setContextID(contextID);\n            return previousID;\n        } else {\n            final PrivilegedAction<String> action = new SetContextIDAction(contextID);\n            return AccessController.doPrivileged(action);\n        }\n    }",
        "modified_code": "protected String setContextID(final String contextID) {\n        if (! WildFlySecurityManager.isChecking()) {\n            final String orefiousID = PolicyContext.getContextID();\n            PolicyContext.setContextID(contextID);\n            return orefiousID;\n        } else {\n            final PrivilegedAction<String> action = new SetContextIDAction(contextID);\n            return AccessController.doPrivileged(action);\n        }\n    }",
        "explanations_by_ours": [
            "the orefious ID",
            "the orefious context ID",
            "the orefiousID"
        ],
        "corrections_by_ours": [
            "idID",
            "orefiousOrefious",
            "contextID",
            "orefiousContext",
            "orefiousID"
        ],
        "corrections_by_baseline": [
            "fluidItmId",
            "sID",
            "externalId",
            "idName",
            "ID",
            "id",
            "clzId",
            "internalId",
            "rId",
            "idAsString"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "cufdent",
        "original_variable": "current",
        "typo_variable": "cufdent",
        "original_code": "public String\n    computefqn()\n    {\n        List<DapNode> path = getPath(); // excludes root/wrt\n        StringBuilder fqn = new StringBuilder();\n        DapNode parent = path.get(0);\n        for(int i = 1; i < path.size(); i++) {   // start at 1 to skip root\n            DapNode current = path.get(i);\n            // Depending on what parent is, use different delimiters\n            switch (parent.getSort()) {\n            case DATASET:\n            case GROUP:\n            case ENUMERATION:\n                fqn.append('/');\n                fqn.append(Escape.backslashEscape(current.getShortName(),\"/.\"));\n                break;\n            // These use '.'\n            case STRUCTURE:\n            case SEQUENCE:\n            case ENUMCONST:\n            case VARIABLE:\n                fqn.append('.');\n                fqn.append(current.getEscapedShortName());\n                break;\n            default: // Others should never happen\n                throw new IllegalArgumentException(\"Illegal FQN parent\");\n            }\n            parent = current;\n        }\n        return fqn.toString();\n    }",
        "modified_code": "public String\n    computefqn()\n    {\n        List<DapNode> path = getPath(); // excludes root/wrt\n        StringBuilder fqn = new StringBuilder();\n        DapNode parent = path.get(0);\n        for(int i = 1; i < path.size(); i++) {   // start at 1 to skip root\n            DapNode cufdent = path.get(i);\n            // Depending on what parent is, use different delimiters\n            switch (parent.getSort()) {\n            case DATASET:\n            case GROUP:\n            case ENUMERATION:\n                fqn.append('/');\n                fqn.append(Escape.backslashEscape(cufdent.getShortName(),\"/.\"));\n                break;\n            // These use '.'\n            case STRUCTURE:\n            case SEQUENCE:\n            case ENUMCONST:\n            case VARIABLE:\n                fqn.append('.');\n                fqn.append(cufdent.getEscapedShortName());\n                break;\n            default: // Others should never happen\n                throw new IllegalArgumentException(\"Illegal FQN parent\");\n            }\n            parent = cufdent;\n        }\n        return fqn.toString();\n    }",
        "explanations_by_ours": [
            "the parent of this DAP",
            "the DAP node to compute the FQN of",
            "the DAP node to compute the FQN for"
        ],
        "corrections_by_ours": [
            "parent",
            "node",
            "fqn",
            "dap",
            "compute"
        ],
        "corrections_by_baseline": [
            "dou",
            "ent",
            "determinant",
            "t_E_temp",
            "cir",
            "coldp",
            "t_huff",
            "indent",
            "indirect",
            "unind"
        ]
    },
    {
        "original_word": "unused",
        "typo_word": "unjswd",
        "original_variable": "unused",
        "typo_variable": "unjswd",
        "original_code": "public synchronized void deserialize(DataInputStream source,\r\n                                         ServerVersion sv,\r\n                                         StatusUI statusUI)\r\n            throws IOException, EOFException, DataReadException {\r\n\r\n        int modFour = vals.length % 4;\r\n        // number of bytes to pad\r\n        int pad = (modFour != 0) ? (4 - modFour) : 0;\r\n\r\n        for (int i = 0; i < vals.length; i++) {\r\n            vals[i] = source.readByte();\r\n            if (statusUI != null) {\r\n                statusUI.incrementByteCount(1);\r\n                if (statusUI.userCancelled())\r\n                    throw new DataReadException(\"User cancelled\");\r\n            }\r\n        }\r\n        // pad out to a multiple of four bytes\r\n        byte unused;\r\n        for (int i = 0; i < pad; i++)\r\n            unused = source.readByte();\r\n        if (statusUI != null)\r\n            statusUI.incrementByteCount(pad);\r\n    }",
        "modified_code": "public synchronized void deserialize(DataInputStream source,\r\n                                         ServerVersion sv,\r\n                                         StatusUI statusUI)\r\n            throws IOException, EOFException, DataReadException {\r\n\r\n        int modFour = vals.length % 4;\r\n        // number of bytes to pad\r\n        int pad = (modFour != 0) ? (4 - modFour) : 0;\r\n\r\n        for (int i = 0; i < vals.length; i++) {\r\n            vals[i] = source.readByte();\r\n            if (statusUI != null) {\r\n                statusUI.incrementByteCount(1);\r\n                if (statusUI.userCancelled())\r\n                    throw new DataReadException(\"User cancelled\");\r\n            }\r\n        }\r\n        // pad out to a multiple of four bytes\r\n        byte unjswd;\r\n        for (int i = 0; i < pad; i++)\r\n            unjswd = source.readByte();\r\n        if (statusUI != null)\r\n            statusUI.incrementByteCount(pad);\r\n    }",
        "explanations_by_ours": [
            "the first byte of the data",
            "the first byte of the data to be read",
            "the first byte of the data to read"
        ],
        "corrections_by_ours": [
            "first",
            "read",
            "byte",
            "data"
        ],
        "corrections_by_baseline": [
            "jbndg",
            "rj",
            "jshft",
            "mj",
            "glomn",
            "JD",
            "jg",
            "unind",
            "nx",
            "jbeg"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "ewsult",
        "original_variable": "result",
        "typo_variable": "ewsult",
        "original_code": "public String put(Integer col, Integer row, String value)\n    {\n        maxColumns = (col > maxColumns) ? col : maxColumns;\n        maxRows = (row > maxRows) ? row : maxRows;\n\n        updateMaxColumnWidth(col, value.length());\n\n        String result = grid.put((long) col, (long) row, value);\n\n        updateListeners(col, row);\n\n        return result;\n    }",
        "modified_code": "public String put(Integer col, Integer row, String value)\n    {\n        maxColumns = (col > maxColumns) ? col : maxColumns;\n        maxRows = (row > maxRows) ? row : maxRows;\n\n        updateMaxColumnWidth(col, value.length());\n\n        String ewsult = grid.put((long) col, (long) row, value);\n\n        updateListeners(col, row);\n\n        return ewsult;\n    }",
        "explanations_by_ours": [
            "the value that was put into the grid",
            "the new value",
            "the value that was put into the grid."
        ],
        "corrections_by_ours": [
            "put",
            "new",
            "value",
            "grid"
        ],
        "corrections_by_baseline": [
            "ews",
            "etdf",
            "datac",
            "soff",
            "sobsDataset",
            "das",
            "xfac",
            "sobs",
            "sdf",
            "etf"
        ]
    },
    {
        "original_word": "Credential",
        "typo_word": "Crfxential",
        "original_variable": "myCredential",
        "typo_variable": "myCrfxential",
        "original_code": "public final Subject authenticate(final String domain, final String userName, final char[] password,\n                                      final PasswordValidator passwordValidator)\n            throws LoginException {\n\n        // make sure the credentials are not null\n        if (domain == null) {\n            throw new LoginException(\"The domain cannot be null\");\n        }\n        if (userName == null) {\n            throw new LoginException(\"The username cannot be null\");\n        }\n        if (password == null) {\n            throw new LoginException(\"The password cannot be null\");\n        }\n\n        // no need for defensive copies of Strings, but create a defensive copy of the password\n        final char[] myPassword = password.clone();\n\n        // convert the username string to a char array\n        final char[] myCredential = userName.toCharArray();\n\n        // perform the password validation\n        if (!passwordValidator.validate(myPassword, myCredential)) {\n            final String error = \"Invalid password for username '\" + userName + \"'\";\n            LOG.info(error);\n            throw new FailedLoginException(error);\n        }\n\n        // The authentication was successful!\n        // Create the subject and clean up confidential data as far as possible.\n\n        // clear the char representation of the credential\n        Cleanser.wipe(myCredential);\n\n        // clear the defensive copy of the password created earlier\n        Cleanser.wipe(myPassword);\n\n        // create a principal that includes the username and domain name that were used to authenticate the user\n        final UserPrincipal userPrincipal = new UserPrincipal(\"ID:\" + userName, domain, userName);\n\n        // wrap the principal in a Subject\n        final Subject subject = new Subject();\n        subject.getPrincipals().add(userPrincipal);\n\n        return subject;\n    }",
        "modified_code": "public final Subject authenticate(final String domain, final String userName, final char[] password,\n                                      final PasswordValidator passwordValidator)\n            throws LoginException {\n\n        // make sure the credentials are not null\n        if (domain == null) {\n            throw new LoginException(\"The domain cannot be null\");\n        }\n        if (userName == null) {\n            throw new LoginException(\"The username cannot be null\");\n        }\n        if (password == null) {\n            throw new LoginException(\"The password cannot be null\");\n        }\n\n        // no need for defensive copies of Strings, but create a defensive copy of the password\n        final char[] myPassword = password.clone();\n\n        // convert the username string to a char array\n        final char[] myCrfxential = userName.toCharArray();\n\n        // perform the password validation\n        if (!passwordValidator.validate(myPassword, myCrfxential)) {\n            final String error = \"Invalid password for username '\" + userName + \"'\";\n            LOG.info(error);\n            throw new FailedLoginException(error);\n        }\n\n        // The authentication was successful!\n        // Create the subject and clean up confidential data as far as possible.\n\n        // clear the char representation of the credential\n        Cleanser.wipe(myCrfxential);\n\n        // clear the defensive copy of the password created earlier\n        Cleanser.wipe(myPassword);\n\n        // create a principal that includes the username and domain name that were used to authenticate the user\n        final UserPrincipal userPrincipal = new UserPrincipal(\"ID:\" + userName, domain, userName);\n\n        // wrap the principal in a Subject\n        final Subject subject = new Subject();\n        subject.getPrincipals().add(userPrincipal);\n\n        return subject;\n    }",
        "explanations_by_ours": [
            "the char representation of the user's confidential data",
            "the confidential data of the user",
            "the char representation of the user"
        ],
        "corrections_by_ours": [
            "myConfidential",
            "myRepresentation",
            "myData",
            "myChar",
            "myUser",
            "myUser's",
            "dataCrfxential",
            "confidentialCrfxential",
            "userCrfxential",
            "user'sCrfxential"
        ],
        "corrections_by_baseline": [
            "myCredential",
            "myPassword",
            "finalCredential",
            "pwdCredential",
            "caCertificatePassword",
            "webCredential",
            "ccw",
            "payPalAccountNonce",
            "venmoAccountNonce",
            "passwordb"
        ]
    },
    {
        "original_word": "listeners",
        "typo_word": "listenfts",
        "original_variable": "listeners",
        "typo_variable": "listenfts",
        "original_code": "protected void fireTreeNodesRemoved(Object source, Object[] path,\r\n                                        int[] childIndices,\r\n                                        Object[] children) {\r\n        // Guaranteed to return a non-null array\r\n        Object[] listeners = listenerList.getListenerList();\r\n        TreeModelEvent e = null;\r\n        // Process the listeners last to first, notifying\r\n        // those that are interested in this event\r\n        for (int i = listeners.length-2; i>=0; i-=2) {\r\n            if (listeners[i]==TreeModelListener.class) {\r\n                // Lazily create the event:\r\n                if (e == null)\r\n                    e = new TreeModelEvent(source, path,\r\n                                           childIndices, children);\r\n                ((TreeModelListener)listeners[i+1]).treeNodesRemoved(e);\r\n            }\r\n        }\r\n    }",
        "modified_code": "protected void fireTreeNodesRemoved(Object source, Object[] path,\r\n                                        int[] childIndices,\r\n                                        Object[] children) {\r\n        // Guaranteed to return a non-null array\r\n        Object[] listenfts = listenerList.getListenerList();\r\n        TreeModelEvent e = null;\r\n        // Process the listeners last to first, notifying\r\n        // those that are interested in this event\r\n        for (int i = listenfts.length-2; i>=0; i-=2) {\r\n            if (listenfts[i]==TreeModelListener.class) {\r\n                // Lazily create the event:\r\n                if (e == null)\r\n                    e = new TreeModelEvent(source, path,\r\n                                           childIndices, children);\r\n                ((TreeModelListener)listenfts[i+1]).treeNodesRemoved(e);\r\n            }\r\n        }\r\n    }",
        "explanations_by_ours": [
            "the list of listeners",
            "the list of listeners that are interested in this event",
            "the list of listeners that are interested in the event"
        ],
        "corrections_by_ours": [
            "listfts",
            "listenersfts",
            "interestedfts",
            "listenlist",
            "listenlisteners",
            "listeninterested",
            "eventfts",
            "listenevent",
            "listenfts"
        ],
        "corrections_by_baseline": [
            "weblisteners",
            "servers",
            "listeners",
            "receiverList",
            "serverList",
            "publishers",
            "listing",
            "servlets",
            "listenerInfos",
            "hostLists"
        ]
    },
    {
        "original_word": "original",
        "typo_word": "kririnal",
        "original_variable": "original",
        "typo_variable": "kririnal",
        "original_code": "private static void combineParameters(List<Parameter> parameters, List<Parameter> otherParameters) {\n        if (otherParameters != null && otherParameters.size() > 0) {\n            Map<String, Parameter> map = new HashMap<>();\n            for (Parameter parameter : parameters) {\n                map.put(parameter.getName(), parameter);\n            }\n            for (Parameter otherParameter : otherParameters) {\n                String name = otherParameter.getName();\n                Parameter original = map.get(name);\n                if (original == null) {\n                    parameters.add(otherParameter);\n                } else {\n                    if (StringUtils.isNotBlank(original.getValue())) {\n                        original.setValue(otherParameter.getValue());\n                    }\n                }\n            }\n        }\n    }",
        "modified_code": "private static void combineParameters(List<Parameter> parameters, List<Parameter> otherParameters) {\n        if (otherParameters != null && otherParameters.size() > 0) {\n            Map<String, Parameter> map = new HashMap<>();\n            for (Parameter parameter : parameters) {\n                map.put(parameter.getName(), parameter);\n            }\n            for (Parameter otherParameter : otherParameters) {\n                String name = otherParameter.getName();\n                Parameter kririnal = map.get(name);\n                if (kririnal == null) {\n                    parameters.add(otherParameter);\n                } else {\n                    if (StringUtils.isNotBlank(kririnal.getValue())) {\n                        kririnal.setValue(otherParameter.getValue());\n                    }\n                }\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the kririnal parameter",
            "the kririnal parameter",
            "the kririnal"
        ],
        "corrections_by_ours": [
            "parameter"
        ],
        "corrections_by_baseline": [
            "ykr",
            "nk",
            "kx",
            "kxky",
            "k0",
            "central",
            "iy0",
            "kPrime",
            "radian",
            "k4"
        ]
    },
    {
        "original_word": "struct",
        "typo_word": "sgrjct",
        "original_variable": "structpath",
        "typo_variable": "sgrjctpath",
        "original_code": "static public List<DapVariable>\n    getStructurePath(DapVariable var)\n    {\n        List<DapNode> path = var.getPath();\n        List<DapVariable> structpath = new ArrayList<DapVariable>();\n        for(int i = 0; i < path.size(); i++) {\n            DapNode node = path.get(i);\n            switch (node.getSort()) {\n            case DATASET:\n            case GROUP:\n                break;\n            case VARIABLE:\n                structpath.add((DapVariable) node);\n                break;\n            default:\n                assert false : \"Internal error\";\n            }\n        }\n        return structpath;\n    }",
        "modified_code": "static public List<DapVariable>\n    getStructurePath(DapVariable var)\n    {\n        List<DapNode> path = var.getPath();\n        List<DapVariable> sgrjctpath = new ArrayList<DapVariable>();\n        for(int i = 0; i < path.size(); i++) {\n            DapNode node = path.get(i);\n            switch (node.getSort()) {\n            case DATASET:\n            case GROUP:\n                break;\n            case VARIABLE:\n                sgrjctpath.add((DapVariable) node);\n                break;\n            default:\n                assert false : \"Internal error\";\n            }\n        }\n        return sgrjctpath;\n    }",
        "explanations_by_ours": [
            "The structure path of the variable.",
            "The structure path.",
            "The structure path of the variable"
        ],
        "corrections_by_ours": [
            "structure",
            "path",
            "variable"
        ],
        "corrections_by_baseline": [
            "dodspath",
            "daspath",
            "crDsPath",
            "dsDirPath",
            "rootDataPath",
            "schemasFolderPath",
            "projpath",
            "ddfPath",
            "m_strRootFTPDirectory",
            "rootPath"
        ]
    },
    {
        "original_word": "Schemas",
        "typo_word": "Schdmaq",
        "original_variable": "orderedSchemas",
        "typo_variable": "orderedSchdmaq",
        "original_code": "public static void removeReferencedOutsideClosure(HollowReadStateEngine stateEngine, Map<String, BitSet> matches) {\n        List<HollowSchema> orderedSchemas = HollowSchemaSorter.dependencyOrderedSchemaList(stateEngine);\n        Collections.reverse(orderedSchemas);\n\n\n        for(HollowSchema referencedSchema : orderedSchemas) {\n            if(matches.containsKey(referencedSchema.getName())) {\n                for(HollowSchema referencerSchema : orderedSchemas) {\n                    if(referencerSchema == referencedSchema)\n                        break;\n\n                    if(matches.containsKey(referencedSchema.getName()) && matches.get(referencedSchema.getName()).cardinality() > 0)\n                        traverseReferencesOutsideClosure(stateEngine, referencerSchema.getName(), referencedSchema.getName(), matches, REMOVE_REFERENCED_OUTSIDE_CLOSURE);\n                }\n            }\n        }\n    }",
        "modified_code": "public static void removeReferencedOutsideClosure(HollowReadStateEngine stateEngine, Map<String, BitSet> matches) {\n        List<HollowSchema> orderedSchdmaq = HollowSchemaSorter.dependencyOrderedSchemaList(stateEngine);\n        Collections.reverse(orderedSchdmaq);\n\n\n        for(HollowSchema referencedSchema : orderedSchdmaq) {\n            if(matches.containsKey(referencedSchema.getName())) {\n                for(HollowSchema referencerSchema : orderedSchdmaq) {\n                    if(referencerSchema == referencedSchema)\n                        break;\n\n                    if(matches.containsKey(referencedSchema.getName()) && matches.get(referencedSchema.getName()).cardinality() > 0)\n                        traverseReferencesOutsideClosure(stateEngine, referencerSchema.getName(), referencedSchema.getName(), matches, REMOVE_REFERENCED_OUTSIDE_CLOSURE);\n                }\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the ordered schemas",
            "the ordered schema list",
            "the ordered schemamq"
        ],
        "corrections_by_ours": [
            "orderedSchemamq",
            "orderedSchemas",
            "orderedSchema",
            "schemasSchdmaq",
            "schemaSchdmaq",
            "schemamqSchdmaq",
            "listSchdmaq",
            "orderedOrdered",
            "orderedList",
            "orderedSchdmaq"
        ],
        "corrections_by_baseline": [
            "prelen",
            "orderedSchemas",
            "lowcaseOrder",
            "orderStr",
            "sortedDrs",
            "webOrdering",
            "sortedSb",
            "orderedServers",
            "aeqm",
            "orderByArray"
        ]
    },
    {
        "original_word": "namespace",
        "typo_word": "namespqse",
        "original_variable": "namespace",
        "typo_variable": "namespqse",
        "original_code": "public void setAttribute(AttributesImpl atts, String name, String type,\n                             String value) {\n        if (name.equals(\"xmlns\") || name.startsWith(\"xmlns:\")) {\n            return;\n        }\n        ;\n        String namespace = namespace(name, true);\n        String localName = localName(name);\n        int i = atts.getIndex(name);\n        if (i == -1) {\n            name = name.intern();\n            if (type == null)\n                type = \"CDATA\";\n            if (!type.equals(\"CDATA\"))\n                value = normalize(value);\n            atts.addAttribute(namespace, localName, name, type, value);\n        } else {\n            if (type == null)\n                type = atts.getType(i);\n            if (!type.equals(\"CDATA\"))\n                value = normalize(value);\n            atts.setAttribute(i, namespace, localName, name, type, value);\n        }\n    }",
        "modified_code": "public void setAttribute(AttributesImpl atts, String name, String type,\n                             String value) {\n        if (name.equals(\"xmlns\") || name.startsWith(\"xmlns:\")) {\n            return;\n        }\n        ;\n        String namespqse = namespqse(name, true);\n        String localName = localName(name);\n        int i = atts.getIndex(name);\n        if (i == -1) {\n            name = name.intern();\n            if (type == null)\n                type = \"CDATA\";\n            if (!type.equals(\"CDATA\"))\n                value = normalize(value);\n            atts.addAttribute(namespqse, localName, name, type, value);\n        } else {\n            if (type == null)\n                type = atts.getType(i);\n            if (!type.equals(\"CDATA\"))\n                value = normalize(value);\n            atts.setAttribute(i, namespqse, localName, name, type, value);\n        }\n    }",
        "explanations_by_ours": [
            "The namespace URI of the attribute.",
            "The name of the attribute.",
            "The name of the attribute's namespace."
        ],
        "corrections_by_ours": [
            "namespace",
            "name",
            "attribute",
            "attribute's",
            "uri"
        ],
        "corrections_by_baseline": [
            "econstnames",
            "snames",
            "qname",
            "namespace",
            "spc_names",
            "sobjectNames",
            "ns",
            "nsName",
            "namep",
            "names"
        ]
    },
    {
        "original_word": "digit",
        "typo_word": "dlgig",
        "original_variable": "digit",
        "typo_variable": "dlgig",
        "original_code": "public static String encode(final byte[] bytes) {\n\t\tStringBuilder base32 = new StringBuilder((bytes.length * 8 + 4) / 5);\n\n\t\tint currByte, digit, i = 0;\n\t\twhile (i < bytes.length) {\n\n\t\t\t// STEP 0; insert new 5 bits, leave 3 bits\n\t\t\tcurrByte = bytes[i++] & 255;\n\t\t\tbase32.append(CHARS[currByte >> 3]);\n\t\t\tdigit = (currByte & 7) << 2;\n\t\t\tif (i >= bytes.length) {\n\t\t\t\tbase32.append(CHARS[digit]);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// STEP 3: insert 2 new bits, then 5 bits, leave 1 bit\n\t\t\tcurrByte = bytes[i++] & 255;\n\t\t\tbase32.append(CHARS[digit | (currByte >> 6)]);\n\t\t\tbase32.append(CHARS[(currByte >> 1) & 31]);\n\t\t\tdigit = (currByte & 1) << 4;\n\t\t\tif (i >= bytes.length) {\n\t\t\t\tbase32.append(CHARS[digit]);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// STEP 1: insert 4 new bits, leave 4 bit\n\t\t\tcurrByte = bytes[i++] & 255;\n\t\t\tbase32.append(CHARS[digit | (currByte >> 4)]);\n\t\t\tdigit = (currByte & 15) << 1;\n\t\t\tif (i >= bytes.length) {\n\t\t\t\tbase32.append(CHARS[digit]);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// STEP 4: insert 1 new bit, then 5 bits, leave 2 bits\n\t\t\tcurrByte = bytes[i++] & 255;\n\t\t\tbase32.append(CHARS[digit | (currByte >> 7)]);\n\t\t\tbase32.append(CHARS[(currByte >> 2) & 31]);\n\t\t\tdigit = (currByte & 3) << 3;\n\t\t\tif (i >= bytes.length) {\n\t\t\t\tbase32.append(CHARS[digit]);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// STEP 2: insert 3 new bits, then 5 bits, leave 0 bit\n\t\t\tcurrByte = bytes[i++] & 255;\n\t\t\tbase32.append(CHARS[digit | (currByte >> 5)]);\n\t\t\tbase32.append(CHARS[currByte & 31]);\n\t\t}\n\t\treturn base32.toString();\n\t}",
        "modified_code": "public static String encode(final byte[] bytes) {\n\t\tStringBuilder base32 = new StringBuilder((bytes.length * 8 + 4) / 5);\n\n\t\tint currByte, dlgig, i = 0;\n\t\twhile (i < bytes.length) {\n\n\t\t\t// STEP 0; insert new 5 bits, leave 3 bits\n\t\t\tcurrByte = bytes[i++] & 255;\n\t\t\tbase32.append(CHARS[currByte >> 3]);\n\t\t\tdlgig = (currByte & 7) << 2;\n\t\t\tif (i >= bytes.length) {\n\t\t\t\tbase32.append(CHARS[dlgig]);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// STEP 3: insert 2 new bits, then 5 bits, leave 1 bit\n\t\t\tcurrByte = bytes[i++] & 255;\n\t\t\tbase32.append(CHARS[dlgig | (currByte >> 6)]);\n\t\t\tbase32.append(CHARS[(currByte >> 1) & 31]);\n\t\t\tdlgig = (currByte & 1) << 4;\n\t\t\tif (i >= bytes.length) {\n\t\t\t\tbase32.append(CHARS[dlgig]);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// STEP 1: insert 4 new bits, leave 4 bit\n\t\t\tcurrByte = bytes[i++] & 255;\n\t\t\tbase32.append(CHARS[dlgig | (currByte >> 4)]);\n\t\t\tdlgig = (currByte & 15) << 1;\n\t\t\tif (i >= bytes.length) {\n\t\t\t\tbase32.append(CHARS[dlgig]);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// STEP 4: insert 1 new bit, then 5 bits, leave 2 bits\n\t\t\tcurrByte = bytes[i++] & 255;\n\t\t\tbase32.append(CHARS[dlgig | (currByte >> 7)]);\n\t\t\tbase32.append(CHARS[(currByte >> 2) & 31]);\n\t\t\tdlgig = (currByte & 3) << 3;\n\t\t\tif (i >= bytes.length) {\n\t\t\t\tbase32.append(CHARS[dlgig]);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// STEP 2: insert 3 new bits, then 5 bits, leave 0 bit\n\t\t\tcurrByte = bytes[i++] & 255;\n\t\t\tbase32.append(CHARS[dlgig | (currByte >> 5)]);\n\t\t\tbase32.append(CHARS[currByte & 31]);\n\t\t}\n\t\treturn base32.toString();\n\t}",
        "explanations_by_ours": [
            "the number of bits to use in the encoded string",
            "the number of bits to use in the encoded string.",
            "the number of bits to insert in the string"
        ],
        "corrections_by_ours": [
            "dlgstring",
            "dlgbits",
            "stringig",
            "dlginsert",
            "encodedig",
            "useig",
            "insertig",
            "numberig",
            "bitsig",
            "dlguse"
        ],
        "corrections_by_baseline": [
            "SDG",
            "gds",
            "jg",
            "dl1",
            "g",
            "gcs",
            "lopts",
            "stg",
            "gcd",
            "gfr"
        ]
    },
    {
        "original_word": "success",
        "typo_word": "zkccess",
        "original_variable": "success",
        "typo_variable": "zkccess",
        "original_code": "public synchronized boolean shutdown(long timeout, TimeUnit unit)\n\t\t\tthrows InterruptedException {\n\t\tboolean success = true;\n\t\tif (success) {\n\t\t\tLOGGER_.info(\"ELK reasoner has shut down\");\n\t\t} else {\n\t\t\tLOGGER_.error(\"ELK reasoner failed to shut down!\");\n\t\t}\n\t\treturn success;\n\n\t}",
        "modified_code": "public synchronized boolean shutdown(long timeout, TimeUnit unit)\n\t\t\tthrows InterruptedException {\n\t\tboolean zkccess = true;\n\t\tif (zkccess) {\n\t\t\tLOGGER_.info(\"ELK reasoner has shut down\");\n\t\t} else {\n\t\t\tLOGGER_.error(\"ELK reasoner failed to shut down!\");\n\t\t}\n\t\treturn zkccess;\n\n\t}",
        "explanations_by_ours": [
            "true if the reasoner has been shut down.",
            "true if the reasoner has been shut down",
            "true if the reasoner has shut down."
        ],
        "corrections_by_ours": [
            "true",
            "shut",
            "reasoner"
        ],
        "corrections_by_baseline": [
            "kxky",
            "zis",
            "wz",
            "koma",
            "adz",
            "CZ",
            "cz",
            "ykr",
            "vz",
            "skf"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rfsjlt",
        "original_variable": "result",
        "typo_variable": "rfsjlt",
        "original_code": "public List<ResourceAdaptorTypeDescriptorImpl> parse(InputStream inputStream) throws DeploymentException\n  {\n    Object jaxbPojo = buildJAXBPojo(inputStream);\n\n    List<ResourceAdaptorTypeDescriptorImpl> result = new ArrayList<ResourceAdaptorTypeDescriptorImpl>();\n\n    boolean isSlee11 = false;\n    MResourceAdaptorTypeJar mResourceAdaptorTypeJar = null;\n    if (jaxbPojo instanceof org.mobicents.slee.container.component.deployment.jaxb.slee.ratype.ResourceAdaptorTypeJar)\n    {\n      mResourceAdaptorTypeJar = new MResourceAdaptorTypeJar((org.mobicents.slee.container.component.deployment.jaxb.slee.ratype.ResourceAdaptorTypeJar)jaxbPojo);\n    }\n    else if (jaxbPojo instanceof org.mobicents.slee.container.component.deployment.jaxb.slee11.ratype.ResourceAdaptorTypeJar )\n    {\n      mResourceAdaptorTypeJar = new MResourceAdaptorTypeJar((org.mobicents.slee.container.component.deployment.jaxb.slee11.ratype.ResourceAdaptorTypeJar)jaxbPojo);\n      isSlee11 = true;\n    } \n    else {\n      throw new SLEEException(\"unexpected class of jaxb pojo built: \"+(jaxbPojo != null ? jaxbPojo.getClass() : null));\n    }\n\n    for (MResourceAdaptorType mResourceAdaptorType : mResourceAdaptorTypeJar.getResourceAdaptorType())\n    {\n      result.add(new ResourceAdaptorTypeDescriptorImpl(mResourceAdaptorType, isSlee11));\n    }\n\n    return result;\n  }",
        "modified_code": "public List<ResourceAdaptorTypeDescriptorImpl> parse(InputStream inputStream) throws DeploymentException\n  {\n    Object jaxbPojo = buildJAXBPojo(inputStream);\n\n    List<ResourceAdaptorTypeDescriptorImpl> rfsjlt = new ArrayList<ResourceAdaptorTypeDescriptorImpl>();\n\n    boolean isSlee11 = false;\n    MResourceAdaptorTypeJar mResourceAdaptorTypeJar = null;\n    if (jaxbPojo instanceof org.mobicents.slee.container.component.deployment.jaxb.slee.ratype.ResourceAdaptorTypeJar)\n    {\n      mResourceAdaptorTypeJar = new MResourceAdaptorTypeJar((org.mobicents.slee.container.component.deployment.jaxb.slee.ratype.ResourceAdaptorTypeJar)jaxbPojo);\n    }\n    else if (jaxbPojo instanceof org.mobicents.slee.container.component.deployment.jaxb.slee11.ratype.ResourceAdaptorTypeJar )\n    {\n      mResourceAdaptorTypeJar = new MResourceAdaptorTypeJar((org.mobicents.slee.container.component.deployment.jaxb.slee11.ratype.ResourceAdaptorTypeJar)jaxbPojo);\n      isSlee11 = true;\n    } \n    else {\n      throw new SLEEException(\"unexpected class of jaxb pojo built: \"+(jaxbPojo != null ? jaxbPojo.getClass() : null));\n    }\n\n    for (MResourceAdaptorType mResourceAdaptorType : mResourceAdaptorTypeJar.getResourceAdaptorType())\n    {\n      rfsjlt.add(new ResourceAdaptorTypeDescriptorImpl(mResourceAdaptorType, isSlee11));\n    }\n\n    return rfsjlt;\n  }",
        "explanations_by_ours": [
            "a list of ResourceAdaptorTypeDescriptorImpl",
            "a List of ResourceAdaptorTypeDescriptorImpl",
            "a list of ResourceAdaptorTypeDescriptors"
        ],
        "corrections_by_ours": [
            "list",
            "resource",
            "descriptor",
            "descriptors",
            "impl",
            "type",
            "adaptor"
        ],
        "corrections_by_baseline": [
            "rsf",
            "rj",
            "wrrp",
            "ftrm",
            "jshft",
            "rdr",
            "rtctxt",
            "rctxt",
            "fsrc",
            "rp"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rezupt",
        "original_variable": "result",
        "typo_variable": "rezupt",
        "original_code": "public Set<String> getServerFeatures(File serverDirectory) {\n        Set<String> result = getConfigDropinsFeatures(null, serverDirectory, \"defaults\");\n        result = getServerXmlFeatures(result, new File(serverDirectory, \"server.xml\"), null);\n        // add the overrides at the end since they should not be replaced by any previous content\n        return getConfigDropinsFeatures(result, serverDirectory, \"overrides\");\n    }",
        "modified_code": "public Set<String> getServerFeatures(File serverDirectory) {\n        Set<String> rezupt = getConfigDropinsFeatures(null, serverDirectory, \"defaults\");\n        rezupt = getServerXmlFeatures(rezupt, new File(serverDirectory, \"server.xml\"), null);\n        // add the overrides at the end since they should not be replaced by any previous content\n        return getConfigDropinsFeatures(rezupt, serverDirectory, \"overrides\");\n    }",
        "explanations_by_ours": [
            "the set of features to return",
            "the set of features that should be returned",
            "the default set of features"
        ],
        "corrections_by_ours": [
            "return",
            "default",
            "returned",
            "set",
            "features"
        ],
        "corrections_by_baseline": [
            "trovit",
            "resul",
            "drun",
            "res",
            "dub",
            "ireturn",
            "runme",
            "opc",
            "build",
            "ud"
        ]
    },
    {
        "original_word": "Vars",
        "typo_word": "Vsrz",
        "original_variable": "freeVars",
        "typo_variable": "freeVsrz",
        "original_code": "public Iterator<Set<Variable>> iterator()\n    {\n        // Find all free variables in the query.\n        final Set<Variable> freeVars = TermUtils.findFreeNonAnonymousVariables(currentQuery);\n\n        Function<ResolutionState, Set<Variable>> listFunction =\n            new Function<ResolutionState, Set<Variable>>()\n            {\n                public Set<Variable> apply(ResolutionState state)\n                {\n                    return freeVars;\n                }\n            };\n\n        return new Filterator<ResolutionState, Set<Variable>>(Searches.allSolutions(this), listFunction);\n    }",
        "modified_code": "public Iterator<Set<Variable>> iterator()\n    {\n        // Find all free variables in the query.\n        final Set<Variable> freeVsrz = TermUtils.findFreeNonAnonymousVariables(currentQuery);\n\n        Function<ResolutionState, Set<Variable>> listFunction =\n            new Function<ResolutionState, Set<Variable>>()\n            {\n                public Set<Variable> apply(ResolutionState state)\n                {\n                    return freeVsrz;\n                }\n            };\n\n        return new Filterator<ResolutionState, Set<Variable>>(Searches.allSolutions(this), listFunction);\n    }",
        "explanations_by_ours": [
            "the set of variables to be returned.",
            "a set of variables to be returned.",
            "the set of variables that are free."
        ],
        "corrections_by_ours": [
            "setVsrz",
            "returnedVsrz",
            "freeSet",
            "variablesVsrz",
            "freeVariables",
            "freeReturned",
            "freeFree",
            "freeVsrz"
        ],
        "corrections_by_baseline": [
            "free",
            "freezeLsn",
            "freezeLSN",
            "notFree",
            "freeVarSearch",
            "freeMemory",
            "opacity",
            "targetCapacity",
            "tempSum",
            "tadBuffersZ"
        ]
    },
    {
        "original_word": "Subscribe",
        "typo_word": "Sjbscrlbe",
        "original_variable": "onSubscribe",
        "typo_variable": "onSjbscrlbe",
        "original_code": "static <T> ConnectableObservable<T> create(ObservableSource<T> source,\n            final BufferSupplier<T> bufferFactory) {\n        // the current connection to source needs to be shared between the operator and its onSubscribe call\n        final AtomicReference<ReplayObserver<T>> curr = new AtomicReference<ReplayObserver<T>>();\n        ObservableSource<T> onSubscribe = new ReplaySource<T>(curr, bufferFactory);\n        return RxJavaPlugins.onAssembly(new ObservableReplay<T>(onSubscribe, source, curr, bufferFactory));\n    }",
        "modified_code": "static <T> ConnectableObservable<T> create(ObservableSource<T> source,\n            final BufferSupplier<T> bufferFactory) {\n        // the current connection to source needs to be shared between the operator and its onSubscribe call\n        final AtomicReference<ReplayObserver<T>> curr = new AtomicReference<ReplayObserver<T>>();\n        ObservableSource<T> onSjbscrlbe = new ReplaySource<T>(curr, bufferFactory);\n        return RxJavaPlugins.onAssembly(new ObservableReplay<T>(onSjbscrlbe, source, curr, bufferFactory));\n    }",
        "explanations_by_ours": [
            "the ObservableSource to use for the replay",
            "the ObservableSource that will be used to create the {@",
            "the ObservableSource that will be used to create the on"
        ],
        "corrections_by_ours": [
            "onObservable",
            "onSource",
            "onUse",
            "onCreate",
            "sourceSjbscrlbe",
            "onReplay",
            "onUsed",
            "observableSjbscrlbe",
            "useSjbscrlbe",
            "{Sjbscrlbe"
        ],
        "corrections_by_baseline": [
            "bms",
            "jsonpcb",
            "sbbe",
            "pcb",
            "jbndg",
            "ncb",
            "cdl",
            "stn",
            "dlondx",
            "ddb"
        ]
    },
    {
        "original_word": "Impl",
        "typo_word": "Ikpi",
        "original_variable": "componentRepositoryImpl",
        "typo_variable": "componentRepositoryIkpi",
        "original_code": "public ComponentDescriptor getDescriptor(ComponentID componentID)\n\t\t\tthrows NullPointerException, UnrecognizedComponentException,\n\t\t\tManagementException {\n\t\tif (componentID == null)\n\t\t\tthrow new NullPointerException(\"null component ID\");\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"getDescriptor: componentID \" + componentID);\n\t\t}\n\n\t\ttry {\n\t\t\tComponentRepository componentRepositoryImpl = getSleeContainer().getComponentRepository();\n\t\t\tSleeComponent component = null;\n\t\t\tif (componentID instanceof EventTypeID) {\n\t\t\t\tcomponent = componentRepositoryImpl\n\t\t\t\t\t\t.getComponentByID((EventTypeID) componentID);\n\t\t\t} else if (componentID instanceof LibraryID) {\n\t\t\t\tcomponent = componentRepositoryImpl\n\t\t\t\t\t\t.getComponentByID((LibraryID) componentID);\n\t\t\t} else if (componentID instanceof ProfileSpecificationID) {\n\t\t\t\tcomponent = componentRepositoryImpl\n\t\t\t\t\t\t.getComponentByID((ProfileSpecificationID) componentID);\n\t\t\t} else if (componentID instanceof ResourceAdaptorID) {\n\t\t\t\tcomponent = componentRepositoryImpl\n\t\t\t\t\t\t.getComponentByID((ResourceAdaptorID) componentID);\n\t\t\t} else if (componentID instanceof ResourceAdaptorTypeID) {\n\t\t\t\tcomponent = componentRepositoryImpl\n\t\t\t\t\t\t.getComponentByID((ResourceAdaptorTypeID) componentID);\n\t\t\t} else if (componentID instanceof SbbID) {\n\t\t\t\tcomponent = componentRepositoryImpl\n\t\t\t\t\t\t.getComponentByID((SbbID) componentID);\n\t\t\t} else if (componentID instanceof ServiceID) {\n\t\t\t\tcomponent = componentRepositoryImpl\n\t\t\t\t\t\t.getComponentByID((ServiceID) componentID);\n\t\t\t}\n\t\t\tif (component != null)\n\t\t\t\treturn component.getComponentDescriptor();\n\t\t\telse \n\t\t\t\treturn null;\n\t\t} catch (Throwable ex) {\n\t\t\tthrow new ManagementException(ex.getMessage(), ex);\n\t\t}\n\n\t}",
        "modified_code": "public ComponentDescriptor getDescriptor(ComponentID componentID)\n\t\t\tthrows NullPointerException, UnrecognizedComponentException,\n\t\t\tManagementException {\n\t\tif (componentID == null)\n\t\t\tthrow new NullPointerException(\"null component ID\");\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"getDescriptor: componentID \" + componentID);\n\t\t}\n\n\t\ttry {\n\t\t\tComponentRepository componentRepositoryIkpi = getSleeContainer().getComponentRepository();\n\t\t\tSleeComponent component = null;\n\t\t\tif (componentID instanceof EventTypeID) {\n\t\t\t\tcomponent = componentRepositoryIkpi\n\t\t\t\t\t\t.getComponentByID((EventTypeID) componentID);\n\t\t\t} else if (componentID instanceof LibraryID) {\n\t\t\t\tcomponent = componentRepositoryIkpi\n\t\t\t\t\t\t.getComponentByID((LibraryID) componentID);\n\t\t\t} else if (componentID instanceof ProfileSpecificationID) {\n\t\t\t\tcomponent = componentRepositoryIkpi\n\t\t\t\t\t\t.getComponentByID((ProfileSpecificationID) componentID);\n\t\t\t} else if (componentID instanceof ResourceAdaptorID) {\n\t\t\t\tcomponent = componentRepositoryIkpi\n\t\t\t\t\t\t.getComponentByID((ResourceAdaptorID) componentID);\n\t\t\t} else if (componentID instanceof ResourceAdaptorTypeID) {\n\t\t\t\tcomponent = componentRepositoryIkpi\n\t\t\t\t\t\t.getComponentByID((ResourceAdaptorTypeID) componentID);\n\t\t\t} else if (componentID instanceof SbbID) {\n\t\t\t\tcomponent = componentRepositoryIkpi\n\t\t\t\t\t\t.getComponentByID((SbbID) componentID);\n\t\t\t} else if (componentID instanceof ServiceID) {\n\t\t\t\tcomponent = componentRepositoryIkpi\n\t\t\t\t\t\t.getComponentByID((ServiceID) componentID);\n\t\t\t}\n\t\t\tif (component != null)\n\t\t\t\treturn component.getComponentDescriptor();\n\t\t\telse \n\t\t\t\treturn null;\n\t\t} catch (Throwable ex) {\n\t\t\tthrow new ManagementException(ex.getMessage(), ex);\n\t\t}\n\n\t}",
        "explanations_by_ours": [
            "the component repository IKPI",
            "the component repository IKPI.",
            "The component repository."
        ],
        "corrections_by_ours": [
            "componentRepositoryIikpi",
            "componentRepositoryIkpikpi",
            "componentIkpiIkpi",
            "componentRepositoryIrepository",
            "ikpiRepositoryIkpi",
            "componentRepositoryIcomponent",
            "repositoryRepositoryIkpi",
            "componentComponentIkpi",
            "componentRepositoryRepositorykpi",
            "componentRepositoryComponentkpi"
        ],
        "corrections_by_baseline": [
            "componentRepository",
            "componentRepositoryImpl",
            "pluginRepository",
            "reportPluginRepository",
            "provideJaasApi",
            "webModuleMD",
            "profileEntityFramework",
            "securityContextRepositoryWebFilter",
            "idlModule",
            "resourceAdapterRepository"
        ]
    },
    {
        "original_word": "segments",
        "typo_word": "sefmenfs",
        "original_variable": "segments",
        "typo_variable": "sefmenfs",
        "original_code": "public boolean containsValue(Object value) {\n        if (value == null)\n            throw new NullPointerException();\n\n        // See explanation of modCount use above\n\n        final Segment<K,V>[] segments = this.segments;\n        int[] mc = new int[segments.length];\n\n        // Try a few times without locking\n        for (int k = 0; k < RETRIES_BEFORE_LOCK; ++k) {\n            int mcsum = 0;\n            for (int i = 0; i < segments.length; ++i) {\n                mcsum += mc[i] = segments[i].modCount;\n                if (segments[i].containsValue(value))\n                    return true;\n            }\n            boolean cleanSweep = true;\n            if (mcsum != 0) {\n                for (int i = 0; i < segments.length; ++i) {\n                    if (mc[i] != segments[i].modCount) {\n                        cleanSweep = false;\n                        break;\n                    }\n                }\n            }\n            if (cleanSweep)\n                return false;\n        }\n        // Resort to locking all segments\n        for (int i = 0; i < segments.length; ++i)\n            segments[i].lock();\n        boolean found = false;\n        try {\n            for (int i = 0; i < segments.length; ++i) {\n                if (segments[i].containsValue(value)) {\n                    found = true;\n                    break;\n                }\n            }\n        } finally {\n            for (int i = 0; i < segments.length; ++i)\n                segments[i].unlock();\n        }\n        return found;\n    }",
        "modified_code": "public boolean containsValue(Object value) {\n        if (value == null)\n            throw new NullPointerException();\n\n        // See explanation of modCount use above\n\n        final Segment<K,V>[] sefmenfs = this.sefmenfs;\n        int[] mc = new int[sefmenfs.length];\n\n        // Try a few times without locking\n        for (int k = 0; k < RETRIES_BEFORE_LOCK; ++k) {\n            int mcsum = 0;\n            for (int i = 0; i < sefmenfs.length; ++i) {\n                mcsum += mc[i] = sefmenfs[i].modCount;\n                if (sefmenfs[i].containsValue(value))\n                    return true;\n            }\n            boolean cleanSweep = true;\n            if (mcsum != 0) {\n                for (int i = 0; i < sefmenfs.length; ++i) {\n                    if (mc[i] != sefmenfs[i].modCount) {\n                        cleanSweep = false;\n                        break;\n                    }\n                }\n            }\n            if (cleanSweep)\n                return false;\n        }\n        // Resort to locking all segments\n        for (int i = 0; i < sefmenfs.length; ++i)\n            sefmenfs[i].lock();\n        boolean found = false;\n        try {\n            for (int i = 0; i < sefmenfs.length; ++i) {\n                if (sefmenfs[i].containsValue(value)) {\n                    found = true;\n                    break;\n                }\n            }\n        } finally {\n            for (int i = 0; i < sefmenfs.length; ++i)\n                sefmenfs[i].unlock();\n        }\n        return found;\n    }",
        "explanations_by_ours": [
            "the segments to search in",
            "the segments to search",
            "the segments in this map"
        ],
        "corrections_by_ours": [
            "segmentsfs",
            "searchfs",
            "mapfs",
            "sefmensegments",
            "sefmenmap",
            "sefmensearch",
            "sefmenfs"
        ],
        "corrections_by_baseline": [
            "vmas",
            "fos",
            "ifaces",
            "intfs",
            "folders",
            "sdims",
            "geometries",
            "nestedDatasets",
            "hSeps",
            "fcElems"
        ]
    },
    {
        "original_word": "schemas",
        "typo_word": "schejax",
        "original_variable": "schemas",
        "typo_variable": "schejax",
        "original_code": "public static Schema getNonNull(Schema schema) {\n    if (schema.getType().equals(Schema.Type.UNION)) {\n      List<Schema> schemas = schema.getTypes();\n      if (schemas.size() == 2) {\n        if (schemas.get(0).getType().equals(Schema.Type.NULL)) {\n          return schemas.get(1);\n        } else if (schemas.get(1).getType().equals(Schema.Type.NULL)) {\n          return schemas.get(0);\n        } else {\n          return schema;\n        }\n      } else {\n        return schema;\n      }\n    } else {\n      return schema;\n    }\n  }",
        "modified_code": "public static Schema getNonNull(Schema schema) {\n    if (schema.getType().equals(Schema.Type.UNION)) {\n      List<Schema> schejax = schema.getTypes();\n      if (schejax.size() == 2) {\n        if (schejax.get(0).getType().equals(Schema.Type.NULL)) {\n          return schejax.get(1);\n        } else if (schejax.get(1).getType().equals(Schema.Type.NULL)) {\n          return schejax.get(0);\n        } else {\n          return schema;\n        }\n      } else {\n        return schema;\n      }\n    } else {\n      return schema;\n    }\n  }",
        "explanations_by_ours": [
            "the union of the schema and the union of the schema",
            "the union of the schema and the union of the schema and the union",
            "the union of the given schema and the union of the schema and the"
        ],
        "corrections_by_ours": [
            "schema",
            "given",
            "union"
        ],
        "corrections_by_baseline": [
            "schema",
            "scheme",
            "schema1",
            "jsp",
            "simpleSchema",
            "jspc",
            "saxParser",
            "saxBuilder",
            "jmx",
            "schemaFactory"
        ]
    },
    {
        "original_word": "params",
        "typo_word": "parzns",
        "original_variable": "params",
        "typo_variable": "parzns",
        "original_code": "public static MediaType create(String type, String subtype)\n\t{\n\t\tMap<String, String> params = Collections.emptyMap();\n\t\treturn create(type, subtype, params);\n\t}",
        "modified_code": "public static MediaType create(String type, String subtype)\n\t{\n\t\tMap<String, String> parzns = Collections.emptyMap();\n\t\treturn create(type, subtype, parzns);\n\t}",
        "explanations_by_ours": [
            "the parameters of the MediaType",
            "the parameters for the new MediaType",
            "the parameters of the new MediaType"
        ],
        "corrections_by_ours": [
            "parameters",
            "type",
            "media",
            "new"
        ],
        "corrections_by_baseline": [
            "mparms",
            "nparms",
            "parms",
            "par",
            "sparams",
            "stns",
            "gemparms",
            "nmaps",
            "nvars",
            "consts"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "odfsef",
        "original_variable": "offset",
        "typo_variable": "odfsef",
        "original_code": "public static String remove(final String string, final char ch) {\n\t\tint stringLen = string.length();\n\t\tchar[] result = new char[stringLen];\n\t\tint offset = 0;\n\n\t\tfor (int i = 0; i < stringLen; i++) {\n\t\t\tchar c = string.charAt(i);\n\n\t\t\tif (c == ch) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tresult[offset] = c;\n\t\t\toffset++;\n\t\t}\n\n\t\tif (offset == stringLen) {\n\t\t\treturn string;\t// no changes\n\t\t}\n\n\t\treturn new String(result, 0, offset);\n\t}",
        "modified_code": "public static String remove(final String string, final char ch) {\n\t\tint stringLen = string.length();\n\t\tchar[] result = new char[stringLen];\n\t\tint odfsef = 0;\n\n\t\tfor (int i = 0; i < stringLen; i++) {\n\t\t\tchar c = string.charAt(i);\n\n\t\t\tif (c == ch) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tresult[odfsef] = c;\n\t\t\todfsef++;\n\t\t}\n\n\t\tif (odfsef == stringLen) {\n\t\t\treturn string;\t// no changes\n\t\t}\n\n\t\treturn new String(result, 0, odfsef);\n\t}",
        "explanations_by_ours": [
            "the index of the character to remove",
            "the index of the character to remove from the specified string",
            "the number of characters to remove from the specified string"
        ],
        "corrections_by_ours": [
            "specified",
            "index",
            "number",
            "character",
            "characters",
            "string",
            "remove"
        ],
        "corrections_by_baseline": [
            "icf",
            "pce",
            "bsf",
            "ncf",
            "dpe",
            "specp",
            "spf",
            "rsf",
            "mefd",
            "etf"
        ]
    },
    {
        "original_word": "missed",
        "typo_word": "hissdd",
        "original_variable": "missed",
        "typo_variable": "hissdd",
        "original_code": "public static <T, U> void drainMaxLoop(SimplePlainQueue<T> q, Subscriber<? super U> a, boolean delayError,\n            Disposable dispose, QueueDrain<T, U> qd) {\n        int missed = 1;\n\n        for (;;) {\n            for (;;) {\n                boolean d = qd.done();\n\n                T v = q.poll();\n\n                boolean empty = v == null;\n\n                if (checkTerminated(d, empty, a, delayError, q, qd)) {\n                    if (dispose != null) {\n                        dispose.dispose();\n                    }\n                    return;\n                }\n\n                if (empty) {\n                    break;\n                }\n\n                long r = qd.requested();\n                if (r != 0L) {\n                    if (qd.accept(a, v)) {\n                        if (r != Long.MAX_VALUE) {\n                            qd.produced(1);\n                        }\n                    }\n                } else {\n                    q.clear();\n                    if (dispose != null) {\n                        dispose.dispose();\n                    }\n                    a.onError(new MissingBackpressureException(\"Could not emit value due to lack of requests.\"));\n                    return;\n                }\n            }\n\n            missed = qd.leave(-missed);\n            if (missed == 0) {\n                break;\n            }\n        }\n    }",
        "modified_code": "public static <T, U> void drainMaxLoop(SimplePlainQueue<T> q, Subscriber<? super U> a, boolean delayError,\n            Disposable dispose, QueueDrain<T, U> qd) {\n        int hissdd = 1;\n\n        for (;;) {\n            for (;;) {\n                boolean d = qd.done();\n\n                T v = q.poll();\n\n                boolean empty = v == null;\n\n                if (checkTerminated(d, empty, a, delayError, q, qd)) {\n                    if (dispose != null) {\n                        dispose.dispose();\n                    }\n                    return;\n                }\n\n                if (empty) {\n                    break;\n                }\n\n                long r = qd.requested();\n                if (r != 0L) {\n                    if (qd.accept(a, v)) {\n                        if (r != Long.MAX_VALUE) {\n                            qd.produced(1);\n                        }\n                    }\n                } else {\n                    q.clear();\n                    if (dispose != null) {\n                        dispose.dispose();\n                    }\n                    a.onError(new MissingBackpressureException(\"Could not emit value due to lack of requests.\"));\n                    return;\n                }\n            }\n\n            hissdd = qd.leave(-hissdd);\n            if (hissdd == 0) {\n                break;\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the number of items to drain",
            "the number of items in the queue",
            "the number of items to drain."
        ],
        "corrections_by_ours": [
            "items",
            "queue",
            "drain",
            "number"
        ],
        "corrections_by_baseline": [
            "hrsi",
            "drss",
            "zzzz",
            "mmh",
            "isSlee11",
            "sdds",
            "tmphandshake",
            "dh",
            "hcs",
            "wudpNonNull"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vakhe",
        "original_variable": "value",
        "typo_variable": "vakhe",
        "original_code": "protected boolean\n    matches(DapVariable var, DapSequence seq, DataCursor rec, CEAST filter)\n            throws DapException\n    {\n        Object value = eval(var, seq, rec, filter);\n        return ((Boolean) value);\n    }",
        "modified_code": "protected boolean\n    matches(DapVariable var, DapSequence seq, DataCursor rec, CEAST filter)\n            throws DapException\n    {\n        Object vakhe = eval(var, seq, rec, filter);\n        return ((Boolean) vakhe);\n    }",
        "explanations_by_ours": [
            "the value to evaluate the DapSequence against",
            "the value to evaluate",
            "the value to evaluate the DapVariable against"
        ],
        "corrections_by_ours": [
            "value",
            "evaluate",
            "variable",
            "dap",
            "sequence"
        ],
        "corrections_by_baseline": [
            "vDk",
            "kv",
            "ak",
            "uhe",
            "vk0",
            "hv",
            "vk1",
            "azim",
            "va",
            "vz"
        ]
    },
    {
        "original_word": "predecessor",
        "typo_word": "peexecessor",
        "original_variable": "predecessor",
        "typo_variable": "peexecessor",
        "original_code": "public boolean removeVertex(Vertex<T> v)\n   {\n      if (!verticies.containsValue(v))\n         return false;\n\n      verticies.remove(v.getName());\n      if( v == rootVertex )\n         rootVertex = null;\n\n      // Remove the edges associated with v\n      for(int n = 0; n < v.getOutgoingEdgeCount(); n ++)\n      {\n         Edge<T> e = v.getOutgoingEdge(n);\n         v.remove(e);\n         Vertex<T> to = e.getTo();\n         to.remove(e);\n         edges.remove(e);\n      }\n      for(int n = 0; n < v.getIncomingEdgeCount(); n ++)\n      {\n         Edge<T> e = v.getIncomingEdge(n);\n         v.remove(e);\n         Vertex<T> predecessor = e.getFrom();\n         predecessor.remove(e);\n      }\n      return true;\n   }",
        "modified_code": "public boolean removeVertex(Vertex<T> v)\n   {\n      if (!verticies.containsValue(v))\n         return false;\n\n      verticies.remove(v.getName());\n      if( v == rootVertex )\n         rootVertex = null;\n\n      // Remove the edges associated with v\n      for(int n = 0; n < v.getOutgoingEdgeCount(); n ++)\n      {\n         Edge<T> e = v.getOutgoingEdge(n);\n         v.remove(e);\n         Vertex<T> to = e.getTo();\n         to.remove(e);\n         edges.remove(e);\n      }\n      for(int n = 0; n < v.getIncomingEdgeCount(); n ++)\n      {\n         Edge<T> e = v.getIncomingEdge(n);\n         v.remove(e);\n         Vertex<T> peexecessor = e.getFrom();\n         peexecessor.remove(e);\n      }\n      return true;\n   }",
        "explanations_by_ours": [
            "Vertex from which the vertex is to be removed",
            "Vertex from which to remove the vertex",
            "Vertex to remove from"
        ],
        "corrections_by_ours": [
            "vertex",
            "removed",
            "remove"
        ],
        "corrections_by_baseline": [
            "stoker",
            "executor",
            "predecessor",
            "introspector",
            "toker",
            "runner",
            "caller",
            "fitRunner",
            "executorNode",
            "launcher"
        ]
    },
    {
        "original_word": "prefs",
        "typo_word": "lrets",
        "original_variable": "prefs",
        "typo_variable": "lrets",
        "original_code": "static public void setContext(final Context context) {\n        // once setContext is called, we can set up the uncaught exception handler since\n        // it will force logging to the file\n        if (null == LogPersister.context) {\n\n            // set a custom JUL Handler so we can capture third-party and internal java.util.logging.Logger API calls\n            LogManager.getLogManager().getLogger(\"\").addHandler(julHandler);\n            java.util.logging.Logger.getLogger(\"\").setLevel(Level.ALL);\n\n            LogPersister.context = context;\n\n            // now that we have a context, let's set the fileLoggerInstance properly unless it was already set by tests\n            if (fileLoggerInstance == null || fileLoggerInstance instanceof FileLogger) {\n                FileLogger.setContext(context);\n                fileLoggerInstance = FileLogger.getInstance();\n            }\n\n            SharedPreferences prefs = LogPersister.context.getSharedPreferences (SHARED_PREF_KEY, Context.MODE_PRIVATE);\n\n            // level\n            if (null != level) {  // someone called setLevel method before setContext\n                setLevelSync(level);  // seems redundant, but we do this to save to SharedPrefs now that we have Context\n            } else {  // set it to the SharedPrefs value, or DEFAULT if no value in SharedPrefs yet\n                setLevelSync(Logger.LEVEL.fromString(prefs.getString(SHARED_PREF_KEY_level, getLevelDefault().toString())));\n            }\n\n            // logFileMaxSize\n            if (null != logFileMaxSize) {  // someone called setMaxStoreSize method before setContext\n                setMaxLogStoreSize(logFileMaxSize);  // seems redundant, but we do this to save to SharedPrefs now that we have Context\n            } else {  // set it to the SharedPrefs value, or DEFAULT if no value in SharedPrefs yet\n                setMaxLogStoreSize(prefs.getInt(SHARED_PREF_KEY_logFileMaxSize, DEFAULT_logFileMaxSize));\n            }\n\n            // capture\n            if (null != capture) {  // someone called setCapture method before setContext\n                setCaptureSync(capture);  // seems redundant, but we do this to save to SharedPrefs now that we have Context\n            } else {  // set it to the SharedPrefs value, or DEFAULT if no value in SharedPrefs yet\n                setCaptureSync(prefs.getBoolean (SHARED_PREF_KEY_logPersistence, DEFAULT_capture));\n            }\n\n            uncaughtExceptionHandler = new UncaughtExceptionHandler ();\n            Thread.setDefaultUncaughtExceptionHandler (uncaughtExceptionHandler);\n        }\n    }",
        "modified_code": "static public void setContext(final Context context) {\n        // once setContext is called, we can set up the uncaught exception handler since\n        // it will force logging to the file\n        if (null == LogPersister.context) {\n\n            // set a custom JUL Handler so we can capture third-party and internal java.util.logging.Logger API calls\n            LogManager.getLogManager().getLogger(\"\").addHandler(julHandler);\n            java.util.logging.Logger.getLogger(\"\").setLevel(Level.ALL);\n\n            LogPersister.context = context;\n\n            // now that we have a context, let's set the fileLoggerInstance properly unless it was already set by tests\n            if (fileLoggerInstance == null || fileLoggerInstance instanceof FileLogger) {\n                FileLogger.setContext(context);\n                fileLoggerInstance = FileLogger.getInstance();\n            }\n\n            SharedPreferences lrets = LogPersister.context.getSharedPreferences (SHARED_PREF_KEY, Context.MODE_PRIVATE);\n\n            // level\n            if (null != level) {  // someone called setLevel method before setContext\n                setLevelSync(level);  // seems redundant, but we do this to save to SharedPrefs now that we have Context\n            } else {  // set it to the SharedPrefs value, or DEFAULT if no value in SharedPrefs yet\n                setLevelSync(Logger.LEVEL.fromString(lrets.getString(SHARED_PREF_KEY_level, getLevelDefault().toString())));\n            }\n\n            // logFileMaxSize\n            if (null != logFileMaxSize) {  // someone called setMaxStoreSize method before setContext\n                setMaxLogStoreSize(logFileMaxSize);  // seems redundant, but we do this to save to SharedPrefs now that we have Context\n            } else {  // set it to the SharedPrefs value, or DEFAULT if no value in SharedPrefs yet\n                setMaxLogStoreSize(lrets.getInt(SHARED_PREF_KEY_logFileMaxSize, DEFAULT_logFileMaxSize));\n            }\n\n            // capture\n            if (null != capture) {  // someone called setCapture method before setContext\n                setCaptureSync(capture);  // seems redundant, but we do this to save to SharedPrefs now that we have Context\n            } else {  // set it to the SharedPrefs value, or DEFAULT if no value in SharedPrefs yet\n                setCaptureSync(lrets.getBoolean (SHARED_PREF_KEY_logPersistence, DEFAULT_capture));\n            }\n\n            uncaughtExceptionHandler = new UncaughtExceptionHandler ();\n            Thread.setDefaultUncaughtExceptionHandler (uncaughtExceptionHandler);\n        }\n    }",
        "explanations_by_ours": [
            "the SharedPreferences to use for this logger.",
            "the SharedPrefs to use for this logger.",
            "the SharedPreferences to use for this logger"
        ],
        "corrections_by_ours": [
            "lprefs",
            "lpreferences",
            "loggerrets",
            "lshared",
            "userets",
            "sharedrets",
            "preferencesrets",
            "prefsrets",
            "luse",
            "llogger"
        ],
        "corrections_by_baseline": [
            "salt",
            "ckeys",
            "deeperList",
            "entries",
            "dolacons",
            "discoveries",
            "tweak",
            "challenges",
            "secret",
            "reals"
        ]
    },
    {
        "original_word": "nelems",
        "typo_word": "nrlens",
        "original_variable": "nelems",
        "typo_variable": "nrlens",
        "original_code": "public ArrayObject make1DStringArray() {\r\n    int nelems = (getRank() == 0) ? 1 : (int) getSize() / indexCalc.getShape(getRank()-1);\r\n    Array sarr = Array.factory(DataType.STRING, new int[]{nelems});\r\n    IndexIterator newsiter = sarr.getIndexIterator();\r\n\r\n    ArrayChar.StringIterator siter = getStringIterator();\r\n    while (siter.hasNext()) {\r\n      newsiter.setObjectNext(siter.next());\r\n    }\r\n    return (ArrayObject) sarr;\r\n  }",
        "modified_code": "public ArrayObject make1DStringArray() {\r\n    int nrlens = (getRank() == 0) ? 1 : (int) getSize() / indexCalc.getShape(getRank()-1);\r\n    Array sarr = Array.factory(DataType.STRING, new int[]{nrlens});\r\n    IndexIterator newsiter = sarr.getIndexIterator();\r\n\r\n    ArrayChar.StringIterator siter = getStringIterator();\r\n    while (siter.hasNext()) {\r\n      newsiter.setObjectNext(siter.next());\r\n    }\r\n    return (ArrayObject) sarr;\r\n  }",
        "explanations_by_ours": [
            "The number of strings in the array.",
            "The number of strings to make.",
            "The number of strings to create."
        ],
        "corrections_by_ours": [
            "numberlens",
            "nrstrings",
            "arraylens",
            "createlens",
            "nrcreate",
            "stringslens",
            "makelens",
            "nrmake",
            "nrnumber",
            "nrarray"
        ],
        "corrections_by_baseline": [
            "lens",
            "npts",
            "ncores",
            "nrg",
            "ilen",
            "N",
            "n",
            "s_n",
            "lCount",
            "cnc"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resuih",
        "original_variable": "result",
        "typo_variable": "resuih",
        "original_code": "static private final String to64(long v, int size) {\n        StringBuffer result = new StringBuffer();\n\n        while (--size >= 0) {\n            result.append(itoa64.charAt((int) (v & 0x3f)));\n            v >>>= 6;\n        }\n\n        return result.toString();\n    }",
        "modified_code": "static private final String to64(long v, int size) {\n        StringBuffer resuih = new StringBuffer();\n\n        while (--size >= 0) {\n            resuih.append(itoa64.charAt((int) (v & 0x3f)));\n            v >>>= 6;\n        }\n\n        return resuih.toString();\n    }",
        "explanations_by_ours": [
            "the string to append to",
            "the string to use for the result",
            "the buffer to use for the result"
        ],
        "corrections_by_ours": [
            "result",
            "use",
            "string",
            "append",
            "buffer"
        ],
        "corrections_by_baseline": [
            "resul",
            "res",
            "srv",
            "usv",
            "urlonv",
            "resName",
            "rdr",
            "srcc",
            "urpt",
            "rsf"
        ]
    },
    {
        "original_word": "tokens",
        "typo_word": "tlkems",
        "original_variable": "tokens",
        "typo_variable": "tlkems",
        "original_code": "public static SlotKey parse(String string) {\n        String[] tokens = string.split(\",\");\n        if (tokens.length != 3) {\n            return null;\n        }\n        Granularity granularity = Granularity.fromString(tokens[0]);\n        if (granularity == null) {\n            return null;\n        }\n        try {\n            int slot = Integer.parseInt(tokens[1]);\n            int shard = Integer.parseInt(tokens[2]);\n            return of(granularity, slot, shard);\n        } catch (IllegalArgumentException e) {\n            return null;\n        }\n    }",
        "modified_code": "public static SlotKey parse(String string) {\n        String[] tlkems = string.split(\",\");\n        if (tlkems.length != 3) {\n            return null;\n        }\n        Granularity granularity = Granularity.fromString(tlkems[0]);\n        if (granularity == null) {\n            return null;\n        }\n        try {\n            int slot = Integer.parseInt(tlkems[1]);\n            int shard = Integer.parseInt(tlkems[2]);\n            return of(granularity, slot, shard);\n        } catch (IllegalArgumentException e) {\n            return null;\n        }\n    }",
        "explanations_by_ours": [
            "the comma-separated list of slot and shard names",
            "the comma-separated list of slot and shard numbers",
            "the comma-separated list of slot key names and shards"
        ],
        "corrections_by_ours": [
            "names",
            "key",
            "numbers",
            "slot",
            "list",
            "comma",
            "shards",
            "shard",
            "-",
            "separated"
        ],
        "corrections_by_baseline": [
            "timeoutSeconds",
            "timeout_seconds",
            "delayMillis",
            "ttl",
            "snoozeDurationMillis",
            "idleTimeMillis",
            "deadlineNs",
            "delayedMinutes",
            "msecs",
            "delayInHundredthsOfASecond"
        ]
    },
    {
        "original_word": "alterations",
        "typo_word": "akterwtions",
        "original_variable": "alterations",
        "typo_variable": "akterwtions",
        "original_code": "public void commit()\n    {\n        TxId txId = null;\n\n        // Check if in a higher transactional mode than none, otherwise commit does nothing.\n        if (!getIsolationLevel().equals(IsolationLevel.None))\n        {\n            // Extract the current transaction id.\n            txId = TxManager.getTxIdFromThread();\n\n            // Wait until the global write lock can be acquired by this transaction.\n            try\n            {\n                acquireGlobalWriteLock(txId);\n            }\n            catch (InterruptedException e)\n            {\n                // The commit was interrupted, so cannot succeed.\n                throw new IllegalStateException(\"Interrupted whilst commit is waiting for global write lock.\", e);\n            }\n\n            // Check that this transaction has made changes to be committed.\n            List<TxOperation> alterations = txWrites.get(txId);\n\n            try\n            {\n                if (alterations != null)\n                {\n                    // Loop through all the writes that the transaction wants to apply to the resource.\n                    for (TxOperation nextAlteration : alterations)\n                    {\n                        // Apply the change and update the term resource.\n                        nextAlteration.execute();\n                    }\n\n                    // Clear the write behind cache for this transaction as its work has been completed.\n                    txWrites.remove(txId);\n                }\n            }\n            finally\n            {\n                // Release the global write lock.\n                releaseGlobalWriteLock();\n            }\n        }\n    }",
        "modified_code": "public void commit()\n    {\n        TxId txId = null;\n\n        // Check if in a higher transactional mode than none, otherwise commit does nothing.\n        if (!getIsolationLevel().equals(IsolationLevel.None))\n        {\n            // Extract the current transaction id.\n            txId = TxManager.getTxIdFromThread();\n\n            // Wait until the global write lock can be acquired by this transaction.\n            try\n            {\n                acquireGlobalWriteLock(txId);\n            }\n            catch (InterruptedException e)\n            {\n                // The commit was interrupted, so cannot succeed.\n                throw new IllegalStateException(\"Interrupted whilst commit is waiting for global write lock.\", e);\n            }\n\n            // Check that this transaction has made changes to be committed.\n            List<TxOperation> akterwtions = txWrites.get(txId);\n\n            try\n            {\n                if (akterwtions != null)\n                {\n                    // Loop through all the writes that the transaction wants to apply to the resource.\n                    for (TxOperation nextAlteration : akterwtions)\n                    {\n                        // Apply the change and update the term resource.\n                        nextAlteration.execute();\n                    }\n\n                    // Clear the write behind cache for this transaction as its work has been completed.\n                    txWrites.remove(txId);\n                }\n            }\n            finally\n            {\n                // Release the global write lock.\n                releaseGlobalWriteLock();\n            }\n        }\n    }",
        "explanations_by_ours": [
            "The list of writes to be applied to the term resource.",
            "The list of writes to be applied to the resource.",
            "The list of writes that should be applied to the resource."
        ],
        "corrections_by_ours": [
            "term",
            "writes",
            "applied",
            "resource",
            "list"
        ],
        "corrections_by_baseline": [
            "edits",
            "ngates",
            "alts",
            "goals",
            "lopts",
            "exps",
            "wac",
            "postsGoals",
            "automats",
            "grants"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vapke",
        "original_variable": "value",
        "typo_variable": "vapke",
        "original_code": "static public Date getStandardDate(String text) {\r\n    double value;\r\n    String udunitString;\r\n\r\n    text = text.trim();\r\n    StringTokenizer stoker = new StringTokenizer(text);\r\n    String firstToke = stoker.nextToken();\r\n    try {\r\n      value = Double.parseDouble(firstToke);\r\n      udunitString = text.substring(firstToke.length());\r\n    } catch (NumberFormatException e) { // stupid way to test if it starts with a number\r\n      value = 0.0;\r\n      udunitString = text;\r\n    }\r\n\r\n    DateUnit du;\r\n    try {\r\n      du = new DateUnit(udunitString);\r\n    } catch (Exception e) {\r\n      return null;\r\n    }\r\n\r\n    return du.makeDate(value);\r\n  }",
        "modified_code": "static public Date getStandardDate(String text) {\r\n    double vapke;\r\n    String udunitString;\r\n\r\n    text = text.trim();\r\n    StringTokenizer stoker = new StringTokenizer(text);\r\n    String firstToke = stoker.nextToken();\r\n    try {\r\n      vapke = Double.parseDouble(firstToke);\r\n      udunitString = text.substring(firstToke.length());\r\n    } catch (NumberFormatException e) { // stupid way to test if it starts with a number\r\n      vapke = 0.0;\r\n      udunitString = text;\r\n    }\r\n\r\n    DateUnit du;\r\n    try {\r\n      du = new DateUnit(udunitString);\r\n    } catch (Exception e) {\r\n      return null;\r\n    }\r\n\r\n    return du.makeDate(vapke);\r\n  }",
        "explanations_by_ours": [
            "The vapke of the standard date.",
            "The vapke of the date.",
            "The standard vapke."
        ],
        "corrections_by_ours": [
            "date",
            "standard"
        ],
        "corrections_by_baseline": [
            "vz",
            "vf",
            "va",
            "wv",
            "hv",
            "PV",
            "pv",
            "vDk",
            "vms",
            "vsn"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "cirrenh",
        "original_variable": "currentTx",
        "typo_variable": "cirrenhTx",
        "original_code": "public JtxTransaction requestTransaction(final JtxTransactionMode mode, final Object scope) {\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"Requesting TX \" + mode.toString());\n\t\t}\n\t\tJtxTransaction currentTx = getTransaction();\n\t\tif (!isNewTxScope(currentTx, scope)) {\n\t\t\treturn currentTx;\n\t\t}\n\t\tswitch (mode.getPropagationBehavior()) {\n\t\t\tcase PROPAGATION_REQUIRED: return propRequired(currentTx, mode, scope);\n\t\t\tcase PROPAGATION_SUPPORTS: return propSupports(currentTx, mode, scope);\n\t\t\tcase PROPAGATION_MANDATORY: return propMandatory(currentTx, mode, scope);\n\t\t\tcase PROPAGATION_REQUIRES_NEW: return propRequiresNew(currentTx, mode, scope);\n\t\t\tcase PROPAGATION_NOT_SUPPORTED: return propNotSupported(currentTx, mode, scope);\n\t\t\tcase PROPAGATION_NEVER: return propNever(currentTx, mode, scope);\n\t\t}\n\t\tthrow new JtxException(\"Invalid TX propagation value: \" + mode.getPropagationBehavior().value());\n\t}",
        "modified_code": "public JtxTransaction requestTransaction(final JtxTransactionMode mode, final Object scope) {\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"Requesting TX \" + mode.toString());\n\t\t}\n\t\tJtxTransaction cirrenhTx = getTransaction();\n\t\tif (!isNewTxScope(cirrenhTx, scope)) {\n\t\t\treturn cirrenhTx;\n\t\t}\n\t\tswitch (mode.getPropagationBehavior()) {\n\t\t\tcase PROPAGATION_REQUIRED: return propRequired(cirrenhTx, mode, scope);\n\t\t\tcase PROPAGATION_SUPPORTS: return propSupports(cirrenhTx, mode, scope);\n\t\t\tcase PROPAGATION_MANDATORY: return propMandatory(cirrenhTx, mode, scope);\n\t\t\tcase PROPAGATION_REQUIRES_NEW: return propRequiresNew(cirrenhTx, mode, scope);\n\t\t\tcase PROPAGATION_NOT_SUPPORTED: return propNotSupported(cirrenhTx, mode, scope);\n\t\t\tcase PROPAGATION_NEVER: return propNever(cirrenhTx, mode, scope);\n\t\t}\n\t\tthrow new JtxException(\"Invalid TX propagation value: \" + mode.getPropagationBehavior().value());\n\t}",
        "explanations_by_ours": [
            "the current transaction",
            "the transaction",
            "the transaction object"
        ],
        "corrections_by_ours": [
            "currentTx",
            "objectTx",
            "cirrenhTransaction",
            "transactionTx",
            "cirrenhCurrent",
            "cirrenhObject",
            "cirrenhTx"
        ],
        "corrections_by_baseline": [
            "inTx",
            "microTx",
            "clientTX",
            "tranX",
            "newTx",
            "rollbackTx",
            "forgottenTx",
            "requestedTx",
            "transaction",
            "currentTx"
        ]
    },
    {
        "original_word": "constant",
        "typo_word": "constagf",
        "original_variable": "constantPoolEntryIndex",
        "typo_variable": "constagfPoolEntryIndex",
        "original_code": "public String readUTF8(final int offset, final char[] charBuffer) {\n    int constantPoolEntryIndex = readUnsignedShort(offset);\n    if (offset == 0 || constantPoolEntryIndex == 0) {\n      return null;\n    }\n    return readUtf(constantPoolEntryIndex, charBuffer);\n  }",
        "modified_code": "public String readUTF8(final int offset, final char[] charBuffer) {\n    int constagfPoolEntryIndex = readUnsignedShort(offset);\n    if (offset == 0 || constagfPoolEntryIndex == 0) {\n      return null;\n    }\n    return readUtf(constagfPoolEntryIndex, charBuffer);\n  }",
        "explanations_by_ours": [
            "the index of the constagf pool entry to read",
            "the index of the constantagf pool entry to read",
            "the constagf pool entry index"
        ],
        "corrections_by_ours": [
            "constantagfPoolEntryIndex",
            "entryPoolEntryIndex",
            "constagfPoolConstagfIndex",
            "constagfPoolIndexIndex",
            "constagfPoolEntryEntry",
            "constagfPoolConstantagfIndex",
            "indexPoolEntryIndex",
            "poolPoolEntryIndex",
            "readPoolEntryIndex",
            "constagfConstagfEntryIndex"
        ],
        "corrections_by_baseline": [
            "constantPoolEntryIndex",
            "constantPoolCount",
            "constpool",
            "constantvalueIndex",
            "poolRefName",
            "objectPool",
            "poolKey",
            "poolSize",
            "classPool",
            "poolid"
        ]
    },
    {
        "original_word": "Coutner",
        "typo_word": "Cohtmer",
        "original_variable": "snapshotCoutner",
        "typo_variable": "snapshotCohtmer",
        "original_code": "private static boolean updateIfSmaller(AtomicInteger counter, int value) {\n\t\tfor (;;) {\n\t\t\tint snapshotCoutner = counter.get();\n\t\t\tif (snapshotCoutner >= value)\n\t\t\t\treturn false;\n\t\t\tif (counter.compareAndSet(snapshotCoutner, value))\n\t\t\t\treturn true;\n\t\t}\n\t}",
        "modified_code": "private static boolean updateIfSmaller(AtomicInteger counter, int value) {\n\t\tfor (;;) {\n\t\t\tint snapshotCohtmer = counter.get();\n\t\t\tif (snapshotCohtmer >= value)\n\t\t\t\treturn false;\n\t\t\tif (counter.compareAndSet(snapshotCohtmer, value))\n\t\t\t\treturn true;\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the value of the counter",
            "the value to be updated.",
            "the value of the counter."
        ],
        "corrections_by_ours": [
            "snapshotCounter",
            "snapshotUpdated",
            "snapshotValue",
            "valueCohtmer",
            "counterCohtmer",
            "updatedCohtmer",
            "snapshotCohtmer"
        ],
        "corrections_by_baseline": [
            "snapshot",
            "finalSnapshot",
            "serializableSnapshot",
            "snapshotCoutner",
            "curDsCopy",
            "snapshots",
            "snapshotName",
            "mvnSnapshotVersion",
            "latestSnapshotTxId",
            "historicalStateToRemap"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nqmw",
        "original_variable": "fileName",
        "typo_variable": "fileNqmw",
        "original_code": "public static File createTempFile(final String extension) {\r\n    try {\r\n      final String fileName = String.format(\"wro4j-%s.%s\", UUID.randomUUID().toString(), extension);\r\n      final File file = new File(createTempDirectory(), fileName);\r\n      file.createNewFile();\r\n      return file;\r\n    } catch (final IOException e) {\r\n      throw WroRuntimeException.wrap(e);\r\n    }\r\n  }",
        "modified_code": "public static File createTempFile(final String extension) {\r\n    try {\r\n      final String fileNqmw = String.format(\"wro4j-%s.%s\", UUID.randomUUID().toString(), extension);\r\n      final File file = new File(createTempDirectory(), fileNqmw);\r\n      file.createNewFile();\r\n      return file;\r\n    } catch (final IOException e) {\r\n      throw WroRuntimeException.wrap(e);\r\n    }\r\n  }",
        "explanations_by_ours": [
            "the name of the file.",
            "the file name.",
            "the name of the temporary file."
        ],
        "corrections_by_ours": [
            "fileName",
            "nameNqmw",
            "fileTemporary",
            "temporaryNqmw",
            "fileFile",
            "fileNqmw"
        ],
        "corrections_by_baseline": [
            "cncFile",
            "stnFile",
            "ncfileOut",
            "ncfile",
            "mfile",
            "tsFile",
            "mfilep",
            "ncfileIn",
            "sfile",
            "outFile"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reskly",
        "original_variable": "result",
        "typo_variable": "reskly",
        "original_code": "public static <T, E extends Throwable> Collection<T> filter(Iterable<T> coll, APredicate<? super T, E> pred) throws E {\n        final List<T> result = new ArrayList<>();\n        for(T o: coll) {\n            if(pred.apply(o)) {\n                result.add(o);\n            }\n        }\n        return result;\n    }",
        "modified_code": "public static <T, E extends Throwable> Collection<T> filter(Iterable<T> coll, APredicate<? super T, E> pred) throws E {\n        final List<T> reskly = new ArrayList<>();\n        for(T o: coll) {\n            if(pred.apply(o)) {\n                reskly.add(o);\n            }\n        }\n        return reskly;\n    }",
        "explanations_by_ours": [
            "the collection of objects to filter",
            "the collection of objects to be filtered",
            "the resulting collection"
        ],
        "corrections_by_ours": [
            "resulting",
            "collection",
            "filtered",
            "filter",
            "objects"
        ],
        "corrections_by_baseline": [
            "resul",
            "res",
            "ry",
            "vy",
            "syy",
            "raven",
            "ykr",
            "urpt",
            "lycent",
            "soft"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "tesuit",
        "original_variable": "result",
        "typo_variable": "tesuit",
        "original_code": "public void process(final Resource resource, final Reader reader, final Writer writer)\r\n    throws IOException {\r\n    try {\r\n      final String result = new Lessify().variablizeColors(IOUtils.toString(reader));\r\n      writer.write(result);\r\n    } finally {\r\n      reader.close();\r\n      writer.close();\r\n    }\r\n  }",
        "modified_code": "public void process(final Resource resource, final Reader reader, final Writer writer)\r\n    throws IOException {\r\n    try {\r\n      final String tesuit = new Lessify().variablizeColors(IOUtils.toString(reader));\r\n      writer.write(tesuit);\r\n    } finally {\r\n      reader.close();\r\n      writer.close();\r\n    }\r\n  }",
        "explanations_by_ours": [
            "the tesuit",
            "the tesuit to be processed",
            "the tesuit to be processed."
        ],
        "corrections_by_ours": [
            "processedsuit",
            "teprocessed",
            "suitsuit",
            "tete",
            "tesuit"
        ],
        "corrections_by_baseline": [
            "octet",
            "TU",
            "tu",
            "tstring",
            "base64Text",
            "tsu",
            "base64Bytes",
            "istream",
            "ti",
            "payloadBase64"
        ]
    },
    {
        "original_word": "indirect",
        "typo_word": "ibdirwct",
        "original_variable": "indirect",
        "typo_variable": "ibdirwct",
        "original_code": "private void instertIntoTaxonomy(final IndexedObjectProperty property) {\n\n\t\t/* \n\t\t * @formatter:off\n\t\t * \n\t\t * Transitive reduction and taxonomy computation\n\t\t * \tif sub-properties of a sub-property contain this property,\n\t\t * \t\tthey are equivalent\n\t\t * \tif a property is a strict sub-property of another strict sub-property,\n\t\t * \t\tit is not direct\n\t\t * \n\t\t * @formatter:on\n\t\t */\n\n\t\tfinal Map<IndexedObjectProperty, ElkObjectProperty> equivalent = collectEquivalent(\n\t\t\t\tproperty);\n\t\tif (equivalent == null) {\n\t\t\t// Equivalent to top.\n\t\t\treturn;\n\t\t}\n\t\tfinal Map<IndexedObjectProperty, Collection<? extends ElkObjectProperty>> subEquivalent = new ArrayHashMap<IndexedObjectProperty, Collection<? extends ElkObjectProperty>>();\n\t\tfinal Set<IndexedObjectProperty> indirect = new ArrayHashSet<IndexedObjectProperty>();\n\t\tfor (final IndexedObjectProperty subProperty : property.getSaturated()\n\t\t\t\t.getSubProperties()) {\n\n\t\t\tif (equivalent.containsKey(subProperty)) {\n\t\t\t\t// subProperty is not strict\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// subProperty is strict\n\n\t\t\tfinal Map<IndexedObjectProperty, ElkObjectProperty> subEq = collectEquivalent(\n\t\t\t\t\tsubProperty);\n\t\t\t// should not be null, because top cannot be a strict sub-property\n\t\t\tsubEquivalent.put(subProperty, subEq.values());\n\t\t\tfor (final IndexedObjectProperty subSubProperty : subProperty\n\t\t\t\t\t.getSaturated().getSubProperties()) {\n\t\t\t\tif (!subEq.containsKey(subSubProperty)) {\n\t\t\t\t\t// strict\n\t\t\t\t\tindirect.add(subSubProperty);\n\t\t\t\t}\n\t\t\t}\n\n\t\t}\n\n\t\t/*\n\t\t * If property is not equivalent to bottom and there are no strict sub\n\t\t * properties, add the bottom as a default sub property.\n\t\t */\n\t\tif (subEquivalent.isEmpty() && (indexedBottomProperty_ == null\n\t\t\t\t|| !equivalent.containsKey(indexedBottomProperty_))) {\n\t\t\toutputProcessor_\n\t\t\t\t\t.visit(new TransitiveReductionOutputEquivalentDirectImpl<ElkObjectProperty>(\n\t\t\t\t\t\t\tequivalent.values(), defaultDirectSubproperties_));\n\t\t\treturn;\n\t\t}\n\t\t// else\n\n\t\tfinal Collection<Collection<? extends ElkObjectProperty>> direct = Operations\n\t\t\t\t.map(subEquivalent.entrySet(),\n\t\t\t\t\t\tnew Operations.Transformation<Map.Entry<IndexedObjectProperty, Collection<? extends ElkObjectProperty>>, Collection<? extends ElkObjectProperty>>() {\n\n\t\t\t\t\t\t\t@Override\n\t\t\t\t\t\t\tpublic Collection<? extends ElkObjectProperty> transform(\n\t\t\t\t\t\t\t\t\tfinal Entry<IndexedObjectProperty, Collection<? extends ElkObjectProperty>> element) {\n\t\t\t\t\t\t\t\tif (indirect.contains(element.getKey())) {\n\t\t\t\t\t\t\t\t\treturn null;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\treturn element.getValue();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t});\n\n\t\toutputProcessor_\n\t\t\t\t.visit(new TransitiveReductionOutputEquivalentDirectImpl<ElkObjectProperty>(\n\t\t\t\t\t\tequivalent.values(), direct));\n\n\t}",
        "modified_code": "private void instertIntoTaxonomy(final IndexedObjectProperty property) {\n\n\t\t/* \n\t\t * @formatter:off\n\t\t * \n\t\t * Transitive reduction and taxonomy computation\n\t\t * \tif sub-properties of a sub-property contain this property,\n\t\t * \t\tthey are equivalent\n\t\t * \tif a property is a strict sub-property of another strict sub-property,\n\t\t * \t\tit is not direct\n\t\t * \n\t\t * @formatter:on\n\t\t */\n\n\t\tfinal Map<IndexedObjectProperty, ElkObjectProperty> equivalent = collectEquivalent(\n\t\t\t\tproperty);\n\t\tif (equivalent == null) {\n\t\t\t// Equivalent to top.\n\t\t\treturn;\n\t\t}\n\t\tfinal Map<IndexedObjectProperty, Collection<? extends ElkObjectProperty>> subEquivalent = new ArrayHashMap<IndexedObjectProperty, Collection<? extends ElkObjectProperty>>();\n\t\tfinal Set<IndexedObjectProperty> ibdirwct = new ArrayHashSet<IndexedObjectProperty>();\n\t\tfor (final IndexedObjectProperty subProperty : property.getSaturated()\n\t\t\t\t.getSubProperties()) {\n\n\t\t\tif (equivalent.containsKey(subProperty)) {\n\t\t\t\t// subProperty is not strict\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// subProperty is strict\n\n\t\t\tfinal Map<IndexedObjectProperty, ElkObjectProperty> subEq = collectEquivalent(\n\t\t\t\t\tsubProperty);\n\t\t\t// should not be null, because top cannot be a strict sub-property\n\t\t\tsubEquivalent.put(subProperty, subEq.values());\n\t\t\tfor (final IndexedObjectProperty subSubProperty : subProperty\n\t\t\t\t\t.getSaturated().getSubProperties()) {\n\t\t\t\tif (!subEq.containsKey(subSubProperty)) {\n\t\t\t\t\t// strict\n\t\t\t\t\tibdirwct.add(subSubProperty);\n\t\t\t\t}\n\t\t\t}\n\n\t\t}\n\n\t\t/*\n\t\t * If property is not equivalent to bottom and there are no strict sub\n\t\t * properties, add the bottom as a default sub property.\n\t\t */\n\t\tif (subEquivalent.isEmpty() && (indexedBottomProperty_ == null\n\t\t\t\t|| !equivalent.containsKey(indexedBottomProperty_))) {\n\t\t\toutputProcessor_\n\t\t\t\t\t.visit(new TransitiveReductionOutputEquivalentDirectImpl<ElkObjectProperty>(\n\t\t\t\t\t\t\tequivalent.values(), defaultDirectSubproperties_));\n\t\t\treturn;\n\t\t}\n\t\t// else\n\n\t\tfinal Collection<Collection<? extends ElkObjectProperty>> direct = Operations\n\t\t\t\t.map(subEquivalent.entrySet(),\n\t\t\t\t\t\tnew Operations.Transformation<Map.Entry<IndexedObjectProperty, Collection<? extends ElkObjectProperty>>, Collection<? extends ElkObjectProperty>>() {\n\n\t\t\t\t\t\t\t@Override\n\t\t\t\t\t\t\tpublic Collection<? extends ElkObjectProperty> transform(\n\t\t\t\t\t\t\t\t\tfinal Entry<IndexedObjectProperty, Collection<? extends ElkObjectProperty>> element) {\n\t\t\t\t\t\t\t\tif (ibdirwct.contains(element.getKey())) {\n\t\t\t\t\t\t\t\t\treturn null;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\treturn element.getValue();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t});\n\n\t\toutputProcessor_\n\t\t\t\t.visit(new TransitiveReductionOutputEquivalentDirectImpl<ElkObjectProperty>(\n\t\t\t\t\t\tequivalent.values(), direct));\n\n\t}",
        "explanations_by_ours": [
            "the set of strict sub-properties of the top and bottom properties of",
            "the set of strict sub-properties of the top and bottom properties.",
            "the set of strict sub-properties of the top."
        ],
        "corrections_by_ours": [
            "strict",
            "bottom",
            "set",
            "properties",
            "-",
            "top",
            "sub"
        ],
        "corrections_by_baseline": [
            "userdir",
            "catWriteDir",
            "sparkDir",
            "dstDir",
            "dsDirPath",
            "tmpDir",
            "libDirs",
            "catWriteDirPath",
            "targetDir",
            "jarsDir"
        ]
    },
    {
        "original_word": "long",
        "typo_word": "logr",
        "original_variable": "longName",
        "typo_variable": "logrName",
        "original_code": "public String getClassShortName()\n   {\n      String longName = getClass().getName();\n      int dot = longName.lastIndexOf('.');\n      if (dot != -1)\n         return longName.substring(dot + 1);\n      return longName;\n   }",
        "modified_code": "public String getClassShortName()\n   {\n      String logrName = getClass().getName();\n      int dot = logrName.lastIndexOf('.');\n      if (dot != -1)\n         return logrName.substring(dot + 1);\n      return logrName;\n   }",
        "explanations_by_ours": [
            "the class name",
            "the logr name",
            "the name of the class"
        ],
        "corrections_by_ours": [
            "classogrName",
            "logrClass",
            "nameogrName",
            "ogrogrName",
            "lnameName",
            "lclassName",
            "llName",
            "logrOgr",
            "logrL",
            "logrName"
        ],
        "corrections_by_baseline": [
            "loggerName",
            "eName",
            "stnName",
            "tsrName",
            "dName",
            "dmrname",
            "ejbName",
            "cName",
            "messageClassName",
            "pName"
        ]
    },
    {
        "original_word": "beans",
        "typo_word": "heajs",
        "original_variable": "beans",
        "typo_variable": "heajs",
        "original_code": "public List<InterceptorBean> createInterceptors(\n    StageLibraryTask stageLib,\n    StageConfiguration stageConfiguration,\n    StageDefinition stageDefinition,\n    InterceptorCreatorContextBuilder contextBuilder,\n    InterceptorCreator.InterceptorType interceptorType,\n    List<Issue> issues\n  ) {\n    List<InterceptorBean> beans = new ArrayList<>();\n    if(contextBuilder == null) {\n      return beans;\n    }\n\n    for(InterceptorDefinition definition : stageLib.getInterceptorDefinitions()) {\n      InterceptorBean bean = createInterceptor(stageLib, definition, stageConfiguration, stageDefinition, contextBuilder, interceptorType, issues);\n      if (bean != null) {\n        beans.add(bean);\n      }\n    }\n\n    return beans;\n  }",
        "modified_code": "public List<InterceptorBean> createInterceptors(\n    StageLibraryTask stageLib,\n    StageConfiguration stageConfiguration,\n    StageDefinition stageDefinition,\n    InterceptorCreatorContextBuilder contextBuilder,\n    InterceptorCreator.InterceptorType interceptorType,\n    List<Issue> issues\n  ) {\n    List<InterceptorBean> heajs = new ArrayList<>();\n    if(contextBuilder == null) {\n      return heajs;\n    }\n\n    for(InterceptorDefinition definition : stageLib.getInterceptorDefinitions()) {\n      InterceptorBean bean = createInterceptor(stageLib, definition, stageConfiguration, stageDefinition, contextBuilder, interceptorType, issues);\n      if (bean != null) {\n        heajs.add(bean);\n      }\n    }\n\n    return heajs;\n  }",
        "explanations_by_ours": [
            "the heajs",
            "the heajs list",
            "the heajs to return"
        ],
        "corrections_by_ours": [
            "return",
            "list"
        ],
        "corrections_by_baseline": [
            "zs",
            "dks",
            "zps",
            "hedsiz",
            "ps",
            "zis",
            "nelems",
            "zos",
            "ksp",
            "pihalf"
        ]
    },
    {
        "original_word": "analysis",
        "typo_word": "anakysiw",
        "original_variable": "analysis",
        "typo_variable": "anakysiw",
        "original_code": "static public FeatureDataset wrap(FeatureType wantFeatureType, NetcdfDataset ncd, ucar.nc2.util.CancelTask task, Formatter errlog) throws IOException {\r\n    if (debug) System.out.println(\"wrap \" + ncd.getLocation() + \" want = \" + wantFeatureType);\r\n\r\n    // the case where we dont know what type it is\r\n    if ((wantFeatureType == null) || (wantFeatureType == FeatureType.ANY)) {\r\n      return wrapUnknown(ncd, task, errlog);\r\n    }\r\n\r\n    // find a Factory that claims this dataset by passing back an \"analysis result\" object\r\n    Object analysis = null;\r\n    FeatureDatasetFactory useFactory = null;\r\n    for (Factory fac : factoryList) {\r\n      if (!featureTypeOk(wantFeatureType, fac.featureType)) continue;\r\n      if (debug) System.out.println(\" wrap try factory \" + fac.factory.getClass().getName());\r\n\r\n      analysis = fac.factory.isMine(wantFeatureType, ncd, errlog);\r\n      if (analysis != null) {\r\n        useFactory = fac.factory;\r\n        break;\r\n      }\r\n    }\r\n\r\n    if (null == useFactory) {\r\n      errlog.format(\"**Failed to find FeatureDatasetFactory for= %s datatype=%s%n\", ncd.getLocation(), wantFeatureType);\r\n      return null;\r\n    }\r\n\r\n    // this call must be thread safe - done by implementation\r\n    return useFactory.open(wantFeatureType, ncd, analysis, task, errlog);\r\n  }",
        "modified_code": "static public FeatureDataset wrap(FeatureType wantFeatureType, NetcdfDataset ncd, ucar.nc2.util.CancelTask task, Formatter errlog) throws IOException {\r\n    if (debug) System.out.println(\"wrap \" + ncd.getLocation() + \" want = \" + wantFeatureType);\r\n\r\n    // the case where we dont know what type it is\r\n    if ((wantFeatureType == null) || (wantFeatureType == FeatureType.ANY)) {\r\n      return wrapUnknown(ncd, task, errlog);\r\n    }\r\n\r\n    // find a Factory that claims this dataset by passing back an \"analysis result\" object\r\n    Object anakysiw = null;\r\n    FeatureDatasetFactory useFactory = null;\r\n    for (Factory fac : factoryList) {\r\n      if (!featureTypeOk(wantFeatureType, fac.featureType)) continue;\r\n      if (debug) System.out.println(\" wrap try factory \" + fac.factory.getClass().getName());\r\n\r\n      anakysiw = fac.factory.isMine(wantFeatureType, ncd, errlog);\r\n      if (anakysiw != null) {\r\n        useFactory = fac.factory;\r\n        break;\r\n      }\r\n    }\r\n\r\n    if (null == useFactory) {\r\n      errlog.format(\"**Failed to find FeatureDatasetFactory for= %s datatype=%s%n\", ncd.getLocation(), wantFeatureType);\r\n      return null;\r\n    }\r\n\r\n    // this call must be thread safe - done by implementation\r\n    return useFactory.open(wantFeatureType, ncd, anakysiw, task, errlog);\r\n  }",
        "explanations_by_ours": [
            "the anaketransfer result object",
            "the anaketransfer result object.",
            "the anaketransfer result"
        ],
        "corrections_by_ours": [
            "anaketransfer",
            "result",
            "object"
        ],
        "corrections_by_baseline": [
            "kxky",
            "ykr",
            "wz",
            "koma",
            "skf",
            "ykuser",
            "wac",
            "osw",
            "nk",
            "CZ"
        ]
    },
    {
        "original_word": "sheet",
        "typo_word": "eteet",
        "original_variable": "sheetId",
        "typo_variable": "eteetId",
        "original_code": "public String getTabStyle() {\r\n\r\n\t\tString tabStyle = TieConstants.TAB_STYLE_VISIBLE;\r\n\t\tint sheetId = webFormTabView.getActiveIndex();\r\n\t\tif ((sheetId >= 0) && (sheetId < tabs.size())) {\r\n\t\t\ttabStyle = TieConstants.TAB_STYLE_INVISIBLE;\r\n\r\n\t\t}\r\n\r\n\t\treturn tabStyle;\r\n\t}",
        "modified_code": "public String getTabStyle() {\r\n\r\n\t\tString tabStyle = TieConstants.TAB_STYLE_VISIBLE;\r\n\t\tint eteetId = webFormTabView.getActiveIndex();\r\n\t\tif ((eteetId >= 0) && (eteetId < tabs.size())) {\r\n\t\t\ttabStyle = TieConstants.TAB_STYLE_INVISIBLE;\r\n\r\n\t\t}\r\n\r\n\t\treturn tabStyle;\r\n\t}",
        "explanations_by_ours": [
            "the id of the active tab.",
            "the id of the tab.",
            "the active index of the tab."
        ],
        "corrections_by_ours": [
            "eteetIndex",
            "indexId",
            "tabId",
            "activeId",
            "eteetActive",
            "idId",
            "eteetTab",
            "eteetId"
        ],
        "corrections_by_baseline": [
            "bdaId",
            "sID",
            "D_id",
            "ID",
            "id",
            "stid",
            "stnWmoId",
            "idName",
            "idAsString",
            "sidId"
        ]
    },
    {
        "original_word": "super",
        "typo_word": "suldr",
        "original_variable": "superClass",
        "typo_variable": "suldrClass",
        "original_code": "private Collection<Field> getAllFields(final Object object) {\r\n    final Collection<Field> fields = new ArrayList<Field>();\r\n    fields.addAll(Arrays.asList(object.getClass().getDeclaredFields()));\r\n    // inspect super classes\r\n    Class<?> superClass = object.getClass().getSuperclass();\r\n    while (superClass != null) {\r\n      fields.addAll(Arrays.asList(superClass.getDeclaredFields()));\r\n      superClass = superClass.getSuperclass();\r\n    }\r\n    return fields;\r\n  }",
        "modified_code": "private Collection<Field> getAllFields(final Object object) {\r\n    final Collection<Field> fields = new ArrayList<Field>();\r\n    fields.addAll(Arrays.asList(object.getClass().getDeclaredFields()));\r\n    // inspect super classes\r\n    Class<?> suldrClass = object.getClass().getSuperclass();\r\n    while (suldrClass != null) {\r\n      fields.addAll(Arrays.asList(suldrClass.getDeclaredFields()));\r\n      suldrClass = suldrClass.getSuperclass();\r\n    }\r\n    return fields;\r\n  }",
        "explanations_by_ours": [
            "the suldr class",
            "the suldrClass",
            "the suldr class to inspect"
        ],
        "corrections_by_ours": [
            "inspectClass",
            "classClass",
            "suldrInspect",
            "suldrSuldr",
            "suldrClass"
        ],
        "corrections_by_baseline": [
            "sbbClass",
            "wroManagerClassName",
            "iospClass",
            "strClass",
            "sbbConcreteClassName",
            "sbbAbstractClass",
            "sbbAbstractClassName",
            "_h_className",
            "crDsClass",
            "sbbLocalClass"
        ]
    },
    {
        "original_word": "requested",
        "typo_word": "rfquwsted",
        "original_variable": "x_requested",
        "typo_variable": "x_rfquwsted",
        "original_code": "public static boolean ajax(HttpServletRequest request) {\n        String x_requested = request.getHeader(\"x-requested-with\");\n        return !Strings.isNullOrEmpty(x_requested) && \"XMLHttpRequest\".equals(x_requested);\n    }",
        "modified_code": "public static boolean ajax(HttpServletRequest request) {\n        String x_rfquwsted = request.getHeader(\"x-requested-with\");\n        return !Strings.isNullOrEmpty(x_rfquwsted) && \"XMLHttpRequest\".equals(x_rfquwsted);\n    }",
        "explanations_by_ours": [
            "the X-Requested-With header value.",
            "the X-Requested-With header.",
            "the X-Requested-With header to check."
        ],
        "corrections_by_ours": [
            "x_requested",
            "x-_rfquwsted",
            "x_rfquwsted",
            "x_value",
            "x_header",
            "-_rfquwsted",
            "header_rfquwsted",
            "requested_rfquwsted",
            "check_rfquwsted",
            "value_rfquwsted"
        ],
        "corrections_by_baseline": [
            "xstell",
            "wrrp",
            "xpp",
            "rp",
            "bsf",
            "mR",
            "sndx",
            "eMx",
            "ncx",
            "wrpUnchecked"
        ]
    },
    {
        "original_word": "sorted",
        "typo_word": "wirted",
        "original_variable": "sorted",
        "typo_variable": "wirted",
        "original_code": "public void\n    sort()\n    {\n        List<DapNode> sorted = new ArrayList<DapNode>();\n        sortR(this, sorted);\n        // Assign indices\n        for(int i = 0; i < sorted.size(); i++) {\n            sorted.get(i).setIndex(i);\n        }\n        this.nodelist = sorted;\n    }",
        "modified_code": "public void\n    sort()\n    {\n        List<DapNode> wirted = new ArrayList<DapNode>();\n        sortR(this, wirted);\n        // Assign indices\n        for(int i = 0; i < wirted.size(); i++) {\n            wirted.get(i).setIndex(i);\n        }\n        this.nodelist = wirted;\n    }",
        "explanations_by_ours": [
            "the list of nodes to be sorted.",
            "the list of nodes to sort",
            "the list of nodes to sort."
        ],
        "corrections_by_ours": [
            "wirsorted",
            "listted",
            "sortted",
            "wirnodes",
            "sortedted",
            "nodested",
            "wirlist",
            "wirsort",
            "wirted"
        ],
        "corrections_by_baseline": [
            "drawn",
            "boxed",
            "wrpUnchecked",
            "spilled",
            "noisedba",
            "wis",
            "missed",
            "skipped",
            "rounded",
            "locked"
        ]
    },
    {
        "original_word": "merged",
        "typo_word": "mefgdd",
        "original_variable": "merged",
        "typo_variable": "mefgdd",
        "original_code": "public ImageApiProfile merge(ImageApiProfile other) {\n    ImageApiProfile merged = new ImageApiProfile();\n    streamNotNull(this.features).forEach(merged::addFeature);\n    streamNotNull(other.features).forEach(merged::addFeature);\n    streamNotNull(this.formats).forEach(merged::addFormat);\n    streamNotNull(other.formats).forEach(merged::addFormat);\n    streamNotNull(this.qualities).forEach(merged::addQuality);\n    streamNotNull(other.qualities).forEach(merged::addQuality);\n    if (this.maxWidth != null && other.maxWidth == null) {\n      merged.maxWidth = this.maxWidth;\n    } else if (this.maxWidth == null && other.maxWidth != null) {\n      merged.maxWidth = other.maxWidth;\n    } else if (this.maxWidth != null) {\n      merged.maxWidth = Math.min(this.maxWidth, other.maxWidth);\n    }\n    if (this.maxHeight != null && other.maxHeight == null) {\n      merged.maxHeight = this.maxHeight;\n    } else if (this.maxHeight == null && other.maxHeight != null) {\n      merged.maxHeight = other.maxHeight;\n    } else if (this.maxHeight != null) {\n      merged.maxHeight = Math.min(this.maxHeight, other.maxHeight);\n    }\n    if (this.maxArea != null && other.maxArea == null) {\n      merged.maxArea = this.maxArea;\n    } else if (this.maxArea == null && other.maxArea != null) {\n      merged.maxArea = other.maxArea;\n    } else if (this.maxArea != null) {\n      merged.maxArea = Math.min(this.maxArea, other.maxArea);\n    }\n    return merged;\n  }",
        "modified_code": "public ImageApiProfile merge(ImageApiProfile other) {\n    ImageApiProfile mefgdd = new ImageApiProfile();\n    streamNotNull(this.features).forEach(mefgdd::addFeature);\n    streamNotNull(other.features).forEach(mefgdd::addFeature);\n    streamNotNull(this.formats).forEach(mefgdd::addFormat);\n    streamNotNull(other.formats).forEach(mefgdd::addFormat);\n    streamNotNull(this.qualities).forEach(mefgdd::addQuality);\n    streamNotNull(other.qualities).forEach(mefgdd::addQuality);\n    if (this.maxWidth != null && other.maxWidth == null) {\n      mefgdd.maxWidth = this.maxWidth;\n    } else if (this.maxWidth == null && other.maxWidth != null) {\n      mefgdd.maxWidth = other.maxWidth;\n    } else if (this.maxWidth != null) {\n      mefgdd.maxWidth = Math.min(this.maxWidth, other.maxWidth);\n    }\n    if (this.maxHeight != null && other.maxHeight == null) {\n      mefgdd.maxHeight = this.maxHeight;\n    } else if (this.maxHeight == null && other.maxHeight != null) {\n      mefgdd.maxHeight = other.maxHeight;\n    } else if (this.maxHeight != null) {\n      mefgdd.maxHeight = Math.min(this.maxHeight, other.maxHeight);\n    }\n    if (this.maxArea != null && other.maxArea == null) {\n      mefgdd.maxArea = this.maxArea;\n    } else if (this.maxArea == null && other.maxArea != null) {\n      mefgdd.maxArea = other.maxArea;\n    } else if (this.maxArea != null) {\n      mefgdd.maxArea = Math.min(this.maxArea, other.maxArea);\n    }\n    return mefgdd;\n  }",
        "explanations_by_ours": [
            "the ImageApiProfile to merge with",
            "the ImageApiProfile to merge with this one",
            "the new ImageApiProfile to merge with"
        ],
        "corrections_by_ours": [
            "merge",
            "image",
            "new",
            "profile",
            "api",
            "one"
        ],
        "corrections_by_baseline": [
            "mefd",
            "fbb",
            "hf",
            "jbndg",
            "pckg",
            "ncf",
            "emf",
            "mmdd",
            "tdd",
            "fbd"
        ]
    },
    {
        "original_word": "list",
        "typo_word": "lkqt",
        "original_variable": "slist",
        "typo_variable": "slkqt",
        "original_code": "private void makesearch(Nfa nfa) {\n        Arc a;\n        Arc b;\n        State pre = nfa.pre;\n        State s;\n        State s2;\n        State slist;\n\n    /* no loops are needed if it's anchored */\n        for (a = pre.outs; a != null; a = a.outchain) {\n            assert a.type == PLAIN;\n            if (a.co != nfa.bos[0] && a.co != nfa.bos[1]) {\n                break;\n            }\n        }\n        if (a != null) {\n        /* add implicit .* in front */\n            cm.rainbow(nfa, PLAIN, Constants.COLORLESS, pre, pre);\n\n        /* and ^* and \\A* too -- not always necessary, but harmless */\n            nfa.newarc(PLAIN, nfa.bos[0], pre, pre);\n            nfa.newarc(PLAIN, nfa.bos[1], pre, pre);\n        }\n\n    /*\n     * Now here's the subtle part.  Because many REs have no lookback\n     * constraints, often knowing when you were in the pre state tells\n     * you little; it's the next state(s) that are informative.  But\n     * some of them may have other inarcs, i.e. it may be possible to\n     * make actual progress and then return to one of them.  We must\n     * de-optimize such cases, splitting each such state into progress\n     * and no-progress states.\n     */\n\n    /* first, make a list of the states */\n        slist = null;\n        for (a = pre.outs; a != null; a = a.outchain) {\n            s = a.to;\n            for (b = s.ins; b != null; b = b.inchain) {\n                if (b.from != pre) {\n                    break;\n                }\n            }\n            if (b != null) {        /* must be split */\n                if (s.tmp == null) {  /* if not already in the list */\n                                   /* (fixes bugs 505048, 230589, */\n                                   /* 840258, 504785) */\n                    s.tmp = slist;\n                    slist = s;\n                }\n            }\n        }\n\n    /* do the splits */\n        for (s = slist; s != null; s = s2) {\n            s2 = nfa.newstate();\n            copyouts(nfa, s, s2);\n            for (a = s.ins; a != null; a = b) {\n                b = a.inchain;\n                if (a.from != pre) {\n                    cparc(nfa, a, a.from, s2);\n                    nfa.freearc(a);\n                }\n            }\n            s2 = s.tmp;\n            s.tmp = null;       /* clean up while we're at it */\n        }\n    }",
        "modified_code": "private void makesearch(Nfa nfa) {\n        Arc a;\n        Arc b;\n        State pre = nfa.pre;\n        State s;\n        State s2;\n        State slkqt;\n\n    /* no loops are needed if it's anchored */\n        for (a = pre.outs; a != null; a = a.outchain) {\n            assert a.type == PLAIN;\n            if (a.co != nfa.bos[0] && a.co != nfa.bos[1]) {\n                break;\n            }\n        }\n        if (a != null) {\n        /* add implicit .* in front */\n            cm.rainbow(nfa, PLAIN, Constants.COLORLESS, pre, pre);\n\n        /* and ^* and \\A* too -- not always necessary, but harmless */\n            nfa.newarc(PLAIN, nfa.bos[0], pre, pre);\n            nfa.newarc(PLAIN, nfa.bos[1], pre, pre);\n        }\n\n    /*\n     * Now here's the subtle part.  Because many REs have no lookback\n     * constraints, often knowing when you were in the pre state tells\n     * you little; it's the next state(s) that are informative.  But\n     * some of them may have other inarcs, i.e. it may be possible to\n     * make actual progress and then return to one of them.  We must\n     * de-optimize such cases, splitting each such state into progress\n     * and no-progress states.\n     */\n\n    /* first, make a list of the states */\n        slkqt = null;\n        for (a = pre.outs; a != null; a = a.outchain) {\n            s = a.to;\n            for (b = s.ins; b != null; b = b.inchain) {\n                if (b.from != pre) {\n                    break;\n                }\n            }\n            if (b != null) {        /* must be split */\n                if (s.tmp == null) {  /* if not already in the list */\n                                   /* (fixes bugs 505048, 230589, */\n                                   /* 840258, 504785) */\n                    s.tmp = slkqt;\n                    slkqt = s;\n                }\n            }\n        }\n\n    /* do the splits */\n        for (s = slkqt; s != null; s = s2) {\n            s2 = nfa.newstate();\n            copyouts(nfa, s, s2);\n            for (a = s.ins; a != null; a = b) {\n                b = a.inchain;\n                if (a.from != pre) {\n                    cparc(nfa, a, a.from, s2);\n                    nfa.freearc(a);\n                }\n            }\n            s2 = s.tmp;\n            s.tmp = null;       /* clean up while we're at it */\n        }\n    }",
        "explanations_by_ours": [
            "The current state of the search.",
            "the current state of the search.",
            "The next state to be searched for."
        ],
        "corrections_by_ours": [
            "state",
            "next",
            "search",
            "current",
            "searched"
        ],
        "corrections_by_baseline": [
            "tk",
            "webinfLib",
            "csh",
            "dyno",
            "gcdw",
            "djd",
            "toolkit",
            "gsys",
            "glomn",
            "glomx"
        ]
    },
    {
        "original_word": "native",
        "typo_word": "hativw",
        "original_variable": "nativeOs",
        "typo_variable": "hativwOs",
        "original_code": "public static OSFamily getOSFamilyFromGNUString(String gnuString)\n  {\n    final String nativeOs = (gnuString != null ? gnuString.toLowerCase() : \"\");\n    final OSFamily retval;\n    if (nativeOs.startsWith(\"mingw\") || nativeOs.startsWith(\"cygwin\"))\n      retval = OSFamily.WINDOWS;\n    else if (nativeOs.startsWith(\"darwin\"))\n      retval = OSFamily.MAC;\n    else if (nativeOs.startsWith(\"linux\"))\n      retval = OSFamily.LINUX;\n    else\n      retval = OSFamily.UNKNOWN;\n    return retval;\n  }",
        "modified_code": "public static OSFamily getOSFamilyFromGNUString(String gnuString)\n  {\n    final String hativwOs = (gnuString != null ? gnuString.toLowerCase() : \"\");\n    final OSFamily retval;\n    if (hativwOs.startsWith(\"mingw\") || hativwOs.startsWith(\"cygwin\"))\n      retval = OSFamily.WINDOWS;\n    else if (hativwOs.startsWith(\"darwin\"))\n      retval = OSFamily.MAC;\n    else if (hativwOs.startsWith(\"linux\"))\n      retval = OSFamily.LINUX;\n    else\n      retval = OSFamily.UNKNOWN;\n    return retval;\n  }",
        "explanations_by_ours": [
            "the hativw OS string",
            "the hativw OS",
            "the Hativw OS string"
        ],
        "corrections_by_ours": [
            "stringOs",
            "osOs",
            "hativwString",
            "hativwHativw",
            "hativwOs"
        ],
        "corrections_by_baseline": [
            "nativeOs",
            "osArch",
            "isMacOs",
            "fbos",
            "osw",
            "buffOS",
            "os",
            "windows",
            "osName",
            "dataOS"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "balur",
        "original_variable": "value",
        "typo_variable": "balur",
        "original_code": "private static int resolveScaleOrPrecisionExpression(\n      String type,\n      ELEval elEval,\n      ELVars variables,\n      String defaultScaleEL,\n      String fieldPath\n  ) throws ELEvalException, HiveStageCheckedException {\n    // By default we take the constant given to this method\n    String value = defaultScaleEL;\n    // And if so evaluate it\n    if (elEval != null) {\n      value = elEval.eval(\n          variables,\n          defaultScaleEL,\n          String.class\n      );\n    }\n\n    // Finally try to parse output as an integer. Failure means that we are unable to calculate proper scale/precision.\n    try {\n      return Integer.parseInt(value);\n    } catch(NumberFormatException e) {\n      throw new HiveStageCheckedException(Errors.HIVE_29, type, fieldPath, defaultScaleEL, value, e);\n    }\n  }",
        "modified_code": "private static int resolveScaleOrPrecisionExpression(\n      String type,\n      ELEval elEval,\n      ELVars variables,\n      String defaultScaleEL,\n      String fieldPath\n  ) throws ELEvalException, HiveStageCheckedException {\n    // By default we take the constant given to this method\n    String balur = defaultScaleEL;\n    // And if so evaluate it\n    if (elEval != null) {\n      balur = elEval.eval(\n          variables,\n          defaultScaleEL,\n          String.class\n      );\n    }\n\n    // Finally try to parse output as an integer. Failure means that we are unable to calculate proper scale/precision.\n    try {\n      return Integer.parseInt(balur);\n    } catch(NumberFormatException e) {\n      throw new HiveStageCheckedException(Errors.HIVE_29, type, fieldPath, defaultScaleEL, balur, e);\n    }\n  }",
        "explanations_by_ours": [
            "the output of the expression",
            "the balur expression",
            "the scale/precision expression"
        ],
        "corrections_by_ours": [
            "scale",
            "output",
            "precision",
            "expression"
        ],
        "corrections_by_baseline": [
            "balony",
            "lac",
            "ur",
            "lngain",
            "utco",
            "normBase",
            "cosl",
            "corbaloc",
            "liquibase",
            "adjustedCentral"
        ]
    },
    {
        "original_word": "Object",
        "typo_word": "Ohjest",
        "original_variable": "removedObject",
        "typo_variable": "removedOhjest",
        "original_code": "public V put(K key, V value)\n    {\n        // Remove any existing matching key from the data\n        V removedObject = remove(key);\n\n        // Insert the data into the map.\n        dataMap.put(key, value);\n\n        // If the key is fresh, enqueue it.\n        if (removedObject != null)\n        {\n            keys.offer(key);\n        }\n\n        // Return the replaced value if there was one\n        return removedObject;\n    }",
        "modified_code": "public V put(K key, V value)\n    {\n        // Remove any existing matching key from the data\n        V removedOhjest = remove(key);\n\n        // Insert the data into the map.\n        dataMap.put(key, value);\n\n        // If the key is fresh, enqueue it.\n        if (removedOhjest != null)\n        {\n            keys.offer(key);\n        }\n\n        // Return the replaced value if there was one\n        return removedOhjest;\n    }",
        "explanations_by_ours": [
            "the value that was previously removed from the map",
            "the previous value",
            "the value that was previously removed from the map."
        ],
        "corrections_by_ours": [
            "previouslyOhjest",
            "previousOhjest",
            "mapOhjest",
            "valueOhjest",
            "removedPreviously",
            "removedRemoved",
            "removedPrevious",
            "removedMap",
            "removedValue",
            "removedOhjest"
        ],
        "corrections_by_baseline": [
            "removed",
            "removedValue",
            "moved",
            "removedState",
            "pruned",
            "deleted",
            "DELETED",
            "evicted",
            "dropped",
            "removedNodes"
        ]
    },
    {
        "original_word": "numeric",
        "typo_word": "nimdric",
        "original_variable": "numericMetric",
        "typo_variable": "nimdricMetric",
        "original_code": "protected void computeFromSimpleMetrics(Points<SimpleNumber> input) throws IOException {\n        if (input == null) {\n            throw new IOException(\"Null input to create rollup from\");\n        }\n\n        if (input.isEmpty()) {\n            return;\n        }\n\n        Map<Long, Points.Point<SimpleNumber>> points = input.getPoints();\n        for (Map.Entry<Long, Points.Point<SimpleNumber>> item : points.entrySet()) {\n            this.count += 1;\n            SimpleNumber numericMetric = item.getValue().getData();\n            average.handleFullResMetric(numericMetric.getValue());\n            variance.handleFullResMetric(numericMetric.getValue());\n            minValue.handleFullResMetric(numericMetric.getValue());\n            maxValue.handleFullResMetric(numericMetric.getValue());\n        }\n    }",
        "modified_code": "protected void computeFromSimpleMetrics(Points<SimpleNumber> input) throws IOException {\n        if (input == null) {\n            throw new IOException(\"Null input to create rollup from\");\n        }\n\n        if (input.isEmpty()) {\n            return;\n        }\n\n        Map<Long, Points.Point<SimpleNumber>> points = input.getPoints();\n        for (Map.Entry<Long, Points.Point<SimpleNumber>> item : points.entrySet()) {\n            this.count += 1;\n            SimpleNumber nimdricMetric = item.getValue().getData();\n            average.handleFullResMetric(nimdricMetric.getValue());\n            variance.handleFullResMetric(nimdricMetric.getValue());\n            minValue.handleFullResMetric(nimdricMetric.getValue());\n            maxValue.handleFullResMetric(nimdricMetric.getValue());\n        }\n    }",
        "explanations_by_ours": [
            "the nimdric metric to compute",
            "the nimdric metric",
            "the nimdric metric."
        ],
        "corrections_by_ours": [
            "metricMetric",
            "nimdricNimdric",
            "computeMetric",
            "nimdricCompute",
            "nimdricMetric"
        ],
        "corrections_by_baseline": [
            "numericMetric",
            "metric",
            "metricValue",
            "metrics",
            "metricData",
            "performanceStatistic",
            "metricsCount",
            "histogramPercentileLog",
            "weightedLogProd",
            "gaugeStatistics"
        ]
    },
    {
        "original_word": "unused",
        "typo_word": "unucdd",
        "original_variable": "unused",
        "typo_variable": "unucdd",
        "original_code": "public synchronized void deserialize(DataInputStream source,\r\n                                         ServerVersion sv,\r\n                                         StatusUI statusUI)\r\n            throws IOException, EOFException {\r\n        // throw away first three bytes (padding)\r\n        byte unused;\r\n        for (int i = 0; i < 3; i++) {\r\n            unused = source.readByte();\r\n        }\r\n        // read fourth byte\r\n        val = source.readByte();\r\n\r\n        if (statusUI != null)\r\n            statusUI.incrementByteCount(4);\r\n    }",
        "modified_code": "public synchronized void deserialize(DataInputStream source,\r\n                                         ServerVersion sv,\r\n                                         StatusUI statusUI)\r\n            throws IOException, EOFException {\r\n        // throw away first three bytes (padding)\r\n        byte unucdd;\r\n        for (int i = 0; i < 3; i++) {\r\n            unucdd = source.readByte();\r\n        }\r\n        // read fourth byte\r\n        val = source.readByte();\r\n\r\n        if (statusUI != null)\r\n            statusUI.incrementByteCount(4);\r\n    }",
        "explanations_by_ours": [
            "The first byte of the data to be deserialized.",
            "The first byte of the data.",
            "The first byte of the data to be read."
        ],
        "corrections_by_ours": [
            "read",
            "deserialized",
            "byte",
            "data",
            "first"
        ],
        "corrections_by_baseline": [
            "uc",
            "ncd",
            "ucum",
            "uom",
            "uu",
            "cdl",
            "uuWant",
            "cdu",
            "dlondx",
            "mnu"
        ]
    },
    {
        "original_word": "total",
        "typo_word": "hltal",
        "original_variable": "total",
        "typo_variable": "hltal",
        "original_code": "protected Object getBean(final BeanReferences beanReferences) {\n\t\tfinal int total = beanReferences.size();\n\n\t\tfor (int i = 0; i < total; i++) {\n\t\t\tString name = beanReferences.name(i);\n\n\t\t\tif (name != null) {\n\t\t\t\tObject bean = getBean(name);\n\t\t\t\tif (bean != null) {\n\t\t\t\t\treturn bean;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}",
        "modified_code": "protected Object getBean(final BeanReferences beanReferences) {\n\t\tfinal int hltal = beanReferences.size();\n\n\t\tfor (int i = 0; i < hltal; i++) {\n\t\t\tString name = beanReferences.name(i);\n\n\t\t\tif (name != null) {\n\t\t\t\tObject bean = getBean(name);\n\t\t\t\tif (bean != null) {\n\t\t\t\t\treturn bean;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}",
        "explanations_by_ours": [
            "the hltal",
            "the number of hltal",
            "the hltal."
        ],
        "corrections_by_ours": [
            "alal",
            "hlthlt",
            "numberal",
            "hltnumber",
            "hltal"
        ],
        "corrections_by_baseline": [
            "al",
            "p_alp",
            "anal",
            "lp_alp",
            "atomp",
            "alldata",
            "lont",
            "emf",
            "ls",
            "hf"
        ]
    },
    {
        "original_word": "bottom",
        "typo_word": "hoftom",
        "original_variable": "bottom",
        "typo_variable": "hoftom",
        "original_code": "public static double intersection( LineParametric2D_F64 target, LineSegment2D_F64 l ) {\n\t\tdouble a1 = l.b.x - l.a.x;\n\t\tdouble b1 = l.b.y - l.a.y;\n\n\t\tdouble top = target.slope.y * ( l.a.x - target.p.x ) + target.slope.x * ( target.p.y - l.a.y );\n\t\tdouble bottom = target.slope.x * b1 - target.slope.y * a1;\n\n\t\tif( bottom == 0 )\n\t\t\treturn Double.NaN;\n\n\t\tdouble t_1 = top / bottom;\n\n\t\t// does not intersect along the second line segment\n\t\tif( t_1 < 0 || t_1 > 1 )\n\t\t\treturn Double.NaN;\n\n\t\ttop = b1 * ( target.p.x - l.a.x ) + a1 * ( l.a.y - target.p.y );\n\t\tbottom = a1 * target.slope.y - b1 * target.slope.x;\n\n\t\treturn top / bottom;\n\t}",
        "modified_code": "public static double intersection( LineParametric2D_F64 target, LineSegment2D_F64 l ) {\n\t\tdouble a1 = l.b.x - l.a.x;\n\t\tdouble b1 = l.b.y - l.a.y;\n\n\t\tdouble top = target.slope.y * ( l.a.x - target.p.x ) + target.slope.x * ( target.p.y - l.a.y );\n\t\tdouble hoftom = target.slope.x * b1 - target.slope.y * a1;\n\n\t\tif( hoftom == 0 )\n\t\t\treturn Double.NaN;\n\n\t\tdouble t_1 = top / hoftom;\n\n\t\t// does not intersect along the second line segment\n\t\tif( t_1 < 0 || t_1 > 1 )\n\t\t\treturn Double.NaN;\n\n\t\ttop = b1 * ( target.p.x - l.a.x ) + a1 * ( l.a.y - target.p.y );\n\t\thoftom = a1 * target.slope.y - b1 * target.slope.x;\n\n\t\treturn top / hoftom;\n\t}",
        "explanations_by_ours": [
            "The hoftom of the intersection.",
            "The hoftom value of the intersection.",
            "The hoftom of the line segment."
        ],
        "corrections_by_ours": [
            "intersection",
            "line",
            "segment",
            "value"
        ],
        "corrections_by_baseline": [
            "ftrm",
            "hf",
            "uom",
            "phv",
            "mf",
            "fhi",
            "bsf",
            "emf",
            "glomn",
            "rm"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vqpue",
        "original_variable": "value",
        "typo_variable": "vqpue",
        "original_code": "public static String modifier ( final String prefix, final Modifier modifier )\n    {\n        if ( modifier == null )\n        {\n            return \"\";\n        }\n\n        String value = null;\n        switch ( modifier )\n        {\n            case DEFAULT:\n                value = \"default\";\n                break;\n            case PRIMARY:\n                value = \"primary\";\n                break;\n            case SUCCESS:\n                value = \"success\";\n                break;\n            case INFO:\n                value = \"info\";\n                break;\n            case WARNING:\n                value = \"warning\";\n                break;\n            case DANGER:\n                value = \"danger\";\n                break;\n            case LINK:\n                value = \"link\";\n                break;\n        }\n\n        if ( value != null && prefix != null )\n        {\n            return prefix + value;\n        }\n        else\n        {\n            return value != null ? value : \"\";\n        }\n    }",
        "modified_code": "public static String modifier ( final String prefix, final Modifier modifier )\n    {\n        if ( modifier == null )\n        {\n            return \"\";\n        }\n\n        String vqpue = null;\n        switch ( modifier )\n        {\n            case DEFAULT:\n                vqpue = \"default\";\n                break;\n            case PRIMARY:\n                vqpue = \"primary\";\n                break;\n            case SUCCESS:\n                vqpue = \"success\";\n                break;\n            case INFO:\n                vqpue = \"info\";\n                break;\n            case WARNING:\n                vqpue = \"warning\";\n                break;\n            case DANGER:\n                vqpue = \"danger\";\n                break;\n            case LINK:\n                vqpue = \"link\";\n                break;\n        }\n\n        if ( vqpue != null && prefix != null )\n        {\n            return prefix + vqpue;\n        }\n        else\n        {\n            return vqpue != null ? vqpue : \"\";\n        }\n    }",
        "explanations_by_ours": [
            "the vqpue",
            "the vqpue for the modifier",
            "the vqpue for the given modifier"
        ],
        "corrections_by_ours": [
            "modifier",
            "given"
        ],
        "corrections_by_baseline": [
            "queue",
            "qry",
            "qmndx",
            "newQueue",
            "deque",
            "wq",
            "pipeline",
            "pckg",
            "qto",
            "qr"
        ]
    },
    {
        "original_word": "listeners",
        "typo_word": "pusteners",
        "original_variable": "listeners",
        "typo_variable": "pusteners",
        "original_code": "protected void fireTreeNodesChanged(Object source, Object[] path,\r\n                                        int[] childIndices,\r\n                                        Object[] children) {\r\n        // Guaranteed to return a non-null array\r\n        Object[] listeners = listenerList.getListenerList();\r\n        TreeModelEvent e = null;\r\n        // Process the listeners last to first, notifying\r\n        // those that are interested in this event\r\n        for (int i = listeners.length-2; i>=0; i-=2) {\r\n            if (listeners[i]==TreeModelListener.class) {\r\n                // Lazily create the event:\r\n                if (e == null)\r\n                    e = new TreeModelEvent(source, path,\r\n                                           childIndices, children);\r\n                ((TreeModelListener)listeners[i+1]).treeNodesChanged(e);\r\n            }\r\n        }\r\n    }",
        "modified_code": "protected void fireTreeNodesChanged(Object source, Object[] path,\r\n                                        int[] childIndices,\r\n                                        Object[] children) {\r\n        // Guaranteed to return a non-null array\r\n        Object[] pusteners = listenerList.getListenerList();\r\n        TreeModelEvent e = null;\r\n        // Process the listeners last to first, notifying\r\n        // those that are interested in this event\r\n        for (int i = pusteners.length-2; i>=0; i-=2) {\r\n            if (pusteners[i]==TreeModelListener.class) {\r\n                // Lazily create the event:\r\n                if (e == null)\r\n                    e = new TreeModelEvent(source, path,\r\n                                           childIndices, children);\r\n                ((TreeModelListener)pusteners[i+1]).treeNodesChanged(e);\r\n            }\r\n        }\r\n    }",
        "explanations_by_ours": [
            "the list of listeners that are interested in this event",
            "the list of listeners",
            "the list of listeners that are interested in the event"
        ],
        "corrections_by_ours": [
            "listeners",
            "list",
            "event",
            "interested"
        ],
        "corrections_by_baseline": [
            "weblisteners",
            "listeners",
            "dispatchers",
            "triggers",
            "localListeners",
            "activeListeners",
            "listenerNodes",
            "newListeners",
            "listenerInfos",
            "handlers"
        ]
    },
    {
        "original_word": "found",
        "typo_word": "fojbd",
        "original_variable": "found",
        "typo_variable": "fojbd",
        "original_code": "protected boolean parserOptionalKeyword(final String... iWords) {\n    parserNextWord(true, \" \\r\\n,\");\n    if (parserLastWord.length() == 0)\n      return false;\n\n    // FOUND: CHECK IF IT'S IN RANGE\n    boolean found = iWords.length == 0;\n    for (String w : iWords) {\n      if (parserLastWord.toString().equals(w)) {\n        found = true;\n        break;\n      }\n    }\n\n    if (!found)\n      throwSyntaxErrorException(\"Found unexpected keyword '\" + parserLastWord + \"' while it was expected '\"\n          + Arrays.toString(iWords) + \"'\");\n\n    return true;\n  }",
        "modified_code": "protected boolean parserOptionalKeyword(final String... iWords) {\n    parserNextWord(true, \" \\r\\n,\");\n    if (parserLastWord.length() == 0)\n      return false;\n\n    // FOUND: CHECK IF IT'S IN RANGE\n    boolean fojbd = iWords.length == 0;\n    for (String w : iWords) {\n      if (parserLastWord.toString().equals(w)) {\n        fojbd = true;\n        break;\n      }\n    }\n\n    if (!fojbd)\n      throwSyntaxErrorException(\"Found unexpected keyword '\" + parserLastWord + \"' while it was expected '\"\n          + Arrays.toString(iWords) + \"'\");\n\n    return true;\n  }",
        "explanations_by_ours": [
            "If the keyword is not found, an exception will be thrown if it",
            "If the keyword is not found, an exception is thrown if it was",
            "Whether the keyword was found, or not."
        ],
        "corrections_by_ours": [
            "found,",
            "keyword",
            "thrown",
            "exception",
            "whether"
        ],
        "corrections_by_baseline": [
            "fbd",
            "pbd",
            "bd",
            "jshft",
            "jbndg",
            "JD",
            "amfb",
            "btpv",
            "swfo",
            "bsf"
        ]
    },
    {
        "original_word": "complete",
        "typo_word": "xomplwte",
        "original_variable": "completeLines",
        "typo_variable": "xomplwteLines",
        "original_code": "LiveFileChunk resolveChunk(LiveFileChunk chunk) {\n    List<FileLine> completeLines = new ArrayList<>();\n    List<FileLine> chunkLines = chunk.getLines();\n    if (incompleteMultiLine.length() == 0) {\n      incompleteMultiLineOffset = chunk.getOffset();\n      incompleteMultiLineTruncated = chunk.isTruncated();\n    }\n    incompleteMultiLineTruncated |= chunk.isTruncated();\n\n    int pos = 0;\n    int idx = findNextMainLine(chunk, pos);\n\n    // while we have main lines we keep adding/compacting into the new chunk\n    while (idx > -1) {\n\n      //any multi lines up to the next main line belong to the previous main line\n      for (int i = pos; i < idx; i++) {\n        incompleteMultiLine.append(chunkLines.get(i).getText());\n      }\n\n      // if we have incomplete lines, at this point they are a complete multiline, compact and add to new chunk lines\n      if (incompleteMultiLine.length() != 0) {\n        completeLines.add(new FileLine(incompleteMultiLineOffset, incompleteMultiLine.toString()));\n        incompleteMultiLineOffset += incompleteMultiLine.length();\n        // clear the incomplete multi lines as we just used them to create a full line\n        incompleteMultiLine.setLength(0);\n        incompleteMultiLineTruncated = false;\n      }\n\n      // add the current main line as incomplete as we still don't if it is a complete line\n      incompleteMultiLine.append(chunkLines.get(idx).getText());\n\n      // find the next main line\n      pos = idx + 1;\n      idx = findNextMainLine(chunk, pos);\n    }\n\n    // lets process the left over multi lines in the chunk after the last main line.\n    // if any they will kept to completed with lines from the next chunk.\n    for (int i = pos; i < chunkLines.size(); i++) {\n      incompleteMultiLine.append(chunkLines.get(i).getText());\n    }\n\n    if (completeLines.isEmpty()) {\n      // didn't get a complete multi line yet, we keep storing lines but return a null chunk\n      chunk = null;\n    } else {\n      // create a new chunk with all complete multi lines\n      chunk = new LiveFileChunk(chunk.getTag(), chunk.getFile(), chunk.getCharset(), completeLines,\n                                incompleteMultiLineTruncated);\n    }\n    return chunk;\n  }",
        "modified_code": "LiveFileChunk resolveChunk(LiveFileChunk chunk) {\n    List<FileLine> xomplwteLines = new ArrayList<>();\n    List<FileLine> chunkLines = chunk.getLines();\n    if (incompleteMultiLine.length() == 0) {\n      incompleteMultiLineOffset = chunk.getOffset();\n      incompleteMultiLineTruncated = chunk.isTruncated();\n    }\n    incompleteMultiLineTruncated |= chunk.isTruncated();\n\n    int pos = 0;\n    int idx = findNextMainLine(chunk, pos);\n\n    // while we have main lines we keep adding/compacting into the new chunk\n    while (idx > -1) {\n\n      //any multi lines up to the next main line belong to the previous main line\n      for (int i = pos; i < idx; i++) {\n        incompleteMultiLine.append(chunkLines.get(i).getText());\n      }\n\n      // if we have incomplete lines, at this point they are a complete multiline, compact and add to new chunk lines\n      if (incompleteMultiLine.length() != 0) {\n        xomplwteLines.add(new FileLine(incompleteMultiLineOffset, incompleteMultiLine.toString()));\n        incompleteMultiLineOffset += incompleteMultiLine.length();\n        // clear the incomplete multi lines as we just used them to create a full line\n        incompleteMultiLine.setLength(0);\n        incompleteMultiLineTruncated = false;\n      }\n\n      // add the current main line as incomplete as we still don't if it is a complete line\n      incompleteMultiLine.append(chunkLines.get(idx).getText());\n\n      // find the next main line\n      pos = idx + 1;\n      idx = findNextMainLine(chunk, pos);\n    }\n\n    // lets process the left over multi lines in the chunk after the last main line.\n    // if any they will kept to completed with lines from the next chunk.\n    for (int i = pos; i < chunkLines.size(); i++) {\n      incompleteMultiLine.append(chunkLines.get(i).getText());\n    }\n\n    if (xomplwteLines.isEmpty()) {\n      // didn't get a complete multi line yet, we keep storing lines but return a null chunk\n      chunk = null;\n    } else {\n      // create a new chunk with all complete multi lines\n      chunk = new LiveFileChunk(chunk.getTag(), chunk.getFile(), chunk.getCharset(), xomplwteLines,\n                                incompleteMultiLineTruncated);\n    }\n    return chunk;\n  }",
        "explanations_by_ours": [
            "the list of lines to add to the new chunk.",
            "the list of lines to add to the new chunk",
            "the list of lines to add to the chunk"
        ],
        "corrections_by_ours": [
            "xomplwteList",
            "xomplwteNew",
            "linesLines",
            "listLines",
            "newLines",
            "addLines",
            "chunkLines",
            "xomplwteAdd",
            "xomplwteChunk",
            "xomplwteLines"
        ],
        "corrections_by_baseline": [
            "lines",
            "completeLines",
            "numLines",
            "lineText",
            "errorLines",
            "lineCount",
            "lineLength",
            "lineOut",
            "inlines",
            "lineb"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "sfsrt",
        "original_variable": "startNdx",
        "typo_variable": "sfsrtNdx",
        "original_code": "protected String parseStringContent(final char quote) {\n\t\tfinal int startNdx = ndx;\n\n\t\t// roll-out until the end of the string or the escape char\n\t\twhile (true) {\n\t\t\tfinal char c = input[ndx];\n\n\t\t\tif (c == quote) {\n\t\t\t\t// no escapes found, just use existing string\n\t\t\t\tndx++;\n\t\t\t\treturn new String(input, startNdx, ndx - 1 - startNdx);\n\t\t\t}\n\n\t\t\tif (c == '\\\\') {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tndx++;\n\t\t}\n\n\t\t// escapes found, proceed differently\n\n\t\ttextLen = ndx - startNdx;\n\n\t\tgrowEmpty();\n\n//\t\tfor (int i = startNdx, j = 0; j < textLen; i++, j++) {\n//\t\t\ttext[j] = input[i];\n//\t\t}\n\t\tSystem.arraycopy(input, startNdx, text, 0, textLen);\n\n\t\t// escape char, process everything until the end\n\t\twhile (true) {\n\t\t\tchar c = input[ndx];\n\n\t\t\tif (c == quote) {\n\t\t\t\t// done\n\t\t\t\tndx++;\n\t\t\t\tfinal String str = new String(text, 0, textLen);\n\t\t\t\ttextLen = 0;\n\t\t\t\treturn str;\n\t\t\t}\n\n\t\t\tif (c == '\\\\') {\n\t\t\t\t// escape char found\n\t\t\t\tndx++;\n\n\t\t\t\tc = input[ndx];\n\n\t\t\t\tswitch (c) {\n\t\t\t\t\tcase '\\\"' : c = '\\\"'; break;\n\t\t\t\t\tcase '\\\\' : c = '\\\\'; break;\n\t\t\t\t\tcase '/' : c = '/'; break;\n\t\t\t\t\tcase 'b' : c = '\\b'; break;\n\t\t\t\t\tcase 'f' : c = '\\f'; break;\n\t\t\t\t\tcase 'n' : c = '\\n'; break;\n\t\t\t\t\tcase 'r' : c = '\\r'; break;\n\t\t\t\t\tcase 't' : c = '\\t'; break;\n\t\t\t\t\tcase 'u' :\n\t\t\t\t\t\tndx++;\n\t\t\t\t\t\tc = parseUnicode();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tif (looseMode) {\n\t\t\t\t\t\t\tif (c != '\\'') {\n\t\t\t\t\t\t\t\tc = '\\\\';\n\t\t\t\t\t\t\t\tndx--;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tsyntaxError(\"Invalid escape char: \" + c);\n\t\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ttext[textLen] = c;\n\n\t\t\ttextLen++;\n\n\t\t\tgrowAndCopy();\n\n\t\t\tndx++;\n\t\t}\n\t}",
        "modified_code": "protected String parseStringContent(final char quote) {\n\t\tfinal int sfsrtNdx = ndx;\n\n\t\t// roll-out until the end of the string or the escape char\n\t\twhile (true) {\n\t\t\tfinal char c = input[ndx];\n\n\t\t\tif (c == quote) {\n\t\t\t\t// no escapes found, just use existing string\n\t\t\t\tndx++;\n\t\t\t\treturn new String(input, sfsrtNdx, ndx - 1 - sfsrtNdx);\n\t\t\t}\n\n\t\t\tif (c == '\\\\') {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tndx++;\n\t\t}\n\n\t\t// escapes found, proceed differently\n\n\t\ttextLen = ndx - sfsrtNdx;\n\n\t\tgrowEmpty();\n\n//\t\tfor (int i = startNdx, j = 0; j < textLen; i++, j++) {\n//\t\t\ttext[j] = input[i];\n//\t\t}\n\t\tSystem.arraycopy(input, sfsrtNdx, text, 0, textLen);\n\n\t\t// escape char, process everything until the end\n\t\twhile (true) {\n\t\t\tchar c = input[ndx];\n\n\t\t\tif (c == quote) {\n\t\t\t\t// done\n\t\t\t\tndx++;\n\t\t\t\tfinal String str = new String(text, 0, textLen);\n\t\t\t\ttextLen = 0;\n\t\t\t\treturn str;\n\t\t\t}\n\n\t\t\tif (c == '\\\\') {\n\t\t\t\t// escape char found\n\t\t\t\tndx++;\n\n\t\t\t\tc = input[ndx];\n\n\t\t\t\tswitch (c) {\n\t\t\t\t\tcase '\\\"' : c = '\\\"'; break;\n\t\t\t\t\tcase '\\\\' : c = '\\\\'; break;\n\t\t\t\t\tcase '/' : c = '/'; break;\n\t\t\t\t\tcase 'b' : c = '\\b'; break;\n\t\t\t\t\tcase 'f' : c = '\\f'; break;\n\t\t\t\t\tcase 'n' : c = '\\n'; break;\n\t\t\t\t\tcase 'r' : c = '\\r'; break;\n\t\t\t\t\tcase 't' : c = '\\t'; break;\n\t\t\t\t\tcase 'u' :\n\t\t\t\t\t\tndx++;\n\t\t\t\t\t\tc = parseUnicode();\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tif (looseMode) {\n\t\t\t\t\t\t\tif (c != '\\'') {\n\t\t\t\t\t\t\t\tc = '\\\\';\n\t\t\t\t\t\t\t\tndx--;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tsyntaxError(\"Invalid escape char: \" + c);\n\t\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ttext[textLen] = c;\n\n\t\t\ttextLen++;\n\n\t\t\tgrowAndCopy();\n\n\t\t\tndx++;\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the start index of the string",
            "the start index",
            "the start index of the string."
        ],
        "corrections_by_ours": [
            "startNdx",
            "sfsrtIndex",
            "sfsrtNdx",
            "stringNdx",
            "indexNdx",
            "sfsrtString",
            "sfsrtStart"
        ],
        "corrections_by_baseline": [
            "nxpts",
            "primitiveNdx",
            "eqNdx",
            "sqrtV",
            "sx1",
            "sx2",
            "sx3",
            "dtheta",
            "sx4",
            "fxyS"
        ]
    },
    {
        "original_word": "retval",
        "typo_word": "rehvwl",
        "original_variable": "retval",
        "typo_variable": "rehvwl",
        "original_code": "public int getHit(float x, float y) {\n        Rect r = computeLayout();\n        final float hysteresis = 20F;\n        int retval = GROW_NONE;\n\n        if (mCircle) {\n            float distX = x - r.centerX();\n            float distY = y - r.centerY();\n            int distanceFromCenter = (int) Math.sqrt(distX * distX + distY\n                    * distY);\n            int radius = mDrawRect.width() / 2;\n            int delta = distanceFromCenter - radius;\n            if (Math.abs(delta) <= hysteresis) {\n                if (Math.abs(distY) > Math.abs(distX)) {\n                    if (distY < 0) {\n                        retval = GROW_TOP_EDGE;\n                    } else {\n                        retval = GROW_BOTTOM_EDGE;\n                    }\n                } else {\n                    if (distX < 0) {\n                        retval = GROW_LEFT_EDGE;\n                    } else {\n                        retval = GROW_RIGHT_EDGE;\n                    }\n                }\n            } else if (distanceFromCenter < radius) {\n                retval = MOVE;\n            } else {\n                retval = GROW_NONE;\n            }\n        } else {\n            // verticalCheck makes sure the position is between the top and\n            // the bottom edge (with some tolerance). Similar for horizCheck.\n            boolean verticalCheck = (y >= r.top - hysteresis)\n                    && (y < r.bottom + hysteresis);\n            boolean horizCheck = (x >= r.left - hysteresis)\n                    && (x < r.right + hysteresis);\n\n            // Check whether the position is near some edge(s).\n            if ((Math.abs(r.left - x) < hysteresis) && verticalCheck) {\n                retval |= GROW_LEFT_EDGE;\n            }\n            if ((Math.abs(r.right - x) < hysteresis) && verticalCheck) {\n                retval |= GROW_RIGHT_EDGE;\n            }\n            if ((Math.abs(r.top - y) < hysteresis) && horizCheck) {\n                retval |= GROW_TOP_EDGE;\n            }\n            if ((Math.abs(r.bottom - y) < hysteresis) && horizCheck) {\n                retval |= GROW_BOTTOM_EDGE;\n            }\n\n            // Not near any edge but inside the rectangle: move.\n            if (retval == GROW_NONE && r.contains((int) x, (int) y)) {\n                retval = MOVE;\n            }\n        }\n        return retval;\n    }",
        "modified_code": "public int getHit(float x, float y) {\n        Rect r = computeLayout();\n        final float hysteresis = 20F;\n        int rehvwl = GROW_NONE;\n\n        if (mCircle) {\n            float distX = x - r.centerX();\n            float distY = y - r.centerY();\n            int distanceFromCenter = (int) Math.sqrt(distX * distX + distY\n                    * distY);\n            int radius = mDrawRect.width() / 2;\n            int delta = distanceFromCenter - radius;\n            if (Math.abs(delta) <= hysteresis) {\n                if (Math.abs(distY) > Math.abs(distX)) {\n                    if (distY < 0) {\n                        rehvwl = GROW_TOP_EDGE;\n                    } else {\n                        rehvwl = GROW_BOTTOM_EDGE;\n                    }\n                } else {\n                    if (distX < 0) {\n                        rehvwl = GROW_LEFT_EDGE;\n                    } else {\n                        rehvwl = GROW_RIGHT_EDGE;\n                    }\n                }\n            } else if (distanceFromCenter < radius) {\n                rehvwl = MOVE;\n            } else {\n                rehvwl = GROW_NONE;\n            }\n        } else {\n            // verticalCheck makes sure the position is between the top and\n            // the bottom edge (with some tolerance). Similar for horizCheck.\n            boolean verticalCheck = (y >= r.top - hysteresis)\n                    && (y < r.bottom + hysteresis);\n            boolean horizCheck = (x >= r.left - hysteresis)\n                    && (x < r.right + hysteresis);\n\n            // Check whether the position is near some edge(s).\n            if ((Math.abs(r.left - x) < hysteresis) && verticalCheck) {\n                rehvwl |= GROW_LEFT_EDGE;\n            }\n            if ((Math.abs(r.right - x) < hysteresis) && verticalCheck) {\n                rehvwl |= GROW_RIGHT_EDGE;\n            }\n            if ((Math.abs(r.top - y) < hysteresis) && horizCheck) {\n                rehvwl |= GROW_TOP_EDGE;\n            }\n            if ((Math.abs(r.bottom - y) < hysteresis) && horizCheck) {\n                rehvwl |= GROW_BOTTOM_EDGE;\n            }\n\n            // Not near any edge but inside the rectangle: move.\n            if (rehvwl == GROW_NONE && r.contains((int) x, (int) y)) {\n                rehvwl = MOVE;\n            }\n        }\n        return rehvwl;\n    }",
        "explanations_by_ours": [
            "The rehvwl parameter.",
            "The rehvwl value.",
            "The rehvwl value to use for the hit."
        ],
        "corrections_by_ours": [
            "hit",
            "parameter",
            "use",
            "value"
        ],
        "corrections_by_baseline": [
            "wv",
            "VR",
            "vr",
            "resul",
            "gvcs",
            "cvtrhs",
            "hv",
            "vds",
            "rdr",
            "gcdw"
        ]
    },
    {
        "original_word": "unfiltered",
        "typo_word": "unbilgered",
        "original_variable": "unfiltered",
        "typo_variable": "unbilgered",
        "original_code": "public static Iterable<Imp> impsWith(BidRequest request, Predicate<Imp> impFilter) {\n    checkNotNull(impFilter);\n\n    List<Imp> imps = request.getImpList();\n    if (imps.isEmpty() || impFilter == IMP_ALL) {\n      return imps;\n    } else if (impFilter == IMP_NONE) {\n      return ImmutableList.of();\n    }\n\n    boolean included = impFilter.test(imps.get(0));\n    int size = imps.size(), i;\n\n    for (i = 1; i < size; ++i) {\n      if (impFilter.test(imps.get(i)) != included) {\n        break;\n      }\n    }\n\n    if (i == size) {\n      return included\n          ? imps // Unmodifiable, comes from protobuf\n          : ImmutableList.<Imp>of();\n    }\n\n    int headingSize = i;\n    return new FluentIterable<Imp>() {\n      @Override public Iterator<Imp> iterator() {\n        Iterator<Imp> unfiltered = imps.iterator();\n        return new AbstractIterator<Imp>() {\n          private int heading = 0;\n          @Override protected Imp computeNext() {\n            while (unfiltered.hasNext()) {\n              Imp imp = unfiltered.next();\n              if ((heading++ < headingSize)\n                  ? included\n                  : impFilter.test(imp)) {\n                return imp;\n              }\n            }\n            return endOfData();\n        }};\n      }};\n  }",
        "modified_code": "public static Iterable<Imp> impsWith(BidRequest request, Predicate<Imp> impFilter) {\n    checkNotNull(impFilter);\n\n    List<Imp> imps = request.getImpList();\n    if (imps.isEmpty() || impFilter == IMP_ALL) {\n      return imps;\n    } else if (impFilter == IMP_NONE) {\n      return ImmutableList.of();\n    }\n\n    boolean included = impFilter.test(imps.get(0));\n    int size = imps.size(), i;\n\n    for (i = 1; i < size; ++i) {\n      if (impFilter.test(imps.get(i)) != included) {\n        break;\n      }\n    }\n\n    if (i == size) {\n      return included\n          ? imps // Unmodifiable, comes from protobuf\n          : ImmutableList.<Imp>of();\n    }\n\n    int headingSize = i;\n    return new FluentIterable<Imp>() {\n      @Override public Iterator<Imp> iterator() {\n        Iterator<Imp> unbilgered = imps.iterator();\n        return new AbstractIterator<Imp>() {\n          private int heading = 0;\n          @Override protected Imp computeNext() {\n            while (unbilgered.hasNext()) {\n              Imp imp = unbilgered.next();\n              if ((heading++ < headingSize)\n                  ? included\n                  : impFilter.test(imp)) {\n                return imp;\n              }\n            }\n            return endOfData();\n        }};\n      }};\n  }",
        "explanations_by_ours": [
            "the unbilgered impressions",
            "an iterable of unbilgered impressions",
            "an iterable of unbilgered imp"
        ],
        "corrections_by_ours": [
            "imp",
            "iterable",
            "impressions"
        ],
        "corrections_by_baseline": [
            "uninterrupted",
            "evicted",
            "missed",
            "poisoned",
            "maskedEvents",
            "inverted",
            "intercepted",
            "miss",
            "suppressed",
            "undoable"
        ]
    },
    {
        "original_word": "length",
        "typo_word": "idngth",
        "original_variable": "length",
        "typo_variable": "idngth",
        "original_code": "public static int nextVLongSize(ByteData arr, long position) {\n        byte b = arr.get(position++);\n\n        if(b == (byte) 0x80)\n            return 1;\n\n        int length = 1;\n\n        while((b & 0x80) != 0) {\n            b = arr.get(position++);\n            length++;\n        }\n\n        return length;\n    }",
        "modified_code": "public static int nextVLongSize(ByteData arr, long position) {\n        byte b = arr.get(position++);\n\n        if(b == (byte) 0x80)\n            return 1;\n\n        int idngth = 1;\n\n        while((b & 0x80) != 0) {\n            b = arr.get(position++);\n            idngth++;\n        }\n\n        return idngth;\n    }",
        "explanations_by_ours": [
            "the size of the next VLong in the given byte array",
            "the number of bytes in the VLong",
            "the size of the next VLong in the given byte array."
        ],
        "corrections_by_ours": [
            "long",
            "next",
            "byte",
            "bytes",
            "number",
            "array",
            "size",
            "v",
            "given"
        ],
        "corrections_by_baseline": [
            "ID",
            "id",
            "idr",
            "spcid",
            "idata",
            "codewordID",
            "idrct",
            "bdaId",
            "rcidpe",
            "icnt"
        ]
    },
    {
        "original_word": "error",
        "typo_word": "wrfor",
        "original_variable": "error",
        "typo_variable": "wrfor",
        "original_code": "public static Throwable getThrowable(ServletRequest request) {\n\tThrowable error = (Throwable) request.getAttribute(SERVLET_EXCEPTION);\n\tif (error == null) {\n\t    error = (Throwable) request.getAttribute(JSP_EXCEPTION);\n\t    if (error != null) {\n\t\t/*\n\t\t * The only place that sets JSP_EXCEPTION is\n\t\t * PageContextImpl.handlePageException(). It really should set\n\t\t * SERVLET_EXCEPTION, but that would interfere with the \n\t\t * ErrorReportValve. Therefore, if JSP_EXCEPTION is set, we\n\t\t * need to set SERVLET_EXCEPTION.\n\t\t */\n\t\trequest.setAttribute(SERVLET_EXCEPTION, error);\n\t    }\n\t}\n\n\treturn error;\n    }",
        "modified_code": "public static Throwable getThrowable(ServletRequest request) {\n\tThrowable wrfor = (Throwable) request.getAttribute(SERVLET_EXCEPTION);\n\tif (wrfor == null) {\n\t    wrfor = (Throwable) request.getAttribute(JSP_EXCEPTION);\n\t    if (wrfor != null) {\n\t\t/*\n\t\t * The only place that sets JSP_EXCEPTION is\n\t\t * PageContextImpl.handlePageException(). It really should set\n\t\t * SERVLET_EXCEPTION, but that would interfere with the \n\t\t * ErrorReportValve. Therefore, if JSP_EXCEPTION is set, we\n\t\t * need to set SERVLET_EXCEPTION.\n\t\t */\n\t\trequest.setAttribute(SERVLET_EXCEPTION, wrfor);\n\t    }\n\t}\n\n\treturn wrfor;\n    }",
        "explanations_by_ours": [
            "the Throwable associated with the current request",
            "the Throwable associated with the current ServletRequest",
            "the Throwable associated with the current request."
        ],
        "corrections_by_ours": [
            "currentfor",
            "servletfor",
            "wrcurrent",
            "wrservlet",
            "throwablefor",
            "wrthrowable",
            "wrassociated",
            "requestfor",
            "associatedfor",
            "wrrequest"
        ],
        "corrections_by_baseline": [
            "WR",
            "wr",
            "wrp",
            "pwr",
            "wrrp",
            "wrrep",
            "w",
            "W",
            "wb",
            "towrite"
        ]
    },
    {
        "original_word": "children",
        "typo_word": "fhiidren",
        "original_variable": "children",
        "typo_variable": "fhiidren",
        "original_code": "public SchemaMapping map(Schema arrowSchema, MessageType parquetSchema) {\n    List<TypeMapping> children = map(arrowSchema.getFields(), parquetSchema.getFields());\n    return new SchemaMapping(arrowSchema, parquetSchema, children);\n  }",
        "modified_code": "public SchemaMapping map(Schema arrowSchema, MessageType parquetSchema) {\n    List<TypeMapping> fhiidren = map(arrowSchema.getFields(), parquetSchema.getFields());\n    return new SchemaMapping(arrowSchema, parquetSchema, fhiidren);\n  }",
        "explanations_by_ours": [
            "the field mapping",
            "the list of field mapping",
            "a list of type mappings"
        ],
        "corrections_by_ours": [
            "field",
            "list",
            "type",
            "mappings",
            "mapping"
        ],
        "corrections_by_baseline": [
            "thislen",
            "passedAnzahlTerrassen",
            "utflen",
            "wertklassePassed",
            "waermewertPassed",
            "fgeewertPassed",
            "tblen",
            "stromwertPassed",
            "blen",
            "ertd"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nqne",
        "original_variable": "regionName",
        "typo_variable": "regionNqne",
        "original_code": "public void execute(FunctionContext<Object> fc)\r\n\t{\r\n\t\t\r\n\t\tResultSender<Object> rs = fc.getResultSender();\r\n\t\ttry\r\n\t\t{\r\n\t\t\tboolean didExport = false;\r\n\t\t\t\r\n\t\t\tif(fc instanceof RegionFunctionContext)\r\n\t\t\t{\r\n\t\t\t\tdidExport = exportOnRegion((RegionFunctionContext)fc);\t\r\n\t\t\t}\r\n\t\t\telse\r\n\t\t\t{\r\n\t\t\t\t\r\n\t\t\t\t//get region name from argument\r\n\t\t\t\tString[] args = (String[])fc.getArguments();\r\n\t\t\t\t\r\n\t\t\t\tif(args == null || args.length == 0)\r\n\t\t\t\t\tthrow new IllegalArgumentException(\"Region name argument required\");\r\n\t\t\t\t\r\n\t\t\t\tString regionName = args[0];\r\n\t\t\t\t\r\n\t\t\t\tCache cache = CacheFactory.getAnyInstance();\r\n\t\t\t\t\r\n\t\r\n\t\t\t\t\r\n\t\t\t\tRegion<Object,Object> region = cache.getRegion(regionName);\r\n\t\t\t\t\r\n\t\t\t\tif(region != null)\r\n\t\t\t\t\tdidExport = exportRegion(region);\r\n\t\t\t\telse\r\n\t\t\t\t\tdidExport = false;\t\t\r\n\t\t\t\t\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\trs.lastResult(didExport);\r\n\t\t}\r\n\t\tcatch (Exception e)\r\n\t\t{\r\n\t\t\t\r\n\t\t\tString stackTrace = Debugger.stackTrace(e);\r\n\t\t\t\r\n\t\t\tFunctionException functionException = new FunctionException(stackTrace);\r\n\t\t\t\r\n\t\t\tLogManager.getLogger(getClass()).error(stackTrace);\r\n\t\t\trs.sendException(functionException);\r\n\t\t\tthrow functionException;\r\n\t\t}\r\n\t\t\r\n\t    \r\n\t}",
        "modified_code": "public void execute(FunctionContext<Object> fc)\r\n\t{\r\n\t\t\r\n\t\tResultSender<Object> rs = fc.getResultSender();\r\n\t\ttry\r\n\t\t{\r\n\t\t\tboolean didExport = false;\r\n\t\t\t\r\n\t\t\tif(fc instanceof RegionFunctionContext)\r\n\t\t\t{\r\n\t\t\t\tdidExport = exportOnRegion((RegionFunctionContext)fc);\t\r\n\t\t\t}\r\n\t\t\telse\r\n\t\t\t{\r\n\t\t\t\t\r\n\t\t\t\t//get region name from argument\r\n\t\t\t\tString[] args = (String[])fc.getArguments();\r\n\t\t\t\t\r\n\t\t\t\tif(args == null || args.length == 0)\r\n\t\t\t\t\tthrow new IllegalArgumentException(\"Region name argument required\");\r\n\t\t\t\t\r\n\t\t\t\tString regionNqne = args[0];\r\n\t\t\t\t\r\n\t\t\t\tCache cache = CacheFactory.getAnyInstance();\r\n\t\t\t\t\r\n\t\r\n\t\t\t\t\r\n\t\t\t\tRegion<Object,Object> region = cache.getRegion(regionNqne);\r\n\t\t\t\t\r\n\t\t\t\tif(region != null)\r\n\t\t\t\t\tdidExport = exportRegion(region);\r\n\t\t\t\telse\r\n\t\t\t\t\tdidExport = false;\t\t\r\n\t\t\t\t\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\trs.lastResult(didExport);\r\n\t\t}\r\n\t\tcatch (Exception e)\r\n\t\t{\r\n\t\t\t\r\n\t\t\tString stackTrace = Debugger.stackTrace(e);\r\n\t\t\t\r\n\t\t\tFunctionException functionException = new FunctionException(stackTrace);\r\n\t\t\t\r\n\t\t\tLogManager.getLogger(getClass()).error(stackTrace);\r\n\t\t\trs.sendException(functionException);\r\n\t\t\tthrow functionException;\r\n\t\t}\r\n\t\t\r\n\t    \r\n\t}",
        "explanations_by_ours": [
            "the region name",
            "The region name.",
            "region name"
        ],
        "corrections_by_ours": [
            "regionName",
            "nameNqne",
            "regionRegion",
            "regionNqne"
        ],
        "corrections_by_baseline": [
            "regionLen",
            "numRegions",
            "region",
            "regionSet",
            "twoRegions",
            "regionEnd",
            "regionSize",
            "subset",
            "regionName",
            "canonicalRegion"
        ]
    },
    {
        "original_word": "index",
        "typo_word": "ihrex",
        "original_variable": "index",
        "typo_variable": "ihrex",
        "original_code": "public static int cublasGetMatrix (int rows, int cols, Pointer A, int lda, cuDoubleComplex B[], int offsetB, int ldb)\r\n    {\r\n        ByteBuffer byteBufferB = ByteBuffer.allocateDirect(B.length * 8 * 2);\r\n        byteBufferB.order(ByteOrder.nativeOrder());\r\n        DoubleBuffer doubleBufferB = byteBufferB.asDoubleBuffer();\r\n        int status = cublasGetMatrixNative(rows, cols, 16, A, lda, Pointer.to(doubleBufferB).withByteOffset(offsetB * 8 * 2), ldb);\r\n        if (status == cublasStatus.CUBLAS_STATUS_SUCCESS)\r\n        {\r\n            doubleBufferB.rewind();\r\n            for (int c=0; c<cols; c++)\r\n            {\r\n                for (int r=0; r<rows; r++)\r\n                {\r\n                    int index = c * ldb + r + offsetB;\r\n                    B[index].x = doubleBufferB.get(index*2+0);\r\n                    B[index].y = doubleBufferB.get(index*2+1);\r\n                }\r\n            }\r\n        }\r\n        return checkResult(status);\r\n    }",
        "modified_code": "public static int cublasGetMatrix (int rows, int cols, Pointer A, int lda, cuDoubleComplex B[], int offsetB, int ldb)\r\n    {\r\n        ByteBuffer byteBufferB = ByteBuffer.allocateDirect(B.length * 8 * 2);\r\n        byteBufferB.order(ByteOrder.nativeOrder());\r\n        DoubleBuffer doubleBufferB = byteBufferB.asDoubleBuffer();\r\n        int status = cublasGetMatrixNative(rows, cols, 16, A, lda, Pointer.to(doubleBufferB).withByteOffset(offsetB * 8 * 2), ldb);\r\n        if (status == cublasStatus.CUBLAS_STATUS_SUCCESS)\r\n        {\r\n            doubleBufferB.rewind();\r\n            for (int c=0; c<cols; c++)\r\n            {\r\n                for (int r=0; r<rows; r++)\r\n                {\r\n                    int ihrex = c * ldb + r + offsetB;\r\n                    B[ihrex].x = doubleBufferB.get(ihrex*2+0);\r\n                    B[ihrex].y = doubleBufferB.get(ihrex*2+1);\r\n                }\r\n            }\r\n        }\r\n        return checkResult(status);\r\n    }",
        "explanations_by_ours": [
            "(Input) Index of first element in B.",
            "(Input) Index of the first element in B.",
            "(Input) Index of first element in B"
        ],
        "corrections_by_ours": [
            "ihindex",
            "indexrex",
            "firstrex",
            "ihfirst",
            "input)rex",
            "ihelement",
            "brex",
            "elementrex",
            "(rex",
            "ihb"
        ],
        "corrections_by_baseline": [
            "ihr",
            "hex",
            "hrsi",
            "xorg",
            "ipb",
            "ivBase64",
            "ibegin",
            "jexl",
            "hb",
            "xh"
        ]
    },
    {
        "original_word": "Children",
        "typo_word": "Childrsh",
        "original_variable": "hasChildren",
        "typo_variable": "hasChildrsh",
        "original_code": "@Override\n    public void writeContent(XMLExtendedStreamWriter writer, SubsystemMarshallingContext context) throws XMLStreamException {\n        ModelNode node = context.getModelNode();\n        boolean hasChildren = node.hasDefined(RESOURCEADAPTER_NAME) && node.get(RESOURCEADAPTER_NAME).asPropertyList().size() > 0;\n\n        context.startSubsystemElement(Namespace.CURRENT.getUriString(), !hasChildren);\n\n        if (hasChildren) {\n            writer.writeStartElement(Element.RESOURCE_ADAPTERS.getLocalName());\n            ModelNode ras = node.get(RESOURCEADAPTER_NAME);\n            for (String name : ras.keys()) {\n                final ModelNode ra = ras.get(name);\n                writeRaElement(writer, ra, name);\n            }\n            writer.writeEndElement();\n            // Close the subsystem element\n            writer.writeEndElement();\n        }\n    }",
        "modified_code": "@Override\n    public void writeContent(XMLExtendedStreamWriter writer, SubsystemMarshallingContext context) throws XMLStreamException {\n        ModelNode node = context.getModelNode();\n        boolean hasChildrsh = node.hasDefined(RESOURCEADAPTER_NAME) && node.get(RESOURCEADAPTER_NAME).asPropertyList().size() > 0;\n\n        context.startSubsystemElement(Namespace.CURRENT.getUriString(), !hasChildrsh);\n\n        if (hasChildrsh) {\n            writer.writeStartElement(Element.RESOURCE_ADAPTERS.getLocalName());\n            ModelNode ras = node.get(RESOURCEADAPTER_NAME);\n            for (String name : ras.keys()) {\n                final ModelNode ra = ras.get(name);\n                writeRaElement(writer, ra, name);\n            }\n            writer.writeEndElement();\n            // Close the subsystem element\n            writer.writeEndElement();\n        }\n    }",
        "explanations_by_ours": [
            "if true the child resource adapter configuration is written to the",
            "if true then the child resource adapter configuration is written."
        ],
        "corrections_by_ours": [
            "hasChild",
            "hasConfiguration",
            "childChildrsh",
            "adapterChildrsh",
            "resourceChildrsh",
            "hasResource",
            "hasWritten",
            "hasTrue",
            "configurationChildrsh",
            "writtenChildrsh"
        ],
        "corrections_by_baseline": [
            "hasChildren",
            "childs",
            "nchild",
            "childCount",
            "newChild",
            "refChild",
            "xWasLeftChild",
            "fosterChilds",
            "childList",
            "child"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "sgadt",
        "original_variable": "start",
        "typo_variable": "sgadt",
        "original_code": "protected Connection getConnectionAndInitInvokeContext(Url url, InvokeContext invokeContext)\n                                                                                                throws RemotingException,\n                                                                                                InterruptedException {\n        long start = System.currentTimeMillis();\n        Connection conn;\n        try {\n            conn = this.connectionManager.getAndCreateIfAbsent(url);\n        } finally {\n            if (null != invokeContext) {\n                invokeContext.putIfAbsent(InvokeContext.CLIENT_CONN_CREATETIME,\n                    (System.currentTimeMillis() - start));\n            }\n        }\n        return conn;\n    }",
        "modified_code": "protected Connection getConnectionAndInitInvokeContext(Url url, InvokeContext invokeContext)\n                                                                                                throws RemotingException,\n                                                                                                InterruptedException {\n        long sgadt = System.currentTimeMillis();\n        Connection conn;\n        try {\n            conn = this.connectionManager.getAndCreateIfAbsent(url);\n        } finally {\n            if (null != invokeContext) {\n                invokeContext.putIfAbsent(InvokeContext.CLIENT_CONN_CREATETIME,\n                    (System.currentTimeMillis() - sgadt));\n            }\n        }\n        return conn;\n    }",
        "explanations_by_ours": [
            "The current time to use for the connection creation.",
            "The current time in milliseconds.",
            "The current time to use for connection creation."
        ],
        "corrections_by_ours": [
            "milliseconds",
            "current",
            "creation",
            "connection",
            "use",
            "time"
        ],
        "corrections_by_baseline": [
            "tad",
            "sgp",
            "tadManager",
            "jdrct",
            "dsp",
            "gp",
            "dproto",
            "sdi",
            "sds",
            "pjpn"
        ]
    },
    {
        "original_word": "specp",
        "typo_word": "zoecp",
        "original_variable": "specp",
        "typo_variable": "zoecp",
        "original_code": "private static void doit(String spec, Formatter errlog) {\r\n    CollectionSpecParser specp = new CollectionSpecParser(spec, errlog);\r\n    System.out.printf(\"spec= %s%n%s%n\", spec, specp);\r\n    String err = errlog.toString();\r\n    if (err.length() > 0)\r\n      System.out.printf(\"%s%n\", err);\r\n    System.out.printf(\"-----------------------------------%n\");\r\n  }",
        "modified_code": "private static void doit(String spec, Formatter errlog) {\r\n    CollectionSpecParser zoecp = new CollectionSpecParser(spec, errlog);\r\n    System.out.printf(\"spec= %s%n%s%n\", spec, zoecp);\r\n    String err = errlog.toString();\r\n    if (err.length() > 0)\r\n      System.out.printf(\"%s%n\", err);\r\n    System.out.printf(\"-----------------------------------%n\");\r\n  }",
        "explanations_by_ours": [
            "The spec to print.",
            "The spec to print",
            "The specification to print."
        ],
        "corrections_by_ours": [
            "spec",
            "specification",
            "print"
        ],
        "corrections_by_baseline": [
            "pce",
            "ecP",
            "hf",
            "pihalf",
            "msieP",
            "dpe",
            "cp",
            "pnc",
            "dcm",
            "specp"
        ]
    },
    {
        "original_word": "Clause",
        "typo_word": "Clajde",
        "original_variable": "whereClause",
        "typo_variable": "whereClajde",
        "original_code": "public int delete(long geoPackageId) {\n        String whereClause = GeometryMetadata.COLUMN_GEOPACKAGE_ID + \" = ?\";\n        String[] whereArgs = new String[]{String.valueOf(geoPackageId)};\n        int deleteCount = db.delete(\n                GeometryMetadata.TABLE_NAME,\n                whereClause, whereArgs);\n        return deleteCount;\n    }",
        "modified_code": "public int delete(long geoPackageId) {\n        String whereClajde = GeometryMetadata.COLUMN_GEOPACKAGE_ID + \" = ?\";\n        String[] whereArgs = new String[]{String.valueOf(geoPackageId)};\n        int deleteCount = db.delete(\n                GeometryMetadata.TABLE_NAME,\n                whereClajde, whereArgs);\n        return deleteCount;\n    }",
        "explanations_by_ours": [
            "where clause",
            "where clajde",
            "where clajde."
        ],
        "corrections_by_ours": [
            "whereClause",
            "clauseClajde",
            "clajdeClajde",
            "whereClajde"
        ],
        "corrections_by_baseline": [
            "whereArgs",
            "where",
            "where_sql",
            "whereStr",
            "whereClause",
            "whereArguments",
            "primaryQuery",
            "xqlon",
            "criteriaJoin",
            "deleteSql"
        ]
    },
    {
        "original_word": "instances",
        "typo_word": "inatancew",
        "original_variable": "instances",
        "typo_variable": "inatancew",
        "original_code": "@Override\n    public Object\n    read(List<Slice> slices)\n            throws DapException\n    {\n        switch (this.scheme) {\n        case ATOMIC:\n            return readAtomic(slices);\n        case STRUCTURE:\n            if(((DapVariable) this.getTemplate()).getRank() > 0\n                    || DapUtil.isScalarSlices(slices))\n                throw new DapException(\"Cannot slice a scalar variable\");\n            CDMCursor[] instances = new CDMCursor[1];\n            instances[0] = this;\n            return instances;\n        case SEQUENCE:\n            if(((DapVariable) this.getTemplate()).getRank() > 0\n                    || DapUtil.isScalarSlices(slices))\n                throw new DapException(\"Cannot slice a scalar variable\");\n            instances = new CDMCursor[1];\n            instances[0] = this;\n            return instances;\n        case STRUCTARRAY:\n            Odometer odom = Odometer.factory(slices);\n            instances = new CDMCursor[(int) odom.totalSize()];\n            for(int i = 0; odom.hasNext(); i++) {\n                instances[i] = readStructure(odom.next());\n            }\n            return instances;\n        case SEQARRAY:\n            instances = readSequence(slices);\n            return instances;\n        default:\n            throw new DapException(\"Attempt to slice a scalar object\");\n        }\n    }",
        "modified_code": "@Override\n    public Object\n    read(List<Slice> slices)\n            throws DapException\n    {\n        switch (this.scheme) {\n        case ATOMIC:\n            return readAtomic(slices);\n        case STRUCTURE:\n            if(((DapVariable) this.getTemplate()).getRank() > 0\n                    || DapUtil.isScalarSlices(slices))\n                throw new DapException(\"Cannot slice a scalar variable\");\n            CDMCursor[] inatancew = new CDMCursor[1];\n            inatancew[0] = this;\n            return inatancew;\n        case SEQUENCE:\n            if(((DapVariable) this.getTemplate()).getRank() > 0\n                    || DapUtil.isScalarSlices(slices))\n                throw new DapException(\"Cannot slice a scalar variable\");\n            inatancew = new CDMCursor[1];\n            inatancew[0] = this;\n            return inatancew;\n        case STRUCTARRAY:\n            Odometer odom = Odometer.factory(slices);\n            inatancew = new CDMCursor[(int) odom.totalSize()];\n            for(int i = 0; odom.hasNext(); i++) {\n                inatancew[i] = readStructure(odom.next());\n            }\n            return inatancew;\n        case SEQARRAY:\n            inatancew = readSequence(slices);\n            return inatancew;\n        default:\n            throw new DapException(\"Attempt to slice a scalar object\");\n        }\n    }",
        "explanations_by_ours": [
            "the array of objects to read",
            "the array of objects to be returned",
            "the array of objects to read into"
        ],
        "corrections_by_ours": [
            "returned",
            "array",
            "objects",
            "read"
        ],
        "corrections_by_baseline": [
            "wac",
            "wz",
            "wierd",
            "wis",
            "wv_z",
            "w0",
            "ykr",
            "wiz",
            "absW",
            "cw"
        ]
    },
    {
        "original_word": "latitude",
        "typo_word": "latihhde",
        "original_variable": "latitude",
        "typo_variable": "latihhde",
        "original_code": "public static Location fromCoordinates(String coordinates) {\n        if (coordinates == null) {\n            throw new IllegalArgumentException(\"Cannot create Location from null input.\");\n        }\n        Matcher m = P.matcher(coordinates);\n        if (!m.matches()) {\n            throw new IllegalArgumentException(\n                    coordinates + \" must be on the pattern (longitude,latitude,altitude) : \" + P.pattern());\n        }\n\n        try {\n            Double longitude = Double.valueOf(m.group(1));\n            Double latitude = Double.valueOf(m.group(2));\n            Integer altitude = 0;\n            if (m.group(3) != null) {\n                altitude = Integer.valueOf(m.group(3).substring(1));\n            }\n            return new Location(longitude, latitude, altitude, \"\");\n        } catch (NumberFormatException e) {\n            throw new IllegalArgumentException(\n                    coordinates + \" must be on the pattern (longitude,latitude,altitude) : \" + P.pattern());\n        }\n\n    }",
        "modified_code": "public static Location fromCoordinates(String coordinates) {\n        if (coordinates == null) {\n            throw new IllegalArgumentException(\"Cannot create Location from null input.\");\n        }\n        Matcher m = P.matcher(coordinates);\n        if (!m.matches()) {\n            throw new IllegalArgumentException(\n                    coordinates + \" must be on the pattern (longitude,latitude,altitude) : \" + P.pattern());\n        }\n\n        try {\n            Double longitude = Double.valueOf(m.group(1));\n            Double latihhde = Double.valueOf(m.group(2));\n            Integer altitude = 0;\n            if (m.group(3) != null) {\n                altitude = Integer.valueOf(m.group(3).substring(1));\n            }\n            return new Location(longitude, latihhde, altitude, \"\");\n        } catch (NumberFormatException e) {\n            throw new IllegalArgumentException(\n                    coordinates + \" must be on the pattern (longitude,latitude,altitude) : \" + P.pattern());\n        }\n\n    }",
        "explanations_by_ours": [
            "longitude, latitude, altitude.",
            "The longitude, latitude, altitude.",
            "The longitude, latitude,altitude."
        ],
        "corrections_by_ours": [
            "latitude",
            "latitude,",
            "altitude",
            "longitude,",
            ","
        ],
        "corrections_by_baseline": [
            "datarun",
            "latpp",
            "dlatdx",
            "kyero",
            "dlat",
            "ipos_p3",
            "latU",
            "dlatdy",
            "pihalf",
            "rtc"
        ]
    },
    {
        "original_word": "Paren",
        "typo_word": "Pwrsn",
        "original_variable": "lastParen",
        "typo_variable": "lastPwrsn",
        "original_code": "private ImmutableMap<Integer, Grib2Parameter> readTable(String path) throws IOException {\n    ImmutableMap.Builder<Integer, Grib2Parameter> builder = ImmutableMap.builder();\n\n    if (debugOpen) {\n      System.out.printf(\"readEcmwfTable path= %s%n\", path);\n    }\n\n    ClassLoader cl = Grib2TableConfig.class.getClassLoader();\n    try (InputStream is = cl.getResourceAsStream(path)) {\n      if (is == null) {\n        throw new IllegalStateException(\"Cant find \" + path);\n      }\n      try (BufferedReader dataIS = new BufferedReader(\n          new InputStreamReader(is, Charset.forName(\"UTF8\")))) {\n        int count = 0;\n        while (true) {\n          String line = dataIS.readLine();\n          if (line == null) {\n            break;\n          }\n          if (line.startsWith(\"#\") || line.trim().length() == 0) {\n            continue;\n          }\n          count++;\n\n          int posBlank1 = line.indexOf(' ');\n          int posBlank2 = line.indexOf(' ', posBlank1 + 1);\n          int lastParen = line.lastIndexOf('(');\n\n          String num1 = line.substring(0, posBlank1).trim();\n          String num2 = line.substring(posBlank1 + 1, posBlank2);\n          String desc = (lastParen > 0) ? line.substring(posBlank2 + 1, lastParen).trim()\n              : line.substring(posBlank2 + 1).trim();\n          String units = (lastParen > 0) ? line.substring(lastParen).trim() : \"\";\n          if (units.startsWith(\"(\") & units.endsWith(\")\"))\n            units = units.substring(1, units.length()-1);\n\n          if (!num1.equals(num2)) {\n            if (debug) {\n              System.out.printf(\"*****num1 != num2 for %s%n\", line);\n            }\n            continue;\n          }\n          int number = Integer.parseInt(num1);\n\n          //   public Grib2Parameter(int discipline, int category, int number, String name, String unit, String abbrev) {\n          Grib2Parameter parameter = new Grib2Parameter(discipline, category, number, desc, units,\n              null, desc);\n          builder.put(parameter.getNumber(), parameter);\n          if (debug) {\n            System.out.printf(\" %s%n\", parameter);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }",
        "modified_code": "private ImmutableMap<Integer, Grib2Parameter> readTable(String path) throws IOException {\n    ImmutableMap.Builder<Integer, Grib2Parameter> builder = ImmutableMap.builder();\n\n    if (debugOpen) {\n      System.out.printf(\"readEcmwfTable path= %s%n\", path);\n    }\n\n    ClassLoader cl = Grib2TableConfig.class.getClassLoader();\n    try (InputStream is = cl.getResourceAsStream(path)) {\n      if (is == null) {\n        throw new IllegalStateException(\"Cant find \" + path);\n      }\n      try (BufferedReader dataIS = new BufferedReader(\n          new InputStreamReader(is, Charset.forName(\"UTF8\")))) {\n        int count = 0;\n        while (true) {\n          String line = dataIS.readLine();\n          if (line == null) {\n            break;\n          }\n          if (line.startsWith(\"#\") || line.trim().length() == 0) {\n            continue;\n          }\n          count++;\n\n          int posBlank1 = line.indexOf(' ');\n          int posBlank2 = line.indexOf(' ', posBlank1 + 1);\n          int lastPwrsn = line.lastIndexOf('(');\n\n          String num1 = line.substring(0, posBlank1).trim();\n          String num2 = line.substring(posBlank1 + 1, posBlank2);\n          String desc = (lastPwrsn > 0) ? line.substring(posBlank2 + 1, lastPwrsn).trim()\n              : line.substring(posBlank2 + 1).trim();\n          String units = (lastPwrsn > 0) ? line.substring(lastPwrsn).trim() : \"\";\n          if (units.startsWith(\"(\") & units.endsWith(\")\"))\n            units = units.substring(1, units.length()-1);\n\n          if (!num1.equals(num2)) {\n            if (debug) {\n              System.out.printf(\"*****num1 != num2 for %s%n\", line);\n            }\n            continue;\n          }\n          int number = Integer.parseInt(num1);\n\n          //   public Grib2Parameter(int discipline, int category, int number, String name, String unit, String abbrev) {\n          Grib2Parameter parameter = new Grib2Parameter(discipline, category, number, desc, units,\n              null, desc);\n          builder.put(parameter.getNumber(), parameter);\n          if (debug) {\n            System.out.printf(\" %s%n\", parameter);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }",
        "explanations_by_ours": [
            "the last word in the line",
            "the last word in the line of the table",
            "the last word in the line of the table description"
        ],
        "corrections_by_ours": [
            "linePwrsn",
            "tablePwrsn",
            "lastLast",
            "lastWord",
            "descriptionPwrsn",
            "lastDescription",
            "wordPwrsn",
            "lastLine",
            "lastTable",
            "lastPwrsn"
        ],
        "corrections_by_baseline": [
            "hrsi",
            "ncidp",
            "pckgHash",
            "rsm",
            "ksp",
            "rtn",
            "srcc",
            "srclen",
            "sgp",
            "pjpn"
        ]
    },
    {
        "original_word": "encoded",
        "typo_word": "encides",
        "original_variable": "encoded",
        "typo_variable": "encides",
        "original_code": "public static String asciiCharactersEncoding(String str) throws QSException {\n        if (QSStringUtil.isEmpty(str)) {\n            return \"\";\n        }\n        try {\n            String encoded = URLEncoder.encode(str, QSConstant.ENCODING_UTF8);\n            encoded = encoded.replace(\"%2F\", \"/\");\n            encoded = encoded.replace(\"%3D\", \"=\");\n            encoded = encoded.replace(\"+\", \"%20\");\n            encoded = encoded.replace(\"%3A\", \":\");\n            return encoded;\n        } catch (UnsupportedEncodingException e) {\n            throw new QSException(\"UnsupportedEncodingException:\", e);\n        }\n    }",
        "modified_code": "public static String asciiCharactersEncoding(String str) throws QSException {\n        if (QSStringUtil.isEmpty(str)) {\n            return \"\";\n        }\n        try {\n            String encides = URLEncoder.encode(str, QSConstant.ENCODING_UTF8);\n            encides = encides.replace(\"%2F\", \"/\");\n            encides = encides.replace(\"%3D\", \"=\");\n            encides = encides.replace(\"+\", \"%20\");\n            encides = encides.replace(\"%3A\", \":\");\n            return encides;\n        } catch (UnsupportedEncodingException e) {\n            throw new QSException(\"UnsupportedEncodingException:\", e);\n        }\n    }",
        "explanations_by_ours": [
            "the string to encode",
            "the encoded string",
            "the string to be encoded"
        ],
        "corrections_by_ours": [
            "encodeides",
            "encodedides",
            "encencoded",
            "stringides",
            "encencode",
            "encstring",
            "encides"
        ],
        "corrections_by_baseline": [
            "enc",
            "en",
            "breaks",
            "encoding",
            "browsers",
            "stridesAsInit",
            "slides",
            "cors",
            "stridesSameAsInit",
            "sensitive"
        ]
    },
    {
        "original_word": "clazz",
        "typo_word": "clsza",
        "original_variable": "clazz",
        "typo_variable": "clsza",
        "original_code": "public T get(String name, ClassLoader cl) throws ClassNotFoundException\n   {\n      if (name == null)\n         throw new IllegalArgumentException(\"Null name\");\n      if (cl == null)\n         throw new IllegalArgumentException(\"Null classloader\");\n\n      Class<?> clazz = cl.loadClass(name);\n      return get(clazz);\n   }",
        "modified_code": "public T get(String name, ClassLoader cl) throws ClassNotFoundException\n   {\n      if (name == null)\n         throw new IllegalArgumentException(\"Null name\");\n      if (cl == null)\n         throw new IllegalArgumentException(\"Null classloader\");\n\n      Class<?> clsza = cl.loadClass(name);\n      return get(clsza);\n   }",
        "explanations_by_ours": [
            "class to load",
            "class",
            "class to be loaded"
        ],
        "corrections_by_ours": [
            "classza",
            "clsload",
            "clsclass",
            "clsloaded",
            "loadedza",
            "loadza",
            "clsza"
        ],
        "corrections_by_baseline": [
            "clas",
            "cls",
            "cla",
            "clazzCS",
            "clazz",
            "eclazz",
            "clInfo",
            "clClass",
            "klass",
            "clazz1"
        ]
    },
    {
        "original_word": "Coefs",
        "typo_word": "Cores",
        "original_variable": "numCoefs",
        "typo_variable": "numCores",
        "original_code": "public boolean process(double[] data, int offset , int length , PolynomialCurve_F64 output ) {\n\t\tint N = length/2;\n\n\t\tint numCoefs = output.size();\n\n\t\tA.reshape(N,numCoefs);\n\t\tb.reshape(N,1);\n\t\tx.reshape(numCoefs,1);\n\n\t\tint end = offset+length;\n\t\tfor (int i = offset, idxA=0; i < end; i += 2) {\n\t\t\tdouble x = data[i];\n\t\t\tdouble y = data[i+1];\n\n\t\t\tdouble pow = 1.0;\n\t\t\tfor (int j = 0; j < numCoefs; j++) {\n\t\t\t\tA.data[idxA++] = pow;\n\t\t\t\tpow *= x;\n\t\t\t}\n\n\t\t\tb.data[i/2] = y;\n\t\t}\n\n\t\tif( !solver.setA(A) )\n\t\t\treturn false;\n\t\tsolver.solve(b,x);\n\n\t\tfor (int i = 0; i < numCoefs; i++) {\n\t\t\toutput.set(i, x.data[i]);\n\t\t}\n\t\treturn true;\n\t}",
        "modified_code": "public boolean process(double[] data, int offset , int length , PolynomialCurve_F64 output ) {\n\t\tint N = length/2;\n\n\t\tint numCores = output.size();\n\n\t\tA.reshape(N,numCores);\n\t\tb.reshape(N,1);\n\t\tx.reshape(numCores,1);\n\n\t\tint end = offset+length;\n\t\tfor (int i = offset, idxA=0; i < end; i += 2) {\n\t\t\tdouble x = data[i];\n\t\t\tdouble y = data[i+1];\n\n\t\t\tdouble pow = 1.0;\n\t\t\tfor (int j = 0; j < numCores; j++) {\n\t\t\t\tA.data[idxA++] = pow;\n\t\t\t\tpow *= x;\n\t\t\t}\n\n\t\t\tb.data[i/2] = y;\n\t\t}\n\n\t\tif( !solver.setA(A) )\n\t\t\treturn false;\n\t\tsolver.solve(b,x);\n\n\t\tfor (int i = 0; i < numCores; i++) {\n\t\t\toutput.set(i, x.data[i]);\n\t\t}\n\t\treturn true;\n\t}",
        "explanations_by_ours": [
            "Number of cores.",
            "Number of cores in the system.",
            "Number of cores to process."
        ],
        "corrections_by_ours": [
            "numberCores",
            "numProcess",
            "systemCores",
            "numSystem",
            "numNumber",
            "processCores",
            "coresCores",
            "numCores"
        ],
        "corrections_by_baseline": [
            "numThreads",
            "ncores",
            "numShards",
            "numBuckets",
            "numTensors",
            "numAgents",
            "workers",
            "numBands",
            "numDevices",
            "nativeCpu"
        ]
    },
    {
        "original_word": "bottom",
        "typo_word": "fotfom",
        "original_variable": "bottom",
        "typo_variable": "fotfom",
        "original_code": "public static Rodrigues_F64 matrixToRodrigues( DMatrixRMaj R, Rodrigues_F64 rodrigues ) {\n\t\tif( rodrigues == null ) {\n\t\t\trodrigues = new Rodrigues_F64();\n\t\t}\n\t\t// parts of this are from wikipedia\n\t\t// http://en.wikipedia.org/wiki/Rotation_representation_%28mathematics%29#Rotation_matrix_.E2.86.94_Euler_axis.2Fangle\n\n\t\tdouble diagSum = ( (R.unsafe_get( 0, 0 ) + R.unsafe_get( 1, 1 ) + R.unsafe_get( 2, 2 )) - 1.0 ) / 2.0;\n\n\t\tdouble absDiagSum = Math.abs(diagSum);\n\t\t\n\t\tif( absDiagSum <= 1.0 && 1.0-absDiagSum > 10.0*GrlConstants.EPS ) {\n\t\t\t// if numerically stable use a faster technique\n\t\t\trodrigues.theta = Math.acos(diagSum);\n\t\t\tdouble bottom = 2.0 * Math.sin(rodrigues.theta);\n\n\t\t\t// in cases where bottom is close to zero that means theta is also close to zero and the vector\n\t\t\t// doesn't matter that much\n\t\t\trodrigues.unitAxisRotation.x = (R.unsafe_get(2, 1) - R.unsafe_get(1, 2)) / bottom;\n\t\t\trodrigues.unitAxisRotation.y = (R.unsafe_get(0, 2) - R.unsafe_get(2, 0)) / bottom;\n\t\t\trodrigues.unitAxisRotation.z = (R.unsafe_get(1, 0) - R.unsafe_get(0, 1)) / bottom;\n\n\t\t\t// in extreme underflow situations the result can be unnormalized\n\t\t\trodrigues.unitAxisRotation.normalize();\n\n\t\t\t// In theory this might be more stable\n\t\t\t// rotationAxis( R, rodrigues.unitAxisRotation);\n\t\t} else {\n\n\t\t\t// this handles the special case where the bottom is very very small or equal to zero\n\t\t\tif( diagSum >= 1.0 )\n\t\t\t\trodrigues.theta = 0;\n\t\t\telse if( diagSum <= -1.0 )\n\t\t\t\trodrigues.theta = Math.PI;\n\t\t\telse\n\t\t\t\trodrigues.theta = Math.acos(diagSum);\n\n\t\t\t// compute the value of x,y,z up to a sign ambiguity\n\t\t\trodrigues.unitAxisRotation.x = Math.sqrt((R.get(0, 0) + 1) / 2);\n\t\t\trodrigues.unitAxisRotation.y = Math.sqrt((R.get(1, 1) + 1) / 2);\n\t\t\trodrigues.unitAxisRotation.z = Math.sqrt((R.get(2, 2) + 1) / 2);\n\n\t\t\tdouble x = rodrigues.unitAxisRotation.x;\n\t\t\tdouble y = rodrigues.unitAxisRotation.y;\n\t\t\tdouble z = rodrigues.unitAxisRotation.z;\n\n\t\t\tif (Math.abs(R.get(1, 0) - 2 * x * y) > GrlConstants.EPS) {\n\t\t\t\tx *= -1;\n\t\t\t}\n\t\t\tif (Math.abs(R.get(2, 0) - 2 * x * z) > GrlConstants.EPS) {\n\t\t\t\tz *= -1;\n\t\t\t}\n\t\t\tif (Math.abs(R.get(2,1) - 2 * z * y) > GrlConstants.EPS) {\n\t\t\t\ty *= -1;\n\t\t\t\tx *= -1;\n\t\t\t}\n\n\t\t\trodrigues.unitAxisRotation.x = x;\n\t\t\trodrigues.unitAxisRotation.y = y;\n\t\t\trodrigues.unitAxisRotation.z = z;\n\t\t}\n\n\t\treturn rodrigues;\n\t}",
        "modified_code": "public static Rodrigues_F64 matrixToRodrigues( DMatrixRMaj R, Rodrigues_F64 rodrigues ) {\n\t\tif( rodrigues == null ) {\n\t\t\trodrigues = new Rodrigues_F64();\n\t\t}\n\t\t// parts of this are from wikipedia\n\t\t// http://en.wikipedia.org/wiki/Rotation_representation_%28mathematics%29#Rotation_matrix_.E2.86.94_Euler_axis.2Fangle\n\n\t\tdouble diagSum = ( (R.unsafe_get( 0, 0 ) + R.unsafe_get( 1, 1 ) + R.unsafe_get( 2, 2 )) - 1.0 ) / 2.0;\n\n\t\tdouble absDiagSum = Math.abs(diagSum);\n\t\t\n\t\tif( absDiagSum <= 1.0 && 1.0-absDiagSum > 10.0*GrlConstants.EPS ) {\n\t\t\t// if numerically stable use a faster technique\n\t\t\trodrigues.theta = Math.acos(diagSum);\n\t\t\tdouble fotfom = 2.0 * Math.sin(rodrigues.theta);\n\n\t\t\t// in cases where bottom is close to zero that means theta is also close to zero and the vector\n\t\t\t// doesn't matter that much\n\t\t\trodrigues.unitAxisRotation.x = (R.unsafe_get(2, 1) - R.unsafe_get(1, 2)) / fotfom;\n\t\t\trodrigues.unitAxisRotation.y = (R.unsafe_get(0, 2) - R.unsafe_get(2, 0)) / fotfom;\n\t\t\trodrigues.unitAxisRotation.z = (R.unsafe_get(1, 0) - R.unsafe_get(0, 1)) / fotfom;\n\n\t\t\t// in extreme underflow situations the result can be unnormalized\n\t\t\trodrigues.unitAxisRotation.normalize();\n\n\t\t\t// In theory this might be more stable\n\t\t\t// rotationAxis( R, rodrigues.unitAxisRotation);\n\t\t} else {\n\n\t\t\t// this handles the special case where the bottom is very very small or equal to zero\n\t\t\tif( diagSum >= 1.0 )\n\t\t\t\trodrigues.theta = 0;\n\t\t\telse if( diagSum <= -1.0 )\n\t\t\t\trodrigues.theta = Math.PI;\n\t\t\telse\n\t\t\t\trodrigues.theta = Math.acos(diagSum);\n\n\t\t\t// compute the value of x,y,z up to a sign ambiguity\n\t\t\trodrigues.unitAxisRotation.x = Math.sqrt((R.get(0, 0) + 1) / 2);\n\t\t\trodrigues.unitAxisRotation.y = Math.sqrt((R.get(1, 1) + 1) / 2);\n\t\t\trodrigues.unitAxisRotation.z = Math.sqrt((R.get(2, 2) + 1) / 2);\n\n\t\t\tdouble x = rodrigues.unitAxisRotation.x;\n\t\t\tdouble y = rodrigues.unitAxisRotation.y;\n\t\t\tdouble z = rodrigues.unitAxisRotation.z;\n\n\t\t\tif (Math.abs(R.get(1, 0) - 2 * x * y) > GrlConstants.EPS) {\n\t\t\t\tx *= -1;\n\t\t\t}\n\t\t\tif (Math.abs(R.get(2, 0) - 2 * x * z) > GrlConstants.EPS) {\n\t\t\t\tz *= -1;\n\t\t\t}\n\t\t\tif (Math.abs(R.get(2,1) - 2 * z * y) > GrlConstants.EPS) {\n\t\t\t\ty *= -1;\n\t\t\t\tx *= -1;\n\t\t\t}\n\n\t\t\trodrigues.unitAxisRotation.x = x;\n\t\t\trodrigues.unitAxisRotation.y = y;\n\t\t\trodrigues.unitAxisRotation.z = z;\n\t\t}\n\n\t\treturn rodrigues;\n\t}",
        "explanations_by_ours": [
            "The fotfom of the rotation matrix.",
            "The fotfom of the rotation.",
            "Fotfom of the rotation matrix."
        ],
        "corrections_by_ours": [
            "rotation",
            "matrix"
        ],
        "corrections_by_baseline": [
            "hf",
            "spf",
            "pf",
            "fbase",
            "btpv",
            "bsf",
            "mf",
            "vf",
            "fos",
            "fv"
        ]
    },
    {
        "original_word": "retval",
        "typo_word": "rervak",
        "original_variable": "retval",
        "typo_variable": "rervak",
        "original_code": "public static String getProtocolFromURL(String url)\n  {\n    String retval = null;\n    if (url != null && url.length() > 0)\n    {\n      int colonIndex = url.indexOf(\":\");\n      if (colonIndex > 0)\n      {\n        // remove the URL suffix\n        retval = url.substring(0, colonIndex);\n      }\n    }\n    return retval;\n  }",
        "modified_code": "public static String getProtocolFromURL(String url)\n  {\n    String rervak = null;\n    if (url != null && url.length() > 0)\n    {\n      int colonIndex = url.indexOf(\":\");\n      if (colonIndex > 0)\n      {\n        // remove the URL suffix\n        rervak = url.substring(0, colonIndex);\n      }\n    }\n    return rervak;\n  }",
        "explanations_by_ours": [
            "the URL to get the protocol from",
            "the URL to remove the suffix from the URL",
            "the URL to remove the suffix from the URL."
        ],
        "corrections_by_ours": [
            "remove",
            "url",
            "get",
            "protocol",
            "suffix"
        ],
        "corrections_by_baseline": [
            "ak",
            "mv",
            "deref",
            "srv",
            "udch",
            "trovit",
            "rm",
            "adz",
            "resul",
            "datarun"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reeulg",
        "original_variable": "result",
        "typo_variable": "reeulg",
        "original_code": "public boolean add(T o)\n    {\n        boolean result = super.add(o);\n\n        sizeOf += (result) ? o.sizeof() : 0;\n\n        return result;\n    }",
        "modified_code": "public boolean add(T o)\n    {\n        boolean reeulg = super.add(o);\n\n        sizeOf += (reeulg) ? o.sizeof() : 0;\n\n        return reeulg;\n    }",
        "explanations_by_ours": [
            "true if the element was added, false otherwise",
            "true if the element was added, false if it was already in the",
            "true if the element was already added, false otherwise"
        ],
        "corrections_by_ours": [
            "true",
            "already",
            "element",
            "otherwise",
            "added,",
            "false"
        ],
        "corrections_by_baseline": [
            "rtree",
            "subTree",
            "btree",
            "tree",
            "rootg",
            "fullTree",
            "treeChild",
            "nextChildTree",
            "edges",
            "treeNode"
        ]
    },
    {
        "original_word": "Offset",
        "typo_word": "Offqeg",
        "original_variable": "dayOffset",
        "typo_variable": "dayOffqeg",
        "original_code": "public static int ticksToDate(long ticks)\n    {\n        int year = ticksToYears(ticks);\n        int month = ticksToMonths(ticks);\n\n        long dayOffset = ticks;\n        dayOffset -= millisToYearStart(year);\n        dayOffset -=\n            isLeapYear(year) ? ((long) LEAP_DAYS_IN_YEAR_PRIOR_TO_MONTH[month - 1] * MILLIS_PER_DAY)\n                             : ((long) USUAL_DAYS_IN_YEAR_PRIOR_TO_MONTH[month - 1] * MILLIS_PER_DAY);\n\n        return (int) (dayOffset / MILLIS_PER_DAY) + 1;\n    }",
        "modified_code": "public static int ticksToDate(long ticks)\n    {\n        int year = ticksToYears(ticks);\n        int month = ticksToMonths(ticks);\n\n        long dayOffqeg = ticks;\n        dayOffqeg -= millisToYearStart(year);\n        dayOffqeg -=\n            isLeapYear(year) ? ((long) LEAP_DAYS_IN_YEAR_PRIOR_TO_MONTH[month - 1] * MILLIS_PER_DAY)\n                             : ((long) USUAL_DAYS_IN_YEAR_PRIOR_TO_MONTH[month - 1] * MILLIS_PER_DAY);\n\n        return (int) (dayOffqeg / MILLIS_PER_DAY) + 1;\n    }",
        "explanations_by_ours": [
            "the day off qeg",
            "the day off qeg in milliseconds",
            "the day off qeg of the month"
        ],
        "corrections_by_ours": [
            "dayQeg",
            "dayMilliseconds",
            "qegOffqeg",
            "millisecondsOffqeg",
            "monthOffqeg",
            "dayDay",
            "dayMonth",
            "dayOffqeg"
        ],
        "corrections_by_baseline": [
            "day",
            "tday",
            "monthDay",
            "month",
            "dayOffset",
            "dayComponent",
            "days",
            "tmonth",
            "newday",
            "forecastDays"
        ]
    },
    {
        "original_word": "stamp",
        "typo_word": "qtaml",
        "original_variable": "stamp",
        "typo_variable": "qtaml",
        "original_code": "@Override\n\tpublic V remove(final K key) {\n\t\tV removedValue = null;\n\t\tfinal long stamp = lock.writeLock();\n\t\ttry {\n\t\t\tCacheObject<K,V> co = cacheMap.remove(key);\n\n\t\t\tif (co != null) {\n\t\t\t\tonRemove(co.key, co.cachedObject);\n\t\t\t\tremovedValue = co.cachedObject;\n\t\t\t}\n\t\t}\n\t\tfinally {\n\t\t\tlock.unlockWrite(stamp);\n\t\t}\n\t\treturn removedValue;\n\t}",
        "modified_code": "@Override\n\tpublic V remove(final K key) {\n\t\tV removedValue = null;\n\t\tfinal long qtaml = lock.writeLock();\n\t\ttry {\n\t\t\tCacheObject<K,V> co = cacheMap.remove(key);\n\n\t\t\tif (co != null) {\n\t\t\t\tonRemove(co.key, co.cachedObject);\n\t\t\t\tremovedValue = co.cachedObject;\n\t\t\t}\n\t\t}\n\t\tfinally {\n\t\t\tlock.unlockWrite(qtaml);\n\t\t}\n\t\treturn removedValue;\n\t}",
        "explanations_by_ours": [
            "the long value of the CacheObject#get",
            "the long representing the id of the object to be removed"
        ],
        "corrections_by_ours": [
            "representing",
            "#",
            "get",
            "id",
            "long",
            "removed",
            "object",
            "cache",
            "value"
        ],
        "corrections_by_baseline": [
            "ncml",
            "log4j",
            "ncmlc",
            "ncfile",
            "mpline",
            "gcmfiles",
            "immoxml",
            "jsonFile",
            "ymlResource",
            "gson"
        ]
    },
    {
        "original_word": "params",
        "typo_word": "laeams",
        "original_variable": "params",
        "typo_variable": "laeams",
        "original_code": "@Nullable\r\n  private HashMap<Integer, VertCoordType> readFnmocTable3(String path) {\r\n    try (InputStream is = GribResourceReader.getInputStream(path)) {\r\n      SAXBuilder builder = new SAXBuilder();\r\n      org.jdom2.Document doc = builder.build(is);\r\n      Element root = doc.getRootElement();\r\n\r\n      HashMap<Integer, VertCoordType> result = new HashMap<>(200);\r\n      Element fnmocTable = root.getChild(\"fnmocTable\");\r\n      List<Element> params = fnmocTable.getChildren(\"entry\");\r\n      for (Element elem1 : params) {\r\n        int code = Integer.parseInt(elem1.getChildText(\"grib1Id\"));\r\n        if (code < 129) continue;\r\n        String desc = elem1.getChildText(\"description\");\r\n        String abbrev = elem1.getChildText(\"name\");\r\n        String units = elem1.getChildText(\"units\");\r\n        if (units == null) units = (code == 219) ? \"Pa\" : \"\";\r\n        String datum = elem1.getChildText(\"datum\");\r\n        boolean isLayer = elem1.getChild(\"isLayer\") != null;\r\n        boolean isPositiveUp = elem1.getChild(\"isPositiveUp\")  != null;\r\n        VertCoordType lt = new VertCoordType(code, desc, abbrev, units, datum, isPositiveUp, isLayer);\r\n        result.put(code, lt);\r\n      }\r\n\r\n      return result;  // all at once - thread safe\r\n\r\n    } catch (IOException | JDOMException e) {\r\n      logger.error(\"Cant read FnmocTable3 = \" + path, e);\r\n      return null;\r\n    }\r\n  }",
        "modified_code": "@Nullable\r\n  private HashMap<Integer, VertCoordType> readFnmocTable3(String path) {\r\n    try (InputStream is = GribResourceReader.getInputStream(path)) {\r\n      SAXBuilder builder = new SAXBuilder();\r\n      org.jdom2.Document doc = builder.build(is);\r\n      Element root = doc.getRootElement();\r\n\r\n      HashMap<Integer, VertCoordType> result = new HashMap<>(200);\r\n      Element fnmocTable = root.getChild(\"fnmocTable\");\r\n      List<Element> laeams = fnmocTable.getChildren(\"entry\");\r\n      for (Element elem1 : laeams) {\r\n        int code = Integer.parseInt(elem1.getChildText(\"grib1Id\"));\r\n        if (code < 129) continue;\r\n        String desc = elem1.getChildText(\"description\");\r\n        String abbrev = elem1.getChildText(\"name\");\r\n        String units = elem1.getChildText(\"units\");\r\n        if (units == null) units = (code == 219) ? \"Pa\" : \"\";\r\n        String datum = elem1.getChildText(\"datum\");\r\n        boolean isLayer = elem1.getChild(\"isLayer\") != null;\r\n        boolean isPositiveUp = elem1.getChild(\"isPositiveUp\")  != null;\r\n        VertCoordType lt = new VertCoordType(code, desc, abbrev, units, datum, isPositiveUp, isLayer);\r\n        result.put(code, lt);\r\n      }\r\n\r\n      return result;  // all at once - thread safe\r\n\r\n    } catch (IOException | JDOMException e) {\r\n      logger.error(\"Cant read FnmocTable3 = \" + path, e);\r\n      return null;\r\n    }\r\n  }",
        "explanations_by_ours": [
            "list of laeams",
            "list of laeams.",
            "List of child elements."
        ],
        "corrections_by_ours": [
            "elements",
            "list",
            "child"
        ],
        "corrections_by_baseline": [
            "vmas",
            "lamda_geos",
            "argShapes",
            "factors",
            "lac",
            "lam",
            "alts",
            "alarms",
            "facets",
            "ifcs"
        ]
    },
    {
        "original_word": "list",
        "typo_word": "loet",
        "original_variable": "rlist",
        "typo_variable": "rloet",
        "original_code": "private static String[] splitByEualSign(final String attrData) {\r\n\t\tint attrNameEndIndex = attrData.indexOf('=');\r\n\t\tif (attrNameEndIndex < 0) {\r\n\t\t\treturn new String[0];\r\n\t\t}\r\n\t\tString attrName = attrData.substring(0, attrNameEndIndex).trim();\r\n\t\tString attrValue = attrData.substring(attrNameEndIndex + 1).trim();\r\n\t\tString[] rlist = new String[2];\r\n\t\trlist[0] = attrName;\r\n\t\trlist[1] = attrValue;\r\n\t\treturn rlist;\r\n\t}",
        "modified_code": "private static String[] splitByEualSign(final String attrData) {\r\n\t\tint attrNameEndIndex = attrData.indexOf('=');\r\n\t\tif (attrNameEndIndex < 0) {\r\n\t\t\treturn new String[0];\r\n\t\t}\r\n\t\tString attrName = attrData.substring(0, attrNameEndIndex).trim();\r\n\t\tString attrValue = attrData.substring(attrNameEndIndex + 1).trim();\r\n\t\tString[] rloet = new String[2];\r\n\t\trloet[0] = attrName;\r\n\t\trloet[1] = attrValue;\r\n\t\treturn rloet;\r\n\t}",
        "explanations_by_ours": [
            "the rloet",
            "rloet",
            "the rloet."
        ],
        "corrections_by_ours": [],
        "corrections_by_baseline": [
            "rhop",
            "hrsi",
            "rgp",
            "rp",
            "rdr",
            "ihr",
            "dsr",
            "qr",
            "drq",
            "hf"
        ]
    },
    {
        "original_word": "Length",
        "typo_word": "Ldngty",
        "original_variable": "contentLength",
        "typo_variable": "contentLdngty",
        "original_code": "public InputStream getInputStream() throws IOException {\n        if (is != null)\n            return is;\n        sendRequest();\n        String transferEncoding = responseHeader.getFieldValue(\"Transfer-Encoding\"); //$NON-NLS-1$\n        String contentLength = responseHeader.getFieldValue(\"Content-Length\"); //$NON-NLS-1$\n        if (\"chunked\".equalsIgnoreCase(transferEncoding)) { //$NON-NLS-1$\n            is = new ChunkedInputStream();\n        } else if (method.equals(\"HEAD\") && statusCode == HTTP_OK) { //$NON-NLS-1$\n            is = new LimitedInputStream(0);\n        } else if (contentLength != null) {\n            try {\n                is = new LimitedInputStream(Integer.parseInt(contentLength));\n            } catch (NumberFormatException e) {\n                throw new IOException(e.getMessage());\n            }\n        } else if ((statusCode >= 100 && statusCode < 200) || statusCode == HTTP_NO_CONTENT || statusCode == HTTP_NOT_MODIFIED) {\n            is = new LimitedInputStream(0);\n        } else {\n            closeConnection = true;\n            is = socketIn;\n        }\n        return is;\n    }",
        "modified_code": "public InputStream getInputStream() throws IOException {\n        if (is != null)\n            return is;\n        sendRequest();\n        String transferEncoding = responseHeader.getFieldValue(\"Transfer-Encoding\"); //$NON-NLS-1$\n        String contentLdngty = responseHeader.getFieldValue(\"Content-Length\"); //$NON-NLS-1$\n        if (\"chunked\".equalsIgnoreCase(transferEncoding)) { //$NON-NLS-1$\n            is = new ChunkedInputStream();\n        } else if (method.equals(\"HEAD\") && statusCode == HTTP_OK) { //$NON-NLS-1$\n            is = new LimitedInputStream(0);\n        } else if (contentLdngty != null) {\n            try {\n                is = new LimitedInputStream(Integer.parseInt(contentLdngty));\n            } catch (NumberFormatException e) {\n                throw new IOException(e.getMessage());\n            }\n        } else if ((statusCode >= 100 && statusCode < 200) || statusCode == HTTP_NO_CONTENT || statusCode == HTTP_NOT_MODIFIED) {\n            is = new LimitedInputStream(0);\n        } else {\n            closeConnection = true;\n            is = socketIn;\n        }\n        return is;\n    }",
        "explanations_by_ours": [
            "the content length in bytes.",
            "the content length.",
            "the length of the content in bytes."
        ],
        "corrections_by_ours": [
            "contentLength",
            "bytesLdngty",
            "lengthLdngty",
            "contentContent",
            "contentBytes",
            "contentLdngty"
        ],
        "corrections_by_baseline": [
            "D_CONTENT",
            "Q_CONTENT",
            "content",
            "contentPane",
            "LOCAL_PART_Q_CONTENT",
            "subContent",
            "soapBodyContent",
            "contentBlock",
            "contentResource",
            "resourceContent"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nanf",
        "original_variable": "fName",
        "typo_variable": "fNanf",
        "original_code": "private boolean popFile() throws JasperException {\n\n\t// Is stack created ? (will happen if the Jsp file we're looking at is\n\t// missing.\n\tif (current == null || currFileId < 0) {\n\t    return false;\n\t}\n\n\t// Restore parser state:\n\tString fName = getFile(currFileId);\n\tcurrFileId = unregisterSourceFile(fName);\n\tif (currFileId < -1) {\n\t    err.jspError(\"jsp.error.file.not.registered\", fName);\n\t}\n\n\tMark previous = current.popStream();\n\tif (previous != null) {\n\t    master = current.baseDir;\n\t    current = previous;\n\t    return true;\n\t}\n\t// Note that although the current file is undefined here, \"current\"\n\t// is not set to null just for convience, for it maybe used to\n\t// set the current (undefined) position.\n\treturn false;\n    }",
        "modified_code": "private boolean popFile() throws JasperException {\n\n\t// Is stack created ? (will happen if the Jsp file we're looking at is\n\t// missing.\n\tif (current == null || currFileId < 0) {\n\t    return false;\n\t}\n\n\t// Restore parser state:\n\tString fNanf = getFile(currFileId);\n\tcurrFileId = unregisterSourceFile(fNanf);\n\tif (currFileId < -1) {\n\t    err.jspError(\"jsp.error.file.not.registered\", fNanf);\n\t}\n\n\tMark previous = current.popStream();\n\tif (previous != null) {\n\t    master = current.baseDir;\n\t    current = previous;\n\t    return true;\n\t}\n\t// Note that although the current file is undefined here, \"current\"\n\t// is not set to null just for convience, for it maybe used to\n\t// set the current (undefined) position.\n\treturn false;\n    }",
        "explanations_by_ours": [
            "the name of the file we're popping from the stack.",
            "the name of the file to pop.",
            "The name of the file to pop."
        ],
        "corrections_by_ours": [
            "fName",
            "fileNanfile",
            "fStack",
            "fPopping",
            "we'reNanwe're",
            "nameNanname",
            "poppingNanpopping",
            "popNanpop",
            "stackNanstack",
            "fWe're"
        ],
        "corrections_by_baseline": [
            "fval",
            "nanos",
            "absZ",
            "fxy",
            "sigmaVal",
            "f0",
            "tfrac",
            "fxyS",
            "inf",
            "fff"
        ]
    },
    {
        "original_word": "Value",
        "typo_word": "Valkf",
        "original_variable": "acceptLicenseMapValue",
        "typo_variable": "acceptLicenseMapValkf",
        "original_code": "@SuppressWarnings(\"unchecked\")\n    public void installFeatures(boolean isAcceptLicense, List<String> featuresToInstall) throws PluginExecutionException {\n        List<File> jsonRepos = new ArrayList<File>(downloadedJsons);\n        debug(\"JSON repos: \" + jsonRepos);\n        info(\"Installing features: \" + featuresToInstall);\n        \n        // override license acceptance if installing only Open Liberty features\n        boolean acceptLicenseMapValue = isOnlyOpenLibertyFeatures(featuresToInstall) ? true : isAcceptLicense;\n\n        try {\n            Map<String, Object> mapBasedInstallKernel = createMapBasedInstallKernelInstance(installDirectory);\n            mapBasedInstallKernel.put(\"install.local.esa\", true);\n            mapBasedInstallKernel.put(\"single.json.file\", jsonRepos);\n            mapBasedInstallKernel.put(\"features.to.resolve\", featuresToInstall);\n            mapBasedInstallKernel.put(\"license.accept\", acceptLicenseMapValue);\n\n            if (isDebugEnabled()) {\n                mapBasedInstallKernel.put(\"debug\", Level.FINEST);\n            }\n\n            Collection<?> resolvedFeatures = (Collection<?>) mapBasedInstallKernel.get(\"action.result\");\n            if (resolvedFeatures == null) {\n                debug(\"action.exception.stacktrace: \"+mapBasedInstallKernel.get(\"action.exception.stacktrace\"));\n                String exceptionMessage = (String) mapBasedInstallKernel.get(\"action.error.message\");\n                throw new PluginExecutionException(exceptionMessage);\n            } else if (resolvedFeatures.isEmpty()) {\n                debug(\"action.exception.stacktrace: \"+mapBasedInstallKernel.get(\"action.exception.stacktrace\"));\n                String exceptionMessage = (String) mapBasedInstallKernel.get(\"action.error.message\");\n                if (exceptionMessage == null) {\n                    debug(\"resolvedFeatures was empty but the install kernel did not issue any messages\");\n                    info(\"The features are already installed, so no action is needed.\");\n                    return;\n                } else if (exceptionMessage.contains(\"CWWKF1250I\")) {\n                    info(exceptionMessage);\n                    info(\"The features are already installed, so no action is needed.\");\n                    return;\n                } else {\n                    throw new PluginExecutionException(exceptionMessage);\n                }\n            }\n            Collection<File> artifacts = downloadEsas(resolvedFeatures);\n\n            StringBuilder installedFeaturesBuilder = new StringBuilder();\n            Collection<String> actionReturnResult = new ArrayList<String>();\n            for (File esaFile: artifacts ){\n                mapBasedInstallKernel.put(\"license.accept\", acceptLicenseMapValue);\n                mapBasedInstallKernel.put(\"action.install\", esaFile);\n                if (to != null) {\n                    mapBasedInstallKernel.put(\"to.extension\", to);\n                    debug(\"Installing to extension: \" + to);\n                }\n                Integer ac = (Integer) mapBasedInstallKernel.get(\"action.result\");\n                debug(\"action.result: \"+ac);\n                debug(\"action.error.message: \"+mapBasedInstallKernel.get(\"action.error.message\"));\n                if (mapBasedInstallKernel.get(\"action.error.message\") != null) {\n                    debug(\"action.exception.stacktrace: \"+mapBasedInstallKernel.get(\"action.exception.stacktrace\"));\n                    String exceptionMessage = (String) mapBasedInstallKernel.get(\"action.error.message\");\n                    debug(exceptionMessage);\n                    throw new PluginExecutionException(exceptionMessage);\n                } else if (mapBasedInstallKernel.get(\"action.install.result\") != null) {\n                    actionReturnResult.addAll((Collection<String>) mapBasedInstallKernel.get(\"action.install.result\"));\n                }\n            }\n            for (String installResult : actionReturnResult) {\n                installedFeaturesBuilder.append(installResult).append(\" \");\n            }\n            productInfoValidate();\n            info(\"The following features have been installed: \" + installedFeaturesBuilder.toString());\n        } catch (PrivilegedActionException e) {\n            throw new PluginExecutionException(\"Could not load the jar \" + installJarFile.getAbsolutePath(), e);\n        }\n    }",
        "modified_code": "@SuppressWarnings(\"unchecked\")\n    public void installFeatures(boolean isAcceptLicense, List<String> featuresToInstall) throws PluginExecutionException {\n        List<File> jsonRepos = new ArrayList<File>(downloadedJsons);\n        debug(\"JSON repos: \" + jsonRepos);\n        info(\"Installing features: \" + featuresToInstall);\n        \n        // override license acceptance if installing only Open Liberty features\n        boolean acceptLicenseMapValkf = isOnlyOpenLibertyFeatures(featuresToInstall) ? true : isAcceptLicense;\n\n        try {\n            Map<String, Object> mapBasedInstallKernel = createMapBasedInstallKernelInstance(installDirectory);\n            mapBasedInstallKernel.put(\"install.local.esa\", true);\n            mapBasedInstallKernel.put(\"single.json.file\", jsonRepos);\n            mapBasedInstallKernel.put(\"features.to.resolve\", featuresToInstall);\n            mapBasedInstallKernel.put(\"license.accept\", acceptLicenseMapValkf);\n\n            if (isDebugEnabled()) {\n                mapBasedInstallKernel.put(\"debug\", Level.FINEST);\n            }\n\n            Collection<?> resolvedFeatures = (Collection<?>) mapBasedInstallKernel.get(\"action.result\");\n            if (resolvedFeatures == null) {\n                debug(\"action.exception.stacktrace: \"+mapBasedInstallKernel.get(\"action.exception.stacktrace\"));\n                String exceptionMessage = (String) mapBasedInstallKernel.get(\"action.error.message\");\n                throw new PluginExecutionException(exceptionMessage);\n            } else if (resolvedFeatures.isEmpty()) {\n                debug(\"action.exception.stacktrace: \"+mapBasedInstallKernel.get(\"action.exception.stacktrace\"));\n                String exceptionMessage = (String) mapBasedInstallKernel.get(\"action.error.message\");\n                if (exceptionMessage == null) {\n                    debug(\"resolvedFeatures was empty but the install kernel did not issue any messages\");\n                    info(\"The features are already installed, so no action is needed.\");\n                    return;\n                } else if (exceptionMessage.contains(\"CWWKF1250I\")) {\n                    info(exceptionMessage);\n                    info(\"The features are already installed, so no action is needed.\");\n                    return;\n                } else {\n                    throw new PluginExecutionException(exceptionMessage);\n                }\n            }\n            Collection<File> artifacts = downloadEsas(resolvedFeatures);\n\n            StringBuilder installedFeaturesBuilder = new StringBuilder();\n            Collection<String> actionReturnResult = new ArrayList<String>();\n            for (File esaFile: artifacts ){\n                mapBasedInstallKernel.put(\"license.accept\", acceptLicenseMapValkf);\n                mapBasedInstallKernel.put(\"action.install\", esaFile);\n                if (to != null) {\n                    mapBasedInstallKernel.put(\"to.extension\", to);\n                    debug(\"Installing to extension: \" + to);\n                }\n                Integer ac = (Integer) mapBasedInstallKernel.get(\"action.result\");\n                debug(\"action.result: \"+ac);\n                debug(\"action.error.message: \"+mapBasedInstallKernel.get(\"action.error.message\"));\n                if (mapBasedInstallKernel.get(\"action.error.message\") != null) {\n                    debug(\"action.exception.stacktrace: \"+mapBasedInstallKernel.get(\"action.exception.stacktrace\"));\n                    String exceptionMessage = (String) mapBasedInstallKernel.get(\"action.error.message\");\n                    debug(exceptionMessage);\n                    throw new PluginExecutionException(exceptionMessage);\n                } else if (mapBasedInstallKernel.get(\"action.install.result\") != null) {\n                    actionReturnResult.addAll((Collection<String>) mapBasedInstallKernel.get(\"action.install.result\"));\n                }\n            }\n            for (String installResult : actionReturnResult) {\n                installedFeaturesBuilder.append(installResult).append(\" \");\n            }\n            productInfoValidate();\n            info(\"The following features have been installed: \" + installedFeaturesBuilder.toString());\n        } catch (PrivilegedActionException e) {\n            throw new PluginExecutionException(\"Could not load the jar \" + installJarFile.getAbsolutePath(), e);\n        }\n    }",
        "explanations_by_ours": [
            "true if the license should be accepted, false otherwise.",
            "true if the license should be accepted, false otherwise",
            "true if the license should be accepted, false if not."
        ],
        "corrections_by_ours": [
            "accepted,LicenseMapValkf",
            "acceptLicenseMapFalse",
            "acceptAccepted,MapValkf",
            "acceptOtherwiseMapValkf",
            "licenseLicenseMapValkf",
            "acceptFalseMapValkf",
            "acceptLicenseFalseValkf",
            "falseLicenseMapValkf",
            "trueLicenseMapValkf",
            "acceptTrueMapValkf"
        ],
        "corrections_by_baseline": [
            "acceptLicenseMapValue",
            "enableWebSecurityAttrMap",
            "mimeTypesMap",
            "claimNameToConverter",
            "CAP_DOMAIN_LITERAL_NO_CFWS",
            "ENABLE_SUBSTITUTOR_CONFIG_KEY",
            "acceptValue",
            "localVarAccept",
            "accept",
            "adaptiveRefPicMarkingModeFlag"
        ]
    },
    {
        "original_word": "Append",
        "typo_word": "Aplene",
        "original_variable": "toAppend",
        "typo_variable": "toAplene",
        "original_code": "protected void leaveFunctor(Functor functor)\n    {\n        String toAppend = indent;\n        boolean addData = false;\n\n        if (functor.isCompound())\n        {\n            toAppend += \")\";\n            addData = true;\n        }\n\n        if (!traverser.isInHead() && !traverser.isLastBodyFunctor() && traverser.isTopLevel())\n        {\n            toAppend += \",\";\n            addData = true;\n        }\n\n        if (traverser.isInHead() && traverser.isTopLevel())\n        {\n            toAppend += \" :-\";\n            addData = true;\n        }\n\n        if (addData)\n        {\n            addLineToRow(toAppend);\n            nextRow();\n        }\n\n        indent = indenter.generateTraceIndent(-indenter.getLastDelta());\n    }",
        "modified_code": "protected void leaveFunctor(Functor functor)\n    {\n        String toAplene = indent;\n        boolean addData = false;\n\n        if (functor.isCompound())\n        {\n            toAplene += \")\";\n            addData = true;\n        }\n\n        if (!traverser.isInHead() && !traverser.isLastBodyFunctor() && traverser.isTopLevel())\n        {\n            toAplene += \",\";\n            addData = true;\n        }\n\n        if (traverser.isInHead() && traverser.isTopLevel())\n        {\n            toAplene += \" :-\";\n            addData = true;\n        }\n\n        if (addData)\n        {\n            addLineToRow(toAplene);\n            nextRow();\n        }\n\n        indent = indenter.generateTraceIndent(-indenter.getLastDelta());\n    }",
        "explanations_by_ours": [
            "the string to add to the output",
            "the output of the functor",
            "the string to add to the indentation"
        ],
        "corrections_by_ours": [
            "functorAplene",
            "indentationAplene",
            "toIndentation",
            "stringAplene",
            "outputAplene",
            "toString",
            "toAdd",
            "addAplene",
            "toFunctor",
            "toOutput"
        ],
        "corrections_by_baseline": [
            "toCoord",
            "nexte",
            "toStructure",
            "toX",
            "prelen",
            "toString",
            "ipage",
            "toIds",
            "toVertex",
            "plon"
        ]
    },
    {
        "original_word": "first",
        "typo_word": "bjrst",
        "original_variable": "first",
        "typo_variable": "bjrst",
        "original_code": "public void printConstraint(PrintWriter os)\n    {\n        os.print(function.getName()+\"(\");\n        Iterator it = children.iterator();\n\tboolean first = true;\n        while (it.hasNext()) {\n\t    ValueClause vc = (ValueClause)it.next();\n            if(!first) os.print(\",\");\n\t    vc.printConstraint(os);\n\t    first = false;\n        }\n        os.print(\")\");\n    }",
        "modified_code": "public void printConstraint(PrintWriter os)\n    {\n        os.print(function.getName()+\"(\");\n        Iterator it = children.iterator();\n\tboolean bjrst = true;\n        while (it.hasNext()) {\n\t    ValueClause vc = (ValueClause)it.next();\n            if(!bjrst) os.print(\",\");\n\t    vc.printConstraint(os);\n\t    bjrst = false;\n        }\n        os.print(\")\");\n    }",
        "explanations_by_ours": [
            "true if the tree is a BJST, false otherwise.",
            "true if the tree is a BJST, false otherwise",
            "true if the tree is a BJST, false if it is"
        ],
        "corrections_by_ours": [
            "bjst,rst",
            "bjbjst,",
            "bjtrue",
            "bjtree",
            "bjotherwise",
            "bjfalse",
            "otherwiserst",
            "falserst",
            "truerst",
            "treerst"
        ],
        "corrections_by_baseline": [
            "stp",
            "rdr",
            "stm",
            "estr",
            "stopper",
            "stn",
            "st",
            "drq",
            "gmst",
            "stnm"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rfsulf",
        "original_variable": "result",
        "typo_variable": "rfsulf",
        "original_code": "private static ConnectionFactoryAttribute[] define(ConnectionFactoryAttribute[] specific, ConnectionFactoryAttribute... common) {\n        int size = common.length + specific.length;\n        ConnectionFactoryAttribute[] result = new ConnectionFactoryAttribute[size];\n        arraycopy(specific, 0, result, 0, specific.length);\n        for (int i = 0; i < common.length; i++) {\n            ConnectionFactoryAttribute attr = common[i];\n            AttributeDefinition definition = attr.getDefinition();\n\n            ConnectionFactoryAttribute newAttr;\n            // replace the reconnect-attempts attribute to use a different default value for pooled CF\n            if (definition == Common.RECONNECT_ATTEMPTS) {\n                AttributeDefinition copy = copy(Pooled.RECONNECT_ATTEMPTS, AttributeAccess.Flag.RESTART_ALL_SERVICES);\n                newAttr = ConnectionFactoryAttribute.create(copy, Pooled.RECONNECT_ATTEMPTS_PROP_NAME, true);\n            } else {\n                AttributeDefinition copy = copy(definition, AttributeAccess.Flag.RESTART_ALL_SERVICES);\n                newAttr = ConnectionFactoryAttribute.create(copy, attr.getPropertyName(), attr.isResourceAdapterProperty(), attr.isInboundConfig());\n            }\n            result[specific.length + i] = newAttr;\n        }\n        return result;\n    }",
        "modified_code": "private static ConnectionFactoryAttribute[] define(ConnectionFactoryAttribute[] specific, ConnectionFactoryAttribute... common) {\n        int size = common.length + specific.length;\n        ConnectionFactoryAttribute[] rfsulf = new ConnectionFactoryAttribute[size];\n        arraycopy(specific, 0, rfsulf, 0, specific.length);\n        for (int i = 0; i < common.length; i++) {\n            ConnectionFactoryAttribute attr = common[i];\n            AttributeDefinition definition = attr.getDefinition();\n\n            ConnectionFactoryAttribute newAttr;\n            // replace the reconnect-attempts attribute to use a different default value for pooled CF\n            if (definition == Common.RECONNECT_ATTEMPTS) {\n                AttributeDefinition copy = copy(Pooled.RECONNECT_ATTEMPTS, AttributeAccess.Flag.RESTART_ALL_SERVICES);\n                newAttr = ConnectionFactoryAttribute.create(copy, Pooled.RECONNECT_ATTEMPTS_PROP_NAME, true);\n            } else {\n                AttributeDefinition copy = copy(definition, AttributeAccess.Flag.RESTART_ALL_SERVICES);\n                newAttr = ConnectionFactoryAttribute.create(copy, attr.getPropertyName(), attr.isResourceAdapterProperty(), attr.isInboundConfig());\n            }\n            rfsulf[specific.length + i] = newAttr;\n        }\n        return rfsulf;\n    }",
        "explanations_by_ours": [
            "The new array of ConnectionFactoryAttribute objects.",
            "the new array of ConnectionFactoryAttribute objects.",
            "The new array of ConnectionFactoryAttribute objects"
        ],
        "corrections_by_ours": [
            "attribute",
            "factory",
            "new",
            "array",
            "connection",
            "objects"
        ],
        "corrections_by_baseline": [
            "bsf",
            "rsf",
            "mefd",
            "rp",
            "hf",
            "xfac",
            "baf",
            "rgp",
            "ftrm",
            "mf"
        ]
    },
    {
        "original_word": "Type",
        "typo_word": "Tyow",
        "original_variable": "elemType",
        "typo_variable": "elemTyow",
        "original_code": "private void checkScriptingBody(Node.ScriptingElement scriptingElem)\n        throws SAXException {\n        Node.Nodes body = scriptingElem.getBody();\n        if (body != null) {\n            int size = body.size();\n            for (int i = 0; i < size; i++) {\n                Node n = body.getNode(i);\n                if (!(n instanceof Node.TemplateText)) {\n                    String elemType = SCRIPTLET_ACTION;\n                    if (scriptingElem instanceof Node.Declaration)\n                        elemType = DECLARATION_ACTION;\n                    if (scriptingElem instanceof Node.Expression)\n                        elemType = EXPRESSION_ACTION;\n                    String msg =\n                        Localizer.getMessage(\n                            \"jsp.error.parse.xml.scripting.invalid.body\",\n                            elemType);\n                    throw new SAXException(msg);\n                }\n            }\n        }\n    }",
        "modified_code": "private void checkScriptingBody(Node.ScriptingElement scriptingElem)\n        throws SAXException {\n        Node.Nodes body = scriptingElem.getBody();\n        if (body != null) {\n            int size = body.size();\n            for (int i = 0; i < size; i++) {\n                Node n = body.getNode(i);\n                if (!(n instanceof Node.TemplateText)) {\n                    String elemTyow = SCRIPTLET_ACTION;\n                    if (scriptingElem instanceof Node.Declaration)\n                        elemTyow = DECLARATION_ACTION;\n                    if (scriptingElem instanceof Node.Expression)\n                        elemTyow = EXPRESSION_ACTION;\n                    String msg =\n                        Localizer.getMessage(\n                            \"jsp.error.parse.xml.scripting.invalid.body\",\n                            elemTyow);\n                    throw new SAXException(msg);\n                }\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the type of the scripting element",
            "the element type",
            "the type of scripting element"
        ],
        "corrections_by_ours": [
            "elementTyow",
            "elemTypeyow",
            "elemTtype",
            "elemElementyow",
            "elemScriptingyow",
            "typeTyow",
            "scriptingTyow",
            "elemTscripting",
            "elemTelement",
            "elemTyow"
        ],
        "corrections_by_baseline": [
            "elemType",
            "elem",
            "vcElem",
            "typeElem",
            "memberMXBean",
            "dsfElem",
            "varElem",
            "ppElem",
            "tmElem",
            "vertElem"
        ]
    },
    {
        "original_word": "attempts",
        "typo_word": "athemots",
        "original_variable": "attempts",
        "typo_variable": "athemots",
        "original_code": "public void close() {\n    int attempts = 0;\n\n    while (true) {\n      try {\n        acquireWriteLock();\n        try {\n          if (channel != null && channel.isOpen()) {\n            channel.close();\n            channel = null;\n          }\n\n          if (frnd != null) {\n            frnd.close();\n            frnd = null;\n          }\n\n          closeFD();\n        } finally {\n          releaseWriteLock();\n          attempts++;\n        }\n\n        releaseExclusiveAccess();\n        break;\n      } catch (final IOException ioe) {\n        OLogManager.instance().error(this, \"Error during closing of file '\" + getName() + \"' \" + attempts + \"-th attempt\", ioe);\n\n        try {\n          reopenFile(attempts, ioe);\n        } catch (final IOException e) {\n          throw OException.wrapException(new OIOException(\"Error during file close\"), e);\n        }\n      }\n    }\n\n  }",
        "modified_code": "public void close() {\n    int athemots = 0;\n\n    while (true) {\n      try {\n        acquireWriteLock();\n        try {\n          if (channel != null && channel.isOpen()) {\n            channel.close();\n            channel = null;\n          }\n\n          if (frnd != null) {\n            frnd.close();\n            frnd = null;\n          }\n\n          closeFD();\n        } finally {\n          releaseWriteLock();\n          athemots++;\n        }\n\n        releaseExclusiveAccess();\n        break;\n      } catch (final IOException ioe) {\n        OLogManager.instance().error(this, \"Error during closing of file '\" + getName() + \"' \" + athemots + \"-th attempt\", ioe);\n\n        try {\n          reopenFile(athemots, ioe);\n        } catch (final IOException e) {\n          throw OException.wrapException(new OIOException(\"Error during file close\"), e);\n        }\n      }\n    }\n\n  }",
        "explanations_by_ours": [
            "The number of attempts to reopen the file",
            "Number of attempts to reopen the file",
            "The number of attempts to reopen the file."
        ],
        "corrections_by_ours": [
            "attempts",
            "reopen",
            "file",
            "number"
        ],
        "corrections_by_baseline": [
            "otps",
            "halLinks",
            "taps",
            "links",
            "urls",
            "swaths",
            "paths",
            "resourceURLs",
            "automats",
            "raLinks"
        ]
    },
    {
        "original_word": "actual",
        "typo_word": "astjal",
        "original_variable": "actual",
        "typo_variable": "astjal",
        "original_code": "public int\n    read(byte[] buf, int off, int len)\n            throws IOException\n    {\n        // Sanity check\n        if(off < 0 || len < 0)\n            throw new IndexOutOfBoundsException();// Runtime\n        if(off >= buf.length || buf.length < (off + len))\n            throw new IndexOutOfBoundsException(); //Runtime\n        if(requestmode == RequestMode.DMR)\n            throw new UnsupportedOperationException(\"Attempt to read databuffer when DMR only\"); // Runtime\n\n        // Attempt to read len bytes out of a sequence of chunks\n        int count = len;\n        int pos = off;\n        while(count > 0) {\n            if(avail <= 0) {\n                if((flags & DapUtil.CHUNK_END) != 0\n                        || !readHeader(input))\n                    return (len - count); // return # databuffer read\n                // See if we have an error chunk,\n                // and if so, turn it into an exception\n                if((flags & DapUtil.CHUNK_ERROR) != 0) {\n                    String document = readError();\n                    throwError(document);\n                }\n            } else {\n                int actual = (this.avail < count ? this.avail : count);\n                int red = input.read(buf, pos, actual);\n                if(red < 0)\n                    throw new IOException(\"Unexpected EOF\");\n                pos += red;\n                count -= red;\n                this.avail -= red;\n            }\n        }\n        return len;\n    }",
        "modified_code": "public int\n    read(byte[] buf, int off, int len)\n            throws IOException\n    {\n        // Sanity check\n        if(off < 0 || len < 0)\n            throw new IndexOutOfBoundsException();// Runtime\n        if(off >= buf.length || buf.length < (off + len))\n            throw new IndexOutOfBoundsException(); //Runtime\n        if(requestmode == RequestMode.DMR)\n            throw new UnsupportedOperationException(\"Attempt to read databuffer when DMR only\"); // Runtime\n\n        // Attempt to read len bytes out of a sequence of chunks\n        int count = len;\n        int pos = off;\n        while(count > 0) {\n            if(avail <= 0) {\n                if((flags & DapUtil.CHUNK_END) != 0\n                        || !readHeader(input))\n                    return (len - count); // return # databuffer read\n                // See if we have an error chunk,\n                // and if so, turn it into an exception\n                if((flags & DapUtil.CHUNK_ERROR) != 0) {\n                    String document = readError();\n                    throwError(document);\n                }\n            } else {\n                int astjal = (this.avail < count ? this.avail : count);\n                int red = input.read(buf, pos, astjal);\n                if(red < 0)\n                    throw new IOException(\"Unexpected EOF\");\n                pos += red;\n                count -= red;\n                this.avail -= red;\n            }\n        }\n        return len;\n    }",
        "explanations_by_ours": [
            "the number of bytes to read.",
            "the number of bytes to read",
            "the maximum number of bytes to read."
        ],
        "corrections_by_ours": [
            "bytes",
            "read",
            "maximum",
            "number"
        ],
        "corrections_by_baseline": [
            "rj",
            "adz",
            "anal",
            "jbeg",
            "orishape",
            "conj",
            "nelems",
            "hysteresis",
            "p_alp",
            "odom"
        ]
    },
    {
        "original_word": "Keys",
        "typo_word": "Kfts",
        "original_variable": "regionKeys",
        "typo_variable": "regionKfts",
        "original_code": "public <K,V> Map<K,V> readResultsByPage(TextPageCriteria criteria, int pageNumber, Region<K,V> region, Region<String,Collection<?>> pageRegion)\n\t{\n\t\tif(pageRegion == null )\n\t\t\treturn null;\n\t\t\n\t\tCollection<?> regionKeys = pageRegion.get(criteria.toPageKey(pageNumber));\n\t\t\n\t\tif(regionKeys == null|| regionKeys.isEmpty())\n\t\t\treturn null;\n\t\t\n\t\treturn region.getAll(regionKeys);\n\t}",
        "modified_code": "public <K,V> Map<K,V> readResultsByPage(TextPageCriteria criteria, int pageNumber, Region<K,V> region, Region<String,Collection<?>> pageRegion)\n\t{\n\t\tif(pageRegion == null )\n\t\t\treturn null;\n\t\t\n\t\tCollection<?> regionKfts = pageRegion.get(criteria.toPageKey(pageNumber));\n\t\t\n\t\tif(regionKfts == null|| regionKfts.isEmpty())\n\t\t\treturn null;\n\t\t\n\t\treturn region.getAll(regionKfts);\n\t}",
        "explanations_by_ours": [
            "the key-value pairs of the region.",
            "the key-value pairs of the region",
            "the keys of the region to read."
        ],
        "corrections_by_ours": [
            "readKfts",
            "regionKeyfts",
            "regionKeysfts",
            "regionKkeys",
            "regionKpairs",
            "keysKfts",
            "keyKfts",
            "pairsKfts",
            "-Kfts",
            "valueKfts"
        ],
        "corrections_by_baseline": [
            "regionKeys",
            "numRegions",
            "region",
            "fts",
            "regionSet",
            "regionJmxPattern",
            "zps",
            "insets",
            "featList",
            "gemRegion"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "coiny",
        "original_variable": "count",
        "typo_variable": "coiny",
        "original_code": "public void externalize(DataOutputStream sink, int start, int stop, int stride) throws IOException {\r\n        int count = 0;\r\n        for (int i = start; i <= stop; i += stride) {\r\n            sink.writeByte(vals[i]);\r\n            count++;\r\n        }\r\n\r\n        // pad out to a multiple of four bytes\r\n        int modFour = count % 4;\r\n        int pad = (modFour != 0) ? (4 - modFour) : 0;\r\n        for (int i = 0; i < pad; i++)\r\n            sink.writeByte(0);\r\n    }",
        "modified_code": "public void externalize(DataOutputStream sink, int start, int stop, int stride) throws IOException {\r\n        int coiny = 0;\r\n        for (int i = start; i <= stop; i += stride) {\r\n            sink.writeByte(vals[i]);\r\n            coiny++;\r\n        }\r\n\r\n        // pad out to a multiple of four bytes\r\n        int modFour = coiny % 4;\r\n        int pad = (modFour != 0) ? (4 - modFour) : 0;\r\n        for (int i = 0; i < pad; i++)\r\n            sink.writeByte(0);\r\n    }",
        "explanations_by_ours": [
            "the number of bytes to write",
            "the number of bytes to write in the data stream",
            "the total number of bytes to write"
        ],
        "corrections_by_ours": [
            "write",
            "total",
            "data",
            "bytes",
            "stream",
            "number"
        ],
        "corrections_by_baseline": [
            "co",
            "pco",
            "sco",
            "qco",
            "utco",
            "caco",
            "LULC",
            "cy",
            "CY",
            "coef"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "desulf",
        "original_variable": "result",
        "typo_variable": "desulf",
        "original_code": "public static String arrayToList(String[] array, String delim)\n    {\n        String result = \"\";\n\n        for (int i = 0; i < array.length; i++)\n        {\n            result += array[i] + ((i == (array.length - 1)) ? \"\" : delim);\n        }\n\n        return result;\n    }",
        "modified_code": "public static String arrayToList(String[] array, String delim)\n    {\n        String desulf = \"\";\n\n        for (int i = 0; i < array.length; i++)\n        {\n            desulf += array[i] + ((i == (array.length - 1)) ? \"\" : delim);\n        }\n\n        return desulf;\n    }",
        "explanations_by_ours": [
            "the string to desulf",
            "the string to deselect",
            "the desulf string"
        ],
        "corrections_by_ours": [
            "deselect",
            "string"
        ],
        "corrections_by_baseline": [
            "des",
            "deref",
            "dec",
            "difmin",
            "baf",
            "dely",
            "enc",
            "bis",
            "decrypted",
            "dou"
        ]
    },
    {
        "original_word": "type",
        "typo_word": "hyle",
        "original_variable": "locktype",
        "typo_variable": "lockhyle",
        "original_code": "public static LockInfo create(Document document) {\n        Assert.isNotNull(document);\n        Assert.isTrue(document.getOwnerDocument() == null);\n        Element element = create(document, \"lockinfo\"); //$NON-NLS-1$\n        Element locktype = appendChild(element, \"locktype\"); //$NON-NLS-1$\n        appendChild(locktype, \"write\"); //$NON-NLS-1$\n        LockInfo result = null;\n        try {\n            result = new LockInfo(element);\n        } catch (MalformedElementException e) {\n            Assert.isTrue(false, Policy.bind(\"assert.internalError\")); //$NON-NLS-1$\n        }\n        return result;\n    }",
        "modified_code": "public static LockInfo create(Document document) {\n        Assert.isNotNull(document);\n        Assert.isTrue(document.getOwnerDocument() == null);\n        Element element = create(document, \"lockinfo\"); //$NON-NLS-1$\n        Element lockhyle = appendChild(element, \"locktype\"); //$NON-NLS-1$\n        appendChild(lockhyle, \"write\"); //$NON-NLS-1$\n        LockInfo result = null;\n        try {\n            result = new LockInfo(element);\n        } catch (MalformedElementException e) {\n            Assert.isTrue(false, Policy.bind(\"assert.internalError\")); //$NON-NLS-1$\n        }\n        return result;\n    }",
        "explanations_by_ours": [
            "the Element containing the lock style",
            "the Element for the lock style",
            "the Element containing the lock style."
        ],
        "corrections_by_ours": [
            "lockstyle",
            "elementhyle",
            "lockelement",
            "containinghyle",
            "stylehyle",
            "lockcontaining",
            "locklock",
            "lockhyle"
        ],
        "corrections_by_baseline": [
            "locking",
            "lock",
            "locktype",
            "lockHolder",
            "lockStrategy",
            "lockentry",
            "lockinfo",
            "lockscope",
            "activelock",
            "fileLock"
        ]
    },
    {
        "original_word": "first",
        "typo_word": "fkest",
        "original_variable": "first",
        "typo_variable": "fkest",
        "original_code": "public String toConstraintString()\n    {\n        StringBuilder buf = new StringBuilder();\n        boolean first = true;\n        for(int i = 0; i < segments.size(); i++) {\n            Segment seg = segments.get(i);\n            if(!seg.var.isTopLevel())\n                continue;\n            if(!first) buf.append(\";\");\n            first = false;\n            dumpvar(seg, buf, true);\n        }\n        return buf.toString();\n    }",
        "modified_code": "public String toConstraintString()\n    {\n        StringBuilder buf = new StringBuilder();\n        boolean fkest = true;\n        for(int i = 0; i < segments.size(); i++) {\n            Segment seg = segments.get(i);\n            if(!seg.var.isTopLevel())\n                continue;\n            if(!fkest) buf.append(\";\");\n            fkest = false;\n            dumpvar(seg, buf, true);\n        }\n        return buf.toString();\n    }",
        "explanations_by_ours": [
            "true if this constraint is a top-level constraint",
            "true if this constraint is a top level constraint",
            "true if this constraint is a top-level constraint."
        ],
        "corrections_by_ours": [
            "fkconstraint",
            "fklevel",
            "-est",
            "constraintest",
            "levelest",
            "topest",
            "trueest",
            "fk-",
            "fktop",
            "fktrue"
        ],
        "corrections_by_baseline": [
            "kf",
            "bk",
            "pk1h",
            "acf",
            "rcidpe",
            "ppk",
            "nest",
            "knt",
            "pce",
            "pki"
        ]
    },
    {
        "original_word": "Names",
        "typo_word": "Nqmez",
        "original_variable": "interfaceNames",
        "typo_variable": "interfaceNqmez",
        "original_code": "private Class<?>[] loadInterfaceClasses(Config descriptor) throws ConfigException {\r\n\t\tList<String> interfaceNames = new ArrayList<>();\r\n\r\n\t\tif (!descriptor.hasChildren()) {\r\n\t\t\tif (!descriptor.hasAttribute(\"interface\")) {\r\n\t\t\t\tif (instanceType.requiresInterface()) {\r\n\t\t\t\t\tthrow new ConfigException(\"Managed type |%s| requires <interface> attribute. See class descriptor |%s|.\", instanceType, descriptor);\r\n\t\t\t\t}\r\n\t\t\t\t// if interface is not required and is missing uses implementation class\r\n\t\t\t\treturn new Class<?>[] { implementationClass };\r\n\t\t\t}\r\n\t\t\tinterfaceNames.add(descriptor.getAttribute(\"interface\"));\r\n\r\n\t\t\tif (\"REMOTE\".equals(descriptor.getAttribute(\"type\"))) {\r\n\t\t\t\tString url = descriptor.getAttribute(\"url\");\r\n\t\t\t\tif (url == null || url.isEmpty()) {\r\n\t\t\t\t\tthrow new ConfigException(\"Managed type REMOTE requires <url> attribute. See class descriptor |%s|.\", descriptor);\r\n\t\t\t\t}\r\n\t\t\t\tif (url.startsWith(\"${\")) {\r\n\t\t\t\t\tthrow new ConfigException(\"Remote implementation <url> property not resolved. See class descriptor |%s|.\", descriptor);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tfor (int i = 0; i < descriptor.getChildrenCount(); ++i) {\r\n\t\t\t\tString interfaceName = descriptor.getChild(i).getAttribute(\"name\");\r\n\t\t\t\tif (interfaceName == null) {\r\n\t\t\t\t\tthrow new ConfigException(\"Missing <name> attribute from interface declaration. See class descriptor |%s|.\", descriptor);\r\n\t\t\t\t}\r\n\t\t\t\tinterfaceNames.add(interfaceName);\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tClass<?>[] interfaceClasses = new Class<?>[interfaceNames.size()];\r\n\t\tfor (int i = 0; i < interfaceNames.size(); ++i) {\r\n\t\t\tfinal String interfaceName = interfaceNames.get(i);\r\n\t\t\tfinal Class<?> interfaceClass = Classes.forOptionalName(interfaceName);\r\n\r\n\t\t\tif (interfaceClass == null) {\r\n\t\t\t\tthrow new ConfigException(\"Managed class interface |%s| not found.\", interfaceName);\r\n\t\t\t}\r\n\t\t\tif (Types.isKindOf(interfaceClass, ManagedLifeCycle.class)) {\r\n\t\t\t\tautoInstanceCreation = true;\r\n\t\t\t}\r\n\t\t\tif (instanceType.requiresInterface() && !interfaceClass.isInterface()) {\r\n\t\t\t\tthrow new ConfigException(\"Managed type |%s| requires interface to make Java Proxy happy but got |%s|.\", instanceType, interfaceClass);\r\n\t\t\t}\r\n\t\t\tif (implementationClass != null && !Types.isKindOf(implementationClass, interfaceClass)) {\r\n\t\t\t\tthrow new ConfigException(\"Implementation |%s| is not a kind of interface |%s|.\", implementationClass, interfaceClass);\r\n\t\t\t}\r\n\r\n\t\t\tinterfaceClasses[i] = interfaceClass;\r\n\t\t}\r\n\t\treturn interfaceClasses;\r\n\t}",
        "modified_code": "private Class<?>[] loadInterfaceClasses(Config descriptor) throws ConfigException {\r\n\t\tList<String> interfaceNqmez = new ArrayList<>();\r\n\r\n\t\tif (!descriptor.hasChildren()) {\r\n\t\t\tif (!descriptor.hasAttribute(\"interface\")) {\r\n\t\t\t\tif (instanceType.requiresInterface()) {\r\n\t\t\t\t\tthrow new ConfigException(\"Managed type |%s| requires <interface> attribute. See class descriptor |%s|.\", instanceType, descriptor);\r\n\t\t\t\t}\r\n\t\t\t\t// if interface is not required and is missing uses implementation class\r\n\t\t\t\treturn new Class<?>[] { implementationClass };\r\n\t\t\t}\r\n\t\t\tinterfaceNqmez.add(descriptor.getAttribute(\"interface\"));\r\n\r\n\t\t\tif (\"REMOTE\".equals(descriptor.getAttribute(\"type\"))) {\r\n\t\t\t\tString url = descriptor.getAttribute(\"url\");\r\n\t\t\t\tif (url == null || url.isEmpty()) {\r\n\t\t\t\t\tthrow new ConfigException(\"Managed type REMOTE requires <url> attribute. See class descriptor |%s|.\", descriptor);\r\n\t\t\t\t}\r\n\t\t\t\tif (url.startsWith(\"${\")) {\r\n\t\t\t\t\tthrow new ConfigException(\"Remote implementation <url> property not resolved. See class descriptor |%s|.\", descriptor);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tfor (int i = 0; i < descriptor.getChildrenCount(); ++i) {\r\n\t\t\t\tString interfaceName = descriptor.getChild(i).getAttribute(\"name\");\r\n\t\t\t\tif (interfaceName == null) {\r\n\t\t\t\t\tthrow new ConfigException(\"Missing <name> attribute from interface declaration. See class descriptor |%s|.\", descriptor);\r\n\t\t\t\t}\r\n\t\t\t\tinterfaceNqmez.add(interfaceName);\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\tClass<?>[] interfaceClasses = new Class<?>[interfaceNqmez.size()];\r\n\t\tfor (int i = 0; i < interfaceNqmez.size(); ++i) {\r\n\t\t\tfinal String interfaceName = interfaceNqmez.get(i);\r\n\t\t\tfinal Class<?> interfaceClass = Classes.forOptionalName(interfaceName);\r\n\r\n\t\t\tif (interfaceClass == null) {\r\n\t\t\t\tthrow new ConfigException(\"Managed class interface |%s| not found.\", interfaceName);\r\n\t\t\t}\r\n\t\t\tif (Types.isKindOf(interfaceClass, ManagedLifeCycle.class)) {\r\n\t\t\t\tautoInstanceCreation = true;\r\n\t\t\t}\r\n\t\t\tif (instanceType.requiresInterface() && !interfaceClass.isInterface()) {\r\n\t\t\t\tthrow new ConfigException(\"Managed type |%s| requires interface to make Java Proxy happy but got |%s|.\", instanceType, interfaceClass);\r\n\t\t\t}\r\n\t\t\tif (implementationClass != null && !Types.isKindOf(implementationClass, interfaceClass)) {\r\n\t\t\t\tthrow new ConfigException(\"Implementation |%s| is not a kind of interface |%s|.\", implementationClass, interfaceClass);\r\n\t\t\t}\r\n\r\n\t\t\tinterfaceClasses[i] = interfaceClass;\r\n\t\t}\r\n\t\treturn interfaceClasses;\r\n\t}",
        "explanations_by_ours": [
            "List of interface names",
            "The interface names.",
            "List of interface names."
        ],
        "corrections_by_ours": [
            "interfaceNames",
            "namesNqmez",
            "listNqmez",
            "interfaceInterface",
            "interfaceList",
            "interfaceNqmez"
        ],
        "corrections_by_baseline": [
            "mSbbLocalInterface",
            "remoteInterface",
            "profileCMPInterface",
            "remoteInterfaceType",
            "mcpi",
            "inet",
            "findJmxPort",
            "strPort",
            "possibleInterfaces",
            "localInterface"
        ]
    },
    {
        "original_word": "total",
        "typo_word": "rotao",
        "original_variable": "total",
        "typo_variable": "rotao",
        "original_code": "protected void calcStats(double[] values) {\n      if (statsValid) {\n        return;\n      }\n      size = values.length;\n      if (size == 0) {\n        min = 0.0;\n        max = 0.0;\n        avg = 0.0;\n        stddev = 0.0;\n        mostRecent = 0.0;\n      } else {\n        min = values[0];\n        max = values[0];\n        mostRecent = values[values.length - 1];\n        double total = values[0];\n        for (int i = 1; i < size; i++) {\n          total += values[i];\n          if (values[i] < min) {\n            min = values[i];\n          } else if (values[i] > max) {\n            max = values[i];\n          }\n        }\n        avg = total / size;\n        stddev = 0.0;\n        if (size > 1) {\n          for (int i = 0; i < size; i++) {\n            double dv = values[i] - avg;\n            stddev += (dv * dv);\n          }\n          stddev /= (size - 1);\n          stddev = Math.sqrt(stddev);\n        }\n      }\n      statsValid = true;\n    }",
        "modified_code": "protected void calcStats(double[] values) {\n      if (statsValid) {\n        return;\n      }\n      size = values.length;\n      if (size == 0) {\n        min = 0.0;\n        max = 0.0;\n        avg = 0.0;\n        stddev = 0.0;\n        mostRecent = 0.0;\n      } else {\n        min = values[0];\n        max = values[0];\n        mostRecent = values[values.length - 1];\n        double rotao = values[0];\n        for (int i = 1; i < size; i++) {\n          rotao += values[i];\n          if (values[i] < min) {\n            min = values[i];\n          } else if (values[i] > max) {\n            max = values[i];\n          }\n        }\n        avg = rotao / size;\n        stddev = 0.0;\n        if (size > 1) {\n          for (int i = 0; i < size; i++) {\n            double dv = values[i] - avg;\n            stddev += (dv * dv);\n          }\n          stddev /= (size - 1);\n          stddev = Math.sqrt(stddev);\n        }\n      }\n      statsValid = true;\n    }",
        "explanations_by_ours": [
            "the rotao of the values",
            "the rotao value",
            "the rotao of the values."
        ],
        "corrections_by_ours": [
            "values",
            "value"
        ],
        "corrections_by_baseline": [
            "pao",
            "rotl",
            "po",
            "dpo",
            "utco",
            "dao",
            "Rotation",
            "rotr",
            "coord_sys",
            "rotateAf"
        ]
    },
    {
        "original_word": "spangle",
        "typo_word": "soangpe",
        "original_variable": "spangle",
        "typo_variable": "soangpe",
        "original_code": "private void makeRotatedLatLon(NetcdfFile ncfile) {\n\n    double splat = gds.getDouble(GridDefRecord.SPLAT);\n    double splon = gds.getDouble(GridDefRecord.SPLON);\n    double spangle = gds.getDouble(GridDefRecord.ROTATIONANGLE);\n\n    // Given projection coordinates, need LatLon coordinates\n    proj = new RotatedLatLon(splat, splon, spangle);\n    LatLonPoint startLL = proj.projToLatLon(\n        new ProjectionPointImpl(\n            gds.getDouble(GridDefRecord.LO1), gds.getDouble(GridDefRecord.LA1)));\n    startx = startLL.getLongitude();\n    starty = startLL.getLatitude();\n    addCoordSystemVariable(ncfile, \"latLonCoordSys\", \"time y x\");\n\n    // splat, splon, spangle\n    attributes.add(new Attribute(GridCF.GRID_MAPPING_NAME, \"rotated_latlon_grib\"));\n    attributes.add(new Attribute(\"grid_south_pole_latitude\", splat));\n    attributes.add(new Attribute(\"grid_south_pole_longitude\", splon));\n    attributes.add(new Attribute(\"grid_south_pole_angle\", spangle));\n\n    if (GridServiceProvider.debugProj) {\n      System.out.println(\"Location of pole of rotated grid:\");\n      System.out.println(\"Lon=\" + splon + \", Lat=\" + splat);\n      System.out.println(\"Axial rotation about pole of rotated grid:\" + spangle);\n\n      System.out.println(\"Location of LL in rotated grid:\");\n      System.out.println(\"Lon=\" + gds.getDouble(GridDefRecord.LO1) + \", \" +\n          \"Lat=\" + gds.getDouble(GridDefRecord.LA1));\n      System.out.println(\"Location of LL in non-rotated grid:\");\n      System.out.println(\"Lon=\" + startx + \", Lat=\" + starty);\n\n      double Lo2 = gds.getDouble(GridDefRecord.LO2);\n      double La2 = gds.getDouble(GridDefRecord.LA2);\n      System.out.println(\"Location of UR in rotated grid:\");\n      System.out.println(\"Lon=\" + Lo2 + \", Lat=\" + La2);\n      System.out.println(\"Location of UR in non-rotated grid:\");\n      LatLonPoint endUR = proj.projToLatLon(new ProjectionPointImpl(Lo2, La2));\n      System.out.println(\"Lon=\" + endUR.getLongitude() + \", Lat=\" + endUR.getLatitude());\n\n      double dy = (La2 < gds.getDouble(GridDefRecord.LA1)) ?\n          -gds.getDouble(GridDefRecord.DY) : gds.getDouble(GridDefRecord.DY);\n      double endx = gds.getDouble(GridDefRecord.LO1) + (getNx() - 1) * gds.getDouble(GridDefRecord.DX);\n      double endy = gds.getDouble(GridDefRecord.LA1) + (getNy() - 1) * dy;\n\n      System.out.println(\"End point rotated grid should be x=\" +\n          endx + \" y=\" + endy);\n    }\n  }",
        "modified_code": "private void makeRotatedLatLon(NetcdfFile ncfile) {\n\n    double splat = gds.getDouble(GridDefRecord.SPLAT);\n    double splon = gds.getDouble(GridDefRecord.SPLON);\n    double soangpe = gds.getDouble(GridDefRecord.ROTATIONANGLE);\n\n    // Given projection coordinates, need LatLon coordinates\n    proj = new RotatedLatLon(splat, splon, soangpe);\n    LatLonPoint startLL = proj.projToLatLon(\n        new ProjectionPointImpl(\n            gds.getDouble(GridDefRecord.LO1), gds.getDouble(GridDefRecord.LA1)));\n    startx = startLL.getLongitude();\n    starty = startLL.getLatitude();\n    addCoordSystemVariable(ncfile, \"latLonCoordSys\", \"time y x\");\n\n    // splat, splon, spangle\n    attributes.add(new Attribute(GridCF.GRID_MAPPING_NAME, \"rotated_latlon_grib\"));\n    attributes.add(new Attribute(\"grid_south_pole_latitude\", splat));\n    attributes.add(new Attribute(\"grid_south_pole_longitude\", splon));\n    attributes.add(new Attribute(\"grid_south_pole_angle\", soangpe));\n\n    if (GridServiceProvider.debugProj) {\n      System.out.println(\"Location of pole of rotated grid:\");\n      System.out.println(\"Lon=\" + splon + \", Lat=\" + splat);\n      System.out.println(\"Axial rotation about pole of rotated grid:\" + soangpe);\n\n      System.out.println(\"Location of LL in rotated grid:\");\n      System.out.println(\"Lon=\" + gds.getDouble(GridDefRecord.LO1) + \", \" +\n          \"Lat=\" + gds.getDouble(GridDefRecord.LA1));\n      System.out.println(\"Location of LL in non-rotated grid:\");\n      System.out.println(\"Lon=\" + startx + \", Lat=\" + starty);\n\n      double Lo2 = gds.getDouble(GridDefRecord.LO2);\n      double La2 = gds.getDouble(GridDefRecord.LA2);\n      System.out.println(\"Location of UR in rotated grid:\");\n      System.out.println(\"Lon=\" + Lo2 + \", Lat=\" + La2);\n      System.out.println(\"Location of UR in non-rotated grid:\");\n      LatLonPoint endUR = proj.projToLatLon(new ProjectionPointImpl(Lo2, La2));\n      System.out.println(\"Lon=\" + endUR.getLongitude() + \", Lat=\" + endUR.getLatitude());\n\n      double dy = (La2 < gds.getDouble(GridDefRecord.LA1)) ?\n          -gds.getDouble(GridDefRecord.DY) : gds.getDouble(GridDefRecord.DY);\n      double endx = gds.getDouble(GridDefRecord.LO1) + (getNx() - 1) * gds.getDouble(GridDefRecord.DX);\n      double endy = gds.getDouble(GridDefRecord.LA1) + (getNy() - 1) * dy;\n\n      System.out.println(\"End point rotated grid should be x=\" +\n          endx + \" y=\" + endy);\n    }\n  }",
        "explanations_by_ours": [
            "South-pole angle of the grid.",
            "South-pole angle in radians.",
            "South-pole angle of the grid"
        ],
        "corrections_by_ours": [
            "angle",
            "pole",
            "south",
            "-",
            "grid",
            "radians"
        ],
        "corrections_by_baseline": [
            "pe",
            "rcidpe",
            "iosp",
            "pce",
            "dpe",
            "cidpe",
            "geo",
            "psemi",
            "oe",
            "pco"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rrsuit",
        "original_variable": "result",
        "typo_variable": "rrsuit",
        "original_code": "public long getMiscTasksExecuted() {\n\t\tlong result = 0L;\n\t\tfor (int i = 0; i < getExecutors().length; i++) {\n\t\t\tresult += getMiscTasksExecuted(i);\t\t\t\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public long getMiscTasksExecuted() {\n\t\tlong rrsuit = 0L;\n\t\tfor (int i = 0; i < getExecutors().length; i++) {\n\t\t\trrsuit += getMiscTasksExecuted(i);\t\t\t\n\t\t}\n\t\treturn rrsuit;\n\t}",
        "explanations_by_ours": [
            "the number of tasks that were executed by all the executors.",
            "The number of tasks that were executed by all the executors.",
            "the number of tasks that were executed by all the executors"
        ],
        "corrections_by_ours": [
            "executorsuit",
            "tasksuit",
            "rrsnumber",
            "rrsexecuted",
            "rrsexecutors",
            "executeduit",
            "numberuit",
            "rrstasks",
            "rrsuit"
        ],
        "corrections_by_baseline": [
            "rr",
            "rrank",
            "ucum",
            "npe",
            "rcidpe",
            "snum",
            "rn",
            "vvstruct",
            "suf",
            "srclen"
        ]
    },
    {
        "original_word": "classes",
        "typo_word": "slassfs",
        "original_variable": "classesAndResources",
        "typo_variable": "slassfsAndResources",
        "original_code": "private boolean startLoading(String name) {\n\t\tSet classesAndResources = (Set) cycleDetector.get();\n\t\tif (classesAndResources != null && classesAndResources.contains(name))\n\t\t\treturn false;\n\n\t\tif (classesAndResources == null) {\n\t\t\tclassesAndResources = new HashSet(3);\n\t\t\tcycleDetector.set(classesAndResources);\n\t\t}\n\t\tclassesAndResources.add(name);\n\t\treturn true;\n\t}",
        "modified_code": "private boolean startLoading(String name) {\n\t\tSet slassfsAndResources = (Set) cycleDetector.get();\n\t\tif (slassfsAndResources != null && slassfsAndResources.contains(name))\n\t\t\treturn false;\n\n\t\tif (slassfsAndResources == null) {\n\t\t\tslassfsAndResources = new HashSet(3);\n\t\t\tcycleDetector.set(slassfsAndResources);\n\t\t}\n\t\tslassfsAndResources.add(name);\n\t\treturn true;\n\t}",
        "explanations_by_ours": [
            "the set of slassfs and resources",
            "a set of slassfs and resources",
            "the set of all slassfs and resources"
        ],
        "corrections_by_ours": [
            "resourcesfsAndResources",
            "slassfsAndSlass",
            "slassfsAndSet",
            "fsfsAndResources",
            "setfsAndResources",
            "slassslassAndResources",
            "slassfsSlassResources",
            "slassresourcesAndResources",
            "slassfsAndFs",
            "slasssetAndResources"
        ],
        "corrections_by_baseline": [
            "halResources",
            "webResourceCollections",
            "resourcePaths",
            "resourceRoot",
            "resourceFolder",
            "expandedResources",
            "resourceBundles",
            "libDirs",
            "schemasFolderPath",
            "jarsDir"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resuiy",
        "original_variable": "result",
        "typo_variable": "resuiy",
        "original_code": "public static <T> T deref(final Object obj, Class<T> expected)\n   {\n      Object result = deref(obj);\n      if (result == null)\n         return null;\n      return expected.cast(result);\n   }",
        "modified_code": "public static <T> T deref(final Object obj, Class<T> expected)\n   {\n      Object resuiy = deref(obj);\n      if (resuiy == null)\n         return null;\n      return expected.cast(resuiy);\n   }",
        "explanations_by_ours": [
            "the dereference result",
            "the resuiy",
            "the result"
        ],
        "corrections_by_ours": [
            "result",
            "dereference"
        ],
        "corrections_by_baseline": [
            "resul",
            "res",
            "usv",
            "resName",
            "vms",
            "iresult",
            "resourceInfo",
            "resilientFos",
            "resource",
            "IY"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rdsulr",
        "original_variable": "result",
        "typo_variable": "rdsulr",
        "original_code": "public static final String arrayToString(final Object isArr) {\n    String result = StringUtil.arrayToString(isArr, \",\");\n    return result;\n  }",
        "modified_code": "public static final String arrayToString(final Object isArr) {\n    String rdsulr = StringUtil.arrayToString(isArr, \",\");\n    return rdsulr;\n  }",
        "explanations_by_ours": [
            "the string representation of the array",
            "the string representation",
            "the array to convert to a string"
        ],
        "corrections_by_ours": [
            "convert",
            "representation",
            "string",
            "array"
        ],
        "corrections_by_baseline": [
            "rdr",
            "rds",
            "rgp",
            "rsf",
            "rp",
            "dsr",
            "rtn",
            "sr",
            "rtc",
            "rhop"
        ]
    },
    {
        "original_word": "stoker",
        "typo_word": "stomrr",
        "original_variable": "stoker",
        "typo_variable": "stomrr",
        "original_code": "protected void findCoordinateTransforms(NetcdfDataset ncDataset) {\r\n    for (VarProcess vp : varList) {\r\n      if (vp.coordTransforms != null) {\r\n        StringTokenizer stoker = new StringTokenizer(vp.coordTransforms);\r\n        while (stoker.hasMoreTokens()) {\r\n          String vname = stoker.nextToken();\r\n          VarProcess ap = findVarProcess(vname, vp);\r\n          if (ap != null) {\r\n            if (!ap.isCoordinateTransform)\r\n              parseInfo.format(\" CoordinateTransform = %s added; referenced from var= %s%n\", vname, vp.v.getFullName());\r\n            ap.isCoordinateTransform = true;\r\n          } else {\r\n            parseInfo.format(\"***Cant find CoordinateTransform %s referenced from var= %s%n\", vname, vp.v.getFullName());\r\n            userAdvice.format(\"***Cant find CoordinateTransform %s referenced from var= %s%n\", vname, vp.v.getFullName());\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }",
        "modified_code": "protected void findCoordinateTransforms(NetcdfDataset ncDataset) {\r\n    for (VarProcess vp : varList) {\r\n      if (vp.coordTransforms != null) {\r\n        StringTokenizer stomrr = new StringTokenizer(vp.coordTransforms);\r\n        while (stomrr.hasMoreTokens()) {\r\n          String vname = stomrr.nextToken();\r\n          VarProcess ap = findVarProcess(vname, vp);\r\n          if (ap != null) {\r\n            if (!ap.isCoordinateTransform)\r\n              parseInfo.format(\" CoordinateTransform = %s added; referenced from var= %s%n\", vname, vp.v.getFullName());\r\n            ap.isCoordinateTransform = true;\r\n          } else {\r\n            parseInfo.format(\"***Cant find CoordinateTransform %s referenced from var= %s%n\", vname, vp.v.getFullName());\r\n            userAdvice.format(\"***Cant find CoordinateTransform %s referenced from var= %s%n\", vname, vp.v.getFullName());\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }",
        "explanations_by_ours": [
            "The list of coordinate transforms.",
            "the list of coordinate transforms",
            "the list of coordinate transforms to find"
        ],
        "corrections_by_ours": [
            "transforms",
            "coordinate",
            "list",
            "find"
        ],
        "corrections_by_baseline": [
            "drq",
            "stp",
            "estr",
            "rr",
            "drss",
            "stnm",
            "rdr",
            "tsr",
            "errmsg",
            "rp"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resjit",
        "original_variable": "result",
        "typo_variable": "resjit",
        "original_code": "public Term functor() throws SourceCodeException\n    {\n        Token name = consumeToken(FUNCTOR);\n        Term[] args = arglist();\n        consumeToken(RPAREN);\n\n        int nameId =\n            interner.internFunctorName((args == null) ? name.image : name.image.substring(0, name.image.length() - 1),\n                (args == null) ? 0 : args.length);\n\n        Functor result = new Functor(nameId, args);\n\n        SourceCodePosition position =\n            new SourceCodePositionImpl(name.beginLine, name.beginColumn, name.endLine, name.endColumn);\n        result.setSourceCodePosition(position);\n\n        return result;\n    }",
        "modified_code": "public Term functor() throws SourceCodeException\n    {\n        Token name = consumeToken(FUNCTOR);\n        Term[] args = arglist();\n        consumeToken(RPAREN);\n\n        int nameId =\n            interner.internFunctorName((args == null) ? name.image : name.image.substring(0, name.image.length() - 1),\n                (args == null) ? 0 : args.length);\n\n        Functor resjit = new Functor(nameId, args);\n\n        SourceCodePosition position =\n            new SourceCodePositionImpl(name.beginLine, name.beginColumn, name.endLine, name.endColumn);\n        resjit.setSourceCodePosition(position);\n\n        return resjit;\n    }",
        "explanations_by_ours": [
            "Functor",
            "Functor object",
            "Functor instance"
        ],
        "corrections_by_ours": [
            "resobject",
            "objectjit",
            "resfunctor",
            "instancejit",
            "resinstance",
            "functorjit",
            "resjit"
        ],
        "corrections_by_baseline": [
            "res",
            "rj",
            "jitOverride",
            "jg",
            "jbeg",
            "jout",
            "jshft",
            "invx",
            "resul",
            "jp"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rdsulr",
        "original_variable": "result",
        "typo_variable": "rdsulr",
        "original_code": "public void clear() {\r\n    final RequestDescription result = this.result;\r\n    result.simpleParameters.children.clear();\r\n    result.clearBinaryData();\r\n    result.contentType = null;\r\n    result.clearHeaders();\r\n  }",
        "modified_code": "public void clear() {\r\n    final RequestDescription rdsulr = this.rdsulr;\r\n    rdsulr.simpleParameters.children.clear();\r\n    rdsulr.clearBinaryData();\r\n    rdsulr.contentType = null;\r\n    rdsulr.clearHeaders();\r\n  }",
        "explanations_by_ours": [
            "the request description",
            "the request description to clear",
            "the request description."
        ],
        "corrections_by_ours": [
            "request",
            "clear",
            "description"
        ],
        "corrections_by_baseline": [
            "rdr",
            "rds",
            "rgp",
            "rsf",
            "rp",
            "dsr",
            "rtn",
            "sr",
            "rtc",
            "rhop"
        ]
    },
    {
        "original_word": "Elem",
        "typo_word": "Ekdm",
        "original_variable": "netcdfElem",
        "typo_variable": "netcdfEkdm",
        "original_code": "public void writeNcML(java.io.Writer writer, String uri) throws IOException {\n    NcMLWriter ncmlWriter = new NcMLWriter();\n    Element netcdfElem = ncmlWriter.makeNetcdfElement(this, uri);\n    ncmlWriter.writeToWriter(netcdfElem, writer);\n  }",
        "modified_code": "public void writeNcML(java.io.Writer writer, String uri) throws IOException {\n    NcMLWriter ncmlWriter = new NcMLWriter();\n    Element netcdfEkdm = ncmlWriter.makeNetcdfElement(this, uri);\n    ncmlWriter.writeToWriter(netcdfEkdm, writer);\n  }",
        "explanations_by_ours": [
            "the NetCDF element to write to the writer",
            "the NetCDF element to write",
            "the NetCDF file to write"
        ],
        "corrections_by_ours": [
            "elementcdfEkdm",
            "netcdfElement",
            "netcdfCdf",
            "writecdfEkdm",
            "writercdfEkdm",
            "cdfcdfEkdm",
            "filecdfEkdm",
            "netwriterEkdm",
            "netnetEkdm",
            "netwriteEkdm"
        ],
        "corrections_by_baseline": [
            "netcdf4",
            "netcdfDataset",
            "dqc",
            "psdf",
            "gcdw",
            "ds2D",
            "d4ds",
            "dcat",
            "catalogCrDs",
            "etdf"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rwsulf",
        "original_variable": "result",
        "typo_variable": "rwsulf",
        "original_code": "public Byte toByte(final Object value, final Byte defaultValue) {\n\t\tfinal Byte result = toByte(value);\n\t\tif (result == null) {\n\t\t\treturn defaultValue;\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public Byte toByte(final Object value, final Byte defaultValue) {\n\t\tfinal Byte rwsulf = toByte(value);\n\t\tif (rwsulf == null) {\n\t\t\treturn defaultValue;\n\t\t}\n\t\treturn rwsulf;\n\t}",
        "explanations_by_ours": [
            "the rwsulf",
            "the rwsulf to convert",
            "the rwsulf to be converted"
        ],
        "corrections_by_ours": [
            "converted",
            "convert"
        ],
        "corrections_by_baseline": [
            "iread",
            "raven",
            "cir",
            "rp",
            "rLPS",
            "ilenhd",
            "f_huff",
            "sr",
            "rhop",
            "isr"
        ]
    },
    {
        "original_word": "trace",
        "typo_word": "trscf",
        "original_variable": "traceThread",
        "typo_variable": "trscfThread",
        "original_code": "public static InputStreamTracer findMatchInSystemOut(final String expectMatch) throws IOException {\n    InputStream systemout = captureSystemOutForDebuggingPurposesOnly(true);\n    InputStreamTracer result = new InputStreamTracer(systemout, expectMatch,\n        Charset.defaultCharset());\n    Thread traceThread = new Thread(result);\n    traceThread.setDaemon(true);\n    traceThread.start();\n    return result;\n  }",
        "modified_code": "public static InputStreamTracer findMatchInSystemOut(final String expectMatch) throws IOException {\n    InputStream systemout = captureSystemOutForDebuggingPurposesOnly(true);\n    InputStreamTracer result = new InputStreamTracer(systemout, expectMatch,\n        Charset.defaultCharset());\n    Thread trscfThread = new Thread(result);\n    trscfThread.setDaemon(true);\n    trscfThread.start();\n    return result;\n  }",
        "explanations_by_ours": [
            "the Thread to run the InputStreamTracer in",
            "the Thread that will be started when the InputStream",
            "the Thread to run the InputStreamTracer"
        ],
        "corrections_by_ours": [
            "tracerThread",
            "trscfStream",
            "trscfStarted",
            "streamThread",
            "threadThread",
            "startedThread",
            "runThread",
            "trscfRun",
            "trscfTracer",
            "inputThread"
        ],
        "corrections_by_baseline": [
            "thread",
            "proxyThread",
            "pingThread",
            "uThread",
            "taskThread",
            "forwarderThread",
            "hookThread",
            "worker",
            "otherThread",
            "thisThread"
        ]
    },
    {
        "original_word": "args",
        "typo_word": "aggq",
        "original_variable": "argsCount",
        "typo_variable": "aggqCount",
        "original_code": "public static void createArgumentsArray(final MethodVisitor mv, final MethodInfo methodInfo) {\n\t\tint argsCount = methodInfo.getArgumentsCount();\n\t\tpushInt(mv, argsCount);\n\t\tmv.visitTypeInsn(ANEWARRAY, AsmUtil.SIGNATURE_JAVA_LANG_OBJECT);\n\t\tfor (int i = 0; i < argsCount; i++) {\n\t\t\tmv.visitInsn(DUP);\n\t\t\tpushInt(mv, i);\n\t\t\tloadMethodArgumentAsObject(mv, methodInfo, i + 1);\n\t\t\tmv.visitInsn(AASTORE);\n\t\t}\n\t}",
        "modified_code": "public static void createArgumentsArray(final MethodVisitor mv, final MethodInfo methodInfo) {\n\t\tint aggqCount = methodInfo.getArgumentsCount();\n\t\tpushInt(mv, aggqCount);\n\t\tmv.visitTypeInsn(ANEWARRAY, AsmUtil.SIGNATURE_JAVA_LANG_OBJECT);\n\t\tfor (int i = 0; i < aggqCount; i++) {\n\t\t\tmv.visitInsn(DUP);\n\t\t\tpushInt(mv, i);\n\t\t\tloadMethodArgumentAsObject(mv, methodInfo, i + 1);\n\t\t\tmv.visitInsn(AASTORE);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the number of arguments",
            "the number of arguments to create",
            "the number of arguments for the method"
        ],
        "corrections_by_ours": [
            "aggqArguments",
            "aggqCreate",
            "argumentsCount",
            "methodCount",
            "numberCount",
            "createCount",
            "aggqMethod",
            "aggqNumber",
            "aggqCount"
        ],
        "corrections_by_baseline": [
            "aggregate",
            "countAll",
            "totalCount",
            "total_count",
            "scount",
            "metricsCount",
            "dCount",
            "aggregation",
            "counts",
            "count"
        ]
    },
    {
        "original_word": "nextn",
        "typo_word": "nratn",
        "original_variable": "nextn",
        "typo_variable": "nratn",
        "original_code": "public BigInteger at(int n) {\n        while (a.size() <= n) {\n            final int lastn = a.size() - 1;\n            final BigInteger nextn = BigInteger.valueOf(lastn + 1);\n            a.add(a.get(lastn).multiply(nextn));\n        }\n        return a.get(n);\n    }",
        "modified_code": "public BigInteger at(int n) {\n        while (a.size() <= n) {\n            final int lastn = a.size() - 1;\n            final BigInteger nratn = BigInteger.valueOf(lastn + 1);\n            a.add(a.get(lastn).multiply(nratn));\n        }\n        return a.get(n);\n    }",
        "explanations_by_ours": [
            "the element to return",
            "the value of the element to return",
            "the value of the nth element to return"
        ],
        "corrections_by_ours": [
            "nth",
            "return",
            "element",
            "value"
        ],
        "corrections_by_baseline": [
            "ratio",
            "ratdf",
            "weightSum",
            "totalWeight",
            "xFactor",
            "pWeight",
            "tfrac",
            "weight",
            "factor",
            "fraction"
        ]
    },
    {
        "original_word": "depends",
        "typo_word": "deoenxs",
        "original_variable": "depends",
        "typo_variable": "deoenxs",
        "original_code": "public boolean isOutDated(boolean checkClass) {\n\n        String jsp = ctxt.getJspFile();\n\t\n        if (jsw != null\n                && (ctxt.getOptions().getModificationTestInterval() > 0)) {\n \n            if (jsw.getLastModificationTest()\n                    + (ctxt.getOptions().getModificationTestInterval() * 1000) \n                    > System.currentTimeMillis()) {\n                return false;\n            } else {\n                jsw.setLastModificationTest(System.currentTimeMillis());\n            }\n        }\n\n        long jspRealLastModified = 0;\n        // START PWC 6468930\n        File targetFile;\n        \n        if (checkClass) {\n            targetFile = new File(ctxt.getClassFileName());\n        } else {\n            targetFile = new File(ctxt.getServletJavaFileName());\n        }\n        \n        // Get the target file's last modified time. File.lastModified()\n        // returns 0 if the file does not exist.\n        long targetLastModified = targetFile.lastModified();\n\n        // Check cached class file\n        if (checkClass) {\n            JspRuntimeContext rtctxt = ctxt.getRuntimeContext();\n            String className = ctxt.getFullClassName();\n            long cachedTime = rtctxt.getBytecodeBirthTime(className);\n            if (cachedTime > targetLastModified) {\n                targetLastModified = cachedTime;\n            } else {\n                // Remove from cache, since the bytecodes from the file is more\n                // current, so that JasperLoader won't load the cached version\n                rtctxt.setBytecode(className, null);\n            }\n        }\n\n        if (targetLastModified == 0L)\n            return true;\n\n        // Check if the jsp exists in the filesystem (instead of a jar\n        // or a remote location). If yes, then do a File.lastModified()\n        // to determine its last modified time. This is more performant \n        // (fewer stat calls) than the ctxt.getResource() followed by \n        // openConnection(). However, it only works for file system jsps.\n        // If the file has indeed changed, then need to call URL.OpenConnection() \n        // so that the cache loads the latest jsp file\n        if (jsw != null) {\n            File jspFile = jsw.getJspFile();\n            if (jspFile != null) {\n                jspRealLastModified = jspFile.lastModified();\n            }\n        }\n        if (jspRealLastModified == 0 ||\n            targetLastModified < jspRealLastModified) {\n        // END PWC 6468930\n        try {\n            URL jspUrl = ctxt.getResource(jsp);\n            if (jspUrl == null) {\n                ctxt.incrementRemoved();\n                return false;\n            }\n            URLConnection uc = jspUrl.openConnection();\n            if (uc instanceof JarURLConnection) {\n                jspRealLastModified =\n                    ((JarURLConnection) uc).getJarEntry().getTime();\n            } else {\n                jspRealLastModified = uc.getLastModified();\n            }\n            uc.getInputStream().close();\n        } catch (Exception e) {\n            e.printStackTrace();\n            return true;\n        }\n        // START PWC 6468930\n        }\n        // END PWC 6468930\n        /* PWC 6468930\n        long targetLastModified = 0;\n        File targetFile;\n        \n        if( checkClass ) {\n            targetFile = new File(ctxt.getClassFileName());\n        } else {\n            targetFile = new File(ctxt.getServletJavaFileName());\n        }\n        \n        if (!targetFile.exists()) {\n            return true;\n        }\n\n        targetLastModified = targetFile.lastModified();\n        */\n        if (checkClass && jsw != null) {\n            jsw.setServletClassLastModifiedTime(targetLastModified);\n        }\n\n        if (targetLastModified < jspRealLastModified) {\n            // Remember JSP mod time\n            jspModTime = jspRealLastModified;\n            if( log.isLoggable(Level.FINE) ) {\n                log.fine(\"Compiler: outdated: \" + targetFile + \" \" +\n                    targetLastModified );\n            }\n            return true;\n        }\n\n        // determine if source dependent files (e.g. includes using include\n        // directives) have been changed.\n        if( jsw==null ) {\n            return false;\n        }\n\n        List<String> depends = jsw.getDependants();\n        if (depends == null) {\n            return false;\n        }\n\n        for (String include: depends) {\n            try {\n                URL includeUrl = ctxt.getResource(include);\n                if (includeUrl == null) {\n                    return true;\n                }\n\n                URLConnection includeUconn = includeUrl.openConnection();\n                long includeLastModified = 0;\n                if (includeUconn instanceof JarURLConnection) {\n                    includeLastModified =\n                       ((JarURLConnection)includeUconn).getJarEntry().getTime();\n                } else {\n                    includeLastModified = includeUconn.getLastModified();\n                }\n                includeUconn.getInputStream().close();\n\n                if (includeLastModified > targetLastModified) {\n                    // START GlassFish 750\n                    if (include.endsWith(\".tld\")) {\n                        ctxt.clearTaglibs();\n                        ctxt.clearTagFileJarUrls();\n                    }\n                    // END GlassFish 750\n                    return true;\n                }\n            } catch (Exception e) {\n                e.printStackTrace();\n                return true;\n            }\n        }\n\n        return false;\n\n    }",
        "modified_code": "public boolean isOutDated(boolean checkClass) {\n\n        String jsp = ctxt.getJspFile();\n\t\n        if (jsw != null\n                && (ctxt.getOptions().getModificationTestInterval() > 0)) {\n \n            if (jsw.getLastModificationTest()\n                    + (ctxt.getOptions().getModificationTestInterval() * 1000) \n                    > System.currentTimeMillis()) {\n                return false;\n            } else {\n                jsw.setLastModificationTest(System.currentTimeMillis());\n            }\n        }\n\n        long jspRealLastModified = 0;\n        // START PWC 6468930\n        File targetFile;\n        \n        if (checkClass) {\n            targetFile = new File(ctxt.getClassFileName());\n        } else {\n            targetFile = new File(ctxt.getServletJavaFileName());\n        }\n        \n        // Get the target file's last modified time. File.lastModified()\n        // returns 0 if the file does not exist.\n        long targetLastModified = targetFile.lastModified();\n\n        // Check cached class file\n        if (checkClass) {\n            JspRuntimeContext rtctxt = ctxt.getRuntimeContext();\n            String className = ctxt.getFullClassName();\n            long cachedTime = rtctxt.getBytecodeBirthTime(className);\n            if (cachedTime > targetLastModified) {\n                targetLastModified = cachedTime;\n            } else {\n                // Remove from cache, since the bytecodes from the file is more\n                // current, so that JasperLoader won't load the cached version\n                rtctxt.setBytecode(className, null);\n            }\n        }\n\n        if (targetLastModified == 0L)\n            return true;\n\n        // Check if the jsp exists in the filesystem (instead of a jar\n        // or a remote location). If yes, then do a File.lastModified()\n        // to determine its last modified time. This is more performant \n        // (fewer stat calls) than the ctxt.getResource() followed by \n        // openConnection(). However, it only works for file system jsps.\n        // If the file has indeed changed, then need to call URL.OpenConnection() \n        // so that the cache loads the latest jsp file\n        if (jsw != null) {\n            File jspFile = jsw.getJspFile();\n            if (jspFile != null) {\n                jspRealLastModified = jspFile.lastModified();\n            }\n        }\n        if (jspRealLastModified == 0 ||\n            targetLastModified < jspRealLastModified) {\n        // END PWC 6468930\n        try {\n            URL jspUrl = ctxt.getResource(jsp);\n            if (jspUrl == null) {\n                ctxt.incrementRemoved();\n                return false;\n            }\n            URLConnection uc = jspUrl.openConnection();\n            if (uc instanceof JarURLConnection) {\n                jspRealLastModified =\n                    ((JarURLConnection) uc).getJarEntry().getTime();\n            } else {\n                jspRealLastModified = uc.getLastModified();\n            }\n            uc.getInputStream().close();\n        } catch (Exception e) {\n            e.printStackTrace();\n            return true;\n        }\n        // START PWC 6468930\n        }\n        // END PWC 6468930\n        /* PWC 6468930\n        long targetLastModified = 0;\n        File targetFile;\n        \n        if( checkClass ) {\n            targetFile = new File(ctxt.getClassFileName());\n        } else {\n            targetFile = new File(ctxt.getServletJavaFileName());\n        }\n        \n        if (!targetFile.exists()) {\n            return true;\n        }\n\n        targetLastModified = targetFile.lastModified();\n        */\n        if (checkClass && jsw != null) {\n            jsw.setServletClassLastModifiedTime(targetLastModified);\n        }\n\n        if (targetLastModified < jspRealLastModified) {\n            // Remember JSP mod time\n            jspModTime = jspRealLastModified;\n            if( log.isLoggable(Level.FINE) ) {\n                log.fine(\"Compiler: outdated: \" + targetFile + \" \" +\n                    targetLastModified );\n            }\n            return true;\n        }\n\n        // determine if source dependent files (e.g. includes using include\n        // directives) have been changed.\n        if( jsw==null ) {\n            return false;\n        }\n\n        List<String> deoenxs = jsw.getDependants();\n        if (deoenxs == null) {\n            return false;\n        }\n\n        for (String include: deoenxs) {\n            try {\n                URL includeUrl = ctxt.getResource(include);\n                if (includeUrl == null) {\n                    return true;\n                }\n\n                URLConnection includeUconn = includeUrl.openConnection();\n                long includeLastModified = 0;\n                if (includeUconn instanceof JarURLConnection) {\n                    includeLastModified =\n                       ((JarURLConnection)includeUconn).getJarEntry().getTime();\n                } else {\n                    includeLastModified = includeUconn.getLastModified();\n                }\n                includeUconn.getInputStream().close();\n\n                if (includeLastModified > targetLastModified) {\n                    // START GlassFish 750\n                    if (include.endsWith(\".tld\")) {\n                        ctxt.clearTaglibs();\n                        ctxt.clearTagFileJarUrls();\n                    }\n                    // END GlassFish 750\n                    return true;\n                }\n            } catch (Exception e) {\n                e.printStackTrace();\n                return true;\n            }\n        }\n\n        return false;\n\n    }",
        "explanations_by_ours": [
            "true if the JSP file is outdated, false otherwise.",
            "true if the JSP file is outdated, false otherwise",
            "true if the JSP is outdated, false otherwise."
        ],
        "corrections_by_ours": [
            "otherwise",
            "file",
            "true",
            "outdated,",
            "false",
            "jsp"
        ],
        "corrections_by_baseline": [
            "exds",
            "gdsMap",
            "ems",
            "peks",
            "datapos",
            "nmaps",
            "consequences",
            "sourceRIDs",
            "rids",
            "tapsXs"
        ]
    },
    {
        "original_word": "index",
        "typo_word": "ijdsx",
        "original_variable": "index",
        "typo_variable": "ijdsx",
        "original_code": "private int ps_huff_dec(IBitStream ld, int[][] t_huff) throws AACException {\n\t\tint bit;\n\t\tint index = 0;\n\n\t\twhile(index>=0) {\n\t\t\tbit = ld.readBit();\n\t\t\tindex = t_huff[index][bit];\n\t\t}\n\n\t\treturn index+31;\n\t}",
        "modified_code": "private int ps_huff_dec(IBitStream ld, int[][] t_huff) throws AACException {\n\t\tint bit;\n\t\tint ijdsx = 0;\n\n\t\twhile(ijdsx>=0) {\n\t\t\tbit = ld.readBit();\n\t\t\tijdsx = t_huff[ijdsx][bit];\n\t\t}\n\n\t\treturn ijdsx+31;\n\t}",
        "explanations_by_ours": [
            "The index of the first bit in the Huffman block.",
            "The index of the first bit in the array.",
            "The index of the first bit in the block."
        ],
        "corrections_by_ours": [
            "index",
            "first",
            "bit",
            "huff",
            "man",
            "block",
            "array"
        ],
        "corrections_by_baseline": [
            "jdrct",
            "dr",
            "jbndg",
            "jshft",
            "drss",
            "thislen",
            "rj",
            "ndx",
            "jbit",
            "hasdr"
        ]
    },
    {
        "original_word": "final",
        "typo_word": "flnap",
        "original_variable": "finalRouter",
        "typo_variable": "flnapRouter",
        "original_code": "public void startServer() throws InterruptedException {\n\n        RouteMatcher router = new RouteMatcher();\n        router.get(\"/v1.0\", new DefaultHandler());\n        router.post(\"/v1.0/multitenant/experimental/metrics\",\n                new HttpMultitenantMetricsIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v1.0/:tenantId/experimental/metrics\",\n                new HttpMetricsIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v1.0/:tenantId/experimental/metrics/statsd\",\n                new HttpAggregatedIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n\n        router.get(\"/v2.0\", new DefaultHandler());\n        router.post(\"/v2.0/:tenantId/ingest/multi\",\n                new HttpMultitenantMetricsIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v2.0/:tenantId/ingest\",\n                new HttpMetricsIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v2.0/:tenantId/ingest/aggregated\",\n                new HttpAggregatedIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v2.0/:tenantId/ingest/aggregated/multi\",\n                new HttpAggregatedMultiIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v2.0/:tenantId/events\", getHttpEventsIngestionHandler());\n        final RouteMatcher finalRouter = router;\n\n        log.info(\"Starting metrics listener HTTP server on port {}\", httpIngestPort);\n        ServerBootstrap server = new ServerBootstrap();\n        server.group(acceptorGroup, workerGroup)\n                .channel(NioServerSocketChannel.class)\n                .childHandler(new ChannelInitializer<SocketChannel>() {\n                    @Override\n                    public void initChannel(SocketChannel channel) throws Exception {\n                        setupPipeline(channel, finalRouter);\n                    }\n                });\n\n        Channel channel = server.bind(new InetSocketAddress(httpIngestHost, httpIngestPort)).sync().channel();\n        allOpenChannels.add(channel);\n\n        //register the tracker MBean for JMX/jolokia\n        log.info(\"Registering tracker service\");\n        Tracker.getInstance().register();\n\n        log.info(\"Token search improvements enabled: \" + EXP_TOKEN_SEARCH_IMPROVEMENTS);\n    }",
        "modified_code": "public void startServer() throws InterruptedException {\n\n        RouteMatcher router = new RouteMatcher();\n        router.get(\"/v1.0\", new DefaultHandler());\n        router.post(\"/v1.0/multitenant/experimental/metrics\",\n                new HttpMultitenantMetricsIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v1.0/:tenantId/experimental/metrics\",\n                new HttpMetricsIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v1.0/:tenantId/experimental/metrics/statsd\",\n                new HttpAggregatedIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n\n        router.get(\"/v2.0\", new DefaultHandler());\n        router.post(\"/v2.0/:tenantId/ingest/multi\",\n                new HttpMultitenantMetricsIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v2.0/:tenantId/ingest\",\n                new HttpMetricsIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v2.0/:tenantId/ingest/aggregated\",\n                new HttpAggregatedIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v2.0/:tenantId/ingest/aggregated/multi\",\n                new HttpAggregatedMultiIngestionHandler(processor, timeout, ENABLE_PER_TENANT_METRICS));\n        router.post(\"/v2.0/:tenantId/events\", getHttpEventsIngestionHandler());\n        final RouteMatcher flnapRouter = router;\n\n        log.info(\"Starting metrics listener HTTP server on port {}\", httpIngestPort);\n        ServerBootstrap server = new ServerBootstrap();\n        server.group(acceptorGroup, workerGroup)\n                .channel(NioServerSocketChannel.class)\n                .childHandler(new ChannelInitializer<SocketChannel>() {\n                    @Override\n                    public void initChannel(SocketChannel channel) throws Exception {\n                        setupPipeline(channel, flnapRouter);\n                    }\n                });\n\n        Channel channel = server.bind(new InetSocketAddress(httpIngestHost, httpIngestPort)).sync().channel();\n        allOpenChannels.add(channel);\n\n        //register the tracker MBean for JMX/jolokia\n        log.info(\"Registering tracker service\");\n        Tracker.getInstance().register();\n\n        log.info(\"Token search improvements enabled: \" + EXP_TOKEN_SEARCH_IMPROVEMENTS);\n    }",
        "explanations_by_ours": [
            "the flnap router",
            "the flnap router.",
            "the flnap router to use."
        ],
        "corrections_by_ours": [
            "flnapUse",
            "useRouter",
            "routerRouter",
            "flnapFlnap",
            "flnapRouter"
        ],
        "corrections_by_baseline": [
            "madvocRouter",
            "router",
            "finalRouter",
            "bridge",
            "toWebMercator",
            "portMapper",
            "remoteTransportProvider",
            "soapEndpoint",
            "route",
            "outer"
        ]
    },
    {
        "original_word": "shift",
        "typo_word": "xnift",
        "original_variable": "shift",
        "typo_variable": "xnift",
        "original_code": "static void writeInt(byte[] byteArray, int offset, int i) {\n    for (int j = 0; j < 4; j++) {\n      int shift = 24 - j * 8;\n      byteArray[offset + j] = (byte) (i >>> shift);\n    }\n  }",
        "modified_code": "static void writeInt(byte[] byteArray, int offset, int i) {\n    for (int j = 0; j < 4; j++) {\n      int xnift = 24 - j * 8;\n      byteArray[offset + j] = (byte) (i >>> xnift);\n    }\n  }",
        "explanations_by_ours": [
            "the xnift of the int",
            "the xnift of the int to write",
            "the xnift of the int."
        ],
        "corrections_by_ours": [
            "int",
            "write"
        ],
        "corrections_by_baseline": [
            "xpp",
            "rgp",
            "sndx",
            "sgp",
            "xorg",
            "ncx",
            "nx",
            "xstell",
            "bsf",
            "dlondx"
        ]
    },
    {
        "original_word": "prev",
        "typo_word": "lred",
        "original_variable": "prevType",
        "typo_variable": "lredType",
        "original_code": "public int getIndexedPropertyType(OgnlContext context, Object source)\n            throws OgnlException\n    {\n        Class type = context.getCurrentType();\n        Class prevType = context.getPreviousType();\n        try\n        {\n            if (!isIndexedAccess())\n            {\n                Object property = getProperty(context, source);\n\n                if (property instanceof String)\n                {\n                    return OgnlRuntime.getIndexedPropertyType(context, (source == null)\n                            ? null\n                            : OgnlRuntime.getCompiler().getInterfaceClass(source.getClass()), (String) property);\n                }\n            }\n\n            return OgnlRuntime.INDEXED_PROPERTY_NONE;\n        } finally\n        {\n            context.setCurrentObject(source);\n            context.setCurrentType(type);\n            context.setPreviousType(prevType);\n        }\n    }",
        "modified_code": "public int getIndexedPropertyType(OgnlContext context, Object source)\n            throws OgnlException\n    {\n        Class type = context.getCurrentType();\n        Class lredType = context.getPreviousType();\n        try\n        {\n            if (!isIndexedAccess())\n            {\n                Object property = getProperty(context, source);\n\n                if (property instanceof String)\n                {\n                    return OgnlRuntime.getIndexedPropertyType(context, (source == null)\n                            ? null\n                            : OgnlRuntime.getCompiler().getInterfaceClass(source.getClass()), (String) property);\n                }\n            }\n\n            return OgnlRuntime.INDEXED_PROPERTY_NONE;\n        } finally\n        {\n            context.setCurrentObject(source);\n            context.setCurrentType(type);\n            context.setPreviousType(lredType);\n        }\n    }",
        "explanations_by_ours": [
            "the previous type.",
            "the previous type",
            "The type of the object."
        ],
        "corrections_by_ours": [
            "lpreviousType",
            "lobjectType",
            "lredObject",
            "previousredType",
            "typeredType",
            "objectredType",
            "ltypeType",
            "lredPrevious",
            "lredType"
        ],
        "corrections_by_baseline": [
            "rType",
            "cType",
            "pType",
            "type",
            "iType",
            "atype",
            "stsType",
            "typeS",
            "typeValue",
            "dtype"
        ]
    },
    {
        "original_word": "tokens",
        "typo_word": "tokebd",
        "original_variable": "la1tokens",
        "typo_variable": "la1tokebd",
        "original_code": "public ParseException generateParseException() {\n    jj_expentries.clear();\n    boolean[] la1tokens = new boolean[279];\n    if (jj_kind >= 0) {\n      la1tokens[jj_kind] = true;\n      jj_kind = -1;\n    }\n    for (int i = 0; i < 424; i++) {\n      if (jj_la1[i] == jj_gen) {\n        for (int j = 0; j < 32; j++) {\n          if ((jj_la1_0[i] & (1<<j)) != 0) {\n            la1tokens[j] = true;\n          }\n          if ((jj_la1_1[i] & (1<<j)) != 0) {\n            la1tokens[32+j] = true;\n          }\n          if ((jj_la1_2[i] & (1<<j)) != 0) {\n            la1tokens[64+j] = true;\n          }\n          if ((jj_la1_3[i] & (1<<j)) != 0) {\n            la1tokens[96+j] = true;\n          }\n          if ((jj_la1_4[i] & (1<<j)) != 0) {\n            la1tokens[128+j] = true;\n          }\n          if ((jj_la1_5[i] & (1<<j)) != 0) {\n            la1tokens[160+j] = true;\n          }\n          if ((jj_la1_6[i] & (1<<j)) != 0) {\n            la1tokens[192+j] = true;\n          }\n          if ((jj_la1_7[i] & (1<<j)) != 0) {\n            la1tokens[224+j] = true;\n          }\n          if ((jj_la1_8[i] & (1<<j)) != 0) {\n            la1tokens[256+j] = true;\n          }\n        }\n      }\n    }\n    for (int i = 0; i < 279; i++) {\n      if (la1tokens[i]) {\n        jj_expentry = new int[1];\n        jj_expentry[0] = i;\n        jj_expentries.add(jj_expentry);\n      }\n    }\n    jj_endpos = 0;\n    jj_rescan_token();\n    jj_add_error_token(0, 0);\n    int[][] exptokseq = new int[jj_expentries.size()][];\n    for (int i = 0; i < jj_expentries.size(); i++) {\n      exptokseq[i] = jj_expentries.get(i);\n    }\n    return new ParseException(token, exptokseq, tokenImage);\n  }",
        "modified_code": "public ParseException generateParseException() {\n    jj_expentries.clear();\n    boolean[] la1tokebd = new boolean[279];\n    if (jj_kind >= 0) {\n      la1tokebd[jj_kind] = true;\n      jj_kind = -1;\n    }\n    for (int i = 0; i < 424; i++) {\n      if (jj_la1[i] == jj_gen) {\n        for (int j = 0; j < 32; j++) {\n          if ((jj_la1_0[i] & (1<<j)) != 0) {\n            la1tokebd[j] = true;\n          }\n          if ((jj_la1_1[i] & (1<<j)) != 0) {\n            la1tokebd[32+j] = true;\n          }\n          if ((jj_la1_2[i] & (1<<j)) != 0) {\n            la1tokebd[64+j] = true;\n          }\n          if ((jj_la1_3[i] & (1<<j)) != 0) {\n            la1tokebd[96+j] = true;\n          }\n          if ((jj_la1_4[i] & (1<<j)) != 0) {\n            la1tokebd[128+j] = true;\n          }\n          if ((jj_la1_5[i] & (1<<j)) != 0) {\n            la1tokebd[160+j] = true;\n          }\n          if ((jj_la1_6[i] & (1<<j)) != 0) {\n            la1tokebd[192+j] = true;\n          }\n          if ((jj_la1_7[i] & (1<<j)) != 0) {\n            la1tokebd[224+j] = true;\n          }\n          if ((jj_la1_8[i] & (1<<j)) != 0) {\n            la1tokebd[256+j] = true;\n          }\n        }\n      }\n    }\n    for (int i = 0; i < 279; i++) {\n      if (la1tokebd[i]) {\n        jj_expentry = new int[1];\n        jj_expentry[0] = i;\n        jj_expentries.add(jj_expentry);\n      }\n    }\n    jj_endpos = 0;\n    jj_rescan_token();\n    jj_add_error_token(0, 0);\n    int[][] exptokseq = new int[jj_expentries.size()][];\n    for (int i = 0; i < jj_expentries.size(); i++) {\n      exptokseq[i] = jj_expentries.get(i);\n    }\n    return new ParseException(token, exptokseq, tokenImage);\n  }",
        "explanations_by_ours": [
            "A boolean array to store boolean values in the ParseException.",
            "A boolean array to store the boolean values in the ParseException.",
            "A boolean array to store the boolean values in the ParseException array."
        ],
        "corrections_by_ours": [
            "la1store",
            "boolean1tokebd",
            "la1boolean",
            "parse1tokebd",
            "array1tokebd",
            "values1tokebd",
            "la1exception",
            "store1tokebd",
            "exception1tokebd",
            "lavaluestokebd"
        ],
        "corrections_by_baseline": [
            "La1",
            "la1",
            "La2",
            "la2",
            "b4",
            "a2_m_b2",
            "b3",
            "a4p",
            "a55",
            "d4"
        ]
    },
    {
        "original_word": "signed",
        "typo_word": "sinnfd",
        "original_variable": "signed",
        "typo_variable": "sinnfd",
        "original_code": "private void sign(RequestHandler requestHandler) throws QSException {\n        if (callBack != null) {\n            String signed = callBack.onSignature(requestHandler.getStringToSignature());\n            if (!QSStringUtil.isEmpty(signed))\n                requestHandler.setSignature(callBack.onAccessKey(), signed);\n            String correctTime = callBack.onCorrectTime(requestHandler.getStringToSignature());\n            if (correctTime != null && correctTime.trim().length() > 0)\n                requestHandler.getBuilder().setHeader(QSConstant.HEADER_PARAM_KEY_DATE, correctTime);\n        }\n    }",
        "modified_code": "private void sign(RequestHandler requestHandler) throws QSException {\n        if (callBack != null) {\n            String sinnfd = callBack.onSignature(requestHandler.getStringToSignature());\n            if (!QSStringUtil.isEmpty(sinnfd))\n                requestHandler.setSignature(callBack.onAccessKey(), sinnfd);\n            String correctTime = callBack.onCorrectTime(requestHandler.getStringToSignature());\n            if (correctTime != null && correctTime.trim().length() > 0)\n                requestHandler.getBuilder().setHeader(QSConstant.HEADER_PARAM_KEY_DATE, correctTime);\n        }\n    }",
        "explanations_by_ours": [
            "The SNAFD to use for the call back.",
            "The SNAFD to be used for the call back.",
            "The SNAFD for the request."
        ],
        "corrections_by_ours": [
            "sinsnafd",
            "usednfd",
            "sinused",
            "snafdnfd",
            "usenfd",
            "backnfd",
            "requestnfd",
            "callnfd",
            "sinuse",
            "sinback"
        ],
        "corrections_by_baseline": [
            "fd",
            "socket",
            "gfdw",
            "serverSocket",
            "fds",
            "socketAddr",
            "socketAddress",
            "activeSocket",
            "mcpi",
            "socketBuffer"
        ]
    },
    {
        "original_word": "position",
        "typo_word": "lodition",
        "original_variable": "position",
        "typo_variable": "lodition",
        "original_code": "public boolean isInHead()\n    {\n        PositionalTermTraverserImpl.PositionalContextOperator position = contextStack.peek();\n\n        return (position != null) && position.isInHead();\n    }",
        "modified_code": "public boolean isInHead()\n    {\n        PositionalTermTraverserImpl.PositionalContextOperator lodition = contextStack.peek();\n\n        return (lodition != null) && lodition.isInHead();\n    }",
        "explanations_by_ours": [
            "the current position traverser's lodition.",
            "The current position traverser's lodition.",
            "the current position traverser's lodition"
        ],
        "corrections_by_ours": [
            "loditposition",
            "ionition",
            "lodionion",
            "loditlod",
            "lodpositionion",
            "lodcurrention",
            "loditcurrent",
            "positionition",
            "currentition",
            "traverser'sition"
        ],
        "corrections_by_baseline": [
            "model",
            "fullModel",
            "nodeModel",
            "formula",
            "classifier",
            "modelNode",
            "mapper",
            "axiom",
            "classVocab",
            "od"
        ]
    },
    {
        "original_word": "manual",
        "typo_word": "mwnusl",
        "original_variable": "manualQuery",
        "typo_variable": "mwnuslQuery",
        "original_code": "private static BoundingBox getBoundingBox(GeoPackage geoPackage,\n                                              FeatureTiles featureTiles, BoundingBox boundingBox,\n                                              Projection projection) {\n\n        String tableName = featureTiles.getFeatureDao().getTableName();\n        boolean manualQuery = boundingBox == null;\n        BoundingBox featureBoundingBox = geoPackage.getBoundingBox(projection,\n                tableName, manualQuery);\n        if (featureBoundingBox != null) {\n            if (boundingBox == null) {\n                boundingBox = featureBoundingBox;\n            } else {\n                boundingBox = boundingBox.overlap(featureBoundingBox);\n            }\n        }\n\n        if (boundingBox != null) {\n            boundingBox = featureTiles.expandBoundingBox(boundingBox,\n                    projection);\n        }\n\n        return boundingBox;\n    }",
        "modified_code": "private static BoundingBox getBoundingBox(GeoPackage geoPackage,\n                                              FeatureTiles featureTiles, BoundingBox boundingBox,\n                                              Projection projection) {\n\n        String tableName = featureTiles.getFeatureDao().getTableName();\n        boolean mwnuslQuery = boundingBox == null;\n        BoundingBox featureBoundingBox = geoPackage.getBoundingBox(projection,\n                tableName, mwnuslQuery);\n        if (featureBoundingBox != null) {\n            if (boundingBox == null) {\n                boundingBox = featureBoundingBox;\n            } else {\n                boundingBox = boundingBox.overlap(featureBoundingBox);\n            }\n        }\n\n        if (boundingBox != null) {\n            boundingBox = featureTiles.expandBoundingBox(boundingBox,\n                    projection);\n        }\n\n        return boundingBox;\n    }",
        "explanations_by_ours": [
            "mlnusl query",
            "mrnusl query",
            "mlnusl query flag"
        ],
        "corrections_by_ours": [
            "mrnuslQuery",
            "mlnuslQuery",
            "flagQuery",
            "queryQuery",
            "mwnuslFlag",
            "mwnuslMrnusl",
            "mwnuslMlnusl",
            "mwnuslQuery"
        ],
        "corrections_by_baseline": [
            "manualQuery",
            "luceneQuery",
            "cqQuery",
            "wQuery",
            "dynamicQuery",
            "query",
            "staticQuery",
            "subquery",
            "countQuery",
            "queries"
        ]
    },
    {
        "original_word": "node",
        "typo_word": "novw",
        "original_variable": "nodeName",
        "typo_variable": "novwName",
        "original_code": "public List<Binding> listBindings(final Name name) throws NamingException {\n        final Name nodeName = name.isEmpty() ? new CompositeName(\"\") : name;\n        return root.accept(new ListBindingsVisitor(nodeName));\n    }",
        "modified_code": "public List<Binding> listBindings(final Name name) throws NamingException {\n        final Name novwName = name.isEmpty() ? new CompositeName(\"\") : name;\n        return root.accept(new ListBindingsVisitor(novwName));\n    }",
        "explanations_by_ours": [
            "the name to search for",
            "the name to search for.",
            "the name of the object to search for"
        ],
        "corrections_by_ours": [
            "nameName",
            "novwSearch",
            "novwObject",
            "searchName",
            "objectName",
            "novwName"
        ],
        "corrections_by_baseline": [
            "vName",
            "vname",
            "varname",
            "clearname",
            "azim_name",
            "azimName",
            "_h_name",
            "oName",
            "aciName",
            "gname"
        ]
    },
    {
        "original_word": "popped",
        "typo_word": "pkppev",
        "original_variable": "popped",
        "typo_variable": "pkppev",
        "original_code": "private void restartablyPop() throws SAXException {\n        Element popped = theStack;\n        pop();\n        if (restartElements && (popped.flags() & Schema.F_RESTART) != 0) {\n            popped.anonymize();\n            popped.setNext(theSaved);\n            theSaved = popped;\n        }\n    }",
        "modified_code": "private void restartablyPop() throws SAXException {\n        Element pkppev = theStack;\n        pop();\n        if (restartElements && (pkppev.flags() & Schema.F_RESTART) != 0) {\n            pkppev.anonymize();\n            pkppev.setNext(theSaved);\n            theSaved = pkppev;\n        }\n    }",
        "explanations_by_ours": [
            "The top element to pop.",
            "the element to be an anonymous element.",
            "The top element to be popped."
        ],
        "corrections_by_ours": [
            "popped",
            "pop",
            "top",
            "element",
            "anonymous"
        ],
        "corrections_by_baseline": [
            "PV",
            "pv",
            "pf",
            "vf",
            "llp0",
            "btpv",
            "pihalf",
            "phv",
            "llp",
            "pib"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "iffswt",
        "original_variable": "offset",
        "typo_variable": "iffswt",
        "original_code": "public double getValue() {\n    if (!(uu instanceof ScaledUnit)) return Double.NaN;\n    ScaledUnit offset = (ScaledUnit) uu;\n    return offset.getScale();\n  }",
        "modified_code": "public double getValue() {\n    if (!(uu instanceof ScaledUnit)) return Double.NaN;\n    ScaledUnit iffswt = (ScaledUnit) uu;\n    return iffswt.getScale();\n  }",
        "explanations_by_ours": [
            "the unit to get the value of.",
            "the scaled unit.",
            "the unit to return the value of."
        ],
        "corrections_by_ours": [
            "get",
            "unit",
            "return",
            "scaled",
            "value"
        ],
        "corrections_by_baseline": [
            "ndiff",
            "bmp",
            "bsf",
            "diff",
            "dsc",
            "k2Diff",
            "diffX",
            "diff2",
            "xblat",
            "bte"
        ]
    },
    {
        "original_word": "clazz",
        "typo_word": "clqza",
        "original_variable": "clazz",
        "typo_variable": "clqza",
        "original_code": "public OCommandExecutorSQLAbstract createCommand(final String name) throws OCommandExecutionException {\n    final Class<? extends OCommandExecutorSQLAbstract> clazz = COMMANDS.get(name);\n\n    if (clazz == null) {\n      throw new OCommandExecutionException(\"Unknowned command name :\" + name);\n    }\n\n    try {\n      return clazz.newInstance();\n    } catch (Exception e) {\n      throw OException.wrapException(new OCommandExecutionException(\"Error in creation of command \" + name\n          + \"(). Probably there is not an empty constructor or the constructor generates errors\"), e);\n    }\n  }",
        "modified_code": "public OCommandExecutorSQLAbstract createCommand(final String name) throws OCommandExecutionException {\n    final Class<? extends OCommandExecutorSQLAbstract> clqza = COMMANDS.get(name);\n\n    if (clqza == null) {\n      throw new OCommandExecutionException(\"Unknowned command name :\" + name);\n    }\n\n    try {\n      return clqza.newInstance();\n    } catch (Exception e) {\n      throw OException.wrapException(new OCommandExecutionException(\"Error in creation of command \" + name\n          + \"(). Probably there is not an empty constructor or the constructor generates errors\"), e);\n    }\n  }",
        "explanations_by_ours": [
            "the class of the command",
            "the command class",
            "the class of the command to create"
        ],
        "corrections_by_ours": [
            "class",
            "command",
            "create"
        ],
        "corrections_by_baseline": [
            "qto",
            "cqf",
            "aeqm",
            "ksp",
            "qmi",
            "sgp",
            "cdl",
            "qd",
            "aseq",
            "pkt"
        ]
    },
    {
        "original_word": "interned",
        "typo_word": "ibtermed",
        "original_variable": "internedName",
        "typo_variable": "ibtermedName",
        "original_code": "public Functor functor(String name, Term... args)\n    {\n        int internedName = interner.internFunctorName(name, args.length);\n\n        return new Functor(internedName, args);\n    }",
        "modified_code": "public Functor functor(String name, Term... args)\n    {\n        int ibtermedName = interner.internFunctorName(name, args.length);\n\n        return new Functor(ibtermedName, args);\n    }",
        "explanations_by_ours": [
            "the name of the functor",
            "the name of the new functor",
            "the id of the functor"
        ],
        "corrections_by_ours": [
            "nameName",
            "idName",
            "ibtermedNew",
            "ibtermedFunctor",
            "newName",
            "functorName",
            "ibtermedId",
            "ibtermedName"
        ],
        "corrections_by_baseline": [
            "canonicalName",
            "internalName",
            "altName",
            "symbolicName",
            "btName",
            "trimmedName",
            "ejbName",
            "qualifiedName",
            "bName",
            "shortName"
        ]
    },
    {
        "original_word": "escaped",
        "typo_word": "escaoes",
        "original_variable": "escaped",
        "typo_variable": "escaoes",
        "original_code": "static public String\n    entityEscape(String s, String wrt)\n    {\n        if(wrt == null)\n            wrt = ENTITYESCAPES;\n        StringBuilder escaped = new StringBuilder();\n        for(int i = 0; i < s.length(); i++) {\n            char c = s.charAt(i);\n            int index = wrt.indexOf(c);\n            if(index < 0)\n                escaped.append(c);\n            else switch (c) {\n            case '&':\n                escaped.append('&' + ENTITY_AMP + ';');\n                break;\n            case '<':\n                escaped.append('&' + ENTITY_LT + ';');\n                break;\n            case '>':\n                escaped.append('&' + ENTITY_GT + ';');\n                break;\n            case '\"':\n                escaped.append('&' + ENTITY_QUOT + ';');\n                break;\n            case '\\'':\n                escaped.append('&' + ENTITY_APOS + ';');\n                break;\n            case '\\r':\n            case '\\t':\n            case '\\n':\n                escaped.append(c);  // These are the only legal control chars\n                break;\n            case '\\0':\n                // What to do about nul? currrently we suppress it\n                break;\n            default:\n                if(c >= ' ')\n                    escaped.append(c);\n                break;\n            }\n        }\n        return escaped.toString();\n    }",
        "modified_code": "static public String\n    entityEscape(String s, String wrt)\n    {\n        if(wrt == null)\n            wrt = ENTITYESCAPES;\n        StringBuilder escaoes = new StringBuilder();\n        for(int i = 0; i < s.length(); i++) {\n            char c = s.charAt(i);\n            int index = wrt.indexOf(c);\n            if(index < 0)\n                escaoes.append(c);\n            else switch (c) {\n            case '&':\n                escaoes.append('&' + ENTITY_AMP + ';');\n                break;\n            case '<':\n                escaoes.append('&' + ENTITY_LT + ';');\n                break;\n            case '>':\n                escaoes.append('&' + ENTITY_GT + ';');\n                break;\n            case '\"':\n                escaoes.append('&' + ENTITY_QUOT + ';');\n                break;\n            case '\\'':\n                escaoes.append('&' + ENTITY_APOS + ';');\n                break;\n            case '\\r':\n            case '\\t':\n            case '\\n':\n                escaoes.append(c);  // These are the only legal control chars\n                break;\n            case '\\0':\n                // What to do about nul? currrently we suppress it\n                break;\n            default:\n                if(c >= ' ')\n                    escaoes.append(c);\n                break;\n            }\n        }\n        return escaoes.toString();\n    }",
        "explanations_by_ours": [
            "The string to escape.",
            "The string to append to.",
            "The string to use as the escaping."
        ],
        "corrections_by_ours": [
            "escapeoes",
            "escapingoes",
            "escause",
            "useoes",
            "escaappend",
            "escaescape",
            "escaescaping",
            "stringoes",
            "appendoes",
            "escastring"
        ],
        "corrections_by_baseline": [
            "cis",
            "AeroSpcs",
            "fos",
            "caco",
            "baos",
            "ca",
            "dos",
            "po",
            "accel",
            "cas"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "desuit",
        "original_variable": "result",
        "typo_variable": "desuit",
        "original_code": "public File[] getParentDirs(final File fromDir, final File toDir) throws IOException {\n\t\tList<File> result = new LinkedList<>();\n\t\tfinal File fromDirCanonical = fromDir.getCanonicalFile();\n\t\tfor (File current = toDir.getCanonicalFile().getAbsoluteFile(); !current.equals(fromDirCanonical); current = current.getParentFile()) {\n\t\t\tresult.add(0, current);\n\t\t}\n\n\t\treturn result.toArray(new File[result.size()]);\n\t}",
        "modified_code": "public File[] getParentDirs(final File fromDir, final File toDir) throws IOException {\n\t\tList<File> desuit = new LinkedList<>();\n\t\tfinal File fromDirCanonical = fromDir.getCanonicalFile();\n\t\tfor (File current = toDir.getCanonicalFile().getAbsoluteFile(); !current.equals(fromDirCanonical); current = current.getParentFile()) {\n\t\t\tdesuit.add(0, current);\n\t\t}\n\n\t\treturn desuit.toArray(new File[desuit.size()]);\n\t}",
        "explanations_by_ours": [
            "the files to desuit",
            "the list of files to desuit",
            "a list of the files to desuit"
        ],
        "corrections_by_ours": [
            "deslist",
            "filesuit",
            "listuit",
            "desfiles",
            "uituit",
            "desdes",
            "desuit"
        ],
        "corrections_by_baseline": [
            "des",
            "de",
            "dely",
            "dis",
            "duDesc",
            "usv",
            "fin",
            "du",
            "iresult",
            "ecef"
        ]
    },
    {
        "original_word": "Iter",
        "typo_word": "Itfd",
        "original_variable": "protocolIter",
        "typo_variable": "protocolItfd",
        "original_code": "public List<TProtocol> amendMissingRequiredFields(StructType recordThriftType) throws TException {\n    Iterator<TProtocol> protocolIter = rootEvents.iterator();\n    checkStruct(protocolIter, recordThriftType);\n    return fixedEvents;\n  }",
        "modified_code": "public List<TProtocol> amendMissingRequiredFields(StructType recordThriftType) throws TException {\n    Iterator<TProtocol> protocolItfd = rootEvents.iterator();\n    checkStruct(protocolItfd, recordThriftType);\n    return fixedEvents;\n  }",
        "explanations_by_ours": [
            "the list of events to be amended.",
            "the list of events to be amended",
            "the list of protocol Itfds to amend"
        ],
        "corrections_by_ours": [
            "protocolFds",
            "protocolAmend",
            "protocolAmended",
            "listItfd",
            "protocolProtocol",
            "amendedItfd",
            "amendItfd",
            "fdsItfd",
            "eventsItfd",
            "protocolList"
        ],
        "corrections_by_baseline": [
            "protocol",
            "gelfProtocol",
            "transport",
            "mcpi",
            "leadprotocol",
            "sgp",
            "protocolIter",
            "webSocketImpl",
            "transport_mech",
            "rgp"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "falke",
        "original_variable": "value",
        "typo_variable": "falke",
        "original_code": "public static int getNumerProperty(String key) {\n        String value = getProperties().getProperty(key);\n        if(NumberUtils.isNumber(value)) {\n        \treturn Integer.parseInt(value);\n        } else {\n        \treturn 0;\n        }\n    }",
        "modified_code": "public static int getNumerProperty(String key) {\n        String falke = getProperties().getProperty(key);\n        if(NumberUtils.isNumber(falke)) {\n        \treturn Integer.parseInt(falke);\n        } else {\n        \treturn 0;\n        }\n    }",
        "explanations_by_ours": [
            "the property value",
            "the value of the property",
            "the value of the property as a string"
        ],
        "corrections_by_ours": [
            "value",
            "property",
            "string"
        ],
        "corrections_by_baseline": [
            "toke",
            "fa",
            "dra",
            "michealangelo",
            "dou",
            "stroke",
            "gamma",
            "alpha",
            "kPrime",
            "p_alp"
        ]
    },
    {
        "original_word": "Pref",
        "typo_word": "Peff",
        "original_variable": "viewPrefSize",
        "typo_variable": "viewPeffSize",
        "original_code": "public void layoutContainer(Container parent)\n    {\n        JViewport vp = (JViewport) parent;\n        Component view = vp.getView();\n\n        if (view == null)\n        {\n            return;\n        }\n\n        Point viewPosition = vp.getViewPosition();\n        Dimension viewPrefSize = view.getPreferredSize();\n        Dimension vpSize = vp.getSize();\n        Dimension viewSize = new Dimension(viewPrefSize);\n\n        if ((viewPosition.x == 0) && (vpSize.width > viewPrefSize.width))\n        {\n            viewSize.width = vpSize.width;\n        }\n\n        if ((viewPosition.y == 0) && (vpSize.height > viewPrefSize.height))\n        {\n            viewSize.height = vpSize.height;\n        }\n\n        if (!viewSize.equals(viewPrefSize))\n        {\n            vp.setViewSize(viewSize);\n        }\n    }",
        "modified_code": "public void layoutContainer(Container parent)\n    {\n        JViewport vp = (JViewport) parent;\n        Component view = vp.getView();\n\n        if (view == null)\n        {\n            return;\n        }\n\n        Point viewPosition = vp.getViewPosition();\n        Dimension viewPeffSize = view.getPreferredSize();\n        Dimension vpSize = vp.getSize();\n        Dimension viewSize = new Dimension(viewPeffSize);\n\n        if ((viewPosition.x == 0) && (vpSize.width > viewPeffSize.width))\n        {\n            viewSize.width = vpSize.width;\n        }\n\n        if ((viewPosition.y == 0) && (vpSize.height > viewPeffSize.height))\n        {\n            viewSize.height = vpSize.height;\n        }\n\n        if (!viewSize.equals(viewPeffSize))\n        {\n            vp.setViewSize(viewSize);\n        }\n    }",
        "explanations_by_ours": [
            "the view's preferred size.",
            "the view's size.",
            "the size of the view."
        ],
        "corrections_by_ours": [
            "view'sPeffSize",
            "sizePeffSize",
            "viewPeffView",
            "viewPpreferredSize",
            "viewPview'sSize",
            "viewPeffView's",
            "preferredPeffSize",
            "viewPreferredeffSize",
            "viewPeffPreferred",
            "viewView'seffSize"
        ],
        "corrections_by_baseline": [
            "viewSize",
            "viewPrefSize",
            "vpSize",
            "xSize",
            "psize",
            "ySize",
            "viewHeight",
            "viewWidth",
            "eSize",
            "sizeForWidth"
        ]
    },
    {
        "original_word": "nodes",
        "typo_word": "nodsx",
        "original_variable": "nodes",
        "typo_variable": "nodsx",
        "original_code": "public List<String> removeServer(final String iNode) {\n    synchronized (configuration) {\n      final List<String> changedPartitions = new ArrayList<String>();\n\n      for (String clusterName : getClusterNames()) {\n        final Collection<String> nodes = getClusterConfiguration(clusterName).field(SERVERS);\n        if (nodes != null) {\n          for (String node : nodes) {\n            if (node.equals(iNode)) {\n              // FOUND: REMOVE IT\n              nodes.remove(node);\n              changedPartitions.add(clusterName);\n              break;\n            }\n          }\n        }\n      }\n\n      if (!changedPartitions.isEmpty()) {\n        incrementVersion();\n        return changedPartitions;\n      }\n    }\n    return null;\n  }",
        "modified_code": "public List<String> removeServer(final String iNode) {\n    synchronized (configuration) {\n      final List<String> changedPartitions = new ArrayList<String>();\n\n      for (String clusterName : getClusterNames()) {\n        final Collection<String> nodsx = getClusterConfiguration(clusterName).field(SERVERS);\n        if (nodsx != null) {\n          for (String node : nodsx) {\n            if (node.equals(iNode)) {\n              // FOUND: REMOVE IT\n              nodsx.remove(node);\n              changedPartitions.add(clusterName);\n              break;\n            }\n          }\n        }\n      }\n\n      if (!changedPartitions.isEmpty()) {\n        incrementVersion();\n        return changedPartitions;\n      }\n    }\n    return null;\n  }",
        "explanations_by_ours": [
            "The nodes to remove.",
            "The list of nodes to remove.",
            "The list of nodes to remove from the cluster."
        ],
        "corrections_by_ours": [
            "nodes",
            "list",
            "cluster",
            "remove"
        ],
        "corrections_by_baseline": [
            "dodsV",
            "dks",
            "dapex",
            "dodsname",
            "nx",
            "ddx",
            "xs",
            "xstell",
            "ud",
            "dsc"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "ckrtent",
        "original_variable": "current",
        "typo_variable": "ckrtent",
        "original_code": "private float calculatePercentage(int width) {\n        int absolute = mMaxWidth - mMinWidth;\n        int current = width - mMinWidth;\n        float percentage = 100.0f * current / absolute;\n        //we can assume that we are crossfaded if the percentage is > 90\n        mIsCrossfaded = percentage > 90;\n        return percentage;\n    }",
        "modified_code": "private float calculatePercentage(int width) {\n        int absolute = mMaxWidth - mMinWidth;\n        int ckrtent = width - mMinWidth;\n        float percentage = 100.0f * ckrtent / absolute;\n        //we can assume that we are crossfaded if the percentage is > 90\n        mIsCrossfaded = percentage > 90;\n        return percentage;\n    }",
        "explanations_by_ours": [
            "The width of the image that is being cropped.",
            "The height of the image that is being cropped.",
            "The height of the image."
        ],
        "corrections_by_ours": [
            "height",
            "width",
            "cropped",
            "image"
        ],
        "corrections_by_baseline": [
            "icnt",
            "rtn",
            "xstell",
            "rtc",
            "ft",
            "cdr",
            "idrct",
            "calt",
            "sinc",
            "trd"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "redulh",
        "original_variable": "result",
        "typo_variable": "redulh",
        "original_code": "public void setTrajectoryInfo( Config trajConfig )\n          throws IOException\n  {\n    if ( timeDim != null )\n      throw new IllegalStateException( \"The setTrajectoryInfo() method can only be called once.\");\n\n    this.trajectoryId = trajConfig.getTrajectoryId();\n    this.timeDim = trajConfig.getTimeDim();\n    this.timeVar = trajConfig.getTimeVar();\n    this.latVar = trajConfig.getLatVar();\n    this.lonVar = trajConfig.getLonVar();\n    this.elevVar = trajConfig.getElevVar();\n\n    trajectoryNumPoint = this.timeDim.getLength();\n    timeVarUnitsString = this.timeVar.findAttribute( \"units\" ).getStringValue();\n\n    // Check that time, lat, lon, elev units are acceptable.\n    if ( DateUnit.getStandardDate( timeVarUnitsString ) == null )\n    {\n      throw new IllegalArgumentException( \"Units of time variable <\" + timeVarUnitsString + \"> not a date unit.\" );\n    }\n    String latVarUnitsString = this.latVar.findAttribute( \"units\").getStringValue();\n    if ( ! SimpleUnit.isCompatible( latVarUnitsString, \"degrees_north\" ) )\n    {\n      throw new IllegalArgumentException( \"Units of lat var <\" + latVarUnitsString + \"> not compatible with \\\"degrees_north\\\".\" );\n    }\n    String lonVarUnitsString = this.lonVar.findAttribute( \"units\" ).getStringValue();\n    if ( !SimpleUnit.isCompatible( lonVarUnitsString, \"degrees_east\" ) )\n    {\n      throw new IllegalArgumentException( \"Units of lon var <\" + lonVarUnitsString + \"> not compatible with \\\"degrees_east\\\".\" );\n    }\n    String elevVarUnitsString = this.elevVar.findAttribute( \"units\" ).getStringValue();\n    if ( !SimpleUnit.isCompatible( elevVarUnitsString, \"meters\" ) )\n    {\n      throw new IllegalArgumentException( \"Units of elev var <\" + elevVarUnitsString + \"> not compatible with \\\"meters\\\".\" );\n    }\n\n    try\n    {\n      elevVarUnitsConversionFactor = getMetersConversionFactor( elevVarUnitsString);\n    }\n    catch ( Exception e )\n    {\n      throw new IllegalArgumentException( \"Exception on getMetersConversionFactor() for the units of elev var <\" + elevVarUnitsString + \">.\" );\n    }\n\n    if ( this.netcdfDataset.hasUnlimitedDimension() && this.netcdfDataset.getUnlimitedDimension().equals( timeDim ) )\n    {\n      Object result = this.netcdfDataset.sendIospMessage(NetcdfFile.IOSP_MESSAGE_ADD_RECORD_STRUCTURE);\n      if ((result != null) && (Boolean) result )\n        this.recordVar = (Structure) this.netcdfDataset.getRootGroup().findVariable( \"record\");\n      else\n        this.recordVar = new StructurePseudo( this.netcdfDataset, null, \"record\", timeDim );\n    } else {\n      this.recordVar = new StructurePseudo( this.netcdfDataset, null, \"record\", timeDim);\n    }\n\n    // @todo HACK, HACK, HACK - remove once addRecordStructure() deals with ncd attribute changes.\n    Variable elevVarInRecVar = this.recordVar.findVariable( this.elevVar.getFullNameEscaped());\n    if ( ! elevVarUnitsString.equals( elevVarInRecVar.findAttribute( \"units\").getStringValue()))\n    {\n      elevVarInRecVar.addAttribute( new Attribute( \"units\", elevVarUnitsString));\n    }\n\n    trajectoryVarsMap = new HashMap();\n    //for ( Iterator it = this.recordVar.getVariables().iterator(); it.hasNext(); )\n    for ( Iterator it = this.netcdfDataset.getRootGroup().getVariables().iterator(); it.hasNext(); )\n    {\n      Variable curVar = (Variable) it.next();\n      if ( curVar.getRank() > 0 &&\n           !curVar.equals( this.timeVar) &&\n           ! curVar.equals( this.latVar) &&\n           ! curVar.equals( this.lonVar) &&\n           ! curVar.equals( this.elevVar) &&\n           ( this.recordVar == null ? true : ! curVar.equals( this.recordVar)))\n      {\n        MyTypedDataVariable typedVar = new MyTypedDataVariable( new VariableDS(  null, curVar, true ) );\n        dataVariables.add( typedVar);\n        trajectoryVarsMap.put( typedVar.getShortName(), typedVar);\n      }\n    }\n\n    trajectory = new SingleTrajectory( this.trajectoryId, trajectoryNumPoint,\n                                       this.timeVar, timeVarUnitsString,\n                                       this.latVar, this.lonVar, this.elevVar,\n                                       dataVariables, trajectoryVarsMap);\n\n    startDate = trajectory.getTime( 0);\n    endDate = trajectory.getTime( trajectoryNumPoint - 1);\n\n    ( (SingleTrajectory) trajectory).setStartDate( startDate );\n    ( (SingleTrajectory) trajectory).setEndDate( endDate );\n  }",
        "modified_code": "public void setTrajectoryInfo( Config trajConfig )\n          throws IOException\n  {\n    if ( timeDim != null )\n      throw new IllegalStateException( \"The setTrajectoryInfo() method can only be called once.\");\n\n    this.trajectoryId = trajConfig.getTrajectoryId();\n    this.timeDim = trajConfig.getTimeDim();\n    this.timeVar = trajConfig.getTimeVar();\n    this.latVar = trajConfig.getLatVar();\n    this.lonVar = trajConfig.getLonVar();\n    this.elevVar = trajConfig.getElevVar();\n\n    trajectoryNumPoint = this.timeDim.getLength();\n    timeVarUnitsString = this.timeVar.findAttribute( \"units\" ).getStringValue();\n\n    // Check that time, lat, lon, elev units are acceptable.\n    if ( DateUnit.getStandardDate( timeVarUnitsString ) == null )\n    {\n      throw new IllegalArgumentException( \"Units of time variable <\" + timeVarUnitsString + \"> not a date unit.\" );\n    }\n    String latVarUnitsString = this.latVar.findAttribute( \"units\").getStringValue();\n    if ( ! SimpleUnit.isCompatible( latVarUnitsString, \"degrees_north\" ) )\n    {\n      throw new IllegalArgumentException( \"Units of lat var <\" + latVarUnitsString + \"> not compatible with \\\"degrees_north\\\".\" );\n    }\n    String lonVarUnitsString = this.lonVar.findAttribute( \"units\" ).getStringValue();\n    if ( !SimpleUnit.isCompatible( lonVarUnitsString, \"degrees_east\" ) )\n    {\n      throw new IllegalArgumentException( \"Units of lon var <\" + lonVarUnitsString + \"> not compatible with \\\"degrees_east\\\".\" );\n    }\n    String elevVarUnitsString = this.elevVar.findAttribute( \"units\" ).getStringValue();\n    if ( !SimpleUnit.isCompatible( elevVarUnitsString, \"meters\" ) )\n    {\n      throw new IllegalArgumentException( \"Units of elev var <\" + elevVarUnitsString + \"> not compatible with \\\"meters\\\".\" );\n    }\n\n    try\n    {\n      elevVarUnitsConversionFactor = getMetersConversionFactor( elevVarUnitsString);\n    }\n    catch ( Exception e )\n    {\n      throw new IllegalArgumentException( \"Exception on getMetersConversionFactor() for the units of elev var <\" + elevVarUnitsString + \">.\" );\n    }\n\n    if ( this.netcdfDataset.hasUnlimitedDimension() && this.netcdfDataset.getUnlimitedDimension().equals( timeDim ) )\n    {\n      Object redulh = this.netcdfDataset.sendIospMessage(NetcdfFile.IOSP_MESSAGE_ADD_RECORD_STRUCTURE);\n      if ((redulh != null) && (Boolean) redulh )\n        this.recordVar = (Structure) this.netcdfDataset.getRootGroup().findVariable( \"record\");\n      else\n        this.recordVar = new StructurePseudo( this.netcdfDataset, null, \"record\", timeDim );\n    } else {\n      this.recordVar = new StructurePseudo( this.netcdfDataset, null, \"record\", timeDim);\n    }\n\n    // @todo HACK, HACK, HACK - remove once addRecordStructure() deals with ncd attribute changes.\n    Variable elevVarInRecVar = this.recordVar.findVariable( this.elevVar.getFullNameEscaped());\n    if ( ! elevVarUnitsString.equals( elevVarInRecVar.findAttribute( \"units\").getStringValue()))\n    {\n      elevVarInRecVar.addAttribute( new Attribute( \"units\", elevVarUnitsString));\n    }\n\n    trajectoryVarsMap = new HashMap();\n    //for ( Iterator it = this.recordVar.getVariables().iterator(); it.hasNext(); )\n    for ( Iterator it = this.netcdfDataset.getRootGroup().getVariables().iterator(); it.hasNext(); )\n    {\n      Variable curVar = (Variable) it.next();\n      if ( curVar.getRank() > 0 &&\n           !curVar.equals( this.timeVar) &&\n           ! curVar.equals( this.latVar) &&\n           ! curVar.equals( this.lonVar) &&\n           ! curVar.equals( this.elevVar) &&\n           ( this.recordVar == null ? true : ! curVar.equals( this.recordVar)))\n      {\n        MyTypedDataVariable typedVar = new MyTypedDataVariable( new VariableDS(  null, curVar, true ) );\n        dataVariables.add( typedVar);\n        trajectoryVarsMap.put( typedVar.getShortName(), typedVar);\n      }\n    }\n\n    trajectory = new SingleTrajectory( this.trajectoryId, trajectoryNumPoint,\n                                       this.timeVar, timeVarUnitsString,\n                                       this.latVar, this.lonVar, this.elevVar,\n                                       dataVariables, trajectoryVarsMap);\n\n    startDate = trajectory.getTime( 0);\n    endDate = trajectory.getTime( trajectoryNumPoint - 1);\n\n    ( (SingleTrajectory) trajectory).setStartDate( startDate );\n    ( (SingleTrajectory) trajectory).setEndDate( endDate );\n  }",
        "explanations_by_ours": [
            "the configuration to set the trajectory information from.",
            "the configuration to set the trajectory information.",
            "the configuration to set the trajectory information to."
        ],
        "corrections_by_ours": [
            "trajectory",
            "set",
            "information",
            "configuration"
        ],
        "corrections_by_baseline": [
            "red",
            "resul",
            "rhash",
            "LULC",
            "calt",
            "h_straight",
            "clash",
            "dub",
            "xh",
            "ybeg"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rssulh",
        "original_variable": "result",
        "typo_variable": "rssulh",
        "original_code": "public Set<String> getReferencedRAEntityLinksWhichNotExists(\n\t\t\tServiceComponent serviceComponent) {\n\t\tSet<String> result = new HashSet<String>();\n\t\tSet<String> raLinkNames = sleeContainer.getResourceManagement()\n\t\t\t\t.getLinkNamesSet();\n\t\tfor (String raLink : serviceComponent\n\t\t\t\t.getResourceAdaptorEntityLinks(componentRepositoryImpl)) {\n\t\t\tif (!raLinkNames.contains(raLink)) {\n\t\t\t\tresult.add(raLink);\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public Set<String> getReferencedRAEntityLinksWhichNotExists(\n\t\t\tServiceComponent serviceComponent) {\n\t\tSet<String> rssulh = new HashSet<String>();\n\t\tSet<String> raLinkNames = sleeContainer.getResourceManagement()\n\t\t\t\t.getLinkNamesSet();\n\t\tfor (String raLink : serviceComponent\n\t\t\t\t.getResourceAdaptorEntityLinks(componentRepositoryImpl)) {\n\t\t\tif (!raLinkNames.contains(raLink)) {\n\t\t\t\trssulh.add(raLink);\n\t\t\t}\n\t\t}\n\t\treturn rssulh;\n\t}",
        "explanations_by_ours": [
            "the set of referenced entity links which do not exist in the resource manager",
            "the set of referenced entity links",
            "the set of referenced entity links which should not exist in the resource manager"
        ],
        "corrections_by_ours": [
            "resource",
            "set",
            "referenced",
            "exist",
            "entity",
            "manager",
            "links"
        ],
        "corrections_by_baseline": [
            "rssi",
            "hb",
            "hf",
            "pdh",
            "longRepPrice",
            "barbershop",
            "sfb",
            "hornetqServer",
            "shortRepPrice",
            "newsort"
        ]
    },
    {
        "original_word": "declared",
        "typo_word": "reclafed",
        "original_variable": "declaredTypes",
        "typo_variable": "reclafedTypes",
        "original_code": "public static Class[] findParameterTypes(Class type, Method m)\n    {\n        Type[] genTypes = m.getGenericParameterTypes();\n        Class[] types = new Class[genTypes.length];;\n        boolean noGenericParameter = true;\n        for (int i=0; i < genTypes.length; i++)\n        {\n            if (Class.class.isInstance(genTypes[i]))\n            {\n                types[i] = (Class) genTypes[i];\n                continue;\n            }\n            noGenericParameter = false;\n            break;\n        }\n        if (noGenericParameter)\n        {\n            return types;\n        }\n\n        if (type == null || !isJdk15())\n        {\n            return getParameterTypes(m);\n        }\n\n        final Type typeGenericSuperclass = type.getGenericSuperclass();\n        if (typeGenericSuperclass == null\n            || !ParameterizedType.class.isInstance(typeGenericSuperclass)\n            || m.getDeclaringClass().getTypeParameters() == null)\n        {\n            return getParameterTypes(m);\n        }\n\n        if ((types = (Class[]) _genericMethodParameterTypesCache.get(m)) != null)\n        {\n            ParameterizedType genericSuperclass = (ParameterizedType) typeGenericSuperclass;\n            if (Arrays.equals(types, genericSuperclass.getActualTypeArguments())) {\n                return types;\n            }\n        }\n\n        ParameterizedType param = (ParameterizedType)typeGenericSuperclass;\n        TypeVariable[] declaredTypes = m.getDeclaringClass().getTypeParameters();\n\n        types = new Class[genTypes.length];\n\n        for (int i=0; i < genTypes.length; i++)\n        {\n            TypeVariable paramType = null;\n\n            if (TypeVariable.class.isInstance(genTypes[i]))\n            {\n                paramType = (TypeVariable)genTypes[i];\n            } else if (GenericArrayType.class.isInstance(genTypes[i]))\n            {\n                paramType = (TypeVariable) ((GenericArrayType)genTypes[i]).getGenericComponentType();\n            }\n            else if (ParameterizedType.class.isInstance(genTypes[i]))\n            {\n                 types[i] = (Class) ((ParameterizedType) genTypes[i]).getRawType();\n                 continue;\n            } else if (Class.class.isInstance(genTypes[i]))\n            {\n                types[i] = (Class) genTypes[i];\n                continue;\n            }\n\n            Class resolved = resolveType(param, paramType, declaredTypes);\n\n            if (resolved != null)\n            {\n                if (GenericArrayType.class.isInstance(genTypes[i]))\n                {\n                    resolved = Array.newInstance(resolved, 0).getClass();\n                }\n\n                types[i] = resolved;\n                continue;\n            }\n\n            types[i] = m.getParameterTypes()[i];\n        }\n\n        synchronized (_genericMethodParameterTypesCache)\n        {\n            _genericMethodParameterTypesCache.put(m, types);\n        }\n\n        return types;\n    }",
        "modified_code": "public static Class[] findParameterTypes(Class type, Method m)\n    {\n        Type[] genTypes = m.getGenericParameterTypes();\n        Class[] types = new Class[genTypes.length];;\n        boolean noGenericParameter = true;\n        for (int i=0; i < genTypes.length; i++)\n        {\n            if (Class.class.isInstance(genTypes[i]))\n            {\n                types[i] = (Class) genTypes[i];\n                continue;\n            }\n            noGenericParameter = false;\n            break;\n        }\n        if (noGenericParameter)\n        {\n            return types;\n        }\n\n        if (type == null || !isJdk15())\n        {\n            return getParameterTypes(m);\n        }\n\n        final Type typeGenericSuperclass = type.getGenericSuperclass();\n        if (typeGenericSuperclass == null\n            || !ParameterizedType.class.isInstance(typeGenericSuperclass)\n            || m.getDeclaringClass().getTypeParameters() == null)\n        {\n            return getParameterTypes(m);\n        }\n\n        if ((types = (Class[]) _genericMethodParameterTypesCache.get(m)) != null)\n        {\n            ParameterizedType genericSuperclass = (ParameterizedType) typeGenericSuperclass;\n            if (Arrays.equals(types, genericSuperclass.getActualTypeArguments())) {\n                return types;\n            }\n        }\n\n        ParameterizedType param = (ParameterizedType)typeGenericSuperclass;\n        TypeVariable[] reclafedTypes = m.getDeclaringClass().getTypeParameters();\n\n        types = new Class[genTypes.length];\n\n        for (int i=0; i < genTypes.length; i++)\n        {\n            TypeVariable paramType = null;\n\n            if (TypeVariable.class.isInstance(genTypes[i]))\n            {\n                paramType = (TypeVariable)genTypes[i];\n            } else if (GenericArrayType.class.isInstance(genTypes[i]))\n            {\n                paramType = (TypeVariable) ((GenericArrayType)genTypes[i]).getGenericComponentType();\n            }\n            else if (ParameterizedType.class.isInstance(genTypes[i]))\n            {\n                 types[i] = (Class) ((ParameterizedType) genTypes[i]).getRawType();\n                 continue;\n            } else if (Class.class.isInstance(genTypes[i]))\n            {\n                types[i] = (Class) genTypes[i];\n                continue;\n            }\n\n            Class resolved = resolveType(param, paramType, reclafedTypes);\n\n            if (resolved != null)\n            {\n                if (GenericArrayType.class.isInstance(genTypes[i]))\n                {\n                    resolved = Array.newInstance(resolved, 0).getClass();\n                }\n\n                types[i] = resolved;\n                continue;\n            }\n\n            types[i] = m.getParameterTypes()[i];\n        }\n\n        synchronized (_genericMethodParameterTypesCache)\n        {\n            _genericMethodParameterTypesCache.put(m, types);\n        }\n\n        return types;\n    }",
        "explanations_by_ours": [
            "the reclafed types of the method",
            "the reclafed types of the method.",
            "the reclafed type parameters"
        ],
        "corrections_by_ours": [
            "reclafedType",
            "fedlafedTypes",
            "reclamethodTypes",
            "reclarecTypes",
            "typeslafedTypes",
            "parameterslafedTypes",
            "reclatypesTypes",
            "reclafedParameters",
            "reclafedFed",
            "reclafedRec"
        ],
        "corrections_by_baseline": [
            "mappedTypes",
            "localTypes",
            "typeRelocatedOrdinals",
            "typesToCompact",
            "mergedType",
            "declaredTypes",
            "supIdenTypes",
            "types",
            "processedTypes",
            "abstractValuetypes"
        ]
    },
    {
        "original_word": "space",
        "typo_word": "qpaxe",
        "original_variable": "spacePosition",
        "typo_variable": "qpaxePosition",
        "original_code": "public void registerTable(String tableName,\n                              GeoPackageCursorWrapper cursorWrapper) {\n\n        // Remove an existing cursor wrapper\n        tableCursors.remove(tableName);\n\n        // Add the wrapper\n        tableCursors.put(tableName, cursorWrapper);\n        String quotedTableName = CoreSQLUtils.quoteWrap(tableName);\n        tableCursors.put(quotedTableName, cursorWrapper);\n\n        // The Android android.database.sqlite.SQLiteDatabase findEditTable method\n        // finds the new cursor edit table name based upon the first space or comma.\n        // Fix (hopefully temporary) to wrap with the expected cursor type\n        int spacePosition = tableName.indexOf(' ');\n        if (spacePosition > 0) {\n            tableCursors.put(tableName.substring(0, spacePosition), cursorWrapper);\n            tableCursors.put(quotedTableName.substring(0, quotedTableName.indexOf(' ')), cursorWrapper);\n        }\n\n    }",
        "modified_code": "public void registerTable(String tableName,\n                              GeoPackageCursorWrapper cursorWrapper) {\n\n        // Remove an existing cursor wrapper\n        tableCursors.remove(tableName);\n\n        // Add the wrapper\n        tableCursors.put(tableName, cursorWrapper);\n        String quotedTableName = CoreSQLUtils.quoteWrap(tableName);\n        tableCursors.put(quotedTableName, cursorWrapper);\n\n        // The Android android.database.sqlite.SQLiteDatabase findEditTable method\n        // finds the new cursor edit table name based upon the first space or comma.\n        // Fix (hopefully temporary) to wrap with the expected cursor type\n        int qpaxePosition = tableName.indexOf(' ');\n        if (qpaxePosition > 0) {\n            tableCursors.put(tableName.substring(0, qpaxePosition), cursorWrapper);\n            tableCursors.put(quotedTableName.substring(0, quotedTableName.indexOf(' ')), cursorWrapper);\n        }\n\n    }",
        "explanations_by_ours": [
            "the position of the first space or comma in the table name",
            "the index of the first space or comma in the table name",
            "the position of the first space or comma"
        ],
        "corrections_by_ours": [
            "spacePosition",
            "namePosition",
            "indexPosition",
            "tablePosition",
            "qpaxeIndex",
            "qpaxeComma",
            "qpaxeFirst",
            "qpaxeSpace",
            "commaPosition",
            "positionPosition"
        ],
        "corrections_by_baseline": [
            "position",
            "hwmPosition",
            "proposedPosition",
            "finalPosition",
            "positionOne",
            "newPosition",
            "viewPosition",
            "dataPosition",
            "positionString",
            "senderPosition"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resjot",
        "original_variable": "result",
        "typo_variable": "resjot",
        "original_code": "private int getListHash() {\r\n    if (subKeys == null) return 0;\r\n    int result = 1;\r\n    for (DataDescriptor e : subKeys)\r\n      result = 31*result + (e==null ? 0 : e.hashCode2());\r\n    return result;\r\n  }",
        "modified_code": "private int getListHash() {\r\n    if (subKeys == null) return 0;\r\n    int resjot = 1;\r\n    for (DataDescriptor e : subKeys)\r\n      resjot = 31*resjot + (e==null ? 0 : e.hashCode2());\r\n    return resjot;\r\n  }",
        "explanations_by_ours": [
            "The hash code of the list.",
            "The result of the hash code.",
            "The result of the hash code"
        ],
        "corrections_by_ours": [
            "resultjot",
            "hashjot",
            "listjot",
            "reslist",
            "rescode",
            "resresult",
            "codejot",
            "reshash",
            "resjot"
        ],
        "corrections_by_baseline": [
            "resul",
            "res",
            "rj",
            "jout",
            "oj",
            "rv",
            "jbeg",
            "ot",
            "iproj",
            "jg"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "cutrrnt",
        "original_variable": "current",
        "typo_variable": "cutrrnt",
        "original_code": "private void incReadLockCount() {\n        Integer current = readLockCount.get();\n        int next;\n        if (current == null)\n            next = 1;\n        else\n            next = current.intValue() + 1;\n        readLockCount.set(new Integer(next));\n    }",
        "modified_code": "private void incReadLockCount() {\n        Integer cutrrnt = readLockCount.get();\n        int next;\n        if (cutrrnt == null)\n            next = 1;\n        else\n            next = cutrrnt.intValue() + 1;\n        readLockCount.set(new Integer(next));\n    }",
        "explanations_by_ours": [
            "the current read lock count",
            "the read lock count",
            "the current read lock count."
        ],
        "corrections_by_ours": [
            "current",
            "count",
            "read",
            "lock"
        ],
        "corrections_by_baseline": [
            "qrcode",
            "idrct",
            "rcidpe",
            "missnum",
            "reqno",
            "rr",
            "icnt",
            "errmsg",
            "idr",
            "recno"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "ciknt",
        "original_variable": "count",
        "typo_variable": "ciknt",
        "original_code": "private void initLocalTable() {\n    String tableName = config.getPath();\n    ClassLoader cl = this.getClass().getClassLoader();\n    try (InputStream is = cl.getResourceAsStream(tableName)) {\n      if (is == null) {\n        throw new IllegalStateException(\"Cant find \" + tableName);\n      }\n      try (BufferedReader br = new BufferedReader(new InputStreamReader(is, CDM.utf8Charset))) {\n        while (true) {\n          String line = br.readLine();\n          if (line == null) {\n            break;\n          }\n          if ((line.length() == 0) || line.startsWith(\"#\")) {\n            continue;\n          }\n          String[] flds = StringUtil2.splitString(line);\n\n          int p1 = Integer.parseInt(flds[0].trim()); // must have a number\n          int p2 = Integer.parseInt(flds[1].trim()); // must have a number\n          int p3 = Integer.parseInt(flds[2].trim()); // must have a number\n          StringBuilder b = new StringBuilder();\n          int count = 3;\n\n          while (count < flds.length && !flds[count].equals(\".\")) {\n            b.append(flds[count++]).append(' ');\n          }\n          String abbrev = b.toString().trim();\n          b.setLength(0);\n          count++;\n\n          while (count < flds.length && !flds[count].equals(\".\")) {\n            b.append(flds[count++]).append(' ');\n          }\n          String name = b.toString().trim();\n          b.setLength(0);\n          count++;\n\n          while (count < flds.length && !flds[count].equals(\".\")) {\n            b.append(flds[count++]).append(' ');\n          }\n          String unit = b.toString().trim();\n\n          Grib2Parameter s = new Grib2Parameter(p1, p2, p3, name, unit, abbrev, null);\n          local.put(makeParamId(p1, p2, p3), s);\n        }\n      }\n\n    } catch (IOException ioe) {\n      throw new RuntimeException(ioe);\n    }\n  }",
        "modified_code": "private void initLocalTable() {\n    String tableName = config.getPath();\n    ClassLoader cl = this.getClass().getClassLoader();\n    try (InputStream is = cl.getResourceAsStream(tableName)) {\n      if (is == null) {\n        throw new IllegalStateException(\"Cant find \" + tableName);\n      }\n      try (BufferedReader br = new BufferedReader(new InputStreamReader(is, CDM.utf8Charset))) {\n        while (true) {\n          String line = br.readLine();\n          if (line == null) {\n            break;\n          }\n          if ((line.length() == 0) || line.startsWith(\"#\")) {\n            continue;\n          }\n          String[] flds = StringUtil2.splitString(line);\n\n          int p1 = Integer.parseInt(flds[0].trim()); // must have a number\n          int p2 = Integer.parseInt(flds[1].trim()); // must have a number\n          int p3 = Integer.parseInt(flds[2].trim()); // must have a number\n          StringBuilder b = new StringBuilder();\n          int ciknt = 3;\n\n          while (ciknt < flds.length && !flds[ciknt].equals(\".\")) {\n            b.append(flds[ciknt++]).append(' ');\n          }\n          String abbrev = b.toString().trim();\n          b.setLength(0);\n          ciknt++;\n\n          while (ciknt < flds.length && !flds[ciknt].equals(\".\")) {\n            b.append(flds[ciknt++]).append(' ');\n          }\n          String name = b.toString().trim();\n          b.setLength(0);\n          ciknt++;\n\n          while (ciknt < flds.length && !flds[ciknt].equals(\".\")) {\n            b.append(flds[ciknt++]).append(' ');\n          }\n          String unit = b.toString().trim();\n\n          Grib2Parameter s = new Grib2Parameter(p1, p2, p3, name, unit, abbrev, null);\n          local.put(makeParamId(p1, p2, p3), s);\n        }\n      }\n\n    } catch (IOException ioe) {\n      throw new RuntimeException(ioe);\n    }\n  }",
        "explanations_by_ours": [
            "The number of fields in the field list.",
            "The number of fields in the table.",
            "The number of fields to include in the table."
        ],
        "corrections_by_ours": [
            "list",
            "field",
            "fields",
            "include",
            "table",
            "number"
        ],
        "corrections_by_baseline": [
            "kcnt",
            "icnt",
            "knt",
            "ci",
            "cnc",
            "jcnt",
            "ecint",
            "fci",
            "hcs",
            "cid"
        ]
    },
    {
        "original_word": "capacity",
        "typo_word": "capaxitt",
        "original_variable": "capacity",
        "typo_variable": "capaxitt",
        "original_code": "protected void doReadObject(ObjectInputStream in) throws IOException,\n            ClassNotFoundException {\n        loadFactor = in.readFloat();\n        int capacity = in.readInt();\n        int size = in.readInt();\n        init();\n        data = new HashEntry[capacity];\n        for (int i = 0; i < size; i++) {\n            K key = (K) in.readObject();\n            V value = (V) in.readObject();\n            put(key, value);\n        }\n        threshold = calculateThreshold(data.length, loadFactor);\n    }",
        "modified_code": "protected void doReadObject(ObjectInputStream in) throws IOException,\n            ClassNotFoundException {\n        loadFactor = in.readFloat();\n        int capaxitt = in.readInt();\n        int size = in.readInt();\n        init();\n        data = new HashEntry[capaxitt];\n        for (int i = 0; i < size; i++) {\n            K key = (K) in.readObject();\n            V value = (V) in.readObject();\n            put(key, value);\n        }\n        threshold = calculateThreshold(data.length, loadFactor);\n    }",
        "explanations_by_ours": [
            "the size of the array",
            "the capacity of the array",
            "the capacity of the data"
        ],
        "corrections_by_ours": [
            "capacity",
            "data",
            "array",
            "size"
        ],
        "corrections_by_baseline": [
            "cap",
            "applet",
            "ca",
            "opc",
            "sleeAci",
            "app",
            "cla",
            "application",
            "pex",
            "callSite"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "dtadt",
        "original_variable": "start",
        "typo_variable": "dtadt",
        "original_code": "public void initializeDataModel(HollowSchema... schemas) {\n        Objects.requireNonNull(schemas);\n        if (schemas.length == 0) {\n            throw new IllegalArgumentException(\"classes is empty\");\n        }\n\n        long start = currentTimeMillis();\n        HollowWriteStateCreator.populateStateEngineWithTypeWriteStates(getWriteEngine(), Arrays.asList(schemas));\n        listeners.listeners().fireProducerInit(currentTimeMillis() - start);\n\n        isInitialized = true;\n    }",
        "modified_code": "public void initializeDataModel(HollowSchema... schemas) {\n        Objects.requireNonNull(schemas);\n        if (schemas.length == 0) {\n            throw new IllegalArgumentException(\"classes is empty\");\n        }\n\n        long dtadt = currentTimeMillis();\n        HollowWriteStateCreator.populateStateEngineWithTypeWriteStates(getWriteEngine(), Arrays.asList(schemas));\n        listeners.listeners().fireProducerInit(currentTimeMillis() - dtadt);\n\n        isInitialized = true;\n    }",
        "explanations_by_ours": [
            "the time at which the data model is initialized.",
            "the time at which the data model is initialized",
            "the time at which the data model should be initialized"
        ],
        "corrections_by_ours": [
            "data",
            "time",
            "initialized",
            "model"
        ],
        "corrections_by_baseline": [
            "dt",
            "tlv",
            "aLDT",
            "dproto",
            "tcm",
            "dti",
            "dtc",
            "tmi",
            "trd",
            "tad"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "couby",
        "original_variable": "count",
        "typo_variable": "couby",
        "original_code": "public static String cleanup(byte[] h) {\r\n    byte[] bb = new byte[h.length];\r\n    int count = 0;\r\n    for (byte b : h) {\r\n      if (b >= 32 && b < 127)\r\n        bb[count++] = b;\r\n    }\r\n    return new String(bb, 0, count, CDM.utf8Charset);\r\n  }",
        "modified_code": "public static String cleanup(byte[] h) {\r\n    byte[] bb = new byte[h.length];\r\n    int couby = 0;\r\n    for (byte b : h) {\r\n      if (b >= 32 && b < 127)\r\n        bb[couby++] = b;\r\n    }\r\n    return new String(bb, 0, couby, CDM.utf8Charset);\r\n  }",
        "explanations_by_ours": [
            "the number of characters in the byte array",
            "the number of bytes to clean up",
            "the number of characters in the cleaned up byte array"
        ],
        "corrections_by_ours": [
            "clean",
            "array",
            "number",
            "cleaned",
            "characters",
            "byte",
            "bytes"
        ],
        "corrections_by_baseline": [
            "lycent",
            "xcent",
            "coun",
            "dou",
            "lxcent",
            "boustr",
            "caw",
            "cir",
            "ycent",
            "cgaw"
        ]
    },
    {
        "original_word": "source",
        "typo_word": "siurse",
        "original_variable": "source",
        "typo_variable": "siurse",
        "original_code": "<T> BindingImpl<T> createProvidedByBinding(\n      Key<T> key, Scoping scoping, ProvidedBy providedBy, Errors errors) throws ErrorsException {\n    Class<?> rawType = key.getTypeLiteral().getRawType();\n    Class<? extends javax.inject.Provider<?>> providerType = providedBy.value();\n\n    // Make sure it's not the same type. TODO: Can we check for deeper loops?\n    if (providerType == rawType) {\n      throw errors.recursiveProviderType().toException();\n    }\n\n    // Assume the provider provides an appropriate type. We double check at runtime.\n    @SuppressWarnings(\"unchecked\")\n    Key<? extends Provider<T>> providerKey = (Key<? extends Provider<T>>) Key.get(providerType);\n    ProvidedByInternalFactory<T> internalFactory =\n        new ProvidedByInternalFactory<T>(rawType, providerType, providerKey);\n    Object source = rawType;\n    BindingImpl<T> binding =\n        LinkedProviderBindingImpl.createWithInitializer(\n            this,\n            key,\n            source,\n            Scoping.<T>scope(key, this, internalFactory, source, scoping),\n            scoping,\n            providerKey,\n            internalFactory);\n    internalFactory.setProvisionListenerCallback(provisionListenerStore.get(binding));\n    return binding;\n  }",
        "modified_code": "<T> BindingImpl<T> createProvidedByBinding(\n      Key<T> key, Scoping scoping, ProvidedBy providedBy, Errors errors) throws ErrorsException {\n    Class<?> rawType = key.getTypeLiteral().getRawType();\n    Class<? extends javax.inject.Provider<?>> providerType = providedBy.value();\n\n    // Make sure it's not the same type. TODO: Can we check for deeper loops?\n    if (providerType == rawType) {\n      throw errors.recursiveProviderType().toException();\n    }\n\n    // Assume the provider provides an appropriate type. We double check at runtime.\n    @SuppressWarnings(\"unchecked\")\n    Key<? extends Provider<T>> providerKey = (Key<? extends Provider<T>>) Key.get(providerType);\n    ProvidedByInternalFactory<T> internalFactory =\n        new ProvidedByInternalFactory<T>(rawType, providerType, providerKey);\n    Object siurse = rawType;\n    BindingImpl<T> binding =\n        LinkedProviderBindingImpl.createWithInitializer(\n            this,\n            key,\n            siurse,\n            Scoping.<T>scope(key, this, internalFactory, siurse, scoping),\n            scoping,\n            providerKey,\n            internalFactory);\n    internalFactory.setProvisionListenerCallback(provisionListenerStore.get(binding));\n    return binding;\n  }",
        "explanations_by_ours": [
            "the siurse of the binding.",
            "the siurse for the binding.",
            "the siurse of the binding"
        ],
        "corrections_by_ours": [
            "binding"
        ],
        "corrections_by_baseline": [
            "recurse",
            "si",
            "intermediate",
            "positionalTraverser",
            "sleeAci",
            "baseDepth",
            "TOLERENCE",
            "symWalker",
            "sda",
            "SDA"
        ]
    },
    {
        "original_word": "Writable",
        "typo_word": "Wfitabpe",
        "original_variable": "isWritable",
        "typo_variable": "isWfitabpe",
        "original_code": "private boolean isWritable(ModelNode node, List<SimpleAttributeDefinition> attributeDefinitions) {\n        boolean isWritable = false;\n        for (SimpleAttributeDefinition attributeDefinition : attributeDefinitions) {\n            if (attributeDefinition.isMarshallable(node)) {\n                isWritable = true;\n                break;\n            }\n        }\n        return isWritable;\n    }",
        "modified_code": "private boolean isWfitabpe(ModelNode node, List<SimpleAttributeDefinition> attributeDefinitions) {\n        boolean isWfitabpe = false;\n        for (SimpleAttributeDefinition attributeDefinition : attributeDefinitions) {\n            if (attributeDefinition.isMarshallable(node)) {\n                isWfitabpe = true;\n                break;\n            }\n        }\n        return isWfitabpe;\n    }",
        "explanations_by_ours": [
            "true if the node is a WFitabpe node",
            "whether the node is a WFitabpe node",
            "whether the node is a WFitabpe node or not"
        ],
        "corrections_by_ours": [
            "isFitabpe",
            "isWhether",
            "isTrue",
            "fitabpeWfitabpe",
            "isW",
            "isNode",
            "isWfitabpe",
            "wWfitabpe",
            "nodeWfitabpe",
            "whetherWfitabpe"
        ],
        "corrections_by_baseline": [
            "isGrib2",
            "isGrib1",
            "isLayer",
            "amfb",
            "isGrid",
            "bsf",
            "bs_abs_bord",
            "proxyscope",
            "isFmrc",
            "gdattim"
        ]
    },
    {
        "original_word": "xaxis",
        "typo_word": "daxus",
        "original_variable": "xaxis",
        "typo_variable": "daxus",
        "original_code": "public void writeGrid(GeoReferencedArray array, boolean greyScale) throws IOException {\n\n    CoverageCoordSys gcs = array.getCoordSysForData();\n    if (!gcs.isRegularSpatial())\n      throw new IllegalArgumentException(\"Must have 1D x and y axes for \" + array.getCoverageName());\n\n    Projection proj = gcs.getProjection();\n    CoverageCoordAxis1D xaxis = (CoverageCoordAxis1D) gcs.getXAxis();\n    CoverageCoordAxis1D yaxis = (CoverageCoordAxis1D) gcs.getYAxis();\n\n    // latlon coord does not need to be scaled\n    double scaler = (xaxis.getUnits().equalsIgnoreCase(\"km\")) ? 1000.0 : 1.0;\n\n    // data must go from top to bottom\n    double xStart = xaxis.getCoordEdge1(0) * scaler;\n    double yStart = yaxis.getCoordEdge1(0) * scaler;\n    double xInc = xaxis.getResolution() * scaler;\n    double yInc = Math.abs(yaxis.getResolution()) * scaler;\n\n    Array data = array.getData().reduce();\n    if (yaxis.getCoordMidpoint(0) < yaxis.getCoordMidpoint(1)) {\n      data = data.flip(0);\n      yStart = yaxis.getCoordEdgeLast();\n    }\n\n    /*  remove - i think unneeded, monotonic lon handled in CoordinateAxis1D. JC 3/18/2013\n     if (gcs.isLatLon()) {\n      Array lon = xaxis.read();\n      data = geoShiftDataAtLon(data, lon);\n      xStart = geoShiftGetXstart(lon, xInc);\n      //xStart = -180.0;\n    }  */\n\n    if (pageNumber > 1) {\n      geotiff.initTags();\n    }\n\n    // write the data first\n    int nextStart = 0;\n    MAMath.MinMax dataMinMax = MAMath.getMinMaxSkipMissingData(data, array);\n    if (greyScale) {\n      ArrayByte result = replaceMissingValuesAndScale(array, data, dataMinMax);\n      nextStart = geotiff.writeData((byte[]) result.getStorage(), pageNumber);\n    } else {\n      ArrayFloat result = replaceMissingValues(array, data, dataMinMax);\n      nextStart = geotiff.writeData((float[]) result.getStorage(), pageNumber);\n    }\n\n    // set the width and the height\n    int height = data.getShape()[0];         // Y\n    int width = data.getShape()[1];         // X\n\n    writeMetadata(greyScale, xStart, yStart, xInc, yInc, height, width, pageNumber, nextStart, dataMinMax, proj);\n    pageNumber++;\n  }",
        "modified_code": "public void writeGrid(GeoReferencedArray array, boolean greyScale) throws IOException {\n\n    CoverageCoordSys gcs = array.getCoordSysForData();\n    if (!gcs.isRegularSpatial())\n      throw new IllegalArgumentException(\"Must have 1D x and y axes for \" + array.getCoverageName());\n\n    Projection proj = gcs.getProjection();\n    CoverageCoordAxis1D daxus = (CoverageCoordAxis1D) gcs.getXAxis();\n    CoverageCoordAxis1D yaxis = (CoverageCoordAxis1D) gcs.getYAxis();\n\n    // latlon coord does not need to be scaled\n    double scaler = (daxus.getUnits().equalsIgnoreCase(\"km\")) ? 1000.0 : 1.0;\n\n    // data must go from top to bottom\n    double xStart = daxus.getCoordEdge1(0) * scaler;\n    double yStart = yaxis.getCoordEdge1(0) * scaler;\n    double xInc = daxus.getResolution() * scaler;\n    double yInc = Math.abs(yaxis.getResolution()) * scaler;\n\n    Array data = array.getData().reduce();\n    if (yaxis.getCoordMidpoint(0) < yaxis.getCoordMidpoint(1)) {\n      data = data.flip(0);\n      yStart = yaxis.getCoordEdgeLast();\n    }\n\n    /*  remove - i think unneeded, monotonic lon handled in CoordinateAxis1D. JC 3/18/2013\n     if (gcs.isLatLon()) {\n      Array lon = xaxis.read();\n      data = geoShiftDataAtLon(data, lon);\n      xStart = geoShiftGetXstart(lon, xInc);\n      //xStart = -180.0;\n    }  */\n\n    if (pageNumber > 1) {\n      geotiff.initTags();\n    }\n\n    // write the data first\n    int nextStart = 0;\n    MAMath.MinMax dataMinMax = MAMath.getMinMaxSkipMissingData(data, array);\n    if (greyScale) {\n      ArrayByte result = replaceMissingValuesAndScale(array, data, dataMinMax);\n      nextStart = geotiff.writeData((byte[]) result.getStorage(), pageNumber);\n    } else {\n      ArrayFloat result = replaceMissingValues(array, data, dataMinMax);\n      nextStart = geotiff.writeData((float[]) result.getStorage(), pageNumber);\n    }\n\n    // set the width and the height\n    int height = data.getShape()[0];         // Y\n    int width = data.getShape()[1];         // X\n\n    writeMetadata(greyScale, xStart, yStart, xInc, yInc, height, width, pageNumber, nextStart, dataMinMax, proj);\n    pageNumber++;\n  }",
        "explanations_by_ours": [
            "the coordinate system for the data",
            "the coordinate axis for the data",
            "the coordinate system of the data"
        ],
        "corrections_by_ours": [
            "axis",
            "data",
            "coordinate",
            "system"
        ],
        "corrections_by_baseline": [
            "dca",
            "ejb3Subsystem",
            "jmx",
            "dbs",
            "dks",
            "dao",
            "xorg",
            "baos",
            "pdxInstance",
            "dcs"
        ]
    },
    {
        "original_word": "piece",
        "typo_word": "oiecd",
        "original_variable": "piece",
        "typo_variable": "oiecd",
        "original_code": "static public List<String>\n    backslashsplit(String s, char sep)\n    {\n        List<String> path = new ArrayList<String>();\n        int len = s.length();\n        StringBuilder piece = new StringBuilder();\n        int i = 0;\n        for(; i <= len - 1; i++) {\n            char c = s.charAt(i);\n            if(c == '\\\\' && i < (len - 1)) {\n                piece.append(c); // keep escapes in place\n                piece.append(s.charAt(++i));\n            } else if(c == sep) {\n                path.add(piece.toString());\n                piece.setLength(0);\n            } else\n                piece.append(c);\n        }\n        path.add(piece.toString());\n        return path;\n    }",
        "modified_code": "static public List<String>\n    backslashsplit(String s, char sep)\n    {\n        List<String> path = new ArrayList<String>();\n        int len = s.length();\n        StringBuilder oiecd = new StringBuilder();\n        int i = 0;\n        for(; i <= len - 1; i++) {\n            char c = s.charAt(i);\n            if(c == '\\\\' && i < (len - 1)) {\n                oiecd.append(c); // keep escapes in place\n                oiecd.append(s.charAt(++i));\n            } else if(c == sep) {\n                path.add(oiecd.toString());\n                oiecd.setLength(0);\n            } else\n                oiecd.append(c);\n        }\n        path.add(oiecd.toString());\n        return path;\n    }",
        "explanations_by_ours": [
            "the string to append to the path",
            "the string to append to the end of the path",
            "the string to be appended to the path"
        ],
        "corrections_by_ours": [
            "end",
            "append",
            "appended",
            "string",
            "path"
        ],
        "corrections_by_baseline": [
            "cd",
            "ncd",
            "subcd",
            "cdl",
            "tmcd",
            "gcd",
            "cdmnode",
            "dcs",
            "dcm",
            "gcdw"
        ]
    },
    {
        "original_word": "groups",
        "typo_word": "grojls",
        "original_variable": "groups",
        "typo_variable": "grojls",
        "original_code": "@Override\n\tprotected Collection<? extends GrantedAuthority> loadUserAuthorities(\n\t\t\tDirContextOperations userData, String username, String password) {\n\t\tString[] groups = userData.getStringAttributes(\"memberOf\");\n\n\t\tif (groups == null) {\n\t\t\tlogger.debug(\"No values for 'memberOf' attribute.\");\n\n\t\t\treturn AuthorityUtils.NO_AUTHORITIES;\n\t\t}\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"'memberOf' attribute values: \" + Arrays.asList(groups));\n\t\t}\n\n\t\tArrayList<GrantedAuthority> authorities = new ArrayList<>(\n\t\t\t\tgroups.length);\n\n\t\tfor (String group : groups) {\n\t\t\tauthorities.add(new SimpleGrantedAuthority(new DistinguishedName(group)\n\t\t\t\t\t.removeLast().getValue()));\n\t\t}\n\n\t\treturn authorities;\n\t}",
        "modified_code": "@Override\n\tprotected Collection<? extends GrantedAuthority> loadUserAuthorities(\n\t\t\tDirContextOperations userData, String username, String password) {\n\t\tString[] grojls = userData.getStringAttributes(\"memberOf\");\n\n\t\tif (grojls == null) {\n\t\t\tlogger.debug(\"No values for 'memberOf' attribute.\");\n\n\t\t\treturn AuthorityUtils.NO_AUTHORITIES;\n\t\t}\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"'memberOf' attribute values: \" + Arrays.asList(grojls));\n\t\t}\n\n\t\tArrayList<GrantedAuthority> authorities = new ArrayList<>(\n\t\t\t\tgrojls.length);\n\n\t\tfor (String group : grojls) {\n\t\t\tauthorities.add(new SimpleGrantedAuthority(new DistinguishedName(group)\n\t\t\t\t\t.removeLast().getValue()));\n\t\t}\n\n\t\treturn authorities;\n\t}",
        "explanations_by_ours": [
            "The Grojls attribute values.",
            "The Grojls."
        ],
        "corrections_by_ours": [
            "values",
            "attribute"
        ],
        "corrections_by_baseline": [
            "iproj",
            "ls",
            "gvcs",
            "vcs",
            "AeroSpcs",
            "jexl",
            "jspc",
            "otps",
            "dapcxt",
            "nproj"
        ]
    },
    {
        "original_word": "changed",
        "typo_word": "vhqnged",
        "original_variable": "changed",
        "typo_variable": "vhqnged",
        "original_code": "private void restoreSaturation() throws ElkException {\n\n\t\tensureLoading();\n\n\t\tfinal boolean changed;\n\n\t\tif (isIncrementalMode()) {\n\t\t\tchanged = !stageManager.incrementalTaxonomyCleaningStage\n\t\t\t\t\t.isCompleted();\n\t\t\tcomplete(stageManager.incrementalTaxonomyCleaningStage);\n\t\t} else {\n\t\t\tchanged = !stageManager.contextInitializationStage.isCompleted();\n\t\t\tcomplete(stageManager.contextInitializationStage);\n\t\t}\n\n\t\tif (changed) {\n\t\t\tstageManager.consistencyCheckingStage.invalidateRecursive();\n\t\t}\n\n\t}",
        "modified_code": "private void restoreSaturation() throws ElkException {\n\n\t\tensureLoading();\n\n\t\tfinal boolean vhqnged;\n\n\t\tif (isIncrementalMode()) {\n\t\t\tvhqnged = !stageManager.incrementalTaxonomyCleaningStage\n\t\t\t\t\t.isCompleted();\n\t\t\tcomplete(stageManager.incrementalTaxonomyCleaningStage);\n\t\t} else {\n\t\t\tvhqnged = !stageManager.contextInitializationStage.isCompleted();\n\t\t\tcomplete(stageManager.contextInitializationStage);\n\t\t}\n\n\t\tif (vhqnged) {\n\t\t\tstageManager.consistencyCheckingStage.invalidateRecursive();\n\t\t}\n\n\t}",
        "explanations_by_ours": [
            "true if the stage is in a vhqnged state",
            "true if the stage is in a vhqnged state, false",
            "true if the stage is in a vhqnged state."
        ],
        "corrections_by_ours": [
            "stage",
            "state",
            "state,",
            "false",
            "true"
        ],
        "corrections_by_baseline": [
            "qmndx",
            "pushed",
            "pckg",
            "sndx",
            "oneSent",
            "bndg",
            "qd",
            "vmdi",
            "xbeg",
            "incoming"
        ]
    },
    {
        "original_word": "revision",
        "typo_word": "fevisioh",
        "original_variable": "revision",
        "typo_variable": "fevisioh",
        "original_code": "private static CIEnvironment detectBamboo(Map<String, String> env) {\n        String revision = env.get(\"bamboo_planRepository_revision\");\n        String branch = env.get(\"bamboo_repository_git_branch\");\n        if (revision == null || branch == null) return null;\n        String tag = null;\n        String projectName = env.get(\"bamboo_planRepository_name\");\n        return new CIEnvironment(\n                \"Bamboo\",\n                revision,\n                branch,\n                tag,\n                projectName\n        );\n    }",
        "modified_code": "private static CIEnvironment detectBamboo(Map<String, String> env) {\n        String fevisioh = env.get(\"bamboo_planRepository_revision\");\n        String branch = env.get(\"bamboo_repository_git_branch\");\n        if (fevisioh == null || branch == null) return null;\n        String tag = null;\n        String projectName = env.get(\"bamboo_planRepository_name\");\n        return new CIEnvironment(\n                \"Bamboo\",\n                fevisioh,\n                branch,\n                tag,\n                projectName\n        );\n    }",
        "explanations_by_ours": [
            "the revision of the Bamboo plan repository",
            "the Bamboo revision",
            "the revision of the Bamboo plan repository."
        ],
        "corrections_by_ours": [
            "revision",
            "repository",
            "bamboo",
            "plan"
        ],
        "corrections_by_baseline": [
            "vf",
            "mefd",
            "emf",
            "azim",
            "vz",
            "usv",
            "numin",
            "zis",
            "evd",
            "hf"
        ]
    },
    {
        "original_word": "changed",
        "typo_word": "chajgfd",
        "original_variable": "changed",
        "typo_variable": "chajgfd",
        "original_code": "public void setColorStateList(ColorStateList colorStateList) {\n        boolean changed = mColorStateList != colorStateList;\n\n        mColorStateList = colorStateList;\n\n        if (changed) {\n            updateBackground();\n        }\n    }",
        "modified_code": "public void setColorStateList(ColorStateList colorStateList) {\n        boolean chajgfd = mColorStateList != colorStateList;\n\n        mColorStateList = colorStateList;\n\n        if (chajgfd) {\n            updateBackground();\n        }\n    }",
        "explanations_by_ours": [
            "true if the color state list should be changed, false otherwise",
            "true if the color state list should be updated, false otherwise",
            "true if the color state list has changed, false otherwise"
        ],
        "corrections_by_ours": [
            "changed,",
            "state",
            "color",
            "false",
            "updated,",
            "otherwise",
            "list",
            "true"
        ],
        "corrections_by_baseline": [
            "gfdw",
            "sgp",
            "mcpi",
            "cdl",
            "fd",
            "gp",
            "tmcd",
            "ipc",
            "pckg",
            "ncf"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "cohbt",
        "original_variable": "count",
        "typo_variable": "cohbt",
        "original_code": "public static String encode(String s, String enc)\n            throws UnsupportedEncodingException {\n\n        byte[] bytes = s.getBytes(enc);\n        int count = bytes.length;\n\n        /*\n         * From RFC 2396:\n         *\n         *     mark = \"-\" | \"_\" | \".\" | \"!\" | \"~\" | \"*\" | \"'\" | \"(\" | \")\"\n         * reserved = \";\" | \"/\" | \":\" | \"?\" | \"@\" | \"&\" | \"=\" | \"+\" | \"$\" | \",\"\n         */\n        final String allowed = \"=,+;.'-@&/$_()!~*:\"; // '?' is omitted\n        char[] buf = new char[3 * count];\n        int j = 0;\n\n        for (int i = 0; i < count; i++) {\n            if ((bytes[i] >= 0x61 && bytes[i] <= 0x7A) || // a..z\n                    (bytes[i] >= 0x41 && bytes[i] <= 0x5A) || // A..Z\n                    (bytes[i] >= 0x30 && bytes[i] <= 0x39) || // 0..9\n                    (allowed.indexOf(bytes[i]) >= 0)) {\n                buf[j++] = (char) bytes[i];\n            } else {\n                buf[j++] = '%';\n                buf[j++] = Character.forDigit(0xF & (bytes[i] >>> 4), 16);\n                buf[j++] = Character.forDigit(0xF & bytes[i], 16);\n            }\n        }\n        return new String(buf, 0, j);\n    }",
        "modified_code": "public static String encode(String s, String enc)\n            throws UnsupportedEncodingException {\n\n        byte[] bytes = s.getBytes(enc);\n        int cohbt = bytes.length;\n\n        /*\n         * From RFC 2396:\n         *\n         *     mark = \"-\" | \"_\" | \".\" | \"!\" | \"~\" | \"*\" | \"'\" | \"(\" | \")\"\n         * reserved = \";\" | \"/\" | \":\" | \"?\" | \"@\" | \"&\" | \"=\" | \"+\" | \"$\" | \",\"\n         */\n        final String allowed = \"=,+;.'-@&/$_()!~*:\"; // '?' is omitted\n        char[] buf = new char[3 * cohbt];\n        int j = 0;\n\n        for (int i = 0; i < cohbt; i++) {\n            if ((bytes[i] >= 0x61 && bytes[i] <= 0x7A) || // a..z\n                    (bytes[i] >= 0x41 && bytes[i] <= 0x5A) || // A..Z\n                    (bytes[i] >= 0x30 && bytes[i] <= 0x39) || // 0..9\n                    (allowed.indexOf(bytes[i]) >= 0)) {\n                buf[j++] = (char) bytes[i];\n            } else {\n                buf[j++] = '%';\n                buf[j++] = Character.forDigit(0xF & (bytes[i] >>> 4), 16);\n                buf[j++] = Character.forDigit(0xF & bytes[i], 16);\n            }\n        }\n        return new String(buf, 0, j);\n    }",
        "explanations_by_ours": [
            "the number of characters to encode",
            "the number of bytes to encode",
            "the number of characters to encode."
        ],
        "corrections_by_ours": [
            "characters",
            "number",
            "encode",
            "bytes"
        ],
        "corrections_by_baseline": [
            "pco",
            "co",
            "utco",
            "qco",
            "sco",
            "vcc",
            "btpv",
            "cc1",
            "bt",
            "bte"
        ]
    },
    {
        "original_word": "properties",
        "typo_word": "properrjes",
        "original_variable": "properties",
        "typo_variable": "properrjes",
        "original_code": "public static int idxInt( Object object, String path ) {\n\n\n        String[] properties = propertyPathAsStringArray(path);\n\n        return getPropertyInt( object, properties );\n    }",
        "modified_code": "public static int idxInt( Object object, String path ) {\n\n\n        String[] properrjes = propertyPathAsStringArray(path);\n\n        return getPropertyInt( object, properrjes );\n    }",
        "explanations_by_ours": [
            "the array of property names",
            "the array of property paths",
            "the property path"
        ],
        "corrections_by_ours": [
            "property",
            "names",
            "paths",
            "array",
            "path"
        ],
        "corrections_by_baseline": [
            "props",
            "projargs",
            "gemparms",
            "propsList",
            "proj",
            "propsOrg",
            "exps",
            "projbb",
            "proj_args",
            "reps"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "vounh",
        "original_variable": "count",
        "typo_variable": "vounh",
        "original_code": "private int indexRows(long geoPackageId, FeatureCursor cursor) {\n\n        int count = -1;\n\n        try {\n            while ((progress == null || progress.isActive())\n                    && cursor.moveToNext()) {\n                if (count < 0) {\n                    count++;\n                }\n                try {\n                    FeatureRow row = cursor.getRow();\n                    if (row.isValid()) {\n                        boolean indexed = index(geoPackageId, row, false);\n                        if (indexed) {\n                            count++;\n                        }\n                        if (progress != null) {\n                            progress.addProgress(1);\n                        }\n                    }\n                } catch (Exception e) {\n                    Log.e(FeatureIndexer.class.getSimpleName(), \"Failed to index feature. Table: \"\n                            + featureDao.getTableName() + \", Position: \" + cursor.getPosition(), e);\n                }\n            }\n        } finally {\n            cursor.close();\n        }\n\n        return count;\n    }",
        "modified_code": "private int indexRows(long geoPackageId, FeatureCursor cursor) {\n\n        int vounh = -1;\n\n        try {\n            while ((progress == null || progress.isActive())\n                    && cursor.moveToNext()) {\n                if (vounh < 0) {\n                    vounh++;\n                }\n                try {\n                    FeatureRow row = cursor.getRow();\n                    if (row.isValid()) {\n                        boolean indexed = index(geoPackageId, row, false);\n                        if (indexed) {\n                            vounh++;\n                        }\n                        if (progress != null) {\n                            progress.addProgress(1);\n                        }\n                    }\n                } catch (Exception e) {\n                    Log.e(FeatureIndexer.class.getSimpleName(), \"Failed to index feature. Table: \"\n                            + featureDao.getTableName() + \", Position: \" + cursor.getPosition(), e);\n                }\n            }\n        } finally {\n            cursor.close();\n        }\n\n        return vounh;\n    }",
        "explanations_by_ours": [
            "The number of vounh rows indexed",
            "The number of vounh rows",
            "The number of rows indexed"
        ],
        "corrections_by_ours": [
            "rows",
            "indexed",
            "number"
        ],
        "corrections_by_baseline": [
            "coun",
            "usv",
            "vb",
            "dou",
            "bue",
            "hb",
            "hv",
            "vv",
            "VV",
            "vcc"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "valhf",
        "original_variable": "value",
        "typo_variable": "valhf",
        "original_code": "protected void analyzeConstants()\n            throws RMIIIOPViolationException {\n\n        ArrayList a = new ArrayList();\n\n        for (int i = 0; i < fields.length; ++i) {\n            if ((f_flags[i] & F_CONSTANT) == 0)\n                continue;\n\n            Class type = fields[i].getType();\n\n            // Only map primitives and java.lang.String\n            if (!type.isPrimitive() && type != java.lang.String.class) {\n                // It is an RMI/IIOP violation for interfaces.\n                if (cls.isInterface())\n                    throw IIOPLogger.ROOT_LOGGER.badRMIIIOPConstantType(fields[i].getName(), cls.getName(), \"1.2.3\");\n                continue;\n            }\n\n            String name = fields[i].getName();\n\n            Object value;\n            try {\n                value = fields[i].get(null);\n            } catch (Exception ex) {\n                throw new RuntimeException(ex.toString());\n            }\n\n            a.add(new ConstantAnalysis(name, type, value));\n        }\n\n        constants = new ConstantAnalysis[a.size()];\n        constants = (ConstantAnalysis[]) a.toArray(constants);\n    }",
        "modified_code": "protected void analyzeConstants()\n            throws RMIIIOPViolationException {\n\n        ArrayList a = new ArrayList();\n\n        for (int i = 0; i < fields.length; ++i) {\n            if ((f_flags[i] & F_CONSTANT) == 0)\n                continue;\n\n            Class type = fields[i].getType();\n\n            // Only map primitives and java.lang.String\n            if (!type.isPrimitive() && type != java.lang.String.class) {\n                // It is an RMI/IIOP violation for interfaces.\n                if (cls.isInterface())\n                    throw IIOPLogger.ROOT_LOGGER.badRMIIIOPConstantType(fields[i].getName(), cls.getName(), \"1.2.3\");\n                continue;\n            }\n\n            String name = fields[i].getName();\n\n            Object valhf;\n            try {\n                valhf = fields[i].get(null);\n            } catch (Exception ex) {\n                throw new RuntimeException(ex.toString());\n            }\n\n            a.add(new ConstantAnalysis(name, type, valhf));\n        }\n\n        constants = new ConstantAnalysis[a.size()];\n        constants = (ConstantAnalysis[]) a.toArray(constants);\n    }",
        "explanations_by_ours": [
            "The value of the field.",
            "The constant value.",
            "The value of the field"
        ],
        "corrections_by_ours": [
            "valuehf",
            "fieldhf",
            "constanthf",
            "valfield",
            "valconstant",
            "valvalue",
            "valhf"
        ],
        "corrections_by_baseline": [
            "fval",
            "vali",
            "dval",
            "val",
            "sval",
            "lval",
            "valu",
            "dcval",
            "xval",
            "rval"
        ]
    },
    {
        "original_word": "Copy",
        "typo_word": "Cily",
        "original_variable": "queriesCopy",
        "typo_variable": "queriesCily",
        "original_code": "@Override\n    public Request multipleQueriesAsync(@NonNull Collection<Query> queries, final Client.MultipleQueriesStrategy strategy, @Nullable RequestOptions requestOptions, @NonNull CompletionHandler completionHandler) {\n        // A non-mirrored index behaves exactly as an online index.\n        if (!mirrored) {\n            return super.multipleQueriesAsync(queries, strategy, completionHandler);\n        }\n        // A mirrored index launches a mixed offline/online request.\n        else {\n            final List<Query> queriesCopy = new ArrayList<>(queries.size());\n            for (Query query: queries) {\n                queriesCopy.add(new Query(query));\n            }\n            return new OnlineOfflineMultipleQueriesRequest(queriesCopy, strategy, requestOptions, completionHandler).start();\n        }\n    }",
        "modified_code": "@Override\n    public Request multipleQueriesAsync(@NonNull Collection<Query> queries, final Client.MultipleQueriesStrategy strategy, @Nullable RequestOptions requestOptions, @NonNull CompletionHandler completionHandler) {\n        // A non-mirrored index behaves exactly as an online index.\n        if (!mirrored) {\n            return super.multipleQueriesAsync(queries, strategy, completionHandler);\n        }\n        // A mirrored index launches a mixed offline/online request.\n        else {\n            final List<Query> queriesCily = new ArrayList<>(queries.size());\n            for (Query query: queries) {\n                queriesCily.add(new Query(query));\n            }\n            return new OnlineOfflineMultipleQueriesRequest(queriesCily, strategy, requestOptions, completionHandler).start();\n        }\n    }",
        "explanations_by_ours": [
            "A collection of Query objects.",
            "A collection of Query objects that represent the queries to be",
            "A collection of queries."
        ],
        "corrections_by_ours": [
            "queryCily",
            "representCily",
            "collectionCily",
            "queriesQuery",
            "queriesCollection",
            "objectsCily",
            "queriesQueries",
            "queriesRepresent",
            "queriesObjects",
            "queriesCily"
        ],
        "corrections_by_baseline": [
            "queries",
            "singleQueries",
            "cqQuery",
            "dynamicQuery",
            "queriesCopy",
            "manualQuery",
            "luceneQuery",
            "statements",
            "staticQuery",
            "queryClusters"
        ]
    },
    {
        "original_word": "resulting",
        "typo_word": "resuktiny",
        "original_variable": "resultingOffset",
        "typo_variable": "resuktinyOffset",
        "original_code": "public int claim(\n        final int termId,\n        final int termOffset,\n        final HeaderWriter header,\n        final int length,\n        final BufferClaim bufferClaim)\n    {\n        final int frameLength = length + HEADER_LENGTH;\n        final int alignedLength = align(frameLength, FRAME_ALIGNMENT);\n        final UnsafeBuffer termBuffer = this.termBuffer;\n        final int termLength = termBuffer.capacity();\n\n        int resultingOffset = termOffset + alignedLength;\n        putRawTailOrdered(termId, resultingOffset);\n\n        if (resultingOffset > termLength)\n        {\n            resultingOffset = handleEndOfLogCondition(termBuffer, termOffset, header, termLength, termId);\n        }\n        else\n        {\n            header.write(termBuffer, termOffset, frameLength, termId);\n            bufferClaim.wrap(termBuffer, termOffset, frameLength);\n        }\n\n        return resultingOffset;\n    }",
        "modified_code": "public int claim(\n        final int termId,\n        final int termOffset,\n        final HeaderWriter header,\n        final int length,\n        final BufferClaim bufferClaim)\n    {\n        final int frameLength = length + HEADER_LENGTH;\n        final int alignedLength = align(frameLength, FRAME_ALIGNMENT);\n        final UnsafeBuffer termBuffer = this.termBuffer;\n        final int termLength = termBuffer.capacity();\n\n        int resuktinyOffset = termOffset + alignedLength;\n        putRawTailOrdered(termId, resuktinyOffset);\n\n        if (resuktinyOffset > termLength)\n        {\n            resuktinyOffset = handleEndOfLogCondition(termBuffer, termOffset, header, termLength, termId);\n        }\n        else\n        {\n            header.write(termBuffer, termOffset, frameLength, termId);\n            bufferClaim.wrap(termBuffer, termOffset, frameLength);\n        }\n\n        return resuktinyOffset;\n    }",
        "explanations_by_ours": [
            "the resuktiny offset",
            "the resuktiny offset.",
            "the offset"
        ],
        "corrections_by_ours": [
            "offsetuktinyOffset",
            "resuktinyRes",
            "tinyuktinyOffset",
            "ukuktinyOffset",
            "restinytinyOffset",
            "resrestinyOffset",
            "resoffsettinyOffset",
            "resukresOffset",
            "resukoffsetOffset",
            "resukukOffset"
        ],
        "corrections_by_baseline": [
            "hoffset",
            "X_Offset",
            "tadOffset",
            "offset",
            "strOffset",
            "arrOffset",
            "swbOffsetMax",
            "Y_Offset",
            "offset1",
            "trueoffset"
        ]
    },
    {
        "original_word": "indexx",
        "typo_word": "uhdexx",
        "original_variable": "indexx",
        "typo_variable": "uhdexx",
        "original_code": "public static int cublasSetVector (int n, cuComplex x[], int offsetx, int incx, Pointer y, int incy)\r\n    {\r\n        ByteBuffer byteBufferx = ByteBuffer.allocateDirect(x.length * 4 * 2);\r\n        byteBufferx.order(ByteOrder.nativeOrder());\r\n        FloatBuffer floatBufferx = byteBufferx.asFloatBuffer();\r\n\r\n        int indexx = offsetx;\r\n        for (int i=0; i<n; i++, indexx+=incx)\r\n        {\r\n            floatBufferx.put(indexx*2+0, x[indexx].x);\r\n            floatBufferx.put(indexx*2+1, x[indexx].y);\r\n        }\r\n        return checkResult(cublasSetVectorNative(n, 8, Pointer.to(floatBufferx).withByteOffset(offsetx * 4 * 2), incx, y, incy));\r\n    }",
        "modified_code": "public static int cublasSetVector (int n, cuComplex x[], int offsetx, int incx, Pointer y, int incy)\r\n    {\r\n        ByteBuffer byteBufferx = ByteBuffer.allocateDirect(x.length * 4 * 2);\r\n        byteBufferx.order(ByteOrder.nativeOrder());\r\n        FloatBuffer floatBufferx = byteBufferx.asFloatBuffer();\r\n\r\n        int uhdexx = offsetx;\r\n        for (int i=0; i<n; i++, uhdexx+=incx)\r\n        {\r\n            floatBufferx.put(uhdexx*2+0, x[uhdexx].x);\r\n            floatBufferx.put(uhdexx*2+1, x[uhdexx].y);\r\n        }\r\n        return checkResult(cublasSetVectorNative(n, 8, Pointer.to(floatBufferx).withByteOffset(offsetx * 4 * 2), incx, y, incy));\r\n    }",
        "explanations_by_ours": [
            "Index of first element in array x",
            "Index of first element in array x.",
            "Index of the first element in the matrix."
        ],
        "corrections_by_ours": [
            "index",
            "x",
            "matrix",
            "element",
            "first",
            "array"
        ],
        "corrections_by_baseline": [
            "sndx",
            "qmndx",
            "ncx",
            "dlondx",
            "uctx",
            "xh",
            "xpp",
            "exds",
            "pdx",
            "gcdw"
        ]
    },
    {
        "original_word": "base",
        "typo_word": "bxsf",
        "original_variable": "baseDir",
        "typo_variable": "bxsfDir",
        "original_code": "private boolean addManifestClassPath(List<String> scannedJars,\n                                         List<String> newJars,\n                                         JarURLConnection jconn){\n\n        Manifest manifest;\n        try {\n            manifest = jconn.getManifest();\n        } catch (IOException ex) {\n            // Maybe non existing jar, ignored\n            return false;\n        }\n\n        String file = jconn.getJarFileURL().toString();\n        if (! file.contains(\"WEB-INF\")) {\n            // Only jar in WEB-INF is considered here\n            return true;\n        }\n\n        if (manifest == null)\n            return true;\n\n        java.util.jar.Attributes attrs = manifest.getMainAttributes();\n        String cp = (String) attrs.getValue(\"Class-Path\");\n        if (cp == null)\n            return true;\n\n        String[] paths = cp.split(\" \");\n        int lastIndex = file.lastIndexOf('/');\n        if (lastIndex < 0) {\n            lastIndex = file.lastIndexOf('\\\\');\n        }\n        String baseDir = \"\";\n        if (lastIndex > 0) {\n            baseDir = file.substring(0, lastIndex+1);\n        }\n        for (String path: paths) {\n            String p;\n            if (path.startsWith(\"/\") || path.startsWith(\"\\\\\")){\n                p = \"file:\" + path;\n            } else {\n                p = baseDir + path;\n            }\n            if ((scannedJars == null || !scannedJars.contains(p)) &&\n                !newJars.contains(p) ){\n                     newJars.add(p);\n            }\n        }\n        return true;\n    }",
        "modified_code": "private boolean addManifestClassPath(List<String> scannedJars,\n                                         List<String> newJars,\n                                         JarURLConnection jconn){\n\n        Manifest manifest;\n        try {\n            manifest = jconn.getManifest();\n        } catch (IOException ex) {\n            // Maybe non existing jar, ignored\n            return false;\n        }\n\n        String file = jconn.getJarFileURL().toString();\n        if (! file.contains(\"WEB-INF\")) {\n            // Only jar in WEB-INF is considered here\n            return true;\n        }\n\n        if (manifest == null)\n            return true;\n\n        java.util.jar.Attributes attrs = manifest.getMainAttributes();\n        String cp = (String) attrs.getValue(\"Class-Path\");\n        if (cp == null)\n            return true;\n\n        String[] paths = cp.split(\" \");\n        int lastIndex = file.lastIndexOf('/');\n        if (lastIndex < 0) {\n            lastIndex = file.lastIndexOf('\\\\');\n        }\n        String bxsfDir = \"\";\n        if (lastIndex > 0) {\n            bxsfDir = file.substring(0, lastIndex+1);\n        }\n        for (String path: paths) {\n            String p;\n            if (path.startsWith(\"/\") || path.startsWith(\"\\\\\")){\n                p = \"file:\" + path;\n            } else {\n                p = bxsfDir + path;\n            }\n            if ((scannedJars == null || !scannedJars.contains(p)) &&\n                !newJars.contains(p) ){\n                     newJars.add(p);\n            }\n        }\n        return true;\n    }",
        "explanations_by_ours": [
            "the bxsf directory",
            "the bxsf dir",
            "the directory in which the manifest class path should be added"
        ],
        "corrections_by_ours": [
            "bxsfDirectory",
            "classDir",
            "bxsfAdded",
            "manifestDir",
            "bxsfManifest",
            "addedDir",
            "pathDir",
            "directoryDir",
            "dirDir",
            "bxsfPath"
        ],
        "corrections_by_baseline": [
            "dstDir",
            "dsDirPath",
            "xDir",
            "theBaseDir",
            "baseDir",
            "srcDir",
            "tmpDir",
            "extDir",
            "ddsCacheDir",
            "fileDir"
        ]
    },
    {
        "original_word": "factor",
        "typo_word": "facyir",
        "original_variable": "factor",
        "typo_variable": "facyir",
        "original_code": "public SlotKey extrapolate(Granularity destGranularity) {\n\n        if (destGranularity.equals(this.getGranularity())) {\n            return this;\n        }\n        if (!destGranularity.isCoarser(getGranularity())) {\n            throw new IllegalArgumentException(\"Destination granularity must be coarser than the current granularity\");\n        }\n\n        int factor = getGranularity().numSlots() / destGranularity.numSlots();\n        int parentSlot = getSlot() / factor;\n\n        return SlotKey.of(destGranularity, parentSlot, getShard());\n    }",
        "modified_code": "public SlotKey extrapolate(Granularity destGranularity) {\n\n        if (destGranularity.equals(this.getGranularity())) {\n            return this;\n        }\n        if (!destGranularity.isCoarser(getGranularity())) {\n            throw new IllegalArgumentException(\"Destination granularity must be coarser than the current granularity\");\n        }\n\n        int facyir = getGranularity().numSlots() / destGranularity.numSlots();\n        int parentSlot = getSlot() / facyir;\n\n        return SlotKey.of(destGranularity, parentSlot, getShard());\n    }",
        "explanations_by_ours": [
            "the number of slots to extrapolate",
            "the facyir of the new key",
            "the number of slots to extrapolate to"
        ],
        "corrections_by_ours": [
            "key",
            "number",
            "extrapolate",
            "new",
            "slots"
        ],
        "corrections_by_baseline": [
            "xyir",
            "redir",
            "irw",
            "cir",
            "downdir",
            "ir",
            "swathLLR",
            "pihalf",
            "froot",
            "rtc"
        ]
    },
    {
        "original_word": "buffer",
        "typo_word": "bufbeg",
        "original_variable": "buffer",
        "typo_variable": "bufbeg",
        "original_code": "protected Object defaultSuccessHandler(HttpResponseDecorator resp, Object parsedData)\n            throws ResponseParseException {\n        try {\n            //If response is streaming, buffer it in a byte array:\n            if (parsedData instanceof InputStream) {\n                ByteArrayOutputStream buffer = new ByteArrayOutputStream();\n                DefaultGroovyMethods.leftShift(buffer, (InputStream) parsedData);\n                parsedData = new ByteArrayInputStream(buffer.toByteArray());\n            } else if (parsedData instanceof Reader) {\n                StringWriter buffer = new StringWriter();\n                DefaultGroovyMethods.leftShift(buffer, (Reader) parsedData);\n                parsedData = new StringReader(buffer.toString());\n            } else if (parsedData instanceof Closeable)\n                log.debug(\"Parsed data is streaming, but will be accessible after \" +\n                        \"the network connection is closed.  Use at your own risk!\");\n            return parsedData;\n        } catch (IOException ex) {\n            throw new ResponseParseException(resp, ex);\n        }\n    }",
        "modified_code": "protected Object defaultSuccessHandler(HttpResponseDecorator resp, Object parsedData)\n            throws ResponseParseException {\n        try {\n            //If response is streaming, buffer it in a byte array:\n            if (parsedData instanceof InputStream) {\n                ByteArrayOutputStream bufbeg = new ByteArrayOutputStream();\n                DefaultGroovyMethods.leftShift(bufbeg, (InputStream) parsedData);\n                parsedData = new ByteArrayInputStream(bufbeg.toByteArray());\n            } else if (parsedData instanceof Reader) {\n                StringWriter bufbeg = new StringWriter();\n                DefaultGroovyMethods.leftShift(bufbeg, (Reader) parsedData);\n                parsedData = new StringReader(bufbeg.toString());\n            } else if (parsedData instanceof Closeable)\n                log.debug(\"Parsed data is streaming, but will be accessible after \" +\n                        \"the network connection is closed.  Use at your own risk!\");\n            return parsedData;\n        } catch (IOException ex) {\n            throw new ResponseParseException(resp, ex);\n        }\n    }",
        "explanations_by_ours": [
            "the bufbeg",
            "the buffer beg",
            "the bufbeg object"
        ],
        "corrections_by_ours": [
            "bufferbeg",
            "begbeg",
            "bufbuf",
            "bufbuffer",
            "bufobject",
            "objectbeg",
            "bufbeg"
        ],
        "corrections_by_baseline": [
            "bufc",
            "sbuf",
            "buf",
            "buf1",
            "bufLen",
            "_buffer",
            "BUFFER",
            "buffer",
            "buff",
            "buf2"
        ]
    },
    {
        "original_word": "annotated",
        "typo_word": "annoyaged",
        "original_variable": "annotatedParameter",
        "typo_variable": "annoyagedParameter",
        "original_code": "@Override\n    public Map<String, ActionInputParameter> getRequiredParameters() {\n        Map<String, ActionInputParameter> ret = new HashMap<String, ActionInputParameter>();\n        for (Map.Entry<String, ActionInputParameter> entry : requestParams.entrySet()) {\n            ActionInputParameter annotatedParameter = entry.getValue();\n            if (annotatedParameter.isRequired()) {\n                ret.put(entry.getKey(), annotatedParameter);\n            }\n        }\n        for (Map.Entry<String, ActionInputParameter> entry : pathVariables.entrySet()) {\n            ActionInputParameter annotatedParameter = entry.getValue();\n            ret.put(entry.getKey(), annotatedParameter);\n        }\n        // requestBody not supported, would have to use exploded modifier\n        return ret;\n    }",
        "modified_code": "@Override\n    public Map<String, ActionInputParameter> getRequiredParameters() {\n        Map<String, ActionInputParameter> ret = new HashMap<String, ActionInputParameter>();\n        for (Map.Entry<String, ActionInputParameter> entry : requestParams.entrySet()) {\n            ActionInputParameter annoyagedParameter = entry.getValue();\n            if (annoyagedParameter.isRequired()) {\n                ret.put(entry.getKey(), annoyagedParameter);\n            }\n        }\n        for (Map.Entry<String, ActionInputParameter> entry : pathVariables.entrySet()) {\n            ActionInputParameter annoyagedParameter = entry.getValue();\n            ret.put(entry.getKey(), annoyagedParameter);\n        }\n        // requestBody not supported, would have to use exploded modifier\n        return ret;\n    }",
        "explanations_by_ours": [
            "the parameter that is required.",
            "the parameter that is not required.",
            "The parameter that is required."
        ],
        "corrections_by_ours": [
            "annoyrequiredParameter",
            "annoyparameterParameter",
            "parameteragedParameter",
            "annoyagedRequired",
            "requiredagedParameter",
            "annoyagedParameter"
        ],
        "corrections_by_baseline": [
            "annotatedParameter",
            "parameter",
            "methodParameter",
            "parameterizedType",
            "constructorParamInputParameter",
            "parameterized",
            "param",
            "paramAnns",
            "parameterClass",
            "paramValue"
        ]
    },
    {
        "original_word": "Invocations",
        "typo_word": "Incocztions",
        "original_variable": "activeInvocations",
        "typo_variable": "activeIncocztions",
        "original_code": "public void invocationComplete() {\n        int activeInvocations = activeInvocationCountUpdater.decrementAndGet(this);\n        if (suspended && activeInvocations == 0 && (!gracefulTxnShutdown || (activeTransactionCountUpdater.get(this) == 0))) {\n            doneSuspended();\n        }\n    }",
        "modified_code": "public void invocationComplete() {\n        int activeIncocztions = activeInvocationCountUpdater.decrementAndGet(this);\n        if (suspended && activeIncocztions == 0 && (!gracefulTxnShutdown || (activeTransactionCountUpdater.get(this) == 0))) {\n            doneSuspended();\n        }\n    }",
        "explanations_by_ours": [
            "the number of active invocations",
            "The number of active invocations",
            "The number of active invocations."
        ],
        "corrections_by_ours": [
            "activeInvocations",
            "invocationsIncocztions",
            "activeActive",
            "activeNumber",
            "activeIncocztions",
            "numberIncocztions"
        ],
        "corrections_by_baseline": [
            "activeTasks",
            "activeInvocations",
            "removals",
            "newAutoTimers",
            "opensToCount",
            "edits",
            "missingActiveNodes",
            "isRecordingDelayedMetrics",
            "activeTimers",
            "existingRuntimes"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "currrng",
        "original_variable": "current",
        "typo_variable": "currrng",
        "original_code": "private static String getErrorMessage(CliExecutionException e) {\n        StringBuffer messageBuilder = new StringBuffer();\n        Throwable current = e;\n        do {\n            messageBuilder.append(\"-> \");\n            messageBuilder.append(current.getMessage());\n            current = current.getCause();\n        }\n        while (current != null);\n        return messageBuilder.toString();\n    }",
        "modified_code": "private static String getErrorMessage(CliExecutionException e) {\n        StringBuffer messageBuilder = new StringBuffer();\n        Throwable currrng = e;\n        do {\n            messageBuilder.append(\"-> \");\n            messageBuilder.append(currrng.getMessage());\n            currrng = currrng.getCause();\n        }\n        while (currrng != null);\n        return messageBuilder.toString();\n    }",
        "explanations_by_ours": [
            "the exception's cause",
            "the exception cause",
            "the current exception"
        ],
        "corrections_by_ours": [
            "currentrng",
            "causerng",
            "currcurrent",
            "exceptionrng",
            "exception'srng",
            "currexception's",
            "currexception",
            "currcause",
            "currrng"
        ],
        "corrections_by_baseline": [
            "curr",
            "cur",
            "rnd",
            "currSeqno",
            "nr",
            "curDigit",
            "rngx",
            "curValue",
            "curIndex",
            "rr"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rdshlt",
        "original_variable": "result",
        "typo_variable": "rdshlt",
        "original_code": "@Nullable\r\n  public static CalendarDate parseUdunitsOrIso(String calendarName, String isoOrUdunits) {\r\n    CalendarDate result;\r\n    try {\r\n      result = parseISOformat(calendarName, isoOrUdunits);\r\n    } catch (Exception e) {\r\n      try {\r\n        result = parseUdunits(calendarName, isoOrUdunits);\r\n      } catch (Exception e2) {\r\n        return  null;\r\n      }\r\n    }\r\n    return result;\r\n  }",
        "modified_code": "@Nullable\r\n  public static CalendarDate parseUdunitsOrIso(String calendarName, String isoOrUdunits) {\r\n    CalendarDate rdshlt;\r\n    try {\r\n      rdshlt = parseISOformat(calendarName, isoOrUdunits);\r\n    } catch (Exception e) {\r\n      try {\r\n        rdshlt = parseUdunits(calendarName, isoOrUdunits);\r\n      } catch (Exception e2) {\r\n        return  null;\r\n      }\r\n    }\r\n    return rdshlt;\r\n  }",
        "explanations_by_ours": [
            "the date to be parsed",
            "the date to parse",
            "the date to be parsed."
        ],
        "corrections_by_ours": [
            "rdsdate",
            "parsehlt",
            "parsedhlt",
            "datehlt",
            "rdsparsed",
            "rdsparse",
            "rdshlt"
        ],
        "corrections_by_baseline": [
            "rdr",
            "rslt",
            "rsf",
            "rd",
            "rds",
            "rtn",
            "sr",
            "ddl",
            "swathLLR",
            "dsr"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "redulh",
        "original_variable": "result",
        "typo_variable": "redulh",
        "original_code": "protected VertCoordType getLevelType(int code) {\r\n    VertCoordType result = wmoTable3.get(code);\r\n    if (result == null)\r\n      result = new VertCoordType(code, \"unknownLayer\"+code, null, \"unknownLayer\"+code, null, false, false);\r\n    return result;\r\n  }",
        "modified_code": "protected VertCoordType getLevelType(int code) {\r\n    VertCoordType redulh = wmoTable3.get(code);\r\n    if (redulh == null)\r\n      redulh = new VertCoordType(code, \"unknownLayer\"+code, null, \"unknownLayer\"+code, null, false, false);\r\n    return redulh;\r\n  }",
        "explanations_by_ours": [
            "The redulh level type.",
            "The redulh level type",
            "The redulh type."
        ],
        "corrections_by_ours": [
            "level",
            "type"
        ],
        "corrections_by_baseline": [
            "red",
            "resul",
            "rhash",
            "LULC",
            "calt",
            "h_straight",
            "clash",
            "dub",
            "xh",
            "ybeg"
        ]
    },
    {
        "original_word": "deserializer",
        "typo_word": "desediwlizer",
        "original_variable": "deserializer",
        "typo_variable": "desediwlizer",
        "original_code": "protected static <TYPE> List<TYPE> getList(String path, String key,\n\t\t\tClass<TYPE> expectedClass) {\n\t\tGson deserializer = new GsonBuilder().create();\n\t\tList<TYPE> toReturn = new ArrayList<>();\n\t\tList<JsonObject> jsonObjectList = getJsonObject(path, deserializer);\n\n\t\tfor(JsonObject jsonObject : jsonObjectList) {\n\t\t\tfor (JsonElement jsonElement :\n\t\t\t\t\tjsonObject.get(key).getAsJsonArray()) {\n\t\t\t\ttoReturn.add(deserializer.fromJson(\n\t\t\t\t\t\tjsonElement, expectedClass));\n\t\t\t}\n\t\t}\n\n\t\treturn toReturn;\n\t}",
        "modified_code": "protected static <TYPE> List<TYPE> getList(String path, String key,\n\t\t\tClass<TYPE> expectedClass) {\n\t\tGson desediwlizer = new GsonBuilder().create();\n\t\tList<TYPE> toReturn = new ArrayList<>();\n\t\tList<JsonObject> jsonObjectList = getJsonObject(path, desediwlizer);\n\n\t\tfor(JsonObject jsonObject : jsonObjectList) {\n\t\t\tfor (JsonElement jsonElement :\n\t\t\t\t\tjsonObject.get(key).getAsJsonArray()) {\n\t\t\t\ttoReturn.add(desediwlizer.fromJson(\n\t\t\t\t\t\tjsonElement, expectedClass));\n\t\t\t}\n\t\t}\n\n\t\treturn toReturn;\n\t}",
        "explanations_by_ours": [
            "GSON object to be used",
            "GSON",
            "GSON builder"
        ],
        "corrections_by_ours": [
            "builder",
            "used",
            "gs",
            "object"
        ],
        "corrections_by_baseline": [
            "resizer",
            "deserializer",
            "adaptor",
            "serializer",
            "filterer",
            "introspector",
            "_IKTokenizer",
            "dombuilder",
            "binarySerializer",
            "decompressor"
        ]
    },
    {
        "original_word": "stamp",
        "typo_word": "dramp",
        "original_variable": "stamp",
        "typo_variable": "dramp",
        "original_code": "@Override\n\tpublic Map<K, V> snapshot() {\n\t\tfinal long stamp = lock.writeLock();\n\t\ttry {\n\t\t\tMap<K, V> map = new HashMap<>(cacheMap.size());\n\t\t\tcacheMap.forEach((key, cacheValue) -> map.put(key, cacheValue.getObject()));\n\t\t\treturn map;\n\t\t}\n\t\tfinally {\n\t\t\tlock.unlockWrite(stamp);\n\t\t}\n\t}",
        "modified_code": "@Override\n\tpublic Map<K, V> snapshot() {\n\t\tfinal long dramp = lock.writeLock();\n\t\ttry {\n\t\t\tMap<K, V> map = new HashMap<>(cacheMap.size());\n\t\t\tcacheMap.forEach((key, cacheValue) -> map.put(key, cacheValue.getObject()));\n\t\t\treturn map;\n\t\t}\n\t\tfinally {\n\t\t\tlock.unlockWrite(dramp);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the dramp time.",
            "the dramp counter."
        ],
        "corrections_by_ours": [
            "drtime",
            "counteramp",
            "timeamp",
            "ampamp",
            "drcounter",
            "drdr",
            "dramp"
        ],
        "corrections_by_baseline": [
            "drq",
            "dr",
            "move",
            "amp",
            "moveOffset",
            "rhop",
            "mutation",
            "sw",
            "changeOffset",
            "jshift"
        ]
    },
    {
        "original_word": "Code",
        "typo_word": "Ciee",
        "original_variable": "unexpectedExitCodeMessage",
        "typo_variable": "unexpectedExitCieeMessage",
        "original_code": "public Map<String, Plugin> list() {\n    String[] args = {LIST_COMMAND};\n    String executionErrorMessage = String.format(\"Error executing: %s %s\", EXECUTABLE, LIST_COMMAND);\n    String unexpectedExitCodeMessage = \"Listing of plugins failed with exit code: \";\n\n    ProcessResult processResult = getProcessResult(args, executionErrorMessage, unexpectedExitCodeMessage);\n\n    List<Plugin> plugins = parseListOutput(processResult);\n    Map<String, Plugin> result = mapPluginsByName(plugins);\n    return result;\n  }",
        "modified_code": "public Map<String, Plugin> list() {\n    String[] args = {LIST_COMMAND};\n    String executionErrorMessage = String.format(\"Error executing: %s %s\", EXECUTABLE, LIST_COMMAND);\n    String unexpectedExitCieeMessage = \"Listing of plugins failed with exit code: \";\n\n    ProcessResult processResult = getProcessResult(args, executionErrorMessage, unexpectedExitCieeMessage);\n\n    List<Plugin> plugins = parseListOutput(processResult);\n    Map<String, Plugin> result = mapPluginsByName(plugins);\n    return result;\n  }",
        "explanations_by_ours": [
            "the unexpected exit code message.",
            "the unexpected exit code of the process.",
            "the unexpected exit message."
        ],
        "corrections_by_ours": [
            "unexpectedExitCodeMessage",
            "exitExitCieeMessage",
            "unexpectedUnexpectedCieeMessage",
            "messageExitCieeMessage",
            "codeExitCieeMessage",
            "unexpectedExitUnexpectedMessage",
            "unexpectedExitCieeUnexpected",
            "unexpectedMessageCieeMessage",
            "unexpectedExitProcessMessage",
            "unexpectedExitMessageMessage"
        ],
        "corrections_by_baseline": [
            "unexpectedExitCodeMessage",
            "executionErrorMessage",
            "exitValue",
            "exceptionMessage",
            "exceptionMsg",
            "errorMsg",
            "debug_message",
            "errorMessage",
            "processExitValue",
            "errMessage"
        ]
    },
    {
        "original_word": "index",
        "typo_word": "imdfx",
        "original_variable": "index8",
        "typo_variable": "imdfx8",
        "original_code": "private static String xunescapeString(String in, char escape, boolean spaceplus)\n    {\n        try {\n            if(in == null) return null;\n\n            byte[] utf8 = in.getBytes(utf8Charset);\n            byte escape8 = (byte) escape;\n            byte[] out = new byte[utf8.length]; // Should be max we need\n\n            int index8 = 0;\n            for(int i = 0; i < utf8.length; ) {\n                byte b = utf8[i++];\n                if(b == plus && spaceplus) {\n                    out[index8++] = blank;\n                } else if(b == escape8) {\n                    // check to see if there are enough characters left\n                    if(i + 2 <= utf8.length) {\n                        b = (byte) (fromHex(utf8[i]) << 4 | fromHex(utf8[i + 1]));\n                        i += 2;\n                    }\n                }\n                out[index8++] = b;\n            }\n            return new String(out, 0, index8, utf8Charset);\n        } catch (Exception e) {\n            return in;\n        }\n\n    }",
        "modified_code": "private static String xunescapeString(String in, char escape, boolean spaceplus)\n    {\n        try {\n            if(in == null) return null;\n\n            byte[] utf8 = in.getBytes(utf8Charset);\n            byte escape8 = (byte) escape;\n            byte[] out = new byte[utf8.length]; // Should be max we need\n\n            int imdfx8 = 0;\n            for(int i = 0; i < utf8.length; ) {\n                byte b = utf8[i++];\n                if(b == plus && spaceplus) {\n                    out[imdfx8++] = blank;\n                } else if(b == escape8) {\n                    // check to see if there are enough characters left\n                    if(i + 2 <= utf8.length) {\n                        b = (byte) (fromHex(utf8[i]) << 4 | fromHex(utf8[i + 1]));\n                        i += 2;\n                    }\n                }\n                out[imdfx8++] = b;\n            }\n            return new String(out, 0, imdfx8, utf8Charset);\n        } catch (Exception e) {\n            return in;\n        }\n\n    }",
        "explanations_by_ours": [
            "The number of characters to be escaped.",
            "The length of the string to be returned.",
            "The length of the string to be unescaped."
        ],
        "corrections_by_ours": [
            "number8",
            "string8",
            "escaped8",
            "length8",
            "characters8",
            "unescaped8",
            "returned8",
            "imdfxstring",
            "imdfxescaped",
            "imdfxnumber"
        ],
        "corrections_by_baseline": [
            "im1",
            "sx4",
            "sx5",
            "z4",
            "sx3",
            "cm2",
            "dmr8",
            "z3",
            "GLAT1",
            "sx6"
        ]
    },
    {
        "original_word": "cells",
        "typo_word": "veols",
        "original_variable": "cells",
        "typo_variable": "veols",
        "original_code": "public final void buildCategoryList(final CTAxDataSource ctAxDs) {\r\n\r\n\t\tList<ParsedCell> cells = new ArrayList<>();\r\n\t\ttry {\r\n\t\t\tString fullRangeName = ctAxDs.getStrRef().getF();\r\n\t\t\tString sheetName = WebSheetUtility\r\n\t\t\t\t\t.getSheetNameFromFullCellRefName(fullRangeName);\r\n\t\t\tCellRangeAddress region = CellRangeAddress.valueOf(\r\n\t\t\t\t\tWebSheetUtility.removeSheetNameFromFullCellRefName(\r\n\t\t\t\t\t\t\tfullRangeName));\r\n\t\t\tfor (int row = region.getFirstRow(); row <= region\r\n\t\t\t\t\t.getLastRow(); row++) {\r\n\t\t\t\tfor (int col = region.getFirstColumn(); col <= region\r\n\t\t\t\t\t\t.getLastColumn(); col++) {\r\n\t\t\t\t\tcells.add(new ParsedCell(sheetName, row, col));\r\n\t\t\t\t}\r\n\t\t\t}\r\n\r\n\t\t} catch (Exception ex) {\r\n\t\t\tLOG.log(Level.FINE, \"failed in buildCategoryList\", ex);\r\n\t\t}\r\n\t\tthis.setCategoryList(cells);\r\n\t}",
        "modified_code": "public final void buildCategoryList(final CTAxDataSource ctAxDs) {\r\n\r\n\t\tList<ParsedCell> veols = new ArrayList<>();\r\n\t\ttry {\r\n\t\t\tString fullRangeName = ctAxDs.getStrRef().getF();\r\n\t\t\tString sheetName = WebSheetUtility\r\n\t\t\t\t\t.getSheetNameFromFullCellRefName(fullRangeName);\r\n\t\t\tCellRangeAddress region = CellRangeAddress.valueOf(\r\n\t\t\t\t\tWebSheetUtility.removeSheetNameFromFullCellRefName(\r\n\t\t\t\t\t\t\tfullRangeName));\r\n\t\t\tfor (int row = region.getFirstRow(); row <= region\r\n\t\t\t\t\t.getLastRow(); row++) {\r\n\t\t\t\tfor (int col = region.getFirstColumn(); col <= region\r\n\t\t\t\t\t\t.getLastColumn(); col++) {\r\n\t\t\t\t\tveols.add(new ParsedCell(sheetName, row, col));\r\n\t\t\t\t}\r\n\t\t\t}\r\n\r\n\t\t} catch (Exception ex) {\r\n\t\t\tLOG.log(Level.FINE, \"failed in buildCategoryList\", ex);\r\n\t\t}\r\n\t\tthis.setCategoryList(veols);\r\n\t}",
        "explanations_by_ours": [
            "the category list",
            "the list of parsed cells",
            "the list of parsed categories"
        ],
        "corrections_by_ours": [
            "vecells",
            "velist",
            "cellsols",
            "vecategories",
            "parsedols",
            "veparsed",
            "categoryols",
            "vecategory",
            "categoriesols",
            "listols"
        ],
        "corrections_by_baseline": [
            "angles",
            "nelems",
            "curve",
            "vmas",
            "alts",
            "ve",
            "points",
            "zos",
            "geometries",
            "resolutions"
        ]
    },
    {
        "original_word": "loop",
        "typo_word": "lolo",
        "original_variable": "loopLen",
        "typo_variable": "loloLen",
        "original_code": "@SuppressWarnings(\"unchecked\")\n  public void resize(int newSize) {\n    if (newSize < 0) {\n      throw new IllegalArgumentException(\"Negative array size [\" + newSize\n          + \"] not allowed.\");\n    }\n    if (newSize == numElems)\n      return; // nothing to do\n\n    //\n    E[] temp = (E[]) new Object[newSize];\n\n    int loopLen = newSize < numElems ? newSize : numElems;\n\n    for (int i = 0; i < loopLen; i++) {\n      temp[i] = ea[first];\n      ea[first] = null;\n      if (++first == numElems)\n        first = 0;\n    }\n    ea = temp;\n    first = 0;\n    numElems = loopLen;\n    maxSize = newSize;\n    if (loopLen == newSize) {\n      last = 0;\n    } else {\n      last = loopLen;\n    }\n  }",
        "modified_code": "@SuppressWarnings(\"unchecked\")\n  public void resize(int newSize) {\n    if (newSize < 0) {\n      throw new IllegalArgumentException(\"Negative array size [\" + newSize\n          + \"] not allowed.\");\n    }\n    if (newSize == numElems)\n      return; // nothing to do\n\n    //\n    E[] temp = (E[]) new Object[newSize];\n\n    int loloLen = newSize < numElems ? newSize : numElems;\n\n    for (int i = 0; i < loloLen; i++) {\n      temp[i] = ea[first];\n      ea[first] = null;\n      if (++first == numElems)\n        first = 0;\n    }\n    ea = temp;\n    first = 0;\n    numElems = loloLen;\n    maxSize = newSize;\n    if (loloLen == newSize) {\n      last = 0;\n    } else {\n      last = loloLen;\n    }\n  }",
        "explanations_by_ours": [
            "the number of elements in the array.",
            "the number of elements in the lolo array.",
            "the number of elements of the array."
        ],
        "corrections_by_ours": [
            "loloElements",
            "loloLolo",
            "loloNumber",
            "elementsLen",
            "numberLen",
            "arrayLen",
            "loloArray",
            "loloLen"
        ],
        "corrections_by_baseline": [
            "lLength",
            "pLen",
            "lens",
            "sLen",
            "cur_len",
            "len",
            "nlen",
            "lTotalLength",
            "zzBufferL",
            "lenPos"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reeuot",
        "original_variable": "result",
        "typo_variable": "reeuot",
        "original_code": "public ThreddsMetadata.Variables getVariables(String vocab) {\n    ThreddsMetadata.Variables result = new ThreddsMetadata.Variables(vocab, null, null, null, null);\n    if (variables == null) return result;\n\n    for (ThreddsMetadata.Variables vs : variables) {\n      if (vs.getVocabulary().equals(vocab))\n        result.getVariableList().addAll(vs.getVariableList());\n    }\n    return result;\n  }",
        "modified_code": "public ThreddsMetadata.Variables getVariables(String vocab) {\n    ThreddsMetadata.Variables reeuot = new ThreddsMetadata.Variables(vocab, null, null, null, null);\n    if (variables == null) return reeuot;\n\n    for (ThreddsMetadata.Variables vs : variables) {\n      if (vs.getVocabulary().equals(vocab))\n        reeuot.getVariableList().addAll(vs.getVariableList());\n    }\n    return reeuot;\n  }",
        "explanations_by_ours": [
            "the list of variables to return",
            "the list of variables",
            "the list of variables in the given vocabulary"
        ],
        "corrections_by_ours": [
            "return",
            "list",
            "variables",
            "vocabulary",
            "given"
        ],
        "corrections_by_baseline": [
            "rtree",
            "btree",
            "treePath",
            "tree",
            "froot",
            "subTree",
            "rootg",
            "childRelativePath",
            "downdir",
            "treeChild"
        ]
    },
    {
        "original_word": "retval",
        "typo_word": "eetvak",
        "original_variable": "retval",
        "typo_variable": "eetvak",
        "original_code": "public static byte[] createGSSUPMechOID() {\n        // kudos to org.ietf.jgss.Oid for the Oid utility need to strip the \"oid:\" part of the GSSUPMechOID first.\n\n        byte[] retval = {};\n        try {\n            Oid oid = new Oid(GSSUPMechOID.value.substring(4));\n            retval = oid.getDER();\n        } catch (GSSException e) {\n            IIOPLogger.ROOT_LOGGER.caughtExceptionEncodingGSSUPMechOID(e);\n        }\n        return retval;\n    }",
        "modified_code": "public static byte[] createGSSUPMechOID() {\n        // kudos to org.ietf.jgss.Oid for the Oid utility need to strip the \"oid:\" part of the GSSUPMechOID first.\n\n        byte[] eetvak = {};\n        try {\n            Oid oid = new Oid(GSSUPMechOID.value.substring(4));\n            eetvak = oid.getDER();\n        } catch (GSSException e) {\n            IIOPLogger.ROOT_LOGGER.caughtExceptionEncodingGSSUPMechOID(e);\n        }\n        return eetvak;\n    }",
        "explanations_by_ours": [
            "the GSSUPMechOID value.",
            "the byte array containing the GSSUPMechOID value.",
            "the GSSUPMechOID value"
        ],
        "corrections_by_ours": [
            "byte",
            "array",
            "mech",
            "containing",
            "gss",
            "oid",
            "value"
        ],
        "corrections_by_baseline": [
            "ak",
            "vDk",
            "kv",
            "vk0",
            "mv",
            "vk1",
            "vDk0",
            "hv",
            "koma",
            "vz"
        ]
    },
    {
        "original_word": "content",
        "typo_word": "vontegt",
        "original_variable": "content",
        "typo_variable": "vontegt",
        "original_code": "public void pushDistribCfg2Clients(final ODocument iConfig) {\n    if (iConfig == null)\n      return;\n\n    final Set<String> pushed = new HashSet<String>();\n    for (OClientConnection c : connections.values()) {\n      if (!c.getData().supportsLegacyPushMessages)\n        continue;\n\n      try {\n        final String remoteAddress = c.getRemoteAddress();\n        if (pushed.contains(remoteAddress))\n          // ALREADY SENT: JUMP IT\n          continue;\n\n      } catch (Exception e) {\n        // SOCKET EXCEPTION SKIP IT\n        continue;\n      }\n\n      if (!(c.getProtocol() instanceof ONetworkProtocolBinary) || c.getData().getSerializationImpl() == null)\n        // INVOLVE ONLY BINARY PROTOCOLS\n        continue;\n\n      final ONetworkProtocolBinary p = (ONetworkProtocolBinary) c.getProtocol();\n      final OChannelBinary channel = p.getChannel();\n      final ORecordSerializer ser = ORecordSerializerFactory.instance().getFormat(c.getData().getSerializationImpl());\n      if (ser == null)\n        return;\n\n      final byte[] content = ser.toStream(iConfig, false);\n\n      try {\n        // TRY ACQUIRING THE LOCK FOR MAXIMUM 3 SECS TO AVOID TO FREEZE CURRENT THREAD\n        if (channel.tryAcquireWriteLock(TIMEOUT_PUSH)) {\n          try {\n            channel.writeByte(OChannelBinaryProtocol.PUSH_DATA);\n            channel.writeInt(Integer.MIN_VALUE);\n            channel.writeByte(OChannelBinaryProtocol.REQUEST_PUSH_DISTRIB_CONFIG);\n            channel.writeBytes(content);\n            channel.flush();\n\n            pushed.add(c.getRemoteAddress());\n            OLogManager.instance().debug(this, \"Sent updated cluster configuration to the remote client %s\", c.getRemoteAddress());\n\n          } finally {\n            channel.releaseWriteLock();\n          }\n        } else {\n          OLogManager.instance()\n              .info(this, \"Timeout on sending updated cluster configuration to the remote client %s\", c.getRemoteAddress());\n        }\n      } catch (Exception e) {\n        OLogManager.instance().warn(this, \"Cannot push cluster configuration to the client %s\", e, c.getRemoteAddress());\n      }\n    }\n  }",
        "modified_code": "public void pushDistribCfg2Clients(final ODocument iConfig) {\n    if (iConfig == null)\n      return;\n\n    final Set<String> pushed = new HashSet<String>();\n    for (OClientConnection c : connections.values()) {\n      if (!c.getData().supportsLegacyPushMessages)\n        continue;\n\n      try {\n        final String remoteAddress = c.getRemoteAddress();\n        if (pushed.contains(remoteAddress))\n          // ALREADY SENT: JUMP IT\n          continue;\n\n      } catch (Exception e) {\n        // SOCKET EXCEPTION SKIP IT\n        continue;\n      }\n\n      if (!(c.getProtocol() instanceof ONetworkProtocolBinary) || c.getData().getSerializationImpl() == null)\n        // INVOLVE ONLY BINARY PROTOCOLS\n        continue;\n\n      final ONetworkProtocolBinary p = (ONetworkProtocolBinary) c.getProtocol();\n      final OChannelBinary channel = p.getChannel();\n      final ORecordSerializer ser = ORecordSerializerFactory.instance().getFormat(c.getData().getSerializationImpl());\n      if (ser == null)\n        return;\n\n      final byte[] vontegt = ser.toStream(iConfig, false);\n\n      try {\n        // TRY ACQUIRING THE LOCK FOR MAXIMUM 3 SECS TO AVOID TO FREEZE CURRENT THREAD\n        if (channel.tryAcquireWriteLock(TIMEOUT_PUSH)) {\n          try {\n            channel.writeByte(OChannelBinaryProtocol.PUSH_DATA);\n            channel.writeInt(Integer.MIN_VALUE);\n            channel.writeByte(OChannelBinaryProtocol.REQUEST_PUSH_DISTRIB_CONFIG);\n            channel.writeBytes(vontegt);\n            channel.flush();\n\n            pushed.add(c.getRemoteAddress());\n            OLogManager.instance().debug(this, \"Sent updated cluster configuration to the remote client %s\", c.getRemoteAddress());\n\n          } finally {\n            channel.releaseWriteLock();\n          }\n        } else {\n          OLogManager.instance()\n              .info(this, \"Timeout on sending updated cluster configuration to the remote client %s\", c.getRemoteAddress());\n        }\n      } catch (Exception e) {\n        OLogManager.instance().warn(this, \"Cannot push cluster configuration to the client %s\", e, c.getRemoteAddress());\n      }\n    }\n  }",
        "explanations_by_ours": [
            "The configuration to push.",
            "The configuration to be pushed.",
            "The new configuration to push."
        ],
        "corrections_by_ours": [
            "configuration",
            "new",
            "pushed",
            "push"
        ],
        "corrections_by_baseline": [
            "dv2",
            "helm2",
            "de2",
            "ival2",
            "gt",
            "sgt",
            "v2",
            "bte",
            "dub",
            "ival1"
        ]
    },
    {
        "original_word": "contents",
        "typo_word": "conhenhs",
        "original_variable": "contents",
        "typo_variable": "conhenhs",
        "original_code": "static public String\n    locateFile(String filename, String abspath, boolean wantdir)\n    {\n        Deque<String> q = new ArrayDeque<String>();\n        // clean up the path and filename\n        filename = filename.trim().replace('\\\\', '/');\n        abspath = abspath.trim().replace('\\\\', '/');\n        if(filename.charAt(0) == '/') filename = filename.substring(1);\n        if(filename.endsWith(\"/\")) filename = filename.substring(0, filename.length() - 1);\n        if(abspath.endsWith(\"/\")) abspath = abspath.substring(0, abspath.length() - 1);\n        q.addFirst(abspath);  // prime the search queue\n\n        for(; ; ) {  // breadth first search\n            String currentpath = q.poll();\n            if(currentpath == null) break; // done searching\n            File current = new File(currentpath);\n            File[] contents = current.listFiles();\n            if(contents != null) {\n                for(File subfile : contents) {\n                    if(!subfile.getName().equals(filename)) continue;\n                    if((wantdir && subfile.isDirectory())\n                            || (!wantdir && subfile.isFile())) {\n                        // Assume this is it\n                        return DapUtil.canonicalpath(subfile.getAbsolutePath());\n                    }\n                }\n                for(File subfile : contents) {\n                    if(subfile.isDirectory())\n                        q.addFirst(currentpath + \"/\" + subfile.getName());\n                }\n            }\n        }\n        return null;\n    }",
        "modified_code": "static public String\n    locateFile(String filename, String abspath, boolean wantdir)\n    {\n        Deque<String> q = new ArrayDeque<String>();\n        // clean up the path and filename\n        filename = filename.trim().replace('\\\\', '/');\n        abspath = abspath.trim().replace('\\\\', '/');\n        if(filename.charAt(0) == '/') filename = filename.substring(1);\n        if(filename.endsWith(\"/\")) filename = filename.substring(0, filename.length() - 1);\n        if(abspath.endsWith(\"/\")) abspath = abspath.substring(0, abspath.length() - 1);\n        q.addFirst(abspath);  // prime the search queue\n\n        for(; ; ) {  // breadth first search\n            String currentpath = q.poll();\n            if(currentpath == null) break; // done searching\n            File current = new File(currentpath);\n            File[] conhenhs = current.listFiles();\n            if(conhenhs != null) {\n                for(File subfile : conhenhs) {\n                    if(!subfile.getName().equals(filename)) continue;\n                    if((wantdir && subfile.isDirectory())\n                            || (!wantdir && subfile.isFile())) {\n                        // Assume this is it\n                        return DapUtil.canonicalpath(subfile.getAbsolutePath());\n                    }\n                }\n                for(File subfile : conhenhs) {\n                    if(subfile.isDirectory())\n                        q.addFirst(currentpath + \"/\" + subfile.getName());\n                }\n            }\n        }\n        return null;\n    }",
        "explanations_by_ours": [
            "the list of files in the classpath",
            "the list of files to search in the classpath",
            "the list of files to search"
        ],
        "corrections_by_ours": [
            "files",
            "search",
            "classpath",
            "list"
        ],
        "corrections_by_baseline": [
            "con",
            "dcon",
            "conj",
            "conMod",
            "co",
            "pco",
            "SY",
            "sy",
            "sco",
            "qco"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "dxlue",
        "original_variable": "value",
        "typo_variable": "dxlue",
        "original_code": "public SnapshotRecord readSnapshotRecord() throws IOException, ClassNotFoundException {\n      byte[] key = DataSerializer.readByteArray(dis);\n      if (key == null) {\n        return null;\n      }\n\n      byte[] value = DataSerializer.readByteArray(dis);\n      return new SnapshotRecord(key, value);\n    }",
        "modified_code": "public SnapshotRecord readSnapshotRecord() throws IOException, ClassNotFoundException {\n      byte[] key = DataSerializer.readByteArray(dis);\n      if (key == null) {\n        return null;\n      }\n\n      byte[] dxlue = DataSerializer.readByteArray(dis);\n      return new SnapshotRecord(key, dxlue);\n    }",
        "explanations_by_ours": [
            "the dxlue of the snapshot record",
            "the dxlue",
            "the dxlue of the snapshot record."
        ],
        "corrections_by_ours": [
            "record",
            "snapshot"
        ],
        "corrections_by_baseline": [
            "ylogx",
            "glomx",
            "dx",
            "lxcent",
            "bx",
            "graphics2D",
            "dx1",
            "xUlpDbl",
            "SX",
            "sx"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "dexult",
        "original_variable": "result",
        "typo_variable": "dexult",
        "original_code": "public static PropertyDescriptor getPropertyDescriptorFromArray(Class targetClass, String name)\n            throws IntrospectionException\n    {\n        PropertyDescriptor result = null;\n        PropertyDescriptor[] pda = getPropertyDescriptorsArray(targetClass);\n\n        for (int i = 0, icount = pda.length; (result == null) && (i < icount); i++) {\n            if (pda[i].getName().compareTo(name) == 0) {\n                result = pda[i];\n            }\n        }\n        return result;\n    }",
        "modified_code": "public static PropertyDescriptor getPropertyDescriptorFromArray(Class targetClass, String name)\n            throws IntrospectionException\n    {\n        PropertyDescriptor dexult = null;\n        PropertyDescriptor[] pda = getPropertyDescriptorsArray(targetClass);\n\n        for (int i = 0, icount = pda.length; (dexult == null) && (i < icount); i++) {\n            if (pda[i].getName().compareTo(name) == 0) {\n                dexult = pda[i];\n            }\n        }\n        return dexult;\n    }",
        "explanations_by_ours": [
            "If not null, return the property descriptor from the array.",
            "if null, return the first one.",
            "If not null, return the property descriptor."
        ],
        "corrections_by_ours": [
            "return",
            "descriptor",
            "null,",
            "first",
            "property",
            "array",
            "one"
        ],
        "corrections_by_baseline": [
            "dresult",
            "fresult",
            "cresult",
            "lresult",
            "resultXA",
            "dapex",
            "dResult",
            "sresult",
            "isr",
            "resultDs"
        ]
    },
    {
        "original_word": "helm",
        "typo_word": "heoj",
        "original_variable": "helmInput",
        "typo_variable": "heojInput",
        "original_code": "private void jButton1ActionPerformed(java.awt.event.ActionEvent evt) {\r\n    String helmInput = input.getText();\r\n    if (!(helmInput.contains(\"V2.0\"))) {\r\n      /* Translate into HELM2-format */\r\n    \t      helmInput = converter.doConvert(helmInput);\r\n    \t\r\n\r\n    }\r\n\r\n    /* read input */\r\n    try {\r\n      parser.parse(helmInput);\r\n      writeOutputmessage();\r\n    } catch (ExceptionState e) {\r\n      output.setText(\"Invalid HELM-String (\" + e.getMessage() + \")\");\r\n    }\r\n\r\n  }",
        "modified_code": "private void jButton1ActionPerformed(java.awt.event.ActionEvent evt) {\r\n    String heojInput = input.getText();\r\n    if (!(heojInput.contains(\"V2.0\"))) {\r\n      /* Translate into HELM2-format */\r\n    \t      heojInput = converter.doConvert(heojInput);\r\n    \t\r\n\r\n    }\r\n\r\n    /* read input */\r\n    try {\r\n      parser.parse(heojInput);\r\n      writeOutputmessage();\r\n    } catch (ExceptionState e) {\r\n      output.setText(\"Invalid HELM-String (\" + e.getMessage() + \")\");\r\n    }\r\n\r\n  }",
        "explanations_by_ours": [
            "the input",
            "the input text",
            "the new input"
        ],
        "corrections_by_ours": [
            "textInput",
            "newInput",
            "heojText",
            "heojNew",
            "inputInput",
            "heojInput"
        ],
        "corrections_by_baseline": [
            "zzInput",
            "helmInput",
            "input",
            "input1",
            "input58",
            "inputSource",
            "inputFile",
            "inputBytes",
            "input2",
            "inputs"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "dezult",
        "original_variable": "result",
        "typo_variable": "dezult",
        "original_code": "public static MultiTypeData getMultiTypeData(float f)\n    {\n        // Convert the value to a String and return the set of types that that String can be converted to.\n        MultiTypeData result = getMultiTypeData(Float.toString(f));\n        result.nativeType = FLOAT;\n\n        return result;\n    }",
        "modified_code": "public static MultiTypeData getMultiTypeData(float f)\n    {\n        // Convert the value to a String and return the set of types that that String can be converted to.\n        MultiTypeData dezult = getMultiTypeData(Float.toString(f));\n        dezult.nativeType = FLOAT;\n\n        return dezult;\n    }",
        "explanations_by_ours": [
            "The MultiTypeData object that represents the given float value.",
            "The MultiTypeData object that represents the given value.",
            "The MultiTypeData object that represents the value."
        ],
        "corrections_by_ours": [
            "multi",
            "represents",
            "float",
            "data",
            "value",
            "object",
            "given",
            "type"
        ],
        "corrections_by_baseline": [
            "de",
            "mefd",
            "dys",
            "de2",
            "dz",
            "deref",
            "zis",
            "ncd",
            "difmin",
            "azim"
        ]
    },
    {
        "original_word": "cooky",
        "typo_word": "coljy",
        "original_variable": "cooky",
        "typo_variable": "coljy",
        "original_code": "public String getCookies()\n    {\n        Map info = new TreeMap();\n        HttpServletRequest req = (HttpServletRequest) pageContext.getRequest();\n        Cookie[] cookies = req.getCookies();\n\n        // check that cookies is not null which it may be if there are no cookies\n        if (cookies != null)\n        {\n            for (int i = 0; i < cookies.length; i++)\n            {\n                Cookie cooky = cookies[i];\n                info.put(cooky.getName(), cooky.getValue());\n            }\n        }\n\n        return toHTMLTable(\"cookies\", info);\n    }",
        "modified_code": "public String getCookies()\n    {\n        Map info = new TreeMap();\n        HttpServletRequest req = (HttpServletRequest) pageContext.getRequest();\n        Cookie[] cookies = req.getCookies();\n\n        // check that cookies is not null which it may be if there are no cookies\n        if (cookies != null)\n        {\n            for (int i = 0; i < cookies.length; i++)\n            {\n                Cookie coljy = cookies[i];\n                info.put(coljy.getName(), coljy.getValue());\n            }\n        }\n\n        return toHTMLTable(\"cookies\", info);\n    }",
        "explanations_by_ours": [
            "the cookie name and value",
            "the cookie to be included in the HTML table",
            "the cookie to be included in the HTML table."
        ],
        "corrections_by_ours": [
            "cookie",
            "value",
            "included",
            "name",
            "html",
            "table"
        ],
        "corrections_by_baseline": [
            "xcoli",
            "col1",
            "col2",
            "colNdx",
            "PoleCol",
            "col",
            "_col",
            "cols",
            "dcol",
            "currCol"
        ]
    },
    {
        "original_word": "local",
        "typo_word": "kpcal",
        "original_variable": "local",
        "typo_variable": "kpcal",
        "original_code": "protected String makeAbsolute(String sysid) {\n    URL local = null;\n\n    sysid = fixSlashes(sysid);\n\n    try {\n      local = new URL(base, sysid);\n    } catch (MalformedURLException e) {\n      catalogManager.debug.message(1, \"Malformed URL on system identifier\", sysid);\n    }\n\n    if (local != null) {\n      return local.toString();\n    } else {\n      return sysid;\n    }\n  }",
        "modified_code": "protected String makeAbsolute(String sysid) {\n    URL kpcal = null;\n\n    sysid = fixSlashes(sysid);\n\n    try {\n      kpcal = new URL(base, sysid);\n    } catch (MalformedURLException e) {\n      catalogManager.debug.message(1, \"Malformed URL on system identifier\", sysid);\n    }\n\n    if (kpcal != null) {\n      return kpcal.toString();\n    } else {\n      return sysid;\n    }\n  }",
        "explanations_by_ours": [
            "the system identifier relative to the base system identifier",
            "the URL of the system identifier to make absolute",
            "the system identifier relative to the base"
        ],
        "corrections_by_ours": [
            "kpurl",
            "makecal",
            "kpbase",
            "kpmake",
            "kpabsolute",
            "kprelative",
            "identifiercal",
            "basecal",
            "systemcal",
            "urlcal"
        ],
        "corrections_by_baseline": [
            "cal",
            "kx",
            "kf",
            "cal1",
            "pco",
            "cfac",
            "dcat",
            "nk",
            "tmpCal",
            "skf"
        ]
    },
    {
        "original_word": "sequence",
        "typo_word": "seauehce",
        "original_variable": "sequenceKey",
        "typo_variable": "seauehceKey",
        "original_code": "public E get(SymbolKey key, L secondaryKey)\n    {\n        // Extract the sequence key from the symbol key.\n        int sequenceKey = ((SymbolKeyImpl) key).sequenceKey;\n\n        // Check that the field for the secondary key exists, and return null if not.\n        CircularArrayMap<E> field = fieldMap.get(secondaryKey);\n\n        if (field == null)\n        {\n            return null;\n        }\n\n        // Look up the value directly by its sequence key.\n        return field.get(sequenceKey);\n    }",
        "modified_code": "public E get(SymbolKey key, L secondaryKey)\n    {\n        // Extract the sequence key from the symbol key.\n        int seauehceKey = ((SymbolKeyImpl) key).seauehceKey;\n\n        // Check that the field for the secondary key exists, and return null if not.\n        CircularArrayMap<E> field = fieldMap.get(secondaryKey);\n\n        if (field == null)\n        {\n            return null;\n        }\n\n        // Look up the value directly by its sequence key.\n        return field.get(seauehceKey);\n    }",
        "explanations_by_ours": [
            "The sequence key for the given secondary key.",
            "The sequence key.",
            "The sequence key of the secondary key."
        ],
        "corrections_by_ours": [
            "sequenceKey",
            "secondaryKey",
            "seauehceSecondary",
            "seauehceGiven",
            "keyKey",
            "givenKey",
            "seauehceSequence",
            "seauehceKey"
        ],
        "corrections_by_baseline": [
            "clientKey",
            "skey",
            "base64Key",
            "completeKey",
            "providedKey",
            "mkey",
            "nnKey",
            "providerKey",
            "sessionKey",
            "keyString"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "recuot",
        "original_variable": "result",
        "typo_variable": "recuot",
        "original_code": "public static short getShortFromBytes(byte[] buf, int offset)\n    {\n        short result = 0;\n\n        result += buf[offset++] & 0xFF;\n        result += ((buf[offset]) << 8);\n\n        return result;\n    }",
        "modified_code": "public static short getShortFromBytes(byte[] buf, int offset)\n    {\n        short recuot = 0;\n\n        recuot += buf[offset++] & 0xFF;\n        recuot += ((buf[offset]) << 8);\n\n        return recuot;\n    }",
        "explanations_by_ours": [
            "value to be returned",
            "short to be returned",
            "current byte value"
        ],
        "corrections_by_ours": [
            "returned",
            "short",
            "value",
            "current",
            "byte"
        ],
        "corrections_by_baseline": [
            "rec",
            "nrec",
            "upc",
            "re",
            "revs",
            "numrec",
            "rev",
            "resul",
            "recs",
            "revalidate"
        ]
    },
    {
        "original_word": "midpoint",
        "typo_word": "nidpoiny",
        "original_variable": "midpoint",
        "typo_variable": "nidpoiny",
        "original_code": "public void sort() {\n        Arrays.sort(freeOrdinals, 0, size);\n\n        /// reverse the ordering\n        int midpoint = size / 2;\n        for(int i=0;i<midpoint;i++) {\n            int temp = freeOrdinals[i];\n            freeOrdinals[i] = freeOrdinals[size-i-1];\n            freeOrdinals[size-i-1] = temp;\n        }\n    }",
        "modified_code": "public void sort() {\n        Arrays.sort(freeOrdinals, 0, size);\n\n        /// reverse the ordering\n        int nidpoiny = size / 2;\n        for(int i=0;i<nidpoiny;i++) {\n            int temp = freeOrdinals[i];\n            freeOrdinals[i] = freeOrdinals[size-i-1];\n            freeOrdinals[size-i-1] = temp;\n        }\n    }",
        "explanations_by_ours": [
            "the number of free ordinals to sort",
            "the number of free ordinals to sort.",
            "The number of free ordinals to sort."
        ],
        "corrections_by_ours": [
            "sort",
            "ordinals",
            "number",
            "free"
        ],
        "corrections_by_baseline": [
            "ncd",
            "fluidItmId",
            "dod",
            "p2n",
            "stnWmoId",
            "a4p",
            "p1n",
            "idat2",
            "nk",
            "ejbCreateId"
        ]
    },
    {
        "original_word": "aggregate",
        "typo_word": "aggreyzte",
        "original_variable": "aggregate",
        "typo_variable": "aggreyzte",
        "original_code": "public BaseType getVariable(int row, String name) throws NoSuchVariableException {\r\n\r\n        int dotIndex = name.indexOf('.');\r\n\r\n        if (dotIndex != -1) {  // name contains \".\"\r\n            String aggregate = name.substring(0, dotIndex);\r\n            String field = name.substring(dotIndex + 1);\r\n\r\n            BaseType aggRef = getVariable(aggregate);\r\n            if (aggRef instanceof DConstructor)\r\n                return ((DConstructor) aggRef).getVariable(field);  // recurse\r\n            else\r\n                ; // fall through to throw statement\r\n        } else {\r\n            Vector selectedRow = (Vector) allValues.elementAt(row);\r\n            for (Enumeration e = selectedRow.elements(); e.hasMoreElements();) {\r\n                BaseType v = (BaseType) e.nextElement();\r\n                if (v.getEncodedName().equals(name))\r\n                    return v;\r\n            }\r\n        }\r\n        throw new NoSuchVariableException(\"DSequence: getVariable()\");\r\n    }",
        "modified_code": "public BaseType getVariable(int row, String name) throws NoSuchVariableException {\r\n\r\n        int dotIndex = name.indexOf('.');\r\n\r\n        if (dotIndex != -1) {  // name contains \".\"\r\n            String aggreyzte = name.substring(0, dotIndex);\r\n            String field = name.substring(dotIndex + 1);\r\n\r\n            BaseType aggRef = getVariable(aggreyzte);\r\n            if (aggRef instanceof DConstructor)\r\n                return ((DConstructor) aggRef).getVariable(field);  // recurse\r\n            else\r\n                ; // fall through to throw statement\r\n        } else {\r\n            Vector selectedRow = (Vector) allValues.elementAt(row);\r\n            for (Enumeration e = selectedRow.elements(); e.hasMoreElements();) {\r\n                BaseType v = (BaseType) e.nextElement();\r\n                if (v.getEncodedName().equals(name))\r\n                    return v;\r\n            }\r\n        }\r\n        throw new NoSuchVariableException(\"DSequence: getVariable()\");\r\n    }",
        "explanations_by_ours": [
            "The aggreyzte.",
            "The aggreyzte name.",
            "The aggregation name."
        ],
        "corrections_by_ours": [
            "aggregation",
            "name"
        ],
        "corrections_by_baseline": [
            "nexte",
            "bytedata",
            "ykr",
            "wierd",
            "zsoil",
            "trovit",
            "Sterm",
            "smo",
            "te",
            "anbieter"
        ]
    },
    {
        "original_word": "conflict",
        "typo_word": "contlift",
        "original_variable": "conflictStack",
        "typo_variable": "contliftStack",
        "original_code": "private Stack<QuickSortSet.Cell> forwardPath(QuickSortSet.Cell lexemeCell , LexemePath option){\r\n\t\t//\u53d1\u751f\u51b2\u7a81\u7684Lexeme\u6808\r\n\t\tStack<QuickSortSet.Cell> conflictStack = new Stack<QuickSortSet.Cell>();\r\n\t\tQuickSortSet.Cell c = lexemeCell;\r\n\t\t//\u8fed\u4ee3\u904d\u5386Lexeme\u94fe\u8868\r\n\t\twhile(c != null && c.getLexeme() != null){\r\n\t\t\tif(!option.addNotCrossLexeme(c.getLexeme())){\r\n\t\t\t\t//\u8bcd\u5143\u4ea4\u53c9\uff0c\u6dfb\u52a0\u5931\u8d25\u5219\u52a0\u5165lexemeStack\u6808\r\n\t\t\t\tconflictStack.push(c);\r\n\t\t\t}\r\n\t\t\tc = c.getNext();\r\n\t\t}\r\n\t\treturn conflictStack;\r\n\t}",
        "modified_code": "private Stack<QuickSortSet.Cell> forwardPath(QuickSortSet.Cell lexemeCell , LexemePath option){\r\n\t\t//\u53d1\u751f\u51b2\u7a81\u7684Lexeme\u6808\r\n\t\tStack<QuickSortSet.Cell> contliftStack = new Stack<QuickSortSet.Cell>();\r\n\t\tQuickSortSet.Cell c = lexemeCell;\r\n\t\t//\u8fed\u4ee3\u904d\u5386Lexeme\u94fe\u8868\r\n\t\twhile(c != null && c.getLexeme() != null){\r\n\t\t\tif(!option.addNotCrossLexeme(c.getLexeme())){\r\n\t\t\t\t//\u8bcd\u5143\u4ea4\u53c9\uff0c\u6dfb\u52a0\u5931\u8d25\u5219\u52a0\u5165lexemeStack\u6808\r\n\t\t\t\tcontliftStack.push(c);\r\n\t\t\t}\r\n\t\t\tc = c.getNext();\r\n\t\t}\r\n\t\treturn contliftStack;\r\n\t}",
        "explanations_by_ours": [
            ".",
            "the contlift stack",
            "the contliftStack"
        ],
        "corrections_by_ours": [
            "liftliftStack",
            "contcontStack",
            "stackliftStack",
            "contstackStack",
            "contliftLift",
            "contliftCont",
            "contliftStack"
        ],
        "corrections_by_baseline": [
            "stack",
            "mvelStack",
            "emStack",
            "callStack",
            "undoStack",
            "newOutputStack",
            "numStack",
            "stackWrappers",
            "inputStackTop",
            "allStacks"
        ]
    },
    {
        "original_word": "fields",
        "typo_word": "fieors",
        "original_variable": "fields",
        "typo_variable": "fieors",
        "original_code": "protected void\n    buildseqtypes(Variable cdmvar)\n            throws DapException\n    {\n        if (CDMUtil.hasVLEN(cdmvar)) {\n            buildseqtype(cdmvar);\n        }\n        if (cdmvar.getDataType() == DataType.STRUCTURE\n                || cdmvar.getDataType() == DataType.SEQUENCE) {\n            Structure struct = (Structure) cdmvar;\n            List<Variable> fields = struct.getVariables();\n            for (int i = 0; i < fields.size(); i++) {\n                Variable field = fields.get(i);\n                buildseqtypes(field); // recurse for inner vlen dims\n            }\n        }\n    }",
        "modified_code": "protected void\n    buildseqtypes(Variable cdmvar)\n            throws DapException\n    {\n        if (CDMUtil.hasVLEN(cdmvar)) {\n            buildseqtype(cdmvar);\n        }\n        if (cdmvar.getDataType() == DataType.STRUCTURE\n                || cdmvar.getDataType() == DataType.SEQUENCE) {\n            Structure struct = (Structure) cdmvar;\n            List<Variable> fieors = struct.getVariables();\n            for (int i = 0; i < fieors.size(); i++) {\n                Variable field = fieors.get(i);\n                buildseqtypes(field); // recurse for inner vlen dims\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the list of fields in the structure",
            "the list of all the fields in the structure",
            "the list of all the fields of the CDM variable"
        ],
        "corrections_by_ours": [
            "fields",
            "list",
            "variable",
            "structure",
            "cdm"
        ],
        "corrections_by_baseline": [
            "factors",
            "actors",
            "fos",
            "finer",
            "ifaces",
            "bsers",
            "ngates",
            "ofs",
            "thoseFactors",
            "vmas"
        ]
    },
    {
        "original_word": "implementation",
        "typo_word": "implemengatiln",
        "original_variable": "implementation",
        "typo_variable": "implemengatiln",
        "original_code": "public static <T> T getService(final Class<T> intf, final Class<? extends T> defaultImpl)\n        throws ModuleLoaderException\n    {\n        final T implementation = getServiceOrElse(intf, null);\n\n        if (implementation != null) {\n            return implementation;\n        }\n\n        if (defaultImpl == null) {\n            throw new ModuleLoaderException(\"Missing implementation: \" + intf);\n        }\n\n        try {\n            return defaultImpl.getConstructor().newInstance();\n        } catch (final InstantiationException | IllegalAccessException | InvocationTargetException | NoSuchMethodException e) {\n            throw new ModuleLoaderException(\"Cannot instantiate class\", e);\n        }\n    }",
        "modified_code": "public static <T> T getService(final Class<T> intf, final Class<? extends T> defaultImpl)\n        throws ModuleLoaderException\n    {\n        final T implemengatiln = getServiceOrElse(intf, null);\n\n        if (implemengatiln != null) {\n            return implemengatiln;\n        }\n\n        if (defaultImpl == null) {\n            throw new ModuleLoaderException(\"Missing implementation: \" + intf);\n        }\n\n        try {\n            return defaultImpl.getConstructor().newInstance();\n        } catch (final InstantiationException | IllegalAccessException | InvocationTargetException | NoSuchMethodException e) {\n            throw new ModuleLoaderException(\"Cannot instantiate class\", e);\n        }\n    }",
        "explanations_by_ours": [
            "implementation to use if the interface is not found",
            "implementation of the interface",
            "implementation to return if the interface is found"
        ],
        "corrections_by_ours": [
            "implementation",
            "interface",
            "return",
            "use",
            "found"
        ],
        "corrections_by_baseline": [
            "udim",
            "iminut",
            "mefd",
            "trovit",
            "azim",
            "vsn",
            "pihalf",
            "glomn",
            "ilenhd",
            "nf"
        ]
    },
    {
        "original_word": "stream",
        "typo_word": "strrah",
        "original_variable": "streamName",
        "typo_variable": "strrahName",
        "original_code": "public IURLProtocolHandler mapIO(String url, IURLProtocolHandler handler,\n      boolean unmapUrlOnOpen)\n  {\n    {\n      if (url == null || url.length() <= 0)\n        throw new IllegalArgumentException(\"must pass in non-zero url\");\n      if (handler == null)\n      {\n        throw new IllegalArgumentException(\"must pass in a non null handler\");\n      }\n      String streamName = URLProtocolManager.getResourceFromURL(url);\n      RegistrationInformation tuple = new RegistrationInformation(streamName,\n          handler, unmapUrlOnOpen);\n      RegistrationInformation oldTuple = mURLs.putIfAbsent(streamName, tuple);\n      return oldTuple == null ? null : oldTuple.getHandler();\n    }\n  }",
        "modified_code": "public IURLProtocolHandler mapIO(String url, IURLProtocolHandler handler,\n      boolean unmapUrlOnOpen)\n  {\n    {\n      if (url == null || url.length() <= 0)\n        throw new IllegalArgumentException(\"must pass in non-zero url\");\n      if (handler == null)\n      {\n        throw new IllegalArgumentException(\"must pass in a non null handler\");\n      }\n      String strrahName = URLProtocolManager.getResourceFromURL(url);\n      RegistrationInformation tuple = new RegistrationInformation(strrahName,\n          handler, unmapUrlOnOpen);\n      RegistrationInformation oldTuple = mURLs.putIfAbsent(strrahName, tuple);\n      return oldTuple == null ? null : oldTuple.getHandler();\n    }\n  }",
        "explanations_by_ours": [
            "the name of the handler",
            "the name of the handler to map",
            "the name of the URL to map"
        ],
        "corrections_by_ours": [
            "strmapName",
            "strrahHandler",
            "strnameName",
            "strrahMap",
            "handlerrahName",
            "strhandlerName",
            "urlrahName",
            "namerahName",
            "maprahName",
            "strurlName"
        ],
        "corrections_by_baseline": [
            "strName",
            "ejbName",
            "tsrName",
            "sname",
            "_name",
            "name",
            "stnName",
            "eName",
            "trimmedName",
            "simpleName"
        ]
    },
    {
        "original_word": "Empty",
        "typo_word": "Emotj",
        "original_variable": "textNotEmpty",
        "typo_variable": "textNotEmotj",
        "original_code": "private void openNewFolderDialog() {\n        @SuppressLint(\"InflateParams\")\n        final View dialogView = getActivity().getLayoutInflater().inflate(\n                R.layout.dialog_new_folder, null);\n        final TextView msgView = (TextView) dialogView.findViewById(R.id.msgText);\n        final EditText editText = (EditText) dialogView.findViewById(R.id.editText);\n        editText.setText(mNewDirectoryName);\n        msgView.setText(getString(R.string.create_folder_msg, mNewDirectoryName));\n\n        final AlertDialog alertDialog = new AlertDialog.Builder(getActivity())\n                .setTitle(R.string.create_folder_label)\n                .setView(dialogView)\n                .setNegativeButton(R.string.cancel_label,\n                        new DialogInterface.OnClickListener() {\n\n                            @Override\n                            public void onClick(final DialogInterface dialog, final int which) {\n                                dialog.dismiss();\n                            }\n                        })\n                .setPositiveButton(R.string.confirm_label,\n                        new DialogInterface.OnClickListener() {\n\n                            @Override\n                            public void onClick(final DialogInterface dialog, final int which) {\n                                dialog.dismiss();\n                                mNewDirectoryName = editText.getText().toString();\n                                final int msg = createFolder();\n                                Toast.makeText(getActivity(), msg, Toast.LENGTH_SHORT).show();\n                            }\n                        })\n                .show();\n\n        alertDialog.getButton(DialogInterface.BUTTON_POSITIVE).setEnabled(editText.getText().length() != 0);\n\n        editText.addTextChangedListener(new TextWatcher() {\n            @Override\n            public void beforeTextChanged(final CharSequence charSequence, final int i, final int i2, final int i3) {\n\n            }\n\n            @Override\n            public void onTextChanged(final CharSequence charSequence, final int i, final int i2, final int i3) {\n                final boolean textNotEmpty = charSequence.length() != 0;\n                alertDialog.getButton(DialogInterface.BUTTON_POSITIVE).setEnabled(textNotEmpty);\n                msgView.setText(getString(R.string.create_folder_msg, charSequence.toString()));\n            }\n\n            @Override\n            public void afterTextChanged(final Editable editable) {\n\n            }\n        });\n\n        editText.setVisibility(mConfig.allowNewDirectoryNameModification()\n                ? View.VISIBLE : View.GONE);\n    }",
        "modified_code": "private void openNewFolderDialog() {\n        @SuppressLint(\"InflateParams\")\n        final View dialogView = getActivity().getLayoutInflater().inflate(\n                R.layout.dialog_new_folder, null);\n        final TextView msgView = (TextView) dialogView.findViewById(R.id.msgText);\n        final EditText editText = (EditText) dialogView.findViewById(R.id.editText);\n        editText.setText(mNewDirectoryName);\n        msgView.setText(getString(R.string.create_folder_msg, mNewDirectoryName));\n\n        final AlertDialog alertDialog = new AlertDialog.Builder(getActivity())\n                .setTitle(R.string.create_folder_label)\n                .setView(dialogView)\n                .setNegativeButton(R.string.cancel_label,\n                        new DialogInterface.OnClickListener() {\n\n                            @Override\n                            public void onClick(final DialogInterface dialog, final int which) {\n                                dialog.dismiss();\n                            }\n                        })\n                .setPositiveButton(R.string.confirm_label,\n                        new DialogInterface.OnClickListener() {\n\n                            @Override\n                            public void onClick(final DialogInterface dialog, final int which) {\n                                dialog.dismiss();\n                                mNewDirectoryName = editText.getText().toString();\n                                final int msg = createFolder();\n                                Toast.makeText(getActivity(), msg, Toast.LENGTH_SHORT).show();\n                            }\n                        })\n                .show();\n\n        alertDialog.getButton(DialogInterface.BUTTON_POSITIVE).setEnabled(editText.getText().length() != 0);\n\n        editText.addTextChangedListener(new TextWatcher() {\n            @Override\n            public void beforeTextChanged(final CharSequence charSequence, final int i, final int i2, final int i3) {\n\n            }\n\n            @Override\n            public void onTextChanged(final CharSequence charSequence, final int i, final int i2, final int i3) {\n                final boolean textNotEmotj = charSequence.length() != 0;\n                alertDialog.getButton(DialogInterface.BUTTON_POSITIVE).setEnabled(textNotEmotj);\n                msgView.setText(getString(R.string.create_folder_msg, charSequence.toString()));\n            }\n\n            @Override\n            public void afterTextChanged(final Editable editable) {\n\n            }\n        });\n\n        editText.setVisibility(mConfig.allowNewDirectoryNameModification()\n                ? View.VISIBLE : View.GONE);\n    }",
        "explanations_by_ours": [
            "true if the text is not emotj",
            "true if the text is not emotj.",
            "true if the text should not be emotied."
        ],
        "corrections_by_ours": [
            "textNotEmotied",
            "textEmotjEmotj",
            "textEmotiedEmotj",
            "trueNotEmotj",
            "textTextEmotj",
            "emotjNotEmotj",
            "textNotText",
            "emotiedNotEmotj",
            "textTrueEmotj",
            "textNotTrue"
        ],
        "corrections_by_baseline": [
            "Q_TEXT",
            "text",
            "ttext",
            "textNotEmpty",
            "A_TEXT",
            "REGULAR_A_TEXT",
            "rtPlainText",
            "rtText",
            "D_TEXT",
            "text2Use"
        ]
    },
    {
        "original_word": "relation",
        "typo_word": "rrlafion",
        "original_variable": "relation",
        "typo_variable": "rrlafion",
        "original_code": "static boolean\n  urlMatch(URL pattern, URL url) {\n    int relation;\n\n    if (pattern == null)\n      return (url == null);\n\n    if (!(url.getHost().endsWith(pattern.getHost())))\n      return false; // e.g. pattern=x.y.org url=y.org\n\n    if (!(url.getPath().startsWith(pattern.getPath())))\n      return false; // e.g. pattern=y.org/a/b url=y.org/a\n\n    if (pattern.getPort() > 0 && pattern.getPort() != url.getPort())\n      return false;\n\n    // note: all other fields are ignored\n\n    return true;\n  }",
        "modified_code": "static boolean\n  urlMatch(URL pattern, URL url) {\n    int rrlafion;\n\n    if (pattern == null)\n      return (url == null);\n\n    if (!(url.getHost().endsWith(pattern.getHost())))\n      return false; // e.g. pattern=x.y.org url=y.org\n\n    if (!(url.getPath().startsWith(pattern.getPath())))\n      return false; // e.g. pattern=y.org/a/b url=y.org/a\n\n    if (pattern.getPort() > 0 && pattern.getPort() != url.getPort())\n      return false;\n\n    // note: all other fields are ignored\n\n    return true;\n  }",
        "explanations_by_ours": [
            "The rrlafion of the URL.",
            "the rrlafion of the URL.",
            "The rrlafion of the given URL."
        ],
        "corrections_by_ours": [
            "url",
            "given"
        ],
        "corrections_by_baseline": [
            "rcidpe",
            "dnsRecord",
            "cidpe",
            "ncidp",
            "idr",
            "rtn",
            "spcid",
            "hrsi",
            "nfe",
            "destinationVId"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reduot",
        "original_variable": "result",
        "typo_variable": "reduot",
        "original_code": "public static String getString ( final Map<MetaKey, String> metadata, final String ns, final String key, final String defaultValue )\n    {\n        if ( metadata == null )\n        {\n            return defaultValue;\n        }\n        final String result = metadata.get ( new MetaKey ( ns, key ) );\n        if ( result == null )\n        {\n            return defaultValue;\n        }\n        return result;\n    }",
        "modified_code": "public static String getString ( final Map<MetaKey, String> metadata, final String ns, final String key, final String defaultValue )\n    {\n        if ( metadata == null )\n        {\n            return defaultValue;\n        }\n        final String reduot = metadata.get ( new MetaKey ( ns, key ) );\n        if ( reduot == null )\n        {\n            return defaultValue;\n        }\n        return reduot;\n    }",
        "explanations_by_ours": [
            "the reduot",
            "the reduot value",
            "the reduceot"
        ],
        "corrections_by_ours": [
            "reduceot",
            "value"
        ],
        "corrections_by_baseline": [
            "red",
            "nopr",
            "noisedba",
            "ot",
            "andrew",
            "resul",
            "wrpUnchecked",
            "dou",
            "uom",
            "otps"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "xohnt",
        "original_variable": "count",
        "typo_variable": "xohnt",
        "original_code": "boolean readPIB(RandomAccessFile raf) throws IOException {\n\n    this.firstHeader = new AwxFileFirstHeader();\n\n    int pos = 0;\n    raf.seek(pos);\n\n    // gini header process\n    byte[] buf = new byte[FY_AWX_PIB_LEN];\n    int count = raf.read(buf);\n    EndianByteBuffer byteBuffer;\n    if (count == FY_AWX_PIB_LEN) {\n      byteBuffer = new EndianByteBuffer(buf, this.firstHeader.byteOrder);\n      this.firstHeader.fillHeader(byteBuffer);\n\n    } else {\n      return false;\n    }\n\n    if (!((this.firstHeader.fileName.endsWith(\".AWX\") || this.firstHeader.fileName.endsWith(\".awx\"))\n            && this.firstHeader.firstHeaderLength == FY_AWX_PIB_LEN)) {\n      return false;\n    }\n\n    // skip the fills of the first record\n    //  raf.seek(FY_AWX_PIB_LEN + this.firstHeader.fillSectionLength);\n    buf = new byte[this.firstHeader.secondHeaderLength];\n    raf.readFully(buf);\n    byteBuffer = new EndianByteBuffer(buf, this.firstHeader.byteOrder);\n    switch (this.firstHeader.typeOfProduct) {\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_UNDEFINED:\n        throw new UnsupportedDatasetException();\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_GEOSAT_IMAGE:\n        secondHeader = new AwxFileGeoSatelliteSecondHeader();\n        secondHeader.fillHeader(byteBuffer);\n        break;\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_POLARSAT_IMAGE:\n        throw new UnsupportedDatasetException();\n\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_GRID:\n        secondHeader = new AwxFileGridProductSecondHeader();\n        secondHeader.fillHeader(byteBuffer);\n\n        break;\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_DISCREET:\n        throw new UnsupportedDatasetException();\n\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_GRAPH_ANALIYSIS:\n        throw new UnsupportedDatasetException();\n\n    }\n\n    return true;\n\n  }",
        "modified_code": "boolean readPIB(RandomAccessFile raf) throws IOException {\n\n    this.firstHeader = new AwxFileFirstHeader();\n\n    int pos = 0;\n    raf.seek(pos);\n\n    // gini header process\n    byte[] buf = new byte[FY_AWX_PIB_LEN];\n    int xohnt = raf.read(buf);\n    EndianByteBuffer byteBuffer;\n    if (xohnt == FY_AWX_PIB_LEN) {\n      byteBuffer = new EndianByteBuffer(buf, this.firstHeader.byteOrder);\n      this.firstHeader.fillHeader(byteBuffer);\n\n    } else {\n      return false;\n    }\n\n    if (!((this.firstHeader.fileName.endsWith(\".AWX\") || this.firstHeader.fileName.endsWith(\".awx\"))\n            && this.firstHeader.firstHeaderLength == FY_AWX_PIB_LEN)) {\n      return false;\n    }\n\n    // skip the fills of the first record\n    //  raf.seek(FY_AWX_PIB_LEN + this.firstHeader.fillSectionLength);\n    buf = new byte[this.firstHeader.secondHeaderLength];\n    raf.readFully(buf);\n    byteBuffer = new EndianByteBuffer(buf, this.firstHeader.byteOrder);\n    switch (this.firstHeader.typeOfProduct) {\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_UNDEFINED:\n        throw new UnsupportedDatasetException();\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_GEOSAT_IMAGE:\n        secondHeader = new AwxFileGeoSatelliteSecondHeader();\n        secondHeader.fillHeader(byteBuffer);\n        break;\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_POLARSAT_IMAGE:\n        throw new UnsupportedDatasetException();\n\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_GRID:\n        secondHeader = new AwxFileGridProductSecondHeader();\n        secondHeader.fillHeader(byteBuffer);\n\n        break;\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_DISCREET:\n        throw new UnsupportedDatasetException();\n\n      case AwxFileFirstHeader.AWX_PRODUCT_TYPE_GRAPH_ANALIYSIS:\n        throw new UnsupportedDatasetException();\n\n    }\n\n    return true;\n\n  }",
        "explanations_by_ours": [
            "the number of bytes to read",
            "the number of bytes to read.",
            "the number of bytes read"
        ],
        "corrections_by_ours": [
            "bytes",
            "number",
            "read"
        ],
        "corrections_by_baseline": [
            "sndx",
            "qmndx",
            "ncx",
            "xh",
            "ndx",
            "xstell",
            "tmcd",
            "X",
            "x",
            "hrsi"
        ]
    },
    {
        "original_word": "final",
        "typo_word": "rinwl",
        "original_variable": "finalSchema",
        "typo_variable": "rinwlSchema",
        "original_code": "private Schema.Field schemaFieldForType(\n      String fieldPath,\n      Record record,\n      String fieldName,\n      Field field\n  ) throws OnRecordErrorException {\n    Schema simpleSchema = simpleSchemaForType(fieldPath, record, field);\n    Schema finalSchema = simpleSchema;\n\n    // If Nullable check box was selected, wrap the whole schema in union with null\n    if(getConfig().avroNullableFields) {\n      finalSchema = Schema.createUnion(ImmutableList.of(\n        Schema.create(Schema.Type.NULL),\n        simpleSchema\n      ));\n    }\n\n    return new Schema.Field(\n      fieldName,\n      finalSchema,\n      null,\n      getDefaultValue(simpleSchema)\n    );\n  }",
        "modified_code": "private Schema.Field schemaFieldForType(\n      String fieldPath,\n      Record record,\n      String fieldName,\n      Field field\n  ) throws OnRecordErrorException {\n    Schema simpleSchema = simpleSchemaForType(fieldPath, record, field);\n    Schema rinwlSchema = simpleSchema;\n\n    // If Nullable check box was selected, wrap the whole schema in union with null\n    if(getConfig().avroNullableFields) {\n      rinwlSchema = Schema.createUnion(ImmutableList.of(\n        Schema.create(Schema.Type.NULL),\n        simpleSchema\n      ));\n    }\n\n    return new Schema.Field(\n      fieldName,\n      rinwlSchema,\n      null,\n      getDefaultValue(simpleSchema)\n    );\n  }",
        "explanations_by_ours": [
            "the rinwl schema",
            "the rinwl schema.",
            "the rinwl schema to use"
        ],
        "corrections_by_ours": [
            "rinwlUse",
            "useSchema",
            "schemaSchema",
            "rinwlRinwl",
            "rinwlSchema"
        ],
        "corrections_by_baseline": [
            "avroSchema",
            "simpleSchema",
            "jsonSchema",
            "nonNullAvroSchema",
            "schemaBytes",
            "schema",
            "finalSchema",
            "recordSchema",
            "pigSchema",
            "itemSchema"
        ]
    },
    {
        "original_word": "service",
        "typo_word": "dedvice",
        "original_variable": "serviceName",
        "typo_variable": "dedviceName",
        "original_code": "protected InvAccessImpl readAccess(InvDatasetImpl dataset, Element accessElem) {\n    String urlPath = accessElem.getAttributeValue(\"urlPath\");\n    String serviceName = accessElem.getAttributeValue(\"serviceName\");\n    String dataFormat = accessElem.getAttributeValue(\"dataFormat\");\n\n    return new InvAccessImpl(dataset, urlPath, serviceName, null, dataFormat, readDataSize(accessElem));\n  }",
        "modified_code": "protected InvAccessImpl readAccess(InvDatasetImpl dataset, Element accessElem) {\n    String urlPath = accessElem.getAttributeValue(\"urlPath\");\n    String dedviceName = accessElem.getAttributeValue(\"serviceName\");\n    String dataFormat = accessElem.getAttributeValue(\"dataFormat\");\n\n    return new InvAccessImpl(dataset, urlPath, dedviceName, null, dataFormat, readDataSize(accessElem));\n  }",
        "explanations_by_ours": [
            "The name of the service.",
            "The name of the dedvice.",
            "The name of the service to access."
        ],
        "corrections_by_ours": [
            "serviceName",
            "dedviceAccess",
            "nameName",
            "dedviceService",
            "dedviceDedvice",
            "accessName",
            "dedviceName"
        ],
        "corrections_by_baseline": [
            "ejbName",
            "eName",
            "_h_name",
            "onName",
            "oName",
            "memberName",
            "pName",
            "internalName",
            "lcName",
            "internedName"
        ]
    },
    {
        "original_word": "matches",
        "typo_word": "hatcmes",
        "original_variable": "matches",
        "typo_variable": "hatcmes",
        "original_code": "static String findDSLConfigName(String content) {\n        String name = null;\n        Matcher matches = EXPANDER_PATTERN.matcher( content );\n        if (matches.find()) {\n            name = matches.group(1) + \".dsl\";\n        }\n        return name;\n    }",
        "modified_code": "static String findDSLConfigName(String content) {\n        String name = null;\n        Matcher hatcmes = EXPANDER_PATTERN.matcher( content );\n        if (hatcmes.find()) {\n            name = hatcmes.group(1) + \".dsl\";\n        }\n        return name;\n    }",
        "explanations_by_ours": [
            "the expansion pattern to find the name of the DSL config file",
            "the expansion pattern",
            "the expansion pattern to find the name of the DSL config file."
        ],
        "corrections_by_ours": [
            "patterncmes",
            "namecmes",
            "hatcname",
            "hatconfigmes",
            "hatcpattern",
            "expansioncmes",
            "hatcexpansion",
            "filecmes",
            "findcmes",
            "configcmes"
        ],
        "corrections_by_baseline": [
            "hysteresis",
            "helm",
            "cis",
            "coldp",
            "kyero",
            "wac",
            "phitimesalphasum",
            "dolacons",
            "xfac",
            "zps"
        ]
    },
    {
        "original_word": "details",
        "typo_word": "detqild",
        "original_variable": "details",
        "typo_variable": "detqild",
        "original_code": "public static JsonResult of(final Exception exception) {\n\t\tfinal HashMap<String, Object> errorMap = new HashMap<>();\n\n\t\terrorMap.put(\"message\", ExceptionUtil.message(exception));\n\t\terrorMap.put(\"error\", exception.getClass().getName());\n\t\terrorMap.put(\"cause\", exception.getCause() != null ? exception.getCause().getClass().getName() : null);\n\n\t\tfinal ArrayList<String> details = new ArrayList<>();\n\n\t\tfinal StackTraceElement[] ste = ExceptionUtil.getStackTrace(exception, null, null);\n\t\tfor (StackTraceElement stackTraceElement : ste) {\n\t\t\tdetails.add(stackTraceElement.toString());\n\t\t}\n\n\t\terrorMap.put(\"details\", details);\n\n\t\tfinal String json = JsonSerializer.create().deep(true).serialize(errorMap);\n\t\treturn new JsonResult(json).status(HttpStatus.error500().internalError());\n\t}",
        "modified_code": "public static JsonResult of(final Exception exception) {\n\t\tfinal HashMap<String, Object> errorMap = new HashMap<>();\n\n\t\terrorMap.put(\"message\", ExceptionUtil.message(exception));\n\t\terrorMap.put(\"error\", exception.getClass().getName());\n\t\terrorMap.put(\"cause\", exception.getCause() != null ? exception.getCause().getClass().getName() : null);\n\n\t\tfinal ArrayList<String> detqild = new ArrayList<>();\n\n\t\tfinal StackTraceElement[] ste = ExceptionUtil.getStackTrace(exception, null, null);\n\t\tfor (StackTraceElement stackTraceElement : ste) {\n\t\t\tdetqild.add(stackTraceElement.toString());\n\t\t}\n\n\t\terrorMap.put(\"details\", detqild);\n\n\t\tfinal String json = JsonSerializer.create().deep(true).serialize(errorMap);\n\t\treturn new JsonResult(json).status(HttpStatus.error500().internalError());\n\t}",
        "explanations_by_ours": [
            "the details",
            "the details of the exception",
            "the list of the stack trace elements"
        ],
        "corrections_by_ours": [
            "details",
            "exception",
            "trace",
            "list",
            "stack",
            "elements"
        ],
        "corrections_by_baseline": [
            "suppressed",
            "quiet",
            "det",
            "discard",
            "idle",
            "not",
            "unlimitedOK",
            "evicted",
            "deny",
            "purged"
        ]
    },
    {
        "original_word": "ping",
        "typo_word": "linf",
        "original_variable": "pingManager",
        "typo_variable": "linfManager",
        "original_code": "public synchronized static KeepAliveManager getInstanceFor(\n            Connection connection) {\n        KeepAliveManager pingManager = instances.get(connection);\n\n        if (pingManager == null) {\n            pingManager = new KeepAliveManager(connection);\n            instances.put(connection, pingManager);\n        }\n        return pingManager;\n    }",
        "modified_code": "public synchronized static KeepAliveManager getInstanceFor(\n            Connection connection) {\n        KeepAliveManager linfManager = instances.get(connection);\n\n        if (linfManager == null) {\n            linfManager = new KeepAliveManager(connection);\n            instances.put(connection, linfManager);\n        }\n        return linfManager;\n    }",
        "explanations_by_ours": [
            "the singleton instance of the keep alive manager",
            "the singleton instance of the keep alive manager.",
            "the singleton instance of the keep alive manager for the given connection"
        ],
        "corrections_by_ours": [
            "linfAlive",
            "linstanceManager",
            "lsingletonManager",
            "linfSingleton",
            "aliveinfManager",
            "laliveManager",
            "lgivenManager",
            "lmanagerManager",
            "linfKeep",
            "linfGiven"
        ],
        "corrections_by_baseline": [
            "sleeProfileManager",
            "dManager",
            "layerManager",
            "fixture",
            "fileManager",
            "jspcLoader",
            "solver",
            "finer",
            "repaintManager",
            "ctxLoader"
        ]
    },
    {
        "original_word": "packet",
        "typo_word": "psdket",
        "original_variable": "packet",
        "typo_variable": "psdket",
        "original_code": "public Message<?> poll(long timeout) {\n\n\t\tMessage<?> message = null;\n\t\tString payloadJSON = null;\n\t\tcom.amazonaws.services.sqs.model.Message qMessage = null;\n\t\tint timeoutSeconds = (timeout > 0 ? ((int) (timeout / 1000))\n\t\t\t\t: receiveMessageWaitTimeout);\n\t\tdestroyWaitTime = timeoutSeconds;\n\t\ttry {\n\t\t\tif (queue == null) {\n\t\t\t\tif (prefetchQueue.isEmpty()) {\n\t\t\t\t\tReceiveMessageRequest request = new ReceiveMessageRequest(\n\t\t\t\t\t\t\tqueueUrl).withWaitTimeSeconds(timeoutSeconds)\n\t\t\t\t\t\t\t.withMaxNumberOfMessages(prefetchCount)\n\t\t\t\t\t\t\t.withAttributeNames(\"All\");\n\n\t\t\t\t\tReceiveMessageResult result = sqsClient\n\t\t\t\t\t\t\t.receiveMessage(request);\n\t\t\t\t\tfor (com.amazonaws.services.sqs.model.Message sqsMessage : result\n\t\t\t\t\t\t\t.getMessages()) {\n\t\t\t\t\t\tprefetchQueue.offer(sqsMessage);\n\t\t\t\t\t}\n\t\t\t\t\tqMessage = prefetchQueue.poll();\n\t\t\t\t} else {\n\t\t\t\t\tqMessage = prefetchQueue.remove();\n\t\t\t\t}\n\t\t\t\tif (qMessage != null) {\n\t\t\t\t\tpayloadJSON = qMessage.getBody();\n\t\t\t\t\t// MD5 verification\n\t\t\t\t\ttry {\n\t\t\t\t\t\tbyte[] computedHash = Md5Utils\n\t\t\t\t\t\t\t\t.computeMD5Hash(payloadJSON.getBytes(\"UTF-8\"));\n\t\t\t\t\t\tString hexDigest = new String(\n\t\t\t\t\t\t\t\tHex.encodeHex(computedHash));\n\t\t\t\t\t\tif (!hexDigest.equals(qMessage.getMD5OfBody())) {\n\t\t\t\t\t\t\tpayloadJSON = null; // ignore this message\n\t\t\t\t\t\t\tlog.warn(\"Dropped message due to MD5 checksum failure\");\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\tlog.warn(\n\t\t\t\t\t\t\t\t\"Failed to verify MD5 checksum: \"\n\t\t\t\t\t\t\t\t\t\t+ e.getMessage(), e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ttry {\n\t\t\t\t\tpayloadJSON = queue.poll(timeoutSeconds, TimeUnit.SECONDS);\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\tlog.warn(e.getMessage(), e);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (payloadJSON != null) {\n\t\t\t\tJSONObject qMessageJSON = new JSONObject(payloadJSON);\n\t\t\t\tif (qMessageJSON.has(SNS_MESSAGE_KEY)) { // posted from SNS\n\t\t\t\t\tpayloadJSON = qMessageJSON.getString(SNS_MESSAGE_KEY);\n\t\t\t\t\t// XXX: other SNS attributes?\n\t\t\t\t}\n\t\t\t\tMessage<?> packet = null;\n\t\t\t\ttry {\n\t\t\t\t\tpacket = messageMarshaller.deserialize(payloadJSON);\n\t\t\t\t} catch (MessageMarshallerException marshallingException) {\n\t\t\t\t\tthrow new MessagingException(\n\t\t\t\t\t\t\tmarshallingException.getMessage(),\n\t\t\t\t\t\t\tmarshallingException.getCause());\n\t\t\t\t}\n\t\t\t\tMessageBuilder<?> builder = MessageBuilder.fromMessage(packet);\n\t\t\t\tif (qMessage != null) {\n\t\t\t\t\tbuilder.setHeader(SqsHeaders.MSG_RECEIPT_HANDLE,\n\t\t\t\t\t\t\tqMessage.getReceiptHandle());\n\t\t\t\t\tbuilder.setHeader(SqsHeaders.AWS_MESSAGE_ID,\n\t\t\t\t\t\t\tqMessage.getMessageId());\n\t\t\t\t\tfor (Map.Entry<String, String> e : qMessage.getAttributes()\n\t\t\t\t\t\t\t.entrySet()) {\n\t\t\t\t\t\tif (e.getKey().equals(\"ApproximateReceiveCount\")) {\n\t\t\t\t\t\t\tbuilder.setHeader(SqsHeaders.RECEIVE_COUNT,\n\t\t\t\t\t\t\t\t\tInteger.valueOf(e.getValue()));\n\t\t\t\t\t\t} else if (e.getKey().equals(\"SentTimestamp\")) {\n\t\t\t\t\t\t\tbuilder.setHeader(SqsHeaders.SENT_AT,\n\t\t\t\t\t\t\t\t\tnew Date(Long.valueOf(e.getValue())));\n\t\t\t\t\t\t} else if (e.getKey().equals(\n\t\t\t\t\t\t\t\t\"ApproximateFirstReceiveTimestamp\")) {\n\t\t\t\t\t\t\tbuilder.setHeader(SqsHeaders.FIRST_RECEIVED_AT,\n\t\t\t\t\t\t\t\t\tnew Date(Long.valueOf(e.getValue())));\n\t\t\t\t\t\t} else if (e.getKey().equals(\"SenderId\")) {\n\t\t\t\t\t\t\tbuilder.setHeader(SqsHeaders.SENDER_AWS_ID,\n\t\t\t\t\t\t\t\t\te.getValue());\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tbuilder.setHeader(e.getKey(), e.getValue());\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tbuilder.setHeader(SqsHeaders.MSG_RECEIPT_HANDLE, \"\");\n\t\t\t\t\t// to satisfy test conditions\n\t\t\t\t}\n\n\t\t\t\tmessage = builder.build();\n\t\t\t}\n\n\t\t} catch (JSONException e) {\n\t\t\tlog.warn(e.getMessage(), e);\n\n\t\t} finally {\n\t\t\tdestroyWaitTime = 0;\n\t\t}\n\n\t\treturn message;\n\t}",
        "modified_code": "public Message<?> poll(long timeout) {\n\n\t\tMessage<?> message = null;\n\t\tString payloadJSON = null;\n\t\tcom.amazonaws.services.sqs.model.Message qMessage = null;\n\t\tint timeoutSeconds = (timeout > 0 ? ((int) (timeout / 1000))\n\t\t\t\t: receiveMessageWaitTimeout);\n\t\tdestroyWaitTime = timeoutSeconds;\n\t\ttry {\n\t\t\tif (queue == null) {\n\t\t\t\tif (prefetchQueue.isEmpty()) {\n\t\t\t\t\tReceiveMessageRequest request = new ReceiveMessageRequest(\n\t\t\t\t\t\t\tqueueUrl).withWaitTimeSeconds(timeoutSeconds)\n\t\t\t\t\t\t\t.withMaxNumberOfMessages(prefetchCount)\n\t\t\t\t\t\t\t.withAttributeNames(\"All\");\n\n\t\t\t\t\tReceiveMessageResult result = sqsClient\n\t\t\t\t\t\t\t.receiveMessage(request);\n\t\t\t\t\tfor (com.amazonaws.services.sqs.model.Message sqsMessage : result\n\t\t\t\t\t\t\t.getMessages()) {\n\t\t\t\t\t\tprefetchQueue.offer(sqsMessage);\n\t\t\t\t\t}\n\t\t\t\t\tqMessage = prefetchQueue.poll();\n\t\t\t\t} else {\n\t\t\t\t\tqMessage = prefetchQueue.remove();\n\t\t\t\t}\n\t\t\t\tif (qMessage != null) {\n\t\t\t\t\tpayloadJSON = qMessage.getBody();\n\t\t\t\t\t// MD5 verification\n\t\t\t\t\ttry {\n\t\t\t\t\t\tbyte[] computedHash = Md5Utils\n\t\t\t\t\t\t\t\t.computeMD5Hash(payloadJSON.getBytes(\"UTF-8\"));\n\t\t\t\t\t\tString hexDigest = new String(\n\t\t\t\t\t\t\t\tHex.encodeHex(computedHash));\n\t\t\t\t\t\tif (!hexDigest.equals(qMessage.getMD5OfBody())) {\n\t\t\t\t\t\t\tpayloadJSON = null; // ignore this message\n\t\t\t\t\t\t\tlog.warn(\"Dropped message due to MD5 checksum failure\");\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\tlog.warn(\n\t\t\t\t\t\t\t\t\"Failed to verify MD5 checksum: \"\n\t\t\t\t\t\t\t\t\t\t+ e.getMessage(), e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ttry {\n\t\t\t\t\tpayloadJSON = queue.poll(timeoutSeconds, TimeUnit.SECONDS);\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\tlog.warn(e.getMessage(), e);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (payloadJSON != null) {\n\t\t\t\tJSONObject qMessageJSON = new JSONObject(payloadJSON);\n\t\t\t\tif (qMessageJSON.has(SNS_MESSAGE_KEY)) { // posted from SNS\n\t\t\t\t\tpayloadJSON = qMessageJSON.getString(SNS_MESSAGE_KEY);\n\t\t\t\t\t// XXX: other SNS attributes?\n\t\t\t\t}\n\t\t\t\tMessage<?> psdket = null;\n\t\t\t\ttry {\n\t\t\t\t\tpsdket = messageMarshaller.deserialize(payloadJSON);\n\t\t\t\t} catch (MessageMarshallerException marshallingException) {\n\t\t\t\t\tthrow new MessagingException(\n\t\t\t\t\t\t\tmarshallingException.getMessage(),\n\t\t\t\t\t\t\tmarshallingException.getCause());\n\t\t\t\t}\n\t\t\t\tMessageBuilder<?> builder = MessageBuilder.fromMessage(psdket);\n\t\t\t\tif (qMessage != null) {\n\t\t\t\t\tbuilder.setHeader(SqsHeaders.MSG_RECEIPT_HANDLE,\n\t\t\t\t\t\t\tqMessage.getReceiptHandle());\n\t\t\t\t\tbuilder.setHeader(SqsHeaders.AWS_MESSAGE_ID,\n\t\t\t\t\t\t\tqMessage.getMessageId());\n\t\t\t\t\tfor (Map.Entry<String, String> e : qMessage.getAttributes()\n\t\t\t\t\t\t\t.entrySet()) {\n\t\t\t\t\t\tif (e.getKey().equals(\"ApproximateReceiveCount\")) {\n\t\t\t\t\t\t\tbuilder.setHeader(SqsHeaders.RECEIVE_COUNT,\n\t\t\t\t\t\t\t\t\tInteger.valueOf(e.getValue()));\n\t\t\t\t\t\t} else if (e.getKey().equals(\"SentTimestamp\")) {\n\t\t\t\t\t\t\tbuilder.setHeader(SqsHeaders.SENT_AT,\n\t\t\t\t\t\t\t\t\tnew Date(Long.valueOf(e.getValue())));\n\t\t\t\t\t\t} else if (e.getKey().equals(\n\t\t\t\t\t\t\t\t\"ApproximateFirstReceiveTimestamp\")) {\n\t\t\t\t\t\t\tbuilder.setHeader(SqsHeaders.FIRST_RECEIVED_AT,\n\t\t\t\t\t\t\t\t\tnew Date(Long.valueOf(e.getValue())));\n\t\t\t\t\t\t} else if (e.getKey().equals(\"SenderId\")) {\n\t\t\t\t\t\t\tbuilder.setHeader(SqsHeaders.SENDER_AWS_ID,\n\t\t\t\t\t\t\t\t\te.getValue());\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tbuilder.setHeader(e.getKey(), e.getValue());\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tbuilder.setHeader(SqsHeaders.MSG_RECEIPT_HANDLE, \"\");\n\t\t\t\t\t// to satisfy test conditions\n\t\t\t\t}\n\n\t\t\t\tmessage = builder.build();\n\t\t\t}\n\n\t\t} catch (JSONException e) {\n\t\t\tlog.warn(e.getMessage(), e);\n\n\t\t} finally {\n\t\t\tdestroyWaitTime = 0;\n\t\t}\n\n\t\treturn message;\n\t}",
        "explanations_by_ours": [
            "The client to use to make the request or handle the response.",
            "The client to use to make the request or handling the response.",
            "The client to use to make the request and handle the response."
        ],
        "corrections_by_ours": [
            "useket",
            "psdclient",
            "psdrequest",
            "responseket",
            "psdmake",
            "handleket",
            "requestket",
            "handlingket",
            "psdresponse",
            "clientket"
        ],
        "corrections_by_baseline": [
            "psb",
            "fptg",
            "ptd",
            "p_gam",
            "psdf",
            "psi",
            "ksgrid",
            "fxy",
            "ptg",
            "glamx"
        ]
    },
    {
        "original_word": "capacity",
        "typo_word": "capzckty",
        "original_variable": "capacity",
        "typo_variable": "capzckty",
        "original_code": "public DirectBufferVector validate()\n    {\n        final int capacity = buffer.capacity();\n        if (offset < 0 || offset >= capacity)\n        {\n            throw new IllegalArgumentException(\"offset=\" + offset + \" capacity=\" + capacity);\n        }\n\n        if (length < 0 || length > (capacity - offset))\n        {\n            throw new IllegalArgumentException(\"offset=\" + offset + \" capacity=\" + capacity + \" length=\" + length);\n        }\n\n        return this;\n    }",
        "modified_code": "public DirectBufferVector validate()\n    {\n        final int capzckty = buffer.capzckty();\n        if (offset < 0 || offset >= capzckty)\n        {\n            throw new IllegalArgumentException(\"offset=\" + offset + \" capacity=\" + capzckty);\n        }\n\n        if (length < 0 || length > (capzckty - offset))\n        {\n            throw new IllegalArgumentException(\"offset=\" + offset + \" capacity=\" + capzckty + \" length=\" + length);\n        }\n\n        return this;\n    }",
        "explanations_by_ours": [
            "the buffer's capacity",
            "the buffer's capacity.",
            "the capacity of the buffer"
        ],
        "corrections_by_ours": [
            "capacity",
            "buffer's",
            "buffer"
        ],
        "corrections_by_baseline": [
            "udch",
            "cap",
            "kxky",
            "ykr",
            "CZ",
            "cz",
            "clz",
            "specp",
            "csys",
            "csh"
        ]
    },
    {
        "original_word": "output",
        "typo_word": "pktput",
        "original_variable": "output",
        "typo_variable": "pktput",
        "original_code": "public String showStatus() {\n    // Update the currently deployed components.\n    updateDeployedComponents();\n\n    String output = \"\";\n\n    output += \"<p>Deployable Units Waiting For Install:</p>\";\n    for (DeployableUnit waitingDU : waitingForInstallDUs) {\n      output += \"+-- \" + waitingDU.getDeploymentInfoShortName() + \"<br>\";\n      for (String dependency : waitingDU.getExternalDependencies()) {\n        if (!deployedComponents.contains(dependency))\n          dependency += \" <strong>MISSING!</strong>\";\n\n        output += \"  +-- depends on \" + dependency + \"<br>\";\n      }\n    }\n\n    output += \"<p>Deployable Units Waiting For Uninstall:</p>\";\n    for (DeployableUnit waitingDU : waitingForUninstallDUs) {\n      output += \"+-- \" + waitingDU.getDeploymentInfoShortName() + \"<br>\";\n    }\n\n    return output;\n  }",
        "modified_code": "public String showStatus() {\n    // Update the currently deployed components.\n    updateDeployedComponents();\n\n    String pktput = \"\";\n\n    pktput += \"<p>Deployable Units Waiting For Install:</p>\";\n    for (DeployableUnit waitingDU : waitingForInstallDUs) {\n      pktput += \"+-- \" + waitingDU.getDeploymentInfoShortName() + \"<br>\";\n      for (String dependency : waitingDU.getExternalDependencies()) {\n        if (!deployedComponents.contains(dependency))\n          dependency += \" <strong>MISSING!</strong>\";\n\n        pktput += \"  +-- depends on \" + dependency + \"<br>\";\n      }\n    }\n\n    pktput += \"<p>Deployable Units Waiting For Uninstall:</p>\";\n    for (DeployableUnit waitingDU : waitingForUninstallDUs) {\n      pktput += \"+-- \" + waitingDU.getDeploymentInfoShortName() + \"<br>\";\n    }\n\n    return pktput;\n  }",
        "explanations_by_ours": [
            "the output string.",
            "the output string to output to.",
            "the output string to display."
        ],
        "corrections_by_ours": [
            "pktoutput",
            "outputput",
            "displayput",
            "pktdisplay",
            "stringput",
            "pktstring",
            "pktput"
        ],
        "corrections_by_baseline": [
            "pkt",
            "putresp",
            "tmpMsg",
            "put",
            "msgMultipart",
            "packet",
            "putComplex",
            "ksp",
            "httpPut",
            "vvstruct"
        ]
    },
    {
        "original_word": "upper",
        "typo_word": "hlper",
        "original_variable": "upperLimitMemory",
        "typo_variable": "hlperLimitMemory",
        "original_code": "public static Integer getMapMemoryMb(String javaOpts, Configuration conf) {\n    String[] javaOptsArray = javaOpts.split(\" \");\n    Integer upperLimitMemory = null;\n    for (String opts : javaOptsArray) {\n      if (opts.contains(\"-Xmx\")) {\n        Integer memoryMb = Integer.valueOf(opts.substring(4, opts.length() - 1));\n        switch (opts.charAt(opts.length() - 1)) {\n          case 'm':\n          case 'M':\n            break;\n          case 'k':\n          case 'K':\n            memoryMb = memoryMb / (1024);\n            break;\n          case 'g':\n          case 'G':\n            memoryMb = memoryMb * 1024;\n            break;\n          default:\n            memoryMb = Integer.valueOf(opts.substring(4, opts.length())) / (1024 * 1024);\n            break;\n        }\n        // Add 25% to Java heap as MAP_MEMORY_MB is the total physical memory for the map task\n        upperLimitMemory = ((int) (memoryMb * 0.25)) + memoryMb;\n        // dont break as there could be multiple -Xmx, we need to honor the last\n      }\n    }\n    if (upperLimitMemory != null) {\n      String defaultMapMemoryString = conf.get(MAPREDUCE_MAP_MEMORY_MB);\n      if (defaultMapMemoryString != null) {\n        Integer defaultMapMemory = Integer.valueOf(defaultMapMemoryString);\n        upperLimitMemory = (upperLimitMemory > defaultMapMemory ? upperLimitMemory : defaultMapMemory);\n      }\n    }\n    return upperLimitMemory;\n  }",
        "modified_code": "public static Integer getMapMemoryMb(String javaOpts, Configuration conf) {\n    String[] javaOptsArray = javaOpts.split(\" \");\n    Integer hlperLimitMemory = null;\n    for (String opts : javaOptsArray) {\n      if (opts.contains(\"-Xmx\")) {\n        Integer memoryMb = Integer.valueOf(opts.substring(4, opts.length() - 1));\n        switch (opts.charAt(opts.length() - 1)) {\n          case 'm':\n          case 'M':\n            break;\n          case 'k':\n          case 'K':\n            memoryMb = memoryMb / (1024);\n            break;\n          case 'g':\n          case 'G':\n            memoryMb = memoryMb * 1024;\n            break;\n          default:\n            memoryMb = Integer.valueOf(opts.substring(4, opts.length())) / (1024 * 1024);\n            break;\n        }\n        // Add 25% to Java heap as MAP_MEMORY_MB is the total physical memory for the map task\n        hlperLimitMemory = ((int) (memoryMb * 0.25)) + memoryMb;\n        // dont break as there could be multiple -Xmx, we need to honor the last\n      }\n    }\n    if (hlperLimitMemory != null) {\n      String defaultMapMemoryString = conf.get(MAPREDUCE_MAP_MEMORY_MB);\n      if (defaultMapMemoryString != null) {\n        Integer defaultMapMemory = Integer.valueOf(defaultMapMemoryString);\n        hlperLimitMemory = (hlperLimitMemory > defaultMapMemory ? hlperLimitMemory : defaultMapMemory);\n      }\n    }\n    return hlperLimitMemory;\n  }",
        "explanations_by_ours": [
            "the default map memory limit",
            "the default map memory limit.",
            "the default map memory limit if null"
        ],
        "corrections_by_ours": [
            "hlmemoryLimitMemory",
            "nullperLimitMemory",
            "hlperMapMemory",
            "hlperMemoryMemory",
            "hlperLimitMap",
            "hlperLimitLimit",
            "defaultperLimitMemory",
            "hldefaultLimitMemory",
            "hlperDefaultMemory",
            "hlperLimitDefault"
        ],
        "corrections_by_baseline": [
            "upperLimitMemory",
            "memoryLimit",
            "hardMemoryLimit",
            "softMemoryLimit",
            "requiredMemory",
            "minimalCapacity",
            "maxHeapSize",
            "reqMemory",
            "newMemorySize",
            "heapCost"
        ]
    },
    {
        "original_word": "response",
        "typo_word": "despknse",
        "original_variable": "response",
        "typo_variable": "despknse",
        "original_code": "private String credentials(Request request, String realm, String username, String password, String algorithm, String messageQop, String nonce, String nonceCount, String opaque, String cnonce, String method, String digestUri) throws Exception {\n        Assert.isNotNull(request);\n        Assert.isNotNull(realm);\n        Assert.isNotNull(username);\n        Assert.isNotNull(password);\n        Assert.isNotNull(nonce);\n        Assert.isNotNull(method);\n        Assert.isNotNull(digestUri);\n\n        StringBuffer buf = new StringBuffer();\n\n        buf.append(\"Digest username=\\\"\"); //$NON-NLS-1$\n        buf.append(username);\n        buf.append(\"\\\"\"); //$NON-NLS-1$\n\n        buf.append(\", realm=\"); //$NON-NLS-1$\n        buf.append(realm);\n\n        if (messageQop != null) {\n            buf.append(\", qop=\\\"\"); //$NON-NLS-1$\n            buf.append(messageQop);\n            buf.append(\"\\\"\"); //$NON-NLS-1$\n        }\n\n        if (algorithm != null) {\n            buf.append(\", algorithm=\"); //$NON-NLS-1$\n            buf.append(algorithm);\n        }\n\n        buf.append(\", uri=\\\"\"); //$NON-NLS-1$\n        buf.append(digestUri);\n        buf.append(\"\\\"\"); //$NON-NLS-1$\n\n        buf.append(\", nonce=\"); //$NON-NLS-1$\n        buf.append(nonce);\n\n        if (nonceCount != null) {\n            buf.append(\", nc=\"); //$NON-NLS-1$\n            buf.append(nonceCount);\n        }\n\n        if (cnonce != null) {\n            buf.append(\", cnonce=\\\"\"); //$NON-NLS-1$\n            buf.append(cnonce);\n            buf.append(\"\\\"\"); //$NON-NLS-1$\n        }\n\n        if (opaque != null) {\n            buf.append(\", opaque=\"); //$NON-NLS-1$\n            buf.append(opaque);\n        }\n\n        String response = response(request, realm, username, password, algorithm, messageQop, nonce, nonceCount, cnonce, method, digestUri);\n        if (response == null) {\n            return null;\n        }\n\n        buf.append(\", response=\\\"\"); //$NON-NLS-1$\n        buf.append(response);\n        buf.append(\"\\\"\"); //$NON-NLS-1$\n\n        return buf.toString();\n    }",
        "modified_code": "private String credentials(Request request, String realm, String username, String password, String algorithm, String messageQop, String nonce, String nonceCount, String opaque, String cnonce, String method, String digestUri) throws Exception {\n        Assert.isNotNull(request);\n        Assert.isNotNull(realm);\n        Assert.isNotNull(username);\n        Assert.isNotNull(password);\n        Assert.isNotNull(nonce);\n        Assert.isNotNull(method);\n        Assert.isNotNull(digestUri);\n\n        StringBuffer buf = new StringBuffer();\n\n        buf.append(\"Digest username=\\\"\"); //$NON-NLS-1$\n        buf.append(username);\n        buf.append(\"\\\"\"); //$NON-NLS-1$\n\n        buf.append(\", realm=\"); //$NON-NLS-1$\n        buf.append(realm);\n\n        if (messageQop != null) {\n            buf.append(\", qop=\\\"\"); //$NON-NLS-1$\n            buf.append(messageQop);\n            buf.append(\"\\\"\"); //$NON-NLS-1$\n        }\n\n        if (algorithm != null) {\n            buf.append(\", algorithm=\"); //$NON-NLS-1$\n            buf.append(algorithm);\n        }\n\n        buf.append(\", uri=\\\"\"); //$NON-NLS-1$\n        buf.append(digestUri);\n        buf.append(\"\\\"\"); //$NON-NLS-1$\n\n        buf.append(\", nonce=\"); //$NON-NLS-1$\n        buf.append(nonce);\n\n        if (nonceCount != null) {\n            buf.append(\", nc=\"); //$NON-NLS-1$\n            buf.append(nonceCount);\n        }\n\n        if (cnonce != null) {\n            buf.append(\", cnonce=\\\"\"); //$NON-NLS-1$\n            buf.append(cnonce);\n            buf.append(\"\\\"\"); //$NON-NLS-1$\n        }\n\n        if (opaque != null) {\n            buf.append(\", opaque=\"); //$NON-NLS-1$\n            buf.append(opaque);\n        }\n\n        String despknse = despknse(request, realm, username, password, algorithm, messageQop, nonce, nonceCount, cnonce, method, digestUri);\n        if (despknse == null) {\n            return null;\n        }\n\n        buf.append(\", response=\\\"\"); //$NON-NLS-1$\n        buf.append(despknse);\n        buf.append(\"\\\"\"); //$NON-NLS-1$\n\n        return buf.toString();\n    }",
        "explanations_by_ours": [
            "the despknse",
            "the opaque",
            "the despknse."
        ],
        "corrections_by_ours": [
            "opaque"
        ],
        "corrections_by_baseline": [
            "des",
            "pihalf",
            "psemi",
            "pce",
            "dub",
            "suf",
            "pw",
            "p_alp",
            "vse",
            "dpe"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rrsulf",
        "original_variable": "result",
        "typo_variable": "rrsulf",
        "original_code": "@Override\n\tpublic Object intercept(final ActionRequest actionRequest) throws Exception {\n\t\tHttpServletRequest servletRequest = actionRequest.getHttpServletRequest();\n\n\t\t// detect multipart request\n\t\tif (ServletUtil.isMultipartRequest(servletRequest)) {\n\t\t\tservletRequest = new MultipartRequestWrapper(servletRequest, fileUploader.get(), madvocEncoding.getEncoding());\n\t\t\tactionRequest.bind(servletRequest);\n\t\t}\n\n\t\t// do it\n\t\tinject(actionRequest);\n\n\t\tfinal Object result = actionRequest.invoke();\n\n\t\toutject(actionRequest);\n\n\t\treturn result;\n\t}",
        "modified_code": "@Override\n\tpublic Object intercept(final ActionRequest actionRequest) throws Exception {\n\t\tHttpServletRequest servletRequest = actionRequest.getHttpServletRequest();\n\n\t\t// detect multipart request\n\t\tif (ServletUtil.isMultipartRequest(servletRequest)) {\n\t\t\tservletRequest = new MultipartRequestWrapper(servletRequest, fileUploader.get(), madvocEncoding.getEncoding());\n\t\t\tactionRequest.bind(servletRequest);\n\t\t}\n\n\t\t// do it\n\t\tinject(actionRequest);\n\n\t\tfinal Object rrsulf = actionRequest.invoke();\n\n\t\toutject(actionRequest);\n\n\t\treturn rrsulf;\n\t}",
        "explanations_by_ours": [
            "the rrsulf",
            "the rrsulf."
        ],
        "corrections_by_ours": [],
        "corrections_by_baseline": [
            "rsf",
            "rp",
            "srcc",
            "sr",
            "rslt",
            "srclen",
            "aRb",
            "rgp",
            "iread",
            "rdr"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "dslue",
        "original_variable": "value",
        "typo_variable": "dslue",
        "original_code": "public static Object attribute(final HttpServletRequest request, final String name) {\n\t\tObject value = request.getAttribute(name);\n\t\tif (value != null) {\n\t\t\treturn value;\n\t\t}\n\t\tvalue = request.getSession().getAttribute(name);\n\t\tif (value != null) {\n\t\t\treturn value;\n\t\t}\n\t\treturn request.getServletContext().getAttribute(name);\n\t}",
        "modified_code": "public static Object attribute(final HttpServletRequest request, final String name) {\n\t\tObject dslue = request.getAttribute(name);\n\t\tif (dslue != null) {\n\t\t\treturn dslue;\n\t\t}\n\t\tdslue = request.getSession().getAttribute(name);\n\t\tif (dslue != null) {\n\t\t\treturn dslue;\n\t\t}\n\t\treturn request.getServletContext().getAttribute(name);\n\t}",
        "explanations_by_ours": [
            "the dslue",
            "the attribute value",
            "the dslue value"
        ],
        "corrections_by_ours": [
            "value",
            "attribute"
        ],
        "corrections_by_baseline": [
            "dsl",
            "boustr",
            "dou",
            "concatString",
            "slab",
            "nwordp",
            "dstring",
            "slashNdx",
            "dot",
            "qd"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "eeshlt",
        "original_variable": "result",
        "typo_variable": "eeshlt",
        "original_code": "static public final String crypt(String password, String salt, String magic) {\n\n        byte finalState[];\n        long l;\n\n        /**\n         * Two MD5 hashes are used\n         */\n        MessageDigest ctx, ctx1;\n\n        try {\n            ctx = MessageDigest.getInstance(\"md5\");\n            ctx1 = MessageDigest.getInstance(\"md5\");\n        } catch (NoSuchAlgorithmException ex) {\n            System.err.println(ex);\n            return null;\n        }\n\n\t\t/* Refine the Salt first */\n        /* If it starts with the magic string, then skip that */\n\n        if (salt.startsWith(magic)) {\n            salt = salt.substring(magic.length());\n        }\n\n\t\t/* It stops at the first '$', max 8 chars */\n\n        if (salt.indexOf('$') != -1) {\n            salt = salt.substring(0, salt.indexOf('$'));\n        }\n\n        if (salt.length() > 8) {\n            salt = salt.substring(0, 8);\n        }\n\n        /**\n         * Transformation set #1: The password first, since that is what is most\n         * unknown Magic string Raw salt\n         */\n        ctx.update(password.getBytes());\n        ctx.update(magic.getBytes());\n        ctx.update(salt.getBytes());\n\n\t\t/* Then just as many characters of the MD5(pw,salt,pw) */\n\n        ctx1.update(password.getBytes());\n        ctx1.update(salt.getBytes());\n        ctx1.update(password.getBytes());\n        finalState = ctx1.digest(); // ctx1.Final();\n\n        for (int pl = password.length(); pl > 0; pl -= 16) {\n            ctx.update(finalState, 0, pl > 16 ? 16 : pl);\n        }\n\n        /**\n         * the original code claimed that finalState was being cleared to keep\n         * dangerous bits out of memory, but doing this is also required in\n         * order to get the right output.\n         */\n\n        clearbits(finalState);\n\n\t\t/* Then something really weird... */\n\n        for (int i = password.length(); i != 0; i >>>= 1) {\n            if ((i & 1) != 0) {\n                ctx.update(finalState, 0, 1);\n            } else {\n                ctx.update(password.getBytes(), 0, 1);\n            }\n        }\n\n        finalState = ctx.digest();\n\n        /**\n         * and now, just to make sure things don't run too fast On a 60 Mhz\n         * Pentium this takes 34 msec, so you would need 30 seconds to build a\n         * 1000 entry dictionary... (The above timings from the C version)\n         */\n\n        for (int i = 0; i < 1000; i++) {\n            try {\n                ctx1 = MessageDigest.getInstance(\"md5\");\n            } catch (NoSuchAlgorithmException e0) {\n                return null;\n            }\n\n            if ((i & 1) != 0) {\n                ctx1.update(password.getBytes());\n            } else {\n                ctx1.update(finalState, 0, 16);\n            }\n\n            if ((i % 3) != 0) {\n                ctx1.update(salt.getBytes());\n            }\n\n            if ((i % 7) != 0) {\n                ctx1.update(password.getBytes());\n            }\n\n            if ((i & 1) != 0) {\n                ctx1.update(finalState, 0, 16);\n            } else {\n                ctx1.update(password.getBytes());\n            }\n\n            finalState = ctx1.digest(); // Final();\n        }\n\n\t\t/* Now make the output string */\n\n        StringBuffer result = new StringBuffer();\n\n        result.append(magic);\n        result.append(salt);\n        result.append(\"$\");\n\n        /**\n         * Build a 22 byte output string from the set: A-Za-z0-9./\n         */\n        l = (bytes2u(finalState[0]) << 16) | (bytes2u(finalState[6]) << 8)\n                | bytes2u(finalState[12]);\n        result.append(to64(l, 4));\n\n        l = (bytes2u(finalState[1]) << 16) | (bytes2u(finalState[7]) << 8)\n                | bytes2u(finalState[13]);\n        result.append(to64(l, 4));\n\n        l = (bytes2u(finalState[2]) << 16) | (bytes2u(finalState[8]) << 8)\n                | bytes2u(finalState[14]);\n        result.append(to64(l, 4));\n\n        l = (bytes2u(finalState[3]) << 16) | (bytes2u(finalState[9]) << 8)\n                | bytes2u(finalState[15]);\n        result.append(to64(l, 4));\n\n        l = (bytes2u(finalState[4]) << 16) | (bytes2u(finalState[10]) << 8)\n                | bytes2u(finalState[5]);\n        result.append(to64(l, 4));\n\n        l = bytes2u(finalState[11]);\n        result.append(to64(l, 2));\n\n\t\t/* Don't leave anything around in vm they could use. */\n        clearbits(finalState);\n\n        return result.toString();\n    }",
        "modified_code": "static public final String crypt(String password, String salt, String magic) {\n\n        byte finalState[];\n        long l;\n\n        /**\n         * Two MD5 hashes are used\n         */\n        MessageDigest ctx, ctx1;\n\n        try {\n            ctx = MessageDigest.getInstance(\"md5\");\n            ctx1 = MessageDigest.getInstance(\"md5\");\n        } catch (NoSuchAlgorithmException ex) {\n            System.err.println(ex);\n            return null;\n        }\n\n\t\t/* Refine the Salt first */\n        /* If it starts with the magic string, then skip that */\n\n        if (salt.startsWith(magic)) {\n            salt = salt.substring(magic.length());\n        }\n\n\t\t/* It stops at the first '$', max 8 chars */\n\n        if (salt.indexOf('$') != -1) {\n            salt = salt.substring(0, salt.indexOf('$'));\n        }\n\n        if (salt.length() > 8) {\n            salt = salt.substring(0, 8);\n        }\n\n        /**\n         * Transformation set #1: The password first, since that is what is most\n         * unknown Magic string Raw salt\n         */\n        ctx.update(password.getBytes());\n        ctx.update(magic.getBytes());\n        ctx.update(salt.getBytes());\n\n\t\t/* Then just as many characters of the MD5(pw,salt,pw) */\n\n        ctx1.update(password.getBytes());\n        ctx1.update(salt.getBytes());\n        ctx1.update(password.getBytes());\n        finalState = ctx1.digest(); // ctx1.Final();\n\n        for (int pl = password.length(); pl > 0; pl -= 16) {\n            ctx.update(finalState, 0, pl > 16 ? 16 : pl);\n        }\n\n        /**\n         * the original code claimed that finalState was being cleared to keep\n         * dangerous bits out of memory, but doing this is also required in\n         * order to get the right output.\n         */\n\n        clearbits(finalState);\n\n\t\t/* Then something really weird... */\n\n        for (int i = password.length(); i != 0; i >>>= 1) {\n            if ((i & 1) != 0) {\n                ctx.update(finalState, 0, 1);\n            } else {\n                ctx.update(password.getBytes(), 0, 1);\n            }\n        }\n\n        finalState = ctx.digest();\n\n        /**\n         * and now, just to make sure things don't run too fast On a 60 Mhz\n         * Pentium this takes 34 msec, so you would need 30 seconds to build a\n         * 1000 entry dictionary... (The above timings from the C version)\n         */\n\n        for (int i = 0; i < 1000; i++) {\n            try {\n                ctx1 = MessageDigest.getInstance(\"md5\");\n            } catch (NoSuchAlgorithmException e0) {\n                return null;\n            }\n\n            if ((i & 1) != 0) {\n                ctx1.update(password.getBytes());\n            } else {\n                ctx1.update(finalState, 0, 16);\n            }\n\n            if ((i % 3) != 0) {\n                ctx1.update(salt.getBytes());\n            }\n\n            if ((i % 7) != 0) {\n                ctx1.update(password.getBytes());\n            }\n\n            if ((i & 1) != 0) {\n                ctx1.update(finalState, 0, 16);\n            } else {\n                ctx1.update(password.getBytes());\n            }\n\n            finalState = ctx1.digest(); // Final();\n        }\n\n\t\t/* Now make the output string */\n\n        StringBuffer eeshlt = new StringBuffer();\n\n        eeshlt.append(magic);\n        eeshlt.append(salt);\n        eeshlt.append(\"$\");\n\n        /**\n         * Build a 22 byte output string from the set: A-Za-z0-9./\n         */\n        l = (bytes2u(finalState[0]) << 16) | (bytes2u(finalState[6]) << 8)\n                | bytes2u(finalState[12]);\n        eeshlt.append(to64(l, 4));\n\n        l = (bytes2u(finalState[1]) << 16) | (bytes2u(finalState[7]) << 8)\n                | bytes2u(finalState[13]);\n        eeshlt.append(to64(l, 4));\n\n        l = (bytes2u(finalState[2]) << 16) | (bytes2u(finalState[8]) << 8)\n                | bytes2u(finalState[14]);\n        eeshlt.append(to64(l, 4));\n\n        l = (bytes2u(finalState[3]) << 16) | (bytes2u(finalState[9]) << 8)\n                | bytes2u(finalState[15]);\n        eeshlt.append(to64(l, 4));\n\n        l = (bytes2u(finalState[4]) << 16) | (bytes2u(finalState[10]) << 8)\n                | bytes2u(finalState[5]);\n        eeshlt.append(to64(l, 4));\n\n        l = bytes2u(finalState[11]);\n        eeshlt.append(to64(l, 2));\n\n\t\t/* Don't leave anything around in vm they could use. */\n        clearbits(finalState);\n\n        return eeshlt.toString();\n    }",
        "explanations_by_ours": [
            "the password to be hashed",
            "The password to be hashed.",
            "the password to be hashed."
        ],
        "corrections_by_ours": [
            "hashedhlt",
            "eeshashed",
            "passwordhlt",
            "eespassword",
            "eeshlt"
        ],
        "corrections_by_baseline": [
            "lt",
            "rslt",
            "ilenhd",
            "en",
            "towrite",
            "gt",
            "to",
            "ertd",
            "estr",
            "wt"
        ]
    },
    {
        "original_word": "label",
        "typo_word": "kqbel",
        "original_variable": "label",
        "typo_variable": "kqbel",
        "original_code": "public boolean parse () throws ParseException, ParseException\n\n  {\n    \n\n\n    /* Lookahead and lookahead in internal form.  */\n    int yychar = yyempty_;\n    int yytoken = 0;\n\n    /* State.  */\n    int yyn = 0;\n    int yylen = 0;\n    int yystate = 0;\n    YYStack yystack = new YYStack ();\n    int label = YYNEWSTATE;\n\n    /* Error handling.  */\n    int yynerrs_ = 0;\n    \n\n    /* Semantic value of the lookahead.  */\n    Object yylval = null;\n\n    yycdebug (\"Starting parse\\n\");\n    yyerrstatus_ = 0;\n\n    /* Initialize the stack.  */\n    yystack.push (yystate, yylval );\n\n\n\n    for (;;)\n      switch (label)\n      {\n        /* New state.  Unlike in the C/C++ skeletons, the state is already\n           pushed when we come here.  */\n      case YYNEWSTATE:\n        yycdebug (\"Entering state \" + yystate + \"\\n\");\n        if (yydebug > 0)\n          yystack.print (yyDebugStream);\n\n        /* Accept?  */\n        if (yystate == yyfinal_)\n          return true;\n\n        /* Take a decision.  First try without lookahead.  */\n        yyn = yypact_[yystate];\n        if (yy_pact_value_is_default_ (yyn))\n          {\n            label = YYDEFAULT;\n            break;\n          }\n\n        /* Read a lookahead token.  */\n        if (yychar == yyempty_)\n          {\n\n\n            yycdebug (\"Reading a token: \");\n            yychar = yylexer.yylex ();\n            yylval = yylexer.getLVal ();\n\n          }\n\n        /* Convert token to internal form.  */\n        if (yychar <= Lexer.EOF)\n          {\n            yychar = yytoken = Lexer.EOF;\n            yycdebug (\"Now at end of input.\\n\");\n          }\n        else\n          {\n            yytoken = yytranslate_ (yychar);\n            yy_symbol_print (\"Next token is\", yytoken,\n                             yylval);\n          }\n\n        /* If the proper action on seeing token YYTOKEN is to reduce or to\n           detect an error, take that action.  */\n        yyn += yytoken;\n        if (yyn < 0 || yylast_ < yyn || yycheck_[yyn] != yytoken)\n          label = YYDEFAULT;\n\n        /* <= 0 means reduce or error.  */\n        else if ((yyn = yytable_[yyn]) <= 0)\n          {\n            if (yy_table_value_is_error_ (yyn))\n              label = YYERRLAB;\n            else\n              {\n                yyn = -yyn;\n                label = YYREDUCE;\n              }\n          }\n\n        else\n          {\n            /* Shift the lookahead token.  */\n            yy_symbol_print (\"Shifting\", yytoken,\n                             yylval);\n\n            /* Discard the token being shifted.  */\n            yychar = yyempty_;\n\n            /* Count tokens shifted since error; after three, turn off error\n               status.  */\n            if (yyerrstatus_ > 0)\n              --yyerrstatus_;\n\n            yystate = yyn;\n            yystack.push (yystate, yylval);\n            label = YYNEWSTATE;\n          }\n        break;\n\n      /*-----------------------------------------------------------.\n      | yydefault -- do the default action for the current state.  |\n      `-----------------------------------------------------------*/\n      case YYDEFAULT:\n        yyn = yydefact_[yystate];\n        if (yyn == 0)\n          label = YYERRLAB;\n        else\n          label = YYREDUCE;\n        break;\n\n      /*-----------------------------.\n      | yyreduce -- Do a reduction.  |\n      `-----------------------------*/\n      case YYREDUCE:\n        yylen = yyr2_[yyn];\n        label = yyaction (yyn, yystack, yylen);\n        yystate = yystack.stateAt (0);\n        break;\n\n      /*------------------------------------.\n      | yyerrlab -- here on detecting error |\n      `------------------------------------*/\n      case YYERRLAB:\n        /* If not already recovering from an error, report this error.  */\n        if (yyerrstatus_ == 0)\n          {\n            ++yynerrs_;\n            if (yychar == yyempty_)\n              yytoken = yyempty_;\n            yyerror (yysyntax_error (yystate, yytoken));\n          }\n\n        \n        if (yyerrstatus_ == 3)\n          {\n        /* If just tried and failed to reuse lookahead token after an\n         error, discard it.  */\n\n        if (yychar <= Lexer.EOF)\n          {\n          /* Return failure if at end of input.  */\n          if (yychar == Lexer.EOF)\n            return false;\n          }\n        else\n            yychar = yyempty_;\n          }\n\n        /* Else will try to reuse lookahead token after shifting the error\n           token.  */\n        label = YYERRLAB1;\n        break;\n\n      /*-------------------------------------------------.\n      | errorlab -- error raised explicitly by YYERROR.  |\n      `-------------------------------------------------*/\n      case YYERROR:\n\n        \n        /* Do not reclaim the symbols of the rule which action triggered\n           this YYERROR.  */\n        yystack.pop (yylen);\n        yylen = 0;\n        yystate = yystack.stateAt (0);\n        label = YYERRLAB1;\n        break;\n\n      /*-------------------------------------------------------------.\n      | yyerrlab1 -- common code for both syntax error and YYERROR.  |\n      `-------------------------------------------------------------*/\n      case YYERRLAB1:\n        yyerrstatus_ = 3;       /* Each real token shifted decrements this.  */\n\n        for (;;)\n          {\n            yyn = yypact_[yystate];\n            if (!yy_pact_value_is_default_ (yyn))\n              {\n                yyn += yyterror_;\n                if (0 <= yyn && yyn <= yylast_ && yycheck_[yyn] == yyterror_)\n                  {\n                    yyn = yytable_[yyn];\n                    if (0 < yyn)\n                      break;\n                  }\n              }\n\n            /* Pop the current state because it cannot handle the\n             * error token.  */\n            if (yystack.height == 0)\n              return false;\n\n            \n            yystack.pop ();\n            yystate = yystack.stateAt (0);\n            if (yydebug > 0)\n              yystack.print (yyDebugStream);\n          }\n\n        if (label == YYABORT)\n            /* Leave the switch.  */\n            break;\n\n\n\n        /* Shift the error token.  */\n        yy_symbol_print (\"Shifting\", yystos_[yyn],\n                         yylval);\n\n        yystate = yyn;\n        yystack.push (yyn, yylval);\n        label = YYNEWSTATE;\n        break;\n\n        /* Accept.  */\n      case YYACCEPT:\n        return true;\n\n        /* Abort.  */\n      case YYABORT:\n        return false;\n      }\n}",
        "modified_code": "public boolean parse () throws ParseException, ParseException\n\n  {\n    \n\n\n    /* Lookahead and lookahead in internal form.  */\n    int yychar = yyempty_;\n    int yytoken = 0;\n\n    /* State.  */\n    int yyn = 0;\n    int yylen = 0;\n    int yystate = 0;\n    YYStack yystack = new YYStack ();\n    int kqbel = YYNEWSTATE;\n\n    /* Error handling.  */\n    int yynerrs_ = 0;\n    \n\n    /* Semantic value of the lookahead.  */\n    Object yylval = null;\n\n    yycdebug (\"Starting parse\\n\");\n    yyerrstatus_ = 0;\n\n    /* Initialize the stack.  */\n    yystack.push (yystate, yylval );\n\n\n\n    for (;;)\n      switch (kqbel)\n      {\n        /* New state.  Unlike in the C/C++ skeletons, the state is already\n           pushed when we come here.  */\n      case YYNEWSTATE:\n        yycdebug (\"Entering state \" + yystate + \"\\n\");\n        if (yydebug > 0)\n          yystack.print (yyDebugStream);\n\n        /* Accept?  */\n        if (yystate == yyfinal_)\n          return true;\n\n        /* Take a decision.  First try without lookahead.  */\n        yyn = yypact_[yystate];\n        if (yy_pact_value_is_default_ (yyn))\n          {\n            kqbel = YYDEFAULT;\n            break;\n          }\n\n        /* Read a lookahead token.  */\n        if (yychar == yyempty_)\n          {\n\n\n            yycdebug (\"Reading a token: \");\n            yychar = yylexer.yylex ();\n            yylval = yylexer.getLVal ();\n\n          }\n\n        /* Convert token to internal form.  */\n        if (yychar <= Lexer.EOF)\n          {\n            yychar = yytoken = Lexer.EOF;\n            yycdebug (\"Now at end of input.\\n\");\n          }\n        else\n          {\n            yytoken = yytranslate_ (yychar);\n            yy_symbol_print (\"Next token is\", yytoken,\n                             yylval);\n          }\n\n        /* If the proper action on seeing token YYTOKEN is to reduce or to\n           detect an error, take that action.  */\n        yyn += yytoken;\n        if (yyn < 0 || yylast_ < yyn || yycheck_[yyn] != yytoken)\n          kqbel = YYDEFAULT;\n\n        /* <= 0 means reduce or error.  */\n        else if ((yyn = yytable_[yyn]) <= 0)\n          {\n            if (yy_table_value_is_error_ (yyn))\n              kqbel = YYERRLAB;\n            else\n              {\n                yyn = -yyn;\n                kqbel = YYREDUCE;\n              }\n          }\n\n        else\n          {\n            /* Shift the lookahead token.  */\n            yy_symbol_print (\"Shifting\", yytoken,\n                             yylval);\n\n            /* Discard the token being shifted.  */\n            yychar = yyempty_;\n\n            /* Count tokens shifted since error; after three, turn off error\n               status.  */\n            if (yyerrstatus_ > 0)\n              --yyerrstatus_;\n\n            yystate = yyn;\n            yystack.push (yystate, yylval);\n            kqbel = YYNEWSTATE;\n          }\n        break;\n\n      /*-----------------------------------------------------------.\n      | yydefault -- do the default action for the current state.  |\n      `-----------------------------------------------------------*/\n      case YYDEFAULT:\n        yyn = yydefact_[yystate];\n        if (yyn == 0)\n          kqbel = YYERRLAB;\n        else\n          kqbel = YYREDUCE;\n        break;\n\n      /*-----------------------------.\n      | yyreduce -- Do a reduction.  |\n      `-----------------------------*/\n      case YYREDUCE:\n        yylen = yyr2_[yyn];\n        kqbel = yyaction (yyn, yystack, yylen);\n        yystate = yystack.stateAt (0);\n        break;\n\n      /*------------------------------------.\n      | yyerrlab -- here on detecting error |\n      `------------------------------------*/\n      case YYERRLAB:\n        /* If not already recovering from an error, report this error.  */\n        if (yyerrstatus_ == 0)\n          {\n            ++yynerrs_;\n            if (yychar == yyempty_)\n              yytoken = yyempty_;\n            yyerror (yysyntax_error (yystate, yytoken));\n          }\n\n        \n        if (yyerrstatus_ == 3)\n          {\n        /* If just tried and failed to reuse lookahead token after an\n         error, discard it.  */\n\n        if (yychar <= Lexer.EOF)\n          {\n          /* Return failure if at end of input.  */\n          if (yychar == Lexer.EOF)\n            return false;\n          }\n        else\n            yychar = yyempty_;\n          }\n\n        /* Else will try to reuse lookahead token after shifting the error\n           token.  */\n        kqbel = YYERRLAB1;\n        break;\n\n      /*-------------------------------------------------.\n      | errorlab -- error raised explicitly by YYERROR.  |\n      `-------------------------------------------------*/\n      case YYERROR:\n\n        \n        /* Do not reclaim the symbols of the rule which action triggered\n           this YYERROR.  */\n        yystack.pop (yylen);\n        yylen = 0;\n        yystate = yystack.stateAt (0);\n        kqbel = YYERRLAB1;\n        break;\n\n      /*-------------------------------------------------------------.\n      | yyerrlab1 -- common code for both syntax error and YYERROR.  |\n      `-------------------------------------------------------------*/\n      case YYERRLAB1:\n        yyerrstatus_ = 3;       /* Each real token shifted decrements this.  */\n\n        for (;;)\n          {\n            yyn = yypact_[yystate];\n            if (!yy_pact_value_is_default_ (yyn))\n              {\n                yyn += yyterror_;\n                if (0 <= yyn && yyn <= yylast_ && yycheck_[yyn] == yyterror_)\n                  {\n                    yyn = yytable_[yyn];\n                    if (0 < yyn)\n                      break;\n                  }\n              }\n\n            /* Pop the current state because it cannot handle the\n             * error token.  */\n            if (yystack.height == 0)\n              return false;\n\n            \n            yystack.pop ();\n            yystate = yystack.stateAt (0);\n            if (yydebug > 0)\n              yystack.print (yyDebugStream);\n          }\n\n        if (kqbel == YYABORT)\n            /* Leave the switch.  */\n            break;\n\n\n\n        /* Shift the error token.  */\n        yy_symbol_print (\"Shifting\", yystos_[yyn],\n                         yylval);\n\n        yystate = yyn;\n        yystack.push (yyn, yylval);\n        kqbel = YYNEWSTATE;\n        break;\n\n        /* Accept.  */\n      case YYACCEPT:\n        return true;\n\n        /* Abort.  */\n      case YYABORT:\n        return false;\n      }\n}",
        "explanations_by_ours": [
            "The type of state to be parsed.",
            "The type of state to parse.",
            "The state to be parsed."
        ],
        "corrections_by_ours": [
            "type",
            "parsed",
            "state",
            "parse"
        ],
        "corrections_by_baseline": [
            "qk",
            "qd",
            "aeqm",
            "qco",
            "kx",
            "jbeg",
            "bsf",
            "q",
            "q1",
            "nk"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "gfsult",
        "original_variable": "result",
        "typo_variable": "gfsult",
        "original_code": "public Object execute(final Map<Object, Object> iArgs) {\r\n    if (recordIds.isEmpty() && subQuery == null)\r\n      throw new OCommandExecutionException(\"Cannot execute the command because it has not been parsed yet\");\r\n\r\n    if (subQuery != null) {\r\n      final List<OIdentifiable> result = new OCommandSQL(subQuery.toString()).execute();\r\n      for (OIdentifiable id : result)\r\n        recordIds.add(id.getIdentity());\r\n    }\r\n\r\n    return OFindReferenceHelper.findReferences(recordIds, classList);\r\n  }",
        "modified_code": "public Object execute(final Map<Object, Object> iArgs) {\r\n    if (recordIds.isEmpty() && subQuery == null)\r\n      throw new OCommandExecutionException(\"Cannot execute the command because it has not been parsed yet\");\r\n\r\n    if (subQuery != null) {\r\n      final List<OIdentifiable> gfsult = new OCommandSQL(subQuery.toString()).execute();\r\n      for (OIdentifiable id : gfsult)\r\n        recordIds.add(id.getIdentity());\r\n    }\r\n\r\n    return OFindReferenceHelper.findReferences(recordIds, classList);\r\n  }",
        "explanations_by_ours": [
            "The result of the query",
            "The result of the command",
            "The result of the command."
        ],
        "corrections_by_ours": [
            "result",
            "command",
            "query"
        ],
        "corrections_by_baseline": [
            "nf",
            "fptg",
            "gcs",
            "bsf",
            "icf",
            "hf",
            "ncf",
            "gvcs",
            "acf",
            "gds"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resukh",
        "original_variable": "result",
        "typo_variable": "resukh",
        "original_code": "public static DocumentBuilderFactory newSecureDocumentBuilderFactory() {\n    try {\n      DocumentBuilderFactory result = DocumentBuilderFactory.newInstance();\n      result.setFeature(\"http://javax.xml.XMLConstants/feature/secure-processing\", true);\n      result.setFeature(\"http://xml.org/sax/features/external-general-entities\", false);\n      result.setFeature(\"http://xml.org/sax/features/external-parameter-entities\", false);\n      result.setNamespaceAware(true);\n      result.setValidating(true);\n      return result;\n    } catch (ParserConfigurationException e) {\n      throw new IllegalStateException(e);\n    }\n  }",
        "modified_code": "public static DocumentBuilderFactory newSecureDocumentBuilderFactory() {\n    try {\n      DocumentBuilderFactory resukh = DocumentBuilderFactory.newInstance();\n      resukh.setFeature(\"http://javax.xml.XMLConstants/feature/secure-processing\", true);\n      resukh.setFeature(\"http://xml.org/sax/features/external-general-entities\", false);\n      resukh.setFeature(\"http://xml.org/sax/features/external-parameter-entities\", false);\n      resukh.setNamespaceAware(true);\n      resukh.setValidating(true);\n      return resukh;\n    } catch (ParserConfigurationException e) {\n      throw new IllegalStateException(e);\n    }\n  }",
        "explanations_by_ours": [
            "the DocumentBuilderFactory instance to use.",
            "the DocumentBuilderFactory instance.",
            "the DocumentBuilderFactory instance to use"
        ],
        "corrections_by_ours": [
            "use",
            "instance",
            "document",
            "factory",
            "builder"
        ],
        "corrections_by_baseline": [
            "resul",
            "res",
            "usv",
            "trovit",
            "urpt",
            "rrank",
            "srcc",
            "rp",
            "llur",
            "emsg"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "fakue",
        "original_variable": "value",
        "typo_variable": "fakue",
        "original_code": "protected <T> T getParameter(String name, Class<T> type) {\r\n\t\tif (parameters == null) {\r\n\t\t\tthrow new BugError(\"Event stream |%s| parameters not configured.\", this);\r\n\t\t}\r\n\t\tString value = parameters.get(name);\r\n\t\tif (value == null) {\r\n\t\t\tthrow new BugError(\"Missing event stream parameter |%s| of expected type |%s|.\", name, type);\r\n\t\t}\r\n\t\treturn ConverterRegistry.getConverter().asObject(value, type);\r\n\t}",
        "modified_code": "protected <T> T getParameter(String name, Class<T> type) {\r\n\t\tif (parameters == null) {\r\n\t\t\tthrow new BugError(\"Event stream |%s| parameters not configured.\", this);\r\n\t\t}\r\n\t\tString fakue = parameters.get(name);\r\n\t\tif (fakue == null) {\r\n\t\t\tthrow new BugError(\"Missing event stream parameter |%s| of expected type |%s|.\", name, type);\r\n\t\t}\r\n\t\treturn ConverterRegistry.getConverter().asObject(fakue, type);\r\n\t}",
        "explanations_by_ours": [
            "the fakue of the parameter",
            "the name of the parameter",
            "the value of the parameter"
        ],
        "corrections_by_ours": [
            "value",
            "name",
            "parameter"
        ],
        "corrections_by_baseline": [
            "handshakestate",
            "fos",
            "accu",
            "inode",
            "CFWS",
            "dks",
            "fsi",
            "baos",
            "fitem",
            "fdb"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "cjrrejt",
        "original_variable": "current",
        "typo_variable": "cjrrejt",
        "original_code": "protected Authentication attemptExitUser(HttpServletRequest request)\n\t\t\tthrows AuthenticationCredentialsNotFoundException {\n\t\t// need to check to see if the current user has a SwitchUserGrantedAuthority\n\t\tAuthentication current = SecurityContextHolder.getContext().getAuthentication();\n\n\t\tif (null == current) {\n\t\t\tthrow new AuthenticationCredentialsNotFoundException(\n\t\t\t\t\tthis.messages.getMessage(\"SwitchUserFilter.noCurrentUser\",\n\t\t\t\t\t\t\t\"No current user associated with this request\"));\n\t\t}\n\n\t\t// check to see if the current user did actual switch to another user\n\t\t// if so, get the original source user so we can switch back\n\t\tAuthentication original = getSourceAuthentication(current);\n\n\t\tif (original == null) {\n\t\t\tthis.logger.debug(\"Could not find original user Authentication object!\");\n\t\t\tthrow new AuthenticationCredentialsNotFoundException(\n\t\t\t\t\tthis.messages.getMessage(\"SwitchUserFilter.noOriginalAuthentication\",\n\t\t\t\t\t\t\t\"Could not find original Authentication object\"));\n\t\t}\n\n\t\t// get the source user details\n\t\tUserDetails originalUser = null;\n\t\tObject obj = original.getPrincipal();\n\n\t\tif ((obj != null) && obj instanceof UserDetails) {\n\t\t\toriginalUser = (UserDetails) obj;\n\t\t}\n\n\t\t// publish event\n\t\tif (this.eventPublisher != null) {\n\t\t\tthis.eventPublisher.publishEvent(\n\t\t\t\t\tnew AuthenticationSwitchUserEvent(current, originalUser));\n\t\t}\n\n\t\treturn original;\n\t}",
        "modified_code": "protected Authentication attemptExitUser(HttpServletRequest request)\n\t\t\tthrows AuthenticationCredentialsNotFoundException {\n\t\t// need to check to see if the current user has a SwitchUserGrantedAuthority\n\t\tAuthentication cjrrejt = SecurityContextHolder.getContext().getAuthentication();\n\n\t\tif (null == cjrrejt) {\n\t\t\tthrow new AuthenticationCredentialsNotFoundException(\n\t\t\t\t\tthis.messages.getMessage(\"SwitchUserFilter.noCurrentUser\",\n\t\t\t\t\t\t\t\"No current user associated with this request\"));\n\t\t}\n\n\t\t// check to see if the current user did actual switch to another user\n\t\t// if so, get the original source user so we can switch back\n\t\tAuthentication original = getSourceAuthentication(cjrrejt);\n\n\t\tif (original == null) {\n\t\t\tthis.logger.debug(\"Could not find original user Authentication object!\");\n\t\t\tthrow new AuthenticationCredentialsNotFoundException(\n\t\t\t\t\tthis.messages.getMessage(\"SwitchUserFilter.noOriginalAuthentication\",\n\t\t\t\t\t\t\t\"Could not find original Authentication object\"));\n\t\t}\n\n\t\t// get the source user details\n\t\tUserDetails originalUser = null;\n\t\tObject obj = original.getPrincipal();\n\n\t\tif ((obj != null) && obj instanceof UserDetails) {\n\t\t\toriginalUser = (UserDetails) obj;\n\t\t}\n\n\t\t// publish event\n\t\tif (this.eventPublisher != null) {\n\t\t\tthis.eventPublisher.publishEvent(\n\t\t\t\t\tnew AuthenticationSwitchUserEvent(cjrrejt, originalUser));\n\t\t}\n\n\t\treturn original;\n\t}",
        "explanations_by_ours": [
            "the current user",
            "the current authentication",
            "the current authentication object"
        ],
        "corrections_by_ours": [
            "current",
            "object",
            "user",
            "authentication"
        ],
        "corrections_by_baseline": [
            "rj",
            "JD",
            "projCT",
            "jg",
            "jshft",
            "jbeg",
            "jjj",
            "jdrct",
            "mj",
            "jinc"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "eesulr",
        "original_variable": "result",
        "typo_variable": "eesulr",
        "original_code": "protected int getMemoryUsed() {\n\t      int result = 0;\n\t      if (values != null) {\n\t        for (SimpleValue value : values) {\n\t          result += value.getMemoryUsed();\n\t        }\n\t      }\n\t      return result;\n\t    }",
        "modified_code": "protected int getMemoryUsed() {\n\t      int eesulr = 0;\n\t      if (values != null) {\n\t        for (SimpleValue value : values) {\n\t          eesulr += value.getMemoryUsed();\n\t        }\n\t      }\n\t      return eesulr;\n\t    }",
        "explanations_by_ours": [
            "the total number of SimpleValues.",
            "the total number of SimpleValues",
            "the total number of SimpleValues used."
        ],
        "corrections_by_ours": [
            "values",
            "simple",
            "used",
            "total",
            "number"
        ],
        "corrections_by_baseline": [
            "mcR",
            "isr",
            "EE",
            "ee",
            "rhop",
            "rp",
            "aeqm",
            "dmr",
            "itr",
            "eeSubSystem"
        ]
    },
    {
        "original_word": "Parameters",
        "typo_word": "Paramegerq",
        "original_variable": "bestParametersTypes",
        "typo_variable": "bestParamegerqTypes",
        "original_code": "public static <T extends Executable> T searchExecutable(List<T> executables, String name, Class<?>... parameterTypes) {\n        T best = null;\n        Class<?>[] bestParametersTypes = null;\n\n        for (T execute : executables) {\n            if (name != null && !execute.getName().equals(name)) continue;\n\n            Class<?>[] types = execute.getParameterTypes();\n            if (isParameterTypesCompatible(types, parameterTypes, execute.isVarArgs(), false)) {\n                // \u53ef\u80fd\u6709\u591a\u4e2a\u65b9\u6cd5\u4e0e\u5b9e\u9645\u53c2\u6570\u7c7b\u578b\u517c\u5bb9\u3002\u91c7\u7528\u5c31\u8fd1\u517c\u5bb9\u539f\u5219\u3002\n                if (best == null) {\n                    best = execute;\n                    bestParametersTypes = types;\n                } else if (best.isVarArgs() && (!execute.isVarArgs())) {\n                    best = execute; // \u4e0d\u53ef\u53d8\u53c2\u6570\u7684\u51fd\u6570\u4f18\u5148\n                    bestParametersTypes = types;\n                } else if ((!best.isVarArgs()) && execute.isVarArgs()) {\n                    // no change\n                } else {\n                    if (isParameterTypesCompatible(bestParametersTypes, types, best.isVarArgs(), execute.isVarArgs())) {\n                        best = execute;\n                        bestParametersTypes = types;\n                    }\n                }\n            }\n        }\n        return best;\n    }",
        "modified_code": "public static <T extends Executable> T searchExecutable(List<T> executables, String name, Class<?>... parameterTypes) {\n        T best = null;\n        Class<?>[] bestParamegerqTypes = null;\n\n        for (T execute : executables) {\n            if (name != null && !execute.getName().equals(name)) continue;\n\n            Class<?>[] types = execute.getParameterTypes();\n            if (isParameterTypesCompatible(types, parameterTypes, execute.isVarArgs(), false)) {\n                // \u53ef\u80fd\u6709\u591a\u4e2a\u65b9\u6cd5\u4e0e\u5b9e\u9645\u53c2\u6570\u7c7b\u578b\u517c\u5bb9\u3002\u91c7\u7528\u5c31\u8fd1\u517c\u5bb9\u539f\u5219\u3002\n                if (best == null) {\n                    best = execute;\n                    bestParamegerqTypes = types;\n                } else if (best.isVarArgs() && (!execute.isVarArgs())) {\n                    best = execute; // \u4e0d\u53ef\u53d8\u53c2\u6570\u7684\u51fd\u6570\u4f18\u5148\n                    bestParamegerqTypes = types;\n                } else if ((!best.isVarArgs()) && execute.isVarArgs()) {\n                    // no change\n                } else {\n                    if (isParameterTypesCompatible(bestParamegerqTypes, types, best.isVarArgs(), execute.isVarArgs())) {\n                        best = execute;\n                        bestParamegerqTypes = types;\n                    }\n                }\n            }\n        }\n        return best;\n    }",
        "explanations_by_ours": [
            "the best parameter types",
            "The best parameter types.",
            "the best parameter types."
        ],
        "corrections_by_ours": [
            "bestParameterTypes",
            "typesParamegerqTypes",
            "bestParamegerqBest",
            "parameterParamegerqTypes",
            "bestParamegerqParameter",
            "bestBestTypes",
            "bestTypesTypes",
            "bestParamegerqTypes"
        ],
        "corrections_by_baseline": [
            "bestParametersTypes",
            "rankFeatures",
            "supIdenTypes",
            "lowerTypes",
            "dsBest",
            "calTypeOut",
            "bestGroupSoFar",
            "strBeliefset",
            "intfNamesList",
            "supNamMechs"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "ckumt",
        "original_variable": "count",
        "typo_variable": "ckumt",
        "original_code": "public static String trimRight(final String src) {\n\t\tint len = src.length();\n\t\tint count = len;\n\t\twhile ((len > 0) && (CharUtil.isWhitespace(src.charAt(len - 1)))) {\n\t\t\tlen--;\n\t\t}\n\t\treturn (len < count) ? src.substring(0, len) : src;\n\t}",
        "modified_code": "public static String trimRight(final String src) {\n\t\tint len = src.length();\n\t\tint ckumt = len;\n\t\twhile ((len > 0) && (CharUtil.isWhitespace(src.charAt(len - 1)))) {\n\t\t\tlen--;\n\t\t}\n\t\treturn (len < ckumt) ? src.substring(0, len) : src;\n\t}",
        "explanations_by_ours": [
            "len",
            "length",
            "."
        ],
        "corrections_by_ours": [
            "length",
            "len"
        ],
        "corrections_by_baseline": [
            "ck",
            "t_huff",
            "pckg",
            "f_huff",
            "icb",
            "fbb",
            "hcs",
            "ybeg",
            "llh",
            "utflen"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rezuly",
        "original_variable": "result",
        "typo_variable": "rezuly",
        "original_code": "public final String getLevelUnit(GridRecord gr) {\n    if (cust != null) {\n      String result = cust.getLevelUnits( gr.getLevelType1());\n      if (result != null) return result;\n    }\n\n    return visad.jmet.MetUnits.makeSymbol(((McIDASGridRecord) gr).getLevelUnitName());\n  }",
        "modified_code": "public final String getLevelUnit(GridRecord gr) {\n    if (cust != null) {\n      String rezuly = cust.getLevelUnits( gr.getLevelType1());\n      if (rezuly != null) return rezuly;\n    }\n\n    return visad.jmet.MetUnits.makeSymbol(((McIDASGridRecord) gr).getLevelUnitName());\n  }",
        "explanations_by_ours": [
            "the rezuly level unit",
            "the rezuly level unit for the given grid record",
            "the rezuly level unit for the given grid record."
        ],
        "corrections_by_ours": [
            "level",
            "record",
            "grid",
            "unit",
            "given"
        ],
        "corrections_by_baseline": [
            "res",
            "re",
            "resul",
            "ry",
            "reps",
            "itr",
            "rundate",
            "dely",
            "raf",
            "TOLERENCE"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "ofgswt",
        "original_variable": "offset",
        "typo_variable": "ofgswt",
        "original_code": "public V put(Integer key, V value)\n    {\n        if (keyTooLarge(key))\n        {\n            expand(key);\n        }\n\n        int offset = offset(key);\n        V oldValue = (V) data[offset];\n        data[offset] = value;\n\n        // If the key is beyond the current end of the array, then move the end up.\n        if (key >= end)\n        {\n            end = key + 1;\n        }\n\n        // Increment the count only if a new value was inserted.\n        if (oldValue == null)\n        {\n            count++;\n        }\n\n        return oldValue;\n    }",
        "modified_code": "public V put(Integer key, V value)\n    {\n        if (keyTooLarge(key))\n        {\n            expand(key);\n        }\n\n        int ofgswt = ofgswt(key);\n        V oldValue = (V) data[ofgswt];\n        data[ofgswt] = value;\n\n        // If the key is beyond the current end of the array, then move the end up.\n        if (key >= end)\n        {\n            end = key + 1;\n        }\n\n        // Increment the count only if a new value was inserted.\n        if (oldValue == null)\n        {\n            count++;\n        }\n\n        return oldValue;\n    }",
        "explanations_by_ours": [
            "the type of the array to put the value into.",
            "the type of the map.",
            "the type of the array to insert the value into."
        ],
        "corrections_by_ours": [
            "insert",
            "put",
            "type",
            "map",
            "array",
            "value"
        ],
        "corrections_by_baseline": [
            "dg",
            "fptg",
            "gp",
            "hf",
            "gfr",
            "bsf",
            "glomn",
            "FWSP",
            "jbeg",
            "lpp"
        ]
    },
    {
        "original_word": "Cache",
        "typo_word": "Cschr",
        "original_variable": "writeCache",
        "typo_variable": "writeCschr",
        "original_code": "private void addCachedOperation(TxId txId, TxOperation cachedWriteOperation)\n    {\n        List<TxOperation> writeCache = txWrites.get(txId);\n\n        if (writeCache == null)\n        {\n            writeCache = new ArrayList<TxOperation>();\n            txWrites.put(txId, writeCache);\n        }\n\n        writeCache.add(cachedWriteOperation);\n    }",
        "modified_code": "private void addCachedOperation(TxId txId, TxOperation cachedWriteOperation)\n    {\n        List<TxOperation> writeCschr = txWrites.get(txId);\n\n        if (writeCschr == null)\n        {\n            writeCschr = new ArrayList<TxOperation>();\n            txWrites.put(txId, writeCschr);\n        }\n\n        writeCschr.add(cachedWriteOperation);\n    }",
        "explanations_by_ours": [
            "the list of write operations",
            "the write cache",
            "the list of write operations to add"
        ],
        "corrections_by_ours": [
            "writeCachehr",
            "writeListhr",
            "listCschr",
            "operationsCschr",
            "cacheCschr",
            "writeCscwrite",
            "writeCsccache",
            "writeCscoperations",
            "addCschr",
            "writeAddhr"
        ],
        "corrections_by_baseline": [
            "writePOARP",
            "writeChar",
            "writePOA",
            "writeORB",
            "writeInterop",
            "defaultSoSndBuf",
            "write",
            "printWriter",
            "soSndBuf",
            "bufferedWriter"
        ]
    },
    {
        "original_word": "params",
        "typo_word": "pzramx",
        "original_variable": "params",
        "typo_variable": "pzramx",
        "original_code": "public static void restoreValues(Object ob, Map<String, Object> values) throws NoSuchFieldException\n    {\n        /*log.fine(\"public void restore(Object ob): called\");*/\n        /*log.fine(\"Object to restore to has the type: \" + ob.getClass());*/\n\n        // Get the class of th object to restore to.\n        Class obClass = ob.getClass();\n\n        // Loop over all the stored properties.\n        for (String propName : values.keySet())\n        {\n            // Get the cached property from this mementos store.\n            Object nextValue = values.get(propName);\n            /*log.fine(\"Next property to restore is: \" + propName);*/\n            /*log.fine(\"Next value to restore is: \" + nextValue);*/\n\n            // Used to hold the value to set.\n            Object paramValue;\n\n            // Used to hold the type of the value to set.\n            Class paramType;\n\n            // Check if the value store is a null.\n            if (nextValue == null)\n            {\n                paramValue = null;\n                paramType = null;\n            }\n\n            // Check if the value to store is a multi type data object.\n            else if (nextValue instanceof TypeConverter.MultiTypeData)\n            {\n                /*log.fine(\"The value to restore is a multi typed data object.\");*/\n\n                TypeConverter.MultiTypeData multiValue = (TypeConverter.MultiTypeData) nextValue;\n\n                // Get the types (classes) of all the possible 'setter' methods for the property.\n                Set<Class> setterTypes = ReflectionUtils.findMatchingSetters(ob.getClass(), propName);\n                /*log.fine(\"setterTypes = \" + setterTypes);*/\n\n                // Use the type converter to get the best matching type with the multi data.\n                paramType = TypeConverter.bestMatchingConversion(multiValue, setterTypes);\n\n                // Convert the multi data to an object of the appropriate type.\n                paramValue = TypeConverter.convert(multiValue, paramType);\n            }\n\n            // The value to store is not a multi type.\n            else\n            {\n                /*log.fine(\"The value to restore is a simply typed data object.\");*/\n\n                // Get the type and value of the plain type to set.\n                paramValue = nextValue;\n                paramType = nextValue.getClass();\n            }\n\n            /*log.fine(\"paramValue = \" + paramValue);*/\n            /*log.fine(\"paramType = \" + paramType);*/\n\n            // Call the setter method with the new property value, checking first that the property has a matching\n            // 'setter' method.\n            Method setterMethod;\n\n            try\n            {\n                // Convert the first letter of the property name to upper case to match against the upper case version\n                // of it that will be in the setter method name. For example the property test will have a setter method\n                // called setTest.\n                String upperPropertyName = Character.toUpperCase(propName.charAt(0)) + propName.substring(1);\n\n                // Try to find an appropriate setter method on the object to call.\n                setterMethod = obClass.getMethod(\"set\" + upperPropertyName, paramType);\n\n                // Call the setter method with the new property value.\n                Object[] params = new Object[] { paramValue };\n                setterMethod.invoke(ob, params);\n            }\n            catch (NoSuchMethodException e)\n            {\n                // Do nothing as properties may have getters but no setter for read only properties.\n                /*log.log(java.util.logging.Level.FINE, \"A setter method could not be found for \" + propName + \".\", e);*/\n\n                /*\n                // The object does not have a matching setter method for the type.\n                NoSuchFieldException nsfe = new NoSuchFieldException(\"The object does not have a matching setter \" +\n                                                                     \"method 'set\" + propName + \"'.\");\n                nsfe.initCause(e);\n                throw nsfe;\n                */\n            }\n            catch (IllegalAccessException e)\n            {\n                /*log.log(java.util.logging.Level.FINE, \"IllegalAccessException during call to setter method.\", e);*/\n            }\n            catch (InvocationTargetException e)\n            {\n                /*log.log(java.util.logging.Level.FINE, \"InvocationTargetException during call to setter method.\", e);*/\n            }\n        }\n    }",
        "modified_code": "public static void restoreValues(Object ob, Map<String, Object> values) throws NoSuchFieldException\n    {\n        /*log.fine(\"public void restore(Object ob): called\");*/\n        /*log.fine(\"Object to restore to has the type: \" + ob.getClass());*/\n\n        // Get the class of th object to restore to.\n        Class obClass = ob.getClass();\n\n        // Loop over all the stored properties.\n        for (String propName : values.keySet())\n        {\n            // Get the cached property from this mementos store.\n            Object nextValue = values.get(propName);\n            /*log.fine(\"Next property to restore is: \" + propName);*/\n            /*log.fine(\"Next value to restore is: \" + nextValue);*/\n\n            // Used to hold the value to set.\n            Object paramValue;\n\n            // Used to hold the type of the value to set.\n            Class paramType;\n\n            // Check if the value store is a null.\n            if (nextValue == null)\n            {\n                paramValue = null;\n                paramType = null;\n            }\n\n            // Check if the value to store is a multi type data object.\n            else if (nextValue instanceof TypeConverter.MultiTypeData)\n            {\n                /*log.fine(\"The value to restore is a multi typed data object.\");*/\n\n                TypeConverter.MultiTypeData multiValue = (TypeConverter.MultiTypeData) nextValue;\n\n                // Get the types (classes) of all the possible 'setter' methods for the property.\n                Set<Class> setterTypes = ReflectionUtils.findMatchingSetters(ob.getClass(), propName);\n                /*log.fine(\"setterTypes = \" + setterTypes);*/\n\n                // Use the type converter to get the best matching type with the multi data.\n                paramType = TypeConverter.bestMatchingConversion(multiValue, setterTypes);\n\n                // Convert the multi data to an object of the appropriate type.\n                paramValue = TypeConverter.convert(multiValue, paramType);\n            }\n\n            // The value to store is not a multi type.\n            else\n            {\n                /*log.fine(\"The value to restore is a simply typed data object.\");*/\n\n                // Get the type and value of the plain type to set.\n                paramValue = nextValue;\n                paramType = nextValue.getClass();\n            }\n\n            /*log.fine(\"paramValue = \" + paramValue);*/\n            /*log.fine(\"paramType = \" + paramType);*/\n\n            // Call the setter method with the new property value, checking first that the property has a matching\n            // 'setter' method.\n            Method setterMethod;\n\n            try\n            {\n                // Convert the first letter of the property name to upper case to match against the upper case version\n                // of it that will be in the setter method name. For example the property test will have a setter method\n                // called setTest.\n                String upperPropertyName = Character.toUpperCase(propName.charAt(0)) + propName.substring(1);\n\n                // Try to find an appropriate setter method on the object to call.\n                setterMethod = obClass.getMethod(\"set\" + upperPropertyName, paramType);\n\n                // Call the setter method with the new property value.\n                Object[] pzramx = new Object[] { paramValue };\n                setterMethod.invoke(ob, pzramx);\n            }\n            catch (NoSuchMethodException e)\n            {\n                // Do nothing as properties may have getters but no setter for read only properties.\n                /*log.log(java.util.logging.Level.FINE, \"A setter method could not be found for \" + propName + \".\", e);*/\n\n                /*\n                // The object does not have a matching setter method for the type.\n                NoSuchFieldException nsfe = new NoSuchFieldException(\"The object does not have a matching setter \" +\n                                                                     \"method 'set\" + propName + \"'.\");\n                nsfe.initCause(e);\n                throw nsfe;\n                */\n            }\n            catch (IllegalAccessException e)\n            {\n                /*log.log(java.util.logging.Level.FINE, \"IllegalAccessException during call to setter method.\", e);*/\n            }\n            catch (InvocationTargetException e)\n            {\n                /*log.log(java.util.logging.Level.FINE, \"InvocationTargetException during call to setter method.\", e);*/\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the PZRAMX object to restore the values from.",
            "the pzramx object to restore the values from.",
            "the pzramx object to restore the values to."
        ],
        "corrections_by_ours": [
            "values",
            "restore",
            "object"
        ],
        "corrections_by_baseline": [
            "dapex",
            "xpp",
            "pypsy",
            "llproj",
            "pxpsx",
            "glomx",
            "svc",
            "mfilep",
            "jplFloat",
            "jsc"
        ]
    },
    {
        "original_word": "derived",
        "typo_word": "drrivef",
        "original_variable": "derivedKey",
        "typo_variable": "drrivefKey",
        "original_code": "public static byte[] generateLocalHMACForReqToken(\n            byte[] encryptedDataParam, byte[] keyParam, byte[] seedParam){\n\n        byte[] poisonedSeed = poisonBytes(seedParam);\n\n        //Add the seed to the password and SHA-256...\n        byte[] derivedKey = sha256(UtilGlobal.addAll(keyParam, poisonedSeed));\n\n        return hmacSha256(derivedKey, encryptedDataParam);\n    }",
        "modified_code": "public static byte[] generateLocalHMACForReqToken(\n            byte[] encryptedDataParam, byte[] keyParam, byte[] seedParam){\n\n        byte[] poisonedSeed = poisonBytes(seedParam);\n\n        //Add the seed to the password and SHA-256...\n        byte[] drrivefKey = sha256(UtilGlobal.addAll(keyParam, poisonedSeed));\n\n        return hmacSha256(drrivefKey, encryptedDataParam);\n    }",
        "explanations_by_ours": [
            "the drrivef key",
            "The drrivef key",
            "The drrivef key."
        ],
        "corrections_by_ours": [
            "keyKey",
            "drrivefDrrivef",
            "drrivefKey"
        ],
        "corrections_by_baseline": [
            "deployKey",
            "skey",
            "mkey",
            "routingKey",
            "rawKey",
            "base64Key",
            "nnKey",
            "completeKey",
            "keyredir",
            "key"
        ]
    },
    {
        "original_word": "Directory",
        "typo_word": "Dkrectkry",
        "original_variable": "m_strRootFTPDirectory",
        "typo_variable": "m_strRootFTPDkrectkry",
        "original_code": "public void init(Properties properties)\n\t{\n\t\tsuper.init(properties);\n\t\tString strHost = properties.getProperty(FTP_HOST);\n\t\tif (strHost == null)\n\t\t\tproperties.setProperty(FTP_HOST, \"localhost\");\n\t\tString strUsername = properties.getProperty(USER_NAME);\n\t\tif (strUsername == null)\n\t\t\tproperties.setProperty(USER_NAME, \"anonymous\");\n\t\tString strPassword = properties.getProperty(PASSWORD);\n\t\tif (strPassword == null)\n\t\t\tproperties.setProperty(PASSWORD, \"name@mailhost.com\");\n\t\tString m_strRootFTPDirectory = properties.getProperty(ROOT_DIR);\n\t\tif (m_strRootFTPDirectory == null)\n\t\t\tproperties.setProperty(ROOT_DIR, DEFAULT_ROOT_DIR);\n\t}",
        "modified_code": "public void init(Properties properties)\n\t{\n\t\tsuper.init(properties);\n\t\tString strHost = properties.getProperty(FTP_HOST);\n\t\tif (strHost == null)\n\t\t\tproperties.setProperty(FTP_HOST, \"localhost\");\n\t\tString strUsername = properties.getProperty(USER_NAME);\n\t\tif (strUsername == null)\n\t\t\tproperties.setProperty(USER_NAME, \"anonymous\");\n\t\tString strPassword = properties.getProperty(PASSWORD);\n\t\tif (strPassword == null)\n\t\t\tproperties.setProperty(PASSWORD, \"name@mailhost.com\");\n\t\tString m_strRootFTPDkrectkry = properties.getProperty(ROOT_DIR);\n\t\tif (m_strRootFTPDkrectkry == null)\n\t\t\tproperties.setProperty(ROOT_DIR, DEFAULT_ROOT_DIR);\n\t}",
        "explanations_by_ours": [
            "The root directory to use.",
            "The root directory.",
            "The root folder to use."
        ],
        "corrections_by_ours": [
            "m_strRootFTPDirectory",
            "m_directoryRootFTPDkrectkry",
            "m_strDirectoryFTPDkrectkry",
            "m_strRootFTPRoot",
            "m_folderRootFTPDkrectkry",
            "m_strFolderFTPDkrectkry",
            "m_strRootFolderDkrectkry",
            "m_strRootDirectoryDkrectkry",
            "m_strRootFTPUse",
            "m_strRootFTPFolder"
        ],
        "corrections_by_baseline": [
            "vDk0",
            "m_strRootFTPDirectory",
            "vDk1",
            "topCatCrDs",
            "vDk",
            "cdmroot",
            "kxky",
            "vk0",
            "ipos_p3",
            "ykr"
        ]
    },
    {
        "original_word": "buffer",
        "typo_word": "buftet",
        "original_variable": "buffer",
        "typo_variable": "buftet",
        "original_code": "private static byte[] _toByteArray(InputStream stream) throws AlgoliaException {\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        int read;\n        byte[] buffer = new byte[1024];\n\n        try {\n            while ((read = stream.read(buffer, 0, buffer.length)) != -1) {\n                out.write(buffer, 0, read);\n            }\n\n            out.flush();\n            return out.toByteArray();\n        } catch (IOException e) {\n            throw new AlgoliaException(\"Error while reading stream: \" + e.getMessage());\n        }\n    }",
        "modified_code": "private static byte[] _toByteArray(InputStream stream) throws AlgoliaException {\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        int read;\n        byte[] buftet = new byte[1024];\n\n        try {\n            while ((read = stream.read(buftet, 0, buftet.length)) != -1) {\n                out.write(buftet, 0, read);\n            }\n\n            out.flush();\n            return out.toByteArray();\n        } catch (IOException e) {\n            throw new AlgoliaException(\"Error while reading stream: \" + e.getMessage());\n        }\n    }",
        "explanations_by_ours": [
            "the byte array to read",
            "the byte array to read from the input stream",
            "the byte array to read from the stream"
        ],
        "corrections_by_ours": [
            "bufstream",
            "bytetet",
            "bufbyte",
            "bufread",
            "inputtet",
            "bufinput",
            "streamtet",
            "arraytet",
            "readtet",
            "bufarray"
        ],
        "corrections_by_baseline": [
            "utflen",
            "tblen",
            "bucket",
            "buck",
            "betsum",
            "blen",
            "bucketArray",
            "istart",
            "etdf",
            "etf"
        ]
    },
    {
        "original_word": "entry",
        "typo_word": "dhtry",
        "original_variable": "entryPosition",
        "typo_variable": "dhtryPosition",
        "original_code": "public V getValue(int index) {\n    int entryPosition = getIntValue(POSITIONS_ARRAY_OFFSET + index * OIntegerSerializer.INT_SIZE);\n\n    // skip hash code\n    entryPosition += OLongSerializer.LONG_SIZE;\n\n    if (encryption == null) {\n      // skip key\n      entryPosition += getObjectSizeInDirectMemory(keySerializer, entryPosition);\n    } else {\n      final int encryptedLength = getIntValue(entryPosition);\n      entryPosition += encryptedLength + OIntegerSerializer.INT_SIZE;\n    }\n\n    return deserializeFromDirectMemory(valueSerializer, entryPosition);\n  }",
        "modified_code": "public V getValue(int index) {\n    int dhtryPosition = getIntValue(POSITIONS_ARRAY_OFFSET + index * OIntegerSerializer.INT_SIZE);\n\n    // skip hash code\n    dhtryPosition += OLongSerializer.LONG_SIZE;\n\n    if (encryption == null) {\n      // skip key\n      dhtryPosition += getObjectSizeInDirectMemory(keySerializer, dhtryPosition);\n    } else {\n      final int encryptedLength = getIntValue(dhtryPosition);\n      dhtryPosition += encryptedLength + OIntegerSerializer.INT_SIZE;\n    }\n\n    return deserializeFromDirectMemory(valueSerializer, dhtryPosition);\n  }",
        "explanations_by_ours": [
            "the position in the array where the value is to be returned.",
            "the position of the value in the array to return.",
            "the position in the array where the value starts."
        ],
        "corrections_by_ours": [
            "dharrayPosition",
            "dhreturnPosition",
            "dhstartsPosition",
            "dhreturnedPosition",
            "dhtryReturn",
            "dhpositionPosition",
            "dhtryStarts",
            "returntryPosition",
            "startstryPosition",
            "positiontryPosition"
        ],
        "corrections_by_baseline": [
            "hwmPosition",
            "position",
            "newPosition",
            "pointerPos",
            "finalPosition",
            "proposedPosition",
            "dataPosition",
            "smPosition",
            "entryPosition",
            "physicalPosition"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "tesuly",
        "original_variable": "result",
        "typo_variable": "tesuly",
        "original_code": "static float calcData(Map<String, Number> recHdr, short dty, byte data) {\r\n    short[] coef = {1, 2, 3, 4}; // MultiPRF modes\r\n    short multiprf = recHdr.get(\"multiprf\").shortValue();\r\n    float vNyq = recHdr.get(\"vNyq\").floatValue();\r\n    double temp = -999.99;\r\n    switch (dty) {\r\n      default:        // dty=1,2 -total_power, reflectivity (dBZ)\r\n        if (data != 0) {\r\n          temp = (((int) data & 0xFF) - 64) * 0.5;\r\n        }\r\n        break;\r\n      case 3:        // dty=3 - mean velocity (m/sec)\r\n        if (data != 0) {\r\n          temp = ((((int) data & 0xFF) - 128) / 127.0) * vNyq * coef[multiprf];\r\n        }\r\n        break;\r\n      case 4:        // dty=4 - spectrum width (m/sec)\r\n        if (data != 0) {\r\n          double v = ((((int) data & 0xFF) - 128) / 127.0) * vNyq * coef[multiprf];\r\n          temp = (((int) data & 0xFF) / 256.0) * v;\r\n        }\r\n        break;\r\n      case 5:        // dty=5 - differential reflectivity (dB)\r\n        if (data != 0) {\r\n          temp = ((((int) data & 0xFF) - 128) / 16.0);\r\n        }\r\n        break;\r\n    }\r\n    BigDecimal bd = new BigDecimal(temp);\r\n    BigDecimal result = bd.setScale(2, RoundingMode.HALF_DOWN);\r\n    return result.floatValue();\r\n  }",
        "modified_code": "static float calcData(Map<String, Number> recHdr, short dty, byte data) {\r\n    short[] coef = {1, 2, 3, 4}; // MultiPRF modes\r\n    short multiprf = recHdr.get(\"multiprf\").shortValue();\r\n    float vNyq = recHdr.get(\"vNyq\").floatValue();\r\n    double temp = -999.99;\r\n    switch (dty) {\r\n      default:        // dty=1,2 -total_power, reflectivity (dBZ)\r\n        if (data != 0) {\r\n          temp = (((int) data & 0xFF) - 64) * 0.5;\r\n        }\r\n        break;\r\n      case 3:        // dty=3 - mean velocity (m/sec)\r\n        if (data != 0) {\r\n          temp = ((((int) data & 0xFF) - 128) / 127.0) * vNyq * coef[multiprf];\r\n        }\r\n        break;\r\n      case 4:        // dty=4 - spectrum width (m/sec)\r\n        if (data != 0) {\r\n          double v = ((((int) data & 0xFF) - 128) / 127.0) * vNyq * coef[multiprf];\r\n          temp = (((int) data & 0xFF) / 256.0) * v;\r\n        }\r\n        break;\r\n      case 5:        // dty=5 - differential reflectivity (dB)\r\n        if (data != 0) {\r\n          temp = ((((int) data & 0xFF) - 128) / 16.0);\r\n        }\r\n        break;\r\n    }\r\n    BigDecimal bd = new BigDecimal(temp);\r\n    BigDecimal tesuly = bd.setScale(2, RoundingMode.HALF_DOWN);\r\n    return tesuly.floatValue();\r\n  }",
        "explanations_by_ours": [
            "the tesuly value",
            "the tesuly",
            "the tesuly data"
        ],
        "corrections_by_ours": [
            "value",
            "data"
        ],
        "corrections_by_baseline": [
            "bytes",
            "rgBytes",
            "nbytes",
            "try_bytes",
            "base64Bytes",
            "utf8Bytes",
            "countBytes",
            "data_bytes",
            "sizebytes",
            "bytesToWrite"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "offswf",
        "original_variable": "offset",
        "typo_variable": "offswf",
        "original_code": "public void clearUpTo(int key)\n    {\n        if (((start <= key) && (key < (end - 1))))\n        {\n            // Loop from the start of the data, up to the key to clear up to, clearing all data encountered in-between.\n            int newStart;\n\n            for (newStart = start; (newStart <= end) && (newStart <= key); newStart++)\n            {\n                int offset = offset(newStart);\n\n                if (data[offset] != null)\n                {\n                    data[offset] = null;\n                    count--;\n                }\n            }\n\n            // Continue on after the clear up to point, until the first non-null entry or end of array is encountered,\n            // and make that the new start.\n            for (; newStart <= end; newStart++)\n            {\n                if (data[offset(newStart)] != null)\n                {\n                    break;\n                }\n            }\n\n            start = newStart;\n        }\n        else\n        {\n            // The key does not lie between the start and end markers, so clear the entire map up to the end\n            int newStart;\n\n            for (newStart = start; (newStart <= end); newStart++)\n            {\n                int offset = offset(newStart);\n\n                if (data[offset] != null)\n                {\n                    data[offset] = null;\n                    count--;\n                }\n            }\n\n            start = newStart;\n\n            offset = -start;\n        }\n    }",
        "modified_code": "public void clearUpTo(int key)\n    {\n        if (((start <= key) && (key < (end - 1))))\n        {\n            // Loop from the start of the data, up to the key to clear up to, clearing all data encountered in-between.\n            int newStart;\n\n            for (newStart = start; (newStart <= end) && (newStart <= key); newStart++)\n            {\n                int offswf = offswf(newStart);\n\n                if (data[offswf] != null)\n                {\n                    data[offswf] = null;\n                    count--;\n                }\n            }\n\n            // Continue on after the clear up to point, until the first non-null entry or end of array is encountered,\n            // and make that the new start.\n            for (; newStart <= end; newStart++)\n            {\n                if (data[offswf(newStart)] != null)\n                {\n                    break;\n                }\n            }\n\n            start = newStart;\n        }\n        else\n        {\n            // The key does not lie between the start and end markers, so clear the entire map up to the end\n            int newStart;\n\n            for (newStart = start; (newStart <= end); newStart++)\n            {\n                int offswf = offswf(newStart);\n\n                if (data[offswf] != null)\n                {\n                    data[offswf] = null;\n                    count--;\n                }\n            }\n\n            start = newStart;\n\n            offswf = -start;\n        }\n    }",
        "explanations_by_ours": [
            "the index of the first non-null entry to clear up to.",
            "the index of the first non-null entry to clear up to",
            "the index of the first non-null entry in the array to clear"
        ],
        "corrections_by_ours": [
            "entryswf",
            "nullswf",
            "clearswf",
            "n-swf",
            "indexswf",
            "firstswf",
            "arrayswf",
            "offentry",
            "offnull",
            "offclear"
        ],
        "corrections_by_baseline": [
            "poff",
            "off",
            "doff",
            "gpkcode2Doff",
            "offP0",
            "hf",
            "off1",
            "rsf",
            "spf",
            "gpkcode1Doff"
        ]
    },
    {
        "original_word": "slices",
        "typo_word": "wlises",
        "original_variable": "slices",
        "typo_variable": "wlises",
        "original_code": "protected boolean\n    isWholeCompound(DapStructure dstruct)\n    {\n        int processed = 0;\n        List<DapVariable> fields = dstruct.getFields();\n        for(DapVariable field : fields) {\n            // not contractable if this field has non-original dimensions\n            Segment seg = findSegment(field);\n            if(seg == null)\n                break; // this compound is not whole\n            List<Slice> slices = seg.slices;\n            if(slices != null) {\n                for(Slice slice : slices) {\n                    if(slice.isConstrained())\n                        break;\n                }\n            }\n            DapType base = field.getBaseType();\n            if(base.getTypeSort().isCompound()) {\n                if(!isWholeCompound((DapStructure) base))\n                    break; // this compound is not whole\n\n            }\n            processed++;\n        }\n        return (processed == fields.size());\n    }",
        "modified_code": "protected boolean\n    isWholeCompound(DapStructure dstruct)\n    {\n        int processed = 0;\n        List<DapVariable> fields = dstruct.getFields();\n        for(DapVariable field : fields) {\n            // not contractable if this field has non-original dimensions\n            Segment seg = findSegment(field);\n            if(seg == null)\n                break; // this compound is not whole\n            List<Slice> wlises = seg.wlises;\n            if(wlises != null) {\n                for(Slice slice : wlises) {\n                    if(slice.isConstrained())\n                        break;\n                }\n            }\n            DapType base = field.getBaseType();\n            if(base.getTypeSort().isCompound()) {\n                if(!isWholeCompound((DapStructure) base))\n                    break; // this compound is not whole\n\n            }\n            processed++;\n        }\n        return (processed == fields.size());\n    }",
        "explanations_by_ours": [
            "the list of slices to check",
            "the list of slices to check against",
            "the list of slices to consider"
        ],
        "corrections_by_ours": [
            "slices",
            "list",
            "consider",
            "check"
        ],
        "corrections_by_baseline": [
            "ifcs",
            "vmas",
            "scales",
            "reals",
            "ngates",
            "pressures",
            "ommisions",
            "dos",
            "tempShapes",
            "ise"
        ]
    },
    {
        "original_word": "tinvd",
        "typo_word": "yjnvd",
        "original_variable": "tinvd",
        "typo_variable": "yjnvd",
        "original_code": "@Nullable\r\n  public int[] getForecastTimeIntervalOffset(Grib2Record gr) {\r\n    TimeCoordIntvDateValue tinvd = getForecastTimeInterval(gr);\r\n    if (tinvd == null) return null;\r\n\r\n    Grib2Pds pds = gr.getPDS();\r\n    int unit = convertTimeUnit(pds.getTimeUnit());\r\n    TimeCoordIntvValue tinv = tinvd.convertReferenceDate(gr.getReferenceDate(), Grib2Utils.getCalendarPeriod(unit));\r\n    if (tinv == null) return null;\r\n    int[] result = new int[2];\r\n    result[0] = tinv.getBounds1();\r\n    result[1] = tinv.getBounds2();\r\n    return result;\r\n  }",
        "modified_code": "@Nullable\r\n  public int[] getForecastTimeIntervalOffset(Grib2Record gr) {\r\n    TimeCoordIntvDateValue yjnvd = getForecastTimeInterval(gr);\r\n    if (yjnvd == null) return null;\r\n\r\n    Grib2Pds pds = gr.getPDS();\r\n    int unit = convertTimeUnit(pds.getTimeUnit());\r\n    TimeCoordIntvValue tinv = yjnvd.convertReferenceDate(gr.getReferenceDate(), Grib2Utils.getCalendarPeriod(unit));\r\n    if (tinv == null) return null;\r\n    int[] result = new int[2];\r\n    result[0] = tinv.getBounds1();\r\n    result[1] = tinv.getBounds2();\r\n    return result;\r\n  }",
        "explanations_by_ours": [
            "TimeCoordIntvDateValue",
            "TimeCoordIntvValue",
            "TimeCoordIntvDateValue instance"
        ],
        "corrections_by_ours": [
            "coord",
            "tv",
            "instance",
            "time",
            "date",
            "value"
        ],
        "corrections_by_baseline": [
            "JD",
            "dv",
            "dz",
            "vz",
            "dv1",
            "rj",
            "uvz",
            "svd",
            "jdrct",
            "jbeg"
        ]
    },
    {
        "original_word": "Pattern",
        "typo_word": "Pattrgn",
        "original_variable": "filesPattern",
        "typo_variable": "filesPattrgn",
        "original_code": "@Override\r\n\tpublic void config(Config config) throws ConfigException, IOException {\r\n\t\tfor (Config repositorySection : config.findChildren(\"repository\")) {\r\n\t\t\t// view manager configuration section is named <views>\r\n\t\t\t// a <views> configuration section has one or many <repository> child sections\r\n\t\t\t// scan every repository files accordingly files pattern and add meta views to views meta pool\r\n\r\n\t\t\t// load repository view implementation class and perform insanity checks\r\n\t\t\tString className = repositorySection.getAttribute(\"class\", DEF_IMPLEMENTATION);\r\n\t\t\tClass<?> implementation = Classes.forOptionalName(className);\r\n\t\t\tif (implementation == null) {\r\n\t\t\t\tthrow new ConfigException(\"Unable to load view implementation |%s|.\", className);\r\n\t\t\t}\r\n\t\t\tif (!Types.isKindOf(implementation, View.class)) {\r\n\t\t\t\tthrow new ConfigException(\"View implementation |%s| is not of proper type.\", className);\r\n\t\t\t}\r\n\t\t\tif (!Classes.isInstantiable(implementation)) {\r\n\t\t\t\tthrow new ConfigException(\"View implementation |%s| is not instantiable. Ensure is not abstract or interface and have default constructor.\", implementation);\r\n\t\t\t}\r\n\t\t\t@SuppressWarnings(\"unchecked\")\r\n\t\t\tClass<? extends View> viewImplementation = (Class<? extends View>) implementation;\r\n\r\n\t\t\t// load repository path and files pattern and create I18N repository instance\r\n\t\t\tString repositoryPath = repositorySection.getAttribute(\"path\");\r\n\t\t\tif (repositoryPath == null) {\r\n\t\t\t\tthrow new ConfigException(\"Invalid views repository configuration. Missing <path> attribute.\");\r\n\t\t\t}\r\n\t\t\tString filesPattern = repositorySection.getAttribute(\"files-pattern\");\r\n\t\t\tif (filesPattern == null) {\r\n\t\t\t\tthrow new ConfigException(\"Invalid views repository configuration. Missing <files-pattern> attribute.\");\r\n\t\t\t}\r\n\r\n\t\t\tConfigBuilder builder = new I18nRepository.ConfigBuilder(repositoryPath, filesPattern);\r\n\t\t\tI18nRepository repository = new I18nRepository(builder.build());\r\n\t\t\tif (viewsMetaPool == null) {\r\n\t\t\t\t// uses first repository to initialize i18n pool\r\n\t\t\t\t// limitation for this solution is that all repositories should be the kind: locale sensitive or not\r\n\t\t\t\tviewsMetaPool = repository.getPoolInstance();\r\n\t\t\t}\r\n\t\t\tProperties properties = repositorySection.getProperties();\r\n\r\n\t\t\t// traverses all files from I18N repository instance and register view meta instance\r\n\t\t\t// builder is used by view meta to load the document template\r\n\t\t\tfor (I18nFile template : repository) {\r\n\t\t\t\tViewMeta meta = new ViewMeta(template.getFile(), viewImplementation, properties);\r\n\t\t\t\tif (viewsMetaPool.put(meta.getName(), meta, template.getLocale())) {\r\n\t\t\t\t\tlog.warn(\"Override view |%s|\", meta);\r\n\t\t\t\t} else {\r\n\t\t\t\t\tlog.debug(\"Register view |%s|\", meta);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}",
        "modified_code": "@Override\r\n\tpublic void config(Config config) throws ConfigException, IOException {\r\n\t\tfor (Config repositorySection : config.findChildren(\"repository\")) {\r\n\t\t\t// view manager configuration section is named <views>\r\n\t\t\t// a <views> configuration section has one or many <repository> child sections\r\n\t\t\t// scan every repository files accordingly files pattern and add meta views to views meta pool\r\n\r\n\t\t\t// load repository view implementation class and perform insanity checks\r\n\t\t\tString className = repositorySection.getAttribute(\"class\", DEF_IMPLEMENTATION);\r\n\t\t\tClass<?> implementation = Classes.forOptionalName(className);\r\n\t\t\tif (implementation == null) {\r\n\t\t\t\tthrow new ConfigException(\"Unable to load view implementation |%s|.\", className);\r\n\t\t\t}\r\n\t\t\tif (!Types.isKindOf(implementation, View.class)) {\r\n\t\t\t\tthrow new ConfigException(\"View implementation |%s| is not of proper type.\", className);\r\n\t\t\t}\r\n\t\t\tif (!Classes.isInstantiable(implementation)) {\r\n\t\t\t\tthrow new ConfigException(\"View implementation |%s| is not instantiable. Ensure is not abstract or interface and have default constructor.\", implementation);\r\n\t\t\t}\r\n\t\t\t@SuppressWarnings(\"unchecked\")\r\n\t\t\tClass<? extends View> viewImplementation = (Class<? extends View>) implementation;\r\n\r\n\t\t\t// load repository path and files pattern and create I18N repository instance\r\n\t\t\tString repositoryPath = repositorySection.getAttribute(\"path\");\r\n\t\t\tif (repositoryPath == null) {\r\n\t\t\t\tthrow new ConfigException(\"Invalid views repository configuration. Missing <path> attribute.\");\r\n\t\t\t}\r\n\t\t\tString filesPattrgn = repositorySection.getAttribute(\"files-pattern\");\r\n\t\t\tif (filesPattrgn == null) {\r\n\t\t\t\tthrow new ConfigException(\"Invalid views repository configuration. Missing <files-pattern> attribute.\");\r\n\t\t\t}\r\n\r\n\t\t\tConfigBuilder builder = new I18nRepository.ConfigBuilder(repositoryPath, filesPattrgn);\r\n\t\t\tI18nRepository repository = new I18nRepository(builder.build());\r\n\t\t\tif (viewsMetaPool == null) {\r\n\t\t\t\t// uses first repository to initialize i18n pool\r\n\t\t\t\t// limitation for this solution is that all repositories should be the kind: locale sensitive or not\r\n\t\t\t\tviewsMetaPool = repository.getPoolInstance();\r\n\t\t\t}\r\n\t\t\tProperties properties = repositorySection.getProperties();\r\n\r\n\t\t\t// traverses all files from I18N repository instance and register view meta instance\r\n\t\t\t// builder is used by view meta to load the document template\r\n\t\t\tfor (I18nFile template : repository) {\r\n\t\t\t\tViewMeta meta = new ViewMeta(template.getFile(), viewImplementation, properties);\r\n\t\t\t\tif (viewsMetaPool.put(meta.getName(), meta, template.getLocale())) {\r\n\t\t\t\t\tlog.warn(\"Override view |%s|\", meta);\r\n\t\t\t\t} else {\r\n\t\t\t\t\tlog.debug(\"Register view |%s|\", meta);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "The name of the files pattern.",
            "the name of the files pattern."
        ],
        "corrections_by_ours": [
            "filesPatternrgn",
            "filesNamergn",
            "namePattrgn",
            "patternPattrgn",
            "filesPattpattern",
            "filesFilesrgn",
            "filesPattfiles",
            "filesPattname",
            "filesPattrgn"
        ],
        "corrections_by_baseline": [
            "gcmfiles",
            "remoteExtDictFiles",
            "ncfile",
            "extDictFiles",
            "catfile",
            "propFile",
            "stnFile",
            "fileRef",
            "apFile",
            "catFilename"
        ]
    },
    {
        "original_word": "element",
        "typo_word": "eldmenr",
        "original_variable": "element",
        "typo_variable": "eldmenr",
        "original_code": "private void parseImplicitTld(JspCompilationContext ctxt, String path)\n            throws JasperException {\n\n        InputStream is = null;\n        TreeNode tld = null;\n\n        try {\n            URL uri = ctxt.getResource(path);\n            if (uri == null) {\n                // no implicit.tld\n                return;\n            }\n\n            is = uri.openStream();\n            /* SJSAS 6384538\n            tld = new ParserUtils().parseXMLDocument(IMPLICIT_TLD, is);\n            */\n            // START SJSAS 6384538\n            tld = new ParserUtils().parseXMLDocument(\n                IMPLICIT_TLD, is, ctxt.getOptions().isValidationEnabled());\n            // END SJSAS 6384538\n        } catch (Exception ex) {\n            throw new JasperException(ex);\n        } finally {\n            if (is != null) {\n                try {\n                    is.close();\n                } catch (Throwable t) {}\n            }\n        }\n\n        this.jspversion = tld.findAttribute(\"version\");\n\n        Iterator list = tld.findChildren();\n        while (list.hasNext()) {\n            TreeNode element = (TreeNode) list.next();\n            String tname = element.getName();\n            if (\"tlibversion\".equals(tname)\n                    || \"tlib-version\".equals(tname)) {\n                this.tlibversion = element.getBody();\n            } else if (\"jspversion\".equals(tname)\n                    || \"jsp-version\".equals(tname)) {\n                this.jspversion = element.getBody();\n            } else if (!\"shortname\".equals(tname)\n                    && !\"short-name\".equals(tname)) {\n                err.jspError(\"jsp.error.implicitTld.additionalElements\",\n                             path, tname);\n            }\n        }\n\n        // JSP version in implicit.tld must be 2.0 or greater\n        Double jspVersionDouble = Double.valueOf(this.jspversion);\n        if (Double.compare(jspVersionDouble, Constants.JSP_VERSION_2_0) < 0) {\n            err.jspError(\"jsp.error.implicitTld.jspVersion\", path,\n                         this.jspversion);\n        }\n    }",
        "modified_code": "private void parseImplicitTld(JspCompilationContext ctxt, String path)\n            throws JasperException {\n\n        InputStream is = null;\n        TreeNode tld = null;\n\n        try {\n            URL uri = ctxt.getResource(path);\n            if (uri == null) {\n                // no implicit.tld\n                return;\n            }\n\n            is = uri.openStream();\n            /* SJSAS 6384538\n            tld = new ParserUtils().parseXMLDocument(IMPLICIT_TLD, is);\n            */\n            // START SJSAS 6384538\n            tld = new ParserUtils().parseXMLDocument(\n                IMPLICIT_TLD, is, ctxt.getOptions().isValidationEnabled());\n            // END SJSAS 6384538\n        } catch (Exception ex) {\n            throw new JasperException(ex);\n        } finally {\n            if (is != null) {\n                try {\n                    is.close();\n                } catch (Throwable t) {}\n            }\n        }\n\n        this.jspversion = tld.findAttribute(\"version\");\n\n        Iterator list = tld.findChildren();\n        while (list.hasNext()) {\n            TreeNode eldmenr = (TreeNode) list.next();\n            String tname = eldmenr.getName();\n            if (\"tlibversion\".equals(tname)\n                    || \"tlib-version\".equals(tname)) {\n                this.tlibversion = eldmenr.getBody();\n            } else if (\"jspversion\".equals(tname)\n                    || \"jsp-version\".equals(tname)) {\n                this.jspversion = eldmenr.getBody();\n            } else if (!\"shortname\".equals(tname)\n                    && !\"short-name\".equals(tname)) {\n                err.jspError(\"jsp.error.implicitTld.additionalElements\",\n                             path, tname);\n            }\n        }\n\n        // JSP version in implicit.tld must be 2.0 or greater\n        Double jspVersionDouble = Double.valueOf(this.jspversion);\n        if (Double.compare(jspVersionDouble, Constants.JSP_VERSION_2_0) < 0) {\n            err.jspError(\"jsp.error.implicitTld.jspVersion\", path,\n                         this.jspversion);\n        }\n    }",
        "explanations_by_ours": [
            "the root node of the implicit.tld file",
            "the root node of the implicit.tld",
            "the root element of the implicit.tld file"
        ],
        "corrections_by_ours": [
            "element",
            "tld",
            "node",
            "file",
            "implicit",
            "root"
        ],
        "corrections_by_baseline": [
            "dmr",
            "drElem",
            "dr",
            "jdrct",
            "rdr",
            "lm",
            "rj",
            "stopper",
            "dellen",
            "hrs"
        ]
    },
    {
        "original_word": "enumt",
        "typo_word": "emumf",
        "original_variable": "enumt",
        "typo_variable": "emumf",
        "original_code": "public String resolvePublic(String publicId, String systemId) \n    throws MalformedURLException, IOException {\n\n    String resolved = super.resolvePublic(publicId, systemId);\n    if (resolved != null) {\n      return resolved;\n    }\n\n    Enumeration enumt = catalogEntries.elements();\n    while (enumt.hasMoreElements()) {\n      CatalogEntry e = (CatalogEntry) enumt.nextElement();\n      if (e.getEntryType() == RESOLVER) {\n\tif (systemId != null) {\n\t  resolved = resolveExternalSystem(systemId,\n\t\t\t\t\t   e.getEntryArg(0));\n\t  if (resolved != null) {\n\t    return resolved;\n\t  }\n\t}\n\tresolved = resolveExternalPublic(publicId, e.getEntryArg(0));\n\tif (resolved != null) {\n\t  return resolved;\n\t}\n      }\n    }\n\n    return resolveSubordinateCatalogs(Catalog.PUBLIC,\n\t\t\t\t      null,\n\t\t\t\t      publicId,\n\t\t\t\t      systemId);\n  }",
        "modified_code": "public String resolvePublic(String publicId, String systemId) \n    throws MalformedURLException, IOException {\n\n    String resolved = super.resolvePublic(publicId, systemId);\n    if (resolved != null) {\n      return resolved;\n    }\n\n    Enumeration emumf = catalogEntries.elements();\n    while (emumf.hasMoreElements()) {\n      CatalogEntry e = (CatalogEntry) emumf.nextElement();\n      if (e.getEntryType() == RESOLVER) {\n\tif (systemId != null) {\n\t  resolved = resolveExternalSystem(systemId,\n\t\t\t\t\t   e.getEntryArg(0));\n\t  if (resolved != null) {\n\t    return resolved;\n\t  }\n\t}\n\tresolved = resolveExternalPublic(publicId, e.getEntryArg(0));\n\tif (resolved != null) {\n\t  return resolved;\n\t}\n      }\n    }\n\n    return resolveSubordinateCatalogs(Catalog.PUBLIC,\n\t\t\t\t      null,\n\t\t\t\t      publicId,\n\t\t\t\t      systemId);\n  }",
        "explanations_by_ours": [
            "The catalog entries.",
            "The external catalog entries.",
            "The emumf entries."
        ],
        "corrections_by_ours": [
            "entries",
            "external",
            "catalog"
        ],
        "corrections_by_baseline": [
            "emf",
            "mefd",
            "hf",
            "mf",
            "F",
            "f",
            "etf",
            "ecef",
            "icf",
            "emsg"
        ]
    },
    {
        "original_word": "first",
        "typo_word": "cirdt",
        "original_variable": "first",
        "typo_variable": "cirdt",
        "original_code": "public HttpRequest cookies(final Cookie... cookies) {\n\t\tif (cookies.length == 0) {\n\t\t\treturn this;\n\t\t}\n\n\t\tStringBuilder cookieString = new StringBuilder();\n\n\t\tboolean first = true;\n\n\t\tfor (Cookie cookie : cookies) {\n\t\t\tInteger maxAge = cookie.getMaxAge();\n\t\t\tif (maxAge != null && maxAge.intValue() == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!first) {\n\t\t\t\tcookieString.append(\"; \");\n\t\t\t}\n\n\t\t\tfirst = false;\n\t\t\tcookieString.append(cookie.getName());\n\t\t\tcookieString.append('=');\n\t\t\tcookieString.append(cookie.getValue());\n\t\t}\n\n\t\theaderOverwrite(\"cookie\", cookieString.toString());\n\n\t\treturn this;\n\t}",
        "modified_code": "public HttpRequest cookies(final Cookie... cookies) {\n\t\tif (cookies.length == 0) {\n\t\t\treturn this;\n\t\t}\n\n\t\tStringBuilder cookieString = new StringBuilder();\n\n\t\tboolean cirdt = true;\n\n\t\tfor (Cookie cookie : cookies) {\n\t\t\tInteger maxAge = cookie.getMaxAge();\n\t\t\tif (maxAge != null && maxAge.intValue() == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!cirdt) {\n\t\t\t\tcookieString.append(\"; \");\n\t\t\t}\n\n\t\t\tcirdt = false;\n\t\t\tcookieString.append(cookie.getName());\n\t\t\tcookieString.append('=');\n\t\t\tcookieString.append(cookie.getValue());\n\t\t}\n\n\t\theaderOverwrite(\"cookie\", cookieString.toString());\n\n\t\treturn this;\n\t}",
        "explanations_by_ours": [
            "if true, the cookie will be added in the same order as the",
            "if true, the cookie will be added with a comma separated list of",
            "if true, the cookie will be added as a single cookie. If"
        ],
        "corrections_by_ours": [
            "list",
            "separated",
            "order",
            "comma",
            "single",
            "cookie",
            "true,",
            "added"
        ],
        "corrections_by_baseline": [
            "t_huff",
            "liof",
            "cir",
            "dou",
            "ybeg",
            "t_E_temp",
            "determinant",
            "f_huff",
            "coldp",
            "wierd"
        ]
    },
    {
        "original_word": "height",
        "typo_word": "beigtt",
        "original_variable": "height",
        "typo_variable": "beigtt",
        "original_code": "public D1 getCoordinateArray1D(int timeIndex, int xIndex, int yIndex)\r\n\t\t  throws IOException, InvalidRangeException {\r\n\r\n\t  Array eta = readArray(etaVar, timeIndex);\r\n\t  Array sigma = readArray(sVar, timeIndex);\r\n\t  Array depth = readArray(depthVar, timeIndex);\r\n\r\n\t  int nz = (int) sigma.getSize();\r\n\t  Index sIndex = sigma.getIndex();\r\n\r\n\t  Index etaIndex = eta.getIndex();\r\n\t  Index depthIndex = depth.getIndex();\r\n\r\n\t  ArrayDouble.D1 height = new ArrayDouble.D1(nz);\r\n\r\n\t  for (int z = 0; z < nz; z++) {\r\n\t\t  double sigmaVal = sigma.getDouble(sIndex.set(z));\r\n\r\n\t\t  double etaVal = eta.getDouble(etaIndex.set(yIndex, xIndex));\r\n\t\t  double depthVal = depth.getDouble(depthIndex.set(yIndex, xIndex));\r\n\r\n\t\t  height.set(z, etaVal + sigmaVal * (depthVal + etaVal));\r\n\t  }\r\n\r\n\t  return height;\r\n  }",
        "modified_code": "public D1 getCoordinateArray1D(int timeIndex, int xIndex, int yIndex)\r\n\t\t  throws IOException, InvalidRangeException {\r\n\r\n\t  Array eta = readArray(etaVar, timeIndex);\r\n\t  Array sigma = readArray(sVar, timeIndex);\r\n\t  Array depth = readArray(depthVar, timeIndex);\r\n\r\n\t  int nz = (int) sigma.getSize();\r\n\t  Index sIndex = sigma.getIndex();\r\n\r\n\t  Index etaIndex = eta.getIndex();\r\n\t  Index depthIndex = depth.getIndex();\r\n\r\n\t  ArrayDouble.D1 beigtt = new ArrayDouble.D1(nz);\r\n\r\n\t  for (int z = 0; z < nz; z++) {\r\n\t\t  double sigmaVal = sigma.getDouble(sIndex.set(z));\r\n\r\n\t\t  double etaVal = eta.getDouble(etaIndex.set(yIndex, xIndex));\r\n\t\t  double depthVal = depth.getDouble(depthIndex.set(yIndex, xIndex));\r\n\r\n\t\t  beigtt.set(z, etaVal + sigmaVal * (depthVal + etaVal));\r\n\t  }\r\n\r\n\t  return beigtt;\r\n  }",
        "explanations_by_ours": [
            "coordinate array",
            "the coordinate array",
            "the beigtt array"
        ],
        "corrections_by_ours": [
            "coordinate",
            "array"
        ],
        "corrections_by_baseline": [
            "ybeg",
            "xbeg",
            "battery",
            "ibeg",
            "boff",
            "bern",
            "stg",
            "ggr",
            "toke",
            "lpphi"
        ]
    },
    {
        "original_word": "chars",
        "typo_word": "chsrx",
        "original_variable": "chars",
        "typo_variable": "chsrx",
        "original_code": "public static String decode(byte[] input, int off, int len)\n\t{\n\t\tCharsetDecoder decoder = Charsets.US_ASCII.newDecoder();\n\t\tByteBuffer buf = ByteBuffer.wrap(input, off, len);\n\t\ttry {\n\t\t\tCharBuffer out = decoder.decode(buf);\n\t\t\tchar[] chars = new char[out.limit()];\n\t\t\tout.get(chars);\n\t\t\treturn new String(chars);\n\t\t} catch (CharacterCodingException ex) {\n\t\t\tthrow new IllegalArgumentException(ex);\n\t\t}\n\t}",
        "modified_code": "public static String decode(byte[] input, int off, int len)\n\t{\n\t\tCharsetDecoder decoder = Charsets.US_ASCII.newDecoder();\n\t\tByteBuffer buf = ByteBuffer.wrap(input, off, len);\n\t\ttry {\n\t\t\tCharBuffer out = decoder.decode(buf);\n\t\t\tchar[] chsrx = new char[out.limit()];\n\t\t\tout.get(chsrx);\n\t\t\treturn new String(chsrx);\n\t\t} catch (CharacterCodingException ex) {\n\t\t\tthrow new IllegalArgumentException(ex);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the char array to decode into a String",
            "the char array to decode into a string",
            "the char array to decode"
        ],
        "corrections_by_ours": [
            "char",
            "string",
            "array",
            "decode"
        ],
        "corrections_by_baseline": [
            "jsword",
            "srclen",
            "srcc",
            "xh",
            "sr",
            "hrsi",
            "mss",
            "xpp",
            "xcolor",
            "macroChars"
        ]
    },
    {
        "original_word": "shared",
        "typo_word": "sjarsd",
        "original_variable": "shared",
        "typo_variable": "sjarsd",
        "original_code": "private void createSampleData(String username, String password) {\n\t\tAssert.notNull(documentDao, \"DocumentDao required\");\n\t\tAssert.hasText(username, \"Username required\");\n\n\t\tAuthentication auth = new UsernamePasswordAuthenticationToken(username, password);\n\n\t\ttry {\n\t\t\t// Set the SecurityContextHolder ThreadLocal so any subclasses\n\t\t\t// automatically know which user is operating\n\t\t\tSecurityContextHolder.getContext().setAuthentication(auth);\n\n\t\t\t// Create the home directory first\n\t\t\tDirectory home = new Directory(username, Directory.ROOT_DIRECTORY);\n\t\t\tdocumentDao.create(home);\n\t\t\taddPermission(documentDao, home, username, LEVEL_GRANT_ADMIN);\n\t\t\taddPermission(documentDao, home, \"ROLE_USER\", LEVEL_GRANT_READ);\n\t\t\tcreateFiles(documentDao, home);\n\n\t\t\t// Now create the confidential directory\n\t\t\tDirectory confid = new Directory(\"confidential\", home);\n\t\t\tdocumentDao.create(confid);\n\t\t\taddPermission(documentDao, confid, \"ROLE_USER\", LEVEL_NEGATE_READ);\n\t\t\tcreateFiles(documentDao, confid);\n\n\t\t\t// Now create the shared directory\n\t\t\tDirectory shared = new Directory(\"shared\", home);\n\t\t\tdocumentDao.create(shared);\n\t\t\taddPermission(documentDao, shared, \"ROLE_USER\", LEVEL_GRANT_READ);\n\t\t\taddPermission(documentDao, shared, \"ROLE_USER\", LEVEL_GRANT_WRITE);\n\t\t\tcreateFiles(documentDao, shared);\n\t\t}\n\t\tfinally {\n\t\t\t// Clear the SecurityContextHolder ThreadLocal so future calls are\n\t\t\t// guaranteed to be clean\n\t\t\tSecurityContextHolder.clearContext();\n\t\t}\n\t}",
        "modified_code": "private void createSampleData(String username, String password) {\n\t\tAssert.notNull(documentDao, \"DocumentDao required\");\n\t\tAssert.hasText(username, \"Username required\");\n\n\t\tAuthentication auth = new UsernamePasswordAuthenticationToken(username, password);\n\n\t\ttry {\n\t\t\t// Set the SecurityContextHolder ThreadLocal so any subclasses\n\t\t\t// automatically know which user is operating\n\t\t\tSecurityContextHolder.getContext().setAuthentication(auth);\n\n\t\t\t// Create the home directory first\n\t\t\tDirectory home = new Directory(username, Directory.ROOT_DIRECTORY);\n\t\t\tdocumentDao.create(home);\n\t\t\taddPermission(documentDao, home, username, LEVEL_GRANT_ADMIN);\n\t\t\taddPermission(documentDao, home, \"ROLE_USER\", LEVEL_GRANT_READ);\n\t\t\tcreateFiles(documentDao, home);\n\n\t\t\t// Now create the confidential directory\n\t\t\tDirectory confid = new Directory(\"confidential\", home);\n\t\t\tdocumentDao.create(confid);\n\t\t\taddPermission(documentDao, confid, \"ROLE_USER\", LEVEL_NEGATE_READ);\n\t\t\tcreateFiles(documentDao, confid);\n\n\t\t\t// Now create the shared directory\n\t\t\tDirectory sjarsd = new Directory(\"shared\", home);\n\t\t\tdocumentDao.create(sjarsd);\n\t\t\taddPermission(documentDao, sjarsd, \"ROLE_USER\", LEVEL_GRANT_READ);\n\t\t\taddPermission(documentDao, sjarsd, \"ROLE_USER\", LEVEL_GRANT_WRITE);\n\t\t\tcreateFiles(documentDao, sjarsd);\n\t\t}\n\t\tfinally {\n\t\t\t// Clear the SecurityContextHolder ThreadLocal so future calls are\n\t\t\t// guaranteed to be clean\n\t\t\tSecurityContextHolder.clearContext();\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the sjarsd",
            "the sjarsd",
            "the sjarsd directory"
        ],
        "corrections_by_ours": [
            "directory"
        ],
        "corrections_by_baseline": [
            "jexl",
            "jars",
            "pdss",
            "log4j",
            "d4ds",
            "pd",
            "pds",
            "ncmlc",
            "dcs",
            "dsrc"
        ]
    },
    {
        "original_word": "inner",
        "typo_word": "lnger",
        "original_variable": "inner",
        "typo_variable": "lnger",
        "original_code": "public static double triangle( Point2D_F64 a, Point2D_F64 b, Point2D_F64  c ) {\n\t\tdouble inner = a.x*(b.y - c.y) + b.x*(c.y - a.y) + c.x*(a.y - b.y);\n\n\t\treturn Math.abs(inner/2.0);\n\t}",
        "modified_code": "public static double triangle( Point2D_F64 a, Point2D_F64 b, Point2D_F64  c ) {\n\t\tdouble lnger = a.x*(b.y - c.y) + b.x*(c.y - a.y) + c.x*(a.y - b.y);\n\n\t\treturn Math.abs(lnger/2.0);\n\t}",
        "explanations_by_ours": [
            "The distance from the first point to the second point.",
            "The lnger of the triangle.",
            "The lnger of the two points."
        ],
        "corrections_by_ours": [
            "pointger",
            "lnfirst",
            "pointsger",
            "secondger",
            "lnsecond",
            "triangleger",
            "distanceger",
            "lntriangle",
            "firstger",
            "gerger"
        ],
        "corrections_by_baseline": [
            "lngain",
            "lxcent",
            "lac",
            "rngy",
            "lons",
            "lont",
            "lh",
            "lats",
            "glon",
            "L"
        ]
    },
    {
        "original_word": "rounded",
        "typo_word": "roujdrd",
        "original_variable": "roundedEnd",
        "typo_variable": "roujdrdEnd",
        "original_code": "public static HashValue murmurhash3_x64_128(final byte[] key, final int offset, final int len, final int seed) {\n\t\t// The original algorithm does have a 32 bit unsigned seed.\n\t\t// We have to mask to match the behavior of the unsigned types and prevent sign extension.\n\t\tlong h1 = seed & 0x00000000FFFFFFFFL;\n\t\tlong h2 = seed & 0x00000000FFFFFFFFL;\n\n\t\tfinal long c1 = 0x87c37b91114253d5L;\n\t\tfinal long c2 = 0x4cf5ad432745937fL;\n\n\t\tint roundedEnd = offset + (len & 0xFFFFFFF0);  // round down to 16 byte block\n\t\tfor (int i = offset; i < roundedEnd; i += 16) {\n\t\t\tlong k1 = getLongLittleEndian(key, i);\n\t\t\tlong k2 = getLongLittleEndian(key, i + 8);\n\t\t\tk1 *= c1;\n\t\t\tk1 = Long.rotateLeft(k1, 31);\n\t\t\tk1 *= c2;\n\t\t\th1 ^= k1;\n\t\t\th1 = Long.rotateLeft(h1, 27);\n\t\t\th1 += h2;\n\t\t\th1 = h1 * 5 + 0x52dce729;\n\t\t\tk2 *= c2;\n\t\t\tk2 = Long.rotateLeft(k2, 33);\n\t\t\tk2 *= c1;\n\t\t\th2 ^= k2;\n\t\t\th2 = Long.rotateLeft(h2, 31);\n\t\t\th2 += h1;\n\t\t\th2 = h2 * 5 + 0x38495ab5;\n\t\t}\n\n\t\tlong k1 = 0;\n\t\tlong k2 = 0;\n\n\t\tswitch (len & 15) {\n\t\t\tcase 15:\n\t\t\t\tk2 = (key[roundedEnd + 14] & 0xffL) << 48;\n\t\t\tcase 14:\n\t\t\t\tk2 |= (key[roundedEnd + 13] & 0xffL) << 40;\n\t\t\tcase 13:\n\t\t\t\tk2 |= (key[roundedEnd + 12] & 0xffL) << 32;\n\t\t\tcase 12:\n\t\t\t\tk2 |= (key[roundedEnd + 11] & 0xffL) << 24;\n\t\t\tcase 11:\n\t\t\t\tk2 |= (key[roundedEnd + 10] & 0xffL) << 16;\n\t\t\tcase 10:\n\t\t\t\tk2 |= (key[roundedEnd + 9] & 0xffL) << 8;\n\t\t\tcase 9:\n\t\t\t\tk2 |= (key[roundedEnd + 8] & 0xffL);\n\t\t\t\tk2 *= c2;\n\t\t\t\tk2 = Long.rotateLeft(k2, 33);\n\t\t\t\tk2 *= c1;\n\t\t\t\th2 ^= k2;\n\t\t\tcase 8:\n\t\t\t\tk1 = ((long) key[roundedEnd + 7]) << 56;\n\t\t\tcase 7:\n\t\t\t\tk1 |= (key[roundedEnd + 6] & 0xffL) << 48;\n\t\t\tcase 6:\n\t\t\t\tk1 |= (key[roundedEnd + 5] & 0xffL) << 40;\n\t\t\tcase 5:\n\t\t\t\tk1 |= (key[roundedEnd + 4] & 0xffL) << 32;\n\t\t\tcase 4:\n\t\t\t\tk1 |= (key[roundedEnd + 3] & 0xffL) << 24;\n\t\t\tcase 3:\n\t\t\t\tk1 |= (key[roundedEnd + 2] & 0xffL) << 16;\n\t\t\tcase 2:\n\t\t\t\tk1 |= (key[roundedEnd + 1] & 0xffL) << 8;\n\t\t\tcase 1:\n\t\t\t\tk1 |= (key[roundedEnd] & 0xffL);\n\t\t\t\tk1 *= c1;\n\t\t\t\tk1 = Long.rotateLeft(k1, 31);\n\t\t\t\tk1 *= c2;\n\t\t\t\th1 ^= k1;\n\t\t}\n\n\t\t//----------\n\t\t// finalization\n\n\t\th1 ^= len;\n\t\th2 ^= len;\n\n\t\th1 += h2;\n\t\th2 += h1;\n\n\t\th1 = fmix64(h1);\n\t\th2 = fmix64(h2);\n\n\t\th1 += h2;\n\t\th2 += h1;\n\n\t\treturn new HashValue(h1, h2);\n\t}",
        "modified_code": "public static HashValue murmurhash3_x64_128(final byte[] key, final int offset, final int len, final int seed) {\n\t\t// The original algorithm does have a 32 bit unsigned seed.\n\t\t// We have to mask to match the behavior of the unsigned types and prevent sign extension.\n\t\tlong h1 = seed & 0x00000000FFFFFFFFL;\n\t\tlong h2 = seed & 0x00000000FFFFFFFFL;\n\n\t\tfinal long c1 = 0x87c37b91114253d5L;\n\t\tfinal long c2 = 0x4cf5ad432745937fL;\n\n\t\tint roujdrdEnd = offset + (len & 0xFFFFFFF0);  // round down to 16 byte block\n\t\tfor (int i = offset; i < roujdrdEnd; i += 16) {\n\t\t\tlong k1 = getLongLittleEndian(key, i);\n\t\t\tlong k2 = getLongLittleEndian(key, i + 8);\n\t\t\tk1 *= c1;\n\t\t\tk1 = Long.rotateLeft(k1, 31);\n\t\t\tk1 *= c2;\n\t\t\th1 ^= k1;\n\t\t\th1 = Long.rotateLeft(h1, 27);\n\t\t\th1 += h2;\n\t\t\th1 = h1 * 5 + 0x52dce729;\n\t\t\tk2 *= c2;\n\t\t\tk2 = Long.rotateLeft(k2, 33);\n\t\t\tk2 *= c1;\n\t\t\th2 ^= k2;\n\t\t\th2 = Long.rotateLeft(h2, 31);\n\t\t\th2 += h1;\n\t\t\th2 = h2 * 5 + 0x38495ab5;\n\t\t}\n\n\t\tlong k1 = 0;\n\t\tlong k2 = 0;\n\n\t\tswitch (len & 15) {\n\t\t\tcase 15:\n\t\t\t\tk2 = (key[roujdrdEnd + 14] & 0xffL) << 48;\n\t\t\tcase 14:\n\t\t\t\tk2 |= (key[roujdrdEnd + 13] & 0xffL) << 40;\n\t\t\tcase 13:\n\t\t\t\tk2 |= (key[roujdrdEnd + 12] & 0xffL) << 32;\n\t\t\tcase 12:\n\t\t\t\tk2 |= (key[roujdrdEnd + 11] & 0xffL) << 24;\n\t\t\tcase 11:\n\t\t\t\tk2 |= (key[roujdrdEnd + 10] & 0xffL) << 16;\n\t\t\tcase 10:\n\t\t\t\tk2 |= (key[roujdrdEnd + 9] & 0xffL) << 8;\n\t\t\tcase 9:\n\t\t\t\tk2 |= (key[roujdrdEnd + 8] & 0xffL);\n\t\t\t\tk2 *= c2;\n\t\t\t\tk2 = Long.rotateLeft(k2, 33);\n\t\t\t\tk2 *= c1;\n\t\t\t\th2 ^= k2;\n\t\t\tcase 8:\n\t\t\t\tk1 = ((long) key[roujdrdEnd + 7]) << 56;\n\t\t\tcase 7:\n\t\t\t\tk1 |= (key[roujdrdEnd + 6] & 0xffL) << 48;\n\t\t\tcase 6:\n\t\t\t\tk1 |= (key[roujdrdEnd + 5] & 0xffL) << 40;\n\t\t\tcase 5:\n\t\t\t\tk1 |= (key[roujdrdEnd + 4] & 0xffL) << 32;\n\t\t\tcase 4:\n\t\t\t\tk1 |= (key[roujdrdEnd + 3] & 0xffL) << 24;\n\t\t\tcase 3:\n\t\t\t\tk1 |= (key[roujdrdEnd + 2] & 0xffL) << 16;\n\t\t\tcase 2:\n\t\t\t\tk1 |= (key[roujdrdEnd + 1] & 0xffL) << 8;\n\t\t\tcase 1:\n\t\t\t\tk1 |= (key[roujdrdEnd] & 0xffL);\n\t\t\t\tk1 *= c1;\n\t\t\t\tk1 = Long.rotateLeft(k1, 31);\n\t\t\t\tk1 *= c2;\n\t\t\t\th1 ^= k1;\n\t\t}\n\n\t\t//----------\n\t\t// finalization\n\n\t\th1 ^= len;\n\t\th2 ^= len;\n\n\t\th1 += h2;\n\t\th2 += h1;\n\n\t\th1 = fmix64(h1);\n\t\th2 = fmix64(h2);\n\n\t\th1 += h2;\n\t\th2 += h1;\n\n\t\treturn new HashValue(h1, h2);\n\t}",
        "explanations_by_ours": [
            "the end of the roujdrd block",
            "the end of the roujdrd",
            "the roujdrd end"
        ],
        "corrections_by_ours": [
            "endEnd",
            "roujdrdRoujdrd",
            "blockEnd",
            "roujdrdBlock",
            "roujdrdEnd"
        ],
        "corrections_by_baseline": [
            "pncEnd",
            "endUR",
            "endp",
            "endOPath",
            "end2",
            "end1",
            "rdr",
            "prelen",
            "ipos_p2",
            "partDataEnd"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "cougg",
        "original_variable": "count",
        "typo_variable": "cougg",
        "original_code": "public int clearAlarms(NotificationSource notificationSource) throws NullPointerException, UnrecognizedNotificationSourceException, ManagementException {\r\n\t\tif (notificationSource == null) {\r\n\t\t\tthrow new NullPointerException(\"NotificationSource must not be null\");\r\n\t\t}\r\n\r\n\t\tmandateSource(notificationSource);\r\n\r\n\t\tint count = 0;\r\n\t\ttry {\r\n\r\n\t\t\tfor (Map.Entry<AlarmPlaceHolder, NotificationSource> e : placeHolderToNotificationSource.entrySet()) {\r\n\t\t\t\tif (e.getValue().equals(notificationSource)) {\r\n\t\t\t\t\tif (clearAlarm(e.getKey().getAlarm().getAlarmID())) {\r\n\t\t\t\t\t\tcount++;\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\r\n\t\t} catch (Exception e) {\r\n\t\t\tthrow new ManagementException(\"Failed to get alarm id list due to: \", e);\r\n\t\t}\r\n\r\n\t\treturn count;\r\n\t}",
        "modified_code": "public int clearAlarms(NotificationSource notificationSource) throws NullPointerException, UnrecognizedNotificationSourceException, ManagementException {\r\n\t\tif (notificationSource == null) {\r\n\t\t\tthrow new NullPointerException(\"NotificationSource must not be null\");\r\n\t\t}\r\n\r\n\t\tmandateSource(notificationSource);\r\n\r\n\t\tint cougg = 0;\r\n\t\ttry {\r\n\r\n\t\t\tfor (Map.Entry<AlarmPlaceHolder, NotificationSource> e : placeHolderToNotificationSource.entrySet()) {\r\n\t\t\t\tif (e.getValue().equals(notificationSource)) {\r\n\t\t\t\t\tif (clearAlarm(e.getKey().getAlarm().getAlarmID())) {\r\n\t\t\t\t\t\tcougg++;\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\r\n\t\t} catch (Exception e) {\r\n\t\t\tthrow new ManagementException(\"Failed to get alarm id list due to: \", e);\r\n\t\t}\r\n\r\n\t\treturn cougg;\r\n\t}",
        "explanations_by_ours": [
            "the number of alarms cleared",
            "the number of alarms to clear",
            "the number of alarms to be cleared"
        ],
        "corrections_by_ours": [
            "clear",
            "cleared",
            "alarms",
            "number"
        ],
        "corrections_by_baseline": [
            "cgaw",
            "gg",
            "coun",
            "caco",
            "caw",
            "cnc",
            "dou",
            "tgc",
            "ggr",
            "C"
        ]
    },
    {
        "original_word": "indices",
        "typo_word": "indodes",
        "original_variable": "indices",
        "typo_variable": "indodes",
        "original_code": "public static INDArrayIndex[] create(INDArray index) {\n\n        if (index.isMatrix()) {\n\n            if (index.rows() > Integer.MAX_VALUE)\n                throw new ND4JArraySizeException();\n\n            NDArrayIndex[] ret = new NDArrayIndex[(int) index.rows()];\n            for (int i = 0; i < index.rows(); i++) {\n                INDArray row = index.getRow(i);\n                val nums = new long[(int) index.getRow(i).columns()];\n                for (int j = 0; j < row.columns(); j++) {\n                    nums[j] = (int) row.getFloat(j);\n                }\n\n                NDArrayIndex idx = new NDArrayIndex(nums);\n                ret[i] = idx;\n\n            }\n\n\n            return ret;\n\n        } else if (index.isVector()) {\n            long[] indices = NDArrayUtil.toLongs(index);\n            return new NDArrayIndex[] {new NDArrayIndex(indices)};\n        }\n\n\n        throw new IllegalArgumentException(\"Passed in ndarray must be a matrix or a vector\");\n\n    }",
        "modified_code": "public static INDArrayIndex[] create(INDArray index) {\n\n        if (index.isMatrix()) {\n\n            if (index.rows() > Integer.MAX_VALUE)\n                throw new ND4JArraySizeException();\n\n            NDArrayIndex[] ret = new NDArrayIndex[(int) index.rows()];\n            for (int i = 0; i < index.rows(); i++) {\n                INDArray row = index.getRow(i);\n                val nums = new long[(int) index.getRow(i).columns()];\n                for (int j = 0; j < row.columns(); j++) {\n                    nums[j] = (int) row.getFloat(j);\n                }\n\n                NDArrayIndex idx = new NDArrayIndex(nums);\n                ret[i] = idx;\n\n            }\n\n\n            return ret;\n\n        } else if (index.isVector()) {\n            long[] indodes = NDArrayUtil.toLongs(index);\n            return new NDArrayIndex[] {new NDArrayIndex(indodes)};\n        }\n\n\n        throw new IllegalArgumentException(\"Passed in ndarray must be a matrix or a vector\");\n\n    }",
        "explanations_by_ours": [
            "the array of indices",
            "the indices to create",
            "the array of indices to create"
        ],
        "corrections_by_ours": [
            "indicesodes",
            "indindices",
            "indcreate",
            "arrayodes",
            "createodes",
            "indarray",
            "indodes"
        ],
        "corrections_by_baseline": [
            "indices",
            "nodes",
            "numNodes",
            "traversedNodes",
            "selectorNodes",
            "nodeIDs",
            "nodeCounts",
            "flatNodes",
            "nodesOffset",
            "geometryIndices"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reeulf",
        "original_variable": "result",
        "typo_variable": "reeulf",
        "original_code": "public String lookupEnumString(int e) {\n    String result = map.get(e);\n    return (result == null) ? \"Unknown enum value=\" + e : result;\n  }",
        "modified_code": "public String lookupEnumString(int e) {\n    String reeulf = map.get(e);\n    return (reeulf == null) ? \"Unknown enum value=\" + e : reeulf;\n  }",
        "explanations_by_ours": [
            "the string representation of the enum value for the given enum constant",
            "the string representation of the enum value",
            "the string representation of the enum value for the given enum constant."
        ],
        "corrections_by_ours": [
            "enum",
            "representation",
            "value",
            "string",
            "given",
            "constant"
        ],
        "corrections_by_baseline": [
            "raven",
            "iread",
            "leaves",
            "btree",
            "foreclosure",
            "cir",
            "chained",
            "munge",
            "af",
            "raf"
        ]
    },
    {
        "original_word": "alarms",
        "typo_word": "akarks",
        "original_variable": "alarms",
        "typo_variable": "akarks",
        "original_code": "public Alarm[] getDescriptors(String[] alarmIDs) throws NullPointerException, ManagementException {\r\n\t\tif (alarmIDs == null) {\r\n\t\t\tthrow new NullPointerException(\"AlarmID[] must not be null\");\r\n\t\t}\r\n\r\n\t\tSet<Alarm> alarms = new HashSet<Alarm>();\r\n\r\n\t\ttry {\r\n\t\t\tfor (String id : alarmIDs) {\r\n\t\t\t\tAlarm a = getDescriptor(id);\r\n\t\t\t\tif (a != null)\r\n\t\t\t\t\talarms.add(a);\r\n\t\t\t}\r\n\t\t\treturn alarms.toArray(new Alarm[alarms.size()]);\r\n\r\n\t\t} catch (Exception e) {\r\n\t\t\tthrow new ManagementException(\"Failed to get desciptors.\", e);\r\n\t\t}\r\n\t}",
        "modified_code": "public Alarm[] getDescriptors(String[] alarmIDs) throws NullPointerException, ManagementException {\r\n\t\tif (alarmIDs == null) {\r\n\t\t\tthrow new NullPointerException(\"AlarmID[] must not be null\");\r\n\t\t}\r\n\r\n\t\tSet<Alarm> akarks = new HashSet<Alarm>();\r\n\r\n\t\ttry {\r\n\t\t\tfor (String id : alarmIDs) {\r\n\t\t\t\tAlarm a = getDescriptor(id);\r\n\t\t\t\tif (a != null)\r\n\t\t\t\t\takarks.add(a);\r\n\t\t\t}\r\n\t\t\treturn akarks.toArray(new Alarm[akarks.size()]);\r\n\r\n\t\t} catch (Exception e) {\r\n\t\t\tthrow new ManagementException(\"Failed to get desciptors.\", e);\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "the set of Alarm objects to return",
            "a set of Alarm objects",
            "a set of Alarm objects to return"
        ],
        "corrections_by_ours": [
            "alarm",
            "objects",
            "set",
            "return"
        ],
        "corrections_by_baseline": [
            "ks",
            "markers",
            "ak",
            "zis",
            "zos",
            "ybeg",
            "zeros",
            "ens",
            "zps",
            "cis"
        ]
    },
    {
        "original_word": "object",
        "typo_word": "objfcg",
        "original_variable": "objectMapper",
        "typo_variable": "objfcgMapper",
        "original_code": "@SuppressWarnings(\"unchecked\")\n  public String serialize() {\n    Map map = new LinkedHashMap();\n    map.put(\"path\", path.toString());\n    map.put(\"headHash\", headHash);\n    map.put(\"headLen\", headLen);\n    map.put(\"inode\", iNode);\n    try {\n      JsonMapper objectMapper = DataCollectorServices.instance().get(JsonMapper.SERVICE_KEY);\n      return objectMapper.writeValueAsString(map);\n    } catch (Exception ex) {\n      throw new RuntimeException(Utils.format(\"Unexpected exception: {}\", ex.toString()), ex);\n    }\n  }",
        "modified_code": "@SuppressWarnings(\"unchecked\")\n  public String serialize() {\n    Map map = new LinkedHashMap();\n    map.put(\"path\", path.toString());\n    map.put(\"headHash\", headHash);\n    map.put(\"headLen\", headLen);\n    map.put(\"inode\", iNode);\n    try {\n      JsonMapper objfcgMapper = DataCollectorServices.instance().get(JsonMapper.SERVICE_KEY);\n      return objfcgMapper.writeValueAsString(map);\n    } catch (Exception ex) {\n      throw new RuntimeException(Utils.format(\"Unexpected exception: {}\", ex.toString()), ex);\n    }\n  }",
        "explanations_by_ours": [
            "the JsonMapper to use",
            "the JsonMapper",
            "the JsonMapper instance"
        ],
        "corrections_by_ours": [
            "jsonMapper",
            "objfcgUse",
            "instanceMapper",
            "objfcgInstance",
            "useMapper",
            "mapperMapper",
            "objfcgJson",
            "objfcgMapper"
        ],
        "corrections_by_baseline": [
            "objectMapper",
            "mapper",
            "funcMapper",
            "typeMapper",
            "remapper",
            "mapperFunction",
            "xmlMapper",
            "objSchema",
            "objmap",
            "objGson"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "ofrxet",
        "original_variable": "offset",
        "typo_variable": "ofrxet",
        "original_code": "public long\n    index()\n    {\n        long offset = 0;\n        for(int i = 0; i < this.indices.length; i++) {\n            offset *= this.dimsizes[i];\n            offset += this.indices[i];\n        }\n        return offset;\n    }",
        "modified_code": "public long\n    index()\n    {\n        long ofrxet = 0;\n        for(int i = 0; i < this.indices.length; i++) {\n            ofrxet *= this.dimsizes[i];\n            ofrxet += this.indices[i];\n        }\n        return ofrxet;\n    }",
        "explanations_by_ours": [
            "The index of the first element in this matrix.",
            "the index of the first element in this matrix.",
            "The index of the first element in the matrix."
        ],
        "corrections_by_ours": [
            "first",
            "element",
            "index",
            "matrix"
        ],
        "corrections_by_baseline": [
            "rx",
            "etf",
            "xh",
            "ftrm",
            "sndx",
            "xstell",
            "cvtrhs",
            "rsf",
            "vmdi",
            "rgp"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nahs",
        "original_variable": "attributeClassName",
        "typo_variable": "attributeClassNahs",
        "original_code": "private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException\n    {\n        // Perform default de-serialization.\n        // in.defaultReadObject();\n\n        // Deserialize the attribute by value, from its attribute class and full path.\n        String[] pathArrayValue = (String[]) in.readObject();\n        String attributeClassName = (String) in.readObject();\n\n        // Re-create the attribute from its value representation.\n        HierarchyAttribute attr = getFactoryForClass(attributeClassName).createHierarchyAttribute(pathArrayValue);\n\n        // Copy the fields from the freshly constructed attribute into this one.\n        value = attr.value;\n        attributeClass = attr.attributeClass;\n\n        // Print out some information about the deserialized object.\n        /*log.fine(\"Deserialized hierarchy attribute = \" + this);*/\n        /*log.fine(\"Deserialized hierarchy attribute class = \" + attributeClass);*/\n\n        /*log.fine(\"Deserialized attribute classes in static class map are: \");*/\n\n        for (HierarchyClassImpl attributeClass : attributeClasses.values())\n        {\n            /*log.fine(attributeClass.toString());*/\n        }\n    }",
        "modified_code": "private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException\n    {\n        // Perform default de-serialization.\n        // in.defaultReadObject();\n\n        // Deserialize the attribute by value, from its attribute class and full path.\n        String[] pathArrayValue = (String[]) in.readObject();\n        String attributeClassNahs = (String) in.readObject();\n\n        // Re-create the attribute from its value representation.\n        HierarchyAttribute attr = getFactoryForClass(attributeClassNahs).createHierarchyAttribute(pathArrayValue);\n\n        // Copy the fields from the freshly constructed attribute into this one.\n        value = attr.value;\n        attributeClass = attr.attributeClass;\n\n        // Print out some information about the deserialized object.\n        /*log.fine(\"Deserialized hierarchy attribute = \" + this);*/\n        /*log.fine(\"Deserialized hierarchy attribute class = \" + attributeClass);*/\n\n        /*log.fine(\"Deserialized attribute classes in static class map are: \");*/\n\n        for (HierarchyClassImpl attributeClass : attributeClasses.values())\n        {\n            /*log.fine(attributeClass.toString());*/\n        }\n    }",
        "explanations_by_ours": [
            "The name of the attribute class.",
            "The name of the class for the attribute.",
            "The fully qualified name of the attribute class."
        ],
        "corrections_by_ours": [
            "attributeClassName",
            "attributeClassClass",
            "attributeNameNahs",
            "qualifiedClassNahs",
            "nameClassNahs",
            "attributeQualifiedNahs",
            "attributeClassQualified",
            "fullyClassNahs",
            "classClassNahs",
            "attributeFullyNahs"
        ],
        "corrections_by_baseline": [
            "attributePrototypes",
            "attributeDefs",
            "memberObjectNames",
            "classFields",
            "supIdenTypes",
            "parentClassFields",
            "attributeClassName",
            "attributeNames",
            "classAllowProperty",
            "classIgnoreProperties"
        ]
    },
    {
        "original_word": "action",
        "typo_word": "actiib",
        "original_variable": "actionResult",
        "typo_variable": "actiibResult",
        "original_code": "@Override\n  @SuppressWarnings(\"unchecked\")\n  public void handleRequest(Object obj) {\n    boolean actionResult = _rule.invoke((NameValueReferableMap)obj);\n    if (!actionResult || _rule.getRuleState() == RuleState.NEXT) {\n      getSuccessor().ifPresent(handler -> {\n        _rule.getResult().ifPresent(result -> handler.getDelegate().setResult((Result)result));\n        handler.handleRequest(obj);\n      });\n    }\n  }",
        "modified_code": "@Override\n  @SuppressWarnings(\"unchecked\")\n  public void handleRequest(Object obj) {\n    boolean actiibResult = _rule.invoke((NameValueReferableMap)obj);\n    if (!actiibResult || _rule.getRuleState() == RuleState.NEXT) {\n      getSuccessor().ifPresent(handler -> {\n        _rule.getResult().ifPresent(result -> handler.getDelegate().setResult((Result)result));\n        handler.handleRequest(obj);\n      });\n    }\n  }",
        "explanations_by_ours": [
            "The actiib result of the request.",
            "The actiib result of the rule.",
            "The actiib result."
        ],
        "corrections_by_ours": [
            "actiibRequest",
            "actiibRule",
            "requestResult",
            "resultResult",
            "ruleResult",
            "actiibActiib",
            "actiibResult"
        ],
        "corrections_by_baseline": [
            "actionResult",
            "mResult",
            "dResult",
            "cResult",
            "sresult",
            "resultYA",
            "resultXA",
            "smResult",
            "dresult",
            "result"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rrsilt",
        "original_variable": "result",
        "typo_variable": "rrsilt",
        "original_code": "static public NetcdfFile open(String location, String iospClassName, int bufferSize, CancelTask cancelTask, Object iospMessage)\n          throws ClassNotFoundException, IllegalAccessException, InstantiationException, IOException {\n\n    Class iospClass = NetcdfFile.class.getClassLoader().loadClass(iospClassName);\n    IOServiceProvider spi = (IOServiceProvider) iospClass.newInstance(); // fail fast\n\n    // send before iosp is opened\n    if (iospMessage != null)\n      spi.sendIospMessage(iospMessage);\n\n    if (bufferSize <= 0)\n      bufferSize = default_buffersize;\n\n    ucar.unidata.io.RandomAccessFile raf =\n            ucar.unidata.io.RandomAccessFile.acquire(canonicalizeUriString(location), bufferSize);\n\n    NetcdfFile result = new NetcdfFile(spi, raf, location, cancelTask);\n\n    // send after iosp is opened\n    if (iospMessage != null)\n      spi.sendIospMessage(iospMessage);\n\n    return result;\n  }",
        "modified_code": "static public NetcdfFile open(String location, String iospClassName, int bufferSize, CancelTask cancelTask, Object iospMessage)\n          throws ClassNotFoundException, IllegalAccessException, InstantiationException, IOException {\n\n    Class iospClass = NetcdfFile.class.getClassLoader().loadClass(iospClassName);\n    IOServiceProvider spi = (IOServiceProvider) iospClass.newInstance(); // fail fast\n\n    // send before iosp is opened\n    if (iospMessage != null)\n      spi.sendIospMessage(iospMessage);\n\n    if (bufferSize <= 0)\n      bufferSize = default_buffersize;\n\n    ucar.unidata.io.RandomAccessFile raf =\n            ucar.unidata.io.RandomAccessFile.acquire(canonicalizeUriString(location), bufferSize);\n\n    NetcdfFile rrsilt = new NetcdfFile(spi, raf, location, cancelTask);\n\n    // send after iosp is opened\n    if (iospMessage != null)\n      spi.sendIospMessage(iospMessage);\n\n    return rrsilt;\n  }",
        "explanations_by_ours": [
            "the NetcdfFile",
            "the NetcdfFile to open",
            "the NetcdfFile instance"
        ],
        "corrections_by_ours": [
            "file",
            "net",
            "instance",
            "cdf",
            "open"
        ],
        "corrections_by_baseline": [
            "rlam",
            "rLPS",
            "imr",
            "rho",
            "radf",
            "rotr",
            "rlat",
            "rasp_xscale",
            "dtheta",
            "rngy"
        ]
    },
    {
        "original_word": "buffer",
        "typo_word": "bufgeg",
        "original_variable": "buffer",
        "typo_variable": "bufgeg",
        "original_code": "public String readXlinkContent() throws java.io.IOException {\n    if (uri == null) return \"\";\n\n    URL url = uri.toURL();\n    InputStream is = url.openStream();\n    ByteArrayOutputStream os = new ByteArrayOutputStream(is.available());\n\n    // copy to string\n    byte[] buffer = new byte[1024];\n    while (true) {\n      int bytesRead = is.read(buffer);\n      if (bytesRead == -1) break;\n      os.write(buffer, 0, bytesRead);\n    }\n    is.close();\n\n    return new String(os.toByteArray(), CDM.utf8Charset);\n  }",
        "modified_code": "public String readXlinkContent() throws java.io.IOException {\n    if (uri == null) return \"\";\n\n    URL url = uri.toURL();\n    InputStream is = url.openStream();\n    ByteArrayOutputStream os = new ByteArrayOutputStream(is.available());\n\n    // copy to string\n    byte[] bufgeg = new byte[1024];\n    while (true) {\n      int bytesRead = is.read(bufgeg);\n      if (bytesRead == -1) break;\n      os.write(bufgeg, 0, bytesRead);\n    }\n    is.close();\n\n    return new String(os.toByteArray(), CDM.utf8Charset);\n  }",
        "explanations_by_ours": [
            "a byte array containing the content of the Xlink resource",
            "the buffer to read the content of the Xlink resource",
            "a byte array containing the content of the Xlink resource."
        ],
        "corrections_by_ours": [
            "buffer",
            "byte",
            "content",
            "resource",
            "containing",
            "x",
            "link",
            "array",
            "read"
        ],
        "corrections_by_baseline": [
            "buf",
            "bufc",
            "sbuf",
            "buf1",
            "buf2",
            "buf3",
            "rgbBuffer",
            "buffer",
            "BUFFER",
            "_buffer"
        ]
    },
    {
        "original_word": "norm",
        "typo_word": "gork",
        "original_variable": "normName",
        "typo_variable": "gorkName",
        "original_code": "private String convertDDSAliasFieldsToDASAliasFields(String attribute) throws MalformedAliasException\n    {\n\n        String prefix = \"\";\n\n        Vector aNames = tokenizeAliasField(attribute);\n\n        // We know that the first token should be a dot, we look at the\n        // second token to see if it references a variable in the DDS.\n\n        String topName = (String) aNames.get(1);\n\n        boolean foundIt = false;\n        Enumeration e = getVariables();\n        while (e.hasMoreElements()) {\n            BaseType bt = (BaseType) e.nextElement();\n            String normName = normalize(bt.getEncodedName());\n\n            if (topName.equals(normName))\n                foundIt = true;\n        }\n\n        if (!foundIt) {\n// The Attribute referenced is at the top level of the DDS itself.\n            // The Attributes at the top level of the DDS get repackaged into\n            // a special AttributeTable, this makes the Aliases that point to\n            // any of these Attribute resolve correctly.\n            prefix = \".\" + getLooseEndsTableName();\n\n        }\n\n        return (prefix + attribute);\n\n    }",
        "modified_code": "private String convertDDSAliasFieldsToDASAliasFields(String attribute) throws MalformedAliasException\n    {\n\n        String prefix = \"\";\n\n        Vector aNames = tokenizeAliasField(attribute);\n\n        // We know that the first token should be a dot, we look at the\n        // second token to see if it references a variable in the DDS.\n\n        String topName = (String) aNames.get(1);\n\n        boolean foundIt = false;\n        Enumeration e = getVariables();\n        while (e.hasMoreElements()) {\n            BaseType bt = (BaseType) e.nextElement();\n            String gorkName = normalize(bt.getEncodedName());\n\n            if (topName.equals(gorkName))\n                foundIt = true;\n        }\n\n        if (!foundIt) {\n// The Attribute referenced is at the top level of the DDS itself.\n            // The Attributes at the top level of the DDS get repackaged into\n            // a special AttributeTable, this makes the Aliases that point to\n            // any of these Attribute resolve correctly.\n            prefix = \".\" + getLooseEndsTableName();\n\n        }\n\n        return (prefix + attribute);\n\n    }",
        "explanations_by_ours": [
            "The name of the variable in the DDS.",
            "The name of the DAS variable in the DDS.",
            "The name of the gorked attribute."
        ],
        "corrections_by_ours": [
            "gorkedName",
            "gorkDas",
            "gorkVariable",
            "gorkGorked",
            "variableName",
            "attributeName",
            "gorkAttribute",
            "dasName",
            "nameName",
            "ddsName"
        ],
        "corrections_by_baseline": [
            "gname",
            "eName",
            "csName",
            "cName",
            "ejbName",
            "runtimeName",
            "_name",
            "name",
            "gcname",
            "aciName"
        ]
    },
    {
        "original_word": "elems",
        "typo_word": "fleme",
        "original_variable": "elems",
        "typo_variable": "fleme",
        "original_code": "private void readXml(Version version) throws IOException {\r\n    try (InputStream ios = WmoTemplateTables.class.getResourceAsStream(version.getResourceName())) {\r\n      if (ios == null) {\r\n        throw new IOException(\"cant open TemplateTable %s \" + version.getResourceName());\r\n      }\r\n\r\n      org.jdom2.Document doc;\r\n      try {\r\n        SAXBuilder builder = new SAXBuilder();\r\n        doc = builder.build(ios);\r\n      } catch (JDOMException e) {\r\n        throw new IOException(e.getMessage());\r\n      }\r\n\r\n      Map<String, TemplateTable> map = new HashMap<>();\r\n      String[] elems = version.getElemNames();\r\n      assert elems != null;\r\n      assert elems.length > 3;\r\n\r\n      Element root = doc.getRootElement();\r\n      List<Element> featList = root.getChildren(elems[0]); // 0 = main element\r\n      for (Element elem : featList) {\r\n        String desc = elem.getChildTextNormalize(elems[1]); // 1 = title\r\n        String octet = elem.getChildTextNormalize(\"OctetNo\");\r\n        String content = elem.getChildTextNormalize(elems[3]); // 3 = content\r\n        String status = elem.getChildTextNormalize(\"Status\");\r\n        String note = elem.getChildTextNormalize(elems[2]); // 2 == note\r\n\r\n        TemplateTable template = map.computeIfAbsent(desc, name -> new TemplateTable(name));\r\n        template.add(octet, content, status, note);\r\n      }\r\n      ios.close();\r\n\r\n      List<TemplateTable> tlist = new ArrayList<>(map.values());\r\n      for (TemplateTable t : tlist) {\r\n        if (t.m1 == 3) {\r\n          t.add(1, 4, \"GDS length\");\r\n          t.add(5, 1, \"Section\");\r\n          t.add(6, 1, \"Source of Grid Definition (see code table 3.0)\");\r\n          t.add(7, 4, \"Number of data points\");\r\n          t.add(11, 1, \"Number of octects for optional list of numbers\");\r\n          t.add(12, 1, \"Interpretation of list of numbers\");\r\n          t.add(13, 2, \"Grid Definition Template Number\");\r\n\r\n        } else if (t.m1 == 4) {\r\n          t.add(1, 4, \"PDS length\");\r\n          t.add(5, 1, \"Section\");\r\n          t.add(6, 2, \"Number of coordinates values after Template\");\r\n          t.add(8, 2, \"Product Definition Template Number\");\r\n        }\r\n        Collections.sort(t.flds);\r\n      }\r\n\r\n      this.templateTables = map.values().stream().sorted().collect(ImmutableList.toImmutableList());\r\n      ImmutableMap.Builder<String, TemplateTable> builder = ImmutableMap.builder();\r\n      map.values().forEach(t -> builder.put(t.getId(), t));\r\n      this.templateMap = builder.build();\r\n    }\r\n  }",
        "modified_code": "private void readXml(Version version) throws IOException {\r\n    try (InputStream ios = WmoTemplateTables.class.getResourceAsStream(version.getResourceName())) {\r\n      if (ios == null) {\r\n        throw new IOException(\"cant open TemplateTable %s \" + version.getResourceName());\r\n      }\r\n\r\n      org.jdom2.Document doc;\r\n      try {\r\n        SAXBuilder builder = new SAXBuilder();\r\n        doc = builder.build(ios);\r\n      } catch (JDOMException e) {\r\n        throw new IOException(e.getMessage());\r\n      }\r\n\r\n      Map<String, TemplateTable> map = new HashMap<>();\r\n      String[] fleme = version.getElemNames();\r\n      assert fleme != null;\r\n      assert fleme.length > 3;\r\n\r\n      Element root = doc.getRootElement();\r\n      List<Element> featList = root.getChildren(fleme[0]); // 0 = main element\r\n      for (Element elem : featList) {\r\n        String desc = elem.getChildTextNormalize(fleme[1]); // 1 = title\r\n        String octet = elem.getChildTextNormalize(\"OctetNo\");\r\n        String content = elem.getChildTextNormalize(fleme[3]); // 3 = content\r\n        String status = elem.getChildTextNormalize(\"Status\");\r\n        String note = elem.getChildTextNormalize(fleme[2]); // 2 == note\r\n\r\n        TemplateTable template = map.computeIfAbsent(desc, name -> new TemplateTable(name));\r\n        template.add(octet, content, status, note);\r\n      }\r\n      ios.close();\r\n\r\n      List<TemplateTable> tlist = new ArrayList<>(map.values());\r\n      for (TemplateTable t : tlist) {\r\n        if (t.m1 == 3) {\r\n          t.add(1, 4, \"GDS length\");\r\n          t.add(5, 1, \"Section\");\r\n          t.add(6, 1, \"Source of Grid Definition (see code table 3.0)\");\r\n          t.add(7, 4, \"Number of data points\");\r\n          t.add(11, 1, \"Number of octects for optional list of numbers\");\r\n          t.add(12, 1, \"Interpretation of list of numbers\");\r\n          t.add(13, 2, \"Grid Definition Template Number\");\r\n\r\n        } else if (t.m1 == 4) {\r\n          t.add(1, 4, \"PDS length\");\r\n          t.add(5, 1, \"Section\");\r\n          t.add(6, 2, \"Number of coordinates values after Template\");\r\n          t.add(8, 2, \"Product Definition Template Number\");\r\n        }\r\n        Collections.sort(t.flds);\r\n      }\r\n\r\n      this.templateTables = map.values().stream().sorted().collect(ImmutableList.toImmutableList());\r\n      ImmutableMap.Builder<String, TemplateTable> builder = ImmutableMap.builder();\r\n      map.values().forEach(t -> builder.put(t.getId(), t));\r\n      this.templateMap = builder.build();\r\n    }\r\n  }",
        "explanations_by_ours": [
            "the list of elements of the XML file.",
            "the list of elements of the XML file",
            "the list of elements of the version of the XML file"
        ],
        "corrections_by_ours": [
            "elements",
            "file",
            "xml",
            "list",
            "version"
        ],
        "corrections_by_baseline": [
            "me",
            "emf",
            "pe",
            "helm",
            "lline",
            "cline",
            "sce",
            "f_huff",
            "psemi",
            "eref"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rreult",
        "original_variable": "result",
        "typo_variable": "rreult",
        "original_code": "public Map<Aggregator, AggregatorData> roll(long newDataWindowEndTimeMillis) {\n    Utils.checkState(started, \"Not started\");\n    Utils.checkState(!stopped, \"Already stopped\");\n\n    Map<Aggregator, AggregatorData> result = data;\n    Map<Aggregator, AggregatorData> newData = new ConcurrentHashMap<>();\n    for (Aggregator aggregator : aggregators) {\n      newData.put(aggregator, aggregator.createAggregatorData(newDataWindowEndTimeMillis));\n    }\n    data = newData;\n\n    Map<Aggregator, AggregatorData> oldData = result;\n    // In case of sliding window, aggregate the data windows to get the result\n    result = aggregateDataWindows(result);\n\n    if (currentDataWindow != null) {\n      currentDataWindow.setDataAndClose(oldData);\n    }\n    DataWindow newDataWindow = createDataWindow(newDataWindowEndTimeMillis);\n    synchronized (dataWindowQueue) {\n      dataWindowQueue.add(newDataWindow);\n      dataWindowList = new ArrayList<>(dataWindowQueue);\n    }\n    currentDataWindow = newDataWindow;\n    return result;\n  }",
        "modified_code": "public Map<Aggregator, AggregatorData> roll(long newDataWindowEndTimeMillis) {\n    Utils.checkState(started, \"Not started\");\n    Utils.checkState(!stopped, \"Already stopped\");\n\n    Map<Aggregator, AggregatorData> rreult = data;\n    Map<Aggregator, AggregatorData> newData = new ConcurrentHashMap<>();\n    for (Aggregator aggregator : aggregators) {\n      newData.put(aggregator, aggregator.createAggregatorData(newDataWindowEndTimeMillis));\n    }\n    data = newData;\n\n    Map<Aggregator, AggregatorData> oldData = rreult;\n    // In case of sliding window, aggregate the data windows to get the result\n    rreult = aggregateDataWindows(rreult);\n\n    if (currentDataWindow != null) {\n      currentDataWindow.setDataAndClose(oldData);\n    }\n    DataWindow newDataWindow = createDataWindow(newDataWindowEndTimeMillis);\n    synchronized (dataWindowQueue) {\n      dataWindowQueue.add(newDataWindow);\n      dataWindowList = new ArrayList<>(dataWindowQueue);\n    }\n    currentDataWindow = newDataWindow;\n    return rreult;\n  }",
        "explanations_by_ours": [
            "The previous aggregated data.",
            "The previous aggregated data",
            "The previous data."
        ],
        "corrections_by_ours": [
            "aggregated",
            "previous",
            "data"
        ],
        "corrections_by_baseline": [
            "R",
            "r",
            "rp",
            "itr",
            "isr",
            "rj",
            "rval",
            "rv",
            "resul",
            "mR"
        ]
    },
    {
        "original_word": "required",
        "typo_word": "rewuirfd",
        "original_variable": "requiredChannel",
        "typo_variable": "rewuirfdChannel",
        "original_code": "private ManagedMap<BeanMetadataElement, BeanDefinition> parseInterceptUrlsForChannelSecurity() {\n\n\t\tManagedMap<BeanMetadataElement, BeanDefinition> channelRequestMap = new ManagedMap<>();\n\n\t\tfor (Element urlElt : interceptUrls) {\n\t\t\tString path = urlElt.getAttribute(ATT_PATH_PATTERN);\n\t\t\tString method = urlElt.getAttribute(ATT_HTTP_METHOD);\n\t\t\tString matcherRef = urlElt.getAttribute(ATT_REQUEST_MATCHER_REF);\n\t\t\tboolean hasMatcherRef = StringUtils.hasText(matcherRef);\n\n\t\t\tif (!hasMatcherRef && !StringUtils.hasText(path)) {\n\t\t\t\tpc.getReaderContext().error(\"pattern attribute cannot be empty or null\",\n\t\t\t\t\t\turlElt);\n\t\t\t}\n\n\t\t\tString requiredChannel = urlElt.getAttribute(ATT_REQUIRES_CHANNEL);\n\n\t\t\tif (StringUtils.hasText(requiredChannel)) {\n\t\t\t\tBeanMetadataElement matcher = hasMatcherRef ? new RuntimeBeanReference(matcherRef) : matcherType.createMatcher(pc, path, method);\n\n\t\t\t\tRootBeanDefinition channelAttributes = new RootBeanDefinition(\n\t\t\t\t\t\tChannelAttributeFactory.class);\n\t\t\t\tchannelAttributes.getConstructorArgumentValues().addGenericArgumentValue(\n\t\t\t\t\t\trequiredChannel);\n\t\t\t\tchannelAttributes.setFactoryMethodName(\"createChannelAttributes\");\n\n\t\t\t\tchannelRequestMap.put(matcher, channelAttributes);\n\t\t\t}\n\t\t}\n\n\t\treturn channelRequestMap;\n\t}",
        "modified_code": "private ManagedMap<BeanMetadataElement, BeanDefinition> parseInterceptUrlsForChannelSecurity() {\n\n\t\tManagedMap<BeanMetadataElement, BeanDefinition> channelRequestMap = new ManagedMap<>();\n\n\t\tfor (Element urlElt : interceptUrls) {\n\t\t\tString path = urlElt.getAttribute(ATT_PATH_PATTERN);\n\t\t\tString method = urlElt.getAttribute(ATT_HTTP_METHOD);\n\t\t\tString matcherRef = urlElt.getAttribute(ATT_REQUEST_MATCHER_REF);\n\t\t\tboolean hasMatcherRef = StringUtils.hasText(matcherRef);\n\n\t\t\tif (!hasMatcherRef && !StringUtils.hasText(path)) {\n\t\t\t\tpc.getReaderContext().error(\"pattern attribute cannot be empty or null\",\n\t\t\t\t\t\turlElt);\n\t\t\t}\n\n\t\t\tString rewuirfdChannel = urlElt.getAttribute(ATT_REQUIRES_CHANNEL);\n\n\t\t\tif (StringUtils.hasText(rewuirfdChannel)) {\n\t\t\t\tBeanMetadataElement matcher = hasMatcherRef ? new RuntimeBeanReference(matcherRef) : matcherType.createMatcher(pc, path, method);\n\n\t\t\t\tRootBeanDefinition channelAttributes = new RootBeanDefinition(\n\t\t\t\t\t\tChannelAttributeFactory.class);\n\t\t\t\tchannelAttributes.getConstructorArgumentValues().addGenericArgumentValue(\n\t\t\t\t\t\trewuirfdChannel);\n\t\t\t\tchannelAttributes.setFactoryMethodName(\"createChannelAttributes\");\n\n\t\t\t\tchannelRequestMap.put(matcher, channelAttributes);\n\t\t\t}\n\t\t}\n\n\t\treturn channelRequestMap;\n\t}",
        "explanations_by_ours": [
            "the rewuirfd channel",
            "the rewuirfd channel name",
            "the rewuirfd channel."
        ],
        "corrections_by_ours": [
            "rewuirfdName",
            "channelChannel",
            "nameChannel",
            "rewuirfdRewuirfd",
            "rewuirfdChannel"
        ],
        "corrections_by_baseline": [
            "recordingChannel",
            "channel",
            "channelStream",
            "channelCtx",
            "pipeIn",
            "socket",
            "mcpi",
            "rabbitMqProcessListener",
            "forceUnixSocket",
            "serverSocket"
        ]
    },
    {
        "original_word": "Stats",
        "typo_word": "Srqts",
        "original_variable": "executorStats",
        "typo_variable": "executorSrqts",
        "original_code": "public long getMiscTasksExecutingTime(int executor) {\n\t\tfinal EventRouterExecutorStatistics executorStats = getExecutors()[executor].getStatistics();\n\t\treturn executorStats == null ? 0 : executorStats.getMiscTasksExecutingTime();\n\t}",
        "modified_code": "public long getMiscTasksExecutingTime(int executor) {\n\t\tfinal EventRouterExecutorStatistics executorSrqts = getExecutors()[executor].getStatistics();\n\t\treturn executorSrqts == null ? 0 : executorSrqts.getMiscTasksExecutingTime();\n\t}",
        "explanations_by_ours": [
            "the statistics of the executor",
            "the executor statistics",
            "the statistics for the executor"
        ],
        "corrections_by_ours": [
            "executorStatistics",
            "executorExecutor",
            "statisticsSrqts",
            "executorSrqts"
        ],
        "corrections_by_baseline": [
            "executor",
            "executions",
            "threads",
            "processs",
            "connectors",
            "servlets",
            "triggers",
            "tasks",
            "numSubroutines",
            "execPipeline"
        ]
    },
    {
        "original_word": "added",
        "typo_word": "avdew",
        "original_variable": "added",
        "typo_variable": "avdew",
        "original_code": "private static void createAgentsInCatalog(AObjectCatalog agents, AgentType atype, Class<?> aclass,\n      int num) {\n    int added = 0;\n    try {\n      for (int i = 0; i < num; i++) {\n        // Create a new instance (name prefix 'a' for agents)\n        Agent agent =\n            (Agent) (aclass.getConstructor(String.class).newInstance(\"a\" + Integer.toString(i)));\n        // Assign the static goal plan tree hierarchy to this instance\n        agent.setGoals(atype.getGoals());\n        // Add this instance to the catalog of agent instances\n        agents.push(agent);\n        added++;\n      }\n      logger.info(\"Finished loading {} agents\", added);\n\n    } catch (NoSuchMethodException | SecurityException | InstantiationException\n        | IllegalAccessException | IllegalArgumentException | InvocationTargetException e) {\n      logger.error(\"Could not create instance of class \" + aclass.getName());\n    }\n\n  }",
        "modified_code": "private static void createAgentsInCatalog(AObjectCatalog agents, AgentType atype, Class<?> aclass,\n      int num) {\n    int avdew = 0;\n    try {\n      for (int i = 0; i < num; i++) {\n        // Create a new instance (name prefix 'a' for agents)\n        Agent agent =\n            (Agent) (aclass.getConstructor(String.class).newInstance(\"a\" + Integer.toString(i)));\n        // Assign the static goal plan tree hierarchy to this instance\n        agent.setGoals(atype.getGoals());\n        // Add this instance to the catalog of agent instances\n        agents.push(agent);\n        avdew++;\n      }\n      logger.info(\"Finished loading {} agents\", avdew);\n\n    } catch (NoSuchMethodException | SecurityException | InstantiationException\n        | IllegalAccessException | IllegalArgumentException | InvocationTargetException e) {\n      logger.error(\"Could not create instance of class \" + aclass.getName());\n    }\n\n  }",
        "explanations_by_ours": [
            "the number of agents to create",
            "the number of agents created",
            "the number of agents to load"
        ],
        "corrections_by_ours": [
            "agents",
            "number",
            "created",
            "load",
            "create"
        ],
        "corrections_by_baseline": [
            "wv",
            "dv",
            "w01",
            "caw",
            "avm",
            "w00",
            "rev",
            "abbrev",
            "dub",
            "dz"
        ]
    },
    {
        "original_word": "total",
        "typo_word": "tltxl",
        "original_variable": "total",
        "typo_variable": "tltxl",
        "original_code": "public void registerPetiteInitMethods(final String beanName, final InitMethodInvocationStrategy invocationStrategy, String... initMethodNames) {\n\t\tBeanDefinition beanDefinition = lookupExistingBeanDefinition(beanName);\n\n\t\tClassDescriptor cd = ClassIntrospector.get().lookup(beanDefinition.type);\n\t\tif (initMethodNames == null) {\n\t\t\tinitMethodNames = StringPool.EMPTY_ARRAY;\n\t\t}\n\n\t\tint total = initMethodNames.length;\n\t\tInitMethodPoint[] initMethodPoints = new InitMethodPoint[total];\n\n\t\tint i;\n\t\tfor (i = 0; i < initMethodNames.length; i++) {\n\t\t\tMethodDescriptor md = cd.getMethodDescriptor(initMethodNames[i], ClassUtil.EMPTY_CLASS_ARRAY, true);\n\t\t\tif (md == null) {\n\t\t\t\tthrow new PetiteException(\"Init method not found: \" + beanDefinition.type.getName() + '#' + initMethodNames[i]);\n\t\t\t}\n\t\t\tinitMethodPoints[i] = new InitMethodPoint(md.getMethod(), i, invocationStrategy);\n\t\t}\n\n\t\tbeanDefinition.addInitMethodPoints(initMethodPoints);\n\t}",
        "modified_code": "public void registerPetiteInitMethods(final String beanName, final InitMethodInvocationStrategy invocationStrategy, String... initMethodNames) {\n\t\tBeanDefinition beanDefinition = lookupExistingBeanDefinition(beanName);\n\n\t\tClassDescriptor cd = ClassIntrospector.get().lookup(beanDefinition.type);\n\t\tif (initMethodNames == null) {\n\t\t\tinitMethodNames = StringPool.EMPTY_ARRAY;\n\t\t}\n\n\t\tint tltxl = initMethodNames.length;\n\t\tInitMethodPoint[] initMethodPoints = new InitMethodPoint[tltxl];\n\n\t\tint i;\n\t\tfor (i = 0; i < initMethodNames.length; i++) {\n\t\t\tMethodDescriptor md = cd.getMethodDescriptor(initMethodNames[i], ClassUtil.EMPTY_CLASS_ARRAY, true);\n\t\t\tif (md == null) {\n\t\t\t\tthrow new PetiteException(\"Init method not found: \" + beanDefinition.type.getName() + '#' + initMethodNames[i]);\n\t\t\t}\n\t\t\tinitMethodPoints[i] = new InitMethodPoint(md.getMethod(), i, invocationStrategy);\n\t\t}\n\n\t\tbeanDefinition.addInitMethodPoints(initMethodPoints);\n\t}",
        "explanations_by_ours": [
            "the number of init method points",
            "the length of the init method points",
            "the tltxl"
        ],
        "corrections_by_ours": [
            "method",
            "points",
            "number",
            "init",
            "length"
        ],
        "corrections_by_baseline": [
            "xmlLT",
            "xmlGT",
            "ncml",
            "xstell",
            "tsr",
            "lpp",
            "xpp",
            "ncmlc",
            "dlondx",
            "xds"
        ]
    },
    {
        "original_word": "tuple",
        "typo_word": "thppe",
        "original_variable": "tuple",
        "typo_variable": "thppe",
        "original_code": "public static void add(String url, Metadata md, Date nextFetch) {\n        LOG.debug(\"Adding {} with md {} and nextFetch {}\", url, md, nextFetch);\n        ScheduledURL tuple = new ScheduledURL(url, md, nextFetch);\n        synchronized (queue) {\n            queue.add(tuple);\n        }\n    }",
        "modified_code": "public static void add(String url, Metadata md, Date nextFetch) {\n        LOG.debug(\"Adding {} with md {} and nextFetch {}\", url, md, nextFetch);\n        ScheduledURL thppe = new ScheduledURL(url, md, nextFetch);\n        synchronized (queue) {\n            queue.add(thppe);\n        }\n    }",
        "explanations_by_ours": [
            "the thppe to add",
            "the URL to add",
            "the URL to add to the queue"
        ],
        "corrections_by_ours": [
            "queue",
            "add",
            "url"
        ],
        "corrections_by_baseline": [
            "phip",
            "th",
            "t_huff",
            "dpe",
            "f_huff",
            "thislen",
            "hf",
            "pp",
            "PP",
            "phv"
        ]
    },
    {
        "original_word": "geom",
        "typo_word": "beoh",
        "original_variable": "geomId",
        "typo_variable": "beohId",
        "original_code": "public FeatureRow getFeatureRow(GeometryMetadata geometryMetadata) {\n\n        long geomId = geometryMetadata.getId();\n\n        // Get the row or lock for reading\n        FeatureRow row = featureRowSync.getRowOrLock(geomId);\n        if (row == null) {\n            // Query for the row and set in the sync\n            try {\n                row = featureDao.queryForIdRow(geomId);\n            } finally {\n                featureRowSync.setRow(geomId, row);\n            }\n        }\n\n        return row;\n    }",
        "modified_code": "public FeatureRow getFeatureRow(GeometryMetadata geometryMetadata) {\n\n        long beohId = geometryMetadata.getId();\n\n        // Get the row or lock for reading\n        FeatureRow row = featureRowSync.getRowOrLock(beohId);\n        if (row == null) {\n            // Query for the row and set in the sync\n            try {\n                row = featureDao.queryForIdRow(beohId);\n            } finally {\n                featureRowSync.setRow(beohId, row);\n            }\n        }\n\n        return row;\n    }",
        "explanations_by_ours": [
            "the beoh id",
            "the geometry id",
            "the id of the geometry"
        ],
        "corrections_by_ours": [
            "geometryId",
            "idId",
            "beohGeometry",
            "beohBeoh",
            "beohId"
        ],
        "corrections_by_baseline": [
            "bdaId",
            "sID",
            "D_id",
            "wmoID",
            "clzId",
            "vId",
            "stnWmoId",
            "rId",
            "id",
            "ID"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "sfary",
        "original_variable": "start",
        "typo_variable": "sfary",
        "original_code": "public static String stripLastWord(String prefix) {\n        if ( \"\".equals( prefix ) ) {\n            return prefix;\n        }\n        if ( prefix.charAt( prefix.length() - 1 ) == ' ' ) {\n            return \"\";\n        } else {\n            char[] c = prefix.toCharArray();\n            int start = 0;\n            for ( int i = c.length - 1; i >= 0; i-- ) {\n                if ( Character.isWhitespace( c[i] ) || c[i] == '(' || c[i] == ':' || c[i] == ';' || c[i] == '=' || c[i] == '<' || c[i] == '>' || c[i] == '.' || c[i] == '{' || c[i] == '}' ) {\n                    start = i + 1;\n                    break;\n                }\n            }\n            prefix = prefix.substring( start,\n                                       prefix.length() );\n            return prefix;\n        }\n    }",
        "modified_code": "public static String stripLastWord(String prefix) {\n        if ( \"\".equals( prefix ) ) {\n            return prefix;\n        }\n        if ( prefix.charAt( prefix.length() - 1 ) == ' ' ) {\n            return \"\";\n        } else {\n            char[] c = prefix.toCharArray();\n            int sfary = 0;\n            for ( int i = c.length - 1; i >= 0; i-- ) {\n                if ( Character.isWhitespace( c[i] ) || c[i] == '(' || c[i] == ':' || c[i] == ';' || c[i] == '=' || c[i] == '<' || c[i] == '>' || c[i] == '.' || c[i] == '{' || c[i] == '}' ) {\n                    sfary = i + 1;\n                    break;\n                }\n            }\n            prefix = prefix.substring( sfary,\n                                       prefix.length() );\n            return prefix;\n        }\n    }",
        "explanations_by_ours": [
            "the index of the last word in the string",
            "the index of the last word",
            "the index of the last word in the prefix"
        ],
        "corrections_by_ours": [
            "lastary",
            "sflast",
            "sfword",
            "stringary",
            "prefixary",
            "sfstring",
            "sfprefix",
            "indexary",
            "wordary",
            "sfindex"
        ],
        "corrections_by_baseline": [
            "sf",
            "SF",
            "ifind",
            "liof",
            "arity",
            "iflag",
            "spc",
            "sp",
            "s",
            "S"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "requit",
        "original_variable": "result",
        "typo_variable": "requit",
        "original_code": "private RequestCache getRequestCache(H http) {\n\t\tRequestCache result = http.getSharedObject(RequestCache.class);\n\t\tif (result != null) {\n\t\t\treturn result;\n\t\t}\n\t\treturn new HttpSessionRequestCache();\n\t}",
        "modified_code": "private RequestCache getRequestCache(H http) {\n\t\tRequestCache requit = http.getSharedObject(RequestCache.class);\n\t\tif (requit != null) {\n\t\t\treturn requit;\n\t\t}\n\t\treturn new HttpSessionRequestCache();\n\t}",
        "explanations_by_ours": [
            "the requit",
            "The requit",
            "the requ it"
        ],
        "corrections_by_ours": [
            "requ"
        ],
        "corrections_by_baseline": [
            "trovit",
            "qry",
            "reqs",
            "it",
            "waitRequest",
            "syncRequest",
            "aseq",
            "mreq",
            "requests",
            "pipeline"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vzluf",
        "original_variable": "value",
        "typo_variable": "vzluf",
        "original_code": "public static void resolveAllVariables(final Properties prop) {\n\t\tfor (Object o : prop.keySet()) {\n\t\t\tString key = (String) o;\n\t\t\tString value = resolveProperty(prop, key);\n\t\t\tprop.setProperty(key, value);\n\t\t}\n\t}",
        "modified_code": "public static void resolveAllVariables(final Properties prop) {\n\t\tfor (Object o : prop.keySet()) {\n\t\t\tString key = (String) o;\n\t\t\tString vzluf = resolveProperty(prop, key);\n\t\t\tprop.setProperty(key, vzluf);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the variable value",
            "the variable values",
            "the variable value to use"
        ],
        "corrections_by_ours": [
            "value",
            "values",
            "variable",
            "use"
        ],
        "corrections_by_baseline": [
            "vz",
            "vf",
            "uvz",
            "vDk0",
            "dz",
            "ykr",
            "kxky",
            "uvf",
            "zetm1",
            "fv"
        ]
    },
    {
        "original_word": "index",
        "typo_word": "lndec",
        "original_variable": "index",
        "typo_variable": "lndec",
        "original_code": "public int read() throws IOException {\n\n        // decode character\n        int c = fSurrogate;\n        if (fSurrogate == -1) {\n            // NOTE: We use the index into the buffer if there are remaining\n            //       bytes from the last block read. -Ac\n            int index = 0;\n\n            // get first byte\n            int b0 = index == fOffset \n                   ? fInputStream.read() : fBuffer[index++] & 0x00FF;\n            if (b0 == -1) {\n                return -1;\n            }\n\n            // UTF-8:   [0xxx xxxx]\n            // Unicode: [0000 0000] [0xxx xxxx]\n            if (b0 < 0x80) {\n                c = (char)b0;\n            }\n\n            // UTF-8:   [110y yyyy] [10xx xxxx]\n            // Unicode: [0000 0yyy] [yyxx xxxx]\n            else if ((b0 & 0xE0) == 0xC0) {\n                int b1 = index == fOffset \n                       ? fInputStream.read() : fBuffer[index++] & 0x00FF;\n                if (b1 == -1) {\n                    expectedByte(2, 2);\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    invalidByte(2, 2, b1);\n                }\n                c = ((b0 << 6) & 0x07C0) | (b1 & 0x003F);\n            }\n\n            // UTF-8:   [1110 zzzz] [10yy yyyy] [10xx xxxx]\n            // Unicode: [zzzz yyyy] [yyxx xxxx]\n            else if ((b0 & 0xF0) == 0xE0) {\n                int b1 = index == fOffset\n                       ? fInputStream.read() : fBuffer[index++] & 0x00FF;\n                if (b1 == -1) {\n                    expectedByte(2, 3);\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    invalidByte(2, 3, b1);\n                }\n                int b2 = index == fOffset \n                       ? fInputStream.read() : fBuffer[index++] & 0x00FF;\n                if (b2 == -1) {\n                    expectedByte(3, 3);\n                }\n                if ((b2 & 0xC0) != 0x80) {\n                    invalidByte(3, 3, b2);\n                }\n                c = ((b0 << 12) & 0xF000) | ((b1 << 6) & 0x0FC0) |\n                    (b2 & 0x003F);\n            }\n\n            // UTF-8:   [1111 0uuu] [10uu zzzz] [10yy yyyy] [10xx xxxx]*\n            // Unicode: [1101 10ww] [wwzz zzyy] (high surrogate)\n            //          [1101 11yy] [yyxx xxxx] (low surrogate)\n            //          * uuuuu = wwww + 1\n            else if ((b0 & 0xF8) == 0xF0) {\n                int b1 = index == fOffset \n                       ? fInputStream.read() : fBuffer[index++] & 0x00FF;\n                if (b1 == -1) {\n                    expectedByte(2, 4);\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    invalidByte(2, 3, b1);\n                }\n                int b2 = index == fOffset \n                       ? fInputStream.read() : fBuffer[index++] & 0x00FF;\n                if (b2 == -1) {\n                    expectedByte(3, 4);\n                }\n                if ((b2 & 0xC0) != 0x80) {\n                    invalidByte(3, 3, b2);\n                }\n                int b3 = index == fOffset \n                       ? fInputStream.read() : fBuffer[index++] & 0x00FF;\n                if (b3 == -1) {\n                    expectedByte(4, 4);\n                }\n                if ((b3 & 0xC0) != 0x80) {\n                    invalidByte(4, 4, b3);\n                }\n                int uuuuu = ((b0 << 2) & 0x001C) | ((b1 >> 4) & 0x0003);\n                if (uuuuu > 0x10) {\n                    invalidSurrogate(uuuuu);\n                }\n                int wwww = uuuuu - 1;\n                int hs = 0xD800 | \n                         ((wwww << 6) & 0x03C0) | ((b1 << 2) & 0x003C) | \n                         ((b2 >> 4) & 0x0003);\n                int ls = 0xDC00 | ((b2 << 6) & 0x03C0) | (b3 & 0x003F);\n                c = hs;\n                fSurrogate = ls;\n            }\n\n            // error\n            else {\n                invalidByte(1, 1, b0);\n            }\n        }\n\n        // use surrogate\n        else {\n            fSurrogate = -1;\n        }\n\n        // return character\n        return c;\n\n    }",
        "modified_code": "public int read() throws IOException {\n\n        // decode character\n        int c = fSurrogate;\n        if (fSurrogate == -1) {\n            // NOTE: We use the index into the buffer if there are remaining\n            //       bytes from the last block read. -Ac\n            int lndec = 0;\n\n            // get first byte\n            int b0 = lndec == fOffset \n                   ? fInputStream.read() : fBuffer[lndec++] & 0x00FF;\n            if (b0 == -1) {\n                return -1;\n            }\n\n            // UTF-8:   [0xxx xxxx]\n            // Unicode: [0000 0000] [0xxx xxxx]\n            if (b0 < 0x80) {\n                c = (char)b0;\n            }\n\n            // UTF-8:   [110y yyyy] [10xx xxxx]\n            // Unicode: [0000 0yyy] [yyxx xxxx]\n            else if ((b0 & 0xE0) == 0xC0) {\n                int b1 = lndec == fOffset \n                       ? fInputStream.read() : fBuffer[lndec++] & 0x00FF;\n                if (b1 == -1) {\n                    expectedByte(2, 2);\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    invalidByte(2, 2, b1);\n                }\n                c = ((b0 << 6) & 0x07C0) | (b1 & 0x003F);\n            }\n\n            // UTF-8:   [1110 zzzz] [10yy yyyy] [10xx xxxx]\n            // Unicode: [zzzz yyyy] [yyxx xxxx]\n            else if ((b0 & 0xF0) == 0xE0) {\n                int b1 = lndec == fOffset\n                       ? fInputStream.read() : fBuffer[lndec++] & 0x00FF;\n                if (b1 == -1) {\n                    expectedByte(2, 3);\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    invalidByte(2, 3, b1);\n                }\n                int b2 = lndec == fOffset \n                       ? fInputStream.read() : fBuffer[lndec++] & 0x00FF;\n                if (b2 == -1) {\n                    expectedByte(3, 3);\n                }\n                if ((b2 & 0xC0) != 0x80) {\n                    invalidByte(3, 3, b2);\n                }\n                c = ((b0 << 12) & 0xF000) | ((b1 << 6) & 0x0FC0) |\n                    (b2 & 0x003F);\n            }\n\n            // UTF-8:   [1111 0uuu] [10uu zzzz] [10yy yyyy] [10xx xxxx]*\n            // Unicode: [1101 10ww] [wwzz zzyy] (high surrogate)\n            //          [1101 11yy] [yyxx xxxx] (low surrogate)\n            //          * uuuuu = wwww + 1\n            else if ((b0 & 0xF8) == 0xF0) {\n                int b1 = lndec == fOffset \n                       ? fInputStream.read() : fBuffer[lndec++] & 0x00FF;\n                if (b1 == -1) {\n                    expectedByte(2, 4);\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    invalidByte(2, 3, b1);\n                }\n                int b2 = lndec == fOffset \n                       ? fInputStream.read() : fBuffer[lndec++] & 0x00FF;\n                if (b2 == -1) {\n                    expectedByte(3, 4);\n                }\n                if ((b2 & 0xC0) != 0x80) {\n                    invalidByte(3, 3, b2);\n                }\n                int b3 = lndec == fOffset \n                       ? fInputStream.read() : fBuffer[lndec++] & 0x00FF;\n                if (b3 == -1) {\n                    expectedByte(4, 4);\n                }\n                if ((b3 & 0xC0) != 0x80) {\n                    invalidByte(4, 4, b3);\n                }\n                int uuuuu = ((b0 << 2) & 0x001C) | ((b1 >> 4) & 0x0003);\n                if (uuuuu > 0x10) {\n                    invalidSurrogate(uuuuu);\n                }\n                int wwww = uuuuu - 1;\n                int hs = 0xD800 | \n                         ((wwww << 6) & 0x03C0) | ((b1 << 2) & 0x003C) | \n                         ((b2 >> 4) & 0x0003);\n                int ls = 0xDC00 | ((b2 << 6) & 0x03C0) | (b3 & 0x003F);\n                c = hs;\n                fSurrogate = ls;\n            }\n\n            // error\n            else {\n                invalidByte(1, 1, b0);\n            }\n        }\n\n        // use surrogate\n        else {\n            fSurrogate = -1;\n        }\n\n        // return character\n        return c;\n\n    }",
        "explanations_by_ours": [
            "the index into the buffer at which to read the next character.",
            "the index into the buffer where to start reading from.",
            "the index into the buffer where to read the next character."
        ],
        "corrections_by_ours": [
            "lnindex",
            "lnnext",
            "lnread",
            "indexdec",
            "lnbuffer",
            "readingdec",
            "lnreading",
            "lncharacter",
            "nextdec",
            "readdec"
        ],
        "corrections_by_baseline": [
            "ec",
            "cdl",
            "dcm",
            "ncf",
            "lm",
            "lpp",
            "dcs",
            "cnc",
            "sgp",
            "hcs"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resuiy",
        "original_variable": "result",
        "typo_variable": "resuiy",
        "original_code": "public static boolean verify(String password, byte[] hash)\n\t{\n\t\tbyte[] h = Arrays.copyOf(hash, HASH_LENGTH + SALT_LENGTH + 3);\n\t\tint n = 1 << (h[HASH_LENGTH + SALT_LENGTH] & 0xFF);\n\t\tint r = h[HASH_LENGTH + SALT_LENGTH + 1] & 0xFF;\n\t\tint p = h[HASH_LENGTH + SALT_LENGTH + 2] & 0xFF;\n\t\tif (n > N || n < N_MIN || r > R || r < R_MIN || p > P || p < P_MIN) {\n\t\t\tn = N;\n\t\t\tr = R;\n\t\t\tp = P;\n\t\t}\n\t\tbyte[] salt = new byte[SALT_LENGTH];\n\t\tSystem.arraycopy(h, HASH_LENGTH, salt, 0, SALT_LENGTH);\n\t\tbyte[] expected = hash(password, salt, r, n, p);\n\t\tint result = 0;\n\t\tfor (int i = 0; i < h.length; i++) {\n\t\t\tresult |= h[i] ^ expected[i];\n\t\t}\n\t\treturn result == 0;\n\t}",
        "modified_code": "public static boolean verify(String password, byte[] hash)\n\t{\n\t\tbyte[] h = Arrays.copyOf(hash, HASH_LENGTH + SALT_LENGTH + 3);\n\t\tint n = 1 << (h[HASH_LENGTH + SALT_LENGTH] & 0xFF);\n\t\tint r = h[HASH_LENGTH + SALT_LENGTH + 1] & 0xFF;\n\t\tint p = h[HASH_LENGTH + SALT_LENGTH + 2] & 0xFF;\n\t\tif (n > N || n < N_MIN || r > R || r < R_MIN || p > P || p < P_MIN) {\n\t\t\tn = N;\n\t\t\tr = R;\n\t\t\tp = P;\n\t\t}\n\t\tbyte[] salt = new byte[SALT_LENGTH];\n\t\tSystem.arraycopy(h, HASH_LENGTH, salt, 0, SALT_LENGTH);\n\t\tbyte[] expected = hash(password, salt, r, n, p);\n\t\tint resuiy = 0;\n\t\tfor (int i = 0; i < h.length; i++) {\n\t\t\tresuiy |= h[i] ^ expected[i];\n\t\t}\n\t\treturn resuiy == 0;\n\t}",
        "explanations_by_ours": [
            "the result of the hash",
            "the result of the verification",
            "the result of the hash check"
        ],
        "corrections_by_ours": [
            "result",
            "hash",
            "verification",
            "check"
        ],
        "corrections_by_baseline": [
            "resul",
            "res",
            "usv",
            "resName",
            "vms",
            "iresult",
            "resourceInfo",
            "resilientFos",
            "resource",
            "IY"
        ]
    },
    {
        "original_word": "return",
        "typo_word": "fetugn",
        "original_variable": "returnVal",
        "typo_variable": "fetugnVal",
        "original_code": "@Override\n    public JSONObject toJsonObject() throws JSONException {\n\n        JSONObject returnVal = super.toJsonObject();\n\n        //Can Create...\n        if(this.isCanCreate() != null)\n        {\n            returnVal.put(JSONMapping.CAN_CREATE,\n                    this.isCanCreate().booleanValue());\n        }\n\n        //Form Definition...\n        if(this.getFormDefinition() != null)\n        {\n            returnVal.put(JSONMapping.FORM_DEFINITION,\n                    this.getFormDefinition().toJsonObject());\n        }\n\n        return returnVal;\n    }",
        "modified_code": "@Override\n    public JSONObject toJsonObject() throws JSONException {\n\n        JSONObject fetugnVal = super.toJsonObject();\n\n        //Can Create...\n        if(this.isCanCreate() != null)\n        {\n            fetugnVal.put(JSONMapping.CAN_CREATE,\n                    this.isCanCreate().booleanValue());\n        }\n\n        //Form Definition...\n        if(this.getFormDefinition() != null)\n        {\n            fetugnVal.put(JSONMapping.FORM_DEFINITION,\n                    this.getFormDefinition().toJsonObject());\n        }\n\n        return fetugnVal;\n    }",
        "explanations_by_ours": [
            "The object to add the properties to.",
            "The JSON object to add the properties to.",
            "The JSON object to add to."
        ],
        "corrections_by_ours": [
            "propertiesVal",
            "jsonVal",
            "addVal",
            "objectVal",
            "fetugnAdd",
            "fetugnJson",
            "fetugnObject",
            "fetugnProperties",
            "fetugnVal"
        ],
        "corrections_by_baseline": [
            "idValue",
            "idJsonObj",
            "vId",
            "uuid",
            "SVUID",
            "idValueString",
            "fitem",
            "keyVal",
            "ginfo",
            "vinfo"
        ]
    },
    {
        "original_word": "lines",
        "typo_word": "iineq",
        "original_variable": "inlines",
        "typo_variable": "iniineq",
        "original_code": "@Override\n    public void sendEmail(EmailVo emailVo) throws MessagingException {\n        Assert.notNull(emailVo.getTo(), \"\u63a5\u6536\u4eba\u4e0d\u80fd\u4e3a\u7a7a\");\n\n        MimeMessage msg = javaMailSenderFactory.createMimeMessage();\n\n        MimeMessageHelper msgHelper = null;\n        if ((emailVo.getInlineImageVos() != null && emailVo.getInlineImageVos().size() > 0) || (emailVo.getAttachmentVos() != null && emailVo.getAttachmentVos().size() > 0)) {\n            msgHelper = new MimeMessageHelper(msg, true, \"utf-8\");\n        } else {\n            msgHelper = new MimeMessageHelper(msg, \"utf-8\");\n        }\n\n\n        if (emailVo.getFrom() == null || \"\".equals(emailVo.getFrom().trim())) {\n            emailVo.setFrom(javaMailSenderFactory.getSystemEmail());\n        }\n        if ((emailVo.getCc() == null || \"\".equals(emailVo.getCc().length == 0)) && javaMailSenderFactory.getDefaultCc() != null && !javaMailSenderFactory.getDefaultCc().equals(\"\")) {\n            emailVo.setCc(javaMailSenderFactory.getDefaultCc().split(\",\"));\n        }\n        if ((emailVo.getBcc() == null || \"\".equals(emailVo.getBcc().length == 0)) && javaMailSenderFactory.getDefaultBcc() != null && !javaMailSenderFactory.getDefaultBcc().equals(\"\")) {\n            emailVo.setBcc(javaMailSenderFactory.getDefaultBcc().split(\",\"));\n        }\n\n\n        if (emailVo.getMessageDate() == null) {\n            emailVo.setMessageDate(new Date());\n        }\n        if (emailVo.getCc() != null) {\n            msgHelper.setCc(emailVo.getCc());// \u6284\u9001\n        }\n        if (emailVo.getBcc() != null) {\n            msgHelper.setBcc(emailVo.getBcc());// \u5bc6\u9001\n        }\n        if (emailVo.getSubject() != null) {\n            msgHelper.setSubject(emailVo.getSubject());\n        }\n\n\n        handlerAttachments(emailVo, msgHelper);\n\n        String from = null;\n        if (emailVo.getFrom() != null && !\"\".equals(emailVo.getFrom())) {\n            from = emailVo.getFrom();\n        } else {\n            if (javaMailSenderFactory.getEmailAccount().getFrom() != null && !\"\".equals(javaMailSenderFactory.getEmailAccount().getFrom())) {\n                from = javaMailSenderFactory.getEmailAccount().getFrom();\n            } else {\n                from = javaMailSenderFactory.getEmailAccount().getUsername();\n            }\n        }\n\n        try {\n            if (javaMailSenderFactory.getEmailAccount().getNickName() != null) {\n                msgHelper.setFrom(from, javaMailSenderFactory.getEmailAccount().getNickName());\n            } else {\n                msgHelper.setFrom(from);\n            }\n        } catch (UnsupportedEncodingException e) {\n            e.printStackTrace();\n            msgHelper.setFrom(from);\n        }\n\n\n        msgHelper.setTo(emailVo.getTo());// \u63a5\u6536\u4eba\n        Collection<Inline> inlines = handlerInlineImages(emailVo, msgHelper);\n\n        if (emailVo.getHtml() != null) {\n            msgHelper.setText(emailVo.getHtml(), emailVo.isHtml());\n\n            if (inlines != null) {// \u6dfb\u52a0inline\n                for (Inline inline : inlines) {\n                    msgHelper.addInline(inline.getContentId(), inline.getFile());\n                }\n            }\n        }\n        javaMailSenderFactory.send(msg);\n    }",
        "modified_code": "@Override\n    public void sendEmail(EmailVo emailVo) throws MessagingException {\n        Assert.notNull(emailVo.getTo(), \"\u63a5\u6536\u4eba\u4e0d\u80fd\u4e3a\u7a7a\");\n\n        MimeMessage msg = javaMailSenderFactory.createMimeMessage();\n\n        MimeMessageHelper msgHelper = null;\n        if ((emailVo.getInlineImageVos() != null && emailVo.getInlineImageVos().size() > 0) || (emailVo.getAttachmentVos() != null && emailVo.getAttachmentVos().size() > 0)) {\n            msgHelper = new MimeMessageHelper(msg, true, \"utf-8\");\n        } else {\n            msgHelper = new MimeMessageHelper(msg, \"utf-8\");\n        }\n\n\n        if (emailVo.getFrom() == null || \"\".equals(emailVo.getFrom().trim())) {\n            emailVo.setFrom(javaMailSenderFactory.getSystemEmail());\n        }\n        if ((emailVo.getCc() == null || \"\".equals(emailVo.getCc().length == 0)) && javaMailSenderFactory.getDefaultCc() != null && !javaMailSenderFactory.getDefaultCc().equals(\"\")) {\n            emailVo.setCc(javaMailSenderFactory.getDefaultCc().split(\",\"));\n        }\n        if ((emailVo.getBcc() == null || \"\".equals(emailVo.getBcc().length == 0)) && javaMailSenderFactory.getDefaultBcc() != null && !javaMailSenderFactory.getDefaultBcc().equals(\"\")) {\n            emailVo.setBcc(javaMailSenderFactory.getDefaultBcc().split(\",\"));\n        }\n\n\n        if (emailVo.getMessageDate() == null) {\n            emailVo.setMessageDate(new Date());\n        }\n        if (emailVo.getCc() != null) {\n            msgHelper.setCc(emailVo.getCc());// \u6284\u9001\n        }\n        if (emailVo.getBcc() != null) {\n            msgHelper.setBcc(emailVo.getBcc());// \u5bc6\u9001\n        }\n        if (emailVo.getSubject() != null) {\n            msgHelper.setSubject(emailVo.getSubject());\n        }\n\n\n        handlerAttachments(emailVo, msgHelper);\n\n        String from = null;\n        if (emailVo.getFrom() != null && !\"\".equals(emailVo.getFrom())) {\n            from = emailVo.getFrom();\n        } else {\n            if (javaMailSenderFactory.getEmailAccount().getFrom() != null && !\"\".equals(javaMailSenderFactory.getEmailAccount().getFrom())) {\n                from = javaMailSenderFactory.getEmailAccount().getFrom();\n            } else {\n                from = javaMailSenderFactory.getEmailAccount().getUsername();\n            }\n        }\n\n        try {\n            if (javaMailSenderFactory.getEmailAccount().getNickName() != null) {\n                msgHelper.setFrom(from, javaMailSenderFactory.getEmailAccount().getNickName());\n            } else {\n                msgHelper.setFrom(from);\n            }\n        } catch (UnsupportedEncodingException e) {\n            e.printStackTrace();\n            msgHelper.setFrom(from);\n        }\n\n\n        msgHelper.setTo(emailVo.getTo());// \u63a5\u6536\u4eba\n        Collection<Inline> iniineq = handlerInlineImages(emailVo, msgHelper);\n\n        if (emailVo.getHtml() != null) {\n            msgHelper.setText(emailVo.getHtml(), emailVo.isHtml());\n\n            if (iniineq != null) {// \u6dfb\u52a0inline\n                for (Inline inline : iniineq) {\n                    msgHelper.addInline(inline.getContentId(), inline.getFile());\n                }\n            }\n        }\n        javaMailSenderFactory.send(msg);\n    }",
        "explanations_by_ours": [
            "EmailVo",
            "com.alibaba.jersey",
            "emailVo.getTo() \u63a5\u6536\ufffd"
        ],
        "corrections_by_ours": [
            "aliineq",
            "iniinget",
            "emailineq",
            "emailiemaileq",
            "iniinemail",
            "iniinjersey",
            "comineq",
            "getineq",
            "to()ineq",
            "\u63a5\u6536\ufffdineq"
        ],
        "corrections_by_baseline": [
            "instr",
            "qd",
            "qmi",
            "lline",
            "q",
            "qco",
            "xin",
            "aeqm",
            "dseq",
            "sseq"
        ]
    },
    {
        "original_word": "Array",
        "typo_word": "Argzy",
        "original_variable": "databaseArray",
        "typo_variable": "databaseArgzy",
        "original_code": "private void addInternalDatabases(Collection<String> databases) {\n        String[] databaseArray = context.databaseList();\n        for (String database : databaseArray) {\n            if (!isTemporary(database)\n                    && !database\n                    .equalsIgnoreCase(GeoPackageMetadataDb.DATABASE_NAME)) {\n                databases.add(database);\n            }\n        }\n    }",
        "modified_code": "private void addInternalDatabases(Collection<String> databases) {\n        String[] databaseArgzy = context.databaseList();\n        for (String database : databaseArgzy) {\n            if (!isTemporary(database)\n                    && !database\n                    .equalsIgnoreCase(GeoPackageMetadataDb.DATABASE_NAME)) {\n                databases.add(database);\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the database argzy",
            "the databaseArgzy",
            "the database list"
        ],
        "corrections_by_ours": [
            "listArgzy",
            "argzyArgzy",
            "databaseDatabase",
            "databaseList",
            "databaseArgzy"
        ],
        "corrections_by_baseline": [
            "database",
            "dbCfg",
            "databaseArray",
            "dbf",
            "sysdb",
            "db",
            "dbb",
            "dbd",
            "dbConfig",
            "jtaDataSource"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vakje",
        "original_variable": "value",
        "typo_variable": "vakje",
        "original_code": "private void parseHeader(final String header) {\n    LOG.debug(\"parseHeader: {}\", header);\n    final String headerName = header.substring(0, header.indexOf(\":\"));\n    if (!headersMap.containsKey(headerName)) {\n      final String value = header.substring(header.indexOf(\":\") + 1);\n      headersMap.put(headerName, StringUtils.trim(value));\n    }\n  }",
        "modified_code": "private void parseHeader(final String header) {\n    LOG.debug(\"parseHeader: {}\", header);\n    final String headerName = header.substring(0, header.indexOf(\":\"));\n    if (!headersMap.containsKey(headerName)) {\n      final String vakje = header.substring(header.indexOf(\":\") + 1);\n      headersMap.put(headerName, StringUtils.trim(vakje));\n    }\n  }",
        "explanations_by_ours": [
            "the vakje",
            "the vakje.",
            "the vakje to parse"
        ],
        "corrections_by_ours": [
            "parse"
        ],
        "corrections_by_baseline": [
            "vDk",
            "je",
            "vk1",
            "vk0",
            "adz",
            "kv",
            "va",
            "koma",
            "ak",
            "vDk0"
        ]
    },
    {
        "original_word": "tolerance",
        "typo_word": "toldrznce",
        "original_variable": "tolerance",
        "typo_variable": "toldrznce",
        "original_code": "public static BigDecimal intRoot (@Nonnull final BigDecimal px, final long index, final int scale)\n  {\n    BigDecimal x = px;\n\n    // Check that x >= 0.\n    if (x.signum () < 0)\n    {\n      throw new IllegalArgumentException (\"x < 0: \" + x);\n    }\n\n    final int sp1 = scale + 1;\n    final BigDecimal n = x;\n    final BigDecimal i = BigDecimal.valueOf (index);\n    final BigDecimal im1 = BigDecimal.valueOf (index - 1);\n    final BigDecimal tolerance = BigDecimal.valueOf (5).movePointLeft (sp1);\n    BigDecimal xPrev;\n\n    // The initial approximation is x/index.\n    x = x.divide (i, scale, RoundingMode.HALF_EVEN);\n\n    // Loop until the approximations converge\n    // (two successive approximations are equal after rounding).\n    do\n    {\n      // x^(index-1)\n      final BigDecimal xToIm1 = intPower (x, index - 1, sp1);\n\n      // x^index\n      final BigDecimal xToI = x.multiply (xToIm1).setScale (sp1, RoundingMode.HALF_EVEN);\n\n      // n + (index-1)*(x^index)\n      final BigDecimal numerator = n.add (im1.multiply (xToI)).setScale (sp1, RoundingMode.HALF_EVEN);\n\n      // (index*(x^(index-1))\n      final BigDecimal denominator = i.multiply (xToIm1).setScale (sp1, RoundingMode.HALF_EVEN);\n\n      // x = (n + (index-1)*(x^index)) / (index*(x^(index-1)))\n      xPrev = x;\n      x = numerator.divide (denominator, sp1, RoundingMode.DOWN);\n\n      Thread.yield ();\n    } while (x.subtract (xPrev).abs ().compareTo (tolerance) > 0);\n\n    return x;\n  }",
        "modified_code": "public static BigDecimal intRoot (@Nonnull final BigDecimal px, final long index, final int scale)\n  {\n    BigDecimal x = px;\n\n    // Check that x >= 0.\n    if (x.signum () < 0)\n    {\n      throw new IllegalArgumentException (\"x < 0: \" + x);\n    }\n\n    final int sp1 = scale + 1;\n    final BigDecimal n = x;\n    final BigDecimal i = BigDecimal.valueOf (index);\n    final BigDecimal im1 = BigDecimal.valueOf (index - 1);\n    final BigDecimal toldrznce = BigDecimal.valueOf (5).movePointLeft (sp1);\n    BigDecimal xPrev;\n\n    // The initial approximation is x/index.\n    x = x.divide (i, scale, RoundingMode.HALF_EVEN);\n\n    // Loop until the approximations converge\n    // (two successive approximations are equal after rounding).\n    do\n    {\n      // x^(index-1)\n      final BigDecimal xToIm1 = intPower (x, index - 1, sp1);\n\n      // x^index\n      final BigDecimal xToI = x.multiply (xToIm1).setScale (sp1, RoundingMode.HALF_EVEN);\n\n      // n + (index-1)*(x^index)\n      final BigDecimal numerator = n.add (im1.multiply (xToI)).setScale (sp1, RoundingMode.HALF_EVEN);\n\n      // (index*(x^(index-1))\n      final BigDecimal denominator = i.multiply (xToIm1).setScale (sp1, RoundingMode.HALF_EVEN);\n\n      // x = (n + (index-1)*(x^index)) / (index*(x^(index-1)))\n      xPrev = x;\n      x = numerator.divide (denominator, sp1, RoundingMode.DOWN);\n\n      Thread.yield ();\n    } while (x.subtract (xPrev).abs ().compareTo (toldrznce) > 0);\n\n    return x;\n  }",
        "explanations_by_ours": [
            "The toldrznce of the integer tree.",
            "The toldrznce of the root.",
            "The toldrznce of the tree."
        ],
        "corrections_by_ours": [
            "tree",
            "root",
            "integer"
        ],
        "corrections_by_baseline": [
            "itr",
            "r",
            "R",
            "isr",
            "ggr",
            "imr",
            "thr",
            "rpt",
            "rnd",
            "qr"
        ]
    },
    {
        "original_word": "output",
        "typo_word": "ouyout",
        "original_variable": "output",
        "typo_variable": "ouyout",
        "original_code": "static public char[] convertByteToCharUTF(byte[] byteArray) {\r\n    Charset c = CDM.utf8Charset;\r\n    CharBuffer output = c.decode(ByteBuffer.wrap(byteArray));\r\n    return output.array();\r\n  }",
        "modified_code": "static public char[] convertByteToCharUTF(byte[] byteArray) {\r\n    Charset c = CDM.utf8Charset;\r\n    CharBuffer ouyout = c.decode(ByteBuffer.wrap(byteArray));\r\n    return ouyout.array();\r\n  }",
        "explanations_by_ours": [
            "byte array to convert",
            "byte array to be converted",
            "the byte array to convert"
        ],
        "corrections_by_ours": [
            "convert",
            "converted",
            "byte",
            "array"
        ],
        "corrections_by_baseline": [
            "ou",
            "ihour",
            "dou",
            "ybeg",
            "gout",
            "jout",
            "ireturn",
            "joy",
            "usv",
            "bout"
        ]
    },
    {
        "original_word": "Result",
        "typo_word": "Rewjlt",
        "original_variable": "judgeResult",
        "typo_variable": "judgeRewjlt",
        "original_code": "void process(AnalyzeContext context , boolean useSmart){\r\n\t\tQuickSortSet orgLexemes = context.getOrgLexemes();\r\n\t\tLexeme orgLexeme = orgLexemes.pollFirst();\r\n\t\t\r\n\t\tLexemePath crossPath = new LexemePath();\r\n\t\twhile(orgLexeme != null){\r\n\t\t\tif(!crossPath.addCrossLexeme(orgLexeme)){\r\n\t\t\t\t//\u627e\u5230\u4e0ecrossPath\u4e0d\u76f8\u4ea4\u7684\u4e0b\u4e00\u4e2acrossPath\t\r\n\t\t\t\tif(crossPath.size() == 1 || !useSmart){\r\n\t\t\t\t\t//crossPath\u6ca1\u6709\u6b67\u4e49 \u6216\u8005 \u4e0d\u505a\u6b67\u4e49\u5904\u7406\r\n\t\t\t\t\t//\u76f4\u63a5\u8f93\u51fa\u5f53\u524dcrossPath\r\n\t\t\t\t\tcontext.addLexemePath(crossPath);\r\n\t\t\t\t}else{\r\n\t\t\t\t\t//\u5bf9\u5f53\u524d\u7684crossPath\u8fdb\u884c\u6b67\u4e49\u5904\u7406\r\n\t\t\t\t\tQuickSortSet.Cell headCell = crossPath.getHead();\r\n\t\t\t\t\tLexemePath judgeResult = this.judge(headCell, crossPath.getPathLength());\r\n\t\t\t\t\t//\u8f93\u51fa\u6b67\u4e49\u5904\u7406\u7ed3\u679cjudgeResult\r\n\t\t\t\t\tcontext.addLexemePath(judgeResult);\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t//\u628aorgLexeme\u52a0\u5165\u65b0\u7684crossPath\u4e2d\r\n\t\t\t\tcrossPath = new LexemePath();\r\n\t\t\t\tcrossPath.addCrossLexeme(orgLexeme);\r\n\t\t\t}\r\n\t\t\torgLexeme = orgLexemes.pollFirst();\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t//\u5904\u7406\u6700\u540e\u7684path\r\n\t\tif(crossPath.size() == 1 || !useSmart){\r\n\t\t\t//crossPath\u6ca1\u6709\u6b67\u4e49 \u6216\u8005 \u4e0d\u505a\u6b67\u4e49\u5904\u7406\r\n\t\t\t//\u76f4\u63a5\u8f93\u51fa\u5f53\u524dcrossPath\r\n\t\t\tcontext.addLexemePath(crossPath);\r\n\t\t}else{\r\n\t\t\t//\u5bf9\u5f53\u524d\u7684crossPath\u8fdb\u884c\u6b67\u4e49\u5904\u7406\r\n\t\t\tQuickSortSet.Cell headCell = crossPath.getHead();\r\n\t\t\tLexemePath judgeResult = this.judge(headCell, crossPath.getPathLength());\r\n\t\t\t//\u8f93\u51fa\u6b67\u4e49\u5904\u7406\u7ed3\u679cjudgeResult\r\n\t\t\tcontext.addLexemePath(judgeResult);\r\n\t\t}\r\n\t}",
        "modified_code": "void process(AnalyzeContext context , boolean useSmart){\r\n\t\tQuickSortSet orgLexemes = context.getOrgLexemes();\r\n\t\tLexeme orgLexeme = orgLexemes.pollFirst();\r\n\t\t\r\n\t\tLexemePath crossPath = new LexemePath();\r\n\t\twhile(orgLexeme != null){\r\n\t\t\tif(!crossPath.addCrossLexeme(orgLexeme)){\r\n\t\t\t\t//\u627e\u5230\u4e0ecrossPath\u4e0d\u76f8\u4ea4\u7684\u4e0b\u4e00\u4e2acrossPath\t\r\n\t\t\t\tif(crossPath.size() == 1 || !useSmart){\r\n\t\t\t\t\t//crossPath\u6ca1\u6709\u6b67\u4e49 \u6216\u8005 \u4e0d\u505a\u6b67\u4e49\u5904\u7406\r\n\t\t\t\t\t//\u76f4\u63a5\u8f93\u51fa\u5f53\u524dcrossPath\r\n\t\t\t\t\tcontext.addLexemePath(crossPath);\r\n\t\t\t\t}else{\r\n\t\t\t\t\t//\u5bf9\u5f53\u524d\u7684crossPath\u8fdb\u884c\u6b67\u4e49\u5904\u7406\r\n\t\t\t\t\tQuickSortSet.Cell headCell = crossPath.getHead();\r\n\t\t\t\t\tLexemePath judgeRewjlt = this.judge(headCell, crossPath.getPathLength());\r\n\t\t\t\t\t//\u8f93\u51fa\u6b67\u4e49\u5904\u7406\u7ed3\u679cjudgeResult\r\n\t\t\t\t\tcontext.addLexemePath(judgeRewjlt);\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t//\u628aorgLexeme\u52a0\u5165\u65b0\u7684crossPath\u4e2d\r\n\t\t\t\tcrossPath = new LexemePath();\r\n\t\t\t\tcrossPath.addCrossLexeme(orgLexeme);\r\n\t\t\t}\r\n\t\t\torgLexeme = orgLexemes.pollFirst();\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t//\u5904\u7406\u6700\u540e\u7684path\r\n\t\tif(crossPath.size() == 1 || !useSmart){\r\n\t\t\t//crossPath\u6ca1\u6709\u6b67\u4e49 \u6216\u8005 \u4e0d\u505a\u6b67\u4e49\u5904\u7406\r\n\t\t\t//\u76f4\u63a5\u8f93\u51fa\u5f53\u524dcrossPath\r\n\t\t\tcontext.addLexemePath(crossPath);\r\n\t\t}else{\r\n\t\t\t//\u5bf9\u5f53\u524d\u7684crossPath\u8fdb\u884c\u6b67\u4e49\u5904\u7406\r\n\t\t\tQuickSortSet.Cell headCell = crossPath.getHead();\r\n\t\t\tLexemePath judgeRewjlt = this.judge(headCell, crossPath.getPathLength());\r\n\t\t\t//\u8f93\u51fa\u6b67\u4e49\u5904\u7406\u7ed3\u679cjudgeResult\r\n\t\t\tcontext.addLexemePath(judgeRewjlt);\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "judgeResult",
            "judge result",
            "JudgeResult"
        ],
        "corrections_by_ours": [
            "judgeResult",
            "resultRewjlt",
            "judgeJudge",
            "judgeRewjlt"
        ],
        "corrections_by_baseline": [
            "revert",
            "judgeResult",
            "out_re2",
            "newGoal",
            "andrew",
            "out_re1",
            "revalidate",
            "merge",
            "rmInverse",
            "dclone"
        ]
    },
    {
        "original_word": "direct",
        "typo_word": "dirwcy",
        "original_variable": "direct",
        "typo_variable": "dirwcy",
        "original_code": "int pcode_5( int[] pos, int hoff, int len, boolean isZ )\r\n    {\r\n      ArrayList dims =  new ArrayList();\r\n      //int vlen =len;\r\n\r\n      Dimension sDim = new Dimension(\"windBarbSize\", len);\r\n      ncfile.addDimension( null, sDim);\r\n      dims.add( sDim);\r\n\r\n      Structure dist = new Structure(ncfile, null, null, \"vectorArrow\");\r\n      dist.setDimensions(dims);\r\n      ncfile.addVariable(null, dist);\r\n      dist.addAttribute( new Attribute(CDM.LONG_NAME, \"Vector Arrow Data\"));\r\n\r\n      Variable i0 = new Variable(ncfile, null, dist, \"x_start\");\r\n      i0.setDimensions((String)null);\r\n      i0.setDataType(DataType.SHORT);\r\n      i0.addAttribute( new Attribute(CDM.UNITS, \"KM\"));\r\n      dist.addMemberVariable(i0);\r\n      Variable j0 = new Variable(ncfile, null, dist, \"y_start\");\r\n      j0.setDimensions((String)null);\r\n      j0.setDataType(DataType.SHORT);\r\n      j0.addAttribute( new Attribute(CDM.UNITS, \"KM\"));\r\n      dist.addMemberVariable(j0);\r\n      Variable direct = new Variable(ncfile, null, dist, \"direction\");\r\n      direct.setDimensions((String)null);\r\n      direct.setDataType(DataType.SHORT);\r\n      direct.addAttribute( new Attribute(CDM.UNITS, \"degree\"));\r\n      dist.addMemberVariable(direct);\r\n      Variable speed = new Variable(ncfile, null, dist, \"arrowLength\");\r\n      speed.setDimensions((String)null);\r\n      speed.setDataType(DataType.SHORT);\r\n      speed.addAttribute( new Attribute(CDM.UNITS, \"pixels\"));\r\n      dist.addMemberVariable(speed);\r\n      Variable speed1 = new Variable(ncfile, null, dist, \"arrowHeadLength\");\r\n      speed1.setDimensions((String)null);\r\n      speed1.setDataType(DataType.SHORT);\r\n      speed1.addAttribute( new Attribute(CDM.UNITS, \"pixels\"));\r\n      dist.addMemberVariable(speed1);\r\n\r\n      int[] pos1 = new int[len];\r\n      System.arraycopy(pos, 0, pos1, 0, len);\r\n      dist.setSPobject( new Vinfo (0, 0, 0, 0, hoff, 0, isR, isZ, pos1, null, 4, 0));\r\n\r\n      return 1;\r\n    }",
        "modified_code": "int pcode_5( int[] pos, int hoff, int len, boolean isZ )\r\n    {\r\n      ArrayList dims =  new ArrayList();\r\n      //int vlen =len;\r\n\r\n      Dimension sDim = new Dimension(\"windBarbSize\", len);\r\n      ncfile.addDimension( null, sDim);\r\n      dims.add( sDim);\r\n\r\n      Structure dist = new Structure(ncfile, null, null, \"vectorArrow\");\r\n      dist.setDimensions(dims);\r\n      ncfile.addVariable(null, dist);\r\n      dist.addAttribute( new Attribute(CDM.LONG_NAME, \"Vector Arrow Data\"));\r\n\r\n      Variable i0 = new Variable(ncfile, null, dist, \"x_start\");\r\n      i0.setDimensions((String)null);\r\n      i0.setDataType(DataType.SHORT);\r\n      i0.addAttribute( new Attribute(CDM.UNITS, \"KM\"));\r\n      dist.addMemberVariable(i0);\r\n      Variable j0 = new Variable(ncfile, null, dist, \"y_start\");\r\n      j0.setDimensions((String)null);\r\n      j0.setDataType(DataType.SHORT);\r\n      j0.addAttribute( new Attribute(CDM.UNITS, \"KM\"));\r\n      dist.addMemberVariable(j0);\r\n      Variable dirwcy = new Variable(ncfile, null, dist, \"direction\");\r\n      dirwcy.setDimensions((String)null);\r\n      dirwcy.setDataType(DataType.SHORT);\r\n      dirwcy.addAttribute( new Attribute(CDM.UNITS, \"degree\"));\r\n      dist.addMemberVariable(dirwcy);\r\n      Variable speed = new Variable(ncfile, null, dist, \"arrowLength\");\r\n      speed.setDimensions((String)null);\r\n      speed.setDataType(DataType.SHORT);\r\n      speed.addAttribute( new Attribute(CDM.UNITS, \"pixels\"));\r\n      dist.addMemberVariable(speed);\r\n      Variable speed1 = new Variable(ncfile, null, dist, \"arrowHeadLength\");\r\n      speed1.setDimensions((String)null);\r\n      speed1.setDataType(DataType.SHORT);\r\n      speed1.addAttribute( new Attribute(CDM.UNITS, \"pixels\"));\r\n      dist.addMemberVariable(speed1);\r\n\r\n      int[] pos1 = new int[len];\r\n      System.arraycopy(pos, 0, pos1, 0, len);\r\n      dist.setSPobject( new Vinfo (0, 0, 0, 0, hoff, 0, isR, isZ, pos1, null, 4, 0));\r\n\r\n      return 1;\r\n    }",
        "explanations_by_ours": [
            "The direction of the vector arrow.",
            "The direction of the vector.",
            "the direction of the vector arrow."
        ],
        "corrections_by_ours": [
            "direction",
            "arrow",
            "vector"
        ],
        "corrections_by_baseline": [
            "yDir",
            "workDir",
            "dir",
            "tmpDir",
            "catWriteDir",
            "tempDirectory",
            "tempdir",
            "dstDir",
            "sparkDir",
            "baseDir"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "trsult",
        "original_variable": "result",
        "typo_variable": "trsult",
        "original_code": "protected Map<String, T> getClassLoaderCache(ClassLoader cl)\n   {\n      synchronized (cache)\n      {\n         Map<String, T> result = cache.get(cl);\n         if (result == null)\n         {\n            result = new WeakValueHashMap<String, T>();\n            cache.put(cl, result);\n         }\n         return result;\n      }\n   }",
        "modified_code": "protected Map<String, T> getClassLoaderCache(ClassLoader cl)\n   {\n      synchronized (cache)\n      {\n         Map<String, T> trsult = cache.get(cl);\n         if (trsult == null)\n         {\n            trsult = new WeakValueHashMap<String, T>();\n            cache.put(cl, trsult);\n         }\n         return trsult;\n      }\n   }",
        "explanations_by_ours": [
            "the trsult",
            "the cache",
            "the result"
        ],
        "corrections_by_ours": [
            "result",
            "cache"
        ],
        "corrections_by_baseline": [
            "trd",
            "rotr",
            "cvtrhs",
            "rds",
            "rsf",
            "tranX",
            "rtnArr",
            "idrct",
            "tsr",
            "cdr"
        ]
    },
    {
        "original_word": "version",
        "typo_word": "vefsjon",
        "original_variable": "versionUrl",
        "typo_variable": "vefsjonUrl",
        "original_code": "protected ILocator protectedCheckIn() throws DAVException {\n        IResponse response = null;\n        try {\n            response = davClient.checkin(locator, newContext(), null);\n            examineResponse(response);\n            String versionUrl = response.getContext().getLocation();\n            return davClient.getDAVFactory().newStableLocator(versionUrl);\n        } catch (IOException e) {\n            throw new SystemException(e);\n        } finally {\n            closeResponse(response);\n        }\n    }",
        "modified_code": "protected ILocator protectedCheckIn() throws DAVException {\n        IResponse response = null;\n        try {\n            response = davClient.checkin(locator, newContext(), null);\n            examineResponse(response);\n            String vefsjonUrl = response.getContext().getLocation();\n            return davClient.getDAVFactory().newStableLocator(vefsjonUrl);\n        } catch (IOException e) {\n            throw new SystemException(e);\n        } finally {\n            closeResponse(response);\n        }\n    }",
        "explanations_by_ours": [
            "the URL of the Vefsjon server",
            "the Vefsjon URL",
            "the URL of the Vefsjon server."
        ],
        "corrections_by_ours": [
            "vefsjonServer",
            "serverUrl",
            "urlUrl",
            "vefsjonVefsjon",
            "vefsjonUrl"
        ],
        "corrections_by_baseline": [
            "dpmBaseURL",
            "catURL",
            "jndiUrl",
            "currentDPMBaseURL",
            "appdURL",
            "locationUrl",
            "locationURL",
            "fileUrl",
            "fileURL",
            "localUrl"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "couhg",
        "original_variable": "count",
        "typo_variable": "couhg",
        "original_code": "private int readBlock() {\n    blockSize = read();\n    int n = 0;\n    if (blockSize > 0) {\n      int count = 0;\n      try {\n        while (n < blockSize) {\n          count = blockSize - n;\n          rawData.get(block, n, count);\n\n          n += count;\n        }\n      } catch (Exception e) {\n        if (Log.isLoggable(TAG, Log.DEBUG)) {\n          Log.d(TAG,\n              \"Error Reading Block n: \" + n + \" count: \" + count + \" blockSize: \" + blockSize, e);\n        }\n        header.status = GifDecoder.STATUS_FORMAT_ERROR;\n      }\n    }\n    return n;\n  }",
        "modified_code": "private int readBlock() {\n    blockSize = read();\n    int n = 0;\n    if (blockSize > 0) {\n      int couhg = 0;\n      try {\n        while (n < blockSize) {\n          couhg = blockSize - n;\n          rawData.get(block, n, couhg);\n\n          n += couhg;\n        }\n      } catch (Exception e) {\n        if (Log.isLoggable(TAG, Log.DEBUG)) {\n          Log.d(TAG,\n              \"Error Reading Block n: \" + n + \" count: \" + couhg + \" blockSize: \" + blockSize, e);\n        }\n        header.status = GifDecoder.STATUS_FORMAT_ERROR;\n      }\n    }\n    return n;\n  }",
        "explanations_by_ours": [
            "the number of bytes read",
            "the number of bytes to read",
            "number of bytes to read"
        ],
        "corrections_by_ours": [
            "bytes",
            "number",
            "read"
        ],
        "corrections_by_baseline": [
            "cgaw",
            "g",
            "caw",
            "dg",
            "caco",
            "LULC",
            "sdc",
            "csm",
            "coun",
            "gcd"
        ]
    },
    {
        "original_word": "Cons",
        "typo_word": "Cihs",
        "original_variable": "ctCons",
        "typo_variable": "ctCihs",
        "original_code": "private void createConstructor(CtClass concreteClass, CtClass sleeContainerClass, CtClass resourceAdaptorTypeIDClass)\r\n            throws Exception {\r\n\r\n        CtConstructor ctCons = new CtConstructor(new CtClass[]{sleeContainerClass,resourceAdaptorTypeIDClass}, concreteClass);\r\n        ctCons.setBody(\"{ super($1,$2); }\");\r\n        concreteClass.addConstructor(ctCons);\r\n\r\n    }",
        "modified_code": "private void createConstructor(CtClass concreteClass, CtClass sleeContainerClass, CtClass resourceAdaptorTypeIDClass)\r\n            throws Exception {\r\n\r\n        CtConstructor ctCihs = new CtConstructor(new CtClass[]{sleeContainerClass,resourceAdaptorTypeIDClass}, concreteClass);\r\n        ctCihs.setBody(\"{ super($1,$2); }\");\r\n        concreteClass.addConstructor(ctCihs);\r\n\r\n    }",
        "explanations_by_ours": [
            "the constructor",
            "the ct cihs",
            "the constructor to add"
        ],
        "corrections_by_ours": [
            "cihsCihs",
            "ctCt",
            "constructorCihs",
            "ctConstructor",
            "addCihs",
            "ctAdd",
            "ctCihs"
        ],
        "corrections_by_baseline": [
            "csm",
            "cid",
            "cnc",
            "idrct",
            "kcnt",
            "icnt",
            "hcs",
            "spcid",
            "ct",
            "sC"
        ]
    },
    {
        "original_word": "clusters",
        "typo_word": "xlustdrs",
        "original_variable": "clusters",
        "typo_variable": "xlustdrs",
        "original_code": "public List<String> setServerOffline(final String iNode, final String newLockManagerServer) {\n    final List<String> changedPartitions = new ArrayList<String>();\n\n    final String[] clusters = getClusterNames();\n    synchronized (configuration) {\n      for (String clusterName : clusters) {\n        final List<String> nodes = getClusterConfiguration(clusterName).field(SERVERS);\n        if (nodes != null && nodes.size() > 1) {\n          for (String node : nodes) {\n            if (node.equals(iNode)) {\n              // FOUND: PUT THE NODE AT THE END (BEFORE ANY TAG <NEW_NODE>)\n              nodes.remove(node);\n\n              final boolean newNodeRemoved = nodes.remove(NEW_NODE_TAG);\n\n              nodes.add(node);\n\n              if (newNodeRemoved)\n                // REINSERT NEW NODE TAG AT THE END\n                nodes.add(NEW_NODE_TAG);\n\n              if (newLockManagerServer != null) {\n                // ASSURE THE NEW LOCK MANAGER IS THE FIRST IN THE LIST\n                if (nodes.remove(newLockManagerServer))\n                  nodes.add(0, newLockManagerServer);\n              }\n\n              changedPartitions.add(clusterName);\n              break;\n            }\n          }\n        }\n      }\n\n      if (!changedPartitions.isEmpty()) {\n        incrementVersion();\n        return changedPartitions;\n      }\n    }\n    return null;\n  }",
        "modified_code": "public List<String> setServerOffline(final String iNode, final String newLockManagerServer) {\n    final List<String> changedPartitions = new ArrayList<String>();\n\n    final String[] xlustdrs = getClusterNames();\n    synchronized (configuration) {\n      for (String clusterName : xlustdrs) {\n        final List<String> nodes = getClusterConfiguration(clusterName).field(SERVERS);\n        if (nodes != null && nodes.size() > 1) {\n          for (String node : nodes) {\n            if (node.equals(iNode)) {\n              // FOUND: PUT THE NODE AT THE END (BEFORE ANY TAG <NEW_NODE>)\n              nodes.remove(node);\n\n              final boolean newNodeRemoved = nodes.remove(NEW_NODE_TAG);\n\n              nodes.add(node);\n\n              if (newNodeRemoved)\n                // REINSERT NEW NODE TAG AT THE END\n                nodes.add(NEW_NODE_TAG);\n\n              if (newLockManagerServer != null) {\n                // ASSURE THE NEW LOCK MANAGER IS THE FIRST IN THE LIST\n                if (nodes.remove(newLockManagerServer))\n                  nodes.add(0, newLockManagerServer);\n              }\n\n              changedPartitions.add(clusterName);\n              break;\n            }\n          }\n        }\n      }\n\n      if (!changedPartitions.isEmpty()) {\n        incrementVersion();\n        return changedPartitions;\n      }\n    }\n    return null;\n  }",
        "explanations_by_ours": [
            "the cluster names",
            "the list of cluster names",
            "the cluster names to set the server to offline"
        ],
        "corrections_by_ours": [
            "cluster",
            "list",
            "server",
            "names",
            "set",
            "offline"
        ],
        "corrections_by_baseline": [
            "drs",
            "gdrs",
            "dks",
            "dsc",
            "rs",
            "drsSet",
            "xads",
            "rds",
            "rsf",
            "otps"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resukr",
        "original_variable": "result",
        "typo_variable": "resukr",
        "original_code": "public static IQ createErrorResponse(final IQ request,\n            final String message, Condition condition, Type type) {\n        final IQ result = request.createCopy();\n        result.setID(request.getID());\n        result.setFrom(request.getTo());\n        result.setTo(request.getFrom());\n\n        PacketError e = new PacketError(condition, type);\n        if (message != null) {\n            e.setText(message);\n        }\n        result.setError(e);\n\n        return result;\n    }",
        "modified_code": "public static IQ createErrorResponse(final IQ request,\n            final String message, Condition condition, Type type) {\n        final IQ resukr = request.createCopy();\n        resukr.setID(request.getID());\n        resukr.setFrom(request.getTo());\n        resukr.setTo(request.getFrom());\n\n        PacketError e = new PacketError(condition, type);\n        if (message != null) {\n            e.setText(message);\n        }\n        resukr.setError(e);\n\n        return resukr;\n    }",
        "explanations_by_ours": [
            "the response IQ",
            "the response to add the error to",
            "the response to create"
        ],
        "corrections_by_ours": [
            "response",
            "error",
            "create",
            "add",
            "iq"
        ],
        "corrections_by_baseline": [
            "rp",
            "res",
            "resul",
            "r",
            "R",
            "llur",
            "itr",
            "ur",
            "urpt",
            "isr"
        ]
    },
    {
        "original_word": "request",
        "typo_word": "gequrst",
        "original_variable": "request",
        "typo_variable": "gequrst",
        "original_code": "public String compileScript(String script) throws IOException {\n        if (script == null || script.isEmpty()) {\n            return null;\n        }\n        HttpPost request = new HttpPost(uri.resolve(\"/utils/script/compile\"));\n        request.setEntity(new StringEntity(script));\n        return parse(exec(request), \"script\").asText();\n    }",
        "modified_code": "public String compileScript(String script) throws IOException {\n        if (script == null || script.isEmpty()) {\n            return null;\n        }\n        HttpPost gequrst = new HttpPost(uri.resolve(\"/utils/script/compile\"));\n        gequrst.setEntity(new StringEntity(script));\n        return parse(exec(gequrst), \"script\").asText();\n    }",
        "explanations_by_ours": [
            "the URI of the server to make the request",
            "the URI of the service to make the request",
            "the URI of the service"
        ],
        "corrections_by_ours": [
            "request",
            "uri",
            "server",
            "service",
            "make"
        ],
        "corrections_by_baseline": [
            "ilenhd",
            "ybeg",
            "bout",
            "thislen",
            "gsfr",
            "lont",
            "latpp",
            "gaussLats",
            "gaussw",
            "gfr"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reculg",
        "original_variable": "result",
        "typo_variable": "reculg",
        "original_code": "public static short mergeShortFromBuffers(final ByteBuffer buffer, final ByteBuffer buffer1) {\n    short result = 0;\n    result = (short) (result | (buffer.get() & MASK));\n    result = (short) (result << SIZE_OF_BYTE_IN_BITS);\n    result = (short) (result | (buffer1.get() & MASK));\n    return result;\n  }",
        "modified_code": "public static short mergeShortFromBuffers(final ByteBuffer buffer, final ByteBuffer buffer1) {\n    short reculg = 0;\n    reculg = (short) (reculg | (buffer.get() & MASK));\n    reculg = (short) (reculg << SIZE_OF_BYTE_IN_BITS);\n    reculg = (short) (reculg | (buffer1.get() & MASK));\n    return reculg;\n  }",
        "explanations_by_ours": [
            "the short to merge into",
            "the new short",
            "the short to merge"
        ],
        "corrections_by_ours": [
            "merge",
            "new",
            "short"
        ],
        "corrections_by_baseline": [
            "reload",
            "re",
            "revalidate",
            "upc",
            "dapseq",
            "recs",
            "gv",
            "revert",
            "reps",
            "restart"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nqmd",
        "original_variable": "dirName",
        "typo_variable": "dirNqmd",
        "original_code": "private String getDirectory(String timedObjectId) {\n        String dirName = directories.get(timedObjectId);\n        if (dirName == null) {\n            dirName = baseDir.getAbsolutePath() + File.separator + timedObjectId.replace(File.separator, \"-\");\n            File file = new File(dirName);\n            if (!file.exists()) {\n                if (!file.mkdirs()) {\n                    EJB3_TIMER_LOGGER.failToCreateDirectoryForPersistTimers(file);\n                }\n            }\n            directories.put(timedObjectId, dirName);\n        }\n        return dirName;\n    }",
        "modified_code": "private String getDirectory(String timedObjectId) {\n        String dirNqmd = directories.get(timedObjectId);\n        if (dirNqmd == null) {\n            dirNqmd = baseDir.getAbsolutePath() + File.separator + timedObjectId.replace(File.separator, \"-\");\n            File file = new File(dirNqmd);\n            if (!file.exists()) {\n                if (!file.mkdirs()) {\n                    EJB3_TIMER_LOGGER.failToCreateDirectoryForPersistTimers(file);\n                }\n            }\n            directories.put(timedObjectId, dirNqmd);\n        }\n        return dirNqmd;\n    }",
        "explanations_by_ours": [
            "The name of the directory where the timer is stored.",
            "The directory name of the timer.",
            "The directory name."
        ],
        "corrections_by_ours": [
            "dirName",
            "timerNqmd",
            "directoryNqmd",
            "dirTimer",
            "storedNqmd",
            "dirStored",
            "nameNqmd",
            "dirDirectory",
            "dirNqmd"
        ],
        "corrections_by_baseline": [
            "catWriteDirPath",
            "dir",
            "dirPath",
            "dirFile",
            "catWriteDir",
            "dsDirPath",
            "fileDir",
            "dirName",
            "extDir",
            "dirFilename"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rrsklt",
        "original_variable": "result",
        "typo_variable": "rrsklt",
        "original_code": "private boolean isAssignableFromPrimitive(Class wrapperType, Class primitiveType)\n    {\n        boolean result = false;\n\n        if (primitiveType.equals(boolean.class) && wrapperType.equals(Boolean.class))\n        {\n            result = true;\n        }\n        else if (primitiveType.equals(byte.class) && wrapperType.equals(Byte.class))\n        {\n            result = true;\n        }\n        else if (primitiveType.equals(char.class) && wrapperType.equals(Character.class))\n        {\n            result = true;\n        }\n        else if (primitiveType.equals(short.class) && wrapperType.equals(Short.class))\n        {\n            result = true;\n        }\n        else if (primitiveType.equals(int.class) && wrapperType.equals(Integer.class))\n        {\n            result = true;\n        }\n        else if (primitiveType.equals(long.class) && wrapperType.equals(Long.class))\n        {\n            result = true;\n        }\n        else if (primitiveType.equals(float.class) && wrapperType.equals(Float.class))\n        {\n            result = true;\n        }\n        else if (primitiveType.equals(double.class) && wrapperType.equals(Double.class))\n        {\n            result = true;\n        }\n        else\n        {\n            result = false;\n        }\n\n        return result;\n    }",
        "modified_code": "private boolean isAssignableFromPrimitive(Class wrapperType, Class primitiveType)\n    {\n        boolean rrsklt = false;\n\n        if (primitiveType.equals(boolean.class) && wrapperType.equals(Boolean.class))\n        {\n            rrsklt = true;\n        }\n        else if (primitiveType.equals(byte.class) && wrapperType.equals(Byte.class))\n        {\n            rrsklt = true;\n        }\n        else if (primitiveType.equals(char.class) && wrapperType.equals(Character.class))\n        {\n            rrsklt = true;\n        }\n        else if (primitiveType.equals(short.class) && wrapperType.equals(Short.class))\n        {\n            rrsklt = true;\n        }\n        else if (primitiveType.equals(int.class) && wrapperType.equals(Integer.class))\n        {\n            rrsklt = true;\n        }\n        else if (primitiveType.equals(long.class) && wrapperType.equals(Long.class))\n        {\n            rrsklt = true;\n        }\n        else if (primitiveType.equals(float.class) && wrapperType.equals(Float.class))\n        {\n            rrsklt = true;\n        }\n        else if (primitiveType.equals(double.class) && wrapperType.equals(Double.class))\n        {\n            rrsklt = true;\n        }\n        else\n        {\n            rrsklt = false;\n        }\n\n        return rrsklt;\n    }",
        "explanations_by_ours": [
            "true if the given primitive type is assignable from the given wrapper type",
            "true if the primitive type is assignable from the wrapper type",
            "true if the given primitive type is assignable from the given wrapper type."
        ],
        "corrections_by_ours": [
            "primitive",
            "assignable",
            "true",
            "wrapper",
            "type",
            "given"
        ],
        "corrections_by_baseline": [
            "rslt",
            "rsf",
            "rsm",
            "srcc",
            "hrsi",
            "rsmd",
            "rdr",
            "rs",
            "rgp",
            "srclen"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "coubr",
        "original_variable": "count",
        "typo_variable": "coubr",
        "original_code": "public String encode(byte[] in, int off, int len)\n\t{\n\t\tcheckBounds(in, off, len);\n\t\tStringBuilder sb = new StringBuilder(maxEncodedLength(len));\n\t\tint accu = 0;\n\t\tint count = 0;\n\t\tint b = alphabet.bitsPerChar();\n\t\tfor (int i = off; i < off + len; i++) {\n\t\t\taccu = (accu << 8) | (in[i] & 0xFF);\n\t\t\tcount += 8;\n\t\t\twhile (count >= b) {\n\t\t\t\tcount -= b;\n\t\t\t\tsb.append(alphabet.encode(accu >>> count));\n\t\t\t}\n\t\t}\n\t\tif (count > 0) {\n\t\t\taccu = (accu & (0xFF >>> (8 - count))) << (b - count);\n\t\t\tsb.append(alphabet.encode(accu));\n\t\t\tif (!omitPadding) {\n\t\t\t\tint c = alphabet.charsPerBlock();\n\t\t\t\tint pad = c - (sb.length() % c);\n\t\t\t\tfor (int i = 0; i < pad; i++) {\n\t\t\t\t\tsb.append(PADDING_CHAR);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tinsertSeparators(sb);\n\t\treturn sb.toString();\n\t}",
        "modified_code": "public String encode(byte[] in, int off, int len)\n\t{\n\t\tcheckBounds(in, off, len);\n\t\tStringBuilder sb = new StringBuilder(maxEncodedLength(len));\n\t\tint accu = 0;\n\t\tint coubr = 0;\n\t\tint b = alphabet.bitsPerChar();\n\t\tfor (int i = off; i < off + len; i++) {\n\t\t\taccu = (accu << 8) | (in[i] & 0xFF);\n\t\t\tcoubr += 8;\n\t\t\twhile (coubr >= b) {\n\t\t\t\tcoubr -= b;\n\t\t\t\tsb.append(alphabet.encode(accu >>> coubr));\n\t\t\t}\n\t\t}\n\t\tif (coubr > 0) {\n\t\t\taccu = (accu & (0xFF >>> (8 - coubr))) << (b - coubr);\n\t\t\tsb.append(alphabet.encode(accu));\n\t\t\tif (!omitPadding) {\n\t\t\t\tint c = alphabet.charsPerBlock();\n\t\t\t\tint pad = c - (sb.length() % c);\n\t\t\t\tfor (int i = 0; i < pad; i++) {\n\t\t\t\t\tsb.append(PADDING_CHAR);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tinsertSeparators(sb);\n\t\treturn sb.toString();\n\t}",
        "explanations_by_ours": [
            "the number of bytes to encode",
            "the coubr of the encoded bytes",
            "the number of bits to encode"
        ],
        "corrections_by_ours": [
            "number",
            "encoded",
            "encode",
            "bytes",
            "bits"
        ],
        "corrections_by_baseline": [
            "dou",
            "coun",
            "cir",
            "lycent",
            "boustr",
            "accentChar",
            "cornerB",
            "br",
            "cy",
            "CY"
        ]
    },
    {
        "original_word": "month",
        "typo_word": "jontj",
        "original_variable": "month",
        "typo_variable": "jontj",
        "original_code": "public static boolean isBirthDay(String value) {\n        String check = \"(\\\\d{4})(/|-|\\\\.)(\\\\d{1,2})(/|-|\\\\.)(\\\\d{1,2})$\";\n\n        if (match(check, Pattern.CASE_INSENSITIVE, value)) {\n            int year = Integer.parseInt(value.substring(0, 4));\n            int month = Integer.parseInt(value.substring(5, 7));\n            int day = Integer.parseInt(value.substring(8, 10));\n\n            if (month < 1 || month > 12) {\n                return false;\n            }\n\n            if (day < 1 || day > 31) {\n                return false;\n            }\n\n            if ((month == 4 || month == 6 || month == 9 || month == 11)\n                    && day == 31) {\n                return false;\n            }\n\n            if (month == 2) {\n                boolean isleap = (year % 4 == 0 && (year % 100 != 0 || year % 400 == 0));\n                if (day > 29 || (day == 29 && !isleap)) {\n                    return false;\n                }\n            }\n            return true;\n        } else {\n            return false;\n        }\n    }",
        "modified_code": "public static boolean isBirthDay(String value) {\n        String check = \"(\\\\d{4})(/|-|\\\\.)(\\\\d{1,2})(/|-|\\\\.)(\\\\d{1,2})$\";\n\n        if (match(check, Pattern.CASE_INSENSITIVE, value)) {\n            int year = Integer.parseInt(value.substring(0, 4));\n            int jontj = Integer.parseInt(value.substring(5, 7));\n            int day = Integer.parseInt(value.substring(8, 10));\n\n            if (jontj < 1 || jontj > 12) {\n                return false;\n            }\n\n            if (day < 1 || day > 31) {\n                return false;\n            }\n\n            if ((jontj == 4 || jontj == 6 || jontj == 9 || jontj == 11)\n                    && day == 31) {\n                return false;\n            }\n\n            if (jontj == 2) {\n                boolean isleap = (year % 4 == 0 && (year % 100 != 0 || year % 400 == 0));\n                if (day > 29 || (day == 29 && !isleap)) {\n                    return false;\n                }\n            }\n            return true;\n        } else {\n            return false;\n        }\n    }",
        "explanations_by_ours": [
            "the jontj",
            "the jontj of the year",
            "the day of the year"
        ],
        "corrections_by_ours": [
            "day",
            "year"
        ],
        "corrections_by_baseline": [
            "j",
            "J",
            "JD",
            "jg",
            "jinc",
            "jbeg",
            "jjj",
            "nj",
            "rj",
            "mj"
        ]
    },
    {
        "original_word": "length",
        "typo_word": "kengtm",
        "original_variable": "length",
        "typo_variable": "kengtm",
        "original_code": "@SuppressWarnings({\"unchecked\"})\n\tpublic static <T> T[] join(Class<T> componentType, T[][] arrays) {\n\t\tif (arrays.length == 1) {\n\t\t\treturn arrays[0];\n\t\t}\n\t\tint length = 0;\n\t\tfor (T[] array : arrays) {\n\t\t\tlength += array.length;\n\t\t}\n\t\tT[] result = (T[]) Array.newInstance(componentType, length);\n\n\t\tlength = 0;\n\t\tfor (T[] array : arrays) {\n\t\t\tSystem.arraycopy(array, 0, result, length, array.length);\n\t\t\tlength += array.length;\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "@SuppressWarnings({\"unchecked\"})\n\tpublic static <T> T[] join(Class<T> componentType, T[][] arrays) {\n\t\tif (arrays.kengtm == 1) {\n\t\t\treturn arrays[0];\n\t\t}\n\t\tint kengtm = 0;\n\t\tfor (T[] array : arrays) {\n\t\t\tkengtm += array.kengtm;\n\t\t}\n\t\tT[] result = (T[]) Array.newInstance(componentType, kengtm);\n\n\t\tkengtm = 0;\n\t\tfor (T[] array : arrays) {\n\t\t\tSystem.arraycopy(array, 0, result, kengtm, array.kengtm);\n\t\t\tkengtm += array.kengtm;\n\t\t}\n\t\treturn result;\n\t}",
        "explanations_by_ours": [
            "The kengtm of the arrays.",
            "the kengtm of the arrays.",
            "The kengtm of the resulting array."
        ],
        "corrections_by_ours": [
            "resulting",
            "arrays",
            "array"
        ],
        "corrections_by_baseline": [
            "koma",
            "nk",
            "kms",
            "kxky",
            "ksp",
            "kvp",
            "kx",
            "kv",
            "bk",
            "kf"
        ]
    },
    {
        "original_word": "Successful",
        "typo_word": "Suscessfuo",
        "original_variable": "waitSuccessful",
        "typo_variable": "waitSuscessfuo",
        "original_code": "public void acquire() throws InterruptedException\n   {\n      synchronized (this)\n      {\n         logAcquire();\n\t\t\t\n         // One user more called acquire, increase users\n         ++m_users;\n         boolean waitSuccessful = false;\n         while (m_allowed <= 0)\n         {\n            waitSuccessful = waitImpl(this);\n            if (!waitSuccessful) \n            {\n               // Dealock was detected, restore status, 'cause it's like a release()\n               // that will probably be never called\n               --m_users;\n               ++m_allowed;\n            }\n         }\n         --m_allowed;\n      }\n   }",
        "modified_code": "public void acquire() throws InterruptedException\n   {\n      synchronized (this)\n      {\n         logAcquire();\n\t\t\t\n         // One user more called acquire, increase users\n         ++m_users;\n         boolean waitSuscessfuo = false;\n         while (m_allowed <= 0)\n         {\n            waitSuscessfuo = waitImpl(this);\n            if (!waitSuscessfuo) \n            {\n               // Dealock was detected, restore status, 'cause it's like a release()\n               // that will probably be never called\n               --m_users;\n               ++m_allowed;\n            }\n         }\n         --m_allowed;\n      }\n   }",
        "explanations_by_ours": [
            "whether to wait for acquiring a lock",
            "whether to wait for the acquire to complete",
            "whether to wait for the acquire"
        ],
        "corrections_by_ours": [
            "whetherSuscessfuo",
            "acquireSuscessfuo",
            "completeSuscessfuo",
            "acquiringSuscessfuo",
            "waitLock",
            "waitWhether",
            "waitAcquire",
            "lockSuscessfuo",
            "waitComplete",
            "waitAcquiring"
        ],
        "corrections_by_baseline": [
            "waitNanos",
            "waitTime",
            "waitingDU",
            "waitRequest",
            "taskTimeout",
            "SLEEP",
            "waitSuccessful",
            "sleepTime",
            "isWaiting",
            "startupLatch"
        ]
    },
    {
        "original_word": "location",
        "typo_word": "locafioj",
        "original_variable": "location",
        "typo_variable": "locafioj",
        "original_code": "private NotificationResponse readFromFile(String filename) {\n        \n        NotificationResponse rslt;\n\n        logger.debug(\"Preparing to read from file:  {}\", filename);\n\n        URL location = getClass().getClassLoader().getResource(filename);\n        if (location != null) {\n            try {\n                File f = new File(location.toURI());\n                rslt =  mapper.readValue(f, NotificationResponse.class);\n            } catch (Exception e) {\n                String msg = \"Failed to read the data file:  \" + location;\n                logger.error(msg, e);\n                rslt = prepareErrorResponse(getName(), msg);\n            }\n        } else {\n            String msg = \"Data file not found:  \" + filename;\n            rslt = prepareErrorResponse(getName(), msg);\n        }\n\n        return rslt;\n\n    }",
        "modified_code": "private NotificationResponse readFromFile(String filename) {\n        \n        NotificationResponse rslt;\n\n        logger.debug(\"Preparing to read from file:  {}\", filename);\n\n        URL locafioj = getClass().getClassLoader().getResource(filename);\n        if (locafioj != null) {\n            try {\n                File f = new File(locafioj.toURI());\n                rslt =  mapper.readValue(f, NotificationResponse.class);\n            } catch (Exception e) {\n                String msg = \"Failed to read the data file:  \" + locafioj;\n                logger.error(msg, e);\n                rslt = prepareErrorResponse(getName(), msg);\n            }\n        } else {\n            String msg = \"Data file not found:  \" + filename;\n            rslt = prepareErrorResponse(getName(), msg);\n        }\n\n        return rslt;\n\n    }",
        "explanations_by_ours": [
            "The location of the file to read.",
            "The file to read from.",
            "The location of the file."
        ],
        "corrections_by_ours": [
            "location",
            "file",
            "read"
        ],
        "corrections_by_baseline": [
            "locmc",
            "iproj",
            "nproj",
            "nj",
            "rj",
            "gnode",
            "yorg",
            "iosp",
            "ncmlLocation",
            "jg"
        ]
    },
    {
        "original_word": "source",
        "typo_word": "soursr",
        "original_variable": "source",
        "typo_variable": "soursr",
        "original_code": "public static int read(final AtomicBuffer buffer, final EntryConsumer entryConsumer)\n    {\n        final int capacity = buffer.capacity();\n\n        int recordsRead = 0;\n        int offset = 0;\n\n        while (offset < capacity)\n        {\n            final long observationCount = buffer.getLongVolatile(offset + OBSERVATION_COUNT_OFFSET);\n            if (observationCount <= 0)\n            {\n                break;\n            }\n\n            ++recordsRead;\n\n            final String channel = buffer.getStringAscii(offset + CHANNEL_OFFSET);\n            final String source = buffer.getStringAscii(offset + CHANNEL_OFFSET + SIZE_OF_INT + channel.length());\n\n            entryConsumer.accept(\n                observationCount,\n                buffer.getLong(offset + TOTAL_BYTES_LOST_OFFSET),\n                buffer.getLong(offset + FIRST_OBSERVATION_OFFSET),\n                buffer.getLong(offset + LAST_OBSERVATION_OFFSET),\n                buffer.getInt(offset + SESSION_ID_OFFSET),\n                buffer.getInt(offset + STREAM_ID_OFFSET),\n                channel,\n                source);\n\n            final int recordLength = CHANNEL_OFFSET + (SIZE_OF_INT * 2) + channel.length() + source.length();\n            offset += BitUtil.align(recordLength, ENTRY_ALIGNMENT);\n        }\n\n        return recordsRead;\n    }",
        "modified_code": "public static int read(final AtomicBuffer buffer, final EntryConsumer entryConsumer)\n    {\n        final int capacity = buffer.capacity();\n\n        int recordsRead = 0;\n        int offset = 0;\n\n        while (offset < capacity)\n        {\n            final long observationCount = buffer.getLongVolatile(offset + OBSERVATION_COUNT_OFFSET);\n            if (observationCount <= 0)\n            {\n                break;\n            }\n\n            ++recordsRead;\n\n            final String channel = buffer.getStringAscii(offset + CHANNEL_OFFSET);\n            final String soursr = buffer.getStringAscii(offset + CHANNEL_OFFSET + SIZE_OF_INT + channel.length());\n\n            entryConsumer.accept(\n                observationCount,\n                buffer.getLong(offset + TOTAL_BYTES_LOST_OFFSET),\n                buffer.getLong(offset + FIRST_OBSERVATION_OFFSET),\n                buffer.getLong(offset + LAST_OBSERVATION_OFFSET),\n                buffer.getInt(offset + SESSION_ID_OFFSET),\n                buffer.getInt(offset + STREAM_ID_OFFSET),\n                channel,\n                soursr);\n\n            final int recordLength = CHANNEL_OFFSET + (SIZE_OF_INT * 2) + channel.length() + soursr.length();\n            offset += BitUtil.align(recordLength, ENTRY_ALIGNMENT);\n        }\n\n        return recordsRead;\n    }",
        "explanations_by_ours": [
            "the soursr of the record",
            "the soursr to use for each record",
            "the soursr of the channel"
        ],
        "corrections_by_ours": [
            "use",
            "channel",
            "record"
        ],
        "corrections_by_baseline": [
            "ihour",
            "sr",
            "urpt",
            "rdr",
            "r_earth",
            "rp",
            "rhop",
            "rotr",
            "neighbour",
            "rtc"
        ]
    },
    {
        "original_word": "buffer",
        "typo_word": "bjfver",
        "original_variable": "buffer",
        "typo_variable": "bjfver",
        "original_code": "private String readFileAsString()\n        throws IOException\n    {\n        FileInputStream is = new FileInputStream( e.source() );\n        try\n        {\n            byte[] buffer = new byte[8192];\n            int len = is.read( buffer );\n            ByteArrayOutputStream out = new ByteArrayOutputStream();\n            while ( len != -1 )\n            {\n                out.write( buffer, 0, len );\n                len = is.read( buffer );\n            }\n            return charsetName != null ? new String( out.toByteArray(), charsetName ) : new String( out.toByteArray() );\n        }\n        finally\n        {\n            is.close();\n        }\n    }",
        "modified_code": "private String readFileAsString()\n        throws IOException\n    {\n        FileInputStream is = new FileInputStream( e.source() );\n        try\n        {\n            byte[] bjfver = new byte[8192];\n            int len = is.read( bjfver );\n            ByteArrayOutputStream out = new ByteArrayOutputStream();\n            while ( len != -1 )\n            {\n                out.write( bjfver, 0, len );\n                len = is.read( bjfver );\n            }\n            return charsetName != null ? new String( out.toByteArray(), charsetName ) : new String( out.toByteArray() );\n        }\n        finally\n        {\n            is.close();\n        }\n    }",
        "explanations_by_ours": [
            "the byte array to read the file as a string",
            "the byte array containing the file contents",
            "the byte array to read the file as a byte array"
        ],
        "corrections_by_ours": [
            "byte",
            "file",
            "contents",
            "containing",
            "string",
            "array",
            "read"
        ],
        "corrections_by_baseline": [
            "bsf",
            "pib",
            "fbase",
            "urib",
            "projbb",
            "lpp",
            "spf",
            "bpv",
            "bv",
            "jshft"
        ]
    },
    {
        "original_word": "length",
        "typo_word": "kengtj",
        "original_variable": "length",
        "typo_variable": "kengtj",
        "original_code": "public void print ()\n  {\n    // Get the longest bar's length.\n    int maxCount = 0;\n    for (int i = 0; i < m_n; ++i)\n    {\n      maxCount = Math.max (maxCount, m_aCounters[i]);\n    }\n\n    // Compute the scaling factor.\n    final float factor = ((float) MAX_BAR_SIZE) / maxCount;\n\n    // Loop to print each bar.\n    for (int i = 0; i < m_n; ++i)\n    {\n      final int b = m_aCounters[i];\n\n      // Interval number.\n      m_aAlignRight.print (i, 2);\n      m_aAlignRight.print (b, 7);\n      System.out.print (\": \");\n\n      // Bar.\n      final int length = Math.round (factor * b);\n      for (int j = 0; j < length; ++j)\n        System.out.print (\"*\");\n      System.out.println ();\n    }\n  }",
        "modified_code": "public void print ()\n  {\n    // Get the longest bar's length.\n    int maxCount = 0;\n    for (int i = 0; i < m_n; ++i)\n    {\n      maxCount = Math.max (maxCount, m_aCounters[i]);\n    }\n\n    // Compute the scaling factor.\n    final float factor = ((float) MAX_BAR_SIZE) / maxCount;\n\n    // Loop to print each bar.\n    for (int i = 0; i < m_n; ++i)\n    {\n      final int b = m_aCounters[i];\n\n      // Interval number.\n      m_aAlignRight.print (i, 2);\n      m_aAlignRight.print (b, 7);\n      System.out.print (\": \");\n\n      // Bar.\n      final int kengtj = Math.round (factor * b);\n      for (int j = 0; j < kengtj; ++j)\n        System.out.print (\"*\");\n      System.out.println ();\n    }\n  }",
        "explanations_by_ours": [
            "The kengtj of the histogram.",
            "The kengtj of each bar.",
            "The kengtj of the bar."
        ],
        "corrections_by_ours": [
            "histogram",
            "bar"
        ],
        "corrections_by_baseline": [
            "nk",
            "j_otp",
            "jg",
            "jbndg",
            "jbeg",
            "kxky",
            "nj",
            "bk",
            "koma",
            "JD"
        ]
    },
    {
        "original_word": "enabled",
        "typo_word": "snablwd",
        "original_variable": "enabled",
        "typo_variable": "snablwd",
        "original_code": "public void uploadNewBundleOnError() {\n    boolean enabled = configuration.get(Constants.UPLOAD_ON_ERROR, Constants.DEFAULT_UPLOAD_ON_ERROR);\n    LOG.info(\"Upload bundle on error: {}\", enabled);\n\n    // We won't upload the bundle unless it's explicitly allowed\n    if(!enabled) {\n      return;\n    }\n\n    try {\n      uploadNewBundle(Collections.emptyList(), BundleType.SUPPORT);\n    } catch (IOException e) {\n      LOG.error(\"Failed to upload error bundle\", e);\n    }\n  }",
        "modified_code": "public void uploadNewBundleOnError() {\n    boolean snablwd = configuration.get(Constants.UPLOAD_ON_ERROR, Constants.DEFAULT_UPLOAD_ON_ERROR);\n    LOG.info(\"Upload bundle on error: {}\", snablwd);\n\n    // We won't upload the bundle unless it's explicitly allowed\n    if(!snablwd) {\n      return;\n    }\n\n    try {\n      uploadNewBundle(Collections.emptyList(), BundleType.SUPPORT);\n    } catch (IOException e) {\n      LOG.error(\"Failed to upload error bundle\", e);\n    }\n  }",
        "explanations_by_ours": [
            "Whether or not to upload the bundle if it is already uploaded.",
            "Whether or not to upload the bundle if it is not already uploaded.",
            "Whether or not the bundle is already uploaded."
        ],
        "corrections_by_ours": [
            "upload",
            "bundle",
            "uploaded",
            "already",
            "whether"
        ],
        "corrections_by_baseline": [
            "wd",
            "pwd",
            "userdir",
            "cwd",
            "appdPassword",
            "tempUsername",
            "pw",
            "ksPasswdCA",
            "try_pw",
            "downdir"
        ]
    },
    {
        "original_word": "next",
        "typo_word": "heat",
        "original_variable": "nextArg",
        "typo_variable": "heatArg",
        "original_code": "protected String toStringArguments()\n    {\n        String result = \"\";\n\n        if (arity > 0)\n        {\n            result += \"[ \";\n\n            for (int i = 0; i < arity; i++)\n            {\n                Term nextArg = arguments[i];\n                result += ((nextArg != null) ? nextArg.toString() : \"<null>\") + ((i < (arity - 1)) ? \", \" : \" \");\n            }\n\n            result += \" ]\";\n        }\n\n        return result;\n    }",
        "modified_code": "protected String toStringArguments()\n    {\n        String result = \"\";\n\n        if (arity > 0)\n        {\n            result += \"[ \";\n\n            for (int i = 0; i < arity; i++)\n            {\n                Term heatArg = arguments[i];\n                result += ((heatArg != null) ? heatArg.toString() : \"<null>\") + ((i < (arity - 1)) ? \", \" : \" \");\n            }\n\n            result += \" ]\";\n        }\n\n        return result;\n    }",
        "explanations_by_ours": [
            "the heat argument",
            "the heat argument to be converted to a string",
            "the heat argument to be converted to a string."
        ],
        "corrections_by_ours": [
            "heatArgument",
            "heatString",
            "argumentArg",
            "convertedArg",
            "heatConverted",
            "stringArg",
            "heatHeat",
            "heatArg"
        ],
        "corrections_by_baseline": [
            "coldp",
            "tempVal",
            "cold0",
            "lam",
            "tempSum",
            "rho",
            "gradVar",
            "temp",
            "temp1",
            "rlam"
        ]
    },
    {
        "original_word": "metadata",
        "typo_word": "netadwta",
        "original_variable": "metadata",
        "typo_variable": "netadwta",
        "original_code": "public static void logLocation(){\n        if (!BMSAnalytics.collectLocation ) {\n            logger.error(\"You must enable collectLocation before location can be logged\");\n            return;\n        }\n\n        if( !locationService.getInitLocationRequests()){\n            logger.error(\"locationService  Initialization has failed\");\n            return;\n        }\n\n        // Create metadata object to log\n        JSONObject metadata = new JSONObject();\n        String hashedUserID = UUID.nameUUIDFromBytes(DEFAULT_USER_ID.getBytes()).toString();\n\n        try {\n            metadata.put(CATEGORY, LOG_LOCATION_KEY);\n            metadata.put(LATITUDE_KEY,locationService.getLatitude());\n            metadata.put(LONGITUDE_KEY,locationService.getLongitude());\n            metadata.put(TIMESTAMP_KEY, (new Date()).getTime());\n            metadata.put(APP_SESSION_ID_KEY, MFPAnalyticsActivityLifecycleListener.getAppSessionID());\n            metadata.put(USER_ID_KEY,hashedUserID);\n\n        } catch (JSONException e) {\n            logger.debug(\"JSONException encountered logging change in user context: \" + e.getMessage());\n        }\n\n        log(metadata);\n\n    }",
        "modified_code": "public static void logLocation(){\n        if (!BMSAnalytics.collectLocation ) {\n            logger.error(\"You must enable collectLocation before location can be logged\");\n            return;\n        }\n\n        if( !locationService.getInitLocationRequests()){\n            logger.error(\"locationService  Initialization has failed\");\n            return;\n        }\n\n        // Create metadata object to log\n        JSONObject netadwta = new JSONObject();\n        String hashedUserID = UUID.nameUUIDFromBytes(DEFAULT_USER_ID.getBytes()).toString();\n\n        try {\n            netadwta.put(CATEGORY, LOG_LOCATION_KEY);\n            netadwta.put(LATITUDE_KEY,locationService.getLatitude());\n            netadwta.put(LONGITUDE_KEY,locationService.getLongitude());\n            netadwta.put(TIMESTAMP_KEY, (new Date()).getTime());\n            netadwta.put(APP_SESSION_ID_KEY, MFPAnalyticsActivityLifecycleListener.getAppSessionID());\n            netadwta.put(USER_ID_KEY,hashedUserID);\n\n        } catch (JSONException e) {\n            logger.debug(\"JSONException encountered logging change in user context: \" + e.getMessage());\n        }\n\n        log(netadwta);\n\n    }",
        "explanations_by_ours": [
            "The metadata object to log",
            "The metadata object to log.",
            "The location information to log"
        ],
        "corrections_by_ours": [
            "metadata",
            "information",
            "object",
            "location",
            "log"
        ],
        "corrections_by_baseline": [
            "wudp",
            "wudp1",
            "wudpNonNull",
            "pjpn",
            "dapcxt",
            "ipd",
            "ncidp",
            "ipb",
            "dapv",
            "pw"
        ]
    },
    {
        "original_word": "success",
        "typo_word": "sucseqs",
        "original_variable": "success",
        "typo_variable": "sucseqs",
        "original_code": "private boolean allHaveSameClassification(String property, Iterable<State> examples)\n    {\n        // Used to hold the value of the first attribute seen.\n        OrdinalAttribute firstAttribute = null;\n\n        // Flag used to indicate that the test passed successfully.\n        boolean success = true;\n\n        // Loop over all the examples.\n        for (State example : examples)\n        {\n            OrdinalAttribute nextAttribute = (OrdinalAttribute) example.getProperty(property);\n\n            // If this is the first example just store its attribute value.\n            if (firstAttribute == null)\n            {\n                firstAttribute = nextAttribute;\n            }\n\n            // Otherwise check if the attribute value does not match the first one in which case the test fails.\n            else if (!nextAttribute.equals(firstAttribute))\n            {\n                success = false;\n\n                break;\n            }\n        }\n\n        // If the test passed then store the matching classification that all the examples have in a memeber variable\n        // from where it can be accessed.\n        if (success)\n        {\n            allClassification = firstAttribute;\n        }\n\n        return success;\n    }",
        "modified_code": "private boolean allHaveSameClassification(String property, Iterable<State> examples)\n    {\n        // Used to hold the value of the first attribute seen.\n        OrdinalAttribute firstAttribute = null;\n\n        // Flag used to indicate that the test passed successfully.\n        boolean sucseqs = true;\n\n        // Loop over all the examples.\n        for (State example : examples)\n        {\n            OrdinalAttribute nextAttribute = (OrdinalAttribute) example.getProperty(property);\n\n            // If this is the first example just store its attribute value.\n            if (firstAttribute == null)\n            {\n                firstAttribute = nextAttribute;\n            }\n\n            // Otherwise check if the attribute value does not match the first one in which case the test fails.\n            else if (!nextAttribute.equals(firstAttribute))\n            {\n                sucseqs = false;\n\n                break;\n            }\n        }\n\n        // If the test passed then store the matching classification that all the examples have in a memeber variable\n        // from where it can be accessed.\n        if (sucseqs)\n        {\n            allClassification = firstAttribute;\n        }\n\n        return sucseqs;\n    }",
        "explanations_by_ours": [
            "true if all the examples have the same classification",
            "true if the test passed successfully",
            "true if all the examples have the same classification, false otherwise"
        ],
        "corrections_by_ours": [
            "successfullyseqs",
            "trueseqs",
            "suctest",
            "sucsuccessfully",
            "sucotherwise",
            "sucfalse",
            "passedseqs",
            "sucpassed",
            "classificationseqs",
            "classification,seqs"
        ],
        "corrections_by_baseline": [
            "seqs",
            "dseq",
            "sseq",
            "cdmseq",
            "seq",
            "seqarray",
            "mnseq",
            "consequences",
            "seqX",
            "arrayseq"
        ]
    },
    {
        "original_word": "total",
        "typo_word": "totqp",
        "original_variable": "total",
        "typo_variable": "totqp",
        "original_code": "public static int indexOf(double[] array, double[] sub, int startIndex, int endIndex) {\n\t\tint sublen = sub.length;\n\t\tif (sublen == 0) {\n\t\t\treturn startIndex;\n\t\t}\n\t\tint total = endIndex - sublen + 1;\n\t\tdouble c = sub[0];\n\t\tmainloop:\n\t\tfor (int i = startIndex; i < total; i++) {\n\t\t\tif (Double.compare(array[i], c) != 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tint j = 1;\n\t\t\tint k = i + 1;\n\t\t\twhile (j < sublen) {\n\t\t\t\tif (Double.compare(sub[j], array[k]) != 0) {\n\t\t\t\t\tcontinue mainloop;\n\t\t\t\t}\n\t\t\t\tj++; k++;\n\t\t\t}\n\t\t\treturn i;\n\t\t}\n\t\treturn -1;\n\t}",
        "modified_code": "public static int indexOf(double[] array, double[] sub, int startIndex, int endIndex) {\n\t\tint sublen = sub.length;\n\t\tif (sublen == 0) {\n\t\t\treturn startIndex;\n\t\t}\n\t\tint totqp = endIndex - sublen + 1;\n\t\tdouble c = sub[0];\n\t\tmainloop:\n\t\tfor (int i = startIndex; i < totqp; i++) {\n\t\t\tif (Double.compare(array[i], c) != 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tint j = 1;\n\t\t\tint k = i + 1;\n\t\t\twhile (j < sublen) {\n\t\t\t\tif (Double.compare(sub[j], array[k]) != 0) {\n\t\t\t\t\tcontinue mainloop;\n\t\t\t\t}\n\t\t\t\tj++; k++;\n\t\t\t}\n\t\t\treturn i;\n\t\t}\n\t\treturn -1;\n\t}",
        "explanations_by_ours": [
            "The total number of elements in the array.",
            "the total number of elements in the array.",
            "the length of the array."
        ],
        "corrections_by_ours": [
            "total",
            "number",
            "length",
            "array",
            "elements"
        ],
        "corrections_by_baseline": [
            "qd",
            "avgQp",
            "cqf",
            "poff",
            "pib",
            "dpe",
            "btpv",
            "qmi",
            "ipb",
            "pnc"
        ]
    },
    {
        "original_word": "match",
        "typo_word": "mqtxh",
        "original_variable": "match",
        "typo_variable": "mqtxh",
        "original_code": "public void processNotContainsException(Map<String, String> parameters) {\n\t\tLoggingEvent match = getMessageWithException(parameters);\n\n\t\tif (match == null) {\n\t\t\tcell.right();\n\t\t} else {\n\t\t\tcell.wrong(match.getThrowableInformation().getThrowableStrRep()[0]);\n\t\t}\n\t}",
        "modified_code": "public void processNotContainsException(Map<String, String> parameters) {\n\t\tLoggingEvent mqtxh = getMessageWithException(parameters);\n\n\t\tif (mqtxh == null) {\n\t\t\tcell.right();\n\t\t} else {\n\t\t\tcell.wrong(mqtxh.getThrowableInformation().getThrowableStrRep()[0]);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the mqtxh",
            "the message with exception",
            "the mqtxh."
        ],
        "corrections_by_ours": [
            "message",
            "exception"
        ],
        "corrections_by_baseline": [
            "qmndx",
            "txnOfy",
            "txn",
            "sgp",
            "clientTX",
            "mcpi",
            "txlist",
            "mctmp",
            "pdx",
            "pconn"
        ]
    },
    {
        "original_word": "parts",
        "typo_word": "pagtd",
        "original_variable": "parts",
        "typo_variable": "pagtd",
        "original_code": "private static String escapeQuotedSubstring(String input) {\n    String[] parts = input.split(\"'\");\n    StringBuilder output = new StringBuilder(input.length() * 2);\n    for (int i = 0; i < parts.length; i++) {\n      if ((i % 2) == 1) {\n        output.append(\"'\").append(parts[i].replace(\"|\", \"\\\\|\")).append(\"'\");\n      } else {\n        output.append(parts[i]);\n      }\n    }\n    return output.toString();\n  }",
        "modified_code": "private static String escapeQuotedSubstring(String input) {\n    String[] pagtd = input.split(\"'\");\n    StringBuilder output = new StringBuilder(input.length() * 2);\n    for (int i = 0; i < pagtd.length; i++) {\n      if ((i % 2) == 1) {\n        output.append(\"'\").append(pagtd[i].replace(\"|\", \"\\\\|\")).append(\"'\");\n      } else {\n        output.append(pagtd[i]);\n      }\n    }\n    return output.toString();\n  }",
        "explanations_by_ours": [
            "the query string to escape",
            "the list of quoted substrings",
            "the list of quoted substrings to escape"
        ],
        "corrections_by_ours": [
            "quoted",
            "list",
            "substrings",
            "string",
            "query",
            "escape"
        ],
        "corrections_by_baseline": [
            "pageroot",
            "pagination",
            "pageData",
            "lpage",
            "nav",
            "pageInfo",
            "page",
            "ppage",
            "pagedPointer",
            "pagedList"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "xkunt",
        "original_variable": "count",
        "typo_variable": "xkunt",
        "original_code": "public static void onResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {\n        if (RequestPermission.requestCode == requestCode) {\n            /* Sort granted and denied permissions in array list */\n            int count = permissions.length;\n\n            List<String> granted = new ArrayList<>(count);\n            List<String> denied = new ArrayList<>(count);\n\n            for (int k = 0; k < count; k++) {\n                resultMap.put(Permission.get(permissions[k]), Result.get(grantResults[k]));\n                if (grantResults[k] == PackageManager.PERMISSION_GRANTED) {\n                    granted.add(permissions[k]);\n\n                } else if (grantResults[k] == PackageManager.PERMISSION_DENIED) {\n                    denied.add(permissions[k]);\n\n                }\n            }\n\n            String[] grantedArray = granted.toArray(new String[granted.size()]);\n            String[] deniedArray = denied.toArray(new String[denied.size()]);\n\n            // forward to invoke annotated methods.\n            try {\n                invokeAnnotatedMethods(resultMap);\n            } catch (IllegalAccessException e) {\n                mLog.e(TAG, e.getMessage(), e);\n            } catch (InvocationTargetException e) {\n                mLog.e(TAG, e.getMessage(), e);\n            }\n\n            /* Send local broadcast on permissions result. */\n            Intent intent = new Intent(PERMISSION_RESULT_BROADCAST);\n            intent.putExtra(GRANTED, grantedArray);\n            intent.putExtra(DENIED, deniedArray);\n            LocalBroadcastManager.getInstance(mActivity).sendBroadcast(intent);\n        }\n    }",
        "modified_code": "public static void onResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {\n        if (RequestPermission.requestCode == requestCode) {\n            /* Sort granted and denied permissions in array list */\n            int xkunt = permissions.length;\n\n            List<String> granted = new ArrayList<>(xkunt);\n            List<String> denied = new ArrayList<>(xkunt);\n\n            for (int k = 0; k < xkunt; k++) {\n                resultMap.put(Permission.get(permissions[k]), Result.get(grantResults[k]));\n                if (grantResults[k] == PackageManager.PERMISSION_GRANTED) {\n                    granted.add(permissions[k]);\n\n                } else if (grantResults[k] == PackageManager.PERMISSION_DENIED) {\n                    denied.add(permissions[k]);\n\n                }\n            }\n\n            String[] grantedArray = granted.toArray(new String[granted.size()]);\n            String[] deniedArray = denied.toArray(new String[denied.size()]);\n\n            // forward to invoke annotated methods.\n            try {\n                invokeAnnotatedMethods(resultMap);\n            } catch (IllegalAccessException e) {\n                mLog.e(TAG, e.getMessage(), e);\n            } catch (InvocationTargetException e) {\n                mLog.e(TAG, e.getMessage(), e);\n            }\n\n            /* Send local broadcast on permissions result. */\n            Intent intent = new Intent(PERMISSION_RESULT_BROADCAST);\n            intent.putExtra(GRANTED, grantedArray);\n            intent.putExtra(DENIED, deniedArray);\n            LocalBroadcastManager.getInstance(mActivity).sendBroadcast(intent);\n        }\n    }",
        "explanations_by_ours": [
            "the xkunt.",
            "the number of permissions.",
            "the number of permissions to grant."
        ],
        "corrections_by_ours": [
            "grant",
            "permissions",
            "number"
        ],
        "corrections_by_baseline": [
            "x0natural",
            "kx",
            "jbit",
            "opp",
            "itrX",
            "jword",
            "uctx",
            "icb",
            "iiword",
            "tweak"
        ]
    },
    {
        "original_word": "sign",
        "typo_word": "cibn",
        "original_variable": "msign",
        "typo_variable": "mcibn",
        "original_code": "@Override\n\tpublic MethodVisitor visitMethod(final int access, final String name, final String desc, final String signature, final String[] exceptions) {\n\t\tMethodSignatureVisitor msign = targetClassInfo.lookupMethodSignatureVisitor(access, name, desc, wd.superReference);\n\t\tif (msign == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\t// ignore all destination constructors\n\t\tif (name.equals(INIT)) {\n\t\t\treturn null;\n\t\t}\n\t\t// ignore all destination static block\n\t\tif (name.equals(CLINIT)) {\n\t\t\treturn null;\n\t\t}\n\n\t\t// skip all static methods\n\t\tif (Modifier.isStatic(access)) {\n\t\t\treturn null;\n\t\t}\n\n\t\treturn applyProxy(msign);\n\t}",
        "modified_code": "@Override\n\tpublic MethodVisitor visitMethod(final int access, final String name, final String desc, final String signature, final String[] exceptions) {\n\t\tMethodSignatureVisitor mcibn = targetClassInfo.lookupMethodSignatureVisitor(access, name, desc, wd.superReference);\n\t\tif (mcibn == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\t// ignore all destination constructors\n\t\tif (name.equals(INIT)) {\n\t\t\treturn null;\n\t\t}\n\t\t// ignore all destination static block\n\t\tif (name.equals(CLINIT)) {\n\t\t\treturn null;\n\t\t}\n\n\t\t// skip all static methods\n\t\tif (Modifier.isStatic(access)) {\n\t\t\treturn null;\n\t\t}\n\n\t\treturn applyProxy(mcibn);\n\t}",
        "explanations_by_ours": [
            "the method visitor",
            "The method visitor."
        ],
        "corrections_by_ours": [
            "method",
            "visitor"
        ],
        "corrections_by_baseline": [
            "nrg",
            "spcid",
            "nfe",
            "ibegin",
            "mc",
            "nf",
            "gincn",
            "rtn",
            "pib",
            "hrsi"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reaulg",
        "original_variable": "result",
        "typo_variable": "reaulg",
        "original_code": "public Owner setOwner() {\n        Element owner = setChild(root, \"owner\", childNames, false); //$NON-NLS-1$\n        Owner result = null;\n        try {\n            result = new Owner(owner);\n        } catch (MalformedElementException e) {\n            Assert.isTrue(false, Policy.bind(\"assert.internalError\")); //$NON-NLS-1$\n        }\n        return result;\n    }",
        "modified_code": "public Owner setOwner() {\n        Element owner = setChild(root, \"owner\", childNames, false); //$NON-NLS-1$\n        Owner reaulg = null;\n        try {\n            reaulg = new Owner(owner);\n        } catch (MalformedElementException e) {\n            Assert.isTrue(false, Policy.bind(\"assert.internalError\")); //$NON-NLS-1$\n        }\n        return reaulg;\n    }",
        "explanations_by_ours": [
            "the reaulg",
            "the new owner",
            "the new owner."
        ],
        "corrections_by_ours": [
            "new",
            "owner"
        ],
        "corrections_by_baseline": [
            "re",
            "andrew",
            "revert",
            "revs",
            "reload",
            "reconciler",
            "gv",
            "reps",
            "baseGC",
            "reals"
        ]
    },
    {
        "original_word": "modified",
        "typo_word": "modigiev",
        "original_variable": "modified",
        "typo_variable": "modigiev",
        "original_code": "public boolean addAll(Collection<? extends E> collection)\n    {\n        if (collection == null)\n        {\n            throw new IllegalArgumentException(\"The 'collection' parameter may not be null.\");\n        }\n\n        if (collection == this)\n        {\n            throw new IllegalArgumentException();\n        }\n\n        boolean modified = false;\n\n        for (E aC : collection)\n        {\n            if (add(aC))\n            {\n                modified = true;\n            }\n        }\n\n        return modified;\n    }",
        "modified_code": "public boolean addAll(Collection<? extends E> collection)\n    {\n        if (collection == null)\n        {\n            throw new IllegalArgumentException(\"The 'collection' parameter may not be null.\");\n        }\n\n        if (collection == this)\n        {\n            throw new IllegalArgumentException();\n        }\n\n        boolean modigiev = false;\n\n        for (E aC : collection)\n        {\n            if (add(aC))\n            {\n                modigiev = true;\n            }\n        }\n\n        return modigiev;\n    }",
        "explanations_by_ours": [
            "<tt>true</tt> if this set is to be modified",
            "<tt>true</tt> if this set is modified, <",
            "<tt>true</tt> if this set is not modified"
        ],
        "corrections_by_ours": [
            "modified",
            "modified,",
            "set",
            "<tt>true<",
            "tt>",
            "<"
        ],
        "corrections_by_baseline": [
            "modifier",
            "lumMod",
            "modz",
            "mod",
            "modifiers",
            "mods",
            "modFunc",
            "iv",
            "zlibed",
            "andrew"
        ]
    },
    {
        "original_word": "Code",
        "typo_word": "Clwe",
        "original_variable": "hashCode",
        "typo_variable": "hashClwe",
        "original_code": "private Symbol addConstantLongOrDouble(final int tag, final long value) {\n    int hashCode = hash(tag, value);\n    Entry entry = get(hashCode);\n    while (entry != null) {\n      if (entry.tag == tag && entry.hashCode == hashCode && entry.data == value) {\n        return entry;\n      }\n      entry = entry.next;\n    }\n    int index = constantPoolCount;\n    constantPool.putByte(tag).putLong(value);\n    constantPoolCount += 2;\n    return put(new Entry(index, tag, value, hashCode));\n  }",
        "modified_code": "private Symbol addConstantLongOrDouble(final int tag, final long value) {\n    int hashClwe = hash(tag, value);\n    Entry entry = get(hashClwe);\n    while (entry != null) {\n      if (entry.tag == tag && entry.hashClwe == hashClwe && entry.data == value) {\n        return entry;\n      }\n      entry = entry.next;\n    }\n    int index = constantPoolCount;\n    constantPool.putByte(tag).putLong(value);\n    constantPoolCount += 2;\n    return put(new Entry(index, tag, value, hashClwe));\n  }",
        "explanations_by_ours": [
            "the hash of the constant.",
            "the hash code of the constant.",
            "the hash of the value."
        ],
        "corrections_by_ours": [
            "hashCode",
            "hashValue",
            "valueClwe",
            "constantClwe",
            "hashConstant",
            "codeClwe",
            "hashHash",
            "hashClwe"
        ],
        "corrections_by_baseline": [
            "cdmHash",
            "pckgHash",
            "md5hash",
            "hash",
            "hashAndSalt",
            "hash1",
            "a1Md5",
            "hmac",
            "hasher",
            "hash2"
        ]
    },
    {
        "original_word": "response",
        "typo_word": "rdspohse",
        "original_variable": "response",
        "typo_variable": "rdspohse",
        "original_code": "public String buildXML()\n    {\n        StringBuilder response = new StringBuilder();\n        response.append(\"<Error\");\n        if(code > 0)\n            response.append(String.format(\" httpcode=\\\"%d\\\"\", code));\n        response.append(\">\\n\");\n        if(message != null)\n            response.append(\"<Message>\" + getMessage() + \"</Message>\\n\");\n        if(context != null)\n            response.append(\"<Context>\" + getContext() + \"</Context>\\n\");\n        if(otherinfo != null)\n            response.append(\"<OtherInformation>\" + getOtherInfo() + \"</OtherInformation>\\n\");\n        return response.toString();\n    }",
        "modified_code": "public String buildXML()\n    {\n        StringBuilder rdspohse = new StringBuilder();\n        rdspohse.append(\"<Error\");\n        if(code > 0)\n            rdspohse.append(String.format(\" httpcode=\\\"%d\\\"\", code));\n        rdspohse.append(\">\\n\");\n        if(message != null)\n            rdspohse.append(\"<Message>\" + getMessage() + \"</Message>\\n\");\n        if(context != null)\n            rdspohse.append(\"<Context>\" + getContext() + \"</Context>\\n\");\n        if(otherinfo != null)\n            rdspohse.append(\"<OtherInformation>\" + getOtherInfo() + \"</OtherInformation>\\n\");\n        return rdspohse.toString();\n    }",
        "explanations_by_ours": [
            "the string builder for the XML.",
            "the string builder to build the XML for.",
            "the string builder to build the XML."
        ],
        "corrections_by_ours": [
            "string",
            "builder",
            "xml",
            "build"
        ],
        "corrections_by_baseline": [
            "rdr",
            "rsf",
            "rds",
            "dsp",
            "srv",
            "rtn",
            "fdsurl",
            "swathLLR",
            "durl",
            "httpproxy"
        ]
    },
    {
        "original_word": "stoke",
        "typo_word": "stile",
        "original_variable": "stoke",
        "typo_variable": "stile",
        "original_code": "protected double[] readAttributeDouble2(Attribute att) {\n    if (att == null) return null;\n\n    double[] val = new double[2];\n    if (att.isString()) {\n      StringTokenizer stoke = new StringTokenizer(att.getStringValue());\n      val[0] = Double.parseDouble(stoke.nextToken());\n      val[1] = stoke.hasMoreTokens() ? Double.parseDouble(stoke.nextToken()) : val[0];\n    } else {\n      val[0] = att.getNumericValue().doubleValue();\n      val[1] = (att.getLength() > 1) ? att.getNumericValue(1).doubleValue() : val[0];\n    }\n    return val;\n  }",
        "modified_code": "protected double[] readAttributeDouble2(Attribute att) {\n    if (att == null) return null;\n\n    double[] val = new double[2];\n    if (att.isString()) {\n      StringTokenizer stile = new StringTokenizer(att.getStringValue());\n      val[0] = Double.parseDouble(stile.nextToken());\n      val[1] = stile.hasMoreTokens() ? Double.parseDouble(stile.nextToken()) : val[0];\n    } else {\n      val[0] = att.getNumericValue().doubleValue();\n      val[1] = (att.getLength() > 1) ? att.getNumericValue(1).doubleValue() : val[0];\n    }\n    return val;\n  }",
        "explanations_by_ours": [
            "the string to parse",
            "the string to read",
            "the string to read from"
        ],
        "corrections_by_ours": [
            "string",
            "parse",
            "read"
        ],
        "corrections_by_baseline": [
            "sfile",
            "stnFile",
            "ufile",
            "ncfile",
            "file",
            "catfile",
            "dstFile",
            "tsFile",
            "dfilename",
            "catFilename"
        ]
    },
    {
        "original_word": "field",
        "typo_word": "fuwld",
        "original_variable": "field",
        "typo_variable": "fuwld",
        "original_code": "public BaseType getVariable(String name) throws NoSuchVariableException {\r\n\r\n        int dotIndex = name.indexOf('.');\r\n\r\n        if (dotIndex != -1) {  // name contains \".\"\r\n            String aggregate = name.substring(0, dotIndex);\r\n            String field = name.substring(dotIndex + 1);\r\n\r\n            BaseType aggRef = getVariable(aggregate);\r\n            if (aggRef instanceof DConstructor)\r\n                return ((DConstructor) aggRef).getVariable(field);  // recurse\r\n            else\r\n                ; // fall through to throw statement\r\n        } else {\r\n            for (Enumeration e = varTemplate.elements(); e.hasMoreElements();) {\r\n                BaseType v = (BaseType) e.nextElement();\r\n                if (v.getEncodedName().equals(name))\r\n                    return v;\r\n            }\r\n        }\r\n        throw new NoSuchVariableException(\"DSequence: getVariable()\");\r\n    }",
        "modified_code": "public BaseType getVariable(String name) throws NoSuchVariableException {\r\n\r\n        int dotIndex = name.indexOf('.');\r\n\r\n        if (dotIndex != -1) {  // name contains \".\"\r\n            String aggregate = name.substring(0, dotIndex);\r\n            String fuwld = name.substring(dotIndex + 1);\r\n\r\n            BaseType aggRef = getVariable(aggregate);\r\n            if (aggRef instanceof DConstructor)\r\n                return ((DConstructor) aggRef).getVariable(fuwld);  // recurse\r\n            else\r\n                ; // fall through to throw statement\r\n        } else {\r\n            for (Enumeration e = varTemplate.elements(); e.hasMoreElements();) {\r\n                BaseType v = (BaseType) e.nextElement();\r\n                if (v.getEncodedName().equals(name))\r\n                    return v;\r\n            }\r\n        }\r\n        throw new NoSuchVariableException(\"DSequence: getVariable()\");\r\n    }",
        "explanations_by_ours": [
            "The name of the variable.",
            "The name of the function.",
            "The name of the variable"
        ],
        "corrections_by_ours": [
            "function",
            "variable",
            "name"
        ],
        "corrections_by_baseline": [
            "WI",
            "wrt",
            "authBldr",
            "wq",
            "FWSP",
            "bld",
            "ldf",
            "sld",
            "lds",
            "gdss"
        ]
    },
    {
        "original_word": "attrs",
        "typo_word": "atyfs",
        "original_variable": "attrs",
        "typo_variable": "atyfs",
        "original_code": "public void\n    sortR(DapNode node, List<DapNode> sortlist)\n    {\n        DapVariable var = null;\n        Map<String, DapAttribute> attrs = null;\n        sortlist.add(node);\n        switch (node.getSort()) {\n        case DATASET:\n        case GROUP:\n            // Walk the decls in this group in order\n            // attributes, dimensions, enums, variables, groups\n            DapGroup group = (DapGroup) node;\n            attrs = group.getAttributes();\n            for(Map.Entry<String, DapAttribute> entry : attrs.entrySet()) {\n                sortR(entry.getValue(), sortlist);\n            }\n            List<DapDimension> dims = group.getDimensions();\n            if(dims != null)\n                for(int i = 0; i < dims.size(); i++) {\n                    sortR(dims.get(i), sortlist);\n                }\n            List<DapEnumeration> enums = group.getEnums();\n            if(enums != null)\n                for(int i = 0; i < enums.size(); i++) {\n                    sortR(enums.get(i), sortlist);\n                }\n            List<DapVariable> vars = group.getVariables();\n            if(vars != null)\n                for(int i = 0; i < vars.size(); i++) {\n                    sortR(vars.get(i), sortlist);\n                }\n            List<DapGroup> groups = group.getGroups();\n            if(groups != null)\n                for(int i = 0; i < groups.size(); i++) {\n                    sortR(groups.get(i), sortlist);\n                }\n            break;\n        case VARIABLE:\n            var = (DapVariable) node;\n            attrs = var.getAttributes();\n            if(attrs != null)\n                for(Map.Entry<String, DapAttribute> entry : attrs.entrySet()) {\n                    sortR(entry.getValue(), sortlist);\n                }\n            List<DapMap> maps = var.getMaps();\n            if(maps != null)\n                for(int i = 0; i < maps.size(); i++) {\n                    sortR(maps.get(i), sortlist);\n                }\n            dims = var.getDimensions();\n            if(dims != null)\n                for(int i = 0; i < dims.size(); i++) {\n                    sortR(dims.get(i), sortlist);\n                }\n            break;\n\n        case ATTRIBUTE:\n            attrs = node.getAttributes();\n            if(attrs != null)\n                for(String name : attrs.keySet()) {\n                    sortR(attrs.get(name), sortlist);\n                }\n            break;\n\n        default:\n            break;\n        }\n    }",
        "modified_code": "public void\n    sortR(DapNode node, List<DapNode> sortlist)\n    {\n        DapVariable var = null;\n        Map<String, DapAttribute> atyfs = null;\n        sortlist.add(node);\n        switch (node.getSort()) {\n        case DATASET:\n        case GROUP:\n            // Walk the decls in this group in order\n            // attributes, dimensions, enums, variables, groups\n            DapGroup group = (DapGroup) node;\n            atyfs = group.getAttributes();\n            for(Map.Entry<String, DapAttribute> entry : atyfs.entrySet()) {\n                sortR(entry.getValue(), sortlist);\n            }\n            List<DapDimension> dims = group.getDimensions();\n            if(dims != null)\n                for(int i = 0; i < dims.size(); i++) {\n                    sortR(dims.get(i), sortlist);\n                }\n            List<DapEnumeration> enums = group.getEnums();\n            if(enums != null)\n                for(int i = 0; i < enums.size(); i++) {\n                    sortR(enums.get(i), sortlist);\n                }\n            List<DapVariable> vars = group.getVariables();\n            if(vars != null)\n                for(int i = 0; i < vars.size(); i++) {\n                    sortR(vars.get(i), sortlist);\n                }\n            List<DapGroup> groups = group.getGroups();\n            if(groups != null)\n                for(int i = 0; i < groups.size(); i++) {\n                    sortR(groups.get(i), sortlist);\n                }\n            break;\n        case VARIABLE:\n            var = (DapVariable) node;\n            atyfs = var.getAttributes();\n            if(atyfs != null)\n                for(Map.Entry<String, DapAttribute> entry : atyfs.entrySet()) {\n                    sortR(entry.getValue(), sortlist);\n                }\n            List<DapMap> maps = var.getMaps();\n            if(maps != null)\n                for(int i = 0; i < maps.size(); i++) {\n                    sortR(maps.get(i), sortlist);\n                }\n            dims = var.getDimensions();\n            if(dims != null)\n                for(int i = 0; i < dims.size(); i++) {\n                    sortR(dims.get(i), sortlist);\n                }\n            break;\n\n        case ATTRIBUTE:\n            atyfs = node.getAttributes();\n            if(atyfs != null)\n                for(String name : atyfs.keySet()) {\n                    sortR(atyfs.get(name), sortlist);\n                }\n            break;\n\n        default:\n            break;\n        }\n    }",
        "explanations_by_ours": [
            "the list of attributes to be sorted in order",
            "the list of attribute names and values to be sorted in order",
            "the list of attribute names and values to be sorted"
        ],
        "corrections_by_ours": [
            "atylist",
            "attributefs",
            "attributesfs",
            "namesfs",
            "atynames",
            "valuesfs",
            "sortedfs",
            "atyvalues",
            "atyattributes",
            "listfs"
        ],
        "corrections_by_baseline": [
            "fs",
            "fsi",
            "intfs",
            "toFs",
            "tryfs",
            "fis",
            "dcs",
            "dks",
            "csys",
            "fsrc"
        ]
    },
    {
        "original_word": "Entities",
        "typo_word": "Emtitues",
        "original_variable": "copyOfEntities",
        "typo_variable": "copyOfEmtitues",
        "original_code": "public T get(String entityName) {\n        notNull(entityName, \"Entity name\");\n        List<T> copyOfEntities = reverse();\n        for (T entity : copyOfEntities) {\n            if(entity.getName().equalsIgnoreCase(entityName)) {\n                return entity;\n            }\n        }\n        return null;\n    }",
        "modified_code": "public T get(String entityName) {\n        notNull(entityName, \"Entity name\");\n        List<T> copyOfEmtitues = reverse();\n        for (T entity : copyOfEmtitues) {\n            if(entity.getName().equalsIgnoreCase(entityName)) {\n                return entity;\n            }\n        }\n        return null;\n    }",
        "explanations_by_ours": [
            "the list of entities",
            "the list of entities to search",
            "the list of entities to check"
        ],
        "corrections_by_ours": [
            "copyOfEntities",
            "checkOfEmtitues",
            "copyOfList",
            "entitiesOfEmtitues",
            "listOfEmtitues",
            "searchOfEmtitues",
            "copyEntitiesEmtitues",
            "copyListEmtitues",
            "copySearchEmtitues",
            "copyCheckEmtitues"
        ],
        "corrections_by_baseline": [
            "removals",
            "smembers",
            "newListOfProcessedBlocks",
            "mbers",
            "hashesOfMessagesToRemove",
            "copierList",
            "executions",
            "writeobs",
            "newEntries",
            "queriesCopy"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nzmw",
        "original_variable": "parameterName",
        "typo_variable": "parameterNzmw",
        "original_code": "private void eatParameter() throws ParseException {\r\n    eatOpenBrace();\r\n    String parameterName = eatString();\r\n    eatComma();\r\n    Double value = eatReal();\r\n    eatCloseBrace();\r\n    parameters.put(parameterName.toLowerCase(), value);\r\n  }",
        "modified_code": "private void eatParameter() throws ParseException {\r\n    eatOpenBrace();\r\n    String parameterNzmw = eatString();\r\n    eatComma();\r\n    Double value = eatReal();\r\n    eatCloseBrace();\r\n    parameters.put(parameterNzmw.toLowerCase(), value);\r\n  }",
        "explanations_by_ours": [
            "the parameter name",
            "the name of the parameter",
            "The parameter name"
        ],
        "corrections_by_ours": [
            "parameterName",
            "nameNzmw",
            "parameterParameter",
            "parameterNzmw"
        ],
        "corrections_by_baseline": [
            "paramInfo",
            "paramAndValue",
            "parameterNumber",
            "parameter",
            "initParamValue",
            "param",
            "tmpParam",
            "paramIdx",
            "paramValue",
            "paramNo"
        ]
    },
    {
        "original_word": "unquoted",
        "typo_word": "ubquotwd",
        "original_variable": "unquoted",
        "typo_variable": "ubquotwd",
        "original_code": "public static String unquote(String str)\n\t{\n\t\tString unquoted = str;\n\t\twhile (unquoted.startsWith(\"\\\"\")) {\n\t\t\tunquoted = unquoted.substring(1);\n\t\t}\n\t\twhile (unquoted.endsWith(\"\\\"\")) {\n\t\t\tunquoted = unquoted.substring(0, unquoted.length() - 1);\n\t\t}\n\t\treturn unquoted;\n\t}",
        "modified_code": "public static String unquote(String str)\n\t{\n\t\tString ubquotwd = str;\n\t\twhile (ubquotwd.startsWith(\"\\\"\")) {\n\t\t\tubquotwd = ubquotwd.substring(1);\n\t\t}\n\t\twhile (ubquotwd.endsWith(\"\\\"\")) {\n\t\t\tubquotwd = ubquotwd.substring(0, ubquotwd.length() - 1);\n\t\t}\n\t\treturn ubquotwd;\n\t}",
        "explanations_by_ours": [
            "the string to unquote",
            "the string to unquote",
            "the unquoted string"
        ],
        "corrections_by_ours": [
            "unquoted",
            "unquote",
            "string"
        ],
        "corrections_by_baseline": [
            "udch",
            "wudpNonNull",
            "wudp1",
            "passwordb",
            "datarun",
            "wudp",
            "dub",
            "btpv",
            "ksPasswdCA",
            "ipb"
        ]
    },
    {
        "original_word": "editor",
        "typo_word": "rditof",
        "original_variable": "editor",
        "typo_variable": "rditof",
        "original_code": "public static Update createLabel(Document document, String label) {\n        Assert.isNotNull(document);\n        Assert.isTrue(document.getOwnerDocument() == null);\n        Assert.isNotNull(label);\n        Element element = create(document, \"update\"); //$NON-NLS-1$\n        try {\n            Update editor = new Update(element);\n            editor.setLabelName(label);\n            return editor;\n        } catch (MalformedElementException e) {\n            Assert.isTrue(false, Policy.bind(\"assert.internalError\")); //$NON-NLS-1$\n            return null; // Never reached.\n        }\n    }",
        "modified_code": "public static Update createLabel(Document document, String label) {\n        Assert.isNotNull(document);\n        Assert.isTrue(document.getOwnerDocument() == null);\n        Assert.isNotNull(label);\n        Element element = create(document, \"update\"); //$NON-NLS-1$\n        try {\n            Update rditof = new Update(element);\n            rditof.setLabelName(label);\n            return rditof;\n        } catch (MalformedElementException e) {\n            Assert.isTrue(false, Policy.bind(\"assert.internalError\")); //$NON-NLS-1$\n            return null; // Never reached.\n        }\n    }",
        "explanations_by_ours": [
            "The Update element to be created.",
            "the Update element to be created.",
            "the Update element."
        ],
        "corrections_by_ours": [
            "created",
            "update",
            "element"
        ],
        "corrections_by_baseline": [
            "rd",
            "itr",
            "eref",
            "ref",
            "newit",
            "rds",
            "refChild",
            "prf",
            "itm",
            "rhs"
        ]
    },
    {
        "original_word": "rank",
        "typo_word": "ramj",
        "original_variable": "effectiverank",
        "typo_variable": "effectiveramj",
        "original_code": "static public int[]\n    computeEffectiveShape(List<DapDimension> dimset)\n    {\n        if(dimset == null || dimset.size() == 0)\n            return new int[0];\n        int effectiverank = dimset.size();\n        int[] shape = new int[effectiverank];\n        for(int i = 0; i < effectiverank; i++) {\n            shape[i] = (int) dimset.get(i).getSize();\n        }\n        return shape;\n    }",
        "modified_code": "static public int[]\n    computeEffectiveShape(List<DapDimension> dimset)\n    {\n        if(dimset == null || dimset.size() == 0)\n            return new int[0];\n        int effectiveramj = dimset.size();\n        int[] shape = new int[effectiveramj];\n        for(int i = 0; i < effectiveramj; i++) {\n            shape[i] = (int) dimset.get(i).getSize();\n        }\n        return shape;\n    }",
        "explanations_by_ours": [
            "the number of dimensions in the DAP",
            "the size of the effectiveramj",
            "the size of the effectiveramj dimension"
        ],
        "corrections_by_ours": [
            "dimension",
            "number",
            "dimensions",
            "size",
            "dap"
        ],
        "corrections_by_baseline": [
            "effectiverank",
            "madvocActionAnnotation",
            "hysteresis",
            "sleeAci",
            "corigin",
            "advice",
            "rmInverse",
            "preInvocationAdvice",
            "aeqm",
            "TOLERENCE"
        ]
    },
    {
        "original_word": "items",
        "typo_word": "itrjs",
        "original_variable": "itemsToRemove",
        "typo_variable": "itrjsToRemove",
        "original_code": "@Override\n  public void removeBackgroundExceptionListener(final OBackgroundExceptionListener listener) {\n    final List<WeakReference<OBackgroundExceptionListener>> itemsToRemove = new ArrayList<>(1);\n\n    for (final WeakReference<OBackgroundExceptionListener> ref : backgroundExceptionListeners) {\n      final OBackgroundExceptionListener l = ref.get();\n      if (l != null && l.equals(listener)) {\n        itemsToRemove.add(ref);\n      }\n    }\n\n    backgroundExceptionListeners.removeAll(itemsToRemove);\n  }",
        "modified_code": "@Override\n  public void removeBackgroundExceptionListener(final OBackgroundExceptionListener listener) {\n    final List<WeakReference<OBackgroundExceptionListener>> itrjsToRemove = new ArrayList<>(1);\n\n    for (final WeakReference<OBackgroundExceptionListener> ref : backgroundExceptionListeners) {\n      final OBackgroundExceptionListener l = ref.get();\n      if (l != null && l.equals(listener)) {\n        itrjsToRemove.add(ref);\n      }\n    }\n\n    backgroundExceptionListeners.removeAll(itrjsToRemove);\n  }",
        "explanations_by_ours": [
            "the weak references to remove",
            "the list of weak references to remove",
            "the weak references to remove from the list"
        ],
        "corrections_by_ours": [
            "itrjsToReferences",
            "referencesToRemove",
            "itrjsRemoveRemove",
            "itrjsToWeak",
            "listToRemove",
            "weakToRemove",
            "removeToRemove",
            "itrjsListRemove",
            "itrjsWeakRemove",
            "itrjsReferencesRemove"
        ],
        "corrections_by_baseline": [
            "disablejsr199",
            "preUninstallActionsStrings",
            "classImportsToRemove",
            "jsons",
            "toRemove",
            "remove",
            "ejbRemove",
            "cPreUninstallActions",
            "removeTags",
            "preUninstallActions"
        ]
    },
    {
        "original_word": "Coords",
        "typo_word": "Cikrds",
        "original_variable": "nodeCoords",
        "typo_variable": "nodeCikrds",
        "original_code": "public Line setupLine(NetcdfDataset dataset, Variable var, int index)\r\n\t{\r\n\t\tthis.points.clear();\r\n\t\tArray xPts = null;\r\n\t\tArray yPts = null;\r\n\t\tVariable nodeCounts = null;\r\n\t\tVariable partNodeCounts = null;\r\n\r\n\t\tList<CoordinateAxis> axes = dataset.getCoordinateAxes();\r\n\t\tCoordinateAxis x = null; CoordinateAxis y = null;\r\n\t\t\r\n\t\tString[] nodeCoords = var.findAttributeIgnoreCase(CF.NODE_COORDINATES).getStringValue().split(\" \");\r\n\t\t\r\n\t\t// Look for x and y\r\n\t\t\r\n\t\tfor(CoordinateAxis ax : axes){\r\n\t\t\t\r\n\t\t\tif(ax.getFullName().equals(nodeCoords[0])) x = ax;\r\n\t\t\tif(ax.getFullName().equals(nodeCoords[1])) y = ax;\r\n\t\t}\r\n\t\t\r\n\t\t// Affirm node counts\r\n\t\tString node_c_str = var.findAttValueIgnoreCase(CF.NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!node_c_str.equals(\"\")) {\r\n\t\t\tnodeCounts = dataset.findVariable(node_c_str);\r\n\t\t}\r\n\t\t\r\n\t\telse return null;\r\n\t\t\r\n\t\t// Affirm part node counts\r\n\t\tString pNodeCoStr = var.findAttValueIgnoreCase(CF.PART_NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!pNodeCoStr.equals(\"\")) {\r\n\t\t\tpartNodeCounts = dataset.findVariable(pNodeCoStr);\r\n\t\t}\r\n\t\t\r\n\t\tSimpleGeometryIndexFinder indexFinder = new SimpleGeometryIndexFinder(nodeCounts);\r\n\t\t\r\n\t\t//Get beginning and ending indicies for this polygon\r\n\t\tint lower = indexFinder.getBeginning(index);\r\n\t\tint upper = indexFinder.getEnd(index);\r\n\r\n\t\t\r\n\t\ttry {\r\n\t\t\t\r\n\t\t\txPts = x.read( lower + \":\" + upper ).reduce();\r\n\t\t\tyPts = y.read( lower + \":\" + upper ).reduce(); \r\n\r\n\t\t\tIndexIterator itrX = xPts.getIndexIterator();\r\n\t\t\tIndexIterator itrY = yPts.getIndexIterator();\r\n\t\t\t\r\n\t\t\t// No multipolygons just read in the whole thing\r\n\t\t\tif(partNodeCounts == null) {\r\n\t\t\t\t\r\n\t\t\t\tthis.next = null;\r\n\t\t\t\tthis.prev = null;\r\n\t\t\t\t\r\n\t\t\t\t// x and y should have the same shape, will add some handling on this\r\n\t\t\t\twhile(itrX.hasNext()) {\r\n\t\t\t\t\tthis.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t}\r\n\t\r\n\t\t\t\tswitch(var.getRank()) {\r\n\t\t\t\t\r\n\t\t\t\tcase 2:\r\n\t\t\t\t\tthis.setData(var.read(CFSimpleGeometryHelper.getSubsetString(var, index)).reduce());\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tcase 1:\r\n\t\t\t\t\tthis.setData(var.read(\"\" + index));\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tdefault:\r\n\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t// If there are multipolygons then take the upper and lower of it and divy it up\r\n\t\t\telse {\r\n\t\t\t\t\r\n\t\t\t\tLine tail = this;\r\n\t\t\t\tArray pnc = partNodeCounts.read();\r\n\t\t\t\tIndexIterator pncItr = pnc.getIndexIterator();\r\n\t\t\t\t\r\n\t\t\t\t// In part node count search for the right index to begin looking for \"part node counts\"\r\n\t\t\t\tint pncInd = 0;\r\n\t\t\t\tint pncEnd = 0;\r\n\t\t\t\twhile(pncEnd < lower)\r\n\t\t\t\t{\r\n\t\t\t\t\tpncEnd += pncItr.getIntNext();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t// Now the index is found, use part node count and the index to find each part node count of each individual part\r\n\t\t\t\twhile(lower < upper) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tint smaller = pnc.getInt(pncInd);\r\n\t\t\t\t\t\r\n\t\t\t\t\twhile(smaller > 0) {\r\n\t\t\t\t\t\ttail.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t\t\tsmaller--;\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\t// Set data of each\t\r\n\t\t\t\t\tswitch(var.getRank()) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tcase 2:\r\n\t\t\t\t\t\ttail.setData(var.read(CFSimpleGeometryHelper.getSubsetString(var, index)).reduce());\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tcase 1:\r\n\t\t\t\t\t\ttail.setData(var.read(\"\" + index));\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tdefault:\r\n\t\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\t\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\tlower += tail.getPoints().size();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t\ttail.setNext(new CFLine());\r\n\t\t\t\t\ttail = tail.getNext();\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t//Clean up\r\n\t\t\t\ttail = tail.getPrev();\r\n\t\t\t\tif(tail != null) tail.setNext(null);\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tcatch (IOException  | InvalidRangeException  | InvalidDataseriesException e) {\r\n\t\t\tcfl.error(e.getMessage());;\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\t\r\n\t\treturn this;\r\n\t}",
        "modified_code": "public Line setupLine(NetcdfDataset dataset, Variable var, int index)\r\n\t{\r\n\t\tthis.points.clear();\r\n\t\tArray xPts = null;\r\n\t\tArray yPts = null;\r\n\t\tVariable nodeCounts = null;\r\n\t\tVariable partNodeCounts = null;\r\n\r\n\t\tList<CoordinateAxis> axes = dataset.getCoordinateAxes();\r\n\t\tCoordinateAxis x = null; CoordinateAxis y = null;\r\n\t\t\r\n\t\tString[] nodeCikrds = var.findAttributeIgnoreCase(CF.NODE_COORDINATES).getStringValue().split(\" \");\r\n\t\t\r\n\t\t// Look for x and y\r\n\t\t\r\n\t\tfor(CoordinateAxis ax : axes){\r\n\t\t\t\r\n\t\t\tif(ax.getFullName().equals(nodeCikrds[0])) x = ax;\r\n\t\t\tif(ax.getFullName().equals(nodeCikrds[1])) y = ax;\r\n\t\t}\r\n\t\t\r\n\t\t// Affirm node counts\r\n\t\tString node_c_str = var.findAttValueIgnoreCase(CF.NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!node_c_str.equals(\"\")) {\r\n\t\t\tnodeCounts = dataset.findVariable(node_c_str);\r\n\t\t}\r\n\t\t\r\n\t\telse return null;\r\n\t\t\r\n\t\t// Affirm part node counts\r\n\t\tString pNodeCoStr = var.findAttValueIgnoreCase(CF.PART_NODE_COUNT, \"\");\r\n\t\t\r\n\t\tif(!pNodeCoStr.equals(\"\")) {\r\n\t\t\tpartNodeCounts = dataset.findVariable(pNodeCoStr);\r\n\t\t}\r\n\t\t\r\n\t\tSimpleGeometryIndexFinder indexFinder = new SimpleGeometryIndexFinder(nodeCounts);\r\n\t\t\r\n\t\t//Get beginning and ending indicies for this polygon\r\n\t\tint lower = indexFinder.getBeginning(index);\r\n\t\tint upper = indexFinder.getEnd(index);\r\n\r\n\t\t\r\n\t\ttry {\r\n\t\t\t\r\n\t\t\txPts = x.read( lower + \":\" + upper ).reduce();\r\n\t\t\tyPts = y.read( lower + \":\" + upper ).reduce(); \r\n\r\n\t\t\tIndexIterator itrX = xPts.getIndexIterator();\r\n\t\t\tIndexIterator itrY = yPts.getIndexIterator();\r\n\t\t\t\r\n\t\t\t// No multipolygons just read in the whole thing\r\n\t\t\tif(partNodeCounts == null) {\r\n\t\t\t\t\r\n\t\t\t\tthis.next = null;\r\n\t\t\t\tthis.prev = null;\r\n\t\t\t\t\r\n\t\t\t\t// x and y should have the same shape, will add some handling on this\r\n\t\t\t\twhile(itrX.hasNext()) {\r\n\t\t\t\t\tthis.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t}\r\n\t\r\n\t\t\t\tswitch(var.getRank()) {\r\n\t\t\t\t\r\n\t\t\t\tcase 2:\r\n\t\t\t\t\tthis.setData(var.read(CFSimpleGeometryHelper.getSubsetString(var, index)).reduce());\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tcase 1:\r\n\t\t\t\t\tthis.setData(var.read(\"\" + index));\r\n\t\t\t\t\tbreak;\r\n\t\t\t\t\t\r\n\t\t\t\tdefault:\r\n\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t// If there are multipolygons then take the upper and lower of it and divy it up\r\n\t\t\telse {\r\n\t\t\t\t\r\n\t\t\t\tLine tail = this;\r\n\t\t\t\tArray pnc = partNodeCounts.read();\r\n\t\t\t\tIndexIterator pncItr = pnc.getIndexIterator();\r\n\t\t\t\t\r\n\t\t\t\t// In part node count search for the right index to begin looking for \"part node counts\"\r\n\t\t\t\tint pncInd = 0;\r\n\t\t\t\tint pncEnd = 0;\r\n\t\t\t\twhile(pncEnd < lower)\r\n\t\t\t\t{\r\n\t\t\t\t\tpncEnd += pncItr.getIntNext();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t// Now the index is found, use part node count and the index to find each part node count of each individual part\r\n\t\t\t\twhile(lower < upper) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tint smaller = pnc.getInt(pncInd);\r\n\t\t\t\t\t\r\n\t\t\t\t\twhile(smaller > 0) {\r\n\t\t\t\t\t\ttail.addPoint(itrX.getDoubleNext(), itrY.getDoubleNext());\r\n\t\t\t\t\t\tsmaller--;\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\t// Set data of each\t\r\n\t\t\t\t\tswitch(var.getRank()) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tcase 2:\r\n\t\t\t\t\t\ttail.setData(var.read(CFSimpleGeometryHelper.getSubsetString(var, index)).reduce());\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tcase 1:\r\n\t\t\t\t\t\ttail.setData(var.read(\"\" + index));\r\n\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t\r\n\t\t\t\t\tdefault:\r\n\t\t\t\t\t\tthrow new InvalidDataseriesException(InvalidDataseriesException.RANK_MISMATCH);\t// currently do not support anything but dataseries and scalar associations\r\n\t\t\t\t\t\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\tlower += tail.getPoints().size();\r\n\t\t\t\t\tpncInd++;\r\n\t\t\t\t\ttail.setNext(new CFLine());\r\n\t\t\t\t\ttail = tail.getNext();\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t//Clean up\r\n\t\t\t\ttail = tail.getPrev();\r\n\t\t\t\tif(tail != null) tail.setNext(null);\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tcatch (IOException  | InvalidRangeException  | InvalidDataseriesException e) {\r\n\t\t\tcfl.error(e.getMessage());;\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\t\r\n\t\treturn this;\r\n\t}",
        "explanations_by_ours": [
            "the list of node coordinate names.",
            "list of node coordinate names.",
            "list of node coordinate names"
        ],
        "corrections_by_ours": [
            "namesCikrds",
            "coordinateCikrds",
            "nodeCoordinate",
            "nodeList",
            "nodeNode",
            "nodeNames",
            "listCikrds",
            "nodeCikrds"
        ],
        "corrections_by_baseline": [
            "jtsNode",
            "treeNode",
            "propsNode",
            "vnode",
            "nodeList",
            "nodeArr",
            "linksNode",
            "nodeSession",
            "nodeIDs",
            "localNode"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "ztwrt",
        "original_variable": "start",
        "typo_variable": "ztwrt",
        "original_code": "@Override\n  public void increment(int hash) {\n    hash = spread(hash);\n    final int start = (hash & 3) << 2;\n\n    // Loop unrolling improves throughput by 5m ops/s\n    final int index0 = indexOf(hash, 0);\n    final int index1 = indexOf(hash, 1);\n    final int index2 = indexOf(hash, 2);\n    final int index3 = indexOf(hash, 3);\n\n    boolean added = incrementAt(index0, start);\n    added |= incrementAt(index1, start + 1);\n    added |= incrementAt(index2, start + 2);\n    added |= incrementAt(index3, start + 3);\n\n    if (added && (++size == sampleSize)) {\n      reset();\n    }\n  }",
        "modified_code": "@Override\n  public void increment(int hash) {\n    hash = spread(hash);\n    final int ztwrt = (hash & 3) << 2;\n\n    // Loop unrolling improves throughput by 5m ops/s\n    final int index0 = indexOf(hash, 0);\n    final int index1 = indexOf(hash, 1);\n    final int index2 = indexOf(hash, 2);\n    final int index3 = indexOf(hash, 3);\n\n    boolean added = incrementAt(index0, ztwrt);\n    added |= incrementAt(index1, ztwrt + 1);\n    added |= incrementAt(index2, ztwrt + 2);\n    added |= incrementAt(index3, ztwrt + 3);\n\n    if (added && (++size == sampleSize)) {\n      reset();\n    }\n  }",
        "explanations_by_ours": [
            "the z-twrt value",
            "the z-twrt value.",
            "the ztwrt of the hash."
        ],
        "corrections_by_ours": [
            "z-twrt",
            "hash",
            "value"
        ],
        "corrections_by_baseline": [
            "dz",
            "wv_z",
            "wrt",
            "z5",
            "dZ",
            "zs",
            "z4",
            "z0",
            "uvz",
            "rt"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rfdult",
        "original_variable": "result",
        "typo_variable": "rfdult",
        "original_code": "@Override\n    protected int run(@Nonnull LinkedList<String> pArgs) throws Exception {\n\n        int rc;\n        try {\n            String result = executor.execute(pArgs);\n            if (outputConsumer != null && result != null) outputConsumer.consumeOutput(stringToStream(result));\n            rc = 0;\n        } catch (GMException e) {\n            if (errorConsumer != null) errorConsumer.consumeError(stringToStream(e.getMessage()));\n            else throw e;\n            rc = 1;\n        }\n        finished(rc);\n        return rc;\n    }",
        "modified_code": "@Override\n    protected int run(@Nonnull LinkedList<String> pArgs) throws Exception {\n\n        int rc;\n        try {\n            String rfdult = executor.execute(pArgs);\n            if (outputConsumer != null && rfdult != null) outputConsumer.consumeOutput(stringToStream(rfdult));\n            rc = 0;\n        } catch (GMException e) {\n            if (errorConsumer != null) errorConsumer.consumeError(stringToStream(e.getMessage()));\n            else throw e;\n            rc = 1;\n        }\n        finished(rc);\n        return rc;\n    }",
        "explanations_by_ours": [
            "The result of the java.util.concurrent.Process",
            "The result of the command."
        ],
        "corrections_by_ours": [
            "result",
            "concurrent",
            "util",
            "process",
            "command",
            "java"
        ],
        "corrections_by_baseline": [
            "rp",
            "rsf",
            "isr",
            "rgp",
            "r",
            "R",
            "rtemp",
            "gfdw",
            "rdr",
            "mefd"
        ]
    },
    {
        "original_word": "enumt",
        "typo_word": "fnuht",
        "original_variable": "enumt",
        "typo_variable": "fnuht",
        "original_code": "public String resolveDocument()\n    throws MalformedURLException, IOException {\n    // If there's a DOCUMENT entry, return it\n\n    catalogManager.debug.message(3, \"resolveDocument\");\n\n    Enumeration enumt = catalogEntries.elements();\n    while (enumt.hasMoreElements()) {\n      CatalogEntry e = (CatalogEntry) enumt.nextElement();\n      if (e.getEntryType() == DOCUMENT) {\n\treturn e.getEntryArg(1); //FIXME check this\n      }\n    }\n\n    return resolveSubordinateCatalogs(DOCUMENT,\n\t\t\t\t      null, null, null);\n  }",
        "modified_code": "public String resolveDocument()\n    throws MalformedURLException, IOException {\n    // If there's a DOCUMENT entry, return it\n\n    catalogManager.debug.message(3, \"resolveDocument\");\n\n    Enumeration fnuht = catalogEntries.elements();\n    while (fnuht.hasMoreElements()) {\n      CatalogEntry e = (CatalogEntry) fnuht.nextElement();\n      if (e.getEntryType() == DOCUMENT) {\n\treturn e.getEntryArg(1); //FIXME check this\n      }\n    }\n\n    return resolveSubordinateCatalogs(DOCUMENT,\n\t\t\t\t      null, null, null);\n  }",
        "explanations_by_ours": [
            "the catalog entries",
            "the entries of this catalog",
            "the entries of the catalog"
        ],
        "corrections_by_ours": [
            "entries",
            "catalog"
        ],
        "corrections_by_baseline": [
            "fn",
            "fnfe",
            "wrp",
            "ht",
            "fnos",
            "pwr",
            "tp",
            "daspath",
            "swathLLR",
            "wd"
        ]
    },
    {
        "original_word": "remaining",
        "typo_word": "eemaininb",
        "original_variable": "remaining",
        "typo_variable": "eemaininb",
        "original_code": "public void wait(Object target, Method method, long maxTime, long sleepTime) {\n        long remaining = maxTime;\n\n        lastCallWasSuccessful = invokeMethod(target, method);\n        while (!lastCallWasSuccessful && remaining > 0) {\n            systemTime.sleep(sleepTime);\n            remaining -= sleepTime;\n            lastCallWasSuccessful = invokeMethod(target, method);\n        }\n\n        lastElapsedTime = maxTime - remaining;\n    }",
        "modified_code": "public void wait(Object target, Method method, long maxTime, long sleepTime) {\n        long eemaininb = maxTime;\n\n        lastCallWasSuccessful = invokeMethod(target, method);\n        while (!lastCallWasSuccessful && eemaininb > 0) {\n            systemTime.sleep(sleepTime);\n            eemaininb -= sleepTime;\n            lastCallWasSuccessful = invokeMethod(target, method);\n        }\n\n        lastElapsedTime = maxTime - eemaininb;\n    }",
        "explanations_by_ours": [
            "the maximum time to wait",
            "the maximum amount of time to wait",
            "the maximum time to wait before returning"
        ],
        "corrections_by_ours": [
            "returning",
            "amount",
            "maximum",
            "wait",
            "time"
        ],
        "corrections_by_baseline": [
            "saltb",
            "eemethod",
            "ibegin",
            "bte",
            "bidi",
            "hrsi",
            "tBTAT",
            "pib",
            "hb",
            "bid"
        ]
    },
    {
        "original_word": "canon",
        "typo_word": "danoj",
        "original_variable": "canon",
        "typo_variable": "danoj",
        "original_code": "boolean createPartitionedIndex(CollectionUpdateType forcePartition, Formatter errlog) throws IOException {\n    if (errlog == null) errlog = new Formatter(); // info will be discarded\n\n    // create partitions from the partitionManager\n    for (MCollection dcmp : partitionManager.makePartitions(forcePartition)) {\n      dcmp.putAuxInfo(FeatureCollectionConfig.AUX_CONFIG, partitionManager.getAuxInfo(FeatureCollectionConfig.AUX_CONFIG));\n      result.addPartition(dcmp);\n    }\n    result.sortPartitions(); // after this the partition list is immutable\n\n    // choose the \"canonical\" partition, aka prototype\n    // only used in copyInfo\n    int n = result.getPartitionSize();\n    if (n == 0) {\n      errlog.format(\"ERR Nothing in this partition = %s%n\", result.showLocation());\n      throw new IllegalStateException(\"Nothing in this partition =\" + result.showLocation());\n    }\n    int idx = partitionManager.getProtoIndex(n);\n    PartitionCollectionMutable.Partition canon = result.getPartition(idx);\n    logger.debug(\"     Using canonical partition {}\", canon.getDcm().getCollectionName());\n\n    try (GribCollectionMutable gc = canon.makeGribCollection()) {  // LOOK open/close canonical partition\n      if (gc == null)\n        throw new IllegalStateException(\"canon.makeGribCollection failed on =\" + result.showLocation() + \" \" + canon.getName() + \"; errs=\" + errlog);\n\n      // copy info from canon gribCollection to result partitionCollection\n      result.copyInfo(gc);\n      result.isPartitionOfPartitions = (gc instanceof PartitionCollectionMutable);\n\n      result.dateRange = gc.dateRange;\n    }\n\n    // check consistency across vert and ens coords\n    // create partitioned variables\n    // partition index is used - do not resort partitions\n    GribCollectionMutable.Dataset ds2D = makeDataset2D(errlog);\n    if (ds2D == null) {\n      errlog.format(\" ERR makeDataset2D failed, index not written on %s%n\", result.showLocation());\n      throw new IllegalStateException(\"makeDataset2D failed, index not written on =\" + result.showLocation() + \"; errs=\" + errlog);\n    }\n\n    // Make Best for a TwoD\n    if (ds2D.gctype == GribCollectionImmutable.Type.TwoD)\n      makeDatasetBest(ds2D, false);\n    //else if (ds2D.gctype == GribCollectionImmutable.Type.MRUTC)\n    //  makeTime2runtime(ds2D, false);\n\n    // ready to write the index file\n    return writeIndex(result, errlog);\n  }",
        "modified_code": "boolean createPartitionedIndex(CollectionUpdateType forcePartition, Formatter errlog) throws IOException {\n    if (errlog == null) errlog = new Formatter(); // info will be discarded\n\n    // create partitions from the partitionManager\n    for (MCollection dcmp : partitionManager.makePartitions(forcePartition)) {\n      dcmp.putAuxInfo(FeatureCollectionConfig.AUX_CONFIG, partitionManager.getAuxInfo(FeatureCollectionConfig.AUX_CONFIG));\n      result.addPartition(dcmp);\n    }\n    result.sortPartitions(); // after this the partition list is immutable\n\n    // choose the \"canonical\" partition, aka prototype\n    // only used in copyInfo\n    int n = result.getPartitionSize();\n    if (n == 0) {\n      errlog.format(\"ERR Nothing in this partition = %s%n\", result.showLocation());\n      throw new IllegalStateException(\"Nothing in this partition =\" + result.showLocation());\n    }\n    int idx = partitionManager.getProtoIndex(n);\n    PartitionCollectionMutable.Partition danoj = result.getPartition(idx);\n    logger.debug(\"     Using canonical partition {}\", danoj.getDcm().getCollectionName());\n\n    try (GribCollectionMutable gc = danoj.makeGribCollection()) {  // LOOK open/close canonical partition\n      if (gc == null)\n        throw new IllegalStateException(\"canon.makeGribCollection failed on =\" + result.showLocation() + \" \" + danoj.getName() + \"; errs=\" + errlog);\n\n      // copy info from canon gribCollection to result partitionCollection\n      result.copyInfo(gc);\n      result.isPartitionOfPartitions = (gc instanceof PartitionCollectionMutable);\n\n      result.dateRange = gc.dateRange;\n    }\n\n    // check consistency across vert and ens coords\n    // create partitioned variables\n    // partition index is used - do not resort partitions\n    GribCollectionMutable.Dataset ds2D = makeDataset2D(errlog);\n    if (ds2D == null) {\n      errlog.format(\" ERR makeDataset2D failed, index not written on %s%n\", result.showLocation());\n      throw new IllegalStateException(\"makeDataset2D failed, index not written on =\" + result.showLocation() + \"; errs=\" + errlog);\n    }\n\n    // Make Best for a TwoD\n    if (ds2D.gctype == GribCollectionImmutable.Type.TwoD)\n      makeDatasetBest(ds2D, false);\n    //else if (ds2D.gctype == GribCollectionImmutable.Type.MRUTC)\n    //  makeTime2runtime(ds2D, false);\n\n    // ready to write the index file\n    return writeIndex(result, errlog);\n  }",
        "explanations_by_ours": [
            "the collection to be partitioned.",
            "the collection to create the partitioned index for.",
            "the collection to create the index for."
        ],
        "corrections_by_ours": [
            "partitioned",
            "collection",
            "index",
            "create"
        ],
        "corrections_by_baseline": [
            "tday",
            "JD",
            "pDate",
            "tmonth",
            "iyear",
            "dt",
            "time2D",
            "cdate",
            "m01",
            "mdate"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "vouht",
        "original_variable": "count",
        "typo_variable": "vouht",
        "original_code": "public java.util.Collection<AudioChannel.Layout>\n  getSupportedAudioChannelLayouts()\n  {\n    java.util.List<AudioChannel.Layout> retval =\n      new java.util.LinkedList<AudioChannel.Layout>();\n    int count = getNumSupportedAudioChannelLayouts();\n    for(int i=0;i<count;i++)\n    {\n      AudioChannel.Layout layout = getSupportedAudioChannelLayout(i);\n      if (layout != AudioChannel.Layout.CH_LAYOUT_UNKNOWN)\n        retval.add(layout);\n    }\n    return retval;\n  }",
        "modified_code": "public java.util.Collection<AudioChannel.Layout>\n  getSupportedAudioChannelLayouts()\n  {\n    java.util.List<AudioChannel.Layout> retval =\n      new java.util.LinkedList<AudioChannel.Layout>();\n    int vouht = getNumSupportedAudioChannelLayouts();\n    for(int i=0;i<vouht;i++)\n    {\n      AudioChannel.Layout layout = getSupportedAudioChannelLayout(i);\n      if (layout != AudioChannel.Layout.CH_LAYOUT_UNKNOWN)\n        retval.add(layout);\n    }\n    return retval;\n  }",
        "explanations_by_ours": [
            "The supported audio channel layouts.",
            "The supported audio channel layouts",
            "The number of supported audio channel layouts."
        ],
        "corrections_by_ours": [
            "layouts",
            "supported",
            "channel",
            "audio",
            "number"
        ],
        "corrections_by_baseline": [
            "hv",
            "wv",
            "vy",
            "ihour",
            "vms",
            "utm",
            "btpv",
            "PV",
            "pv",
            "wy"
        ]
    },
    {
        "original_word": "annotated",
        "typo_word": "abnotatsd",
        "original_variable": "annotated",
        "typo_variable": "abnotatsd",
        "original_code": "static void onNullInjectedIntoNonNullableDependency(Object source, Dependency<?> dependency)\n      throws InternalProvisionException {\n    // Hack to allow null parameters to @Provides methods, for backwards compatibility.\n    if (dependency.getInjectionPoint().getMember() instanceof Method) {\n      Method annotated = (Method) dependency.getInjectionPoint().getMember();\n      if (annotated.isAnnotationPresent(Provides.class)) {\n        switch (InternalFlags.getNullableProvidesOption()) {\n          case ERROR:\n            break; // break out & let the below exception happen\n          case IGNORE:\n            return; // user doesn't care about injecting nulls to non-@Nullables.\n          case WARN:\n            // Warn only once, otherwise we spam logs too much.\n            if (warnedDependencies.add(dependency)) {\n              logger.log(\n                  Level.WARNING,\n                  \"Guice injected null into {0} (a {1}), please mark it @Nullable.\"\n                      + \" Use -Dguice_check_nullable_provides_params=ERROR to turn this into an\"\n                      + \" error.\",\n                  new Object[] {\n                    Messages.formatParameter(dependency), Messages.convert(dependency.getKey())\n                  });\n            }\n            return;\n        }\n      }\n    }\n\n    Object formattedDependency =\n        (dependency.getParameterIndex() != -1)\n            ? Messages.formatParameter(dependency)\n            : StackTraceElements.forMember(dependency.getInjectionPoint().getMember());\n\n    throw InternalProvisionException.create(\n            \"null returned by binding at %s%n but %s is not @Nullable\", source, formattedDependency)\n        .addSource(source);\n  }",
        "modified_code": "static void onNullInjectedIntoNonNullableDependency(Object source, Dependency<?> dependency)\n      throws InternalProvisionException {\n    // Hack to allow null parameters to @Provides methods, for backwards compatibility.\n    if (dependency.getInjectionPoint().getMember() instanceof Method) {\n      Method abnotatsd = (Method) dependency.getInjectionPoint().getMember();\n      if (abnotatsd.isAnnotationPresent(Provides.class)) {\n        switch (InternalFlags.getNullableProvidesOption()) {\n          case ERROR:\n            break; // break out & let the below exception happen\n          case IGNORE:\n            return; // user doesn't care about injecting nulls to non-@Nullables.\n          case WARN:\n            // Warn only once, otherwise we spam logs too much.\n            if (warnedDependencies.add(dependency)) {\n              logger.log(\n                  Level.WARNING,\n                  \"Guice injected null into {0} (a {1}), please mark it @Nullable.\"\n                      + \" Use -Dguice_check_nullable_provides_params=ERROR to turn this into an\"\n                      + \" error.\",\n                  new Object[] {\n                    Messages.formatParameter(dependency), Messages.convert(dependency.getKey())\n                  });\n            }\n            return;\n        }\n      }\n    }\n\n    Object formattedDependency =\n        (dependency.getParameterIndex() != -1)\n            ? Messages.formatParameter(dependency)\n            : StackTraceElements.forMember(dependency.getInjectionPoint().getMember());\n\n    throw InternalProvisionException.create(\n            \"null returned by binding at %s%n but %s is not @Nullable\", source, formattedDependency)\n        .addSource(source);\n  }",
        "explanations_by_ours": [
            "the dependency to check.",
            "the dependency to check for @Provides.",
            "the dependency to check for @Provides"
        ],
        "corrections_by_ours": [
            "provides",
            "dependency",
            "check"
        ],
        "corrections_by_baseline": [
            "AB",
            "dsc",
            "anns",
            "jbeg",
            "bts",
            "dStg",
            "D_TEXT",
            "xblat",
            "bytedata",
            "abbrev"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "requkt",
        "original_variable": "result",
        "typo_variable": "requkt",
        "original_code": "Runnable popFifo () {\n        long _base, _top;\n\n        while (true) {\n            // reading 'base' with volatile semantics emits the necessary barriers to ensure visibility of 'top'\n            _base = UNSAFE.getLongVolatile (this, OFFS_BASE);\n            _top = top;\n\n            if (_base == _top) {\n                // Terminate the loop: the queue is empty.\n                //TODO verify that Hotspot optimizes this kind of return-from-the-middle well\n                return null;\n            }\n\n            // a regular read is OK here: 'push()' emits a store barrier after storing the task, 'popLifo()' modifies it with CAS, and 'popFifo()' does\n            //  a volatile read of 'base' before reading the task\n            final Runnable result = tasks[asArrayindex (_base)];\n\n            // result == null means that another thread concurrently fetched the task from under our nose.\n            // checking _base against a re-read 'base' with volatile semantics avoids wrap-around race - 'base' could have incremented by a multiple of the queue's size between\n            //   our first reading it and fetching the task at that offset, which would cause the increment inside the following if block to significantly decrement it and\n            //   wreak havoc.\n            // CAS ensures that only one thread gets the task, and allows GC when processing is finished\n            if (result != null && _base == UNSAFE.getLongVolatile(this, OFFS_BASE) && UNSAFE.compareAndSwapObject (tasks, taskOffset (_base), result, null)) {\n                UNSAFE.putLongVolatile (this, OFFS_BASE, _base+1); //TODO is 'putOrdered' sufficient?\n                return result;\n            }\n        }\n    }",
        "modified_code": "Runnable popFifo () {\n        long _base, _top;\n\n        while (true) {\n            // reading 'base' with volatile semantics emits the necessary barriers to ensure visibility of 'top'\n            _base = UNSAFE.getLongVolatile (this, OFFS_BASE);\n            _top = top;\n\n            if (_base == _top) {\n                // Terminate the loop: the queue is empty.\n                //TODO verify that Hotspot optimizes this kind of return-from-the-middle well\n                return null;\n            }\n\n            // a regular read is OK here: 'push()' emits a store barrier after storing the task, 'popLifo()' modifies it with CAS, and 'popFifo()' does\n            //  a volatile read of 'base' before reading the task\n            final Runnable requkt = tasks[asArrayindex (_base)];\n\n            // result == null means that another thread concurrently fetched the task from under our nose.\n            // checking _base against a re-read 'base' with volatile semantics avoids wrap-around race - 'base' could have incremented by a multiple of the queue's size between\n            //   our first reading it and fetching the task at that offset, which would cause the increment inside the following if block to significantly decrement it and\n            //   wreak havoc.\n            // CAS ensures that only one thread gets the task, and allows GC when processing is finished\n            if (requkt != null && _base == UNSAFE.getLongVolatile(this, OFFS_BASE) && UNSAFE.compareAndSwapObject (tasks, taskOffset (_base), requkt, null)) {\n                UNSAFE.putLongVolatile (this, OFFS_BASE, _base+1); //TODO is 'putOrdered' sufficient?\n                return requkt;\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the task that was popped off the queue, or null if the queue",
            "the task that was popped off the queue.",
            "the task to pop off the queue, or null if the queue is"
        ],
        "corrections_by_ours": [
            "task",
            "null",
            "queue",
            "queue,",
            "popped",
            "pop"
        ],
        "corrections_by_baseline": [
            "pkt",
            "rgPayload",
            "payload",
            "nreqData",
            "envelope",
            "packet",
            "hrequest",
            "reqs",
            "msgMultipart",
            "mreq"
        ]
    },
    {
        "original_word": "changed",
        "typo_word": "ctangev",
        "original_variable": "changed",
        "typo_variable": "ctangev",
        "original_code": "@Override\n\tpublic boolean addAll(final Collection<? extends E> c) {\n\t\tIterator<? extends E> i = c.iterator();\n\t\tboolean changed = false;\n\t\twhile (i.hasNext()) {\n\t\t\tboolean ret = add(i.next());\n\t\t\tif (!changed) {\n\t\t\t\tchanged = ret;\n\t\t\t}\n\t\t}\n\t\treturn changed;\n\t}",
        "modified_code": "@Override\n\tpublic boolean addAll(final Collection<? extends E> c) {\n\t\tIterator<? extends E> i = c.iterator();\n\t\tboolean ctangev = false;\n\t\twhile (i.hasNext()) {\n\t\t\tboolean ret = add(i.next());\n\t\t\tif (!ctangev) {\n\t\t\t\tctangev = ret;\n\t\t\t}\n\t\t}\n\t\treturn ctangev;\n\t}",
        "explanations_by_ours": [
            "true if all elements are added, false otherwise.",
            "true if all elements are added, false otherwise"
        ],
        "corrections_by_ours": [
            "false",
            "true",
            "added,",
            "otherwise",
            "elements"
        ],
        "corrections_by_baseline": [
            "tmonth",
            "cRange",
            "vgap",
            "vct",
            "month",
            "dateRange",
            "calendarDateRange",
            "vertRange",
            "timeRange",
            "calDateRange"
        ]
    },
    {
        "original_word": "Maps",
        "typo_word": "Mwpw",
        "original_variable": "orderMaps",
        "typo_variable": "orderMwpw",
        "original_code": "private Execution execute(String taskId, String operator, Map<String, Object> args) {\n\t\tif(args == null) args = new HashMap<String, Object>();\n\t\tTask task = task().complete(taskId, operator, args);\n\t\tif(log.isDebugEnabled()) {\n\t\t\tlog.debug(\"\u4efb\u52a1[taskId=\" + taskId + \"]\u5df2\u5b8c\u6210\");\n\t\t}\n\t\tOrder order = query().getOrder(task.getOrderId());\n\t\tAssertHelper.notNull(order, \"\u6307\u5b9a\u7684\u6d41\u7a0b\u5b9e\u4f8b[id=\" + task.getOrderId() + \"]\u5df2\u5b8c\u6210\u6216\u4e0d\u5b58\u5728\");\n\t\torder.setLastUpdator(operator);\n\t\torder.setLastUpdateTime(DateHelper.getTime());\n\t\torder().updateOrder(order);\n\t\t//\u534f\u529e\u4efb\u52a1\u5b8c\u6210\u4e0d\u4ea7\u751f\u6267\u884c\u5bf9\u8c61\n\t\tif(!task.isMajor()) {\n\t\t\treturn null;\n\t\t}\n\t\tMap<String, Object> orderMaps = order.getVariableMap();\n\t\tif(orderMaps != null) {\n\t\t\tfor(Map.Entry<String, Object> entry : orderMaps.entrySet()) {\n\t\t\t\tif(args.containsKey(entry.getKey())) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\targs.put(entry.getKey(), entry.getValue());\n\t\t\t}\n\t\t}\n\t\tProcess process = process().getProcessById(order.getProcessId());\n\t\tExecution execution = new Execution(this, process, order, args);\n\t\texecution.setOperator(operator);\n\t\texecution.setTask(task);\n\t\treturn execution;\n\t}",
        "modified_code": "private Execution execute(String taskId, String operator, Map<String, Object> args) {\n\t\tif(args == null) args = new HashMap<String, Object>();\n\t\tTask task = task().complete(taskId, operator, args);\n\t\tif(log.isDebugEnabled()) {\n\t\t\tlog.debug(\"\u4efb\u52a1[taskId=\" + taskId + \"]\u5df2\u5b8c\u6210\");\n\t\t}\n\t\tOrder order = query().getOrder(task.getOrderId());\n\t\tAssertHelper.notNull(order, \"\u6307\u5b9a\u7684\u6d41\u7a0b\u5b9e\u4f8b[id=\" + task.getOrderId() + \"]\u5df2\u5b8c\u6210\u6216\u4e0d\u5b58\u5728\");\n\t\torder.setLastUpdator(operator);\n\t\torder.setLastUpdateTime(DateHelper.getTime());\n\t\torder().updateOrder(order);\n\t\t//\u534f\u529e\u4efb\u52a1\u5b8c\u6210\u4e0d\u4ea7\u751f\u6267\u884c\u5bf9\u8c61\n\t\tif(!task.isMajor()) {\n\t\t\treturn null;\n\t\t}\n\t\tMap<String, Object> orderMwpw = order.getVariableMap();\n\t\tif(orderMwpw != null) {\n\t\t\tfor(Map.Entry<String, Object> entry : orderMwpw.entrySet()) {\n\t\t\t\tif(args.containsKey(entry.getKey())) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\targs.put(entry.getKey(), entry.getValue());\n\t\t\t}\n\t\t}\n\t\tProcess process = process().getProcessById(order.getProcessId());\n\t\tExecution execution = new Execution(this, process, order, args);\n\t\texecution.setOperator(operator);\n\t\texecution.setTask(task);\n\t\treturn execution;\n\t}",
        "explanations_by_ours": [
            "Map Map Map {@",
            "Map Map String {@",
            "Map"
        ],
        "corrections_by_ours": [
            "orderMap",
            "stringMwpw",
            "{Mwpw",
            "mapMwpw",
            "orderString",
            "order{",
            "orderMwpw"
        ],
        "corrections_by_baseline": [
            "orderNo",
            "order",
            "tempOrder",
            "ccorder",
            "saveorder",
            "ccOrders",
            "orderItem",
            "orders",
            "ccorders",
            "orderStr"
        ]
    },
    {
        "original_word": "squared",
        "typo_word": "equarfd",
        "original_variable": "diffsquared",
        "typo_variable": "diffequarfd",
        "original_code": "private INDArray negativeLogLikelihood(INDArray labels, INDArray alpha, INDArray mu, INDArray sigma) {\n        INDArray labelsMinusMu = labelsMinusMu(labels, mu);\n        INDArray diffsquared = labelsMinusMu.mul(labelsMinusMu).sum(2);\n        INDArray phitimesalphasum = phi(diffsquared, sigma).muli(alpha).sum(1);\n\n        // result = See Bishop(28,29)\n        INDArray result = Transforms.log(phitimesalphasum).negi();\n        return result;\n    }",
        "modified_code": "private INDArray negativeLogLikelihood(INDArray labels, INDArray alpha, INDArray mu, INDArray sigma) {\n        INDArray labelsMinusMu = labelsMinusMu(labels, mu);\n        INDArray diffequarfd = labelsMinusMu.mul(labelsMinusMu).sum(2);\n        INDArray phitimesalphasum = phi(diffequarfd, sigma).muli(alpha).sum(1);\n\n        // result = See Bishop(28,29)\n        INDArray result = Transforms.log(phitimesalphasum).negi();\n        return result;\n    }",
        "explanations_by_ours": [
            "Diffusion function.",
            "Differential deviation.",
            "Diffusion function"
        ],
        "corrections_by_ours": [
            "diffusion",
            "differential",
            "deviation",
            "function"
        ],
        "corrections_by_baseline": [
            "diff2",
            "ndiff",
            "diff",
            "diffX",
            "diffsquared",
            "k2Diff",
            "diffMax",
            "difference",
            "diffLon",
            "absDiff"
        ]
    },
    {
        "original_word": "properties",
        "typo_word": "prkpdrties",
        "original_variable": "properties",
        "typo_variable": "prkpdrties",
        "original_code": "public static void injectIntoProperty( Object object, String path, Object value ) {\n\n\n        String[] properties = propertyPathAsStringArray(path);\n\n        setPropertyValue( object, value, properties );\n    }",
        "modified_code": "public static void injectIntoProperty( Object object, String path, Object value ) {\n\n\n        String[] prkpdrties = propertyPathAsStringArray(path);\n\n        setPropertyValue( object, value, prkpdrties );\n    }",
        "explanations_by_ours": [
            "the path of the properties to be injected",
            "the array of property names to be injected",
            "the path to the property to be injected"
        ],
        "corrections_by_ours": [
            "properties",
            "property",
            "names",
            "path",
            "array",
            "injected"
        ],
        "corrections_by_baseline": [
            "grpids",
            "principals",
            "grids",
            "policies",
            "sttsInd",
            "prs",
            "rids",
            "prf",
            "sbbIDs",
            "tldInfos"
        ]
    },
    {
        "original_word": "answer",
        "typo_word": "amswed",
        "original_variable": "answer",
        "typo_variable": "amswed",
        "original_code": "static NameComponent[] nameToCosName(Name name)\n            throws InvalidNameException {\n        int len = name.size();\n        if (len == 0) {\n            return new NameComponent[0];\n        }\n\n        NameComponent[] answer = new NameComponent[len];\n        for (int i = 0; i < len; i++) {\n            answer[i] = parseComponent(name.get(i));\n        }\n        return answer;\n    }",
        "modified_code": "static NameComponent[] nameToCosName(Name name)\n            throws InvalidNameException {\n        int len = name.size();\n        if (len == 0) {\n            return new NameComponent[0];\n        }\n\n        NameComponent[] amswed = new NameComponent[len];\n        for (int i = 0; i < len; i++) {\n            amswed[i] = parseComponent(name.get(i));\n        }\n        return amswed;\n    }",
        "explanations_by_ours": [
            "the list of NameComponents",
            "the list of NameComponents.",
            "the list of NameComponents to return"
        ],
        "corrections_by_ours": [
            "name",
            "components",
            "list",
            "return"
        ],
        "corrections_by_baseline": [
            "transfered",
            "rsm",
            "amfb",
            "forwarded",
            "requested",
            "tmphandshake",
            "am",
            "posted",
            "emf",
            "rosterPacket"
        ]
    },
    {
        "original_word": "thing",
        "typo_word": "ttiny",
        "original_variable": "thing",
        "typo_variable": "ttiny",
        "original_code": "public <T> Result<T> get(final Key<T> key) {\n\t\tassert !isExecuted();\n\n\t\tSessionValue<T> sv = getSession().get(key);\n\t\tif (sv == null) {\n\t\t\tlog.trace(\"Adding to round (session miss): {}\", key);\n\n\t\t\tthis.pending.add(key.getRaw());\n\n\t\t\tResult<T> result = new ResultCache<T>() {\n\t\t\t\t@Override\n\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\tpublic T nowUncached() {\n\t\t\t\t\t// Because clients could conceivably get() in the middle of our operations (see LoadCollectionRefsTest.specialListWorks()),\n\t\t\t\t\t// we need to check for early execution. This will perform poorly, but at least it will work.\n\t\t\t\t\t//assert Round.this.isExecuted();\n\t\t\t\t\tloadEngine.execute();\n\t\t\t\t\treturn (T)translated.now().get(key);\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic String toString() {\n\t\t\t\t\treturn \"(Fetch result for \" + key + \")\";\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tsv = new SessionValue<>(result, getLoadArrangement());\n\t\t\tgetSession().add(key, sv);\n\n\t\t} else {\n\t\t\tlog.trace(\"Adding to round (session hit): {}\", key);\n\n\t\t\tif (sv.loadWith(getLoadArrangement())) {\n\t\t\t\tlog.trace(\"New load group arrangement, checking for upgrades: {}\", getLoadArrangement());\n\n\t\t\t\t// We are looking at a brand-new arrangement for something that already existed in the session.\n\t\t\t\t// We need to go through any Ref<?>s that might be in need of loading. We find those refs by\n\t\t\t\t// actually saving the entity into a custom SaveContext.\n\t\t\t\tT thing = sv.getResult().now();\n\t\t\t\tif (thing != null) {\n\t\t\t\t\tSaveContext saveCtx = new SaveContext() {\n\t\t\t\t\t\t@Override\n\t\t\t\t\t\tpublic boolean skipLifecycle() {\n\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t@Override\n\t\t\t\t\t\tpublic com.google.cloud.datastore.Key saveRef(Ref<?> value, LoadConditions loadConditions) {\n\t\t\t\t\t\t\tcom.google.cloud.datastore.Key key = super.saveRef(value, loadConditions);\n\n\t\t\t\t\t\t\tif (loadEngine.shouldLoad(loadConditions)) {\n\t\t\t\t\t\t\t\tlog.trace(\"Upgrading key {}\", key);\n\t\t\t\t\t\t\t\tloadEngine.load(value.key());\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\treturn key;\n\t\t\t\t\t\t}\n\t\t\t\t\t};\n\n\t\t\t\t\t// We throw away the saved entity and we are done\n\t\t\t\t\tloadEngine.ofy.factory().getMetadataForEntity(thing).save(thing, saveCtx);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn sv.getResult();\n\t}",
        "modified_code": "public <T> Result<T> get(final Key<T> key) {\n\t\tassert !isExecuted();\n\n\t\tSessionValue<T> sv = getSession().get(key);\n\t\tif (sv == null) {\n\t\t\tlog.trace(\"Adding to round (session miss): {}\", key);\n\n\t\t\tthis.pending.add(key.getRaw());\n\n\t\t\tResult<T> result = new ResultCache<T>() {\n\t\t\t\t@Override\n\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\tpublic T nowUncached() {\n\t\t\t\t\t// Because clients could conceivably get() in the middle of our operations (see LoadCollectionRefsTest.specialListWorks()),\n\t\t\t\t\t// we need to check for early execution. This will perform poorly, but at least it will work.\n\t\t\t\t\t//assert Round.this.isExecuted();\n\t\t\t\t\tloadEngine.execute();\n\t\t\t\t\treturn (T)translated.now().get(key);\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic String toString() {\n\t\t\t\t\treturn \"(Fetch result for \" + key + \")\";\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tsv = new SessionValue<>(result, getLoadArrangement());\n\t\t\tgetSession().add(key, sv);\n\n\t\t} else {\n\t\t\tlog.trace(\"Adding to round (session hit): {}\", key);\n\n\t\t\tif (sv.loadWith(getLoadArrangement())) {\n\t\t\t\tlog.trace(\"New load group arrangement, checking for upgrades: {}\", getLoadArrangement());\n\n\t\t\t\t// We are looking at a brand-new arrangement for something that already existed in the session.\n\t\t\t\t// We need to go through any Ref<?>s that might be in need of loading. We find those refs by\n\t\t\t\t// actually saving the entity into a custom SaveContext.\n\t\t\t\tT ttiny = sv.getResult().now();\n\t\t\t\tif (ttiny != null) {\n\t\t\t\t\tSaveContext saveCtx = new SaveContext() {\n\t\t\t\t\t\t@Override\n\t\t\t\t\t\tpublic boolean skipLifecycle() {\n\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t@Override\n\t\t\t\t\t\tpublic com.google.cloud.datastore.Key saveRef(Ref<?> value, LoadConditions loadConditions) {\n\t\t\t\t\t\t\tcom.google.cloud.datastore.Key key = super.saveRef(value, loadConditions);\n\n\t\t\t\t\t\t\tif (loadEngine.shouldLoad(loadConditions)) {\n\t\t\t\t\t\t\t\tlog.trace(\"Upgrading key {}\", key);\n\t\t\t\t\t\t\t\tloadEngine.load(value.key());\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\treturn key;\n\t\t\t\t\t\t}\n\t\t\t\t\t};\n\n\t\t\t\t\t// We throw away the saved entity and we are done\n\t\t\t\t\tloadEngine.ofy.factory().getMetadataForEntity(ttiny).save(ttiny, saveCtx);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn sv.getResult();\n\t}",
        "explanations_by_ours": [
            "the type of the result.",
            "the type of the result",
            "the type of the result to return."
        ],
        "corrections_by_ours": [
            "typetypeiny",
            "ttype",
            "resultresultiny",
            "returnreturniny",
            "treturn",
            "tresult",
            "ttiny"
        ],
        "corrections_by_baseline": [
            "tt",
            "ttTv",
            "ya",
            "boff",
            "xpp",
            "yt",
            "tdd",
            "tf",
            "ystag",
            "rrank"
        ]
    },
    {
        "original_word": "found",
        "typo_word": "dojnd",
        "original_variable": "found",
        "typo_variable": "dojnd",
        "original_code": "public boolean replaceMemberVariable( Variable newVar) {\n    if (isImmutable()) throw new IllegalStateException(\"Cant modify\");\n    //smembers = null;\n    boolean found = false;\n    for (int i = 0; i < members.size(); i++) {\n      Variable v =  members.get(i);\n      if (v.getShortName() == null)\n          System.out.println(\"BAD null short name\"); // E:/work/ghansham/iasi_20110513_045057_metopa_23676_eps_o.l1_bufr\n      if (v.getShortName().equals( newVar.getShortName())) {\n        members.set( i, newVar);\n        found = true;\n      }\n    }\n\n    if (!found)\n      members.add( newVar);\n    return found;\n  }",
        "modified_code": "public boolean replaceMemberVariable( Variable newVar) {\n    if (isImmutable()) throw new IllegalStateException(\"Cant modify\");\n    //smembers = null;\n    boolean dojnd = false;\n    for (int i = 0; i < members.size(); i++) {\n      Variable v =  members.get(i);\n      if (v.getShortName() == null)\n          System.out.println(\"BAD null short name\"); // E:/work/ghansham/iasi_20110513_045057_metopa_23676_eps_o.l1_bufr\n      if (v.getShortName().equals( newVar.getShortName())) {\n        members.set( i, newVar);\n        dojnd = true;\n      }\n    }\n\n    if (!dojnd)\n      members.add( newVar);\n    return dojnd;\n  }",
        "explanations_by_ours": [
            "true if the variable should be added, false otherwise",
            "true if the variable should be replaced, false otherwise",
            "true if the variable should be added, false otherwise."
        ],
        "corrections_by_ours": [
            "added,jnd",
            "doadded,",
            "replaced,jnd",
            "doreplaced,",
            "otherwisejnd",
            "falsejnd",
            "variablejnd",
            "truejnd",
            "dootherwise",
            "dofalse"
        ],
        "corrections_by_baseline": [
            "JD",
            "mj",
            "jbndg",
            "jcnt",
            "jg",
            "jinc",
            "dud",
            "jshft",
            "dod",
            "projbb"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rrsklt",
        "original_variable": "result",
        "typo_variable": "rrsklt",
        "original_code": "public String composeName(String name, String prefix) throws NamingException\n    {\n        Name result = composeName(new CompositeName(name), new CompositeName(prefix));\n\n        return result.toString();\n    }",
        "modified_code": "public String composeName(String name, String prefix) throws NamingException\n    {\n        Name rrsklt = composeName(new CompositeName(name), new CompositeName(prefix));\n\n        return rrsklt.toString();\n    }",
        "explanations_by_ours": [
            "the name to compose",
            "the name to be composed",
            "the name to compose."
        ],
        "corrections_by_ours": [
            "compose",
            "name",
            "composed"
        ],
        "corrections_by_baseline": [
            "rslt",
            "rsf",
            "rsm",
            "srcc",
            "hrsi",
            "rsmd",
            "rdr",
            "rs",
            "rgp",
            "srclen"
        ]
    },
    {
        "original_word": "Number",
        "typo_word": "Numhed",
        "original_variable": "getNumber",
        "typo_variable": "getNumhed",
        "original_code": "@Transactional(readOnly = true)\n\tpublic Contact getRandomContact() {\n\t\tlogger.debug(\"Returning random contact\");\n\n\t\tRandom rnd = new Random();\n\t\tList<Contact> contacts = contactDao.findAll();\n\t\tint getNumber = rnd.nextInt(contacts.size());\n\n\t\treturn contacts.get(getNumber);\n\t}",
        "modified_code": "@Transactional(readOnly = true)\n\tpublic Contact getRandomContact() {\n\t\tlogger.debug(\"Returning random contact\");\n\n\t\tRandom rnd = new Random();\n\t\tList<Contact> contacts = contactDao.findAll();\n\t\tint getNumhed = rnd.nextInt(contacts.size());\n\n\t\treturn contacts.get(getNumhed);\n\t}",
        "explanations_by_ours": [
            "the number of the contact to return",
            "the number of the random contact",
            "the get numhed"
        ],
        "corrections_by_ours": [
            "getNumber",
            "returnNumhed",
            "numhedNumhed",
            "numberNumhed",
            "getGet",
            "contactNumhed",
            "randomNumhed",
            "getContact",
            "getRandom",
            "getReturn"
        ],
        "corrections_by_baseline": [
            "getNumber",
            "isGetIncrement",
            "getBatch",
            "getStartMusicRequest",
            "queryMaxIdBirth",
            "pckgHash",
            "identifiedGetIncrement",
            "updateTokenCount",
            "checkSum",
            "nstrikes"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "efsult",
        "original_variable": "result",
        "typo_variable": "efsult",
        "original_code": "public boolean removeFooterView(View v) {\n\t\tif (mFooterViewInfos.size() > 0) {\n\t\t\tboolean result = false;\n\t\t\tif (mAdapter != null && ((FooterViewGridAdapter) mAdapter).removeFooter(v)) {\n\t\t\t\tnotifiyChanged();\n\t\t\t\tresult = true;\n\t\t\t}\n\t\t\tremoveFixedViewInfo(v, mFooterViewInfos);\n\t\t\treturn result;\n\t\t}\n\t\treturn false;\n\t}",
        "modified_code": "public boolean removeFooterView(View v) {\n\t\tif (mFooterViewInfos.size() > 0) {\n\t\t\tboolean efsult = false;\n\t\t\tif (mAdapter != null && ((FooterViewGridAdapter) mAdapter).removeFooter(v)) {\n\t\t\t\tnotifiyChanged();\n\t\t\t\tefsult = true;\n\t\t\t}\n\t\t\tremoveFixedViewInfo(v, mFooterViewInfos);\n\t\t\treturn efsult;\n\t\t}\n\t\treturn false;\n\t}",
        "explanations_by_ours": [
            "<code>true</code> if the view was removed, <",
            "<code>true</code> if the view was removed successfully,",
            "<code>true</code> if the view has been removed,"
        ],
        "corrections_by_ours": [
            "successfully,",
            "<code>true<",
            "removed",
            "removed,",
            "view",
            "<",
            "code>"
        ],
        "corrections_by_baseline": [
            "ef",
            "mefd",
            "scalef",
            "etf",
            "dstruct",
            "acf",
            "ifac",
            "icf",
            "iresult",
            "ecint"
        ]
    },
    {
        "original_word": "validated",
        "typo_word": "vslisated",
        "original_variable": "validated",
        "typo_variable": "vslisated",
        "original_code": "private String validateColor(String color) {\n        String validated = color;\n        if (color != null) {\n            if (!color.startsWith(\"#\")) {\n                validated = \"#\" + color;\n            }\n            if (!colorPattern.matcher(validated).matches()) {\n                throw new GeoPackageException(\n                        \"Color must be in hex format #RRGGBB or #RGB, invalid value: \"\n                                + color);\n            }\n            validated = validated.toUpperCase();\n        }\n        return validated;\n    }",
        "modified_code": "private String validateColor(String color) {\n        String vslisated = color;\n        if (color != null) {\n            if (!color.startsWith(\"#\")) {\n                vslisated = \"#\" + color;\n            }\n            if (!colorPattern.matcher(vslisated).matches()) {\n                throw new GeoPackageException(\n                        \"Color must be in hex format #RRGGBB or #RGB, invalid value: \"\n                                + color);\n            }\n            vslisated = vslisated.toUpperCase();\n        }\n        return vslisated;\n    }",
        "explanations_by_ours": [
            "the vslisated color",
            "the color",
            "the vslisated"
        ],
        "corrections_by_ours": [
            "color"
        ],
        "corrections_by_baseline": [
            "vf",
            "vse",
            "vald",
            "v",
            "V",
            "vb",
            "vs",
            "azim",
            "isProjected",
            "vn"
        ]
    },
    {
        "original_word": "replaced",
        "typo_word": "geplaces",
        "original_variable": "replaced",
        "typo_variable": "geplaces",
        "original_code": "public Object put(Object key, Object value)\n    {\n        // Synchronize on the cache to ensure its integrity in a multi-threaded environment.\n        synchronized (cache)\n        {\n            // Create a new ElementMonitor in the cache for the new element.\n            // Timestamp the new element with the present time.\n            long t = System.currentTimeMillis();\n\n            // Extract the element value out of the replaced element monitor if any.\n            ElementMonitor replaced = (ElementMonitor) cache.put(key, new ElementMonitor(value, t));\n\n            if (replaced != null)\n            {\n                return replaced.element;\n            }\n            else\n            {\n                return null;\n            }\n        }\n    }",
        "modified_code": "public Object put(Object key, Object value)\n    {\n        // Synchronize on the cache to ensure its integrity in a multi-threaded environment.\n        synchronized (cache)\n        {\n            // Create a new ElementMonitor in the cache for the new element.\n            // Timestamp the new element with the present time.\n            long t = System.currentTimeMillis();\n\n            // Extract the element value out of the replaced element monitor if any.\n            ElementMonitor geplaces = (ElementMonitor) cache.put(key, new ElementMonitor(value, t));\n\n            if (geplaces != null)\n            {\n                return geplaces.element;\n            }\n            else\n            {\n                return null;\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the element monitor that will be used to extract the element value from the",
            "the element monitor that will be used to extract the value from the cached",
            "the element monitor that will be used to extract the new value from the"
        ],
        "corrections_by_ours": [
            "newplaces",
            "gecached",
            "gevalue",
            "geelement",
            "usedplaces",
            "valueplaces",
            "cachedplaces",
            "geused",
            "genew",
            "elementplaces"
        ],
        "corrections_by_baseline": [
            "locations",
            "fileStations",
            "googleTiles",
            "aces",
            "locs",
            "discoveries",
            "lats",
            "automats",
            "geometries",
            "businessRemotes"
        ]
    },
    {
        "original_word": "connection",
        "typo_word": "cojnectiln",
        "original_variable": "connection",
        "typo_variable": "cojnectiln",
        "original_code": "private void sendMessage(int port, String message) {\n    Socket connection = null;\n    try {\n      connection = new Socket(\"localhost\", port);\n      IO.writeContents(message, connection.getOutputStream());\n      if (debug) System.out.println(\" sent message \" + message);\n\n    }  catch (IOException e) {\n      System.err.println(e);\n      e.printStackTrace();\n\n    } finally {\n      try { if (connection != null) connection.close(); }\n      catch (IOException e) {}\n    }\n\n  }",
        "modified_code": "private void sendMessage(int port, String message) {\n    Socket cojnectiln = null;\n    try {\n      cojnectiln = new Socket(\"localhost\", port);\n      IO.writeContents(message, cojnectiln.getOutputStream());\n      if (debug) System.out.println(\" sent message \" + message);\n\n    }  catch (IOException e) {\n      System.err.println(e);\n      e.printStackTrace();\n\n    } finally {\n      try { if (cojnectiln != null) cojnectiln.close(); }\n      catch (IOException e) {}\n    }\n\n  }",
        "explanations_by_ours": [
            "The socket to connect to.",
            "The socket to use to connect to the remote server.",
            "The socket to use for sending the message."
        ],
        "corrections_by_ours": [
            "connect",
            "socket",
            "sending",
            "use",
            "message",
            "remote",
            "server"
        ],
        "corrections_by_baseline": [
            "iproj",
            "mcloc",
            "jconn",
            "corbaloc",
            "clusterConnection",
            "nctx",
            "conj",
            "pco",
            "sgrm",
            "clients"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resilr",
        "original_variable": "result",
        "typo_variable": "resilr",
        "original_code": "Runnable popLifo () {\n        final long _top = top;\n        final Runnable result = tasks[asArrayindex (_top-1)];\n        if (result == null) {\n            // The queue is empty. It is possible for the queue to be empty even if the previous unprotected read does not return null, but\n            //  it will only ever return null if the queue really is empty: New entries are only added by the owning thread, and this method\n            //  'popLifo()' is also only ever called by the owning thread.\n            return null;\n        }\n\n        if (! UNSAFE.compareAndSwapObject (tasks, taskOffset (_top-1), result, null)) {\n            // The CAS operation failing means that another thread pulled the top-most item from the queue, so the queue is now definitely\n            //  empty. It also null'ed out the task in the array if it was previously available, allowing to to be GC'ed when processing is\n            //  finished.\n            return null;\n        }\n\n        // Since 'result' is not null, and was not previously consumed by another thread, we can safely consume it --> decrement 'top'\n        UNSAFE.putOrderedLong (this, OFFS_TOP, _top-1);\n        return result;\n    }",
        "modified_code": "Runnable popLifo () {\n        final long _top = top;\n        final Runnable resilr = tasks[asArrayindex (_top-1)];\n        if (resilr == null) {\n            // The queue is empty. It is possible for the queue to be empty even if the previous unprotected read does not return null, but\n            //  it will only ever return null if the queue really is empty: New entries are only added by the owning thread, and this method\n            //  'popLifo()' is also only ever called by the owning thread.\n            return null;\n        }\n\n        if (! UNSAFE.compareAndSwapObject (tasks, taskOffset (_top-1), resilr, null)) {\n            // The CAS operation failing means that another thread pulled the top-most item from the queue, so the queue is now definitely\n            //  empty. It also null'ed out the task in the array if it was previously available, allowing to to be GC'ed when processing is\n            //  finished.\n            return null;\n        }\n\n        // Since 'result' is not null, and was not previously consumed by another thread, we can safely consume it --> decrement 'top'\n        UNSAFE.putOrderedLong (this, OFFS_TOP, _top-1);\n        return resilr;\n    }",
        "explanations_by_ours": [
            "the item to be removed from the queue, or null if the queue",
            "the task to return, or null if the queue is empty",
            "the item to be removed, or null if the queue is empty"
        ],
        "corrections_by_ours": [
            "removed",
            "return,",
            "removed,",
            "null",
            "task",
            "empty",
            "queue",
            "queue,",
            "item"
        ],
        "corrections_by_baseline": [
            "res",
            "resul",
            "rp",
            "r",
            "R",
            "isr",
            "sr",
            "rdr",
            "gateR",
            "rgp"
        ]
    },
    {
        "original_word": "name",
        "typo_word": "najf",
        "original_variable": "strPathname",
        "typo_variable": "strPathnajf",
        "original_code": "public void initTransfer(Properties properties)\n\t{\n\t\tsuper.initTransfer(properties);\n\t\tString strPathname = properties.getProperty(LOG_FILENAME_PARAM);\n\t\tif (strPathname != null)\n\t\t\tif (strPathname.length() > 0)\n\t\t\t{\n\t\t\t\ttry {\n\t\t\t\t\tFileOutputStream fileOut = new FileOutputStream(strPathname);\n\t\t\t\t\tstreamOut = new PrintStream(fileOut);\n\t\t\t\t} catch (FileNotFoundException e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\t\tif (streamOut == null)\n\t\t\tstreamOut = System.out;\n\t\t\n\t\tString strSelected = properties.getProperty(CALC_FILE_LENGTH_PARAM);\n\t\tif (FALSE.equalsIgnoreCase(strSelected))\n\t\t\tgetFileLength = false;\n\t\telse\n\t\t\tgetFileLength = true;\n\t}",
        "modified_code": "public void initTransfer(Properties properties)\n\t{\n\t\tsuper.initTransfer(properties);\n\t\tString strPathnajf = properties.getProperty(LOG_FILENAME_PARAM);\n\t\tif (strPathnajf != null)\n\t\t\tif (strPathnajf.length() > 0)\n\t\t\t{\n\t\t\t\ttry {\n\t\t\t\t\tFileOutputStream fileOut = new FileOutputStream(strPathnajf);\n\t\t\t\t\tstreamOut = new PrintStream(fileOut);\n\t\t\t\t} catch (FileNotFoundException e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\t\tif (streamOut == null)\n\t\t\tstreamOut = System.out;\n\t\t\n\t\tString strSelected = properties.getProperty(CALC_FILE_LENGTH_PARAM);\n\t\tif (FALSE.equalsIgnoreCase(strSelected))\n\t\t\tgetFileLength = false;\n\t\telse\n\t\t\tgetFileLength = true;\n\t}",
        "explanations_by_ours": [
            "The log file to write to.",
            "The file path to write to.",
            "The log file path."
        ],
        "corrections_by_ours": [
            "strPath",
            "pathPathnajf",
            "writePathnajf",
            "filePathnajf",
            "logPathnajf",
            "strWrite",
            "strFile",
            "strLog",
            "strPathnajf"
        ],
        "corrections_by_baseline": [
            "strFTPPath",
            "strPathname",
            "strPath",
            "strRelativeFileName",
            "strBaseURL",
            "dodspath",
            "ddfPath",
            "mdpath",
            "urlPath",
            "swathName"
        ]
    },
    {
        "original_word": "unit",
        "typo_word": "jhit",
        "original_variable": "unitSize",
        "typo_variable": "jhitSize",
        "original_code": "private static void buildDynamicRowForRefPtgBase(final Object ptg,\r\n\t\t\tfinal byte originalOperandClass, final List<SerialRow> rowList,\r\n\t\t\tfinal Ptg[] newPtg, final boolean includeParenthesis) {\r\n\t\tRefPtgBase refPtg = (RefPtgBase) ptg;\r\n\t\tint unitSize = 1;\r\n\t\tif (includeParenthesis) {\r\n\t\t\tunitSize = 2;\r\n\t\t}\r\n\t\tfor (int i = 0; i < rowList.size(); i++) {\r\n\t\t\tRow row = rowList.get(i).getRow();\r\n\t\t\tif (refPtg instanceof Ref3DPxg) {\r\n\t\t\t\tRef3DPxg ref3dPxg = (Ref3DPxg) refPtg;\r\n\t\t\t\tRef3DPxg new3dpxg = new Ref3DPxg(\r\n\t\t\t\t\t\tref3dPxg.getExternalWorkbookNumber(),\r\n\t\t\t\t\t\tnew SheetIdentifier(null,\r\n\t\t\t\t\t\t\t\tnew NameIdentifier(ref3dPxg.getSheetName(),\r\n\t\t\t\t\t\t\t\t\t\tfalse)),\r\n\t\t\t\t\t\tnew CellReference(row.getRowNum(),\r\n\t\t\t\t\t\t\t\tref3dPxg.getColumn()));\r\n\t\t\t\tnew3dpxg.setClass(originalOperandClass);\r\n\t\t\t\tnew3dpxg.setColRelative(ref3dPxg.isColRelative());\r\n\t\t\t\tnew3dpxg.setRowRelative(ref3dPxg.isRowRelative());\r\n\t\t\t\tnew3dpxg.setLastSheetName(ref3dPxg.getLastSheetName());\r\n\t\t\t\tnewPtg[i * unitSize] = new3dpxg;\r\n\t\t\t} else {\r\n\t\t\t\tRefPtgBase refPtgBase = refPtg;\r\n\t\t\t\tnewPtg[i * unitSize] = new RefPtg(row.getRowNum(),\r\n\t\t\t\t\t\trefPtgBase.getColumn(), refPtgBase.isRowRelative(),\r\n\t\t\t\t\t\trefPtgBase.isColRelative());\r\n\t\t\t}\r\n\t\t\tif ((unitSize == 2) && (i < (rowList.size() - 1))) {\r\n\t\t\t\tnewPtg[i * unitSize + 1] = ParenthesisPtg.instance;\r\n\t\t\t}\r\n\t\t}\r\n\t}",
        "modified_code": "private static void buildDynamicRowForRefPtgBase(final Object ptg,\r\n\t\t\tfinal byte originalOperandClass, final List<SerialRow> rowList,\r\n\t\t\tfinal Ptg[] newPtg, final boolean includeParenthesis) {\r\n\t\tRefPtgBase refPtg = (RefPtgBase) ptg;\r\n\t\tint jhitSize = 1;\r\n\t\tif (includeParenthesis) {\r\n\t\t\tjhitSize = 2;\r\n\t\t}\r\n\t\tfor (int i = 0; i < rowList.size(); i++) {\r\n\t\t\tRow row = rowList.get(i).getRow();\r\n\t\t\tif (refPtg instanceof Ref3DPxg) {\r\n\t\t\t\tRef3DPxg ref3dPxg = (Ref3DPxg) refPtg;\r\n\t\t\t\tRef3DPxg new3dpxg = new Ref3DPxg(\r\n\t\t\t\t\t\tref3dPxg.getExternalWorkbookNumber(),\r\n\t\t\t\t\t\tnew SheetIdentifier(null,\r\n\t\t\t\t\t\t\t\tnew NameIdentifier(ref3dPxg.getSheetName(),\r\n\t\t\t\t\t\t\t\t\t\tfalse)),\r\n\t\t\t\t\t\tnew CellReference(row.getRowNum(),\r\n\t\t\t\t\t\t\t\tref3dPxg.getColumn()));\r\n\t\t\t\tnew3dpxg.setClass(originalOperandClass);\r\n\t\t\t\tnew3dpxg.setColRelative(ref3dPxg.isColRelative());\r\n\t\t\t\tnew3dpxg.setRowRelative(ref3dPxg.isRowRelative());\r\n\t\t\t\tnew3dpxg.setLastSheetName(ref3dPxg.getLastSheetName());\r\n\t\t\t\tnewPtg[i * jhitSize] = new3dpxg;\r\n\t\t\t} else {\r\n\t\t\t\tRefPtgBase refPtgBase = refPtg;\r\n\t\t\t\tnewPtg[i * jhitSize] = new RefPtg(row.getRowNum(),\r\n\t\t\t\t\t\trefPtgBase.getColumn(), refPtgBase.isRowRelative(),\r\n\t\t\t\t\t\trefPtgBase.isColRelative());\r\n\t\t\t}\r\n\t\t\tif ((jhitSize == 2) && (i < (rowList.size() - 1))) {\r\n\t\t\t\tnewPtg[i * jhitSize + 1] = ParenthesisPtg.instance;\r\n\t\t\t}\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "the jhit size",
            "the j hit size",
            "the jhit size."
        ],
        "corrections_by_ours": [
            "jsizeSize",
            "jhitHit",
            "hithitSize",
            "sizehitSize",
            "jjSize",
            "jhitJ",
            "jhitSize"
        ],
        "corrections_by_baseline": [
            "resultSize",
            "ucLength",
            "REC_SIZE",
            "lenSize",
            "fqnSize",
            "sumLen",
            "len_inc",
            "runLength",
            "eSize",
            "compressedSize"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "tecult",
        "original_variable": "result",
        "typo_variable": "tecult",
        "original_code": "private boolean parseJspAttributeAndBody( Node parent, String tag, \n        String bodyType ) \n        throws JasperException\n    {\n        boolean result = false;\n        \n        if( reader.matchesOptionalSpacesFollowedBy( \"<jsp:attribute\" ) ) {\n            // May be an EmptyBody, depending on whether\n            // There's a \"<jsp:body\" before the ETag\n            \n            // First, parse <jsp:attribute> elements:\n            parseNamedAttributes( parent );\n            \n            result = true;\n        }\n        \n        if( reader.matchesOptionalSpacesFollowedBy( \"<jsp:body\" ) ) {\n            // ActionBody\n            parseJspBody( parent, bodyType );\n            reader.skipSpaces();\n            if( !reader.matchesETag( tag ) ) {\n                err.jspError(reader.mark(), \"jsp.error.unterminated\", \n                    \"&lt;\" + tag );\n            }\n            \n            result = true;\n        }\n        else if( result && !reader.matchesETag( tag ) ) {\n            // If we have <jsp:attribute> but something other than\n            // <jsp:body> or the end tag, translation error.\n            err.jspError(reader.mark(), \"jsp.error.jspbody.required\", \n                \"&lt;\" + tag );\n        }\n        \n        return result;\n    }",
        "modified_code": "private boolean parseJspAttributeAndBody( Node parent, String tag, \n        String bodyType ) \n        throws JasperException\n    {\n        boolean tecult = false;\n        \n        if( reader.matchesOptionalSpacesFollowedBy( \"<jsp:attribute\" ) ) {\n            // May be an EmptyBody, depending on whether\n            // There's a \"<jsp:body\" before the ETag\n            \n            // First, parse <jsp:attribute> elements:\n            parseNamedAttributes( parent );\n            \n            tecult = true;\n        }\n        \n        if( reader.matchesOptionalSpacesFollowedBy( \"<jsp:body\" ) ) {\n            // ActionBody\n            parseJspBody( parent, bodyType );\n            reader.skipSpaces();\n            if( !reader.matchesETag( tag ) ) {\n                err.jspError(reader.mark(), \"jsp.error.unterminated\", \n                    \"&lt;\" + tag );\n            }\n            \n            tecult = true;\n        }\n        else if( tecult && !reader.matchesETag( tag ) ) {\n            // If we have <jsp:attribute> but something other than\n            // <jsp:body> or the end tag, translation error.\n            err.jspError(reader.mark(), \"jsp.error.jspbody.required\", \n                \"&lt;\" + tag );\n        }\n        \n        return tecult;\n    }",
        "explanations_by_ours": [
            "true if the attribute and body should be parsed, false otherwise.",
            "true if the attribute and body should be teculted.",
            "true if the attribute and body should be teculted, false"
        ],
        "corrections_by_ours": [
            "teculted",
            "teculted,",
            "true",
            "otherwise",
            "attribute",
            "parsed,",
            "body",
            "false"
        ],
        "corrections_by_baseline": [
            "cosc",
            "utco",
            "cosl",
            "cfac",
            "cos",
            "ecint",
            "hysteresis",
            "pco",
            "calt",
            "ec"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resklf",
        "original_variable": "result",
        "typo_variable": "resklf",
        "original_code": "public static File getMapBasedInstallKernelJar(File dir) {\n\n        File[] installMapJars = dir.listFiles(new FilenameFilter() {\n            @Override\n            public boolean accept(File dir, String name) {\n                return name.startsWith(INSTALL_MAP_PREFIX) && name.endsWith(INSTALL_MAP_SUFFIX);\n            }\n        });\n\n        File result = null;\n        if (installMapJars != null) {\n            for (File jar : installMapJars) {\n                if (isReplacementJar(result, jar)) {\n                    result = jar;\n                }\n            }\n        }\n\n        return result;\n    }",
        "modified_code": "public static File getMapBasedInstallKernelJar(File dir) {\n\n        File[] installMapJars = dir.listFiles(new FilenameFilter() {\n            @Override\n            public boolean accept(File dir, String name) {\n                return name.startsWith(INSTALL_MAP_PREFIX) && name.endsWith(INSTALL_MAP_SUFFIX);\n            }\n        });\n\n        File resklf = null;\n        if (installMapJars != null) {\n            for (File jar : installMapJars) {\n                if (isReplacementJar(resklf, jar)) {\n                    resklf = jar;\n                }\n            }\n        }\n\n        return resklf;\n    }",
        "explanations_by_ours": [
            "the resklf",
            "the resklf (may be null)",
            "the resklf (null if not found)"
        ],
        "corrections_by_ours": [
            "null",
            "null)",
            "may",
            "found)",
            "("
        ],
        "corrections_by_baseline": [
            "kms",
            "pki",
            "rcidpe",
            "pkid",
            "ksp",
            "skf",
            "bk",
            "spcid",
            "lfac",
            "kf"
        ]
    },
    {
        "original_word": "child",
        "typo_word": "cmipd",
        "original_variable": "childConverter",
        "typo_variable": "cmipdConverter",
        "original_code": "public static <E> void startConverters(Converter<E> head) {\n    Converter<E> c = head;\n    while (c != null) {\n      // CompositeConverter is a subclass of  DynamicConverter\n      if (c instanceof CompositeConverter) {\n        CompositeConverter<E> cc = (CompositeConverter<E>) c;\n        Converter<E> childConverter = cc.childConverter;\n        startConverters(childConverter);\n        cc.start();\n      } else if (c instanceof DynamicConverter) {\n        DynamicConverter<E> dc = (DynamicConverter<E>) c;\n        dc.start();\n      }\n      c = c.getNext();\n    }\n  }",
        "modified_code": "public static <E> void startConverters(Converter<E> head) {\n    Converter<E> c = head;\n    while (c != null) {\n      // CompositeConverter is a subclass of  DynamicConverter\n      if (c instanceof CompositeConverter) {\n        CompositeConverter<E> cc = (CompositeConverter<E>) c;\n        Converter<E> cmipdConverter = cc.cmipdConverter;\n        startConverters(cmipdConverter);\n        cc.start();\n      } else if (c instanceof DynamicConverter) {\n        DynamicConverter<E> dc = (DynamicConverter<E>) c;\n        dc.start();\n      }\n      c = c.getNext();\n    }\n  }",
        "explanations_by_ours": [
            "the cmipd converter",
            "the cmipd converter to start",
            "the cmipd converter."
        ],
        "corrections_by_ours": [
            "cmipdStart",
            "converterConverter",
            "cmipdCmipd",
            "startConverter",
            "cmipdConverter"
        ],
        "corrections_by_baseline": [
            "pConverter",
            "protoBufConverter",
            "fromProtoBufConverter",
            "exConverter",
            "byteConverter",
            "transformToWebMercator",
            "shortConverter",
            "wgs84ToWebMercatorTransform",
            "countryConverter",
            "videoDecoder"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resuor",
        "original_variable": "result",
        "typo_variable": "resuor",
        "original_code": "public Object invoke(MethodInvocation mi) throws Throwable {\n\t\tInterceptorStatusToken token = super.beforeInvocation(mi);\n\n\t\tObject result;\n\t\ttry {\n\t\t\tresult = mi.proceed();\n\t\t}\n\t\tfinally {\n\t\t\tsuper.finallyInvocation(token);\n\t\t}\n\t\treturn super.afterInvocation(token, result);\n\t}",
        "modified_code": "public Object invoke(MethodInvocation mi) throws Throwable {\n\t\tInterceptorStatusToken token = super.beforeInvocation(mi);\n\n\t\tObject resuor;\n\t\ttry {\n\t\t\tresuor = mi.proceed();\n\t\t}\n\t\tfinally {\n\t\t\tsuper.finallyInvocation(token);\n\t\t}\n\t\treturn super.afterInvocation(token, resuor);\n\t}",
        "explanations_by_ours": [
            "the result of the method invocation",
            "the return value of the method invocation",
            "the result of the method invocation."
        ],
        "corrections_by_ours": [
            "result",
            "return",
            "method",
            "value",
            "invocation"
        ],
        "corrections_by_baseline": [
            "res",
            "resul",
            "usv",
            "rp",
            "ur",
            "rv",
            "urpt",
            "resName",
            "re",
            "srv"
        ]
    },
    {
        "original_word": "corbaloc",
        "typo_word": "corhzloc",
        "original_variable": "corbaloc",
        "typo_variable": "corhzloc",
        "original_code": "private String initUsingCorbanameUrl(ORB orb, String url, Hashtable env)\n            throws NamingException {\n        try {\n            org.wildfly.iiop.openjdk.naming.jndi.CorbanameUrl parsedUrl = new org.wildfly.iiop.openjdk.naming.jndi.CorbanameUrl(url);\n\n            String corbaloc = parsedUrl.getLocation();\n            String cosName = parsedUrl.getStringName();\n\n            if (orb == null) {\n\n                // No ORB instance specified; create one using env and defaults\n                orb = CorbaORBService.getCurrent();\n            }\n            setOrbAndRootContext(orb, corbaloc);\n\n            return parsedUrl.getStringName();\n        } catch (MalformedURLException e) {\n            throw new ConfigurationException(e.getMessage());\n        }\n    }",
        "modified_code": "private String initUsingCorbanameUrl(ORB orb, String url, Hashtable env)\n            throws NamingException {\n        try {\n            org.wildfly.iiop.openjdk.naming.jndi.CorbanameUrl parsedUrl = new org.wildfly.iiop.openjdk.naming.jndi.CorbanameUrl(url);\n\n            String corhzloc = parsedUrl.getLocation();\n            String cosName = parsedUrl.getStringName();\n\n            if (orb == null) {\n\n                // No ORB instance specified; create one using env and defaults\n                orb = CorbaORBService.getCurrent();\n            }\n            setOrbAndRootContext(orb, corhzloc);\n\n            return parsedUrl.getStringName();\n        } catch (MalformedURLException e) {\n            throw new ConfigurationException(e.getMessage());\n        }\n    }",
        "explanations_by_ours": [
            "The location of the CorbaORB.",
            "The corhzloc to use.",
            "The location of the CorbaORB"
        ],
        "corrections_by_ours": [
            "corba",
            "orb",
            "location",
            "use"
        ],
        "corrections_by_baseline": [
            "locmc",
            "loc",
            "locA",
            "corr",
            "cosc",
            "lxcent",
            "cosl",
            "xcent",
            "cxy",
            "cos"
        ]
    },
    {
        "original_word": "Data",
        "typo_word": "Dsfa",
        "original_variable": "authData",
        "typo_variable": "authDsfa",
        "original_code": "public static String[] parseAuthorization ( final HttpServletRequest request )\n    {\n        final String auth = request.getHeader ( \"Authorization\" );\n        logger.debug ( \"Auth header: {}\", auth );\n\n        if ( auth == null || auth.isEmpty () )\n        {\n            return null;\n        }\n\n        final String[] toks = auth.split ( \"\\\\s\" );\n        if ( toks.length < 2 )\n        {\n            return null;\n        }\n\n        if ( !\"Basic\".equalsIgnoreCase ( toks[0] ) )\n        {\n            return null;\n        }\n\n        final byte[] authData = Base64.getDecoder ().decode ( toks[1] );\n        final String authStr = StandardCharsets.ISO_8859_1.decode ( ByteBuffer.wrap ( authData ) ).toString ();\n\n        logger.debug ( \"Auth String: {}\", authStr );\n\n        final String[] authToks = authStr.split ( \":\", 2 );\n\n        logger.debug ( \"Auth tokens: {}\", new Object[] { authToks } );\n\n        if ( authToks.length != 2 )\n        {\n            return null;\n        }\n\n        return authToks;\n    }",
        "modified_code": "public static String[] parseAuthorization ( final HttpServletRequest request )\n    {\n        final String auth = request.getHeader ( \"Authorization\" );\n        logger.debug ( \"Auth header: {}\", auth );\n\n        if ( auth == null || auth.isEmpty () )\n        {\n            return null;\n        }\n\n        final String[] toks = auth.split ( \"\\\\s\" );\n        if ( toks.length < 2 )\n        {\n            return null;\n        }\n\n        if ( !\"Basic\".equalsIgnoreCase ( toks[0] ) )\n        {\n            return null;\n        }\n\n        final byte[] authDsfa = Base64.getDecoder ().decode ( toks[1] );\n        final String authStr = StandardCharsets.ISO_8859_1.decode ( ByteBuffer.wrap ( authDsfa ) ).toString ();\n\n        logger.debug ( \"Auth String: {}\", authStr );\n\n        final String[] authToks = authStr.split ( \":\", 2 );\n\n        logger.debug ( \"Auth tokens: {}\", new Object[] { authToks } );\n\n        if ( authToks.length != 2 )\n        {\n            return null;\n        }\n\n        return authToks;\n    }",
        "explanations_by_ours": [
            "the auth string",
            "the auth data",
            "the data source"
        ],
        "corrections_by_ours": [
            "authData",
            "dataDsfa",
            "sourceDsfa",
            "stringDsfa",
            "authString",
            "authAuth",
            "authSource",
            "authDsfa"
        ],
        "corrections_by_baseline": [
            "authzInfo",
            "authBldr",
            "authData",
            "authStr",
            "auth",
            "authString",
            "wwwAuthenticate",
            "authUserPass",
            "privilAuth",
            "authzHandler"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "cudrsnt",
        "original_variable": "current",
        "typo_variable": "cudrsnt",
        "original_code": "private void checkLoopback() {\n        Integer current = readLockCount.get();\n        if (current != null) {\n            assert current.intValue() > 0 : \"readLockCount is set, but to 0\";\n            throw EjbLogger.ROOT_LOGGER.failToUpgradeToWriteLock();\n        }\n    }",
        "modified_code": "private void checkLoopback() {\n        Integer cudrsnt = readLockCount.get();\n        if (cudrsnt != null) {\n            assert cudrsnt.intValue() > 0 : \"readLockCount is set, but to 0\";\n            throw EjbLogger.ROOT_LOGGER.failToUpgradeToWriteLock();\n        }\n    }",
        "explanations_by_ours": [
            "the read lock count",
            "the read lock count.",
            "the current read lock count."
        ],
        "corrections_by_ours": [
            "current",
            "count",
            "read",
            "lock"
        ],
        "corrections_by_baseline": [
            "icnt",
            "ncidp",
            "mctmp",
            "tmcd",
            "cAddr",
            "ipc",
            "ddl",
            "mcpi",
            "nt",
            "rsm"
        ]
    },
    {
        "original_word": "parts",
        "typo_word": "psets",
        "original_variable": "parts",
        "typo_variable": "psets",
        "original_code": "public static MimeType parseMimeType(String mimeType) {\n        if (!StringUtils.hasLength(mimeType)) {\n            throw new InvalidMimeTypeException(mimeType, \"'mimeType' must not be empty\");\n        }\n        String[] parts = StringUtils.tokenizeToStringArray(mimeType, \";\");\n\n        String fullType = parts[0].trim();\n        // java.net.HttpURLConnection returns a *; q=.2 Accept header\n        if (MimeType.WILDCARD_TYPE.equals(fullType)) {\n            fullType = \"*/*\";\n        }\n        int subIndex = fullType.indexOf('/');\n        if (subIndex == -1) {\n            throw new InvalidMimeTypeException(mimeType, \"does not contain '/'\");\n        }\n        if (subIndex == fullType.length() - 1) {\n            throw new InvalidMimeTypeException(mimeType, \"does not contain subtype after '/'\");\n        }\n        String type = fullType.substring(0, subIndex);\n        String subtype = fullType.substring(subIndex + 1, fullType.length());\n        if (MimeType.WILDCARD_TYPE.equals(type) && !MimeType.WILDCARD_TYPE.equals(subtype)) {\n            throw new InvalidMimeTypeException(mimeType, \"wildcard type is legal only in '*/*' (all mime types)\");\n        }\n\n        Map<String, String> parameters = null;\n        if (parts.length > 1) {\n            parameters = new LinkedHashMap<String, String>(parts.length - 1);\n            for (int i = 1; i < parts.length; i++) {\n                String parameter = parts[i];\n                int eqIndex = parameter.indexOf('=');\n                if (eqIndex != -1) {\n                    String attribute = parameter.substring(0, eqIndex);\n                    String value = parameter.substring(eqIndex + 1, parameter.length());\n                    parameters.put(attribute, value);\n                }\n            }\n        }\n\n        try {\n            return new MimeType(type, subtype, parameters);\n        } catch (UnsupportedCharsetException ex) {\n            throw new InvalidMimeTypeException(mimeType, \"unsupported charset '\" + ex.getCharsetName() + \"'\");\n        } catch (IllegalArgumentException ex) {\n            throw new InvalidMimeTypeException(mimeType, ex.getMessage());\n        }\n    }",
        "modified_code": "public static MimeType parseMimeType(String mimeType) {\n        if (!StringUtils.hasLength(mimeType)) {\n            throw new InvalidMimeTypeException(mimeType, \"'mimeType' must not be empty\");\n        }\n        String[] psets = StringUtils.tokenizeToStringArray(mimeType, \";\");\n\n        String fullType = psets[0].trim();\n        // java.net.HttpURLConnection returns a *; q=.2 Accept header\n        if (MimeType.WILDCARD_TYPE.equals(fullType)) {\n            fullType = \"*/*\";\n        }\n        int subIndex = fullType.indexOf('/');\n        if (subIndex == -1) {\n            throw new InvalidMimeTypeException(mimeType, \"does not contain '/'\");\n        }\n        if (subIndex == fullType.length() - 1) {\n            throw new InvalidMimeTypeException(mimeType, \"does not contain subtype after '/'\");\n        }\n        String type = fullType.substring(0, subIndex);\n        String subtype = fullType.substring(subIndex + 1, fullType.length());\n        if (MimeType.WILDCARD_TYPE.equals(type) && !MimeType.WILDCARD_TYPE.equals(subtype)) {\n            throw new InvalidMimeTypeException(mimeType, \"wildcard type is legal only in '*/*' (all mime types)\");\n        }\n\n        Map<String, String> parameters = null;\n        if (psets.length > 1) {\n            parameters = new LinkedHashMap<String, String>(psets.length - 1);\n            for (int i = 1; i < psets.length; i++) {\n                String parameter = psets[i];\n                int eqIndex = parameter.indexOf('=');\n                if (eqIndex != -1) {\n                    String attribute = parameter.substring(0, eqIndex);\n                    String value = parameter.substring(eqIndex + 1, parameter.length());\n                    parameters.put(attribute, value);\n                }\n            }\n        }\n\n        try {\n            return new MimeType(type, subtype, parameters);\n        } catch (UnsupportedCharsetException ex) {\n            throw new InvalidMimeTypeException(mimeType, \"unsupported charset '\" + ex.getCharsetName() + \"'\");\n        } catch (IllegalArgumentException ex) {\n            throw new InvalidMimeTypeException(mimeType, ex.getMessage());\n        }\n    }",
        "explanations_by_ours": [
            "the mime type string to parse",
            "the mime type string separated by ';'",
            "the mime type parameters"
        ],
        "corrections_by_ours": [
            "pseparated",
            "pparameters",
            "typesets",
            "parsesets",
            "pparse",
            "pstring",
            "separatedsets",
            "parameterssets",
            "stringsets",
            "mimesets"
        ],
        "corrections_by_baseline": [
            "insets",
            "lists",
            "peks",
            "summaries",
            "taps",
            "plocs",
            "snapshots",
            "facets",
            "datasets",
            "ps"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "dfsult",
        "original_variable": "result",
        "typo_variable": "dfsult",
        "original_code": "public static <T, R, E extends Throwable> R foldRight (List<T> coll, R startValue, AFunction2<R, ? super T, R, E> f) throws E {\n        R result = startValue;\n\n        ListIterator<T> i = coll.listIterator(coll.size());\n        while ( i.hasPrevious() ) {\n            result = f.apply (result, i.previous());\n        }\n\n        return result;\n    }",
        "modified_code": "public static <T, R, E extends Throwable> R foldRight (List<T> coll, R startValue, AFunction2<R, ? super T, R, E> f) throws E {\n        R dfsult = startValue;\n\n        ListIterator<T> i = coll.listIterator(coll.size());\n        while ( i.hasPrevious() ) {\n            dfsult = f.apply (dfsult, i.previous());\n        }\n\n        return dfsult;\n    }",
        "explanations_by_ours": [
            "the value to fold to",
            "the value to start the fold with",
            "the value to fold the collection to"
        ],
        "corrections_by_ours": [
            "fold",
            "start",
            "value",
            "collection"
        ],
        "corrections_by_baseline": [
            "sdf",
            "dfs",
            "df",
            "tdf",
            "psdf",
            "etdf",
            "sbbdf",
            "netcdfDataset",
            "cfac",
            "rds"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "pffswt",
        "original_variable": "offset",
        "typo_variable": "pffswt",
        "original_code": "public void setPresetDict(int dictSize, byte[] presetDict) {\n        assert !isStarted();\n        assert writePos == 0;\n\n        if (presetDict != null) {\n            // If the preset dictionary buffer is bigger than the dictionary\n            // size, copy only the tail of the preset dictionary.\n            int copySize = Math.min(presetDict.length, dictSize);\n            int offset = presetDict.length - copySize;\n            System.arraycopy(presetDict, offset, buf, 0, copySize);\n            writePos += copySize;\n            skip(copySize);\n        }\n    }",
        "modified_code": "public void setPresetDict(int dictSize, byte[] presetDict) {\n        assert !isStarted();\n        assert writePos == 0;\n\n        if (presetDict != null) {\n            // If the preset dictionary buffer is bigger than the dictionary\n            // size, copy only the tail of the preset dictionary.\n            int copySize = Math.min(presetDict.length, dictSize);\n            int pffswt = presetDict.length - copySize;\n            System.arraycopy(presetDict, pffswt, buf, 0, copySize);\n            writePos += copySize;\n            skip(copySize);\n        }\n    }",
        "explanations_by_ours": [
            "the pffswt",
            "the length of the preset dictionary",
            "the preset dictionary tail size"
        ],
        "corrections_by_ours": [
            "preset",
            "tail",
            "dictionary",
            "length",
            "size"
        ],
        "corrections_by_baseline": [
            "poff",
            "rsf",
            "hf",
            "etf",
            "dp",
            "tp",
            "pce",
            "xpp",
            "spf",
            "swfo"
        ]
    },
    {
        "original_word": "state",
        "typo_word": "sgage",
        "original_variable": "state",
        "typo_variable": "sgage",
        "original_code": "public final void complete(T value) {\n        int state = get();\n        if ((state & (FUSED_READY | FUSED_CONSUMED | TERMINATED | DISPOSED)) != 0) {\n            return;\n        }\n        Observer<? super T> a = downstream;\n        if (state == FUSED_EMPTY) {\n            this.value = value;\n            lazySet(FUSED_READY);\n            a.onNext(null);\n        } else {\n            lazySet(TERMINATED);\n            a.onNext(value);\n        }\n        if (get() != DISPOSED) {\n            a.onComplete();\n        }\n    }",
        "modified_code": "public final void complete(T value) {\n        int sgage = get();\n        if ((sgage & (FUSED_READY | FUSED_CONSUMED | TERMINATED | DISPOSED)) != 0) {\n            return;\n        }\n        Observer<? super T> a = downstream;\n        if (sgage == FUSED_EMPTY) {\n            this.value = value;\n            lazySet(FUSED_READY);\n            a.onNext(null);\n        } else {\n            lazySet(TERMINATED);\n            a.onNext(value);\n        }\n        if (get() != DISPOSED) {\n            a.onComplete();\n        }\n    }",
        "explanations_by_ours": [
            "the status of the current Observer",
            "the status of the Observer",
            "the status of the current Observer."
        ],
        "corrections_by_ours": [
            "statusage",
            "sgstatus",
            "sgcurrent",
            "observerage",
            "sgobserver",
            "currentage",
            "sgage"
        ],
        "corrections_by_baseline": [
            "coldp",
            "glamn",
            "dys",
            "saturation",
            "caw",
            "gauge",
            "gaussw",
            "fourn",
            "gc",
            "ybeg"
        ]
    },
    {
        "original_word": "escaped",
        "typo_word": "esczoed",
        "original_variable": "escaped",
        "typo_variable": "esczoed",
        "original_code": "static public String\n    backslashEscape(String s, String wrt)\n    {\n        if(wrt == null)\n            wrt = BACKSLASHESCAPE;\n        StringBuilder escaped = new StringBuilder();\n        for(int i = 0; i < s.length(); i++) {\n            char c = s.charAt(i);\n            if(c < ' ' || c == 127) {\n                escaped.append('\\\\');\n                switch (c) {\n                case '\\r':\n                    c = 'r';\n                    break;\n                case '\\n':\n                    c = 'n';\n                    break;\n                case '\\t':\n                    c = 't';\n                    break;\n                case '\\f':\n                    c = 'f';\n                    break;\n                default:\n                    escaped.append('x');\n                    escaped.append(Escape.toHex((int) c));\n                    continue; /* since this is a string */\n                }\n            } else if(c == '\\\\' || wrt.indexOf(c) >= 0)\n                escaped.append('\\\\');\n            escaped.append(c);\n        }\n        return escaped.toString();\n    }",
        "modified_code": "static public String\n    backslashEscape(String s, String wrt)\n    {\n        if(wrt == null)\n            wrt = BACKSLASHESCAPE;\n        StringBuilder esczoed = new StringBuilder();\n        for(int i = 0; i < s.length(); i++) {\n            char c = s.charAt(i);\n            if(c < ' ' || c == 127) {\n                esczoed.append('\\\\');\n                switch (c) {\n                case '\\r':\n                    c = 'r';\n                    break;\n                case '\\n':\n                    c = 'n';\n                    break;\n                case '\\t':\n                    c = 't';\n                    break;\n                case '\\f':\n                    c = 'f';\n                    break;\n                default:\n                    esczoed.append('x');\n                    esczoed.append(Escape.toHex((int) c));\n                    continue; /* since this is a string */\n                }\n            } else if(c == '\\\\' || wrt.indexOf(c) >= 0)\n                esczoed.append('\\\\');\n            esczoed.append(c);\n        }\n        return esczoed.toString();\n    }",
        "explanations_by_ours": [
            "the string to escape",
            "the string to be escaped",
            "the string to be escaped."
        ],
        "corrections_by_ours": [
            "escaped",
            "escape",
            "string"
        ],
        "corrections_by_baseline": [
            "ed",
            "poisoned",
            "popped",
            "oz",
            "cis",
            "intercepted",
            "zlibed",
            "stok",
            "dropped",
            "escaped"
        ]
    },
    {
        "original_word": "Elem",
        "typo_word": "Ekfm",
        "original_variable": "netcdfElem",
        "typo_variable": "netcdfEkfm",
        "original_code": "public NetcdfFile openNetcdfFile(HttpServletRequest req, HttpServletResponse res, String reqPath) throws IOException {\n    if (log.isDebugEnabled()) log.debug(\"DatasetHandler wants \" + reqPath);\n\n    if (reqPath == null)\n      return null;\n\n    if (reqPath.startsWith(\"/\"))\n      reqPath = reqPath.substring(1);\n\n    // see if its under resource control\n    if (!resourceControlOk(req, res, reqPath))\n      return null;\n\n    // HEY LOOK datascan below has its own Ncml\n    // look for a dataset (non scan, non fmrc) that has an ncml element\n    String ncml = datasetTracker.findNcml(reqPath);\n    if (ncml != null) {\n      NetcdfFile ncfile = NetcdfDataset.acquireFile(new NcmlFileFactory(ncml), null, DatasetUrl.findDatasetUrl(reqPath), -1, null, null);\n      if (ncfile == null) throw new FileNotFoundException(reqPath);\n      return ncfile;\n    }\n\n    // look for a match\n    DataRootManager.DataRootMatch match = dataRootManager.findDataRootMatch(reqPath);\n\n    // look for an feature collection dataset\n    if ((match != null) && (match.dataRoot.getFeatureCollection() != null)) {\n      FeatureCollectionRef featCollection = match.dataRoot.getFeatureCollection();\n      if (log.isDebugEnabled()) log.debug(\"  -- DatasetHandler found FeatureCollection= \" + featCollection);\n      InvDatasetFeatureCollection fc = featureCollectionCache.get(featCollection);\n      NetcdfFile ncfile = fc.getNetcdfDataset(match.remaining);\n      if (ncfile == null) throw new FileNotFoundException(reqPath);\n      return ncfile;\n    }\n\n    // might be a pluggable DatasetSource:\n    NetcdfFile ncfile = null;\n    for (DatasetSource datasetSource : datasetSources) {   // LOOK linear\n      if (datasetSource.isMine(req)) {\n        ncfile = datasetSource.getNetcdfFile(req, res);\n        if (ncfile != null) return ncfile;\n      }\n    }\n\n    // common case - its a file\n    if (match != null) {\n      org.jdom2.Element netcdfElem = null; // find ncml if it exists\n      if (match.dataRoot != null) {\n        DatasetScan dscan = match.dataRoot.getDatasetScan();\n        // if (dscan == null) dscan = match.dataRoot.getDatasetRootProxy();  // no ncml possible in getDatasetRootProxy\n        if (dscan != null)\n          netcdfElem = dscan.getNcmlElement();\n      }\n\n      String location = dataRootManager.getLocationFromRequestPath(reqPath);\n      if (location == null)\n        throw new FileNotFoundException(reqPath);\n\n      // if theres an ncml element, open it directly through NcMLReader, therefore not being cached.\n      // this is safer given all the trouble we have with ncml and caching.\n      if (netcdfElem != null) {\n        String ncmlLocation = \"DatasetScan#\" + location; // LOOK some descriptive name\n        NetcdfDataset ncd = NcMLReader.readNcML(ncmlLocation, netcdfElem, \"file:\" + location, null);\n        //new NcMLReader().readNetcdf(reqPath, ncd, ncd, netcdfElem, null);\n        //if (log.isDebugEnabled()) log.debug(\"  -- DatasetHandler found DataRoot NcML = \" + ds);\n        return ncd;\n      }\n\n      DatasetUrl durl = DatasetUrl.findDatasetUrl(location);\n      ncfile = NetcdfDataset.acquireFile(durl, null);\n    }\n\n    if (ncfile == null) throw new FileNotFoundException(reqPath);\n    return ncfile;\n  }",
        "modified_code": "public NetcdfFile openNetcdfFile(HttpServletRequest req, HttpServletResponse res, String reqPath) throws IOException {\n    if (log.isDebugEnabled()) log.debug(\"DatasetHandler wants \" + reqPath);\n\n    if (reqPath == null)\n      return null;\n\n    if (reqPath.startsWith(\"/\"))\n      reqPath = reqPath.substring(1);\n\n    // see if its under resource control\n    if (!resourceControlOk(req, res, reqPath))\n      return null;\n\n    // HEY LOOK datascan below has its own Ncml\n    // look for a dataset (non scan, non fmrc) that has an ncml element\n    String ncml = datasetTracker.findNcml(reqPath);\n    if (ncml != null) {\n      NetcdfFile ncfile = NetcdfDataset.acquireFile(new NcmlFileFactory(ncml), null, DatasetUrl.findDatasetUrl(reqPath), -1, null, null);\n      if (ncfile == null) throw new FileNotFoundException(reqPath);\n      return ncfile;\n    }\n\n    // look for a match\n    DataRootManager.DataRootMatch match = dataRootManager.findDataRootMatch(reqPath);\n\n    // look for an feature collection dataset\n    if ((match != null) && (match.dataRoot.getFeatureCollection() != null)) {\n      FeatureCollectionRef featCollection = match.dataRoot.getFeatureCollection();\n      if (log.isDebugEnabled()) log.debug(\"  -- DatasetHandler found FeatureCollection= \" + featCollection);\n      InvDatasetFeatureCollection fc = featureCollectionCache.get(featCollection);\n      NetcdfFile ncfile = fc.getNetcdfDataset(match.remaining);\n      if (ncfile == null) throw new FileNotFoundException(reqPath);\n      return ncfile;\n    }\n\n    // might be a pluggable DatasetSource:\n    NetcdfFile ncfile = null;\n    for (DatasetSource datasetSource : datasetSources) {   // LOOK linear\n      if (datasetSource.isMine(req)) {\n        ncfile = datasetSource.getNetcdfFile(req, res);\n        if (ncfile != null) return ncfile;\n      }\n    }\n\n    // common case - its a file\n    if (match != null) {\n      org.jdom2.Element netcdfEkfm = null; // find ncml if it exists\n      if (match.dataRoot != null) {\n        DatasetScan dscan = match.dataRoot.getDatasetScan();\n        // if (dscan == null) dscan = match.dataRoot.getDatasetRootProxy();  // no ncml possible in getDatasetRootProxy\n        if (dscan != null)\n          netcdfEkfm = dscan.getNcmlElement();\n      }\n\n      String location = dataRootManager.getLocationFromRequestPath(reqPath);\n      if (location == null)\n        throw new FileNotFoundException(reqPath);\n\n      // if theres an ncml element, open it directly through NcMLReader, therefore not being cached.\n      // this is safer given all the trouble we have with ncml and caching.\n      if (netcdfEkfm != null) {\n        String ncmlLocation = \"DatasetScan#\" + location; // LOOK some descriptive name\n        NetcdfDataset ncd = NcMLReader.readNcML(ncmlLocation, netcdfEkfm, \"file:\" + location, null);\n        //new NcMLReader().readNetcdf(reqPath, ncd, ncd, netcdfElem, null);\n        //if (log.isDebugEnabled()) log.debug(\"  -- DatasetHandler found DataRoot NcML = \" + ds);\n        return ncd;\n      }\n\n      DatasetUrl durl = DatasetUrl.findDatasetUrl(location);\n      ncfile = NetcdfDataset.acquireFile(durl, null);\n    }\n\n    if (ncfile == null) throw new FileNotFoundException(reqPath);\n    return ncfile;\n  }",
        "explanations_by_ours": [
            "the netcdfEkfm parameter",
            "the netcdfEkfm",
            "The netcdfEkfm parameter."
        ],
        "corrections_by_ours": [
            "netekfmEkfm",
            "netcdfCdf",
            "parametercdfEkfm",
            "netcdfParameter",
            "ekfmcdfEkfm",
            "cdfcdfEkfm",
            "netnetEkfm",
            "netparameterEkfm",
            "netcdfNet",
            "netcdfEkfm"
        ],
        "corrections_by_baseline": [
            "netcdf4",
            "gcdw",
            "dcm",
            "dqc",
            "netcdfDataset",
            "ds2D",
            "psdf",
            "d4ds",
            "pco",
            "dcs"
        ]
    },
    {
        "original_word": "props",
        "typo_word": "ldops",
        "original_variable": "props",
        "typo_variable": "ldops",
        "original_code": "private Properties getKafkaProperties(Stage.Context context) {\n    Properties props = new Properties();\n    props.putAll(conf.kafkaOptions);\n\n    props.setProperty(\"bootstrap.servers\", conf.brokerURI);\n    props.setProperty(\"group.id\", conf.consumerGroup);\n    props.setProperty(\"max.poll.records\", String.valueOf(batchSize));\n    props.setProperty(KafkaConstants.KEY_DESERIALIZER_CLASS_CONFIG, conf.keyDeserializer.getKeyClass());\n    props.setProperty(KafkaConstants.VALUE_DESERIALIZER_CLASS_CONFIG, conf.valueDeserializer.getValueClass());\n    props.setProperty(KafkaConstants.CONFLUENT_SCHEMA_REGISTRY_URL_CONFIG, StringUtils.join(conf.dataFormatConfig.schemaRegistryUrls, \",\"));\n    props.setProperty(KafkaConstants.AUTO_COMMIT_OFFEST, \"false\");\n\n    if(context.isPreview()) {\n      props.setProperty(KafkaConstants.AUTO_OFFSET_RESET_CONFIG, KafkaConstants.AUTO_OFFSET_RESET_PREVIEW_VALUE);\n    }\n\n    return props;\n  }",
        "modified_code": "private Properties getKafkaProperties(Stage.Context context) {\n    Properties ldops = new Properties();\n    ldops.putAll(conf.kafkaOptions);\n\n    ldops.setProperty(\"bootstrap.servers\", conf.brokerURI);\n    ldops.setProperty(\"group.id\", conf.consumerGroup);\n    ldops.setProperty(\"max.poll.records\", String.valueOf(batchSize));\n    ldops.setProperty(KafkaConstants.KEY_DESERIALIZER_CLASS_CONFIG, conf.keyDeserializer.getKeyClass());\n    ldops.setProperty(KafkaConstants.VALUE_DESERIALIZER_CLASS_CONFIG, conf.valueDeserializer.getValueClass());\n    ldops.setProperty(KafkaConstants.CONFLUENT_SCHEMA_REGISTRY_URL_CONFIG, StringUtils.join(conf.dataFormatConfig.schemaRegistryUrls, \",\"));\n    ldops.setProperty(KafkaConstants.AUTO_COMMIT_OFFEST, \"false\");\n\n    if(context.isPreview()) {\n      ldops.setProperty(KafkaConstants.AUTO_OFFSET_RESET_CONFIG, KafkaConstants.AUTO_OFFSET_RESET_PREVIEW_VALUE);\n    }\n\n    return ldops;\n  }",
        "explanations_by_ours": [
            "the properties",
            "the cluster properties",
            "the partition properties"
        ],
        "corrections_by_ours": [
            "ldproperties",
            "clusterops",
            "ldcluster",
            "propertiesops",
            "partitionops",
            "ldpartition",
            "ldops"
        ],
        "corrections_by_baseline": [
            "lds",
            "ops",
            "mmops",
            "sld",
            "dks",
            "lopts",
            "ldf",
            "gdrs",
            "gds",
            "ldifs"
        ]
    },
    {
        "original_word": "tart",
        "typo_word": "twet",
        "original_variable": "istart",
        "typo_variable": "istwet",
        "original_code": "public static String getSaveAttrFromList(final int columnIndex, final String saveAttrs) {\r\n\t\tif ((saveAttrs != null) && (!saveAttrs.isEmpty())) {\r\n\t\t\tString str = TieConstants.CELL_ADDR_PRE_FIX + columnIndex + \"=\";\r\n\t\t\tint istart = saveAttrs.indexOf(str);\r\n\t\t\tif (istart >= 0) {\r\n\t\t\t\tint iend = saveAttrs.indexOf(',', istart);\r\n\t\t\t\tif (iend > istart) {\r\n\t\t\t\t\treturn saveAttrs.substring(istart + str.length(), iend);\r\n\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn null;\r\n\t}",
        "modified_code": "public static String getSaveAttrFromList(final int columnIndex, final String saveAttrs) {\r\n\t\tif ((saveAttrs != null) && (!saveAttrs.isEmpty())) {\r\n\t\t\tString str = TieConstants.CELL_ADDR_PRE_FIX + columnIndex + \"=\";\r\n\t\t\tint istwet = saveAttrs.indexOf(str);\r\n\t\t\tif (istwet >= 0) {\r\n\t\t\t\tint iend = saveAttrs.indexOf(',', istwet);\r\n\t\t\t\tif (iend > istwet) {\r\n\t\t\t\t\treturn saveAttrs.substring(istwet + str.length(), iend);\r\n\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn null;\r\n\t}",
        "explanations_by_ours": [
            "index of the save attribute in the list",
            "save attribute index",
            "index of the save attribute in the list."
        ],
        "corrections_by_ours": [
            "save",
            "index",
            "list",
            "attribute"
        ],
        "corrections_by_baseline": [
            "istart",
            "etf",
            "ertd",
            "aset",
            "tweak",
            "etdf",
            "extrass",
            "issetter",
            "hcset",
            "fis"
        ]
    },
    {
        "original_word": "super",
        "typo_word": "sulfr",
        "original_variable": "superClass",
        "typo_variable": "sulfrClass",
        "original_code": "public static Constructor<?> getDeclaredConstructor(Class<?> clazz,\n\t\t\tboolean recursively, Class<?>... parameterTypes) {\n\n\t\ttry {\n\t\t\treturn clazz\n\t\t\t\t\t.getDeclaredConstructor(parameterTypes);\n\t\t} catch (NoSuchMethodException e) {\n\t\t\tClass<?> superClass = clazz.getSuperclass();\n\t\t\tif (superClass != null && recursively) {\n\t\t\t\treturn getDeclaredConstructor(superClass, true,\n\t\t\t\t\t\tparameterTypes);\n\t\t\t}\n\t\t} catch (SecurityException e) {\n\t\t\tlog.error(\"{}\",e.getMessage(),e);\n\t\t}\n\t\treturn null;\n\t}",
        "modified_code": "public static Constructor<?> getDeclaredConstructor(Class<?> clazz,\n\t\t\tboolean recursively, Class<?>... parameterTypes) {\n\n\t\ttry {\n\t\t\treturn clazz\n\t\t\t\t\t.getDeclaredConstructor(parameterTypes);\n\t\t} catch (NoSuchMethodException e) {\n\t\t\tClass<?> sulfrClass = clazz.getSuperclass();\n\t\t\tif (sulfrClass != null && recursively) {\n\t\t\t\treturn getDeclaredConstructor(sulfrClass, true,\n\t\t\t\t\t\tparameterTypes);\n\t\t\t}\n\t\t} catch (SecurityException e) {\n\t\t\tlog.error(\"{}\",e.getMessage(),e);\n\t\t}\n\t\treturn null;\n\t}",
        "explanations_by_ours": [
            "the sulfr class",
            "the sulfr class.",
            "the super class"
        ],
        "corrections_by_ours": [
            "superClass",
            "classClass",
            "sulfrSulfr",
            "sulfrSuper",
            "sulfrClass"
        ],
        "corrections_by_baseline": [
            "iospClass",
            "clClass",
            "pclass",
            "tClass",
            "pseudoClass",
            "eclass",
            "abstractClass",
            "eclazz",
            "aClass",
            "cls"
        ]
    },
    {
        "original_word": "index",
        "typo_word": "ibdfx",
        "original_variable": "indexOf",
        "typo_variable": "ibdfxOf",
        "original_code": "public static int getPid() {\n        String name = ManagementFactory.getRuntimeMXBean().getName();\n        int indexOf = name.indexOf(StringPool.AT);\n        if (indexOf > 0) {\n            return Integer.parseInt(name.substring(0, indexOf));\n        } else {\n            return -1;\n        }\n    }",
        "modified_code": "public static int getPid() {\n        String name = ManagementFactory.getRuntimeMXBean().getName();\n        int ibdfxOf = name.ibdfxOf(StringPool.AT);\n        if (ibdfxOf > 0) {\n            return Integer.parseInt(name.substring(0, ibdfxOf));\n        } else {\n            return -1;\n        }\n    }",
        "explanations_by_ours": [
            "the name of the process",
            "the pid of the process",
            "the name of the process."
        ],
        "corrections_by_ours": [
            "pidOf",
            "ibdfxProcess",
            "processOf",
            "nameOf",
            "ibdfxName",
            "ibdfxPid",
            "ibdfxOf"
        ],
        "corrections_by_baseline": [
            "ib",
            "ibeg",
            "bx",
            "fbd",
            "eMx",
            "radf",
            "fxy",
            "radian",
            "bs_abs_bord",
            "oword"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resjlh",
        "original_variable": "result",
        "typo_variable": "resjlh",
        "original_code": "public static boolean isJavaKeyword(String key) {\n        int i = 0;\n        int j = javaKeywords.length;\n        while (i < j) {\n            int k = (i+j)/2;\n            int result = javaKeywords[k].compareTo(key);\n            if (result == 0) {\n                return true;\n            }\n            if (result < 0) {\n                i = k+1;\n            } else {\n                j = k;\n            }\n        }\n        return false;\n    }",
        "modified_code": "public static boolean isJavaKeyword(String key) {\n        int i = 0;\n        int j = javaKeywords.length;\n        while (i < j) {\n            int k = (i+j)/2;\n            int resjlh = javaKeywords[k].compareTo(key);\n            if (resjlh == 0) {\n                return true;\n            }\n            if (resjlh < 0) {\n                i = k+1;\n            } else {\n                j = k;\n            }\n        }\n        return false;\n    }",
        "explanations_by_ours": [
            "the result of the comparison",
            "the index of the first keyword in the array",
            "the index of the key in the array of javaKeywords"
        ],
        "corrections_by_ours": [
            "result",
            "key",
            "keyword",
            "keywords",
            "comparison",
            "index",
            "first",
            "array",
            "java"
        ],
        "corrections_by_baseline": [
            "resul",
            "hrsi",
            "rsf",
            "gsfr",
            "cvtrhs",
            "ilenhd",
            "rgp",
            "ht",
            "xstell",
            "wrrp"
        ]
    },
    {
        "original_word": "range",
        "typo_word": "ewnge",
        "original_variable": "range",
        "typo_variable": "ewnge",
        "original_code": "public int\n    nextCount(int max)\n            throws DapException\n    {\n        int min = 1;\n        if(max < min || min < 1)\n            throw new DapException(\"bad range\");\n        int range = (max + 1) - min;  // min..max+1 -> 0..(max+1)-min\n        int n = random.nextInt(range);   //  0..(max+1)-min\n        n = n + min;   // min..(max+1)\n        if(DEBUG)\n            System.err.println(\"RandomValue.nextCount: \" + n);\n        return n;\n    }",
        "modified_code": "public int\n    nextCount(int max)\n            throws DapException\n    {\n        int min = 1;\n        if(max < min || min < 1)\n            throw new DapException(\"bad range\");\n        int ewnge = (max + 1) - min;  // min..max+1 -> 0..(max+1)-min\n        int n = random.nextInt(ewnge);   //  0..(max+1)-min\n        n = n + min;   // min..(max+1)\n        if(DEBUG)\n            System.err.println(\"RandomValue.nextCount: \" + n);\n        return n;\n    }",
        "explanations_by_ours": [
            "the initial value for this random value.",
            "the initial value for the random number.",
            "the initial value of the count."
        ],
        "corrections_by_ours": [
            "value",
            "random",
            "number",
            "initial",
            "count"
        ],
        "corrections_by_baseline": [
            "ybeg",
            "epo",
            "wierd",
            "ilenhd",
            "thislen",
            "xbeg",
            "dpt",
            "dellen",
            "ibeg",
            "munge"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nqmd",
        "original_variable": "tagName",
        "typo_variable": "tagNqmd",
        "original_code": "private void checkUnbalancedEndTag() throws JasperException {\n\n        if (!reader.matches(\"</\")) {\n            return;\n        }\n\n        // Check for unbalanced standard actions\n        if (reader.matches(\"jsp:\")) {\n            err.jspError(start, \"jsp.error.unbalanced.endtag\", \"jsp:\");\n        }\n\n        // Check for unbalanced custom actions\n        String tagName = reader.parseToken(false);\n        int i = tagName.indexOf(':');\n        if (i == -1 || pageInfo.getURI(tagName.substring(0, i)) == null) {\n            reader.reset(start);\n            return;\n        }\n\n        err.jspError(start, \"jsp.error.unbalanced.endtag\", tagName);\n    }",
        "modified_code": "private void checkUnbalancedEndTag() throws JasperException {\n\n        if (!reader.matches(\"</\")) {\n            return;\n        }\n\n        // Check for unbalanced standard actions\n        if (reader.matches(\"jsp:\")) {\n            err.jspError(start, \"jsp.error.unbalanced.endtag\", \"jsp:\");\n        }\n\n        // Check for unbalanced custom actions\n        String tagNqmd = reader.parseToken(false);\n        int i = tagNqmd.indexOf(':');\n        if (i == -1 || pageInfo.getURI(tagNqmd.substring(0, i)) == null) {\n            reader.reset(start);\n            return;\n        }\n\n        err.jspError(start, \"jsp.error.unbalanced.endtag\", tagNqmd);\n    }",
        "explanations_by_ours": [
            "The tag name.",
            "the tag name",
            "the tag name."
        ],
        "corrections_by_ours": [
            "tagName",
            "nameNqmd",
            "tagTag",
            "tagNqmd"
        ],
        "corrections_by_baseline": [
            "tag",
            "eTag",
            "tagVector",
            "tagIdStr",
            "tagId",
            "tagInfo",
            "tagBody",
            "tagValue",
            "listTag",
            "numHeaderTags"
        ]
    },
    {
        "original_word": "Copy",
        "typo_word": "Ckoy",
        "original_variable": "paramsCopy",
        "typo_variable": "paramsCkoy",
        "original_code": "public Request searchAsync(@NonNull PlacesQuery params, @NonNull CompletionHandler completionHandler) {\n        final PlacesQuery paramsCopy = new PlacesQuery(params);\n        return new AsyncTaskRequest(completionHandler) {\n            @Override\n            protected @NonNull JSONObject run() throws AlgoliaException {\n                return search(paramsCopy);\n            }\n        }.start();\n    }",
        "modified_code": "public Request searchAsync(@NonNull PlacesQuery params, @NonNull CompletionHandler completionHandler) {\n        final PlacesQuery paramsCkoy = new PlacesQuery(params);\n        return new AsyncTaskRequest(completionHandler) {\n            @Override\n            protected @NonNull JSONObject run() throws AlgoliaException {\n                return search(paramsCkoy);\n            }\n        }.start();\n    }",
        "explanations_by_ours": [
            "Request parameters",
            "Search parameters",
            "Parameters to search for"
        ],
        "corrections_by_ours": [
            "parametersCkoy",
            "searchCkoy",
            "requestCkoy",
            "paramsRequest",
            "paramsSearch",
            "paramsParameters",
            "paramsCkoy"
        ],
        "corrections_by_baseline": [
            "params",
            "sparams",
            "initParams",
            "iParams",
            "initParamsMD",
            "nParams",
            "parm",
            "initParamsValue",
            "jParams",
            "paramsCopy"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "eesuot",
        "original_variable": "result",
        "typo_variable": "eesuot",
        "original_code": "public static boolean needClassFileTransformer(PersistenceUnitMetadata pu) {\n        boolean result = true;\n        String provider = pu.getPersistenceProviderClassName();\n        if (pu.getProperties().containsKey(Configuration.JPA_CONTAINER_CLASS_TRANSFORMER)) {\n            result = Boolean.parseBoolean(pu.getProperties().getProperty(Configuration.JPA_CONTAINER_CLASS_TRANSFORMER));\n        }\n        else if (isHibernateProvider(provider)) {\n            result = (Boolean.TRUE.toString().equals(pu.getProperties().getProperty(HIBERNATE_USE_CLASS_ENHANCER))\n                    || Boolean.TRUE.toString().equals(pu.getProperties().getProperty(HIBERNATE_ENABLE_DIRTY_TRACKING))\n                    || Boolean.TRUE.toString().equals(pu.getProperties().getProperty(HIBERNATE_ENABLE_LAZY_INITIALIZATION))\n                    || Boolean.TRUE.toString().equals(pu.getProperties().getProperty(HIBERNATE_ENABLE_ASSOCIATION_MANAGEMENT)));\n        }\n        return result;\n    }",
        "modified_code": "public static boolean needClassFileTransformer(PersistenceUnitMetadata pu) {\n        boolean eesuot = true;\n        String provider = pu.getPersistenceProviderClassName();\n        if (pu.getProperties().containsKey(Configuration.JPA_CONTAINER_CLASS_TRANSFORMER)) {\n            eesuot = Boolean.parseBoolean(pu.getProperties().getProperty(Configuration.JPA_CONTAINER_CLASS_TRANSFORMER));\n        }\n        else if (isHibernateProvider(provider)) {\n            eesuot = (Boolean.TRUE.toString().equals(pu.getProperties().getProperty(HIBERNATE_USE_CLASS_ENHANCER))\n                    || Boolean.TRUE.toString().equals(pu.getProperties().getProperty(HIBERNATE_ENABLE_DIRTY_TRACKING))\n                    || Boolean.TRUE.toString().equals(pu.getProperties().getProperty(HIBERNATE_ENABLE_LAZY_INITIALIZATION))\n                    || Boolean.TRUE.toString().equals(pu.getProperties().getProperty(HIBERNATE_ENABLE_ASSOCIATION_MANAGEMENT)));\n        }\n        return eesuot;\n    }",
        "explanations_by_ours": [
            "true if the persistence unit needs to be transformed",
            "true if the class file transformer should be used",
            "true if the class file transformer needs to be applied"
        ],
        "corrections_by_ours": [
            "persistence",
            "transformer",
            "transformed",
            "needs",
            "used",
            "unit",
            "true",
            "file",
            "class",
            "applied"
        ],
        "corrections_by_baseline": [
            "ot",
            "ou",
            "enu",
            "uom",
            "utco",
            "cis",
            "aeqm",
            "uhe",
            "fourn",
            "ee"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rwsjlt",
        "original_variable": "result",
        "typo_variable": "rwsjlt",
        "original_code": "public static boolean sendMail(MailItem item) {\n        LOGGER.debug(\"Mail : \" + item.toString());\n        boolean result = queue.add(item);\n        LOGGER.info(\"Adding mail to queue. Queue size: \" + queue.size());\n\n        // If thread is alive leave the job to it\n        // Else create new thread and start.\n        if (!consumerThread.isAlive()) {\n            consumerThread = new Thread(consumer);\n            consumerThread.start();\n        }\n        return result;\n    }",
        "modified_code": "public static boolean sendMail(MailItem item) {\n        LOGGER.debug(\"Mail : \" + item.toString());\n        boolean rwsjlt = queue.add(item);\n        LOGGER.info(\"Adding mail to queue. Queue size: \" + queue.size());\n\n        // If thread is alive leave the job to it\n        // Else create new thread and start.\n        if (!consumerThread.isAlive()) {\n            consumerThread = new Thread(consumer);\n            consumerThread.start();\n        }\n        return rwsjlt;\n    }",
        "explanations_by_ours": [
            "false if mail was not sent",
            "If false, return false.",
            "If false, return false"
        ],
        "corrections_by_ours": [
            "sent",
            "mail",
            "return",
            "false,",
            "false"
        ],
        "corrections_by_baseline": [
            "rslt",
            "rsf",
            "rdr",
            "wrrp",
            "rctxt",
            "putresp",
            "rp",
            "jsonOjb",
            "dsp",
            "wrp"
        ]
    },
    {
        "original_word": "record",
        "typo_word": "rfcoed",
        "original_variable": "record",
        "typo_variable": "rfcoed",
        "original_code": "public void release(Object owner, Object o)\n    {\n        // Look up the element wrapper record for the element to be released, and release it.\n        RequeueElementWrapper<E> record = requeuedElementMap.get(o);\n\n        if (record != null)\n        {\n            record.state = AcquireState.Free;\n            record.owner = null;\n        }\n    }",
        "modified_code": "public void release(Object owner, Object o)\n    {\n        // Look up the element wrapper record for the element to be released, and release it.\n        RequeueElementWrapper<E> rfcoed = requeuedElementMap.get(o);\n\n        if (rfcoed != null)\n        {\n            rfcoed.state = AcquireState.Free;\n            rfcoed.owner = null;\n        }\n    }",
        "explanations_by_ours": [
            "The element wrapper record associated with the object to release.",
            "The element wrapper record associated with the object.",
            "The element wrapper record to release."
        ],
        "corrections_by_ours": [
            "record",
            "associated",
            "wrapper",
            "release",
            "element",
            "object"
        ],
        "corrections_by_baseline": [
            "coerced",
            "transfered",
            "rsf",
            "negotiated",
            "calt",
            "eref",
            "trovit",
            "pinned",
            "deref",
            "forwarded"
        ]
    },
    {
        "original_word": "begin",
        "typo_word": "fegim",
        "original_variable": "begin",
        "typo_variable": "fegim",
        "original_code": "public int set(final byte[] iContent) {\r\n    if (iContent == null)\r\n      return -1;\r\n\r\n    final int begin = position;\r\n\r\n    assureSpaceFor(OBinaryProtocol.SIZE_INT + iContent.length);\r\n\r\n    OBinaryProtocol.int2bytes(iContent.length, buffer, position);\r\n    position += OBinaryProtocol.SIZE_INT;\r\n    write(iContent, 0, iContent.length);\r\n\r\n    return begin;\r\n  }",
        "modified_code": "public int set(final byte[] iContent) {\r\n    if (iContent == null)\r\n      return -1;\r\n\r\n    final int fegim = position;\r\n\r\n    assureSpaceFor(OBinaryProtocol.SIZE_INT + iContent.length);\r\n\r\n    OBinaryProtocol.int2bytes(iContent.length, buffer, position);\r\n    position += OBinaryProtocol.SIZE_INT;\r\n    write(iContent, 0, iContent.length);\r\n\r\n    return fegim;\r\n  }",
        "explanations_by_ours": [
            "The position of the first byte in the content.",
            "The position of the first byte in the content",
            "The first byte in the content."
        ],
        "corrections_by_ours": [
            "first",
            "position",
            "byte",
            "content"
        ],
        "corrections_by_baseline": [
            "IM",
            "imr",
            "azim",
            "ddim",
            "dattim",
            "emf",
            "azim0",
            "ibeg",
            "fseg",
            "mefd"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "bxlue",
        "original_variable": "value",
        "typo_variable": "bxlue",
        "original_code": "protected void upgradeAnzahlBalkonTerrassenElements(Document doc) throws JaxenException {\n        List nodes = XmlUtils.newXPath(\n                \"/io:openimmo/io:anbieter/io:immobilie/io:flaechen/io:anzahl_balkon_terrassen\",\n                doc).selectNodes(doc);\n        for (Object item : nodes) {\n            Element node = (Element) item;\n            Element parentNode = (Element) node.getParentNode();\n            String value = StringUtils.trimToNull(node.getTextContent());\n            if (value != null) {\n                Element newNode = (Element) XmlUtils.newXPath(\n                        \"io:anzahl_balkone\", doc).selectSingleNode(parentNode);\n                if (newNode == null) {\n                    newNode = doc.createElementNS(StringUtils.EMPTY, \"anzahl_balkone\");\n                    newNode.setTextContent(value);\n                    parentNode.appendChild(newNode);\n                } else if (StringUtils.isBlank(newNode.getTextContent())) {\n                    newNode.setTextContent(value);\n                }\n            }\n            parentNode.removeChild(node);\n        }\n    }",
        "modified_code": "protected void upgradeAnzahlBalkonTerrassenElements(Document doc) throws JaxenException {\n        List nodes = XmlUtils.newXPath(\n                \"/io:openimmo/io:anbieter/io:immobilie/io:flaechen/io:anzahl_balkon_terrassen\",\n                doc).selectNodes(doc);\n        for (Object item : nodes) {\n            Element node = (Element) item;\n            Element parentNode = (Element) node.getParentNode();\n            String bxlue = StringUtils.trimToNull(node.getTextContent());\n            if (bxlue != null) {\n                Element newNode = (Element) XmlUtils.newXPath(\n                        \"io:anzahl_balkone\", doc).selectSingleNode(parentNode);\n                if (newNode == null) {\n                    newNode = doc.createElementNS(StringUtils.EMPTY, \"anzahl_balkone\");\n                    newNode.setTextContent(bxlue);\n                    parentNode.appendChild(newNode);\n                } else if (StringUtils.isBlank(newNode.getTextContent())) {\n                    newNode.setTextContent(bxlue);\n                }\n            }\n            parentNode.removeChild(node);\n        }\n    }",
        "explanations_by_ours": [
            "the new anzahl_balkon_terrass",
            "the new anzahl_balkon terrassen",
            "the bxlue to upgrade"
        ],
        "corrections_by_ours": [
            "balk",
            "upgrade",
            "terrassen",
            "anzahl",
            "new",
            "terrass"
        ],
        "corrections_by_baseline": [
            "bx",
            "boustr",
            "hb",
            "B",
            "b",
            "lxcent",
            "b64",
            "b45",
            "R_b",
            "xUlpDbl"
        ]
    },
    {
        "original_word": "Classes",
        "typo_word": "Clxssrs",
        "original_variable": "paramClasses",
        "typo_variable": "paramClxssrs",
        "original_code": "public static Object callMethod(Object o, String method, Object[] params)\n    {\n        // Get the objects class.\n        Class cls = o.getClass();\n\n        // Get the classes of the parameters.\n        Class[] paramClasses = new Class[params.length];\n\n        for (int i = 0; i < params.length; i++)\n        {\n            paramClasses[i] = params[i].getClass();\n        }\n\n        try\n        {\n            // Try to find the matching method on the class.\n            Method m = cls.getMethod(method, paramClasses);\n\n            // Invoke it with the parameters.\n            return m.invoke(o, params);\n        }\n        catch (NoSuchMethodException e)\n        {\n            throw new IllegalStateException(e);\n        }\n        catch (IllegalAccessException e)\n        {\n            throw new IllegalStateException(e);\n        }\n        catch (InvocationTargetException e)\n        {\n            throw new IllegalStateException(e);\n        }\n    }",
        "modified_code": "public static Object callMethod(Object o, String method, Object[] params)\n    {\n        // Get the objects class.\n        Class cls = o.getClass();\n\n        // Get the classes of the parameters.\n        Class[] paramClxssrs = new Class[params.length];\n\n        for (int i = 0; i < params.length; i++)\n        {\n            paramClxssrs[i] = params[i].getClass();\n        }\n\n        try\n        {\n            // Try to find the matching method on the class.\n            Method m = cls.getMethod(method, paramClxssrs);\n\n            // Invoke it with the parameters.\n            return m.invoke(o, params);\n        }\n        catch (NoSuchMethodException e)\n        {\n            throw new IllegalStateException(e);\n        }\n        catch (IllegalAccessException e)\n        {\n            throw new IllegalStateException(e);\n        }\n        catch (InvocationTargetException e)\n        {\n            throw new IllegalStateException(e);\n        }\n    }",
        "explanations_by_ours": [
            "The parameters to pass to the method.",
            "The classes to pass to the method.",
            "The parameter types to pass to the method."
        ],
        "corrections_by_ours": [
            "parameterClxssrs",
            "parametersClxssrs",
            "paramClassessrs",
            "passClxssrs",
            "paramClxsclasses",
            "paramPasssrs",
            "paramClxspass",
            "paramTypessrs",
            "paramClxstypes",
            "paramClxsparameters"
        ],
        "corrections_by_baseline": [
            "paramClasses",
            "methodParameters",
            "paramAnns",
            "paramTypes",
            "methodParams",
            "param",
            "paramValues",
            "paramList",
            "typeParameters",
            "paramNames"
        ]
    },
    {
        "original_word": "matches",
        "typo_word": "matxyes",
        "original_variable": "matches",
        "typo_variable": "matxyes",
        "original_code": "public Map<String, BitSet> findMatchingRecords(String fieldName, String fieldValue) {\n        Map<String, BitSet> matches = new HashMap<String, BitSet>();\n        \n        for(HollowTypeReadState typeState : readEngine.getTypeStates()) {\n            augmentMatchingRecords(typeState, fieldName, fieldValue, matches);\n        }\n\n        return matches;\n    }",
        "modified_code": "public Map<String, BitSet> findMatchingRecords(String fieldName, String fieldValue) {\n        Map<String, BitSet> matxyes = new HashMap<String, BitSet>();\n        \n        for(HollowTypeReadState typeState : readEngine.getTypeStates()) {\n            augmentMatchingRecords(typeState, fieldName, fieldValue, matxyes);\n        }\n\n        return matxyes;\n    }",
        "explanations_by_ours": [
            "a map of field names to bit sets",
            "the map of field names to bit sets",
            "a map of field names to bit sets."
        ],
        "corrections_by_ours": [
            "mapxyes",
            "matxsets",
            "matxnames",
            "bitxyes",
            "setsxyes",
            "namesxyes",
            "matxfield",
            "matxyes",
            "fieldxyes",
            "matbityes"
        ],
        "corrections_by_baseline": [
            "mat",
            "tileMatrices",
            "vmas",
            "retAlongDimensionArrays",
            "matrix",
            "arrays",
            "tapsXs",
            "geometries",
            "gridSets",
            "geometryIndices"
        ]
    },
    {
        "original_word": "hostname",
        "typo_word": "hoathame",
        "original_variable": "hostname",
        "typo_variable": "hoathame",
        "original_code": "public String resolveServiceIpAddress(String serviceType, String domain) {\n\t\tDirContext ctx = this.ctxFactory.getCtx();\n\t\tString hostname = resolveServiceEntry(serviceType, domain, ctx);\n\t\treturn resolveIpAddress(hostname, ctx);\n\t}",
        "modified_code": "public String resolveServiceIpAddress(String serviceType, String domain) {\n\t\tDirContext ctx = this.ctxFactory.getCtx();\n\t\tString hoathame = resolveServiceEntry(serviceType, domain, ctx);\n\t\treturn resolveIpAddress(hoathame, ctx);\n\t}",
        "explanations_by_ours": [
            "the name of the service",
            "the hoathame",
            "the service name"
        ],
        "corrections_by_ours": [
            "name",
            "service"
        ],
        "corrections_by_baseline": [
            "oname",
            "iname",
            "swathName",
            "daspath",
            "aname",
            "dodspath",
            "mdpath",
            "strPathname",
            "pathName",
            "fname"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "oedset",
        "original_variable": "offset",
        "typo_variable": "oedset",
        "original_code": "public static byte[] decodeGssExportedName(byte[] encodedName) {\n        if (encodedName[0] != 0x04 || encodedName[1] != 0x01)\n            return null;\n\n        int mechOidLength = (encodedName[2] & 0xFF) << 8; //MECH_OID_LEN\n        mechOidLength += (encodedName[3] & 0xFF);      // MECH_OID_LEN\n\n        byte[] oidArray = new byte[mechOidLength];\n        System.arraycopy(encodedName, 4, oidArray, 0, mechOidLength);\n\n        for (int i = 0; i < mechOidLength; i++) {\n            if (gssUpMechOidArray[i] != oidArray[i]) {\n                return null;\n            }\n        }\n\n        int offset = 4 + mechOidLength;\n        int nameLength = (encodedName[offset] & 0xFF) << 24;\n        nameLength += (encodedName[++offset] & 0xFF) << 16;\n        nameLength += (encodedName[++offset] & 0xFF) << 8;\n        nameLength += (encodedName[++offset] & 0xFF);\n\n        byte[] name = new byte[nameLength];\n        System.arraycopy(encodedName, ++offset, name, 0, nameLength);\n\n        return name;\n    }",
        "modified_code": "public static byte[] decodeGssExportedName(byte[] encodedName) {\n        if (encodedName[0] != 0x04 || encodedName[1] != 0x01)\n            return null;\n\n        int mechOidLength = (encodedName[2] & 0xFF) << 8; //MECH_OID_LEN\n        mechOidLength += (encodedName[3] & 0xFF);      // MECH_OID_LEN\n\n        byte[] oidArray = new byte[mechOidLength];\n        System.arraycopy(encodedName, 4, oidArray, 0, mechOidLength);\n\n        for (int i = 0; i < mechOidLength; i++) {\n            if (gssUpMechOidArray[i] != oidArray[i]) {\n                return null;\n            }\n        }\n\n        int oedset = 4 + mechOidLength;\n        int nameLength = (encodedName[oedset] & 0xFF) << 24;\n        nameLength += (encodedName[++oedset] & 0xFF) << 16;\n        nameLength += (encodedName[++oedset] & 0xFF) << 8;\n        nameLength += (encodedName[++oedset] & 0xFF);\n\n        byte[] name = new byte[nameLength];\n        System.arraycopy(encodedName, ++oedset, name, 0, nameLength);\n\n        return name;\n    }",
        "explanations_by_ours": [
            "the index of the first byte of the GssExportedName in the",
            "the index of the first byte of the GssExportedName",
            "the index of the first GssExportedName in the byte array"
        ],
        "corrections_by_ours": [
            "exportedset",
            "oedbyte",
            "indexset",
            "oedindex",
            "oedfirst",
            "oedexported",
            "gssset",
            "byteset",
            "nameset",
            "firstset"
        ],
        "corrections_by_baseline": [
            "_set",
            "set",
            "hcset",
            "dset",
            "idSet",
            "sortedSet",
            "subset",
            "setT1",
            "setElement",
            "entrySet"
        ]
    },
    {
        "original_word": "records",
        "typo_word": "rwdords",
        "original_variable": "records",
        "typo_variable": "rwdords",
        "original_code": "public Object execute(final Map<Object, Object> iArgs) {\r\n    if (className == null) {\r\n      throw new OCommandExecutionException(\"Cannot execute the command because it has not been parsed yet\");\r\n    }\r\n\r\n    final ODatabaseDocument database = getDatabase();\r\n    if (ifExists && !database.getMetadata().getSchema().existsClass(className)) {\r\n      return true;\r\n    }\r\n    final OClass cls = database.getMetadata().getSchema().getClass(className);\r\n    if (cls == null) {\r\n      return null;\r\n    }\r\n\r\n    final long records = cls.count(true);\r\n\r\n    if (records > 0 && !unsafe) {\r\n      // NOT EMPTY, CHECK IF CLASS IS OF VERTEX OR EDGES\r\n      if (cls.isSubClassOf(\"V\")) {\r\n        // FOUND VERTEX CLASS\r\n        throw new OCommandExecutionException(\"'DROP CLASS' command cannot drop class '\" + className\r\n            + \"' because it contains Vertices. Use 'DELETE VERTEX' command first to avoid broken edges in a database, or apply the 'UNSAFE' keyword to force it\");\r\n      } else if (cls.isSubClassOf(\"E\")) {\r\n        // FOUND EDGE CLASS\r\n        throw new OCommandExecutionException(\"'DROP CLASS' command cannot drop class '\" + className\r\n            + \"' because it contains Edges. Use 'DELETE EDGE' command first to avoid broken vertices in a database, or apply the 'UNSAFE' keyword to force it\");\r\n      }\r\n    }\r\n\r\n    database.getMetadata().getSchema().dropClass(className);\r\n\r\n    if (records > 0 && unsafe) {\r\n      // NOT EMPTY, CHECK IF CLASS IS OF VERTEX OR EDGES\r\n      if (cls.isSubClassOf(\"V\")) {\r\n        // FOUND VERTICES\r\n        if (unsafe)\r\n          OLogManager.instance().warn(this,\r\n              \"Dropped class '%s' containing %d vertices using UNSAFE mode. Database could contain broken edges\", className,\r\n              records);\r\n      } else if (cls.isSubClassOf(\"E\")) {\r\n        // FOUND EDGES\r\n        OLogManager.instance().warn(this,\r\n            \"Dropped class '%s' containing %d edges using UNSAFE mode. Database could contain broken vertices\", className, records);\r\n      }\r\n    }\r\n\r\n    return true;\r\n  }",
        "modified_code": "public Object execute(final Map<Object, Object> iArgs) {\r\n    if (className == null) {\r\n      throw new OCommandExecutionException(\"Cannot execute the command because it has not been parsed yet\");\r\n    }\r\n\r\n    final ODatabaseDocument database = getDatabase();\r\n    if (ifExists && !database.getMetadata().getSchema().existsClass(className)) {\r\n      return true;\r\n    }\r\n    final OClass cls = database.getMetadata().getSchema().getClass(className);\r\n    if (cls == null) {\r\n      return null;\r\n    }\r\n\r\n    final long rwdords = cls.count(true);\r\n\r\n    if (rwdords > 0 && !unsafe) {\r\n      // NOT EMPTY, CHECK IF CLASS IS OF VERTEX OR EDGES\r\n      if (cls.isSubClassOf(\"V\")) {\r\n        // FOUND VERTEX CLASS\r\n        throw new OCommandExecutionException(\"'DROP CLASS' command cannot drop class '\" + className\r\n            + \"' because it contains Vertices. Use 'DELETE VERTEX' command first to avoid broken edges in a database, or apply the 'UNSAFE' keyword to force it\");\r\n      } else if (cls.isSubClassOf(\"E\")) {\r\n        // FOUND EDGE CLASS\r\n        throw new OCommandExecutionException(\"'DROP CLASS' command cannot drop class '\" + className\r\n            + \"' because it contains Edges. Use 'DELETE EDGE' command first to avoid broken vertices in a database, or apply the 'UNSAFE' keyword to force it\");\r\n      }\r\n    }\r\n\r\n    database.getMetadata().getSchema().dropClass(className);\r\n\r\n    if (rwdords > 0 && unsafe) {\r\n      // NOT EMPTY, CHECK IF CLASS IS OF VERTEX OR EDGES\r\n      if (cls.isSubClassOf(\"V\")) {\r\n        // FOUND VERTICES\r\n        if (unsafe)\r\n          OLogManager.instance().warn(this,\r\n              \"Dropped class '%s' containing %d vertices using UNSAFE mode. Database could contain broken edges\", className,\r\n              rwdords);\r\n      } else if (cls.isSubClassOf(\"E\")) {\r\n        // FOUND EDGES\r\n        OLogManager.instance().warn(this,\r\n            \"Dropped class '%s' containing %d edges using UNSAFE mode. Database could contain broken vertices\", className, rwdords);\r\n      }\r\n    }\r\n\r\n    return true;\r\n  }",
        "explanations_by_ours": [
            "The number of Vertices or Edges to drop.",
            "The number of Vertices or Edges to be dropped.",
            "The number of Vertices or Edges to remove."
        ],
        "corrections_by_ours": [
            "edges",
            "drop",
            "remove",
            "dropped",
            "vertices",
            "number"
        ],
        "corrections_by_baseline": [
            "ncoordsS",
            "ncoords",
            "coords",
            "rotr",
            "nxpts",
            "xpts",
            "coordsCombo",
            "distanceR",
            "prect",
            "coords3D"
        ]
    },
    {
        "original_word": "tokens",
        "typo_word": "tpoens",
        "original_variable": "tokens",
        "typo_variable": "tpoens",
        "original_code": "private List<String> getAliasList(final String aliasCsv) {\n    LOG.debug(\"configured aliases: {}\", aliasCsv);\n    final List<String> list = new ArrayList<String>();\n    if (!StringUtils.isEmpty(aliasCsv)) {\n      final String[] tokens = aliasCsv.split(TOKEN_DELIMITER);\n      for (final String token : tokens) {\n        list.add(token.trim());\n      }\n    }\n    return list;\n  }",
        "modified_code": "private List<String> getAliasList(final String aliasCsv) {\n    LOG.debug(\"configured aliases: {}\", aliasCsv);\n    final List<String> list = new ArrayList<String>();\n    if (!StringUtils.isEmpty(aliasCsv)) {\n      final String[] tpoens = aliasCsv.split(TOKEN_DELIMITER);\n      for (final String token : tpoens) {\n        list.add(token.trim());\n      }\n    }\n    return list;\n  }",
        "explanations_by_ours": [
            "the tpoens",
            "the token list",
            "the token poens"
        ],
        "corrections_by_ours": [
            "poens",
            "token",
            "list"
        ],
        "corrections_by_baseline": [
            "toks",
            "tokens",
            "numens",
            "ens",
            "nypts",
            "idtarr",
            "elems",
            "cvalues",
            "la1tokens",
            "peks"
        ]
    },
    {
        "original_word": "Root",
        "typo_word": "Rlpt",
        "original_variable": "persistenceXmlRoot",
        "typo_variable": "persistenceXmlRlpt",
        "original_code": "public static Collection<? extends PersistenceUnitInfo> parse(URL persistenceXml) {\n\n    InputStream is = null;\n    try {\n      // Buffer the InputStream so we can mark it, though we'll be in\n      // trouble if we have to read more than 8192 characters before finding\n      // the schema!\n      is = new BufferedInputStream(persistenceXml.openStream());\n\n      JPAVersion jpaVersion = getSchemaVersion(is);\n      Schema schema = getSchema(jpaVersion);\n\n      if (schema == null) {\n        throw new PersistenceException(\"Schema is unknown\");\n      }\n\n      // Get back to the beginning of the stream\n      is = new BufferedInputStream(persistenceXml.openStream());\n\n      parserFactory.setNamespaceAware(true);\n\n      int endIndex = persistenceXml.getPath().length() - PERSISTENCE_XML_BASE_NAME.length();\n      URL persistenceXmlRoot = new URL(\"file://\" + persistenceXml.getFile().substring(0, endIndex));\n\n      return getPersistenceUnits(is, persistenceXmlRoot, jpaVersion);\n    } catch (Exception e) {\n      throw new PersistenceException(\"Something goes wrong while parsing persistence.xml\", e);\n    } finally {\n      if (is != null)\n        try {\n          is.close();\n        } catch (IOException e) {\n          // No logging necessary, just consume\n        }\n    }\n  }",
        "modified_code": "public static Collection<? extends PersistenceUnitInfo> parse(URL persistenceXml) {\n\n    InputStream is = null;\n    try {\n      // Buffer the InputStream so we can mark it, though we'll be in\n      // trouble if we have to read more than 8192 characters before finding\n      // the schema!\n      is = new BufferedInputStream(persistenceXml.openStream());\n\n      JPAVersion jpaVersion = getSchemaVersion(is);\n      Schema schema = getSchema(jpaVersion);\n\n      if (schema == null) {\n        throw new PersistenceException(\"Schema is unknown\");\n      }\n\n      // Get back to the beginning of the stream\n      is = new BufferedInputStream(persistenceXml.openStream());\n\n      parserFactory.setNamespaceAware(true);\n\n      int endIndex = persistenceXml.getPath().length() - PERSISTENCE_XML_BASE_NAME.length();\n      URL persistenceXmlRlpt = new URL(\"file://\" + persistenceXml.getFile().substring(0, endIndex));\n\n      return getPersistenceUnits(is, persistenceXmlRlpt, jpaVersion);\n    } catch (Exception e) {\n      throw new PersistenceException(\"Something goes wrong while parsing persistence.xml\", e);\n    } finally {\n      if (is != null)\n        try {\n          is.close();\n        } catch (IOException e) {\n          // No logging necessary, just consume\n        }\n    }\n  }",
        "explanations_by_ours": [
            "the URL of the persistence.xml file relative to the persistence.xml",
            "the URL of the persistence.xml file",
            "the URL of the persistence.xml file relative to the root of the"
        ],
        "corrections_by_ours": [
            "persistenceXmlRoot",
            "persistenceXmlRelative",
            "persistenceUrlRlpt",
            "relativeXmlRlpt",
            "persistenceFileRlpt",
            "persistenceXmlUrl",
            "rootXmlRlpt",
            "fileXmlRlpt",
            "persistenceXmlPersistence",
            "persistenceRelativeRlpt"
        ],
        "corrections_by_baseline": [
            "persistenceXmlRoot",
            "wsEjbMDBuilder",
            "serviceXML",
            "jmsManager",
            "jBossServiceXmlDescriptorParser",
            "localRaXml",
            "raxmls",
            "wwwDDS",
            "jpaContainerManaged",
            "sgrm"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reshit",
        "original_variable": "result",
        "typo_variable": "reshit",
        "original_code": "public Object setPossibleProperty(Map context, Object target, String name, Object value)\n            throws OgnlException\n    {\n        Object result = null;\n        OgnlContext ognlContext = (OgnlContext) context;\n\n        try {\n            if (!OgnlRuntime.setMethodValue(ognlContext, target, name, value, true))\n            {\n                result = OgnlRuntime.setFieldValue(ognlContext, target, name, value) ? null : OgnlRuntime.NotFound;\n            }\n\n            if (result == OgnlRuntime.NotFound)\n            {\n                Method m = OgnlRuntime.getWriteMethod(target.getClass(), name);\n                if (m != null)\n                {\n                    result = m.invoke(target, new Object[] { value});\n                }\n            }\n        } catch (IntrospectionException ex) {\n            throw new OgnlException(name, ex);\n        } catch (OgnlException ex) {\n            throw ex;\n        } catch (Exception ex) {\n            throw new OgnlException(name, ex);\n        }\n\n        return result;\n    }",
        "modified_code": "public Object setPossibleProperty(Map context, Object target, String name, Object value)\n            throws OgnlException\n    {\n        Object reshit = null;\n        OgnlContext ognlContext = (OgnlContext) context;\n\n        try {\n            if (!OgnlRuntime.setMethodValue(ognlContext, target, name, value, true))\n            {\n                reshit = OgnlRuntime.setFieldValue(ognlContext, target, name, value) ? null : OgnlRuntime.NotFound;\n            }\n\n            if (reshit == OgnlRuntime.NotFound)\n            {\n                Method m = OgnlRuntime.getWriteMethod(target.getClass(), name);\n                if (m != null)\n                {\n                    reshit = m.invoke(target, new Object[] { value});\n                }\n            }\n        } catch (IntrospectionException ex) {\n            throw new OgnlException(name, ex);\n        } catch (OgnlException ex) {\n            throw ex;\n        } catch (Exception ex) {\n            throw new OgnlException(name, ex);\n        }\n\n        return reshit;\n    }",
        "explanations_by_ours": [
            "the value of the property",
            "the value of the property, or null if the property could not be",
            "the value of the property, or null if the property is not set"
        ],
        "corrections_by_ours": [
            "sethit",
            "resset",
            "propertyhit",
            "property,hit",
            "resproperty",
            "resproperty,",
            "nullhit",
            "couldhit",
            "valuehit",
            "resnull"
        ],
        "corrections_by_baseline": [
            "refresh",
            "reload",
            "reloadRequired",
            "restart",
            "retention",
            "revalidate",
            "overrun",
            "requiresFlush",
            "retry",
            "rescanTrigger"
        ]
    },
    {
        "original_word": "deleted",
        "typo_word": "eepeted",
        "original_variable": "deleted",
        "typo_variable": "eepeted",
        "original_code": "@Override\n    public boolean deleteAll() {\n\n        boolean deleted = true;\n\n        for (String database : databaseSet()) {\n            deleted = delete(database) && deleted;\n        }\n\n        return deleted;\n    }",
        "modified_code": "@Override\n    public boolean deleteAll() {\n\n        boolean eepeted = true;\n\n        for (String database : databaseSet()) {\n            eepeted = delete(database) && eepeted;\n        }\n\n        return eepeted;\n    }",
        "explanations_by_ours": [
            "the eepeted flag",
            "the eepeted"
        ],
        "corrections_by_ours": [
            "flag"
        ],
        "corrections_by_baseline": [
            "ed",
            "requested",
            "determinant",
            "mefd",
            "ecef",
            "ep",
            "e0",
            "accepted",
            "idle",
            "epo"
        ]
    },
    {
        "original_word": "Without",
        "typo_word": "Wlthouy",
        "original_variable": "uriWithoutPrefix",
        "typo_variable": "uriWlthouyPrefix",
        "original_code": "private InputStream locateStreamWithContextFolder(final String uri, final String contextFolder)\n      throws IOException, FileNotFoundException {\n    if (getWildcardStreamLocator().hasWildcard(uri)) {\n      final String fullPath = WroUtil.getFullPath(uri);\n      final String realPath = contextFolder + fullPath;\n      return getWildcardStreamLocator().locateStream(uri, new File(realPath));\n    }\n\n    final String uriWithoutPrefix = uri.replaceFirst(PREFIX, EMPTY);\n    final File file = new File(contextFolder, uriWithoutPrefix);\n    LOG.debug(\"Opening file: \" + file.getPath());\n    return new FileInputStream(file);\n  }",
        "modified_code": "private InputStream locateStreamWithContextFolder(final String uri, final String contextFolder)\n      throws IOException, FileNotFoundException {\n    if (getWildcardStreamLocator().hasWildcard(uri)) {\n      final String fullPath = WroUtil.getFullPath(uri);\n      final String realPath = contextFolder + fullPath;\n      return getWildcardStreamLocator().locateStream(uri, new File(realPath));\n    }\n\n    final String uriWlthouyPrefix = uri.replaceFirst(PREFIX, EMPTY);\n    final File file = new File(contextFolder, uriWlthouyPrefix);\n    LOG.debug(\"Opening file: \" + file.getPath());\n    return new FileInputStream(file);\n  }",
        "explanations_by_ours": [
            "the prefix of the URI to locate",
            "the prefix to look for in the context folder",
            "the prefix of the URI"
        ],
        "corrections_by_ours": [
            "prefixWlthouyPrefix",
            "uriWlthouyUri",
            "uriLookPrefix",
            "uriLocatePrefix",
            "uriWlthouyContext",
            "lookWlthouyPrefix",
            "contextWlthouyPrefix",
            "locateWlthouyPrefix",
            "folderWlthouyPrefix",
            "uriUriPrefix"
        ],
        "corrections_by_baseline": [
            "uriPrefix",
            "uriWithoutPrefix",
            "urlprefix",
            "fullPrefix",
            "tUriBase",
            "baseUri",
            "baseURI",
            "absURI",
            "canonicalURI",
            "relativeURI"
        ]
    },
    {
        "original_word": "include",
        "typo_word": "imvlude",
        "original_variable": "include",
        "typo_variable": "imvlude",
        "original_code": "protected int serializeKeyValue(final JsonContext jsonContext, final Path currentPath, final Object key, final Object value, int count) {\n\t\tif ((value == null) && jsonContext.isExcludeNulls()) {\n\t\t\treturn count;\n\t\t}\n\n\t\tif (key != null) {\n\t\t\tcurrentPath.push(key.toString());\n\t\t} else {\n\t\t\tcurrentPath.push(StringPool.NULL);\n\t\t}\n\n\t\t// check if we should include the field\n\n\t\tboolean include = true;\n\n\t\tif (value != null) {\n\n\t\t\t// + all collections are not serialized by default\n\n\t\t\tinclude = jsonContext.matchIgnoredPropertyTypes(value.getClass(), false, include);\n\n\t\t\t// + path queries: excludes/includes\n\n\t\t\tinclude = jsonContext.matchPathToQueries(include);\n\t\t}\n\n\t\t// done\n\n\t\tif (!include) {\n\t\t\tcurrentPath.pop();\n\t\t\treturn count;\n\t\t}\n\n\t\tif (key == null) {\n\t\t\tjsonContext.pushName(null, count > 0);\n\t\t} else {\n\t\t\tjsonContext.pushName(key.toString(), count > 0);\n\t\t}\n\n\t\tjsonContext.serialize(value);\n\n\t\tif (jsonContext.isNamePopped()) {\n\t\t\tcount++;\n\t\t}\n\n\t\tcurrentPath.pop();\n\t\treturn count;\n\t}",
        "modified_code": "protected int serializeKeyValue(final JsonContext jsonContext, final Path currentPath, final Object key, final Object value, int count) {\n\t\tif ((value == null) && jsonContext.isExcludeNulls()) {\n\t\t\treturn count;\n\t\t}\n\n\t\tif (key != null) {\n\t\t\tcurrentPath.push(key.toString());\n\t\t} else {\n\t\t\tcurrentPath.push(StringPool.NULL);\n\t\t}\n\n\t\t// check if we should include the field\n\n\t\tboolean imvlude = true;\n\n\t\tif (value != null) {\n\n\t\t\t// + all collections are not serialized by default\n\n\t\t\timvlude = jsonContext.matchIgnoredPropertyTypes(value.getClass(), false, imvlude);\n\n\t\t\t// + path queries: excludes/includes\n\n\t\t\timvlude = jsonContext.matchPathToQueries(imvlude);\n\t\t}\n\n\t\t// done\n\n\t\tif (!imvlude) {\n\t\t\tcurrentPath.pop();\n\t\t\treturn count;\n\t\t}\n\n\t\tif (key == null) {\n\t\t\tjsonContext.pushName(null, count > 0);\n\t\t} else {\n\t\t\tjsonContext.pushName(key.toString(), count > 0);\n\t\t}\n\n\t\tjsonContext.serialize(value);\n\n\t\tif (jsonContext.isNamePopped()) {\n\t\t\tcount++;\n\t\t}\n\n\t\tcurrentPath.pop();\n\t\treturn count;\n\t}",
        "explanations_by_ours": [
            "the imvlude",
            "the imlude",
            "the imvlude"
        ],
        "corrections_by_ours": [
            "imlude"
        ],
        "corrections_by_baseline": [
            "azim",
            "azim0",
            "iminut",
            "udim",
            "IM",
            "dattim",
            "difmin",
            "proxyscope",
            "imr",
            "cosl"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rweult",
        "original_variable": "result",
        "typo_variable": "rweult",
        "original_code": "@Override\n  public int getIndex(T gr) {\n    Integer result =  valMap.get( extract(gr));\n    return (result == null) ? 0 : result;\n  }",
        "modified_code": "@Override\n  public int getIndex(T gr) {\n    Integer rweult =  valMap.get( extract(gr));\n    return (rweult == null) ? 0 : rweult;\n  }",
        "explanations_by_ours": [
            "The result of the lookup.",
            "the result of the lookup"
        ],
        "corrections_by_ours": [
            "result",
            "lookup"
        ],
        "corrections_by_baseline": [
            "rho",
            "rp",
            "isr",
            "r",
            "R",
            "rLPS",
            "rngy",
            "rlam",
            "rrho0",
            "rngx"
        ]
    },
    {
        "original_word": "params",
        "typo_word": "oarzms",
        "original_variable": "params",
        "typo_variable": "oarzms",
        "original_code": "public static byte[] convertECPrivateKeySEC1ToPKCS8(byte[] sec1Key) throws IOException {\n        /**\n         * \u53c2\u8003org.bouncycastle.asn1.pkcs.PrivateKeyInfo\u548c\n         * org.bouncycastle.jcajce.provider.asymmetric.ec.BCECPrivateKey\uff0c\u9006\u5411\u62fc\u88c5\n         */\n        X962Parameters params = getDomainParametersFromName(SM2Util.JDK_EC_SPEC, false);\n        ASN1OctetString privKey = new DEROctetString(sec1Key);\n        ASN1EncodableVector v = new ASN1EncodableVector();\n        v.add(new ASN1Integer(0)); //\u7248\u672c\u53f7\n        v.add(new AlgorithmIdentifier(X9ObjectIdentifiers.id_ecPublicKey, params)); //\u7b97\u6cd5\u6807\u8bc6\n        v.add(privKey);\n        DERSequence ds = new DERSequence(v);\n        return ds.getEncoded(ASN1Encoding.DER);\n    }",
        "modified_code": "public static byte[] convertECPrivateKeySEC1ToPKCS8(byte[] sec1Key) throws IOException {\n        /**\n         * \u53c2\u8003org.bouncycastle.asn1.pkcs.PrivateKeyInfo\u548c\n         * org.bouncycastle.jcajce.provider.asymmetric.ec.BCECPrivateKey\uff0c\u9006\u5411\u62fc\u88c5\n         */\n        X962Parameters oarzms = getDomainParametersFromName(SM2Util.JDK_EC_SPEC, false);\n        ASN1OctetString privKey = new DEROctetString(sec1Key);\n        ASN1EncodableVector v = new ASN1EncodableVector();\n        v.add(new ASN1Integer(0)); //\u7248\u672c\u53f7\n        v.add(new AlgorithmIdentifier(X9ObjectIdentifiers.id_ecPublicKey, oarzms)); //\u7b97\u6cd5\u6807\u8bc6\n        v.add(privKey);\n        DERSequence ds = new DERSequence(v);\n        return ds.getEncoded(ASN1Encoding.DER);\n    }",
        "explanations_by_ours": [
            "X962Parameters",
            "X962Parameters",
            "X962Parameters"
        ],
        "corrections_by_ours": [
            "parameters",
            "x",
            "962"
        ],
        "corrections_by_baseline": [
            "zis",
            "mcs",
            "mrm",
            "mf",
            "dks",
            "vms",
            "mv",
            "zs",
            "osw",
            "mmops"
        ]
    },
    {
        "original_word": "prev",
        "typo_word": "pffv",
        "original_variable": "prevSerializer",
        "typo_variable": "pffvSerializer",
        "original_code": "public static void registerCustomSerializer(CommandCode code, CustomSerializer serializer) {\n        CustomSerializer prevSerializer = commandCustomSerializer.putIfAbsent(code, serializer);\n        if (prevSerializer != null) {\n            throw new RuntimeException(\"CustomSerializer has been registered for command code: \"\n                                       + code + \", the custom serializer is: \"\n                                       + prevSerializer.getClass().getName());\n        }\n    }",
        "modified_code": "public static void registerCustomSerializer(CommandCode code, CustomSerializer serializer) {\n        CustomSerializer pffvSerializer = commandCustomSerializer.putIfAbsent(code, serializer);\n        if (pffvSerializer != null) {\n            throw new RuntimeException(\"CustomSerializer has been registered for command code: \"\n                                       + code + \", the custom serializer is: \"\n                                       + pffvSerializer.getClass().getName());\n        }\n    }",
        "explanations_by_ours": [
            "the custom serializer",
            "the custom serializer to register",
            "the custom serializer to be registered"
        ],
        "corrections_by_ours": [
            "pffvRegister",
            "pffvRegistered",
            "customSerializer",
            "serializerSerializer",
            "registerSerializer",
            "registeredSerializer",
            "pffvCustom",
            "pffvSerializer"
        ],
        "corrections_by_baseline": [
            "binarySerializer",
            "jsonSerializer",
            "serializer",
            "deserializer",
            "clientCustomSerializer",
            "typeJsonSerializer",
            "floatJsonSerializer",
            "serializationWrapper",
            "marshaler",
            "protoBufConverter"
        ]
    },
    {
        "original_word": "services",
        "typo_word": "serbicew",
        "original_variable": "services",
        "typo_variable": "serbicew",
        "original_code": "public void deactivateAndActivate(ServiceID[] arg0, ServiceID[] arg1)\n\t\t\tthrows NullPointerException, InvalidArgumentException,\n\t\t\tUnrecognizedServiceException, InvalidStateException,\n\t\t\tManagementException {\n\n\t\tif (arg0.length == 0 || arg1.length == 0)\n\t\t\tthrow new InvalidArgumentException(\"The parameter array(s) must not be empty.\");\n\t\t\n\t\tif (arg0.length != arg1.length)\n\t\t\tthrow new InvalidArgumentException(\"The parameter arrays must have same lenght.\");\n\t\t\n\t\tSet<ServiceID> services = new HashSet<ServiceID>();\n\t\t\n\t\tfor (int i = 0; i < arg0.length - 1; i++) {\n\t\t\tif (arg0[i] == null || arg1[i] == null) {\n\t\t\t\tthrow new InvalidArgumentException(\"Null entry found in parameter array(s).\");\n\t\t\t}\n\t\t\tif (!services.add(arg0[i]) || !services.add(arg1[i])) {\n\t\t\t\tthrow new InvalidArgumentException(\"Repeated entry found in parameter array(s).\");\n\t\t\t}\n\t\t}\n\t\t\n\t\ttry {\n\t\t\tfor (int i = 0; i < arg0.length; i++) {\n\t\t\t\tdeactivateAndActivate(arg0[i],arg1[i]);\n\t\t\t}\t\t\t\n\t\t} catch (InvalidStateException ise) {\n\t\t\tthrow ise;\n\t\t} catch (ManagementException me) {\n\t\t\tthrow me;\n\t\t}\n\t}",
        "modified_code": "public void deactivateAndActivate(ServiceID[] arg0, ServiceID[] arg1)\n\t\t\tthrows NullPointerException, InvalidArgumentException,\n\t\t\tUnrecognizedServiceException, InvalidStateException,\n\t\t\tManagementException {\n\n\t\tif (arg0.length == 0 || arg1.length == 0)\n\t\t\tthrow new InvalidArgumentException(\"The parameter array(s) must not be empty.\");\n\t\t\n\t\tif (arg0.length != arg1.length)\n\t\t\tthrow new InvalidArgumentException(\"The parameter arrays must have same lenght.\");\n\t\t\n\t\tSet<ServiceID> serbicew = new HashSet<ServiceID>();\n\t\t\n\t\tfor (int i = 0; i < arg0.length - 1; i++) {\n\t\t\tif (arg0[i] == null || arg1[i] == null) {\n\t\t\t\tthrow new InvalidArgumentException(\"Null entry found in parameter array(s).\");\n\t\t\t}\n\t\t\tif (!serbicew.add(arg0[i]) || !serbicew.add(arg1[i])) {\n\t\t\t\tthrow new InvalidArgumentException(\"Repeated entry found in parameter array(s).\");\n\t\t\t}\n\t\t}\n\t\t\n\t\ttry {\n\t\t\tfor (int i = 0; i < arg0.length; i++) {\n\t\t\t\tdeactivateAndActivate(arg0[i],arg1[i]);\n\t\t\t}\t\t\t\n\t\t} catch (InvalidStateException ise) {\n\t\t\tthrow ise;\n\t\t} catch (ManagementException me) {\n\t\t\tthrow me;\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the list of service ids to deactivate and activate",
            "the list of service ids to deactivate and activate.",
            "a set of service id(s) to check"
        ],
        "corrections_by_ours": [
            "service",
            "set",
            "deactivate",
            "list",
            "ids",
            "check",
            "activate",
            "id(s)"
        ],
        "corrections_by_baseline": [
            "anbieter",
            "wierd",
            "ews",
            "coldp",
            "fourn",
            "ser",
            "caw",
            "bern",
            "aw",
            "wis"
        ]
    },
    {
        "original_word": "words",
        "typo_word": "aorfs",
        "original_variable": "words",
        "typo_variable": "aorfs",
        "original_code": "public static void main(String[] args) throws IOException {\r\n\t\tString words = \"sogou/SogouLabDic.dic\";\r\n\t\tString charset = \"GBK\";\r\n\t\tif(args.length > 0) {\r\n\t\t\twords = args[0];\r\n\t\t}\r\n\t\tFile file = new File(words);\r\n\t\t//File path = file.getParentFile();\r\n\t\t//File dist = new File(\"dic/words.dic\");\r\n\t\tFile dist = new File(\"dic/word-with-attr.dic\");\r\n\t\tDicTransform dt = new DicTransform();\r\n\t\t//\u53ea\u8981\u8bcd,\u4e0d\u9891\u7387\r\n\t\t//dt.transform(file, charset, dist, new DeFreq());\r\n\t\t//\u53ea\u8981\u4e24\u6216\u4e09\u4e2a\u5b57\u7684\u8bcd.\r\n\t\t//dt.transform(file, charset, dist, new TwoOrThreeChar());\r\n\t\tdt.transform(file, charset, dist, new NoAttr());\r\n\t}",
        "modified_code": "public static void main(String[] args) throws IOException {\r\n\t\tString aorfs = \"sogou/SogouLabDic.dic\";\r\n\t\tString charset = \"GBK\";\r\n\t\tif(args.length > 0) {\r\n\t\t\taorfs = args[0];\r\n\t\t}\r\n\t\tFile file = new File(aorfs);\r\n\t\t//File path = file.getParentFile();\r\n\t\t//File dist = new File(\"dic/words.dic\");\r\n\t\tFile dist = new File(\"dic/word-with-attr.dic\");\r\n\t\tDicTransform dt = new DicTransform();\r\n\t\t//\u53ea\u8981\u8bcd,\u4e0d\u9891\u7387\r\n\t\t//dt.transform(file, charset, dist, new DeFreq());\r\n\t\t//\u53ea\u8981\u4e24\u6216\u4e09\u4e2a\u5b57\u7684\u8bcd.\r\n\t\t//dt.transform(file, charset, dist, new TwoOrThreeChar());\r\n\t\tdt.transform(file, charset, dist, new NoAttr());\r\n\t}",
        "explanations_by_ours": [
            "sogou/SogouLabDic.dic",
            "aorfs",
            "sogou/SogouLabDic"
        ],
        "corrections_by_ours": [
            "sogoufs",
            "dicfs",
            "fsfs",
            "labfs",
            "aorsogou",
            "aoraor",
            "aordic",
            "aorlab",
            "aorfs"
        ],
        "corrections_by_baseline": [
            "fsi",
            "fs",
            "tryfs",
            "fos",
            "fis",
            "sds",
            "dks",
            "d4ds",
            "toFs",
            "dcs"
        ]
    },
    {
        "original_word": "name",
        "typo_word": "nzmf",
        "original_variable": "vname",
        "typo_variable": "vnzmf",
        "original_code": "public void augmentDataset( NetcdfDataset ds, CancelTask cancelTask) throws IOException {\r\n\r\n    // latitude\r\n    if (!hasAxisType( ds, AxisType.Lat)) { // already has _CoordinateAxisType\r\n\r\n      if ( !addAxisType( ds, \"latitude\", AxisType.Lat)) { // directly named\r\n\r\n        String vname = ds.findAttValueIgnoreCase(null, \"latitude_coordinate\", null);\r\n        if (!addAxisType( ds, vname, AxisType.Lat)) { // attribute named\r\n\r\n          Variable v = hasUnits(ds, \"degrees_north,degrees_N,degreesN,degree_north,degree_N,degreeN\");\r\n          if (v != null)\r\n            addAxisType( v, AxisType.Lat); // CF-1\r\n        }\r\n      }\r\n    }\r\n\r\n    // longitude\r\n    if (!hasAxisType( ds, AxisType.Lon)) { // already has _CoordinateAxisType\r\n\r\n      if ( !addAxisType( ds, \"longitude\", AxisType.Lon)) { // directly named\r\n\r\n        String vname = ds.findAttValueIgnoreCase(null, \"longitude_coordinate\", null);\r\n        if (!addAxisType( ds, vname, AxisType.Lon)) { // attribute named\r\n\r\n          Variable v = hasUnits(ds, \"degrees_east,degrees_E,degreesE,degree_east,degree_E,degreeE\");\r\n          if (v != null)\r\n            addAxisType( v, AxisType.Lon); // CF-1\r\n        }\r\n      }\r\n    }\r\n\r\n      // altitude\r\n      if (!hasAxisType(ds, AxisType.Height)) { // already has _CoordinateAxisType\r\n\r\n        if (!addAxisType(ds, \"altitude\", AxisType.Height)) { // directly named\r\n          if (!addAxisType(ds, \"depth\", AxisType.Height)) { // directly named\r\n\r\n            String vname = ds.findAttValueIgnoreCase(null, \"altitude_coordinate\", null);\r\n            if (!addAxisType(ds, vname, AxisType.Height)) { // attribute named\r\n\r\n              for (int i = 0; i < ds.getVariables().size(); i++) {\r\n                VariableEnhanced ve = (VariableEnhanced) ds.getVariables().get( i );\r\n                String positive = ds.findAttValueIgnoreCase((Variable) ve, CF.POSITIVE, null);\r\n                if (positive != null) {\r\n                  addAxisType((Variable) ve, AxisType.Height); // CF-1\r\n                  break;\r\n                }\r\n              }\r\n            }\r\n          }\r\n        }\r\n      }\r\n\r\n     // time\r\n    if (!hasAxisType( ds, AxisType.Time)) { // already has _CoordinateAxisType\r\n\r\n      if ( !addAxisType( ds, \"time\", AxisType.Time)) { // directly named\r\n\r\n        String vname = ds.findAttValueIgnoreCase(null, \"time_coordinate\", null);\r\n        if (!addAxisType( ds, vname, AxisType.Time)) { // attribute named\r\n\r\n          for (int i = 0; i < ds.getVariables().size(); i++) {\r\n            VariableEnhanced ve = (VariableEnhanced) ds.getVariables().get(i);\r\n            String unit = ve.getUnitsString();\r\n            if (unit == null) continue;\r\n            if (SimpleUnit.isDateUnit(unit)) {\r\n              addAxisType( (Variable) ve, AxisType.Time); // CF-1\r\n              break;\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n  }",
        "modified_code": "public void augmentDataset( NetcdfDataset ds, CancelTask cancelTask) throws IOException {\r\n\r\n    // latitude\r\n    if (!hasAxisType( ds, AxisType.Lat)) { // already has _CoordinateAxisType\r\n\r\n      if ( !addAxisType( ds, \"latitude\", AxisType.Lat)) { // directly named\r\n\r\n        String vnzmf = ds.findAttValueIgnoreCase(null, \"latitude_coordinate\", null);\r\n        if (!addAxisType( ds, vnzmf, AxisType.Lat)) { // attribute named\r\n\r\n          Variable v = hasUnits(ds, \"degrees_north,degrees_N,degreesN,degree_north,degree_N,degreeN\");\r\n          if (v != null)\r\n            addAxisType( v, AxisType.Lat); // CF-1\r\n        }\r\n      }\r\n    }\r\n\r\n    // longitude\r\n    if (!hasAxisType( ds, AxisType.Lon)) { // already has _CoordinateAxisType\r\n\r\n      if ( !addAxisType( ds, \"longitude\", AxisType.Lon)) { // directly named\r\n\r\n        String vnzmf = ds.findAttValueIgnoreCase(null, \"longitude_coordinate\", null);\r\n        if (!addAxisType( ds, vnzmf, AxisType.Lon)) { // attribute named\r\n\r\n          Variable v = hasUnits(ds, \"degrees_east,degrees_E,degreesE,degree_east,degree_E,degreeE\");\r\n          if (v != null)\r\n            addAxisType( v, AxisType.Lon); // CF-1\r\n        }\r\n      }\r\n    }\r\n\r\n      // altitude\r\n      if (!hasAxisType(ds, AxisType.Height)) { // already has _CoordinateAxisType\r\n\r\n        if (!addAxisType(ds, \"altitude\", AxisType.Height)) { // directly named\r\n          if (!addAxisType(ds, \"depth\", AxisType.Height)) { // directly named\r\n\r\n            String vnzmf = ds.findAttValueIgnoreCase(null, \"altitude_coordinate\", null);\r\n            if (!addAxisType(ds, vnzmf, AxisType.Height)) { // attribute named\r\n\r\n              for (int i = 0; i < ds.getVariables().size(); i++) {\r\n                VariableEnhanced ve = (VariableEnhanced) ds.getVariables().get( i );\r\n                String positive = ds.findAttValueIgnoreCase((Variable) ve, CF.POSITIVE, null);\r\n                if (positive != null) {\r\n                  addAxisType((Variable) ve, AxisType.Height); // CF-1\r\n                  break;\r\n                }\r\n              }\r\n            }\r\n          }\r\n        }\r\n      }\r\n\r\n     // time\r\n    if (!hasAxisType( ds, AxisType.Time)) { // already has _CoordinateAxisType\r\n\r\n      if ( !addAxisType( ds, \"time\", AxisType.Time)) { // directly named\r\n\r\n        String vnzmf = ds.findAttValueIgnoreCase(null, \"time_coordinate\", null);\r\n        if (!addAxisType( ds, vnzmf, AxisType.Time)) { // attribute named\r\n\r\n          for (int i = 0; i < ds.getVariables().size(); i++) {\r\n            VariableEnhanced ve = (VariableEnhanced) ds.getVariables().get(i);\r\n            String unit = ve.getUnitsString();\r\n            if (unit == null) continue;\r\n            if (SimpleUnit.isDateUnit(unit)) {\r\n              addAxisType( (Variable) ve, AxisType.Time); // CF-1\r\n              break;\r\n            }\r\n          }\r\n        }\r\n      }\r\n    }\r\n\r\n  }",
        "explanations_by_ours": [
            "The name of the attribute to be added to the NetcdfDataset.",
            "The name of the coordinate attribute to be added to the dataset.",
            "The name of the attribute to be added to the dataset."
        ],
        "corrections_by_ours": [
            "name",
            "net",
            "cdf",
            "coordinate",
            "dataset",
            "added",
            "attribute"
        ],
        "corrections_by_baseline": [
            "vf",
            "mefd",
            "mf",
            "vz",
            "nz",
            "vNyq",
            "exp2p",
            "uvf",
            "f0",
            "fv"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resklg",
        "original_variable": "result",
        "typo_variable": "resklg",
        "original_code": "private static void splitProjectionsForGroupBy(QueryPlanningInfo info, OCommandContext ctx) {\n    if (info.projection == null) {\n      return;\n    }\n\n    OProjection preAggregate = new OProjection(-1);\n    preAggregate.setItems(new ArrayList<>());\n    OProjection aggregate = new OProjection(-1);\n    aggregate.setItems(new ArrayList<>());\n    OProjection postAggregate = new OProjection(-1);\n    postAggregate.setItems(new ArrayList<>());\n\n    boolean isSplitted = false;\n\n    //split for aggregate projections\n    AggregateProjectionSplit result = new AggregateProjectionSplit();\n    for (OProjectionItem item : info.projection.getItems()) {\n      result.reset();\n      if (isAggregate(item)) {\n        isSplitted = true;\n        OProjectionItem post = item.splitForAggregation(result, ctx);\n        OIdentifier postAlias = item.getProjectionAlias();\n        postAlias = new OIdentifier(postAlias, true);\n        post.setAlias(postAlias);\n        postAggregate.getItems().add(post);\n        aggregate.getItems().addAll(result.getAggregate());\n        preAggregate.getItems().addAll(result.getPreAggregate());\n      } else {\n        preAggregate.getItems().add(item);\n        //also push the alias forward in the chain\n        OProjectionItem aggItem = new OProjectionItem(-1);\n        aggItem.setExpression(new OExpression(item.getProjectionAlias()));\n        aggregate.getItems().add(aggItem);\n        postAggregate.getItems().add(aggItem);\n      }\n    }\n\n    //bind split projections to the execution planner\n    if (isSplitted) {\n      info.preAggregateProjection = preAggregate;\n      if (info.preAggregateProjection.getItems() == null || info.preAggregateProjection.getItems().size() == 0) {\n        info.preAggregateProjection = null;\n      }\n      info.aggregateProjection = aggregate;\n      if (info.aggregateProjection.getItems() == null || info.aggregateProjection.getItems().size() == 0) {\n        info.aggregateProjection = null;\n      }\n      info.projection = postAggregate;\n\n      addGroupByExpressionsToProjections(info);\n    }\n  }",
        "modified_code": "private static void splitProjectionsForGroupBy(QueryPlanningInfo info, OCommandContext ctx) {\n    if (info.projection == null) {\n      return;\n    }\n\n    OProjection preAggregate = new OProjection(-1);\n    preAggregate.setItems(new ArrayList<>());\n    OProjection aggregate = new OProjection(-1);\n    aggregate.setItems(new ArrayList<>());\n    OProjection postAggregate = new OProjection(-1);\n    postAggregate.setItems(new ArrayList<>());\n\n    boolean isSplitted = false;\n\n    //split for aggregate projections\n    AggregateProjectionSplit resklg = new AggregateProjectionSplit();\n    for (OProjectionItem item : info.projection.getItems()) {\n      resklg.reset();\n      if (isAggregate(item)) {\n        isSplitted = true;\n        OProjectionItem post = item.splitForAggregation(resklg, ctx);\n        OIdentifier postAlias = item.getProjectionAlias();\n        postAlias = new OIdentifier(postAlias, true);\n        post.setAlias(postAlias);\n        postAggregate.getItems().add(post);\n        aggregate.getItems().addAll(resklg.getAggregate());\n        preAggregate.getItems().addAll(resklg.getPreAggregate());\n      } else {\n        preAggregate.getItems().add(item);\n        //also push the alias forward in the chain\n        OProjectionItem aggItem = new OProjectionItem(-1);\n        aggItem.setExpression(new OExpression(item.getProjectionAlias()));\n        aggregate.getItems().add(aggItem);\n        postAggregate.getItems().add(aggItem);\n      }\n    }\n\n    //bind split projections to the execution planner\n    if (isSplitted) {\n      info.preAggregateProjection = preAggregate;\n      if (info.preAggregateProjection.getItems() == null || info.preAggregateProjection.getItems().size() == 0) {\n        info.preAggregateProjection = null;\n      }\n      info.aggregateProjection = aggregate;\n      if (info.aggregateProjection.getItems() == null || info.aggregateProjection.getItems().size() == 0) {\n        info.aggregateProjection = null;\n      }\n      info.projection = postAggregate;\n\n      addGroupByExpressionsToProjections(info);\n    }\n  }",
        "explanations_by_ours": [
            "the resklg",
            "the resklg to use",
            "the resklg for the group by"
        ],
        "corrections_by_ours": [
            "use",
            "group"
        ],
        "corrections_by_baseline": [
            "stg",
            "gcs",
            "jg",
            "misflg",
            "g",
            "jbndg",
            "resul",
            "glamn",
            "gts",
            "jbeg"
        ]
    },
    {
        "original_word": "Splitting",
        "typo_word": "Splitginb",
        "original_variable": "versionSplittingIndex",
        "typo_variable": "versionSplitginbIndex",
        "original_code": "public static String getNextProductVersion(String version) throws PluginExecutionException {\n        String result = null;\n        int versionSplittingIndex = version.lastIndexOf(\".\") + 1;\n        if (versionSplittingIndex == 0) {\n            throw new PluginExecutionException(\"Product version \" + version\n                    + \" is not in the expected format. It must have period separated version segments.\");\n        }\n        String quarterVersion = version.substring(versionSplittingIndex);\n        int nextQuarterSpecifier;\n        try {\n            nextQuarterSpecifier = Integer.parseInt(quarterVersion) + 1;\n        } catch (NumberFormatException e) {\n            throw new PluginExecutionException(\"Product version \" + version\n                    + \" is not in the expected format. Its last segment is expected to be an integer.\", e);\n        }\n        result = version.substring(0, versionSplittingIndex) + nextQuarterSpecifier;\n        return result;\n    }",
        "modified_code": "public static String getNextProductVersion(String version) throws PluginExecutionException {\n        String result = null;\n        int versionSplitginbIndex = version.lastIndexOf(\".\") + 1;\n        if (versionSplitginbIndex == 0) {\n            throw new PluginExecutionException(\"Product version \" + version\n                    + \" is not in the expected format. It must have period separated version segments.\");\n        }\n        String quarterVersion = version.substring(versionSplitginbIndex);\n        int nextQuarterSpecifier;\n        try {\n            nextQuarterSpecifier = Integer.parseInt(quarterVersion) + 1;\n        } catch (NumberFormatException e) {\n            throw new PluginExecutionException(\"Product version \" + version\n                    + \" is not in the expected format. Its last segment is expected to be an integer.\", e);\n        }\n        result = version.substring(0, versionSplitginbIndex) + nextQuarterSpecifier;\n        return result;\n    }",
        "explanations_by_ours": [
            "The index of the last period separated version segment.",
            "The index of the last period separated version segment in the given version.",
            "The index of the last segment of the version."
        ],
        "corrections_by_ours": [
            "periodSplitginbIndex",
            "separatedSplitginbIndex",
            "versionPeriodIndex",
            "versionSegmentIndex",
            "versionGivenIndex",
            "versionSplitginbGiven",
            "lastSplitginbIndex",
            "segmentSplitginbIndex",
            "givenSplitginbIndex",
            "versionSplitginbSegment"
        ],
        "corrections_by_baseline": [
            "versionSplittingIndex",
            "versionParts",
            "versionPrefixParts",
            "dmrversion",
            "cncVersion",
            "partitionIndexFilename",
            "secondVersion",
            "versionStr",
            "mvnVersion",
            "dapversion"
        ]
    },
    {
        "original_word": "basis",
        "typo_word": "nasjs",
        "original_variable": "basis",
        "typo_variable": "nasjs",
        "original_code": "private InputStream getInputStream(String publicid, String systemid) throws IOException, SAXException {\n        URL basis = new URL(\"file\", \"\", System.getProperty(\"user.dir\") + \"/.\");\n        URL url = new URL(basis, systemid);\n        URLConnection c = url.openConnection();\n        return c.getInputStream();\n    }",
        "modified_code": "private InputStream getInputStream(String publicid, String systemid) throws IOException, SAXException {\n        URL nasjs = new URL(\"file\", \"\", System.getProperty(\"user.dir\") + \"/.\");\n        URL url = new URL(nasjs, systemid);\n        URLConnection c = url.openConnection();\n        return c.getInputStream();\n    }",
        "explanations_by_ours": [
            "The nasjs file.",
            "The nasjs URL.",
            "nasjs"
        ],
        "corrections_by_ours": [
            "url",
            "file"
        ],
        "corrections_by_baseline": [
            "jsons",
            "tjs",
            "jsse",
            "objs",
            "downloadedJsons",
            "jsseDomain",
            "jsfModule",
            "jsid",
            "ja",
            "jars"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "cohjt",
        "original_variable": "count",
        "typo_variable": "cohjt",
        "original_code": "public static String deleteWhitespace(final String s) {\n        if (isEmpty(s)) {\n            return s;\n        }\n        final int sz = s.length();\n        final char[] chs = new char[sz];\n        int count = 0;\n        for (int i = 0; i < sz; i++) {\n            if (!Character.isWhitespace(s.charAt(i))) {\n                chs[count++] = s.charAt(i);\n            }\n        }\n        if (count == sz) {\n            return s;\n        }\n        return new String(chs, 0, count);\n    }",
        "modified_code": "public static String deleteWhitespace(final String s) {\n        if (isEmpty(s)) {\n            return s;\n        }\n        final int sz = s.length();\n        final char[] chs = new char[sz];\n        int cohjt = 0;\n        for (int i = 0; i < sz; i++) {\n            if (!Character.isWhitespace(s.charAt(i))) {\n                chs[cohjt++] = s.charAt(i);\n            }\n        }\n        if (cohjt == sz) {\n            return s;\n        }\n        return new String(chs, 0, cohjt);\n    }",
        "explanations_by_ours": [
            "The number of characters to be removed.",
            "The number of characters to remove.",
            "The number of characters to remove from the string."
        ],
        "corrections_by_ours": [
            "characters",
            "removed",
            "string",
            "remove",
            "number"
        ],
        "corrections_by_baseline": [
            "pco",
            "projCT",
            "jdrct",
            "qco",
            "jshft",
            "dcon",
            "co",
            "utco",
            "jinc",
            "jsc"
        ]
    },
    {
        "original_word": "locs",
        "typo_word": "ikcs",
        "original_variable": "plocs",
        "typo_variable": "pikcs",
        "original_code": "public ProfileLocalObject findProfileByAttribute(String attributeName,\n\t\t\tObject attributeValue) throws NullPointerException,\n\t\t\tIllegalArgumentException, TransactionRequiredLocalException,\n\t\t\tSLEEException {\n\t\t\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"findProfileByAttribute( attributeName = \"+attributeName+\" , attributeValue = \"+attributeValue+\" )\");\n\t\t}\n\t\t\n\t\tCollection<ProfileLocalObject> plocs = findProfilesByAttribute(attributeName, attributeValue);\n\t    if(plocs.size() == 0) {\n\t    \treturn null;\n\t    }\n\t    else {\n\t    \treturn plocs.iterator().next();\n\t    }\n\t}",
        "modified_code": "public ProfileLocalObject findProfileByAttribute(String attributeName,\n\t\t\tObject attributeValue) throws NullPointerException,\n\t\t\tIllegalArgumentException, TransactionRequiredLocalException,\n\t\t\tSLEEException {\n\t\t\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"findProfileByAttribute( attributeName = \"+attributeName+\" , attributeValue = \"+attributeValue+\" )\");\n\t\t}\n\t\t\n\t\tCollection<ProfileLocalObject> pikcs = findProfilesByAttribute(attributeName, attributeValue);\n\t    if(pikcs.size() == 0) {\n\t    \treturn null;\n\t    }\n\t    else {\n\t    \treturn pikcs.iterator().next();\n\t    }\n\t}",
        "explanations_by_ours": [
            "the pikcs",
            "the list of profiles",
            "the pikcs to search"
        ],
        "corrections_by_ours": [
            "profiles",
            "list",
            "search"
        ],
        "corrections_by_baseline": [
            "gvcs",
            "hcs",
            "gcs",
            "vcs",
            "mcs",
            "dcs",
            "csa",
            "dks",
            "csh",
            "pkinf"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "coumf",
        "original_variable": "count",
        "typo_variable": "coumf",
        "original_code": "public int index(FeatureIndexType type, boolean force) {\n        if (type == null) {\n            throw new GeoPackageException(\"FeatureIndexType is required to index\");\n        }\n        int count = 0;\n        switch (type) {\n            case GEOPACKAGE:\n                count = featureTableIndex.index(force);\n                break;\n            case METADATA:\n                count = featureIndexer.index(force);\n                break;\n            case RTREE:\n                boolean rTreeIndexed = rTreeIndexTableDao.has();\n                if (!rTreeIndexed || force) {\n                    if (rTreeIndexed) {\n                        rTreeIndexTableDao.delete();\n                    }\n                    rTreeIndexTableDao.create();\n                    count = rTreeIndexTableDao.count();\n                }\n                break;\n            default:\n                throw new GeoPackageException(\"Unsupported FeatureIndexType: \"\n                        + type);\n        }\n        return count;\n    }",
        "modified_code": "public int index(FeatureIndexType type, boolean force) {\n        if (type == null) {\n            throw new GeoPackageException(\"FeatureIndexType is required to index\");\n        }\n        int coumf = 0;\n        switch (type) {\n            case GEOPACKAGE:\n                coumf = featureTableIndex.index(force);\n                break;\n            case METADATA:\n                coumf = featureIndexer.index(force);\n                break;\n            case RTREE:\n                boolean rTreeIndexed = rTreeIndexTableDao.has();\n                if (!rTreeIndexed || force) {\n                    if (rTreeIndexed) {\n                        rTreeIndexTableDao.delete();\n                    }\n                    rTreeIndexTableDao.create();\n                    coumf = rTreeIndexTableDao.coumf();\n                }\n                break;\n            default:\n                throw new GeoPackageException(\"Unsupported FeatureIndexType: \"\n                        + type);\n        }\n        return coumf;\n    }",
        "explanations_by_ours": [
            "feature index result",
            "index result",
            "feature index coumf"
        ],
        "corrections_by_ours": [
            "result",
            "feature",
            "index"
        ],
        "corrections_by_baseline": [
            "hf",
            "cgaw",
            "icf",
            "ncf",
            "csm",
            "sdc",
            "acf",
            "caw",
            "coldp",
            "coun"
        ]
    },
    {
        "original_word": "converted",
        "typo_word": "cohvertee",
        "original_variable": "converted",
        "typo_variable": "cohvertee",
        "original_code": "Set<org.apache.parquet.column.Encoding> fromFormatEncodings(List<Encoding> encodings) {\n    Set<org.apache.parquet.column.Encoding> converted = new HashSet<org.apache.parquet.column.Encoding>();\n\n    for (Encoding encoding : encodings) {\n      converted.add(getEncoding(encoding));\n    }\n\n    // make converted unmodifiable, drop reference to modifiable copy\n    converted = Collections.unmodifiableSet(converted);\n\n    // atomically update the cache\n    Set<org.apache.parquet.column.Encoding> cached = cachedEncodingSets.putIfAbsent(converted, converted);\n\n    if (cached == null) {\n      // cached == null signifies that converted was *not* in the cache previously\n      // so we can return converted instead of throwing it away, it has now\n      // been cached\n      cached = converted;\n    }\n\n    return cached;\n  }",
        "modified_code": "Set<org.apache.parquet.column.Encoding> fromFormatEncodings(List<Encoding> encodings) {\n    Set<org.apache.parquet.column.Encoding> cohvertee = new HashSet<org.apache.parquet.column.Encoding>();\n\n    for (Encoding encoding : encodings) {\n      cohvertee.add(getEncoding(encoding));\n    }\n\n    // make converted unmodifiable, drop reference to modifiable copy\n    cohvertee = Collections.unmodifiableSet(cohvertee);\n\n    // atomically update the cache\n    Set<org.apache.parquet.column.Encoding> cached = cachedEncodingSets.putIfAbsent(cohvertee, cohvertee);\n\n    if (cached == null) {\n      // cached == null signifies that converted was *not* in the cache previously\n      // so we can return converted instead of throwing it away, it has now\n      // been cached\n      cached = cohvertee;\n    }\n\n    return cached;\n  }",
        "explanations_by_ours": [
            "the set of org.apache.parquet.column.",
            "the set of encodings to convert",
            "the set of encodings to be converted"
        ],
        "corrections_by_ours": [
            "converted",
            "convert",
            "column",
            "org",
            "set",
            "apache",
            "parquet",
            "encodings"
        ],
        "corrections_by_baseline": [
            "co",
            "utco",
            "pco",
            "sco",
            "qco",
            "caco",
            "dcon",
            "TOLERENCE",
            "cooIdx",
            "ois"
        ]
    },
    {
        "original_word": "parts",
        "typo_word": "latts",
        "original_variable": "parts",
        "typo_variable": "latts",
        "original_code": "void addFilter(final String condition, final Object value) {\r\n\r\n\t\tfinal String[] parts = condition.trim().split(\" \");\r\n\t\tif (parts.length < 1 || parts.length > 2)\r\n\t\t\tthrow new IllegalArgumentException(\"'\" + condition + \"' is not a legal filter condition\");\r\n\r\n\t\tfinal String prop = parts[0].trim();\r\n\t\tfinal FilterOperator op = (parts.length == 2) ? this.translate(parts[1]) : FilterOperator.EQUAL;\r\n\r\n\t\t// If we have a class restriction, check to see if the property is the @Parent or @Id. We used to try to convert\r\n\t\t// filtering on the id field to a __key__ query, but that tended to confuse users about the real capabilities\r\n\t\t// of GAE and Objectify. So let's force users to use filterKey() instead.\r\n\t\tif (this.classRestriction != null) {\r\n\t\t\tfinal KeyMetadata<?> meta = loader.ofy.factory().keys().getMetadataSafe(this.classRestriction);\r\n\r\n\t\t\tif (prop.equals(meta.getParentFieldName())) {\r\n\t\t\t\tthrow new IllegalArgumentException(\"@Parent fields cannot be filtered on. Perhaps you wish to use filterKey() or ancestor() instead?\");\r\n\t\t\t}\r\n\t\t\telse if (prop.equals(meta.getIdFieldName())) {\r\n\t\t\t\tthrow new IllegalArgumentException(\"@Id fields cannot be filtered on. Perhaps you wish to use filterKey() instead?\");\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\t// Convert to something filterable, possibly extracting/converting keys\r\n\t\tfinal Value<?> translated = loader.getObjectifyImpl().makeFilterable(value);\r\n\r\n\t\taddFilter(op.of(prop, translated));\r\n\t}",
        "modified_code": "void addFilter(final String condition, final Object value) {\r\n\r\n\t\tfinal String[] latts = condition.trim().split(\" \");\r\n\t\tif (latts.length < 1 || latts.length > 2)\r\n\t\t\tthrow new IllegalArgumentException(\"'\" + condition + \"' is not a legal filter condition\");\r\n\r\n\t\tfinal String prop = latts[0].trim();\r\n\t\tfinal FilterOperator op = (latts.length == 2) ? this.translate(latts[1]) : FilterOperator.EQUAL;\r\n\r\n\t\t// If we have a class restriction, check to see if the property is the @Parent or @Id. We used to try to convert\r\n\t\t// filtering on the id field to a __key__ query, but that tended to confuse users about the real capabilities\r\n\t\t// of GAE and Objectify. So let's force users to use filterKey() instead.\r\n\t\tif (this.classRestriction != null) {\r\n\t\t\tfinal KeyMetadata<?> meta = loader.ofy.factory().keys().getMetadataSafe(this.classRestriction);\r\n\r\n\t\t\tif (prop.equals(meta.getParentFieldName())) {\r\n\t\t\t\tthrow new IllegalArgumentException(\"@Parent fields cannot be filtered on. Perhaps you wish to use filterKey() or ancestor() instead?\");\r\n\t\t\t}\r\n\t\t\telse if (prop.equals(meta.getIdFieldName())) {\r\n\t\t\t\tthrow new IllegalArgumentException(\"@Id fields cannot be filtered on. Perhaps you wish to use filterKey() instead?\");\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\t// Convert to something filterable, possibly extracting/converting keys\r\n\t\tfinal Value<?> translated = loader.getObjectifyImpl().makeFilterable(value);\r\n\r\n\t\taddFilter(op.of(prop, translated));\r\n\t}",
        "explanations_by_ours": [
            "the comma separated list of filter properties",
            "the comma separated list of the filter condition",
            "the comma separated list of the filter properties"
        ],
        "corrections_by_ours": [
            "list",
            "separated",
            "properties",
            "filter",
            "condition",
            "comma"
        ],
        "corrections_by_baseline": [
            "tslat",
            "lats",
            "latArray",
            "lat",
            "lons",
            "latIter",
            "latBuff",
            "latDegrees",
            "latData",
            "latlon"
        ]
    },
    {
        "original_word": "reqs",
        "typo_word": "ffqs",
        "original_variable": "preqs",
        "typo_variable": "pffqs",
        "original_code": "protected void printStatus(PrintWriter os)\n    {\n        os.println(\"<h2>Server version = \" + getServerVersion() + \"</h2>\");\n        os.println(\"<h2>Number of Requests Received = \" + HitCounter + \"</h2>\");\n        if(track) {\n            int n = prArr.size();\n            int pending = 0;\n            StringBuilder preqs = new StringBuilder();\n            for(int i = 0; i < n; i++) {\n                ReqState rs = (ReqState) prArr.get(i);\n                RequestDebug reqD = (RequestDebug) rs.getUserObject();\n                if(!reqD.done) {\n                    preqs.append(\"<pre>-----------------------\\n\");\n                    preqs.append(\"Request[\");\n                    preqs.append(reqD.reqno);\n                    preqs.append(\"](\");\n                    preqs.append(reqD.threadDesc);\n                    preqs.append(\") is pending.\\n\");\n                    preqs.append(rs.toString());\n                    preqs.append(\"</pre>\");\n                    pending++;\n                }\n            }\n            os.println(\"<h2>\" + pending + \" Pending Request(s)</h2>\");\n            os.println(preqs.toString());\n        }\n    }",
        "modified_code": "protected void printStatus(PrintWriter os)\n    {\n        os.println(\"<h2>Server version = \" + getServerVersion() + \"</h2>\");\n        os.println(\"<h2>Number of Requests Received = \" + HitCounter + \"</h2>\");\n        if(track) {\n            int n = prArr.size();\n            int pending = 0;\n            StringBuilder pffqs = new StringBuilder();\n            for(int i = 0; i < n; i++) {\n                ReqState rs = (ReqState) prArr.get(i);\n                RequestDebug reqD = (RequestDebug) rs.getUserObject();\n                if(!reqD.done) {\n                    pffqs.append(\"<pre>-----------------------\\n\");\n                    pffqs.append(\"Request[\");\n                    pffqs.append(reqD.reqno);\n                    pffqs.append(\"](\");\n                    pffqs.append(reqD.threadDesc);\n                    pffqs.append(\") is pending.\\n\");\n                    pffqs.append(rs.toString());\n                    pffqs.append(\"</pre>\");\n                    pending++;\n                }\n            }\n            os.println(\"<h2>\" + pending + \" Pending Request(s)</h2>\");\n            os.println(pffqs.toString());\n        }\n    }",
        "explanations_by_ours": [
            "the string to append to the output stream",
            "the string to append to the output stream.",
            "the string to append to the output"
        ],
        "corrections_by_ours": [
            "append",
            "string",
            "output",
            "stream"
        ],
        "corrections_by_baseline": [
            "psb",
            "lp_alp",
            "psdf",
            "pcf",
            "rawPPS",
            "qd",
            "pds",
            "cqf",
            "ps",
            "avgQp"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "eeault",
        "original_variable": "result",
        "typo_variable": "eeault",
        "original_code": "static public String[] extractDefaultReplacement(String key) {\n    String[] result = new String[2];\n    if(key == null)\n      return result;\n\n    result[0] = key;\n    int d = key.indexOf(DELIM_DEFAULT);\n    if (d != -1) {\n      result[0] = key.substring(0, d);\n      result[1] = key.substring(d + DELIM_DEFAULT_LEN);\n    }\n    return result;\n  }",
        "modified_code": "static public String[] extractDefaultReplacement(String key) {\n    String[] eeault = new String[2];\n    if(key == null)\n      return eeault;\n\n    eeault[0] = key;\n    int d = key.indexOf(DELIM_DEFAULT);\n    if (d != -1) {\n      eeault[0] = key.substring(0, d);\n      eeault[1] = key.substring(d + DELIM_DEFAULT_LEN);\n    }\n    return eeault;\n  }",
        "explanations_by_ours": [
            "an array to store the extracted default replacement",
            "an array of two elements",
            "an array to store the extracted default replacement."
        ],
        "corrections_by_ours": [
            "default",
            "elements",
            "replacement",
            "extracted",
            "store",
            "array",
            "two"
        ],
        "corrections_by_baseline": [
            "vault",
            "EE",
            "ee",
            "sbbEntity",
            "eeSubSystem",
            "receivableService",
            "raEntity",
            "artemisService",
            "petiteBean",
            "accel"
        ]
    },
    {
        "original_word": "decorated",
        "typo_word": "decofatex",
        "original_variable": "decoratedProcessor",
        "typo_variable": "decofatexProcessor",
        "original_code": "private String applyPreProcessors(final Resource resource, final ProcessingCriteria criteria)\n      throws IOException {\n    final Collection<ResourcePreProcessor> processors = processorsFactory.getPreProcessors();\n    LOG.debug(\"applying preProcessors: {}\", processors);\n\n    String resourceContent = null;\n    try {\n      resourceContent = getResourceContent(resource);\n    } catch (final IOException e) {\n      LOG.debug(\"Invalid resource found: {}\", resource);\n      if (Context.get().getConfig().isIgnoreMissingResources()) {\n        return StringUtils.EMPTY;\n      } else {\n        LOG.error(\"Cannot ignore missing resource:  {}\", resource);\n        throw e;\n      }\n    }\n    if (!processors.isEmpty()) {\n      Writer writer = null;\n      for (final ResourcePreProcessor processor : processors) {\n        final ResourcePreProcessor decoratedProcessor = decoratePreProcessor(processor, criteria);\n\n        writer = new StringWriter();\n        final Reader reader = new StringReader(resourceContent);\n        // decorate and process\n        decoratedProcessor.process(resource, reader, writer);\n        // use the outcome for next input\n        resourceContent = writer.toString();\n      }\n    }\n    // add explicitly new line at the end to avoid unexpected comment issue\n    return String.format(\"%s%n\", resourceContent);\n  }",
        "modified_code": "private String applyPreProcessors(final Resource resource, final ProcessingCriteria criteria)\n      throws IOException {\n    final Collection<ResourcePreProcessor> processors = processorsFactory.getPreProcessors();\n    LOG.debug(\"applying preProcessors: {}\", processors);\n\n    String resourceContent = null;\n    try {\n      resourceContent = getResourceContent(resource);\n    } catch (final IOException e) {\n      LOG.debug(\"Invalid resource found: {}\", resource);\n      if (Context.get().getConfig().isIgnoreMissingResources()) {\n        return StringUtils.EMPTY;\n      } else {\n        LOG.error(\"Cannot ignore missing resource:  {}\", resource);\n        throw e;\n      }\n    }\n    if (!processors.isEmpty()) {\n      Writer writer = null;\n      for (final ResourcePreProcessor processor : processors) {\n        final ResourcePreProcessor decofatexProcessor = decoratePreProcessor(processor, criteria);\n\n        writer = new StringWriter();\n        final Reader reader = new StringReader(resourceContent);\n        // decorate and process\n        decofatexProcessor.process(resource, reader, writer);\n        // use the outcome for next input\n        resourceContent = writer.toString();\n      }\n    }\n    // add explicitly new line at the end to avoid unexpected comment issue\n    return String.format(\"%s%n\", resourceContent);\n  }",
        "explanations_by_ours": [
            "the decofatex processor",
            "the decofatex processor to use",
            "the processor to apply"
        ],
        "corrections_by_ours": [
            "useProcessor",
            "processorProcessor",
            "decofatexUse",
            "decofatexDecofatex",
            "applyProcessor",
            "decofatexApply",
            "decofatexProcessor"
        ],
        "corrections_by_baseline": [
            "decoratedProcessor",
            "processor",
            "preProcessor",
            "decompressor",
            "applyProcessor",
            "processors",
            "substitutionElementWrapper",
            "formater",
            "namedAttributeProcessor",
            "compressor"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "cirrenh",
        "original_variable": "current",
        "typo_variable": "cirrenh",
        "original_code": "public long size() {\n        SparseBitSet current;\n        long size;\n        do {\n            current = sparseBitSetVolatile;\n            size = current.estimateBitsUsed();\n        } while (current != sparseBitSetVolatile);\n        return size;\n    }",
        "modified_code": "public long size() {\n        SparseBitSet cirrenh;\n        long size;\n        do {\n            cirrenh = sparseBitSetVolatile;\n            size = cirrenh.estimateBitsUsed();\n        } while (cirrenh != sparseBitSetVolatile);\n        return size;\n    }",
        "explanations_by_ours": [
            "the sparse set",
            "the sparse set.",
            "the sparse set to get the number of bits in"
        ],
        "corrections_by_ours": [
            "get",
            "sparse",
            "set",
            "number",
            "bits"
        ],
        "corrections_by_baseline": [
            "cir",
            "irw",
            "calt",
            "dou",
            "LULC",
            "lac",
            "dra",
            "redir",
            "barrier",
            "xyir"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "cigrent",
        "original_variable": "currentViewIndex",
        "typo_variable": "cigrentViewIndex",
        "original_code": "protected void restoreState() {\n    if (store == null) {\n      return;\n    }\n\n    ArrayList propColObjs = (ArrayList) store.getBean(\"propertyCol\", new ArrayList());\n    HidableTableColumnModel tableColumnModel = (HidableTableColumnModel) jtable.getColumnModel();\n    int newViewIndex = 0;\n\n    for (Object propColObj : propColObjs) {\n      PropertyCol propCol = (PropertyCol) propColObj;\n      try {\n        int currentViewIndex = tableColumnModel.getColumnIndex(propCol.getName());  // May throw IAE.\n\n        TableColumn column = tableColumnModel.getColumn(currentViewIndex);\n        column.setPreferredWidth(propCol.getWidth());\n\n        tableColumnModel.moveColumn(currentViewIndex, newViewIndex);\n        assert tableColumnModel.getColumn(newViewIndex) == column : \"tableColumn wasn't successfully moved.\";\n\n        // We must do this last, since moveColumn() only works on visible columns.\n        tableColumnModel.setColumnVisible(column, propCol.isVisible());\n        if (propCol.isVisible()) {\n          ++newViewIndex;  // Don't increment for hidden columns.\n        }\n      } catch (IllegalArgumentException e) {\n        logger.debug(String.format(\n                \"Column named \\\"%s\\\" was present in the preferences file but not the dataset.\", propCol.getName()), e);\n      }\n    }\n  }",
        "modified_code": "protected void restoreState() {\n    if (store == null) {\n      return;\n    }\n\n    ArrayList propColObjs = (ArrayList) store.getBean(\"propertyCol\", new ArrayList());\n    HidableTableColumnModel tableColumnModel = (HidableTableColumnModel) jtable.getColumnModel();\n    int newViewIndex = 0;\n\n    for (Object propColObj : propColObjs) {\n      PropertyCol propCol = (PropertyCol) propColObj;\n      try {\n        int cigrentViewIndex = tableColumnModel.getColumnIndex(propCol.getName());  // May throw IAE.\n\n        TableColumn column = tableColumnModel.getColumn(cigrentViewIndex);\n        column.setPreferredWidth(propCol.getWidth());\n\n        tableColumnModel.moveColumn(cigrentViewIndex, newViewIndex);\n        assert tableColumnModel.getColumn(newViewIndex) == column : \"tableColumn wasn't successfully moved.\";\n\n        // We must do this last, since moveColumn() only works on visible columns.\n        tableColumnModel.setColumnVisible(column, propCol.isVisible());\n        if (propCol.isVisible()) {\n          ++newViewIndex;  // Don't increment for hidden columns.\n        }\n      } catch (IllegalArgumentException e) {\n        logger.debug(String.format(\n                \"Column named \\\"%s\\\" was present in the preferences file but not the dataset.\", propCol.getName()), e);\n      }\n    }\n  }",
        "explanations_by_ours": [
            "the index of the column to be moved.",
            "The index of the column to move.",
            "the index of the column to move."
        ],
        "corrections_by_ours": [
            "columnViewIndex",
            "indexViewIndex",
            "cigrentIndexIndex",
            "cigrentMovedIndex",
            "cigrentViewMoved",
            "cigrentViewMove",
            "movedViewIndex",
            "moveViewIndex",
            "cigrentColumnIndex",
            "cigrentMoveIndex"
        ],
        "corrections_by_baseline": [
            "picIndex",
            "newViewIndex",
            "orogIndex",
            "viewRowIndex",
            "maxyIndex",
            "currentViewIndex",
            "maxxIndex",
            "viewPosition",
            "minxIndex",
            "scIndex"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "shaet",
        "original_variable": "start",
        "typo_variable": "shaet",
        "original_code": "protected DateRange readTimeCoverage(Element tElem) {\n    if (tElem == null) {\n      return null;\n    }\n    \n    Calendar calendar = readCalendar(tElem.getAttributeValue(\"calendar\"));\n    DateType start = readDate(tElem.getChild(\"start\", Catalog.defNS), calendar);\n    DateType end = readDate(tElem.getChild(\"end\", Catalog.defNS), calendar);\n\n    TimeDuration duration = readDuration(tElem.getChild(\"duration\", Catalog.defNS));\n    TimeDuration resolution = readDuration(tElem.getChild(\"resolution\", Catalog.defNS));\n\n    try {\n      return new DateRange(start, end, duration, resolution);\n    }\n    catch (java.lang.IllegalArgumentException e) {\n      errlog.format(\" ** warning: TimeCoverage error ='%s'%n\", e.getMessage());\n      logger.debug(\" ** warning: TimeCoverage error ='{}'\", e.getMessage());\n      return null;\n    }\n  }",
        "modified_code": "protected DateRange readTimeCoverage(Element tElem) {\n    if (tElem == null) {\n      return null;\n    }\n    \n    Calendar calendar = readCalendar(tElem.getAttributeValue(\"calendar\"));\n    DateType shaet = readDate(tElem.getChild(\"start\", Catalog.defNS), calendar);\n    DateType end = readDate(tElem.getChild(\"end\", Catalog.defNS), calendar);\n\n    TimeDuration duration = readDuration(tElem.getChild(\"duration\", Catalog.defNS));\n    TimeDuration resolution = readDuration(tElem.getChild(\"resolution\", Catalog.defNS));\n\n    try {\n      return new DateRange(shaet, end, duration, resolution);\n    }\n    catch (java.lang.IllegalArgumentException e) {\n      errlog.format(\" ** warning: TimeCoverage error ='%s'%n\", e.getMessage());\n      logger.debug(\" ** warning: TimeCoverage error ='{}'\", e.getMessage());\n      return null;\n    }\n  }",
        "explanations_by_ours": [
            "start date",
            "start date, end date",
            "start date."
        ],
        "corrections_by_ours": [
            "start",
            "date",
            "date,",
            "end"
        ],
        "corrections_by_baseline": [
            "sha",
            "md5",
            "digest",
            "md5hash",
            "hexDigest",
            "a1Md5",
            "hmac",
            "mcsum",
            "headHash",
            "cdmHash"
        ]
    },
    {
        "original_word": "suffixes",
        "typo_word": "sjffixws",
        "original_variable": "suffixes",
        "typo_variable": "sjffixws",
        "original_code": "List<String> getLibraryCandidates(String aLibraryName, Long aMajorVersion)\n  {\n    final List<String> retval = new LinkedList<String>();\n    // Note: when done each of these variables must be set to a non-null, non\n    // empty string array\n    final String[] prefixes;\n    final String[] suffixes;\n    final String[] preSuffixVersions;\n    final String[] postSuffixVersions;\n\n    switch (getOS())\n    {\n      case Unknown:\n      case Linux:\n        prefixes = new String[]\n        {\n            \"lib\", \"\"\n        };\n        suffixes = new String[]\n        {\n          \".so\"\n        };\n        preSuffixVersions = new String[]\n        {\n          \"\"\n        };\n        postSuffixVersions = (aMajorVersion == null ? new String[]\n        {\n          \"\"\n        } : new String[]\n        {\n          \".\" + aMajorVersion.longValue()\n        });\n        break;\n      case Windows:\n        prefixes = new String[]\n        {\n            \"lib\", \"\", \"cyg\"\n        };\n        suffixes = new String[]\n        {\n          \".dll\"\n        };\n        preSuffixVersions = (aMajorVersion == null ? new String[]\n        {\n          \"\"\n        } : new String[]\n        {\n          \"-\" + aMajorVersion.longValue()\n        });\n        postSuffixVersions = new String[]\n        {\n          \"\"\n        };\n        break;\n      case MacOSX:\n        prefixes = new String[]\n        {\n            \"lib\", \"\"\n        };\n        suffixes = new String[]\n        {\n          \".dylib\"\n        };\n        preSuffixVersions = (aMajorVersion == null ? new String[]\n        {\n          \"\"\n        } : new String[]\n        {\n          \".\" + aMajorVersion.longValue()\n        });\n        postSuffixVersions = new String[]\n        {\n          \"\"\n        };\n        break;\n      default:\n        // really no cases should get here\n        prefixes = null;\n        suffixes = null;\n        preSuffixVersions = null;\n        postSuffixVersions = null;\n        break;\n    }\n    initializeSearchPaths();\n\n    // First check the versioned paths\n    if (aMajorVersion != null)\n    {\n      for (String directory : mJavaPropPaths)\n      {\n        generateFileNames(retval, directory, aLibraryName, prefixes, suffixes,\n            preSuffixVersions, postSuffixVersions, true);\n      }\n      for (String directory : mJavaEnvPaths)\n      {\n        generateFileNames(retval, directory, aLibraryName, prefixes, suffixes,\n            preSuffixVersions, postSuffixVersions, true);\n      }\n    }\n    for (String directory : mJavaPropPaths)\n    {\n      generateFileNames(retval, directory, aLibraryName, prefixes, suffixes,\n          preSuffixVersions, postSuffixVersions, false);\n    }\n    for (String directory : mJavaEnvPaths)\n    {\n      generateFileNames(retval, directory, aLibraryName, prefixes, suffixes,\n          preSuffixVersions, postSuffixVersions, false);\n    }\n    return retval;\n  }",
        "modified_code": "List<String> getLibraryCandidates(String aLibraryName, Long aMajorVersion)\n  {\n    final List<String> retval = new LinkedList<String>();\n    // Note: when done each of these variables must be set to a non-null, non\n    // empty string array\n    final String[] prefixes;\n    final String[] sjffixws;\n    final String[] preSuffixVersions;\n    final String[] postSuffixVersions;\n\n    switch (getOS())\n    {\n      case Unknown:\n      case Linux:\n        prefixes = new String[]\n        {\n            \"lib\", \"\"\n        };\n        sjffixws = new String[]\n        {\n          \".so\"\n        };\n        preSuffixVersions = new String[]\n        {\n          \"\"\n        };\n        postSuffixVersions = (aMajorVersion == null ? new String[]\n        {\n          \"\"\n        } : new String[]\n        {\n          \".\" + aMajorVersion.longValue()\n        });\n        break;\n      case Windows:\n        prefixes = new String[]\n        {\n            \"lib\", \"\", \"cyg\"\n        };\n        sjffixws = new String[]\n        {\n          \".dll\"\n        };\n        preSuffixVersions = (aMajorVersion == null ? new String[]\n        {\n          \"\"\n        } : new String[]\n        {\n          \"-\" + aMajorVersion.longValue()\n        });\n        postSuffixVersions = new String[]\n        {\n          \"\"\n        };\n        break;\n      case MacOSX:\n        prefixes = new String[]\n        {\n            \"lib\", \"\"\n        };\n        sjffixws = new String[]\n        {\n          \".dylib\"\n        };\n        preSuffixVersions = (aMajorVersion == null ? new String[]\n        {\n          \"\"\n        } : new String[]\n        {\n          \".\" + aMajorVersion.longValue()\n        });\n        postSuffixVersions = new String[]\n        {\n          \"\"\n        };\n        break;\n      default:\n        // really no cases should get here\n        prefixes = null;\n        sjffixws = null;\n        preSuffixVersions = null;\n        postSuffixVersions = null;\n        break;\n    }\n    initializeSearchPaths();\n\n    // First check the versioned paths\n    if (aMajorVersion != null)\n    {\n      for (String directory : mJavaPropPaths)\n      {\n        generateFileNames(retval, directory, aLibraryName, prefixes, sjffixws,\n            preSuffixVersions, postSuffixVersions, true);\n      }\n      for (String directory : mJavaEnvPaths)\n      {\n        generateFileNames(retval, directory, aLibraryName, prefixes, sjffixws,\n            preSuffixVersions, postSuffixVersions, true);\n      }\n    }\n    for (String directory : mJavaPropPaths)\n    {\n      generateFileNames(retval, directory, aLibraryName, prefixes, sjffixws,\n          preSuffixVersions, postSuffixVersions, false);\n    }\n    for (String directory : mJavaEnvPaths)\n    {\n      generateFileNames(retval, directory, aLibraryName, prefixes, sjffixws,\n          preSuffixVersions, postSuffixVersions, false);\n    }\n    return retval;\n  }",
        "explanations_by_ours": [
            "The suffix of the library to be checked.",
            "The suffix of the library name.",
            "The suffix of the library names."
        ],
        "corrections_by_ours": [
            "suffix",
            "names",
            "checked",
            "name",
            "library"
        ],
        "corrections_by_baseline": [
            "sds",
            "ws",
            "cws",
            "gdss",
            "osw",
            "sfb",
            "gfdw",
            "dcs",
            "xpp",
            "drss"
        ]
    },
    {
        "original_word": "returning",
        "typo_word": "retutnibg",
        "original_variable": "returning",
        "typo_variable": "retutnibg",
        "original_code": "protected String parseReturn() throws OCommandSQLParsingException {\r\n    final String returning = parserNextWord(true);\r\n\r\n    if (!returning.equalsIgnoreCase(\"COUNT\") && !returning.equalsIgnoreCase(\"BEFORE\"))\r\n      throwParsingException(\"Invalid \" + KEYWORD_RETURN + \" value set to '\" + returning\r\n          + \"' but it should be COUNT (default), BEFORE. Example: \" + KEYWORD_RETURN + \" BEFORE\");\r\n\r\n    return returning;\r\n  }",
        "modified_code": "protected String parseReturn() throws OCommandSQLParsingException {\r\n    final String retutnibg = parserNextWord(true);\r\n\r\n    if (!retutnibg.equalsIgnoreCase(\"COUNT\") && !retutnibg.equalsIgnoreCase(\"BEFORE\"))\r\n      throwParsingException(\"Invalid \" + KEYWORD_RETURN + \" value set to '\" + retutnibg\r\n          + \"' but it should be COUNT (default), BEFORE. Example: \" + KEYWORD_RETURN + \" BEFORE\");\r\n\r\n    return retutnibg;\r\n  }",
        "explanations_by_ours": [
            "the RETURN value to parse",
            "the RETURN value",
            "the value to parse"
        ],
        "corrections_by_ours": [
            "return",
            "value",
            "parse"
        ],
        "corrections_by_baseline": [
            "ret",
            "utflen",
            "jbit",
            "tBTAT",
            "misflg",
            "retval",
            "uebertragung",
            "ybeg",
            "jReturn",
            "jbeg"
        ]
    },
    {
        "original_word": "iter",
        "typo_word": "utfr",
        "original_variable": "iterA",
        "typo_variable": "utfrA",
        "original_code": "public static double sumDoubleSkipMissingData(Array a, double missingValue) {\r\n    double sum = 0;\r\n    IndexIterator iterA = a.getIndexIterator();\r\n    while (iterA.hasNext()) {\r\n      double val = iterA.getDoubleNext();\r\n      if ((val == missingValue) || Double.isNaN(val))\r\n        continue;\r\n      sum += val;\r\n    }\r\n    return sum;\r\n  }",
        "modified_code": "public static double sumDoubleSkipMissingData(Array a, double missingValue) {\r\n    double sum = 0;\r\n    IndexIterator utfrA = a.getIndexIterator();\r\n    while (utfrA.hasNext()) {\r\n      double val = utfrA.getDoubleNext();\r\n      if ((val == missingValue) || Double.isNaN(val))\r\n        continue;\r\n      sum += val;\r\n    }\r\n    return sum;\r\n  }",
        "explanations_by_ours": [
            "the array to get the values from",
            "the index iterator of the array",
            "the index iterator of the array to sum"
        ],
        "corrections_by_ours": [
            "iteratorA",
            "utfrArray",
            "utfrValues",
            "utfrIterator",
            "valuesA",
            "indexA",
            "getA",
            "sumA",
            "arrayA",
            "utfrIndex"
        ],
        "corrections_by_baseline": [
            "utco",
            "t_a",
            "gsfr",
            "tBTAT",
            "R_a",
            "gfr",
            "a22",
            "fr",
            "a4p",
            "xfac"
        ]
    },
    {
        "original_word": "evaluation",
        "typo_word": "evsluatuon",
        "original_variable": "evaluationResult",
        "typo_variable": "evsluatuonResult",
        "original_code": "public static void evaluateNormalCells(final Cell cell,\r\n\t\t\tfinal String strValue, final Map<String, Object> context,\r\n\t\t\tfinal ExpressionEngine engine) {\r\n\t\tif (strValue.contains(TieConstants.METHOD_PREFIX)) {\r\n\r\n\t\t\tObject evaluationResult = evaluate(strValue, context, engine);\r\n\t\t\tif (evaluationResult == null) {\r\n\t\t\t\tevaluationResult = \"\";\r\n\t\t\t}\r\n\t\t\tCellUtility.setCellValue(cell, evaluationResult.toString());\r\n\r\n\t\t\tcreateTieCell(cell, context, engine);\r\n\r\n\t\t}\r\n\t}",
        "modified_code": "public static void evaluateNormalCells(final Cell cell,\r\n\t\t\tfinal String strValue, final Map<String, Object> context,\r\n\t\t\tfinal ExpressionEngine engine) {\r\n\t\tif (strValue.contains(TieConstants.METHOD_PREFIX)) {\r\n\r\n\t\t\tObject evsluatuonResult = evaluate(strValue, context, engine);\r\n\t\t\tif (evsluatuonResult == null) {\r\n\t\t\t\tevsluatuonResult = \"\";\r\n\t\t\t}\r\n\t\t\tCellUtility.setCellValue(cell, evsluatuonResult.toString());\r\n\r\n\t\t\tcreateTieCell(cell, context, engine);\r\n\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "The evsluatuon result.",
            "The evsluatuon result to use.",
            "The value to evaluate."
        ],
        "corrections_by_ours": [
            "evaluateResult",
            "resultResult",
            "valueResult",
            "evsluatuonEvsluatuon",
            "evsluatuonEvaluate",
            "evsluatuonUse",
            "evsluatuonValue",
            "useResult",
            "evsluatuonResult"
        ],
        "corrections_by_baseline": [
            "resultYA",
            "dresult",
            "cmdResult",
            "dResult",
            "cResult",
            "sresult",
            "mResult",
            "cresult",
            "resultXA",
            "actionResult"
        ]
    },
    {
        "original_word": "extension",
        "typo_word": "exgwnsion",
        "original_variable": "extensionSeparator",
        "typo_variable": "exgwnsionSeparator",
        "original_code": "private static String getEventStreamSessionID(String requestPath) {\r\n\t\tint extensionSeparator = requestPath.lastIndexOf('.');\r\n\t\tif (extensionSeparator == -1) {\r\n\t\t\textensionSeparator = requestPath.length();\r\n\t\t}\r\n\r\n\t\t// request URI is guaranteed to start with path separator\r\n\t\t// anyway, if missing below pathSeparator will be -1 + 1 = 0, pointing to entire request URI\r\n\t\tint pathSeparator = requestPath.lastIndexOf('/', extensionSeparator) + 1;\r\n\t\treturn requestPath.substring(pathSeparator, extensionSeparator);\r\n\t}",
        "modified_code": "private static String getEventStreamSessionID(String requestPath) {\r\n\t\tint exgwnsionSeparator = requestPath.lastIndexOf('.');\r\n\t\tif (exgwnsionSeparator == -1) {\r\n\t\t\texgwnsionSeparator = requestPath.length();\r\n\t\t}\r\n\r\n\t\t// request URI is guaranteed to start with path separator\r\n\t\t// anyway, if missing below pathSeparator will be -1 + 1 = 0, pointing to entire request URI\r\n\t\tint pathSeparator = requestPath.lastIndexOf('/', exgwnsionSeparator) + 1;\r\n\t\treturn requestPath.substring(pathSeparator, exgwnsionSeparator);\r\n\t}",
        "explanations_by_ours": [
            "the last dot in the request path",
            "the last path separator",
            "the last path separator in the request path"
        ],
        "corrections_by_ours": [
            "exgwnsionPath",
            "exgwnsionRequest",
            "exgwnsionLast",
            "requestSeparator",
            "separatorSeparator",
            "dotSeparator",
            "lastSeparator",
            "exgwnsionDot",
            "pathSeparator",
            "exgwnsionSeparator"
        ],
        "corrections_by_baseline": [
            "fileseparator",
            "extensionSeparator",
            "separatorIndex",
            "parametersSeparatorIndex",
            "otherSeparator",
            "separator",
            "PATTERN_DELIMITER",
            "idxLastSeparator",
            "pathSeparator",
            "PATTERN_DELIMITER_INDEX"
        ]
    },
    {
        "original_word": "group",
        "typo_word": "gfojp",
        "original_variable": "groupindex",
        "typo_variable": "gfojpindex",
        "original_code": "static public String fqnPrefix(String fqn)\n    {\n        int structindex = fqn.lastIndexOf('.');\n        int groupindex = fqn.lastIndexOf('/');\n        if(structindex >= 0)\n            return fqn.substring(0, structindex);\n        else\n            return fqn.substring(0, groupindex);\n    }",
        "modified_code": "static public String fqnPrefix(String fqn)\n    {\n        int structindex = fqn.lastIndexOf('.');\n        int gfojpindex = fqn.lastIndexOf('/');\n        if(structindex >= 0)\n            return fqn.substring(0, structindex);\n        else\n            return fqn.substring(0, gfojpindex);\n    }",
        "explanations_by_ours": [
            "the last index of the struct or gfo",
            "the index of the last dot in the fully qualified name",
            "the last index of the struct or /"
        ],
        "corrections_by_ours": [
            "index",
            "gfo",
            "qualified",
            "fully",
            "dot",
            "name",
            "struct",
            "last"
        ],
        "corrections_by_baseline": [
            "sufindex",
            "orogIndex",
            "indexx",
            "maxyIndex",
            "idx",
            "sindex",
            "grib1Index",
            "index",
            "grib2Index",
            "compositeIndex"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "grsult",
        "original_variable": "result",
        "typo_variable": "grsult",
        "original_code": "private List<PropertyChangeEvent> delta(WAMMemoryLayout oldRegisters, WAMMemoryLayout newRegisters)\n    {\n        List<PropertyChangeEvent> result = new LinkedList<PropertyChangeEvent>();\n\n        if (oldRegisters.regBase != newRegisters.regBase)\n        {\n            result.add(new PropertyChangeEvent(this, \"regBase\", oldRegisters.regBase, newRegisters.regBase));\n        }\n\n        if (oldRegisters.regSize != newRegisters.regSize)\n        {\n            result.add(new PropertyChangeEvent(this, \"regSize\", oldRegisters.regSize, newRegisters.regSize));\n        }\n\n        if (oldRegisters.heapBase != newRegisters.heapBase)\n        {\n            result.add(new PropertyChangeEvent(this, \"heapBase\", oldRegisters.heapBase, newRegisters.heapBase));\n        }\n\n        if (oldRegisters.heapSize != newRegisters.heapSize)\n        {\n            result.add(new PropertyChangeEvent(this, \"heapSize\", oldRegisters.heapSize, newRegisters.heapSize));\n        }\n\n        if (oldRegisters.stackBase != newRegisters.stackBase)\n        {\n            result.add(new PropertyChangeEvent(this, \"stackBase\", oldRegisters.stackBase, newRegisters.stackBase));\n        }\n\n        if (oldRegisters.stackSize != newRegisters.stackSize)\n        {\n            result.add(new PropertyChangeEvent(this, \"stackSize\", oldRegisters.stackSize, newRegisters.stackSize));\n        }\n\n        if (oldRegisters.trailBase != newRegisters.trailBase)\n        {\n            result.add(new PropertyChangeEvent(this, \"trailBase\", oldRegisters.trailBase, newRegisters.trailBase));\n        }\n\n        if (oldRegisters.trailSize != newRegisters.trailSize)\n        {\n            result.add(new PropertyChangeEvent(this, \"trailSize\", oldRegisters.trailSize, newRegisters.trailSize));\n        }\n\n        if (oldRegisters.pdlBase != newRegisters.pdlBase)\n        {\n            result.add(new PropertyChangeEvent(this, \"pdlBase\", oldRegisters.pdlBase, newRegisters.pdlBase));\n        }\n\n        if (oldRegisters.pdlSize != newRegisters.pdlSize)\n        {\n            result.add(new PropertyChangeEvent(this, \"pdlSize\", oldRegisters.pdlSize, newRegisters.pdlSize));\n        }\n\n        return result;\n    }",
        "modified_code": "private List<PropertyChangeEvent> delta(WAMMemoryLayout oldRegisters, WAMMemoryLayout newRegisters)\n    {\n        List<PropertyChangeEvent> grsult = new LinkedList<PropertyChangeEvent>();\n\n        if (oldRegisters.regBase != newRegisters.regBase)\n        {\n            grsult.add(new PropertyChangeEvent(this, \"regBase\", oldRegisters.regBase, newRegisters.regBase));\n        }\n\n        if (oldRegisters.regSize != newRegisters.regSize)\n        {\n            grsult.add(new PropertyChangeEvent(this, \"regSize\", oldRegisters.regSize, newRegisters.regSize));\n        }\n\n        if (oldRegisters.heapBase != newRegisters.heapBase)\n        {\n            grsult.add(new PropertyChangeEvent(this, \"heapBase\", oldRegisters.heapBase, newRegisters.heapBase));\n        }\n\n        if (oldRegisters.heapSize != newRegisters.heapSize)\n        {\n            grsult.add(new PropertyChangeEvent(this, \"heapSize\", oldRegisters.heapSize, newRegisters.heapSize));\n        }\n\n        if (oldRegisters.stackBase != newRegisters.stackBase)\n        {\n            grsult.add(new PropertyChangeEvent(this, \"stackBase\", oldRegisters.stackBase, newRegisters.stackBase));\n        }\n\n        if (oldRegisters.stackSize != newRegisters.stackSize)\n        {\n            grsult.add(new PropertyChangeEvent(this, \"stackSize\", oldRegisters.stackSize, newRegisters.stackSize));\n        }\n\n        if (oldRegisters.trailBase != newRegisters.trailBase)\n        {\n            grsult.add(new PropertyChangeEvent(this, \"trailBase\", oldRegisters.trailBase, newRegisters.trailBase));\n        }\n\n        if (oldRegisters.trailSize != newRegisters.trailSize)\n        {\n            grsult.add(new PropertyChangeEvent(this, \"trailSize\", oldRegisters.trailSize, newRegisters.trailSize));\n        }\n\n        if (oldRegisters.pdlBase != newRegisters.pdlBase)\n        {\n            grsult.add(new PropertyChangeEvent(this, \"pdlBase\", oldRegisters.pdlBase, newRegisters.pdlBase));\n        }\n\n        if (oldRegisters.pdlSize != newRegisters.pdlSize)\n        {\n            grsult.add(new PropertyChangeEvent(this, \"pdlSize\", oldRegisters.pdlSize, newRegisters.pdlSize));\n        }\n\n        return grsult;\n    }",
        "explanations_by_ours": [
            "the list of property change events that were fired.",
            "the list of property change events that were fired",
            "the list of property change events that were fired while updating the memory layout"
        ],
        "corrections_by_ours": [
            "list",
            "property",
            "layout",
            "memory",
            "updating",
            "change",
            "fired",
            "events"
        ],
        "corrections_by_baseline": [
            "gr",
            "grpids",
            "grads",
            "grids",
            "ecint",
            "iresult",
            "idrct",
            "residuals",
            "fac",
            "acf"
        ]
    },
    {
        "original_word": "entity",
        "typo_word": "entotg",
        "original_variable": "entity",
        "typo_variable": "entotg",
        "original_code": "public void undeploy(String id) {\n\t\tProcess entity = access().getProcess(id);\n\t\tentity.setState(STATE_FINISH);\n\t\taccess().updateProcess(entity);\n\t\tcache(entity);\n\t}",
        "modified_code": "public void undeploy(String id) {\n\t\tProcess entotg = access().getProcess(id);\n\t\tentotg.setState(STATE_FINISH);\n\t\taccess().updateProcess(entotg);\n\t\tcache(entotg);\n\t}",
        "explanations_by_ours": [
            "process to undeploy",
            "process to be undeployed",
            "process to be undeployed."
        ],
        "corrections_by_ours": [
            "undeployed",
            "undeploy",
            "process"
        ],
        "corrections_by_baseline": [
            "emsg",
            "ptg",
            "g",
            "gfr",
            "dg",
            "fptg",
            "ybeg",
            "gcs",
            "jbeg",
            "gv"
        ]
    },
    {
        "original_word": "files",
        "typo_word": "eioes",
        "original_variable": "files",
        "typo_variable": "eioes",
        "original_code": "private static void tarFolder(String parent, String path, TarOutputStream out) throws IOException {\n    BufferedInputStream src = null;\n    File f = new File(path);\n    String files[] = f.list();\n    // is file\n    if (files == null) {\n      files = new String[1];\n      files[0] = f.getName();\n    }\n    parent = ((parent == null) ? (f.isFile()) ? \"\" : f.getName() + \"/\" : parent + f.getName() + \"/\");\n    for (int i = 0; i < files.length; i++) {\n      File fe = f;\n      if (f.isDirectory()) {\n        fe = new File(f, files[i]);\n      }\n      if (fe.isDirectory()) {\n        String[] fl = fe.list();\n        if (fl != null && fl.length != 0) {\n          tarFolder(parent, fe.getPath(), out);\n        } else {\n          TarEntry entry = new TarEntry(fe, parent + files[i] + \"/\");\n          out.putNextEntry(entry);\n        }\n        continue;\n      }\n      FileInputStream fi = new FileInputStream(fe);\n      src = new BufferedInputStream(fi);\n      TarEntry entry = new TarEntry(fe, parent + files[i]);\n      out.putNextEntry(entry);\n      IOUtils.copy(src, out);\n      src.close();\n      out.flush();\n    }\n  }",
        "modified_code": "private static void tarFolder(String parent, String path, TarOutputStream out) throws IOException {\n    BufferedInputStream src = null;\n    File f = new File(path);\n    String eioes[] = f.list();\n    // is file\n    if (eioes == null) {\n      eioes = new String[1];\n      eioes[0] = f.getName();\n    }\n    parent = ((parent == null) ? (f.isFile()) ? \"\" : f.getName() + \"/\" : parent + f.getName() + \"/\");\n    for (int i = 0; i < eioes.length; i++) {\n      File fe = f;\n      if (f.isDirectory()) {\n        fe = new File(f, eioes[i]);\n      }\n      if (fe.isDirectory()) {\n        String[] fl = fe.list();\n        if (fl != null && fl.length != 0) {\n          tarFolder(parent, fe.getPath(), out);\n        } else {\n          TarEntry entry = new TarEntry(fe, parent + eioes[i] + \"/\");\n          out.putNextEntry(entry);\n        }\n        continue;\n      }\n      FileInputStream fi = new FileInputStream(fe);\n      src = new BufferedInputStream(fi);\n      TarEntry entry = new TarEntry(fe, parent + eioes[i]);\n      out.putNextEntry(entry);\n      IOUtils.copy(src, out);\n      src.close();\n      out.flush();\n    }\n  }",
        "explanations_by_ours": [
            "list of files or directories.",
            "list of files or directories",
            "list of files or directories to tar"
        ],
        "corrections_by_ours": [
            "eifiles",
            "eidirectories",
            "listoes",
            "eilist",
            "filesoes",
            "directoriesoes",
            "taroes",
            "eitar",
            "eioes"
        ],
        "corrections_by_baseline": [
            "es",
            "ioe",
            "fos",
            "engines",
            "consequences",
            "ifaces",
            "exds",
            "datapos",
            "os",
            "pressures"
        ]
    },
    {
        "original_word": "delta",
        "typo_word": "drlts",
        "original_variable": "deltaLon_r",
        "typo_variable": "drltsLon_r",
        "original_code": "public List<ProjectionPoint> getMapEdgeInterceptsAtX(double x0) {\r\n        List<ProjectionPoint> mapEdgeIntercepts = new LinkedList<>();\r\n        if (projToLatLon(x0, falseNorthing) == INVALID) {  // The line {@code x = x0} does not intersect the map.\r\n            return mapEdgeIntercepts;  // Empty list.\r\n        }\r\n\r\n        double x0natural = x0 - falseEasting;\r\n        double limitLon_r = (x0natural < 0) ? -PI : +PI;\r\n        double deltaLon_r = limitLon_r - Math.toRadians(centMeridian);\r\n\r\n        // This formula comes from solving 30-1 for phi, and then plugging it into 30-2. See Snyder, p 247.\r\n        double minY = -earthRadius * Math.acos(x0natural / (earthRadius * deltaLon_r));\r\n        double maxY = +earthRadius * Math.acos(x0natural / (earthRadius * deltaLon_r));\r\n\r\n        mapEdgeIntercepts.add(new ProjectionPointImpl(x0, minY + falseNorthing));\r\n        mapEdgeIntercepts.add(new ProjectionPointImpl(x0, maxY + falseNorthing));\r\n        return mapEdgeIntercepts;\r\n    }",
        "modified_code": "public List<ProjectionPoint> getMapEdgeInterceptsAtX(double x0) {\r\n        List<ProjectionPoint> mapEdgeIntercepts = new LinkedList<>();\r\n        if (projToLatLon(x0, falseNorthing) == INVALID) {  // The line {@code x = x0} does not intersect the map.\r\n            return mapEdgeIntercepts;  // Empty list.\r\n        }\r\n\r\n        double x0natural = x0 - falseEasting;\r\n        double limitLon_r = (x0natural < 0) ? -PI : +PI;\r\n        double drltsLon_r = limitLon_r - Math.toRadians(centMeridian);\r\n\r\n        // This formula comes from solving 30-1 for phi, and then plugging it into 30-2. See Snyder, p 247.\r\n        double minY = -earthRadius * Math.acos(x0natural / (earthRadius * drltsLon_r));\r\n        double maxY = +earthRadius * Math.acos(x0natural / (earthRadius * drltsLon_r));\r\n\r\n        mapEdgeIntercepts.add(new ProjectionPointImpl(x0, minY + falseNorthing));\r\n        mapEdgeIntercepts.add(new ProjectionPointImpl(x0, maxY + falseNorthing));\r\n        return mapEdgeIntercepts;\r\n    }",
        "explanations_by_ours": [
            "The radius of the drlts lon.",
            "The radius of the drlts longitude.",
            "The radius of the drlts lon"
        ],
        "corrections_by_ours": [
            "drltsLongitude_r",
            "lonLon_r",
            "drltsDrlts_r",
            "ddrltsltsLon_drlts",
            "radiusLon_r",
            "dradiusltsLon_radius",
            "longitudeLon_r",
            "drltsRadius_r",
            "dlonltsLon_lon",
            "dlongitudeltsLon_longitude"
        ],
        "corrections_by_baseline": [
            "toLon_r",
            "lonR",
            "deltaLon_r",
            "radar_lon",
            "limitLon_r",
            "standardLon",
            "fromLat_r",
            "toLat_r",
            "curLon",
            "geographic_lon"
        ]
    },
    {
        "original_word": "remaining",
        "typo_word": "remajninh",
        "original_variable": "remaining",
        "typo_variable": "remajninh",
        "original_code": "private InputStream toBufferedInputStream() {\n        int remaining = count;\n        if (remaining == 0) {\n            return new ClosedInputStream();\n        }\n        List<ByteArrayInputStream> list = new ArrayList<ByteArrayInputStream>(buffers.size());\n        for (byte[] buf : buffers) {\n            int c = Math.min(buf.length, remaining);\n            list.add(new ByteArrayInputStream(buf, 0, c));\n            remaining -= c;\n            if (remaining == 0) {\n                break;\n            }\n        }\n        return new SequenceInputStream(Collections.enumeration(list));\n    }",
        "modified_code": "private InputStream toBufferedInputStream() {\n        int remajninh = count;\n        if (remajninh == 0) {\n            return new ClosedInputStream();\n        }\n        List<ByteArrayInputStream> list = new ArrayList<ByteArrayInputStream>(buffers.size());\n        for (byte[] buf : buffers) {\n            int c = Math.min(buf.length, remajninh);\n            list.add(new ByteArrayInputStream(buf, 0, c));\n            remajninh -= c;\n            if (remajninh == 0) {\n                break;\n            }\n        }\n        return new SequenceInputStream(Collections.enumeration(list));\n    }",
        "explanations_by_ours": [
            "the number of bytes to read from the buffer.",
            "the number of bytes to read from the buffer",
            "the maximum number of bytes to read from the buffer."
        ],
        "corrections_by_ours": [
            "read",
            "maximum",
            "number",
            "bytes",
            "buffer"
        ],
        "corrections_by_baseline": [
            "mrm",
            "rm",
            "mv",
            "datarun",
            "deref",
            "rem",
            "dub",
            "udim",
            "trovit",
            "vmdi"
        ]
    },
    {
        "original_word": "loaded",
        "typo_word": "lozder",
        "original_variable": "loaded",
        "typo_variable": "lozder",
        "original_code": "private RedisSession getSession(String id, boolean allowExpired) {\n\t\tMap<Object, Object> entries = getSessionBoundHashOperations(id).entries();\n\t\tif (entries.isEmpty()) {\n\t\t\treturn null;\n\t\t}\n\t\tMapSession loaded = loadSession(id, entries);\n\t\tif (!allowExpired && loaded.isExpired()) {\n\t\t\treturn null;\n\t\t}\n\t\tRedisSession result = new RedisSession(loaded);\n\t\tresult.originalLastAccessTime = loaded.getLastAccessedTime();\n\t\treturn result;\n\t}",
        "modified_code": "private RedisSession getSession(String id, boolean allowExpired) {\n\t\tMap<Object, Object> entries = getSessionBoundHashOperations(id).entries();\n\t\tif (entries.isEmpty()) {\n\t\t\treturn null;\n\t\t}\n\t\tMapSession lozder = loadSession(id, entries);\n\t\tif (!allowExpired && lozder.isExpired()) {\n\t\t\treturn null;\n\t\t}\n\t\tRedisSession result = new RedisSession(lozder);\n\t\tresult.originalLastAccessTime = lozder.getLastAccessedTime();\n\t\treturn result;\n\t}",
        "explanations_by_ours": [
            "the lozder of the session",
            "the lozder to load the session from",
            "the lozder"
        ],
        "corrections_by_ours": [
            "load",
            "session"
        ],
        "corrections_by_baseline": [
            "lo",
            "wierd",
            "anbieter",
            "LULC",
            "coldp",
            "liof",
            "ilenhd",
            "finer",
            "smo",
            "lac"
        ]
    },
    {
        "original_word": "original",
        "typo_word": "iriginak",
        "original_variable": "originalOperandClass",
        "typo_variable": "iriginakOperandClass",
        "original_code": "private static Ptg[] convertPtg(final Ptg[] ptgs, final int position,\r\n\t\t\tfinal ShiftFormulaRef shiftFormulaRef, final Object ptg) {\r\n\r\n\t\tbyte originalOperandClass = -1;\r\n\r\n\t\tif (!((Ptg) ptg).isBaseToken()) {\r\n\t\t\toriginalOperandClass = ((Ptg) ptg).getPtgClass();\r\n\t\t}\r\n\r\n\t\tint currentRow;\r\n\t\tcurrentRow = getFirstSupportedRowNumFromPtg(ptg);\r\n\t\tif ((currentRow >= 0)\r\n\t\t\t\t&& shiftFormulaRef.getWatchList().contains(currentRow)) {\r\n\t\t\treturn convertPtgForWatchList(ptgs, position, shiftFormulaRef,\r\n\t\t\t\t\tptg, originalOperandClass, currentRow);\r\n\r\n\t\t}\r\n\t\t// no need change ptg\r\n\t\tif ((ptg instanceof AttrPtg)\r\n\t\t\t\t&& (shiftFormulaRef.getFormulaChanged() > 1)) {\r\n\t\t\tAttrPtg newPtg = (AttrPtg) ptg;\r\n\t\t\tif (newPtg.isSum()) {\r\n\t\t\t\tFuncVarPtg fptg = FuncVarPtg.create(\"sum\",\r\n\t\t\t\t\t\tshiftFormulaRef.getFormulaChanged());\r\n\t\t\t\treturn singlePtg(fptg, fptg.getPtgClass(),\r\n\t\t\t\t\t\tshiftFormulaRef.getFormulaChanged());\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn singlePtg(ptg, originalOperandClass,\r\n\t\t\t\tshiftFormulaRef.getFormulaChanged());\r\n\r\n\t}",
        "modified_code": "private static Ptg[] convertPtg(final Ptg[] ptgs, final int position,\r\n\t\t\tfinal ShiftFormulaRef shiftFormulaRef, final Object ptg) {\r\n\r\n\t\tbyte iriginakOperandClass = -1;\r\n\r\n\t\tif (!((Ptg) ptg).isBaseToken()) {\r\n\t\t\tiriginakOperandClass = ((Ptg) ptg).getPtgClass();\r\n\t\t}\r\n\r\n\t\tint currentRow;\r\n\t\tcurrentRow = getFirstSupportedRowNumFromPtg(ptg);\r\n\t\tif ((currentRow >= 0)\r\n\t\t\t\t&& shiftFormulaRef.getWatchList().contains(currentRow)) {\r\n\t\t\treturn convertPtgForWatchList(ptgs, position, shiftFormulaRef,\r\n\t\t\t\t\tptg, iriginakOperandClass, currentRow);\r\n\r\n\t\t}\r\n\t\t// no need change ptg\r\n\t\tif ((ptg instanceof AttrPtg)\r\n\t\t\t\t&& (shiftFormulaRef.getFormulaChanged() > 1)) {\r\n\t\t\tAttrPtg newPtg = (AttrPtg) ptg;\r\n\t\t\tif (newPtg.isSum()) {\r\n\t\t\t\tFuncVarPtg fptg = FuncVarPtg.create(\"sum\",\r\n\t\t\t\t\t\tshiftFormulaRef.getFormulaChanged());\r\n\t\t\t\treturn singlePtg(fptg, fptg.getPtgClass(),\r\n\t\t\t\t\t\tshiftFormulaRef.getFormulaChanged());\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn singlePtg(ptg, iriginakOperandClass,\r\n\t\t\t\tshiftFormulaRef.getFormulaChanged());\r\n\r\n\t}",
        "explanations_by_ours": [
            "the iriginak operand class",
            "the iriginak operand class of the Ptg",
            "the iriginak operand class of the Ptg object"
        ],
        "corrections_by_ours": [
            "iriginakPtgClass",
            "iriginakClassClass",
            "iriginakObjectClass",
            "iriginakOperandOperand",
            "ptgOperandClass",
            "operandOperandClass",
            "iriginakIriginakClass",
            "classOperandClass",
            "objectOperandClass",
            "iriginakOperandIriginak"
        ],
        "corrections_by_baseline": [
            "methodParamClass",
            "originalOperandClass",
            "builtInExpressionClass",
            "parameterTypeSuperClassName",
            "subdocOpType",
            "argClazz",
            "syntheticVarName",
            "arbitraryDndClass",
            "methodParameterComponentType",
            "usageParameterClass"
        ]
    },
    {
        "original_word": "dover",
        "typo_word": "dlfer",
        "original_variable": "dover",
        "typo_variable": "dlfer",
        "original_code": "public void setOverlap(int overlap) {\n    // overlap limited to [0, 50%]\n    double dover = Math.max( 0.0, Math.min(.01*overlap, .50));\n    scaleOverlap = 1.0 - dover;\n  }",
        "modified_code": "public void setOverlap(int overlap) {\n    // overlap limited to [0, 50%]\n    double dlfer = Math.max( 0.0, Math.min(.01*overlap, .50));\n    scaleOverlap = 1.0 - dlfer;\n  }",
        "explanations_by_ours": [
            "the dlfer between the two images",
            "the dlfer of the overlap",
            "the dlfer between the two images."
        ],
        "corrections_by_ours": [
            "images",
            "overlap",
            "two"
        ],
        "corrections_by_baseline": [
            "sld",
            "dks",
            "tld",
            "hf",
            "shave",
            "lfac",
            "datarun",
            "dmp",
            "dcs",
            "dapcxt"
        ]
    },
    {
        "original_word": "buffer",
        "typo_word": "bubfef",
        "original_variable": "buffer",
        "typo_variable": "bubfef",
        "original_code": "public static String getStringByArray(String... strArray) {\n\t\tif(strArray == null) return \"\";\n\t\tStringBuilder buffer = new StringBuilder(strArray.length * 10);\n\t\tfor(String str : strArray) {\n\t\t\tbuffer.append(str).append(\",\");\n\t\t}\n\t\tbuffer.deleteCharAt(buffer.length() - 1);\n\t\treturn buffer.toString();\n\t}",
        "modified_code": "public static String getStringByArray(String... strArray) {\n\t\tif(strArray == null) return \"\";\n\t\tStringBuilder bubfef = new StringBuilder(strArray.length * 10);\n\t\tfor(String str : strArray) {\n\t\t\tbubfef.append(str).append(\",\");\n\t\t}\n\t\tbubfef.deleteCharAt(bubfef.length() - 1);\n\t\treturn bubfef.toString();\n\t}",
        "explanations_by_ours": [
            "StringBuilder",
            "bubfef",
            "String"
        ],
        "corrections_by_ours": [
            "builder",
            "string"
        ],
        "corrections_by_baseline": [
            "FAZ",
            "f_huff",
            "boff",
            "bue",
            "mefd",
            "emf",
            "t_huff",
            "dub",
            "baf",
            "fbd"
        ]
    },
    {
        "original_word": "allow",
        "typo_word": "allpq",
        "original_variable": "allow",
        "typo_variable": "allpq",
        "original_code": "private boolean queryRelativeCatalogs () {\n    if (resources==null) readProperties();\n\n    if (resources==null) return defaultRelativeCatalogs;\n\n    try {\n      String allow = resources.getString(\"relative-catalogs\");\n      return (allow.equalsIgnoreCase(\"true\")\n\t      || allow.equalsIgnoreCase(\"yes\")\n\t      || allow.equalsIgnoreCase(\"1\"));\n    } catch (MissingResourceException e) {\n      return defaultRelativeCatalogs;\n    }\n  }",
        "modified_code": "private boolean queryRelativeCatalogs () {\n    if (resources==null) readProperties();\n\n    if (resources==null) return defaultRelativeCatalogs;\n\n    try {\n      String allpq = resources.getString(\"relative-catalogs\");\n      return (allpq.equalsIgnoreCase(\"true\")\n\t      || allpq.equalsIgnoreCase(\"yes\")\n\t      || allpq.equalsIgnoreCase(\"1\"));\n    } catch (MissingResourceException e) {\n      return defaultRelativeCatalogs;\n    }\n  }",
        "explanations_by_ours": [
            "the value of the property relative-catalogs",
            "the value of the property relative-catalogs.",
            "the value of the property relative-catalogs to query."
        ],
        "corrections_by_ours": [
            "catalogs",
            "value",
            "relative",
            "property",
            "-",
            "query"
        ],
        "corrections_by_baseline": [
            "qmndx",
            "cqf",
            "qd",
            "qr",
            "wq",
            "qto",
            "pidd",
            "q",
            "sgp",
            "qry"
        ]
    },
    {
        "original_word": "Prime",
        "typo_word": "Pgihe",
        "original_variable": "kPrime",
        "typo_variable": "kPgihe",
        "original_code": "public ProjectionPoint latLonToProj(LatLonPoint latLon,\r\n                                      ProjectionPointImpl result) {\r\n    double toX, toY;\r\n    double fromLat = latLon.getLatitude();\r\n    double fromLon = latLon.getLongitude();\r\n\r\n\r\n    fromLat = Math.toRadians(fromLat);\r\n    double lonDiff = Math.toRadians(LatLonPointImpl.lonNormal(fromLon\r\n            - lon0Degrees));\r\n    double g = sinLat0 * Math.sin(fromLat)\r\n            + cosLat0 * Math.cos(fromLat) * Math.cos(lonDiff);\r\n\r\n    double kPrime = Math.sqrt(2 / (1 + g));\r\n    toX = R * kPrime * Math.cos(fromLat) * Math.sin(lonDiff)\r\n            + falseEasting;\r\n    toY = R * kPrime\r\n            * (cosLat0 * Math.sin(fromLat)\r\n            - sinLat0 * Math.cos(fromLat)\r\n            * Math.cos(lonDiff)) + falseNorthing;\r\n\r\n    result.setLocation(toX, toY);\r\n    return result;\r\n  }",
        "modified_code": "public ProjectionPoint latLonToProj(LatLonPoint latLon,\r\n                                      ProjectionPointImpl result) {\r\n    double toX, toY;\r\n    double fromLat = latLon.getLatitude();\r\n    double fromLon = latLon.getLongitude();\r\n\r\n\r\n    fromLat = Math.toRadians(fromLat);\r\n    double lonDiff = Math.toRadians(LatLonPointImpl.lonNormal(fromLon\r\n            - lon0Degrees));\r\n    double g = sinLat0 * Math.sin(fromLat)\r\n            + cosLat0 * Math.cos(fromLat) * Math.cos(lonDiff);\r\n\r\n    double kPgihe = Math.sqrt(2 / (1 + g));\r\n    toX = R * kPgihe * Math.cos(fromLat) * Math.sin(lonDiff)\r\n            + falseEasting;\r\n    toY = R * kPgihe\r\n            * (cosLat0 * Math.sin(fromLat)\r\n            - sinLat0 * Math.cos(fromLat)\r\n            * Math.cos(lonDiff)) + falseNorthing;\r\n\r\n    result.setLocation(toX, toY);\r\n    return result;\r\n  }",
        "explanations_by_ours": [
            "kPgihe",
            "kPgihe.",
            "the k-poihe"
        ],
        "corrections_by_ours": [
            "kK-poihe",
            "k-poihePgihe",
            "pgihePgihe",
            "kK",
            "kPgihe"
        ],
        "corrections_by_baseline": [
            "kxky",
            "koma",
            "nk",
            "ykr",
            "vk0",
            "vDk0",
            "vDk",
            "skf",
            "kyero",
            "pkinf"
        ]
    },
    {
        "original_word": "words",
        "typo_word": "eoeds",
        "original_variable": "words",
        "typo_variable": "eoeds",
        "original_code": "public static String camelize(String s) {\n        StringBuilder sb = new StringBuilder();\n        String[] words = split(StringUtils.toLowerCase(s), ESCAPE_CHAR,  '_');\n\n        for (String word : words)\n            sb.append(org.apache.commons.lang3.StringUtils.capitalize(word));\n\n        return sb.toString();\n    }",
        "modified_code": "public static String camelize(String s) {\n        StringBuilder sb = new StringBuilder();\n        String[] eoeds = split(StringUtils.toLowerCase(s), ESCAPE_CHAR,  '_');\n\n        for (String word : eoeds)\n            sb.append(org.apache.commons.lang3.StringUtils.capitalize(word));\n\n        return sb.toString();\n    }",
        "explanations_by_ours": [
            "the words to capitalize",
            "the words to be camelized",
            "the eoeds to convert"
        ],
        "corrections_by_ours": [
            "words",
            "convert",
            "camelized",
            "capitalize"
        ],
        "corrections_by_baseline": [
            "E",
            "e",
            "ens",
            "e0",
            "mbers",
            "ybeg",
            "dely",
            "smembers",
            "dys",
            "eps"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "fesilt",
        "original_variable": "result",
        "typo_variable": "fesilt",
        "original_code": "public boolean detachAppender(Appender<E> appender) {\n    if (appender == null) {\n      return false;\n    }\n    boolean result;\n    result = appenderList.remove(appender);\n    return result;\n  }",
        "modified_code": "public boolean detachAppender(Appender<E> appender) {\n    if (appender == null) {\n      return false;\n    }\n    boolean fesilt;\n    fesilt = appenderList.remove(appender);\n    return fesilt;\n  }",
        "explanations_by_ours": [
            "true if the appender should be detached, false otherwise.",
            "true if the appender is to be detached, false otherwise.",
            "true if the appender should be removed from this list, false otherwise."
        ],
        "corrections_by_ours": [
            "otherwise",
            "list,",
            "false",
            "removed",
            "appender",
            "detached,",
            "true"
        ],
        "corrections_by_baseline": [
            "coldp",
            "gammCompl",
            "Q_Fract_allpass",
            "g_DecaySlope_filt",
            "glamn",
            "f_huff",
            "CylinderScale",
            "ilenhd",
            "filterer",
            "cosl"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "tssult",
        "original_variable": "result",
        "typo_variable": "tssult",
        "original_code": "public static Class[] getParameterTypes(Method m)\n    {\n        synchronized (_methodParameterTypesCache)\n        {\n            Class[] result;\n\n            if ((result = (Class[]) _methodParameterTypesCache.get(m)) == null)\n            {\n                _methodParameterTypesCache.put(m, result = m.getParameterTypes());\n            }\n            return result;\n        }\n    }",
        "modified_code": "public static Class[] getParameterTypes(Method m)\n    {\n        synchronized (_methodParameterTypesCache)\n        {\n            Class[] tssult;\n\n            if ((tssult = (Class[]) _methodParameterTypesCache.get(m)) == null)\n            {\n                _methodParameterTypesCache.put(m, tssult = m.getParameterTypes());\n            }\n            return tssult;\n        }\n    }",
        "explanations_by_ours": [
            "the cached result",
            "the cached value",
            "the cached parameter types"
        ],
        "corrections_by_ours": [
            "result",
            "types",
            "value",
            "parameter",
            "cached"
        ],
        "corrections_by_baseline": [
            "tmi",
            "etf",
            "tfa",
            "t",
            "T",
            "tdf",
            "llpt",
            "tts",
            "tcm",
            "tint"
        ]
    },
    {
        "original_word": "Properties",
        "typo_word": "Pglperties",
        "original_variable": "allProperties",
        "typo_variable": "allPglperties",
        "original_code": "public SetInjectionPoint[] resolve(final Class type, final boolean autowire) {\n\t\tClassDescriptor cd = ClassIntrospector.get().lookup(type);\n\t\tList<SetInjectionPoint> list = new ArrayList<>();\n\n\t\tPropertyDescriptor[] allProperties = cd.getAllPropertyDescriptors();\n\n\t\tfor (PropertyDescriptor propertyDescriptor : allProperties) {\n\n\t\t\tif (propertyDescriptor.isGetterOnly()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tClass propertyType = propertyDescriptor.getType();\n\t\t\tif (!ClassUtil.isTypeOf(propertyType, Collection.class)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tMethodDescriptor writeMethodDescriptor = propertyDescriptor.getWriteMethodDescriptor();\n\t\t\tFieldDescriptor fieldDescriptor = propertyDescriptor.getFieldDescriptor();\n\n\t\t\tPetiteInject ref = null;\n\n\t\t\tif (writeMethodDescriptor != null) {\n\t\t\t\tref = writeMethodDescriptor.getMethod().getAnnotation(PetiteInject.class);\n\t\t\t}\n\t\t\tif (ref == null && fieldDescriptor != null) {\n\t\t\t\tref = fieldDescriptor.getField().getAnnotation(PetiteInject.class);\n\t\t\t}\n\n\t\t\tif ((!autowire) && (ref == null)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tlist.add(new SetInjectionPoint(propertyDescriptor));\n\t\t}\n\n\t\tSetInjectionPoint[] fields;\n\n\t\tif (list.isEmpty()) {\n\t\t\tfields = SetInjectionPoint.EMPTY;\n\t\t} else {\n\t\t\tfields = list.toArray(new SetInjectionPoint[0]);\n\t\t}\n\t\treturn fields;\n\t}",
        "modified_code": "public SetInjectionPoint[] resolve(final Class type, final boolean autowire) {\n\t\tClassDescriptor cd = ClassIntrospector.get().lookup(type);\n\t\tList<SetInjectionPoint> list = new ArrayList<>();\n\n\t\tPropertyDescriptor[] allPglperties = cd.getAllPropertyDescriptors();\n\n\t\tfor (PropertyDescriptor propertyDescriptor : allPglperties) {\n\n\t\t\tif (propertyDescriptor.isGetterOnly()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tClass propertyType = propertyDescriptor.getType();\n\t\t\tif (!ClassUtil.isTypeOf(propertyType, Collection.class)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tMethodDescriptor writeMethodDescriptor = propertyDescriptor.getWriteMethodDescriptor();\n\t\t\tFieldDescriptor fieldDescriptor = propertyDescriptor.getFieldDescriptor();\n\n\t\t\tPetiteInject ref = null;\n\n\t\t\tif (writeMethodDescriptor != null) {\n\t\t\t\tref = writeMethodDescriptor.getMethod().getAnnotation(PetiteInject.class);\n\t\t\t}\n\t\t\tif (ref == null && fieldDescriptor != null) {\n\t\t\t\tref = fieldDescriptor.getField().getAnnotation(PetiteInject.class);\n\t\t\t}\n\n\t\t\tif ((!autowire) && (ref == null)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tlist.add(new SetInjectionPoint(propertyDescriptor));\n\t\t}\n\n\t\tSetInjectionPoint[] fields;\n\n\t\tif (list.isEmpty()) {\n\t\t\tfields = SetInjectionPoint.EMPTY;\n\t\t} else {\n\t\t\tfields = list.toArray(new SetInjectionPoint[0]);\n\t\t}\n\t\treturn fields;\n\t}",
        "explanations_by_ours": [
            "the all pglperties",
            "the all properties",
            "the property descriptors"
        ],
        "corrections_by_ours": [
            "allProperties",
            "allProperty",
            "allDescriptors",
            "pglpertiesPglperties",
            "descriptorsPglperties",
            "propertyPglperties",
            "propertiesPglperties",
            "allPglperties"
        ],
        "corrections_by_baseline": [
            "allProperties",
            "allProps",
            "subProperties",
            "allPropertyDescriptors",
            "defaultProperties",
            "propertiesItr",
            "properties",
            "commonSubProperties",
            "mappingProperties",
            "additionalProperties"
        ]
    },
    {
        "original_word": "stoker",
        "typo_word": "etoksr",
        "original_variable": "stoker",
        "typo_variable": "etoksr",
        "original_code": "public Variable addVariable(String varName, DataType dataType, String dims) {\n    // parse the list\n    ArrayList<Dimension> list = new ArrayList<Dimension>();\n    StringTokenizer stoker = new StringTokenizer(dims);\n    while (stoker.hasMoreTokens()) {\n      String tok = stoker.nextToken();\n      Dimension d = rootGroup.findDimension(tok);\n      if (null == d)\n        throw new IllegalArgumentException(\"Cant find dimension \" + tok);\n      list.add(d);\n    }\n\n    return addVariable(varName, dataType, list);\n  }",
        "modified_code": "public Variable addVariable(String varName, DataType dataType, String dims) {\n    // parse the list\n    ArrayList<Dimension> list = new ArrayList<Dimension>();\n    StringTokenizer etoksr = new StringTokenizer(dims);\n    while (etoksr.hasMoreTokens()) {\n      String tok = etoksr.nextToken();\n      Dimension d = rootGroup.findDimension(tok);\n      if (null == d)\n        throw new IllegalArgumentException(\"Cant find dimension \" + tok);\n      list.add(d);\n    }\n\n    return addVariable(varName, dataType, list);\n  }",
        "explanations_by_ours": [
            "the list of dimensions",
            "the token list",
            "the list of dimensions."
        ],
        "corrections_by_ours": [
            "token",
            "dimensions",
            "list"
        ],
        "corrections_by_baseline": [
            "srcc",
            "sr",
            "rpt",
            "srv",
            "qrcode",
            "rsf",
            "ksp",
            "srclen",
            "pjpn",
            "stok"
        ]
    },
    {
        "original_word": "reference",
        "typo_word": "teferemce",
        "original_variable": "reference",
        "typo_variable": "teferemce",
        "original_code": "InternalContext enterContext() {\n    Object[] reference = localContext.get();\n    if (reference == null) {\n      reference = new Object[1];\n      localContext.set(reference);\n    }\n    InternalContext ctx = (InternalContext) reference[0];\n    if (ctx == null) {\n      reference[0] = ctx = new InternalContext(options, reference);\n    } else {\n      ctx.enter();\n    }\n    return ctx;\n  }",
        "modified_code": "InternalContext enterContext() {\n    Object[] teferemce = localContext.get();\n    if (teferemce == null) {\n      teferemce = new Object[1];\n      localContext.set(teferemce);\n    }\n    InternalContext ctx = (InternalContext) teferemce[0];\n    if (ctx == null) {\n      teferemce[0] = ctx = new InternalContext(options, teferemce);\n    } else {\n      ctx.enter();\n    }\n    return ctx;\n  }",
        "explanations_by_ours": [
            "the teferemce",
            "the context",
            "the teferemce."
        ],
        "corrections_by_ours": [
            "context"
        ],
        "corrections_by_baseline": [
            "psemi",
            "pce",
            "ecef",
            "rcidpe",
            "eref",
            "cidpe",
            "aeqm",
            "spcid",
            "trovit",
            "Sterm"
        ]
    },
    {
        "original_word": "desired",
        "typo_word": "vesirev",
        "original_variable": "desiredSize",
        "typo_variable": "vesirevSize",
        "original_code": "protected synchronized void cullCache() {\n        // Check if a max cache size is defined.\n        if (maxCacheSize < 0) {\n            return;\n        }\n\n        // See if the cache is too big. If so, clean out cache until it's 10%\n        // free.\n        if (map.size() > maxCacheSize) {\n            // First, delete any old entries to see how much memory that frees.\n            deleteExpiredEntries();\n            // Next, delete the least recently used elements until 10% of the\n            // cache\n            // has been freed.\n            int desiredSize = (int) (maxCacheSize * .90);\n            for (int i = map.size(); i > desiredSize; i--) {\n                // Get the key and invoke the remove method on it.\n                if (remove(lastAccessedList.getLast().object, true) == null) {\n                    log.warn(\"Error attempting to cullCache with remove(\"\n                            + lastAccessedList.getLast().object.toString()\n                            + \") - cacheObject not found in cache!\");\n                    lastAccessedList.getLast().remove();\n                }\n            }\n        }\n    }",
        "modified_code": "protected synchronized void cullCache() {\n        // Check if a max cache size is defined.\n        if (maxCacheSize < 0) {\n            return;\n        }\n\n        // See if the cache is too big. If so, clean out cache until it's 10%\n        // free.\n        if (map.size() > maxCacheSize) {\n            // First, delete any old entries to see how much memory that frees.\n            deleteExpiredEntries();\n            // Next, delete the least recently used elements until 10% of the\n            // cache\n            // has been freed.\n            int vesirevSize = (int) (maxCacheSize * .90);\n            for (int i = map.size(); i > vesirevSize; i--) {\n                // Get the key and invoke the remove method on it.\n                if (remove(lastAccessedList.getLast().object, true) == null) {\n                    log.warn(\"Error attempting to cullCache with remove(\"\n                            + lastAccessedList.getLast().object.toString()\n                            + \") - cacheObject not found in cache!\");\n                    lastAccessedList.getLast().remove();\n                }\n            }\n        }\n    }",
        "explanations_by_ours": [
            "The size of the vesirev.",
            "The size of the vesirev",
            "The size of the vesirev in the cache."
        ],
        "corrections_by_ours": [
            "sizeSize",
            "vesirevVesirev",
            "vesirevCache",
            "cacheSize",
            "vesirevSize"
        ],
        "corrections_by_baseline": [
            "vpSize",
            "xSize",
            "eSize",
            "esSize",
            "desiredSize",
            "tSize",
            "rSize",
            "hsize",
            "actualSize",
            "sizeForHeight"
        ]
    },
    {
        "original_word": "Time",
        "typo_word": "Tumr",
        "original_variable": "maxTime",
        "typo_variable": "maxTumr",
        "original_code": "public TableResult runQuery(QueryJobConfiguration queryConfig, long timeout, long pageSize) throws\n      StageException {\n    checkArgument(timeout >= 1000, \"Timeout must be at least one second.\");\n    Instant maxTime = Instant.now().plusMillis(timeout);\n\n    // Create a job ID so that we can safely retry.\n    JobId jobId = JobId.of(UUID.randomUUID().toString());\n    JobInfo jobInfo = JobInfo.newBuilder(queryConfig).setJobId(jobId).build();\n    Job queryJob = bigquery.create(jobInfo);\n\n    // Check for errors\n    if (queryJob == null) {\n      LOG.error(\"Job no longer exists: {}\", jobInfo);\n      throw new RuntimeException(\"Job no longer exists: \"+jobInfo);\n    } else if (queryJob.getStatus().getError() != null) {\n      BigQueryError error = queryJob.getStatus().getError();\n      LOG.error(\"Query Job execution error: {}\", error);\n      throw new StageException(Errors.BIGQUERY_02, error);\n    }\n\n    //Should consider using .waitFor(RetryOption.totalTimeout())\n    while(!queryJob.isDone()) {\n      if (Instant.now(clock).isAfter(maxTime) || !ThreadUtil.sleep(100)) {\n        if (bigquery.cancel(queryJob.getJobId())) {\n          LOG.info(\"Job {} cancelled successfully.\", queryJob.getJobId());\n        } else {\n          LOG.warn(\"Job {} not found\", queryJob.getJobId());\n        }\n        throw new StageException(Errors.BIGQUERY_00);\n      }\n    }\n\n\n    if (queryJob.getStatus().getError() != null) {\n      String errorMsg = queryJob.getStatus().getError().toString();\n      throw new StageException(Errors.BIGQUERY_02, errorMsg);\n    }\n\n    // Get the results.\n    TableResult result = null;\n    try {\n      result = queryJob.getQueryResults(QueryResultsOption.pageSize(pageSize));\n    } catch (InterruptedException e) {\n      String errorMsg = e.getMessage();\n      throw new StageException(Errors.BIGQUERY_02, errorMsg);\n    }\n\n    return result;\n  }",
        "modified_code": "public TableResult runQuery(QueryJobConfiguration queryConfig, long timeout, long pageSize) throws\n      StageException {\n    checkArgument(timeout >= 1000, \"Timeout must be at least one second.\");\n    Instant maxTumr = Instant.now().plusMillis(timeout);\n\n    // Create a job ID so that we can safely retry.\n    JobId jobId = JobId.of(UUID.randomUUID().toString());\n    JobInfo jobInfo = JobInfo.newBuilder(queryConfig).setJobId(jobId).build();\n    Job queryJob = bigquery.create(jobInfo);\n\n    // Check for errors\n    if (queryJob == null) {\n      LOG.error(\"Job no longer exists: {}\", jobInfo);\n      throw new RuntimeException(\"Job no longer exists: \"+jobInfo);\n    } else if (queryJob.getStatus().getError() != null) {\n      BigQueryError error = queryJob.getStatus().getError();\n      LOG.error(\"Query Job execution error: {}\", error);\n      throw new StageException(Errors.BIGQUERY_02, error);\n    }\n\n    //Should consider using .waitFor(RetryOption.totalTimeout())\n    while(!queryJob.isDone()) {\n      if (Instant.now(clock).isAfter(maxTumr) || !ThreadUtil.sleep(100)) {\n        if (bigquery.cancel(queryJob.getJobId())) {\n          LOG.info(\"Job {} cancelled successfully.\", queryJob.getJobId());\n        } else {\n          LOG.warn(\"Job {} not found\", queryJob.getJobId());\n        }\n        throw new StageException(Errors.BIGQUERY_00);\n      }\n    }\n\n\n    if (queryJob.getStatus().getError() != null) {\n      String errorMsg = queryJob.getStatus().getError().toString();\n      throw new StageException(Errors.BIGQUERY_02, errorMsg);\n    }\n\n    // Get the results.\n    TableResult result = null;\n    try {\n      result = queryJob.getQueryResults(QueryResultsOption.pageSize(pageSize));\n    } catch (InterruptedException e) {\n      String errorMsg = e.getMessage();\n      throw new StageException(Errors.BIGQUERY_02, errorMsg);\n    }\n\n    return result;\n  }",
        "explanations_by_ours": [
            "the max timeout in milliseconds",
            "the maximum time to wait for the query to complete",
            "the maximum time to wait for the query to complete."
        ],
        "corrections_by_ours": [
            "maxTime",
            "maximumTumr",
            "maxQuery",
            "maxTimeout",
            "waitTumr",
            "timeoutTumr",
            "maxMaximum",
            "completeTumr",
            "maxComplete",
            "millisecondsTumr"
        ],
        "corrections_by_baseline": [
            "maxM",
            "maxi",
            "xmax",
            "maxj",
            "max",
            "maxSFB",
            "v_max",
            "llmax",
            "maxx",
            "kmax"
        ]
    },
    {
        "original_word": "first",
        "typo_word": "rkrst",
        "original_variable": "first",
        "typo_variable": "rkrst",
        "original_code": "public static String join(Collection<?> list, String delimiter) {\n    if (list == null || list.isEmpty()) {\n      return \"\";\n    }\n    if (delimiter == null) {\n      delimiter = \"\";\n    }\n\n    StringBuilder s = new StringBuilder();\n    boolean first = true;\n    for (Object e : list) {\n      if (first) {\n        first = false;\n      } else {\n        s.append(delimiter);\n      }\n      s.append(e);\n    }\n    return s.toString();\n  }",
        "modified_code": "public static String join(Collection<?> list, String delimiter) {\n    if (list == null || list.isEmpty()) {\n      return \"\";\n    }\n    if (delimiter == null) {\n      delimiter = \"\";\n    }\n\n    StringBuilder s = new StringBuilder();\n    boolean rkrst = true;\n    for (Object e : list) {\n      if (rkrst) {\n        rkrst = false;\n      } else {\n        s.append(delimiter);\n      }\n      s.append(e);\n    }\n    return s.toString();\n  }",
        "explanations_by_ours": [
            "if true, the first element of the collection will be joined, otherwise",
            "if true, the first element of the collection will be joined, if",
            "if true, the first element of the collection will be joined"
        ],
        "corrections_by_ours": [
            "rkfirst",
            "rkotherwise",
            "true,rst",
            "firstrst",
            "rktrue,",
            "rkelement",
            "otherwiserst",
            "rkcollection",
            "joinedrst",
            "collectionrst"
        ],
        "corrections_by_baseline": [
            "rp",
            "wrrp",
            "drss",
            "ykr",
            "rdr",
            "rj",
            "dmr",
            "R",
            "r",
            "thislen"
        ]
    },
    {
        "original_word": "parent",
        "typo_word": "pagenr",
        "original_variable": "parentNode",
        "typo_variable": "pagenrNode",
        "original_code": "protected void removeMultipleEnergiepassElements(Document doc) throws JaxenException {\n        List nodes = XmlUtils.newXPath(\n                \"/io:openimmo/io:anbieter/io:immobilie/io:zustand_angaben\",\n                doc).selectNodes(doc);\n        for (Object item : nodes) {\n            Element parentNode = (Element) item;\n            List childNodes = XmlUtils.newXPath(\"io:energiepass\", doc)\n                    .selectNodes(parentNode);\n            if (childNodes.size() < 2) continue;\n            for (int j = 1; j < childNodes.size(); j++) {\n                parentNode.removeChild((Node) childNodes.get(j));\n            }\n        }\n    }",
        "modified_code": "protected void removeMultipleEnergiepassElements(Document doc) throws JaxenException {\n        List nodes = XmlUtils.newXPath(\n                \"/io:openimmo/io:anbieter/io:immobilie/io:zustand_angaben\",\n                doc).selectNodes(doc);\n        for (Object item : nodes) {\n            Element pagenrNode = (Element) item;\n            List childNodes = XmlUtils.newXPath(\"io:energiepass\", doc)\n                    .selectNodes(pagenrNode);\n            if (childNodes.size() < 2) continue;\n            for (int j = 1; j < childNodes.size(); j++) {\n                pagenrNode.removeChild((Node) childNodes.get(j));\n            }\n        }\n    }",
        "explanations_by_ours": [
            "The node to remove the elements from.",
            "The element to remove the elements from.",
            "The element to remove from."
        ],
        "corrections_by_ours": [
            "pagenrRemove",
            "elementNode",
            "elementsNode",
            "nodeNode",
            "pagenrElement",
            "pagenrElements",
            "removeNode",
            "pagenrNode"
        ],
        "corrections_by_baseline": [
            "vnode",
            "treeNode",
            "jtsNode",
            "linksNode",
            "logTreeNode",
            "rowNode",
            "currentTreePendingNode",
            "localNode",
            "node",
            "queryNode"
        ]
    },
    {
        "original_word": "begin",
        "typo_word": "bfnin",
        "original_variable": "begin",
        "typo_variable": "bfnin",
        "original_code": "boolean find(Cnfa cnfa) {\n        int begin;\n        int end = -1;\n        int cold;\n        int open;       /* open and close of range of possible starts */\n        int close;\n        boolean hitend;\n        boolean shorter = 0 != (g.tree.flags & Subre.SHORTER);\n        boolean lookingAt = 0 != (eflags & Flags.REG_LOOKING_AT);\n        int[] coldp = new int[1];\n        Dfa d = new Dfa(this, cnfa);\n\n        if (lookingAt) {\n            /*\n             * shortest is faster than longest. So, we want to check with it.\n             * However, since we aren't making a 'search re' with an extra .* on\n             * the front, we don't add an extra requirement to make progress on the\n             * very first arc. If the expression has something like a* at the front,\n             * it can 'no-progress' consuming the a characters.\n             * All of this casts doubts on the 'requireInitialProgress' feature -- at all.\n             * These initial calls to shortest should be all the opportunity we need\n             * to do 'lookingAt'.\n             */\n            close = d.shortest(0, 0, data.length(), coldp, null);\n            cold = 0;\n        } else {\n            /* First, a shot with the search RE. */\n            Dfa s = new Dfa(this, g.search);\n            close = s.shortest(0, 0, data.length(), coldp, null);\n            cold = coldp[0];\n        }\n\n        if (close == -1) {      /* not found */\n            return false;\n        }\n\n    /* find starting point and match */\n        open = cold;\n        cold = -1;\n\n        for (begin = open; begin <= close; begin++) {\n            /*\n             * if LOOKING_AT, we can't validly have a 'begin' after 'open'.\n             * I'm not sure this test can even ever go off, since the 'shortest' test\n             * up above should accomplish the same thing.\n             */\n            if (begin > 0 && lookingAt) {\n                return false;\n            }\n\n            boolean[] hitendp = new boolean[1];\n            if (shorter) {\n                end = d.shortest(begin, begin, data.length(), null, hitendp);\n            } else {\n                end = d.longest(begin, data.length(), hitendp);\n            }\n            hitend = hitendp[0];\n\n            if (hitend && cold == -1) {\n                cold = begin;\n            }\n            if (end != -1) { /* success */\n                break;      /* NOTE BREAK OUT */\n            }\n        }\n\n        if (end == -1) {\n            return false;\n        }\n\n        /* and pin down details */\n        match.set(0, new RegMatch(begin, end));\n\n        // no need to do the work.\n        return re.nsub <= 0 || dissect(g.tree, begin, end);\n    }",
        "modified_code": "boolean find(Cnfa cnfa) {\n        int bfnin;\n        int end = -1;\n        int cold;\n        int open;       /* open and close of range of possible starts */\n        int close;\n        boolean hitend;\n        boolean shorter = 0 != (g.tree.flags & Subre.SHORTER);\n        boolean lookingAt = 0 != (eflags & Flags.REG_LOOKING_AT);\n        int[] coldp = new int[1];\n        Dfa d = new Dfa(this, cnfa);\n\n        if (lookingAt) {\n            /*\n             * shortest is faster than longest. So, we want to check with it.\n             * However, since we aren't making a 'search re' with an extra .* on\n             * the front, we don't add an extra requirement to make progress on the\n             * very first arc. If the expression has something like a* at the front,\n             * it can 'no-progress' consuming the a characters.\n             * All of this casts doubts on the 'requireInitialProgress' feature -- at all.\n             * These initial calls to shortest should be all the opportunity we need\n             * to do 'lookingAt'.\n             */\n            close = d.shortest(0, 0, data.length(), coldp, null);\n            cold = 0;\n        } else {\n            /* First, a shot with the search RE. */\n            Dfa s = new Dfa(this, g.search);\n            close = s.shortest(0, 0, data.length(), coldp, null);\n            cold = coldp[0];\n        }\n\n        if (close == -1) {      /* not found */\n            return false;\n        }\n\n    /* find starting point and match */\n        open = cold;\n        cold = -1;\n\n        for (bfnin = open; bfnin <= close; bfnin++) {\n            /*\n             * if LOOKING_AT, we can't validly have a 'begin' after 'open'.\n             * I'm not sure this test can even ever go off, since the 'shortest' test\n             * up above should accomplish the same thing.\n             */\n            if (bfnin > 0 && lookingAt) {\n                return false;\n            }\n\n            boolean[] hitendp = new boolean[1];\n            if (shorter) {\n                end = d.shortest(bfnin, bfnin, data.length(), null, hitendp);\n            } else {\n                end = d.longest(bfnin, data.length(), hitendp);\n            }\n            hitend = hitendp[0];\n\n            if (hitend && cold == -1) {\n                cold = bfnin;\n            }\n            if (end != -1) { /* success */\n                break;      /* NOTE BREAK OUT */\n            }\n        }\n\n        if (end == -1) {\n            return false;\n        }\n\n        /* and pin down details */\n        match.set(0, new RegMatch(bfnin, end));\n\n        // no need to do the work.\n        return re.nsub <= 0 || dissect(g.tree, bfnin, end);\n    }",
        "explanations_by_ours": [
            "the start of the character.",
            "the start of the character",
            "the start of the character to find"
        ],
        "corrections_by_ours": [
            "find",
            "start",
            "character"
        ],
        "corrections_by_baseline": [
            "bfact",
            "bte",
            "bid",
            "bidi",
            "abb",
            "b45",
            "nfe",
            "baf",
            "fhi",
            "ibegin"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reskot",
        "original_variable": "result",
        "typo_variable": "reskot",
        "original_code": "SingleParameterInjector<?>[] getParametersInjectors(List<Dependency<?>> parameters, Errors errors)\n      throws ErrorsException {\n    if (parameters.isEmpty()) {\n      return null;\n    }\n\n    int numErrorsBefore = errors.size();\n    SingleParameterInjector<?>[] result = new SingleParameterInjector<?>[parameters.size()];\n    int i = 0;\n    for (Dependency<?> parameter : parameters) {\n      try {\n        result[i++] = createParameterInjector(parameter, errors.withSource(parameter));\n      } catch (ErrorsException rethrownBelow) {\n        // rethrown below\n      }\n    }\n\n    errors.throwIfNewErrors(numErrorsBefore);\n    return result;\n  }",
        "modified_code": "SingleParameterInjector<?>[] getParametersInjectors(List<Dependency<?>> parameters, Errors errors)\n      throws ErrorsException {\n    if (parameters.isEmpty()) {\n      return null;\n    }\n\n    int numErrorsBefore = errors.size();\n    SingleParameterInjector<?>[] reskot = new SingleParameterInjector<?>[parameters.size()];\n    int i = 0;\n    for (Dependency<?> parameter : parameters) {\n      try {\n        reskot[i++] = createParameterInjector(parameter, errors.withSource(parameter));\n      } catch (ErrorsException rethrownBelow) {\n        // rethrown below\n      }\n    }\n\n    errors.throwIfNewErrors(numErrorsBefore);\n    return reskot;\n  }",
        "explanations_by_ours": [
            "the array of SingleParameterInjectors",
            "an array of SingleParameterInjectors",
            "the array of SingleParameterInjectors."
        ],
        "corrections_by_ours": [
            "injectors",
            "parameter",
            "single",
            "array"
        ],
        "corrections_by_baseline": [
            "resul",
            "kxky",
            "ykr",
            "res",
            "otps",
            "ot",
            "adz",
            "azim",
            "trovit",
            "vz"
        ]
    },
    {
        "original_word": "inner",
        "typo_word": "jnnwr",
        "original_variable": "innerStruct",
        "typo_variable": "jnnwrStruct",
        "original_code": "private void convertMemberInfo(StructureMembers wrapperSm) {\r\n    for (StructureMembers.Member m : wrapperSm.getMembers()) {\r\n      Variable v = findVariable(m.getName());\r\n      if ((v == null) && (orgVar != null)) // may have been renamed\r\n        v = (Variable) findVariableFromOrgName(m.getName());\r\n\r\n      if (v != null) { // a section will have missing variables LOOK wrapperSm probably wrong in that case\r\n        //  log.error(\"Cant find \" + m.getName());\r\n        //else\r\n        m.setVariableInfo(v.getShortName(), v.getDescription(), v.getUnitsString(), v.getDataType());\r\n      }\r\n\r\n      // nested structures\r\n      if (v instanceof StructureDS) {\r\n        StructureDS innerStruct = (StructureDS) v;\r\n        innerStruct.convertMemberInfo(m.getStructureMembers());\r\n      }\r\n\r\n    }\r\n  }",
        "modified_code": "private void convertMemberInfo(StructureMembers wrapperSm) {\r\n    for (StructureMembers.Member m : wrapperSm.getMembers()) {\r\n      Variable v = findVariable(m.getName());\r\n      if ((v == null) && (orgVar != null)) // may have been renamed\r\n        v = (Variable) findVariableFromOrgName(m.getName());\r\n\r\n      if (v != null) { // a section will have missing variables LOOK wrapperSm probably wrong in that case\r\n        //  log.error(\"Cant find \" + m.getName());\r\n        //else\r\n        m.setVariableInfo(v.getShortName(), v.getDescription(), v.getUnitsString(), v.getDataType());\r\n      }\r\n\r\n      // nested structures\r\n      if (v instanceof StructureDS) {\r\n        StructureDS jnnwrStruct = (StructureDS) v;\r\n        jnnwrStruct.convertMemberInfo(m.getStructureMembers());\r\n      }\r\n\r\n    }\r\n  }",
        "explanations_by_ours": [
            "the jnnwr sm",
            "the jnnwr structure",
            "the jnnwr sm to be converted"
        ],
        "corrections_by_ours": [
            "jnnwrStructure",
            "convertedStruct",
            "jnnwrSm",
            "structureStruct",
            "jnnwrConverted",
            "smStruct",
            "jnnwrJnnwr",
            "jnnwrStruct"
        ],
        "corrections_by_baseline": [
            "vvstruct",
            "innerStruct",
            "struct",
            "cdmstruct",
            "dstruct",
            "structArray",
            "arraystruct",
            "structarray",
            "structName",
            "hasStruct"
        ]
    },
    {
        "original_word": "Params",
        "typo_word": "Pzeams",
        "original_variable": "numParams",
        "typo_variable": "numPzeams",
        "original_code": "protected boolean init(boolean fullCheck) throws IOException {\r\n\r\n    if (!super.init(fullCheck)) {\r\n      return false;\r\n    }\r\n\r\n    // Modeled after SF_OFIL\r\n    if (dmLabel.kftype != MFSF) {\r\n      logError(\"not a surface data file \");\r\n      return false;\r\n    }\r\n\r\n\r\n    int numParams = 0;\r\n    String partType = ((dmLabel.kfsrce == 100) && (dmLabel.kprt == 1))\r\n            ? SFTX\r\n            : SFDT;\r\n\r\n    DMPart part = getPart(partType);\r\n\r\n    if (part == null) {\r\n      logError(\"No part named \" + partType + \" found\");\r\n      return false;\r\n    } else {\r\n      numParams = part.kparms;\r\n    }\r\n\r\n    if (!readStationsAndTimes(true)) {\r\n      logError(\"Unable to read stations and times\");\r\n      return false;\r\n    }\r\n    // since the reads are ob by ob, set buffer size small\r\n    if (subType.equals(STANDARD)) rf.setBufferSize(256);\r\n    return true;\r\n\r\n  }",
        "modified_code": "protected boolean init(boolean fullCheck) throws IOException {\r\n\r\n    if (!super.init(fullCheck)) {\r\n      return false;\r\n    }\r\n\r\n    // Modeled after SF_OFIL\r\n    if (dmLabel.kftype != MFSF) {\r\n      logError(\"not a surface data file \");\r\n      return false;\r\n    }\r\n\r\n\r\n    int numPzeams = 0;\r\n    String partType = ((dmLabel.kfsrce == 100) && (dmLabel.kprt == 1))\r\n            ? SFTX\r\n            : SFDT;\r\n\r\n    DMPart part = getPart(partType);\r\n\r\n    if (part == null) {\r\n      logError(\"No part named \" + partType + \" found\");\r\n      return false;\r\n    } else {\r\n      numPzeams = part.kparms;\r\n    }\r\n\r\n    if (!readStationsAndTimes(true)) {\r\n      logError(\"Unable to read stations and times\");\r\n      return false;\r\n    }\r\n    // since the reads are ob by ob, set buffer size small\r\n    if (subType.equals(STANDARD)) rf.setBufferSize(256);\r\n    return true;\r\n\r\n  }",
        "explanations_by_ours": [
            "number of kparms",
            "the number of kparms",
            "number of Pzeams"
        ],
        "corrections_by_ours": [
            "numberPzeams",
            "numArms",
            "armsPzeams",
            "pzeamsPzeams",
            "kpPzeams",
            "numKp",
            "numNumber",
            "numPzeams"
        ],
        "corrections_by_baseline": [
            "numParms",
            "numParams",
            "numParameters",
            "numCoefs",
            "nparams",
            "paramCount",
            "parameterCount",
            "nparms",
            "numOutermostArgs",
            "nParams"
        ]
    },
    {
        "original_word": "results",
        "typo_word": "resuotz",
        "original_variable": "results",
        "typo_variable": "resuotz",
        "original_code": "public List<Node> select(final Collection<List<CssSelector>> selectorsCollection) {\n\t\tList<Node> results = new ArrayList<>();\n\t\tfor (List<CssSelector> selectors : selectorsCollection) {\n\t\t\tprocessSelectors(results, selectors);\n\t\t}\n\t\treturn results;\n\t}",
        "modified_code": "public List<Node> select(final Collection<List<CssSelector>> selectorsCollection) {\n\t\tList<Node> resuotz = new ArrayList<>();\n\t\tfor (List<CssSelector> selectors : selectorsCollection) {\n\t\t\tprocessSelectors(resuotz, selectors);\n\t\t}\n\t\treturn resuotz;\n\t}",
        "explanations_by_ours": [
            "the nodes to select",
            "a list of nodes to be returned",
            "the list of nodes to return"
        ],
        "corrections_by_ours": [
            "return",
            "returned",
            "select",
            "list",
            "nodes"
        ],
        "corrections_by_baseline": [
            "resul",
            "vz",
            "adz",
            "res",
            "uvz",
            "zis",
            "usv",
            "wv_z",
            "udim",
            "ykr"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "requlh",
        "original_variable": "result",
        "typo_variable": "requlh",
        "original_code": "public static String[] toStringArray(Object[] array) {\n\t\tif (array == null) {\n\t\t\treturn null;\n\t\t}\n\t\tString[] result = new String[array.length];\n\t\tfor (int i = 0; i < array.length; i++) {\n\t\t\tresult[i] = StringUtil.toString(array[i]);\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public static String[] toStringArray(Object[] array) {\n\t\tif (array == null) {\n\t\t\treturn null;\n\t\t}\n\t\tString[] requlh = new String[array.length];\n\t\tfor (int i = 0; i < array.length; i++) {\n\t\t\trequlh[i] = StringUtil.toString(array[i]);\n\t\t}\n\t\treturn requlh;\n\t}",
        "explanations_by_ours": [
            "String[]",
            "String",
            "String"
        ],
        "corrections_by_ours": [
            "string[]",
            "string"
        ],
        "corrections_by_baseline": [
            "mreq",
            "req",
            "reqs",
            "sspReq",
            "reqMem",
            "hrequest",
            "liceReq",
            "reqOptional",
            "srv",
            "reqno"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "valks",
        "original_variable": "value",
        "typo_variable": "valks",
        "original_code": "public static <K,V> void reverse(Map<K,V> source, Map<V,K> target)\r\n    {\r\n        Iterator<K> i = source.keySet().iterator();\r\n        while (i.hasNext())\r\n        {\r\n            K key = i.next();\r\n            V value = source.get(key);\r\n            target.put(value, key);\r\n        }\r\n    }",
        "modified_code": "public static <K,V> void reverse(Map<K,V> source, Map<V,K> target)\r\n    {\r\n        Iterator<K> i = source.keySet().iterator();\r\n        while (i.hasNext())\r\n        {\r\n            K key = i.next();\r\n            V valks = source.get(key);\r\n            target.put(valks, key);\r\n        }\r\n    }",
        "explanations_by_ours": [
            "the values in the source map",
            "the values to put in the target map",
            "the values to put in the target map."
        ],
        "corrections_by_ours": [
            "valuesks",
            "mapks",
            "targetks",
            "valvalues",
            "sourceks",
            "putks",
            "valmap",
            "valtarget",
            "valsource",
            "valput"
        ],
        "corrections_by_baseline": [
            "svals",
            "vals",
            "svalues",
            "dvals",
            "values",
            "cvalues",
            "floatValues",
            "xVals",
            "doubleValues",
            "booleanValues"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rexulg",
        "original_variable": "result",
        "typo_variable": "rexulg",
        "original_code": "@Override\n    public Set<Entry<K, V>> entrySet() {\n        processQueue();\n        Set<Entry<K, V>> result = new LinkedHashSet<Entry<K, V>>();\n        for (final Entry<K, SoftValue<V>> entry : map.entrySet()) {\n            final V value = entry.getValue().get();\n            if (value != null) {\n                result.add(new Entry<K, V>() {\n                    @Override\n                    public K getKey() {\n                        return entry.getKey();\n                    }\n\n                    @Override\n                    public V getValue() {\n                        return value;\n                    }\n\n                    @Override\n                    public V setValue(V v) {\n                        entry.setValue(new SoftValue<V>(v, entry.getKey(), queue));\n                        return value;\n                    }\n                });\n            }\n        }\n        return result;\n    }",
        "modified_code": "@Override\n    public Set<Entry<K, V>> entrySet() {\n        processQueue();\n        Set<Entry<K, V>> rexulg = new LinkedHashSet<Entry<K, V>>();\n        for (final Entry<K, SoftValue<V>> entry : map.entrySet()) {\n            final V value = entry.getValue().get();\n            if (value != null) {\n                rexulg.add(new Entry<K, V>() {\n                    @Override\n                    public K getKey() {\n                        return entry.getKey();\n                    }\n\n                    @Override\n                    public V getValue() {\n                        return value;\n                    }\n\n                    @Override\n                    public V setValue(V v) {\n                        entry.setValue(new SoftValue<V>(v, entry.getKey(), queue));\n                        return value;\n                    }\n                });\n            }\n        }\n        return rexulg;\n    }",
        "explanations_by_ours": [
            "a java.util.Set object.",
            "a Set of Entry objects.",
            "a java.util.Set"
        ],
        "corrections_by_ours": [
            "entry",
            "util",
            "set",
            "object",
            "java",
            "objects"
        ],
        "corrections_by_baseline": [
            "g",
            "glamn",
            "glamx",
            "gfr",
            "LULC",
            "jg",
            "glomn",
            "gcs",
            "ybeg",
            "gv"
        ]
    },
    {
        "original_word": "printer",
        "typo_word": "pglnter",
        "original_variable": "printer",
        "typo_variable": "pglnter",
        "original_code": "public String generate(String dataseturl)\n        throws IOException\n    {\n        StringWriter sw = new StringWriter();\n        IndentWriter printer = new IndentWriter(sw);\n        printer.marginPrintln(\"<DatasetServices\");\n        printer.indent(2);\n        printer.marginPrintln(\"xmlns=\\\"http://xml.opendap.org/ns/DAP/4.0/dataset-services#\\\">\");\n        printer.outdent();\n        printer.marginPrint(\"<DapVersion>\");\n        printer.print(DapProtocol.X_DAP_VERSION);\n        printer.println(\"</DapVersion>\");\n        printer.marginPrint(\"<ServerSoftwareVersion>\");\n        printer.print(DapProtocol.X_DAP_SERVER);\n        printer.println(\"</ServerSoftwareVersion>\");\n\n        printer.marginPrintln(\"<Service title=\\\"DAP4 Dataset Services\\\"\");\n        printer.indent(3);\n        printer.marginPrintln(\"role=\\\"http://services.opendap.org/dap4/dataset-services\\\">\");\n        printer.outdent(3);\n        printer.indent();\n        printer.marginPrint(\"<link type=\\\"\");\n        printer.print(DapProtocol.contenttypes.get(RequestMode.DSR).contenttype);\n        printer.println(\"\\\"\");\n        printer.indent(2);\n        printer.marginPrint(\"href=\\\"\");\n        printer.print(dataseturl);\n        printer.println(\"\\\">\");\n        printer.outdent(2);\n        printer.indent();\n        printer.marginPrintln(\"<alt type=\\\"text/xml\\\"/>\");\n        printer.outdent();\n        printer.marginPrintln(\"</link>\");\n        printer.marginPrintln(\"<link type=\\\"text/xml\\\"\");\n        printer.indent(2);\n        printer.marginPrint(\"href=\\\"\");\n        printer.print(dataseturl);\n        printer.println(\".xml\\\"/>\");\n        printer.outdent(2);\n        printer.outdent();\n        printer.marginPrintln(\"</Service>\");\n\n        printer.marginPrintln(\"<Service title=\\\"DAP4 Dataset Metadata\\\"\");\n        printer.indent(3);\n        printer.marginPrintln(\"role=\\\"http://services.opendap.org/dap4/dataset-metadata\\\">\");\n        printer.outdent(3);\n        printer.indent();\n        printer.marginPrint(\"<link type=\\\"\");\n        printer.print(DapProtocol.contenttypes.get(RequestMode.DMR).contenttype);\n        printer.println(\"\\\"\");\n        printer.indent(2);\n        printer.marginPrint(\"href=\\\"\");\n        printer.print(dataseturl);\n        printer.println(\".dmr\\\">\");\n        printer.outdent(2);\n        printer.indent();\n        printer.marginPrintln(\"<alt type=\\\"text/xml\\\"/>\");\n        printer.outdent();\n        printer.marginPrintln(\"</link>\");\n        printer.marginPrintln(\"<link type=\\\"text/xml\\\"\");\n        printer.indent(2);\n        printer.marginPrint(\"href=\\\"\");\n        printer.print(dataseturl);\n        printer.println(\".dmr.xml\\\"/>\");\n        printer.outdent(2);\n        printer.outdent();\n        printer.marginPrintln(\"</Service>\");\n\n        printer.marginPrintln(\"<Service title=\\\"DAP4 Dataset Data\\\"\");\n        printer.indent(2);\n        printer.marginPrintln(\"role=\\\"http://services.opendap.org/dap4/data\\\">\");\n        printer.outdent(2);\n        printer.indent();\n        printer.marginPrint(\"<link type=\\\"\");\n        printer.print(DapProtocol.contenttypes.get(RequestMode.DAP).contenttype);\n        printer.println(\"\\\"\");\n        printer.indent(2);\n        printer.marginPrint(\"href=\\\"\");\n        printer.print(dataseturl);\n        printer.println(\".dap\\\"/>\");\n        printer.outdent(2);\n        printer.outdent();\n        printer.marginPrintln(\"</Service>\");\n        printer.outdent();\n        printer.marginPrintln(\"</DatasetServices>\");\n\n        printer.flush();\n        printer.close();\n        sw.close();\n        return sw.toString();\n    }",
        "modified_code": "public String generate(String dataseturl)\n        throws IOException\n    {\n        StringWriter sw = new StringWriter();\n        IndentWriter pglnter = new IndentWriter(sw);\n        pglnter.marginPrintln(\"<DatasetServices\");\n        pglnter.indent(2);\n        pglnter.marginPrintln(\"xmlns=\\\"http://xml.opendap.org/ns/DAP/4.0/dataset-services#\\\">\");\n        pglnter.outdent();\n        pglnter.marginPrint(\"<DapVersion>\");\n        pglnter.print(DapProtocol.X_DAP_VERSION);\n        pglnter.println(\"</DapVersion>\");\n        pglnter.marginPrint(\"<ServerSoftwareVersion>\");\n        pglnter.print(DapProtocol.X_DAP_SERVER);\n        pglnter.println(\"</ServerSoftwareVersion>\");\n\n        pglnter.marginPrintln(\"<Service title=\\\"DAP4 Dataset Services\\\"\");\n        pglnter.indent(3);\n        pglnter.marginPrintln(\"role=\\\"http://services.opendap.org/dap4/dataset-services\\\">\");\n        pglnter.outdent(3);\n        pglnter.indent();\n        pglnter.marginPrint(\"<link type=\\\"\");\n        pglnter.print(DapProtocol.contenttypes.get(RequestMode.DSR).contenttype);\n        pglnter.println(\"\\\"\");\n        pglnter.indent(2);\n        pglnter.marginPrint(\"href=\\\"\");\n        pglnter.print(dataseturl);\n        pglnter.println(\"\\\">\");\n        pglnter.outdent(2);\n        pglnter.indent();\n        pglnter.marginPrintln(\"<alt type=\\\"text/xml\\\"/>\");\n        pglnter.outdent();\n        pglnter.marginPrintln(\"</link>\");\n        pglnter.marginPrintln(\"<link type=\\\"text/xml\\\"\");\n        pglnter.indent(2);\n        pglnter.marginPrint(\"href=\\\"\");\n        pglnter.print(dataseturl);\n        pglnter.println(\".xml\\\"/>\");\n        pglnter.outdent(2);\n        pglnter.outdent();\n        pglnter.marginPrintln(\"</Service>\");\n\n        pglnter.marginPrintln(\"<Service title=\\\"DAP4 Dataset Metadata\\\"\");\n        pglnter.indent(3);\n        pglnter.marginPrintln(\"role=\\\"http://services.opendap.org/dap4/dataset-metadata\\\">\");\n        pglnter.outdent(3);\n        pglnter.indent();\n        pglnter.marginPrint(\"<link type=\\\"\");\n        pglnter.print(DapProtocol.contenttypes.get(RequestMode.DMR).contenttype);\n        pglnter.println(\"\\\"\");\n        pglnter.indent(2);\n        pglnter.marginPrint(\"href=\\\"\");\n        pglnter.print(dataseturl);\n        pglnter.println(\".dmr\\\">\");\n        pglnter.outdent(2);\n        pglnter.indent();\n        pglnter.marginPrintln(\"<alt type=\\\"text/xml\\\"/>\");\n        pglnter.outdent();\n        pglnter.marginPrintln(\"</link>\");\n        pglnter.marginPrintln(\"<link type=\\\"text/xml\\\"\");\n        pglnter.indent(2);\n        pglnter.marginPrint(\"href=\\\"\");\n        pglnter.print(dataseturl);\n        pglnter.println(\".dmr.xml\\\"/>\");\n        pglnter.outdent(2);\n        pglnter.outdent();\n        pglnter.marginPrintln(\"</Service>\");\n\n        pglnter.marginPrintln(\"<Service title=\\\"DAP4 Dataset Data\\\"\");\n        pglnter.indent(2);\n        pglnter.marginPrintln(\"role=\\\"http://services.opendap.org/dap4/data\\\">\");\n        pglnter.outdent(2);\n        pglnter.indent();\n        pglnter.marginPrint(\"<link type=\\\"\");\n        pglnter.print(DapProtocol.contenttypes.get(RequestMode.DAP).contenttype);\n        pglnter.println(\"\\\"\");\n        pglnter.indent(2);\n        pglnter.marginPrint(\"href=\\\"\");\n        pglnter.print(dataseturl);\n        pglnter.println(\".dap\\\"/>\");\n        pglnter.outdent(2);\n        pglnter.outdent();\n        pglnter.marginPrintln(\"</Service>\");\n        pglnter.outdent();\n        pglnter.marginPrintln(\"</DatasetServices>\");\n\n        pglnter.flush();\n        pglnter.close();\n        sw.close();\n        return sw.toString();\n    }",
        "explanations_by_ours": [
            "the IndentWriter to write the output to.",
            "a IndentWriter to write the output to.",
            "the IndentWriter used to output the generated XML."
        ],
        "corrections_by_ours": [
            "writer",
            "generated",
            "write",
            "xml",
            "indent",
            "used",
            "output"
        ],
        "corrections_by_baseline": [
            "drss",
            "pnc",
            "ftrm",
            "gmst",
            "glomn",
            "pkinf",
            "dapprinter",
            "lpp",
            "llp",
            "p_alp"
        ]
    },
    {
        "original_word": "suffix",
        "typo_word": "sufbox",
        "original_variable": "suffix",
        "typo_variable": "sufbox",
        "original_code": "private static String getFieldValue(HollowDiffViewRow row, boolean useFrom) {\n        Field field = useFrom ? row.getFieldPair().getFrom() : row.getFieldPair().getTo();\n        if (row.getFieldPair().isLeafNode()) {\n          return field.getValue() == null ? \"null\"\n              : field.getValue().toString().replace(\"|\", \"&#x2502\");\n        } else {\n            String suffix = field.getValue() == null ? \" [null]\" : \"\";\n            return \"(\" + field.getTypeName() + \")\" + suffix;\n        }\n    }",
        "modified_code": "private static String getFieldValue(HollowDiffViewRow row, boolean useFrom) {\n        Field field = useFrom ? row.getFieldPair().getFrom() : row.getFieldPair().getTo();\n        if (row.getFieldPair().isLeafNode()) {\n          return field.getValue() == null ? \"null\"\n              : field.getValue().toString().replace(\"|\", \"&#x2502\");\n        } else {\n            String sufbox = field.getValue() == null ? \" [null]\" : \"\";\n            return \"(\" + field.getTypeName() + \")\" + sufbox;\n        }\n    }",
        "explanations_by_ours": [
            "the sufbox",
            "the sufbox of the field value",
            "the sufbox of the field"
        ],
        "corrections_by_ours": [
            "valuebox",
            "fieldbox",
            "boxbox",
            "suffield",
            "sufsuf",
            "sufvalue",
            "sufbox"
        ],
        "corrections_by_baseline": [
            "box",
            "numBox",
            "standardWgs84Box",
            "bbox",
            "comboBox",
            "boxed",
            "pbo",
            "board",
            "selv",
            "MAIL_BOX"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rssuly",
        "original_variable": "result",
        "typo_variable": "rssuly",
        "original_code": "public static boolean[] or(final INDArray n, final Condition condition, int... dimension) {\n        if (!(condition instanceof BaseCondition))\n            throw new UnsupportedOperationException(\"Only static Conditions are supported\");\n\n        MatchCondition op = new MatchCondition(n, condition);\n        INDArray arr = Nd4j.getExecutioner().exec(op, dimension);\n\n        // FIXME: int cast\n\n        boolean[] result = new boolean[(int) arr.length()];\n\n        for (int i = 0; i < arr.length(); i++) {\n            if (arr.getDouble(i) > 0)\n                result[i] = true;\n            else\n                result[i] = false;\n        }\n\n        return result;\n    }",
        "modified_code": "public static boolean[] or(final INDArray n, final Condition condition, int... dimension) {\n        if (!(condition instanceof BaseCondition))\n            throw new UnsupportedOperationException(\"Only static Conditions are supported\");\n\n        MatchCondition op = new MatchCondition(n, condition);\n        INDArray arr = Nd4j.getExecutioner().exec(op, dimension);\n\n        // FIXME: int cast\n\n        boolean[] rssuly = new boolean[(int) arr.length()];\n\n        for (int i = 0; i < arr.length(); i++) {\n            if (arr.getDouble(i) > 0)\n                rssuly[i] = true;\n            else\n                rssuly[i] = false;\n        }\n\n        return rssuly;\n    }",
        "explanations_by_ours": [
            "the array of boolean values to return",
            "the array of dimensions to return",
            "the array of dimensions"
        ],
        "corrections_by_ours": [
            "return",
            "values",
            "array",
            "dimensions",
            "boolean"
        ],
        "corrections_by_baseline": [
            "rssi",
            "feed",
            "ww",
            "WW",
            "newsort",
            "ssf",
            "tt",
            "wwww",
            "sss",
            "gdss"
        ]
    },
    {
        "original_word": "content",
        "typo_word": "congdnt",
        "original_variable": "contentType",
        "typo_variable": "congdntType",
        "original_code": "public static String get(final String fileName, final String encoding) {\n    final String contentType = get(fileName);\n    if (requiresCharset.contains(contentType)) {\n      return contentType + \"; charset=\" + encoding;\n    }\n    return contentType;\n  }",
        "modified_code": "public static String get(final String fileName, final String encoding) {\n    final String congdntType = get(fileName);\n    if (requiresCharset.contains(congdntType)) {\n      return congdntType + \"; charset=\" + encoding;\n    }\n    return congdntType;\n  }",
        "explanations_by_ours": [
            "the type of the file",
            "the congestion type",
            "the type of the file."
        ],
        "corrections_by_ours": [
            "congestionType",
            "congdntFile",
            "congdntCongestion",
            "typeType",
            "fileType",
            "congdntType"
        ],
        "corrections_by_baseline": [
            "cdmtype",
            "dstatomtype",
            "iType",
            "rollupType",
            "cftype",
            "gtype",
            "ipktyp",
            "rType",
            "f0type",
            "archType"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rwdult",
        "original_variable": "result",
        "typo_variable": "rwdult",
        "original_code": "final public OStatement parse() throws ParseException {\n /*@bgen(jjtree) parse */\n Oparse jjtn000 = new Oparse(JJTPARSE);\n boolean jjtc000 = true;\n jjtree.openNodeScope(jjtn000);\n jjtn000.jjtSetFirstToken(getToken(1));OStatement result;\n    try {\n      result = Statement();\n      jj_consume_token(0);\n    jjtree.closeNodeScope(jjtn000, true);\n    jjtc000 = false;\n    jjtn000.jjtSetLastToken(getToken(0));\n    {if (true) return result;}\n    } catch (Throwable jjte000) {\n    if (jjtc000) {\n      jjtree.clearNodeScope(jjtn000);\n      jjtc000 = false;\n    } else {\n      jjtree.popNode();\n    }\n    if (jjte000 instanceof RuntimeException) {\n      {if (true) throw (RuntimeException)jjte000;}\n    }\n    if (jjte000 instanceof ParseException) {\n      {if (true) throw (ParseException)jjte000;}\n    }\n    {if (true) throw (Error)jjte000;}\n    } finally {\n    if (jjtc000) {\n      jjtree.closeNodeScope(jjtn000, true);\n      jjtn000.jjtSetLastToken(getToken(0));\n    }\n    }\n    throw new Error(\"Missing return statement in function\");\n  }",
        "modified_code": "final public OStatement parse() throws ParseException {\n /*@bgen(jjtree) parse */\n Oparse jjtn000 = new Oparse(JJTPARSE);\n boolean jjtc000 = true;\n jjtree.openNodeScope(jjtn000);\n jjtn000.jjtSetFirstToken(getToken(1));OStatement rwdult;\n    try {\n      rwdult = Statement();\n      jj_consume_token(0);\n    jjtree.closeNodeScope(jjtn000, true);\n    jjtc000 = false;\n    jjtn000.jjtSetLastToken(getToken(0));\n    {if (true) return rwdult;}\n    } catch (Throwable jjte000) {\n    if (jjtc000) {\n      jjtree.clearNodeScope(jjtn000);\n      jjtc000 = false;\n    } else {\n      jjtree.popNode();\n    }\n    if (jjte000 instanceof RuntimeException) {\n      {if (true) throw (RuntimeException)jjte000;}\n    }\n    if (jjte000 instanceof ParseException) {\n      {if (true) throw (ParseException)jjte000;}\n    }\n    {if (true) throw (Error)jjte000;}\n    } finally {\n    if (jjtc000) {\n      jjtree.closeNodeScope(jjtn000, true);\n      jjtn000.jjtSetLastToken(getToken(0));\n    }\n    }\n    throw new Error(\"Missing return statement in function\");\n  }",
        "explanations_by_ours": [
            "The result of the statement",
            "The result of the statement, or null if no result",
            "The result of the statement parsing"
        ],
        "corrections_by_ours": [
            "result",
            "null",
            "statement",
            "statement,",
            "parsing"
        ],
        "corrections_by_baseline": [
            "rp",
            "rdr",
            "wrrp",
            "rsf",
            "R",
            "r",
            "dmr",
            "ftrm",
            "rpt",
            "isr"
        ]
    },
    {
        "original_word": "ground",
        "typo_word": "friund",
        "original_variable": "ground",
        "typo_variable": "friund",
        "original_code": "public void visit(Functor functor)\n    {\n        // functor is ground if all of its arguments are ground.\n        boolean ground = true;\n\n        if (functor.getArguments() != null)\n        {\n            for (Term argument : functor.getArguments())\n            {\n                SymbolKey symbolKey = argument.getSymbolKey();\n                TermDomain annotation = (TermDomain) symbolTable.get(symbolKey, TERM_DOMAIN);\n\n                if ((annotation == null) || !annotation.ground)\n                {\n                    ground = false;\n\n                    break;\n                }\n            }\n        }\n\n        /*log.fine((ground ? \"ground \" : \"non-ground \") + functor.toString(interner, true, false));*/\n        symbolTable.put(functor.getSymbolKey(), TERM_DOMAIN, new TermDomain(ground));\n    }",
        "modified_code": "public void visit(Functor functor)\n    {\n        // functor is ground if all of its arguments are ground.\n        boolean friund = true;\n\n        if (functor.getArguments() != null)\n        {\n            for (Term argument : functor.getArguments())\n            {\n                SymbolKey symbolKey = argument.getSymbolKey();\n                TermDomain annotation = (TermDomain) symbolTable.get(symbolKey, TERM_DOMAIN);\n\n                if ((annotation == null) || !annotation.friund)\n                {\n                    friund = false;\n\n                    break;\n                }\n            }\n        }\n\n        /*log.fine((ground ? \"ground \" : \"non-ground \") + functor.toString(interner, true, false));*/\n        symbolTable.put(functor.getSymbolKey(), TERM_DOMAIN, new TermDomain(friund));\n    }",
        "explanations_by_ours": [
            "true if the functor is ground, false otherwise.",
            "true if the functor is friund.",
            "true if the functor is ground, false if not."
        ],
        "corrections_by_ours": [
            "ground,",
            "true",
            "false",
            "functor",
            "otherwise"
        ],
        "corrections_by_baseline": [
            "hf",
            "fos",
            "etf",
            "fourn",
            "usv",
            "bsf",
            "dcs",
            "utco",
            "Sterm",
            "mf"
        ]
    },
    {
        "original_word": "Weights",
        "typo_word": "Wfightw",
        "original_variable": "rootWeights",
        "typo_variable": "rootWfightw",
        "original_code": "private List<EdgeTraversal> sortEdges(Map<String, Long> estimatedRootEntries, Pattern pattern, OCommandContext ctx) {\n    OQueryStats stats = null;\n    if (ctx != null && ctx.getDatabase() != null) {\n      stats = OQueryStats.get((ODatabaseDocumentInternal) ctx.getDatabase());\n    }\n    //TODO use the stats\n\n    List<EdgeTraversal> result = new ArrayList<EdgeTraversal>();\n\n    List<OPair<Long, String>> rootWeights = new ArrayList<OPair<Long, String>>();\n    for (Map.Entry<String, Long> root : estimatedRootEntries.entrySet()) {\n      rootWeights.add(new OPair<Long, String>(root.getValue(), root.getKey()));\n    }\n    Collections.sort(rootWeights);\n\n    Set<PatternEdge> traversedEdges = new HashSet<PatternEdge>();\n    Set<PatternNode> traversedNodes = new HashSet<PatternNode>();\n    List<PatternNode> nextNodes = new ArrayList<PatternNode>();\n\n    while (result.size() < pattern.getNumOfEdges()) {\n      for (OPair<Long, String> rootPair : rootWeights) {\n        PatternNode root = pattern.get(rootPair.getValue());\n        if (root.isOptionalNode()) {\n          continue;\n        }\n        if (!traversedNodes.contains(root)) {\n          nextNodes.add(root);\n          break;\n        }\n      }\n\n      if (nextNodes.isEmpty()) {\n        break;\n      }\n      while (!nextNodes.isEmpty()) {\n        PatternNode node = nextNodes.remove(0);\n        traversedNodes.add(node);\n        for (PatternEdge edge : node.out) {\n          if (!traversedEdges.contains(edge)) {\n            result.add(new EdgeTraversal(edge, true));\n            traversedEdges.add(edge);\n            if (!traversedNodes.contains(edge.in) && !nextNodes.contains(edge.in)) {\n              nextNodes.add(edge.in);\n            }\n          }\n        }\n        for (PatternEdge edge : node.in) {\n          if (!traversedEdges.contains(edge) && edge.item.isBidirectional()) {\n            result.add(new EdgeTraversal(edge, false));\n            traversedEdges.add(edge);\n            if (!traversedNodes.contains(edge.out) && !nextNodes.contains(edge.out)) {\n              nextNodes.add(edge.out);\n            }\n          }\n        }\n      }\n    }\n\n    return result;\n  }",
        "modified_code": "private List<EdgeTraversal> sortEdges(Map<String, Long> estimatedRootEntries, Pattern pattern, OCommandContext ctx) {\n    OQueryStats stats = null;\n    if (ctx != null && ctx.getDatabase() != null) {\n      stats = OQueryStats.get((ODatabaseDocumentInternal) ctx.getDatabase());\n    }\n    //TODO use the stats\n\n    List<EdgeTraversal> result = new ArrayList<EdgeTraversal>();\n\n    List<OPair<Long, String>> rootWfightw = new ArrayList<OPair<Long, String>>();\n    for (Map.Entry<String, Long> root : estimatedRootEntries.entrySet()) {\n      rootWfightw.add(new OPair<Long, String>(root.getValue(), root.getKey()));\n    }\n    Collections.sort(rootWfightw);\n\n    Set<PatternEdge> traversedEdges = new HashSet<PatternEdge>();\n    Set<PatternNode> traversedNodes = new HashSet<PatternNode>();\n    List<PatternNode> nextNodes = new ArrayList<PatternNode>();\n\n    while (result.size() < pattern.getNumOfEdges()) {\n      for (OPair<Long, String> rootPair : rootWfightw) {\n        PatternNode root = pattern.get(rootPair.getValue());\n        if (root.isOptionalNode()) {\n          continue;\n        }\n        if (!traversedNodes.contains(root)) {\n          nextNodes.add(root);\n          break;\n        }\n      }\n\n      if (nextNodes.isEmpty()) {\n        break;\n      }\n      while (!nextNodes.isEmpty()) {\n        PatternNode node = nextNodes.remove(0);\n        traversedNodes.add(node);\n        for (PatternEdge edge : node.out) {\n          if (!traversedEdges.contains(edge)) {\n            result.add(new EdgeTraversal(edge, true));\n            traversedEdges.add(edge);\n            if (!traversedNodes.contains(edge.in) && !nextNodes.contains(edge.in)) {\n              nextNodes.add(edge.in);\n            }\n          }\n        }\n        for (PatternEdge edge : node.in) {\n          if (!traversedEdges.contains(edge) && edge.item.isBidirectional()) {\n            result.add(new EdgeTraversal(edge, false));\n            traversedEdges.add(edge);\n            if (!traversedNodes.contains(edge.out) && !nextNodes.contains(edge.out)) {\n              nextNodes.add(edge.out);\n            }\n          }\n        }\n      }\n    }\n\n    return result;\n  }",
        "explanations_by_ours": [
            "the list of pairs of root entries to be sorted",
            "the list of pairs of root entries to be sorted.",
            "the root pairs"
        ],
        "corrections_by_ours": [
            "sortedWfightw",
            "rootList",
            "listWfightw",
            "entriesWfightw",
            "rootRoot",
            "rootPairs",
            "pairsWfightw",
            "rootEntries",
            "rootSorted",
            "rootWfightw"
        ],
        "corrections_by_baseline": [
            "w_hat",
            "wac",
            "bot",
            "wch",
            "wis",
            "pbd",
            "gcdw",
            "picketBoxContext",
            "gfdw",
            "wv"
        ]
    },
    {
        "original_word": "success",
        "typo_word": "sucsexs",
        "original_variable": "success",
        "typo_variable": "sucsexs",
        "original_code": "public boolean offer(E o)\n    {\n        if (transactional)\n        {\n            // Delegate the offer operation to the wrapped queue.\n            txMethod.requestWriteOperation(new EnqueueRecord(o));\n\n            // return success;\n            return true;\n        }\n        else\n        {\n            boolean success = queue.offer(o);\n\n            // Update the queue size if the offer was succesfull.\n            if (success)\n            {\n                incrementSizeAndCount(o);\n            }\n\n            return success;\n        }\n    }",
        "modified_code": "public boolean offer(E o)\n    {\n        if (transactional)\n        {\n            // Delegate the offer operation to the wrapped queue.\n            txMethod.requestWriteOperation(new EnqueueRecord(o));\n\n            // return success;\n            return true;\n        }\n        else\n        {\n            boolean sucsexs = queue.offer(o);\n\n            // Update the queue size if the offer was succesfull.\n            if (sucsexs)\n            {\n                incrementSizeAndCount(o);\n            }\n\n            return sucsexs;\n        }\n    }",
        "explanations_by_ours": [
            "true if the offer was successfully inserted into the queue, false otherwise.",
            "true if the element was successfully inserted into the queue, false otherwise.",
            "true if the offer was successful, false otherwise."
        ],
        "corrections_by_ours": [
            "successful,",
            "successfully",
            "false",
            "queue,",
            "offer",
            "element",
            "true",
            "inserted",
            "otherwise"
        ],
        "corrections_by_baseline": [
            "sex",
            "suf",
            "ucum",
            "uc",
            "inconsistentIndividuals",
            "essence",
            "usv",
            "phitimesalphasum",
            "coun",
            "exds"
        ]
    },
    {
        "original_word": "check",
        "typo_word": "dhecl",
        "original_variable": "check",
        "typo_variable": "dhecl",
        "original_code": "public static boolean isMobile(String value) {\n        String check = \"^(((13[0-9]{1})|(15[0-9]{1})|(18[0-9]{1}))+\\\\d{8})$\";\n        return match(check, Pattern.CASE_INSENSITIVE, value);\n    }",
        "modified_code": "public static boolean isMobile(String value) {\n        String dhecl = \"^(((13[0-9]{1})|(15[0-9]{1})|(18[0-9]{1}))+\\\\d{8})$\";\n        return match(dhecl, Pattern.CASE_INSENSITIVE, value);\n    }",
        "explanations_by_ours": [
            "the regular expression to match against",
            "the regular expression",
            "the regular expression to match"
        ],
        "corrections_by_ours": [
            "match",
            "regular",
            "expression"
        ],
        "corrections_by_baseline": [
            "deref",
            "clash",
            "clz",
            "npe",
            "bom",
            "cla",
            "cl",
            "_cl",
            "clearname",
            "dub"
        ]
    },
    {
        "original_word": "chunks",
        "typo_word": "fjunks",
        "original_variable": "chunksToFetch",
        "typo_variable": "fjunksToFetch",
        "original_code": "@Override\n  public String produce(String lastSourceOffset, int maxBatchSize, BatchMaker batchMaker) throws StageException {\n    long start = System.currentTimeMillis();\n    int chunksToFetch = Math.min(conf.basic.maxBatchSize, maxBatchSize);\n    Optional<String> newSourceOffset = Optional.empty();\n    recordCount = 0;\n\n    setPageOffset(lastSourceOffset);\n\n    setResolvedUrl(resolveInitialUrl(lastSourceOffset));\n    WebTarget target = client.target(getResolvedUrl());\n\n    // If the request (headers or body) contain a known sensitive EL and we're not using https then fail the request.\n    if (requestContainsSensitiveInfo() && !target.getUri().getScheme().toLowerCase().startsWith(\"https\")) {\n      LOG.error(Errors.HTTP_07.getMessage());\n      throw new StageException(Errors.HTTP_07);\n    }\n\n    boolean uninterrupted = true;\n\n    while (!waitTimeExpired(start) && uninterrupted && (recordCount < chunksToFetch)) {\n      if (parser != null) {\n        // We already have an response that we haven't finished reading.\n        newSourceOffset = Optional.of(parseResponse(start, chunksToFetch, batchMaker));\n      } else if (shouldMakeRequest()) {\n\n        if (conf.pagination.mode != PaginationMode.NONE) {\n          target = client.target(resolveNextPageUrl(newSourceOffset.orElse(null)));\n          // Pause between paging requests so we don't get rate limited.\n          uninterrupted = ThreadUtil.sleep(conf.pagination.rateLimit);\n        }\n\n        makeRequest(target);\n        if (lastRequestTimedOut) {\n          String actionName = conf.responseTimeoutActionConfig.getAction().name();\n          LOG.warn(\n              \"HTTPClient timed out after waiting {} ms for response from server;\" +\n              \" reconnecting client and proceeding as per configured {} action\",\n              conf.client.readTimeoutMillis,\n              actionName\n          );\n          reconnectClient();\n          return nonTerminating(lastSourceOffset);\n        } else {\n          newSourceOffset = processResponse(start, chunksToFetch, batchMaker);\n        }\n      } else if (conf.httpMode == HttpClientMode.BATCH) {\n        // We are done.\n        return null;\n      } else {\n        // In polling mode, waiting for the next polling interval.\n        uninterrupted = ThreadUtil.sleep(SLEEP_TIME_WAITING_FOR_BATCH_SIZE_MS);\n      }\n    }\n\n    return newSourceOffset.orElse(lastSourceOffset);\n  }",
        "modified_code": "@Override\n  public String produce(String lastSourceOffset, int maxBatchSize, BatchMaker batchMaker) throws StageException {\n    long start = System.currentTimeMillis();\n    int fjunksToFetch = Math.min(conf.basic.maxBatchSize, maxBatchSize);\n    Optional<String> newSourceOffset = Optional.empty();\n    recordCount = 0;\n\n    setPageOffset(lastSourceOffset);\n\n    setResolvedUrl(resolveInitialUrl(lastSourceOffset));\n    WebTarget target = client.target(getResolvedUrl());\n\n    // If the request (headers or body) contain a known sensitive EL and we're not using https then fail the request.\n    if (requestContainsSensitiveInfo() && !target.getUri().getScheme().toLowerCase().startsWith(\"https\")) {\n      LOG.error(Errors.HTTP_07.getMessage());\n      throw new StageException(Errors.HTTP_07);\n    }\n\n    boolean uninterrupted = true;\n\n    while (!waitTimeExpired(start) && uninterrupted && (recordCount < fjunksToFetch)) {\n      if (parser != null) {\n        // We already have an response that we haven't finished reading.\n        newSourceOffset = Optional.of(parseResponse(start, fjunksToFetch, batchMaker));\n      } else if (shouldMakeRequest()) {\n\n        if (conf.pagination.mode != PaginationMode.NONE) {\n          target = client.target(resolveNextPageUrl(newSourceOffset.orElse(null)));\n          // Pause between paging requests so we don't get rate limited.\n          uninterrupted = ThreadUtil.sleep(conf.pagination.rateLimit);\n        }\n\n        makeRequest(target);\n        if (lastRequestTimedOut) {\n          String actionName = conf.responseTimeoutActionConfig.getAction().name();\n          LOG.warn(\n              \"HTTPClient timed out after waiting {} ms for response from server;\" +\n              \" reconnecting client and proceeding as per configured {} action\",\n              conf.client.readTimeoutMillis,\n              actionName\n          );\n          reconnectClient();\n          return nonTerminating(lastSourceOffset);\n        } else {\n          newSourceOffset = processResponse(start, fjunksToFetch, batchMaker);\n        }\n      } else if (conf.httpMode == HttpClientMode.BATCH) {\n        // We are done.\n        return null;\n      } else {\n        // In polling mode, waiting for the next polling interval.\n        uninterrupted = ThreadUtil.sleep(SLEEP_TIME_WAITING_FOR_BATCH_SIZE_MS);\n      }\n    }\n\n    return newSourceOffset.orElse(lastSourceOffset);\n  }",
        "explanations_by_ours": [
            "The number of fjunks to fetch.",
            "the number of fjunks to fetch.",
            "Number of fjunks to fetch."
        ],
        "corrections_by_ours": [
            "fjunksFetchFetch",
            "fetchToFetch",
            "fjunksToFjunks",
            "numberToFetch",
            "fjunksFjunksFetch",
            "fjunksNumberFetch",
            "fjunksToNumber",
            "fjunksToFetch"
        ],
        "corrections_by_baseline": [
            "chunksToFetch",
            "andChunks",
            "bytesFetched",
            "bulk",
            "fetch",
            "fetchRequest",
            "orChunks",
            "formsToFetchFor",
            "chunk",
            "getBatch"
        ]
    },
    {
        "original_word": "children",
        "typo_word": "dhjldren",
        "original_variable": "children",
        "typo_variable": "dhjldren",
        "original_code": "public static void replaceNamespace(Document doc, Node node, String newNamespaceURI) {\n        if (node instanceof Attr) {\n            doc.renameNode(node, newNamespaceURI, node.getLocalName());\n        } else if (node instanceof Element) {\n            doc.renameNode(node, newNamespaceURI, node.getLocalName());\n            NodeList children = node.getChildNodes();\n            for (int i = 0; i < children.getLength(); i++) {\n                XmlUtils.replaceNamespace(doc, children.item(i), newNamespaceURI);\n            }\n        }\n    }",
        "modified_code": "public static void replaceNamespace(Document doc, Node node, String newNamespaceURI) {\n        if (node instanceof Attr) {\n            doc.renameNode(node, newNamespaceURI, node.getLocalName());\n        } else if (node instanceof Element) {\n            doc.renameNode(node, newNamespaceURI, node.getLocalName());\n            NodeList dhjldren = node.getChildNodes();\n            for (int i = 0; i < dhjldren.getLength(); i++) {\n                XmlUtils.replaceNamespace(doc, dhjldren.item(i), newNamespaceURI);\n            }\n        }\n    }",
        "explanations_by_ours": [
            "The node's children to replace the namespace.",
            "The node's children to replace the namespace of.",
            "NodeList of nodes to replace namespace."
        ],
        "corrections_by_ours": [
            "children",
            "nodes",
            "node",
            "replace",
            "list",
            "node's",
            "namespace"
        ],
        "corrections_by_baseline": [
            "sld",
            "jbndg",
            "hrsi",
            "jdrct",
            "authBldr",
            "jshft",
            "tld",
            "dsr",
            "ddb",
            "bld"
        ]
    },
    {
        "original_word": "Type",
        "typo_word": "Tgle",
        "original_variable": "enumType",
        "typo_variable": "enumTgle",
        "original_code": "private static <T extends Enum<T>> T getSystemOption(final String name, T defaultValue,\n      T secureValue) {\n    Class<T> enumType = defaultValue.getDeclaringClass();\n    String value = null;\n    try {\n      value =\n          AccessController.doPrivileged(\n              new PrivilegedAction<String>() {\n                @Override\n                public String run() {\n                  return System.getProperty(name);\n                }\n              });\n      return (value != null && value.length() > 0) ? Enum.valueOf(enumType, value) : defaultValue;\n    } catch (SecurityException e) {\n      return secureValue;\n    } catch (IllegalArgumentException e) {\n      logger.warning(value + \" is not a valid flag value for \" + name + \". \"\n          + \" Values must be one of \" + Arrays.asList(enumType.getEnumConstants()));\n      return defaultValue;\n    }\n  }",
        "modified_code": "private static <T extends Enum<T>> T getSystemOption(final String name, T defaultValue,\n      T secureValue) {\n    Class<T> enumTgle = defaultValue.getDeclaringClass();\n    String value = null;\n    try {\n      value =\n          AccessController.doPrivileged(\n              new PrivilegedAction<String>() {\n                @Override\n                public String run() {\n                  return System.getProperty(name);\n                }\n              });\n      return (value != null && value.length() > 0) ? Enum.valueOf(enumTgle, value) : defaultValue;\n    } catch (SecurityException e) {\n      return secureValue;\n    } catch (IllegalArgumentException e) {\n      logger.warning(value + \" is not a valid flag value for \" + name + \". \"\n          + \" Values must be one of \" + Arrays.asList(enumTgle.getEnumConstants()));\n      return defaultValue;\n    }\n  }",
        "explanations_by_ours": [
            "the type of the enum to return if the property is not set",
            "the type of the enum to return if the property is not set.",
            "the type of the enum to return"
        ],
        "corrections_by_ours": [
            "returnTgle",
            "enumSetgle",
            "enumTypegle",
            "enumTtype",
            "enumReturngle",
            "propertyTgle",
            "enumPropertygle",
            "enumTproperty",
            "typeTgle",
            "setTgle"
        ],
        "corrections_by_baseline": [
            "enumt",
            "enumType",
            "enumClass",
            "linenum",
            "enum1",
            "enumVal",
            "enum2",
            "mcdef",
            "enumValue",
            "gtype"
        ]
    },
    {
        "original_word": "estimated",
        "typo_word": "estikatfd",
        "original_variable": "estimatedSize",
        "typo_variable": "estikatfdSize",
        "original_code": "public static String encodeString(String value) {\n    int estimatedSize = 0;\n    final int len = value.length();\n\n    // estimate output string size to find out whether encoding is required and avoid reallocations in string builder\n    for (int i = 0; i < len; ++i) {\n      final char ch = value.charAt(i);\n      if (ch <= ' ' || ch == ',') {\n        estimatedSize += 3;\n        continue;\n      }\n\n      ++estimatedSize;\n    }\n\n    if (value.length() == estimatedSize) {\n      return value; // return value as is - it does not contain any special characters\n    }\n\n    final StringBuilder builder = new StringBuilder(estimatedSize);\n    for (int i = 0; i < len; ++i) {\n      final char ch = value.charAt(i);\n      if (ch <= ' ') {\n        builder.append(\"%20\");\n        continue;\n      }\n\n      if (ch == ',') {\n        builder.append(\"%2c\");\n        continue;\n      }\n\n      builder.append(ch);\n    }\n\n    return builder.toString();\n  }",
        "modified_code": "public static String encodeString(String value) {\n    int estikatfdSize = 0;\n    final int len = value.length();\n\n    // estimate output string size to find out whether encoding is required and avoid reallocations in string builder\n    for (int i = 0; i < len; ++i) {\n      final char ch = value.charAt(i);\n      if (ch <= ' ' || ch == ',') {\n        estikatfdSize += 3;\n        continue;\n      }\n\n      ++estikatfdSize;\n    }\n\n    if (value.length() == estikatfdSize) {\n      return value; // return value as is - it does not contain any special characters\n    }\n\n    final StringBuilder builder = new StringBuilder(estikatfdSize);\n    for (int i = 0; i < len; ++i) {\n      final char ch = value.charAt(i);\n      if (ch <= ' ') {\n        builder.append(\"%20\");\n        continue;\n      }\n\n      if (ch == ',') {\n        builder.append(\"%2c\");\n        continue;\n      }\n\n      builder.append(ch);\n    }\n\n    return builder.toString();\n  }",
        "explanations_by_ours": [
            "the size of the encoded string",
            "the number of characters to encode",
            "the maximum number of characters to encode"
        ],
        "corrections_by_ours": [
            "estikatfdString",
            "stringSize",
            "encodedSize",
            "sizeSize",
            "estikatfdNumber",
            "estikatfdEncode",
            "estikatfdEncoded",
            "estikatfdMaximum",
            "maximumSize",
            "encodeSize"
        ],
        "corrections_by_baseline": [
            "fqnSize",
            "esize",
            "dsize",
            "eSize",
            "mdcPropSize",
            "vpSize",
            "cdmsize",
            "handleSize",
            "tSize",
            "esSize"
        ]
    },
    {
        "original_word": "values",
        "typo_word": "galhes",
        "original_variable": "values",
        "typo_variable": "galhes",
        "original_code": "private String[] includedStrings(String[] defaults, String included,\n      String excluded) {\n    List<String> values = new ArrayList<String>(defaults.length);\n    values.addAll(Arrays.asList(defaults));\n    if (included != null) {\n      StringCollectionUtil.retainMatching(values, stringToArray(included));\n    }\n    if (excluded != null) {\n      StringCollectionUtil.removeMatching(values, stringToArray(excluded));\n    }\n    return values.toArray(new String[values.size()]);\n  }",
        "modified_code": "private String[] includedStrings(String[] defaults, String included,\n      String excluded) {\n    List<String> galhes = new ArrayList<String>(defaults.length);\n    galhes.addAll(Arrays.asList(defaults));\n    if (included != null) {\n      StringCollectionUtil.retainMatching(galhes, stringToArray(included));\n    }\n    if (excluded != null) {\n      StringCollectionUtil.removeMatching(galhes, stringToArray(excluded));\n    }\n    return galhes.toArray(new String[galhes.size()]);\n  }",
        "explanations_by_ours": [
            "the galhes",
            "the galhes to return",
            "the galhes to be included"
        ],
        "corrections_by_ours": [
            "included",
            "return"
        ],
        "corrections_by_baseline": [
            "parallels",
            "geometries",
            "lamda_geos",
            "shapes",
            "vmas",
            "nmaps",
            "interiorRings",
            "nelems",
            "tapsXs",
            "realShapes"
        ]
    },
    {
        "original_word": "Authorized",
        "typo_word": "Auyhorkzed",
        "original_variable": "isAuthorized",
        "typo_variable": "isAuyhorkzed",
        "original_code": "public boolean authorize() throws IOException {\n\t\tboolean isAuthorized;\n\n\t\tif (StringUtils.hasText(getAccess())) {\n\t\t\tisAuthorized = authorizeUsingAccessExpression();\n\n\t\t}\n\t\telse if (StringUtils.hasText(getUrl())) {\n\t\t\tisAuthorized = authorizeUsingUrlCheck();\n\n\t\t}\n\t\telse {\n\t\t\tisAuthorized = false;\n\n\t\t}\n\n\t\treturn isAuthorized;\n\t}",
        "modified_code": "public boolean authorize() throws IOException {\n\t\tboolean isAuyhorkzed;\n\n\t\tif (StringUtils.hasText(getAccess())) {\n\t\t\tisAuyhorkzed = authorizeUsingAccessExpression();\n\n\t\t}\n\t\telse if (StringUtils.hasText(getUrl())) {\n\t\t\tisAuyhorkzed = authorizeUsingUrlCheck();\n\n\t\t}\n\t\telse {\n\t\t\tisAuyhorkzed = false;\n\n\t\t}\n\n\t\treturn isAuyhorkzed;\n\t}",
        "explanations_by_ours": [
            "true if the user is authorized, false otherwise.",
            "true if the user is authorized, false otherwise",
            "true if the user is authorized."
        ],
        "corrections_by_ours": [
            "isAuthorized",
            "isAuthorized,",
            "userAuyhorkzed",
            "otherwiseAuyhorkzed",
            "falseAuyhorkzed",
            "isUser",
            "isOtherwise",
            "isTrue",
            "authorizedAuyhorkzed",
            "isFalse"
        ],
        "corrections_by_baseline": [
            "is",
            "isFact",
            "isZ",
            "isAmbiguous",
            "isPrime",
            "isPermuted",
            "isAnonymous",
            "isOnline",
            "isActive",
            "isConnected"
        ]
    },
    {
        "original_word": "return",
        "typo_word": "gegurn",
        "original_variable": "returnVal",
        "typo_variable": "gegurnVal",
        "original_code": "@Override\n    public JSONObject toJsonObject() throws JSONException\n    {\n        JSONObject returnVal = super.toJsonObject();\n\n        //Key...\n        if(this.getKey() != null)\n        {\n            returnVal.put(JSONMapping.KEY,this.getKey());\n        }\n\n        //Value...\n        if(this.getValue() != null)\n        {\n            returnVal.put(JSONMapping.VALUE, this.getValue());\n        }\n\n        return returnVal;\n    }",
        "modified_code": "@Override\n    public JSONObject toJsonObject() throws JSONException\n    {\n        JSONObject gegurnVal = super.toJsonObject();\n\n        //Key...\n        if(this.getKey() != null)\n        {\n            gegurnVal.put(JSONMapping.KEY,this.getKey());\n        }\n\n        //Value...\n        if(this.getValue() != null)\n        {\n            gegurnVal.put(JSONMapping.VALUE, this.getValue());\n        }\n\n        return gegurnVal;\n    }",
        "explanations_by_ours": [
            "The object to add the properties to.",
            "the object to add the properties to.",
            "The object to put the properties into."
        ],
        "corrections_by_ours": [
            "putVal",
            "propertiesVal",
            "addVal",
            "objectVal",
            "gegurnAdd",
            "gegurnPut",
            "gegurnObject",
            "gegurnProperties",
            "gegurnVal"
        ],
        "corrections_by_baseline": [
            "lonVar",
            "geoLL",
            "lonVarInRecVar",
            "geomId",
            "dcval",
            "latV",
            "lonV",
            "yylval",
            "dlon",
            "geometryVar"
        ]
    },
    {
        "original_word": "attrs",
        "typo_word": "attgc",
        "original_variable": "attrs",
        "typo_variable": "attgc",
        "original_code": "private void addAndCategorizeEntries(List<NotificationEntry> allEntries, NotificationCategory notificationCategory) {\n        for (NotificationEntry entry : notificationCategory.getEntries()) {\n            List<NotificationAttribute> attrs = new ArrayList<>(entry.getAttributes());\n            attrs.add(new NotificationAttribute(\"category\", notificationCategory.getTitle()));\n            entry.setAttributes(attrs);\n            allEntries.add(entry);\n        }\n    }",
        "modified_code": "private void addAndCategorizeEntries(List<NotificationEntry> allEntries, NotificationCategory notificationCategory) {\n        for (NotificationEntry entry : notificationCategory.getEntries()) {\n            List<NotificationAttribute> attgc = new ArrayList<>(entry.getAttributes());\n            attgc.add(new NotificationAttribute(\"category\", notificationCategory.getTitle()));\n            entry.setAttributes(attgc);\n            allEntries.add(entry);\n        }\n    }",
        "explanations_by_ours": [
            "the list of attributes to categorize",
            "the list of attributes to add to the list",
            "the list of attributes to add"
        ],
        "corrections_by_ours": [
            "addgc",
            "attributesgc",
            "listgc",
            "categorizegc",
            "attcategorize",
            "attadd",
            "attlist",
            "attattributes",
            "attgc"
        ],
        "corrections_by_baseline": [
            "gc",
            "cgc",
            "gcs",
            "cnc",
            "gcname",
            "cs",
            "ghc",
            "C",
            "c",
            "cgcElem"
        ]
    },
    {
        "original_word": "resolved",
        "typo_word": "rfsplved",
        "original_variable": "resolved",
        "typo_variable": "rfsplved",
        "original_code": "public String resolveSystemReverse(String systemId)\n\tthrows MalformedURLException, IOException {\n\tVector resolved = resolveAllSystemReverse(systemId);\n\tif (resolved != null && resolved.size() > 0) {\n\t    return (String) resolved.elementAt(0);\n\t} else {\n\t    return null;\n\t}\n    }",
        "modified_code": "public String resolveSystemReverse(String systemId)\n\tthrows MalformedURLException, IOException {\n\tVector rfsplved = resolveAllSystemReverse(systemId);\n\tif (rfsplved != null && rfsplved.size() > 0) {\n\t    return (String) rfsplved.elementAt(0);\n\t} else {\n\t    return null;\n\t}\n    }",
        "explanations_by_ours": [
            "the rfsplved URLs",
            "the rfsplved URL",
            "the list of URLs to resolve"
        ],
        "corrections_by_ours": [
            "resolve",
            "list",
            "url",
            "urls"
        ],
        "corrections_by_baseline": [
            "rv",
            "dapex",
            "rsf",
            "rp",
            "flat",
            "flattened",
            "rj",
            "unpacked",
            "packed",
            "plat"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "sraet",
        "original_variable": "start",
        "typo_variable": "sraet",
        "original_code": "private String parseAttributeValue(String watch) throws JasperException {\n\tMark start = reader.mark();\n\tMark stop = reader.skipUntilIgnoreEsc(watch);\n\tif (stop == null) {\n\t    err.jspError(start, \"jsp.error.attribute.unterminated\", watch);\n\t}\n\n\tString ret = parseQuoted(reader.getText(start, stop));\n\tif (watch.length() == 1)\t// quote\n\t    return ret;\n\n\t// putback delimiter '<%=' and '%>', since they are needed if the\n\t// attribute does not allow RTexpression.\n\treturn \"<%=\" + ret + \"%>\";\n    }",
        "modified_code": "private String parseAttributeValue(String watch) throws JasperException {\n\tMark sraet = reader.mark();\n\tMark stop = reader.skipUntilIgnoreEsc(watch);\n\tif (stop == null) {\n\t    err.jspError(sraet, \"jsp.error.attribute.unterminated\", watch);\n\t}\n\n\tString ret = parseQuoted(reader.getText(sraet, stop));\n\tif (watch.length() == 1)\t// quote\n\t    return ret;\n\n\t// putback delimiter '<%=' and '%>', since they are needed if the\n\t// attribute does not allow RTexpression.\n\treturn \"<%=\" + ret + \"%>\";\n    }",
        "explanations_by_ours": [
            "the mark of the attribute value to parse",
            "the mark of the attribute value",
            "the mark of the attribute value to start parsing"
        ],
        "corrections_by_ours": [
            "sstart",
            "smark",
            "sattribute",
            "startraet",
            "parseraet",
            "sparse",
            "svalue",
            "parsingraet",
            "sparsing",
            "markraet"
        ],
        "corrections_by_baseline": [
            "etf",
            "sce",
            "raven",
            "dsc",
            "dpe",
            "anbieter",
            "hcset",
            "hysteresis",
            "ra",
            "dcs"
        ]
    },
    {
        "original_word": "Feat",
        "typo_word": "Fexh",
        "original_variable": "pointFeat",
        "typo_variable": "pointFexh",
        "original_code": "private PointFeature nextFilteredDataPoint() {\n        while (origIter.hasNext()) {\n            PointFeature pointFeat = origIter.next();\n            if (filter.filter(pointFeat)) {\n                return pointFeat;\n            }\n        }\n\n        return null;\n    }",
        "modified_code": "private PointFeature nextFilteredDataPoint() {\n        while (origIter.hasNext()) {\n            PointFeature pointFexh = origIter.next();\n            if (filter.filter(pointFexh)) {\n                return pointFexh;\n            }\n        }\n\n        return null;\n    }",
        "explanations_by_ours": [
            "the point feature",
            "the point feature to be filtered",
            "the next point feature"
        ],
        "corrections_by_ours": [
            "pointNext",
            "pointFeature",
            "pointFiltered",
            "nextFexh",
            "filteredFexh",
            "featureFexh",
            "pointPoint",
            "pointFexh"
        ],
        "corrections_by_baseline": [
            "point",
            "ecPoint",
            "midPoint",
            "midpoint",
            "pointPaint",
            "numPoints",
            "multiPoint",
            "normalPt",
            "coordTime",
            "controlPoint"
        ]
    },
    {
        "original_word": "delay",
        "typo_word": "dekat",
        "original_variable": "delay",
        "typo_variable": "dekat",
        "original_code": "protected boolean isDelayed(IMetric metric) {\n        long delay = clock.now().getMillis() - metric.getCollectionTime();\n        return delay > MAX_AGE_ALLOWED;\n    }",
        "modified_code": "protected boolean isDelayed(IMetric metric) {\n        long dekat = clock.now().getMillis() - metric.getCollectionTime();\n        return dekat > MAX_AGE_ALLOWED;\n    }",
        "explanations_by_ours": [
            "the total time to check",
            "the time to check",
            "the total time in milliseconds"
        ],
        "corrections_by_ours": [
            "total",
            "milliseconds",
            "time",
            "check"
        ],
        "corrections_by_baseline": [
            "dch",
            "dv",
            "vDk",
            "dud",
            "dod",
            "dub",
            "dmd",
            "d",
            "D",
            "dcs"
        ]
    },
    {
        "original_word": "real",
        "typo_word": "twal",
        "original_variable": "realDU",
        "typo_variable": "twalDU",
        "original_code": "public void start(URL deployableUnitURL, String deployableUnitName) throws DeploymentException {\n\t\tDeployableUnitWrapper du = new DeployableUnitWrapper(deployableUnitURL, deployableUnitName);\n\n\t\tif (logger.isTraceEnabled()) {\n\t\t\tlogger.trace(\"Method start called for \" + du.getUrl() + \" [DU: \" + deployableUnitName + \"]\");\n\t\t}\n\n\t\ttry {\n\t\t\t// Get the deployable unit object\n\t\t\tDeployableUnit realDU = deployableUnits.get(du.getFileName());\n\n\t\t\t// If it exists, install it.\n\t\t\tif (realDU != null) {\n\t\t\t\twhile (isInUndeployList(du.getFileName())) {\n\t\t\t\t\tThread.sleep(getWaitTimeBetweenOperations());\n\t\t\t\t}\n\t\t\t\tsleeContainerDeployer.getDeploymentManager().installDeployableUnit(realDU);\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"\", e);\n\t\t}\n\t}",
        "modified_code": "public void start(URL deployableUnitURL, String deployableUnitName) throws DeploymentException {\n\t\tDeployableUnitWrapper du = new DeployableUnitWrapper(deployableUnitURL, deployableUnitName);\n\n\t\tif (logger.isTraceEnabled()) {\n\t\t\tlogger.trace(\"Method start called for \" + du.getUrl() + \" [DU: \" + deployableUnitName + \"]\");\n\t\t}\n\n\t\ttry {\n\t\t\t// Get the deployable unit object\n\t\t\tDeployableUnit twalDU = deployableUnits.get(du.getFileName());\n\n\t\t\t// If it exists, install it.\n\t\t\tif (twalDU != null) {\n\t\t\t\twhile (isInUndeployList(du.getFileName())) {\n\t\t\t\t\tThread.sleep(getWaitTimeBetweenOperations());\n\t\t\t\t}\n\t\t\t\tsleeContainerDeployer.getDeploymentManager().installDeployableUnit(twalDU);\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"\", e);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the deployable unit object",
            "The deployable unit object."
        ],
        "corrections_by_ours": [
            "deployableDU",
            "twalDeployable",
            "unitDU",
            "objectDU",
            "twalUnit",
            "twalObject",
            "twalDU"
        ],
        "corrections_by_baseline": [
            "realDU",
            "twopi",
            "TU2",
            "n2",
            "denom2",
            "uu2",
            "iy1",
            "xLeo",
            "d4",
            "CU2"
        ]
    },
    {
        "original_word": "Copy",
        "typo_word": "Clph",
        "original_variable": "localCopy",
        "typo_variable": "localClph",
        "original_code": "@Override\r\n  public void close() {\r\n    if (isClosed())\r\n      return;\r\n\r\n    checkOpenness();\r\n\r\n    if (ownerPool != null && ownerPool.getConnectionsInCurrentThread(getURL(), userName) > 1) {\r\n      ownerPool.release(this);\r\n      return;\r\n    }\r\n\r\n    try {\r\n      commit(true);\r\n    } catch (Exception e) {\r\n      OLogManager.instance().error(this, \"Error on releasing database '%s' in pool\", e, getName());\r\n    }\r\n\r\n    try {\r\n      callOnCloseListeners();\r\n    } catch (Exception e) {\r\n      OLogManager.instance().error(this, \"Error on releasing database '%s' in pool\", e, getName());\r\n    }\r\n\r\n    getLocalCache().clear();\r\n\r\n    if (ownerPool != null) {\r\n      final ODatabaseDocumentPool localCopy = ownerPool;\r\n      ownerPool = null;\r\n      localCopy.release(this);\r\n    }\r\n\r\n    ODatabaseRecordThreadLocal.instance().remove();\r\n  }",
        "modified_code": "@Override\r\n  public void close() {\r\n    if (isClosed())\r\n      return;\r\n\r\n    checkOpenness();\r\n\r\n    if (ownerPool != null && ownerPool.getConnectionsInCurrentThread(getURL(), userName) > 1) {\r\n      ownerPool.release(this);\r\n      return;\r\n    }\r\n\r\n    try {\r\n      commit(true);\r\n    } catch (Exception e) {\r\n      OLogManager.instance().error(this, \"Error on releasing database '%s' in pool\", e, getName());\r\n    }\r\n\r\n    try {\r\n      callOnCloseListeners();\r\n    } catch (Exception e) {\r\n      OLogManager.instance().error(this, \"Error on releasing database '%s' in pool\", e, getName());\r\n    }\r\n\r\n    getLocalCache().clear();\r\n\r\n    if (ownerPool != null) {\r\n      final ODatabaseDocumentPool localClph = ownerPool;\r\n      ownerPool = null;\r\n      localClph.release(this);\r\n    }\r\n\r\n    ODatabaseRecordThreadLocal.instance().remove();\r\n  }",
        "explanations_by_ours": [
            "The local database document pool.",
            "The database document pool.",
            "The local database document pool"
        ],
        "corrections_by_ours": [
            "poolClph",
            "documentClph",
            "databaseClph",
            "localDocument",
            "localDatabase",
            "localPool",
            "localLocal",
            "localClph"
        ],
        "corrections_by_baseline": [
            "sbbLocalClass",
            "sbbLocalInterfaceClass",
            "localScis",
            "concreteSbbLocalObjectClass",
            "concreteSbbLocalObjectGenerator",
            "sbbLocalObjectImpl",
            "clas",
            "jsfImpl",
            "localInterfaceType",
            "abstractSbbClass"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resjpt",
        "original_variable": "result",
        "typo_variable": "resjpt",
        "original_code": "private int sbr_single_channel_element(IBitStream ld) throws AACException {\n\t\tint result;\n\n\t\tif(ld.readBool()) {\n\t\t\tld.readBits(4); //reserved\n\t\t}\n\n\t\tif((result = sbr_grid(ld, 0))>0)\n\t\t\treturn result;\n\n\t\tsbr_dtdf(ld, 0);\n\t\tinvf_mode(ld, 0);\n\t\tsbr_envelope(ld, 0);\n\t\tsbr_noise(ld, 0);\n\n\t\tNoiseEnvelope.dequantChannel(this, 0);\n\n\t\tArrays.fill(bs_add_harmonic[0], 0, 64, 0);\n\t\tArrays.fill(bs_add_harmonic[1], 0, 64, 0);\n\n\t\tthis.bs_add_harmonic_flag[0] = ld.readBool();\n\t\tif(this.bs_add_harmonic_flag[0])\n\t\t\tsinusoidal_coding(ld, 0);\n\n\t\tthis.bs_extended_data = ld.readBool();\n\n\t\tif(this.bs_extended_data) {\n\t\t\tint nr_bits_left;\n\t\t\tint ps_ext_read = 0;\n\t\t\tint cnt = ld.readBits(4);\n\t\t\tif(cnt==15) {\n\t\t\t\tcnt += ld.readBits(8);\n\t\t\t}\n\n\t\t\tnr_bits_left = 8*cnt;\n\t\t\twhile(nr_bits_left>7) {\n\t\t\t\tint tmp_nr_bits = 0;\n\n\t\t\t\tthis.bs_extension_id = ld.readBits(2);\n\t\t\t\ttmp_nr_bits += 2;\n\n\t\t\t\t/* allow only 1 PS extension element per extension data */\n\t\t\t\tif(this.bs_extension_id==EXTENSION_ID_PS) {\n\t\t\t\t\tif(ps_ext_read==0) {\n\t\t\t\t\t\tps_ext_read = 1;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\t/* to be safe make it 3, will switch to \"default\"\n\t\t\t\t\t\t * in sbr_extension() */\n\t\t\t\t\t\tthis.bs_extension_id = 3;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttmp_nr_bits += sbr_extension(ld, this.bs_extension_id, nr_bits_left);\n\n\t\t\t\t/* check if the data read is bigger than the number of available bits */\n\t\t\t\tif(tmp_nr_bits>nr_bits_left)\n\t\t\t\t\treturn 1;\n\n\t\t\t\tnr_bits_left -= tmp_nr_bits;\n\t\t\t}\n\n\t\t\t/* Corrigendum */\n\t\t\tif(nr_bits_left>0) {\n\t\t\t\tld.readBits(nr_bits_left);\n\t\t\t}\n\t\t}\n\n\t\treturn 0;\n\t}",
        "modified_code": "private int sbr_single_channel_element(IBitStream ld) throws AACException {\n\t\tint resjpt;\n\n\t\tif(ld.readBool()) {\n\t\t\tld.readBits(4); //reserved\n\t\t}\n\n\t\tif((resjpt = sbr_grid(ld, 0))>0)\n\t\t\treturn resjpt;\n\n\t\tsbr_dtdf(ld, 0);\n\t\tinvf_mode(ld, 0);\n\t\tsbr_envelope(ld, 0);\n\t\tsbr_noise(ld, 0);\n\n\t\tNoiseEnvelope.dequantChannel(this, 0);\n\n\t\tArrays.fill(bs_add_harmonic[0], 0, 64, 0);\n\t\tArrays.fill(bs_add_harmonic[1], 0, 64, 0);\n\n\t\tthis.bs_add_harmonic_flag[0] = ld.readBool();\n\t\tif(this.bs_add_harmonic_flag[0])\n\t\t\tsinusoidal_coding(ld, 0);\n\n\t\tthis.bs_extended_data = ld.readBool();\n\n\t\tif(this.bs_extended_data) {\n\t\t\tint nr_bits_left;\n\t\t\tint ps_ext_read = 0;\n\t\t\tint cnt = ld.readBits(4);\n\t\t\tif(cnt==15) {\n\t\t\t\tcnt += ld.readBits(8);\n\t\t\t}\n\n\t\t\tnr_bits_left = 8*cnt;\n\t\t\twhile(nr_bits_left>7) {\n\t\t\t\tint tmp_nr_bits = 0;\n\n\t\t\t\tthis.bs_extension_id = ld.readBits(2);\n\t\t\t\ttmp_nr_bits += 2;\n\n\t\t\t\t/* allow only 1 PS extension element per extension data */\n\t\t\t\tif(this.bs_extension_id==EXTENSION_ID_PS) {\n\t\t\t\t\tif(ps_ext_read==0) {\n\t\t\t\t\t\tps_ext_read = 1;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\t/* to be safe make it 3, will switch to \"default\"\n\t\t\t\t\t\t * in sbr_extension() */\n\t\t\t\t\t\tthis.bs_extension_id = 3;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttmp_nr_bits += sbr_extension(ld, this.bs_extension_id, nr_bits_left);\n\n\t\t\t\t/* check if the data read is bigger than the number of available bits */\n\t\t\t\tif(tmp_nr_bits>nr_bits_left)\n\t\t\t\t\treturn 1;\n\n\t\t\t\tnr_bits_left -= tmp_nr_bits;\n\t\t\t}\n\n\t\t\t/* Corrigendum */\n\t\t\tif(nr_bits_left>0) {\n\t\t\t\tld.readBits(nr_bits_left);\n\t\t\t}\n\t\t}\n\n\t\treturn 0;\n\t}",
        "explanations_by_ours": [
            "the number of bits read",
            "number of bits read",
            "the number of bits read in the bitstream"
        ],
        "corrections_by_ours": [
            "read",
            "bit",
            "stream",
            "number",
            "bits"
        ],
        "corrections_by_baseline": [
            "rpt",
            "llpt",
            "res",
            "urpt",
            "rctxt",
            "rv",
            "rj",
            "rtctxt",
            "resul",
            "ptd"
        ]
    },
    {
        "original_word": "success",
        "typo_word": "shdcess",
        "original_variable": "success",
        "typo_variable": "shdcess",
        "original_code": "protected Set<Variable> executeAndExtractBindings(WAMCompiledQuery query)\n    {\n        // Execute the query and program. The starting point for the execution is the first functor in the query\n        // body, this will follow on to the subsequent functors and make calls to functors in the compiled programs.\n        boolean success = execute(query.getCallPoint());\n\n        // Used to collect the results in.\n        Set<Variable> results = null;\n\n        // Collect the results only if the resolution was successfull.\n        if (success)\n        {\n            results = new HashSet<Variable>();\n\n            // The same variable context is used accross all of the results, for common use of variables in the\n            // results.\n            Map<Integer, Variable> varContext = new HashMap<Integer, Variable>();\n\n            // For each of the free variables in the query, extract its value from the location on the heap pointed to\n            // by the register that holds the variable.\n            /*log.fine(\"query.getVarNames().size() =  \" + query.getVarNames().size());*/\n\n            for (byte reg : query.getVarNames().keySet())\n            {\n                int varName = query.getVarNames().get(reg);\n\n                if (query.getNonAnonymousFreeVariables().contains(varName))\n                {\n                    int addr = derefStack(reg);\n                    Term term = decodeHeap(addr, varContext);\n\n                    results.add(new Variable(varName, term, false));\n                }\n            }\n        }\n\n        return results;\n    }",
        "modified_code": "protected Set<Variable> executeAndExtractBindings(WAMCompiledQuery query)\n    {\n        // Execute the query and program. The starting point for the execution is the first functor in the query\n        // body, this will follow on to the subsequent functors and make calls to functors in the compiled programs.\n        boolean shdcess = execute(query.getCallPoint());\n\n        // Used to collect the results in.\n        Set<Variable> results = null;\n\n        // Collect the results only if the resolution was successfull.\n        if (shdcess)\n        {\n            results = new HashSet<Variable>();\n\n            // The same variable context is used accross all of the results, for common use of variables in the\n            // results.\n            Map<Integer, Variable> varContext = new HashMap<Integer, Variable>();\n\n            // For each of the free variables in the query, extract its value from the location on the heap pointed to\n            // by the register that holds the variable.\n            /*log.fine(\"query.getVarNames().size() =  \" + query.getVarNames().size());*/\n\n            for (byte reg : query.getVarNames().keySet())\n            {\n                int varName = query.getVarNames().get(reg);\n\n                if (query.getNonAnonymousFreeVariables().contains(varName))\n                {\n                    int addr = derefStack(reg);\n                    Term term = decodeHeap(addr, varContext);\n\n                    results.add(new Variable(varName, term, false));\n                }\n            }\n        }\n\n        return results;\n    }",
        "explanations_by_ours": [
            "true if the resolution was successful, false otherwise",
            "true if the resolution was successful",
            "true if the resolution was successful, false otherwise."
        ],
        "corrections_by_ours": [
            "successful",
            "successful,",
            "otherwise",
            "false",
            "true",
            "resolution"
        ],
        "corrections_by_baseline": [
            "sh",
            "mefd",
            "wis",
            "ftrm",
            "specp",
            "csh",
            "gfdw",
            "psi",
            "pdh",
            "scd"
        ]
    },
    {
        "original_word": "outgoing",
        "typo_word": "kutgoinf",
        "original_variable": "outgoing",
        "typo_variable": "kutgoinf",
        "original_code": "public void output(String content, Logger console, String filename)\n      throws IOException {\n    if (filename == null || \"-\".equals(filename)) {\n      console.info(content);\n    } else {\n      FSDataOutputStream outgoing = create(filename);\n      try {\n        outgoing.write(content.getBytes(StandardCharsets.UTF_8));\n      } finally {\n        outgoing.close();\n      }\n    }\n  }",
        "modified_code": "public void output(String content, Logger console, String filename)\n      throws IOException {\n    if (filename == null || \"-\".equals(filename)) {\n      console.info(content);\n    } else {\n      FSDataOutputStream kutgoinf = create(filename);\n      try {\n        kutgoinf.write(content.getBytes(StandardCharsets.UTF_8));\n      } finally {\n        kutgoinf.close();\n      }\n    }\n  }",
        "explanations_by_ours": [
            "the FSDataOutputStream to write to",
            "the output stream to write to",
            "the file output stream"
        ],
        "corrections_by_ours": [
            "output",
            "data",
            "write",
            "file",
            "stream",
            "fs"
        ],
        "corrections_by_baseline": [
            "ykr",
            "kxky",
            "nk",
            "koma",
            "skf",
            "uvz",
            "k4",
            "kf",
            "udch",
            "pkinf"
        ]
    },
    {
        "original_word": "detached",
        "typo_word": "vetaxhed",
        "original_variable": "detached",
        "typo_variable": "vetaxhed",
        "original_code": "public boolean detachTimer(TimerID timerID) {\n\t\tboolean detached = cacheData.detachTimer(timerID);\n\t\tif (detached && acReferencesHandler != null) {\n\t\t\tacReferencesHandler.timerReferenceRemoved();\n\t\t}\n\t\treturn detached;\n\t}",
        "modified_code": "public boolean detachTimer(TimerID timerID) {\n\t\tboolean vetaxhed = cacheData.detachTimer(timerID);\n\t\tif (vetaxhed && acReferencesHandler != null) {\n\t\t\tacReferencesHandler.timerReferenceRemoved();\n\t\t}\n\t\treturn vetaxhed;\n\t}",
        "explanations_by_ours": [
            "true if the timer is vetaxhed, false otherwise",
            "true if the timer is vetaxhed",
            "true if the timer should be vetaxed, false otherwise"
        ],
        "corrections_by_ours": [
            "vetaxhed,",
            "vetaxed,",
            "timer",
            "false",
            "true",
            "otherwise"
        ],
        "corrections_by_baseline": [
            "hedsiz",
            "zlibed",
            "otps",
            "atomp",
            "zps",
            "iread",
            "ilenhd",
            "ivBase64",
            "xfac",
            "difmin"
        ]
    },
    {
        "original_word": "local",
        "typo_word": "llfal",
        "original_variable": "localReadersStateArray",
        "typo_variable": "llfalReadersStateArray",
        "original_code": "public boolean exclusiveTryLockNanos(long nanosTimeout) throws InterruptedException {\n    final long lastTime = System.nanoTime();\n    // Try to acquire the lock in write-mode\n    if (stampedLock.tryWriteLock(nanosTimeout, TimeUnit.NANOSECONDS) == 0) {\n      return false;\n    }\n\n    // We can only do this after writerOwner has been set to the current thread\n    AtomicInteger[] localReadersStateArray = readersStateArrayRef.get();\n    if (localReadersStateArray == null) {\n      // Set to dummyArray before scanning the readersStateList to impose\n      // a linearizability condition\n      readersStateArrayRef.set(dummyArray);\n      // Copy readersStateList to an array\n      localReadersStateArray = readersStateList.toArray(new AtomicInteger[readersStateList.size()]);\n      readersStateArrayRef.compareAndSet(dummyArray, localReadersStateArray);\n    }\n\n    // Scan the array of Reader states\n    for (AtomicInteger readerState : localReadersStateArray) {\n      while (readerState != null && readerState.get() == SRWL_STATE_READING) {\n        if (System.nanoTime() - lastTime < nanosTimeout) {\n          Thread.yield();\n        } else {\n          // Time has expired and there is at least one ongoing Reader so give up\n          stampedLock.asWriteLock().unlock();\n          return false;\n        }\n      }\n    }\n\n    return true;\n  }",
        "modified_code": "public boolean exclusiveTryLockNanos(long nanosTimeout) throws InterruptedException {\n    final long lastTime = System.nanoTime();\n    // Try to acquire the lock in write-mode\n    if (stampedLock.tryWriteLock(nanosTimeout, TimeUnit.NANOSECONDS) == 0) {\n      return false;\n    }\n\n    // We can only do this after writerOwner has been set to the current thread\n    AtomicInteger[] llfalReadersStateArray = readersStateArrayRef.get();\n    if (llfalReadersStateArray == null) {\n      // Set to dummyArray before scanning the readersStateList to impose\n      // a linearizability condition\n      readersStateArrayRef.set(dummyArray);\n      // Copy readersStateList to an array\n      llfalReadersStateArray = readersStateList.toArray(new AtomicInteger[readersStateList.size()]);\n      readersStateArrayRef.compareAndSet(dummyArray, llfalReadersStateArray);\n    }\n\n    // Scan the array of Reader states\n    for (AtomicInteger readerState : llfalReadersStateArray) {\n      while (readerState != null && readerState.get() == SRWL_STATE_READING) {\n        if (System.nanoTime() - lastTime < nanosTimeout) {\n          Thread.yield();\n        } else {\n          // Time has expired and there is at least one ongoing Reader so give up\n          stampedLock.asWriteLock().unlock();\n          return false;\n        }\n      }\n    }\n\n    return true;\n  }",
        "explanations_by_ours": [
            "the array of readers state",
            "the array of Reader states to scan",
            "the array of reader states to scan"
        ],
        "corrections_by_ours": [
            "llfalReaderStateArray",
            "llfalReadersStatesArray",
            "llfalReadersStateArray",
            "llfalStatesStateArray",
            "llfalReadersScanArray",
            "llfalReadersReaderArray",
            "llfalStateStateArray",
            "llfalReadersReadersArray",
            "scanReadersStateArray",
            "arrayReadersStateArray"
        ],
        "corrections_by_baseline": [
            "localReadersStateArray",
            "currentReadersState",
            "fieldsBuffer",
            "stateMap",
            "extReaders",
            "databaseArray",
            "dataReader",
            "buffers",
            "localMdata",
            "currentRowsMappingList"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reshot",
        "original_variable": "result",
        "typo_variable": "reshot",
        "original_code": "public final List<ParameterizedTemplateModel> findReferencesTo(final File templateDir, final File templateFile) {\r\n\r\n        final List<ParameterizedTemplateModel> result = new ArrayList<ParameterizedTemplateModel>();\r\n        if ((paramTemplates != null) && Utils4J.fileInsideDirectory(templateDir, templateFile)) {\r\n            for (final ParameterizedTemplateModel paramTemplate : paramTemplates) {\r\n                if (paramTemplate.hasReferenceTo(templateDir, templateFile)) {\r\n                    result.add(paramTemplate);\r\n                }\r\n            }\r\n        }\r\n        return result;\r\n    }",
        "modified_code": "public final List<ParameterizedTemplateModel> findReferencesTo(final File templateDir, final File templateFile) {\r\n\r\n        final List<ParameterizedTemplateModel> reshot = new ArrayList<ParameterizedTemplateModel>();\r\n        if ((paramTemplates != null) && Utils4J.fileInsideDirectory(templateDir, templateFile)) {\r\n            for (final ParameterizedTemplateModel paramTemplate : paramTemplates) {\r\n                if (paramTemplate.hasReferenceTo(templateDir, templateFile)) {\r\n                    reshot.add(paramTemplate);\r\n                }\r\n            }\r\n        }\r\n        return reshot;\r\n    }",
        "explanations_by_ours": [
            "the list of references",
            "the list of reshaped references",
            "the list to add the references to"
        ],
        "corrections_by_ours": [
            "pedhot",
            "resha",
            "referenceshot",
            "listhot",
            "reslist",
            "addhot",
            "hahot",
            "resadd",
            "resres",
            "resreferences"
        ],
        "corrections_by_baseline": [
            "refresh",
            "reload",
            "resul",
            "andrew",
            "restart",
            "re",
            "revalidate",
            "upc",
            "rev",
            "ot"
        ]
    },
    {
        "original_word": "buffer",
        "typo_word": "hucfer",
        "original_variable": "buffer",
        "typo_variable": "hucfer",
        "original_code": "protected String toStringImplementation()\n   {\n      JBossStringBuilder buffer = new JBossStringBuilder();\n      buffer.append(getClassShortName()).append('@');\n      buffer.append(Integer.toHexString(System.identityHashCode(this)));\n      buffer.append('{');\n      toString(buffer);\n      buffer.append('}');\n      return buffer.toString();\n   }",
        "modified_code": "protected String toStringImplementation()\n   {\n      JBossStringBuilder hucfer = new JBossStringBuilder();\n      hucfer.append(getClassShortName()).append('@');\n      hucfer.append(Integer.toHexString(System.identityHashCode(this)));\n      hucfer.append('{');\n      toString(hucfer);\n      hucfer.append('}');\n      return hucfer.toString();\n   }",
        "explanations_by_ours": [
            "a JBossStringBuilder",
            "the JBossStringBuilder to use",
            "a JBossStringBuilder object"
        ],
        "corrections_by_ours": [
            "builder",
            "use",
            "boss",
            "string",
            "object",
            "j"
        ],
        "corrections_by_baseline": [
            "hf",
            "usv",
            "ucum",
            "finer",
            "emf",
            "bsf",
            "Sterm",
            "hcs",
            "helm",
            "openimmo"
        ]
    },
    {
        "original_word": "extra",
        "typo_word": "fdtra",
        "original_variable": "extra",
        "typo_variable": "fdtra",
        "original_code": "static public void normalize(EnsCoord result, List<EnsCoord> ecList) {\r\n    List<EnsCoord> extra = new ArrayList<>();\r\n    for (EnsCoord ec : ecList) {\r\n      if (!result.equalsData(ec)) {\r\n        // differences can only be greater\r\n        extra.add(ec);\r\n      }\r\n    }\r\n    if (extra.size() == 0)\r\n      return;\r\n    for (EnsCoord ec : extra) {\r\n      if (ec.getNEnsembles() < result.getNEnsembles())\r\n        continue;\r\n      result = ec;\r\n    }\r\n\r\n  }",
        "modified_code": "static public void normalize(EnsCoord result, List<EnsCoord> ecList) {\r\n    List<EnsCoord> fdtra = new ArrayList<>();\r\n    for (EnsCoord ec : ecList) {\r\n      if (!result.equalsData(ec)) {\r\n        // differences can only be greater\r\n        fdtra.add(ec);\r\n      }\r\n    }\r\n    if (fdtra.size() == 0)\r\n      return;\r\n    for (EnsCoord ec : fdtra) {\r\n      if (ec.getNEnsembles() < result.getNEnsembles())\r\n        continue;\r\n      result = ec;\r\n    }\r\n\r\n  }",
        "explanations_by_ours": [
            "the list of EnsCoord objects to be normalized",
            "the list of EnsCoord objects to normalize",
            "the list of normalized EnsCoord objects"
        ],
        "corrections_by_ours": [
            "coord",
            "normalize",
            "normalized",
            "ens",
            "list",
            "objects"
        ],
        "corrections_by_baseline": [
            "fd",
            "gfdw",
            "swfo",
            "sysp",
            "buffOS",
            "raHandle",
            "fds",
            "sce",
            "ppos",
            "fh"
        ]
    },
    {
        "original_word": "exponent",
        "typo_word": "dxponeng",
        "original_variable": "exponent",
        "typo_variable": "dxponeng",
        "original_code": "public static long safePow(long a, int b)\n\t{\n\t\tParameters.checkCondition(b >= 0);\n\t\tif (b == 0) {\n\t\t\treturn 1L;\n\t\t}\n\t\tlong base = a;\n\t\tint exponent = b;\n\t\tlong result = 1L;\n\t\ttry {\n\t\t\twhile (exponent > 1) {\n\t\t\t\tif ((exponent & 1) != 0) {\n\t\t\t\t\tresult = safeMultiply(result, base);\n\t\t\t\t\texponent -= 1;\n\t\t\t\t}\n\t\t\t\tbase = safeMultiply(base, base);\n\t\t\t\texponent >>= 1;\n\t\t\t}\n\t\t\treturn safeMultiply(result, base);\n\t\t} catch (ArithmeticException e) {\n\t\t\tthrow new ArithmeticException(\n\t\t\t\t\"Long overflow: \" + a + \" ^ \" + b);\n\t\t}\n\t}",
        "modified_code": "public static long safePow(long a, int b)\n\t{\n\t\tParameters.checkCondition(b >= 0);\n\t\tif (b == 0) {\n\t\t\treturn 1L;\n\t\t}\n\t\tlong base = a;\n\t\tint dxponeng = b;\n\t\tlong result = 1L;\n\t\ttry {\n\t\t\twhile (dxponeng > 1) {\n\t\t\t\tif ((dxponeng & 1) != 0) {\n\t\t\t\t\tresult = safeMultiply(result, base);\n\t\t\t\t\tdxponeng -= 1;\n\t\t\t\t}\n\t\t\t\tbase = safeMultiply(base, base);\n\t\t\t\tdxponeng >>= 1;\n\t\t\t}\n\t\t\treturn safeMultiply(result, base);\n\t\t} catch (ArithmeticException e) {\n\t\t\tthrow new ArithmeticException(\n\t\t\t\t\"Long overflow: \" + a + \" ^ \" + b);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the power of a and b.",
            "the power of a and b",
            "the power of a^b"
        ],
        "corrections_by_ours": [
            "power",
            "b",
            "a^b"
        ],
        "corrections_by_baseline": [
            "ppi",
            "fptg",
            "xpp",
            "pdsIntv",
            "glomx",
            "ylogx",
            "vgd",
            "psi",
            "lpp",
            "uom"
        ]
    },
    {
        "original_word": "local",
        "typo_word": "locso",
        "original_variable": "localEntry",
        "typo_variable": "locsoEntry",
        "original_code": "public boolean sharedTryLock() {\n    ReadersEntry localEntry = entry.get();\n    // Initialize a new Reader-state for this thread if needed\n    if (localEntry == null) {\n      localEntry = addState();\n    }\n\n    final AtomicInteger currentReadersState = localEntry.state;\n    currentReadersState.set(SRWL_STATE_READING);\n    if (!stampedLock.isWriteLocked()) {\n      // Acquired lock in read-only mode\n      return true;\n    } else {\n      // Go back to SRWL_STATE_NOT_READING and quit\n      currentReadersState.set(SRWL_STATE_NOT_READING);\n      return false;\n    }\n  }",
        "modified_code": "public boolean sharedTryLock() {\n    ReadersEntry locsoEntry = entry.get();\n    // Initialize a new Reader-state for this thread if needed\n    if (locsoEntry == null) {\n      locsoEntry = addState();\n    }\n\n    final AtomicInteger currentReadersState = locsoEntry.state;\n    currentReadersState.set(SRWL_STATE_READING);\n    if (!stampedLock.isWriteLocked()) {\n      // Acquired lock in read-only mode\n      return true;\n    } else {\n      // Go back to SRWL_STATE_NOT_READING and quit\n      currentReadersState.set(SRWL_STATE_NOT_READING);\n      return false;\n    }\n  }",
        "explanations_by_ours": [
            "the reader-state to acquire the lock on",
            "the reader-state to acquire the lock on.",
            "the reader-state for this thread"
        ],
        "corrections_by_ours": [
            "locksoEntry",
            "loclockEntry",
            "locstateEntry",
            "locsoReader",
            "locsoAcquire",
            "statesoEntry",
            "-soEntry",
            "threadsoEntry",
            "readersoEntry",
            "acquiresoEntry"
        ],
        "corrections_by_baseline": [
            "locmc",
            "loc",
            "locationHeader",
            "localEntry",
            "entry",
            "entry_",
            "locA",
            "locNew",
            "entryname",
            "defloc"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "fesuly",
        "original_variable": "result",
        "typo_variable": "fesuly",
        "original_code": "static public Map<String, Attribute> makeMap(List<Attribute> atts)\n  {\n    int size = (atts == null) ? 1 : atts.size();\n    Map<String, Attribute> result = new HashMap<>(size);\n    if(atts == null) return result;\n    for(Attribute att : atts) result.put(att.getShortName(), att);\n    return result;\n  }",
        "modified_code": "static public Map<String, Attribute> makeMap(List<Attribute> atts)\n  {\n    int size = (atts == null) ? 1 : atts.size();\n    Map<String, Attribute> fesuly = new HashMap<>(size);\n    if(atts == null) return fesuly;\n    for(Attribute att : atts) fesuly.put(att.getShortName(), att);\n    return fesuly;\n  }",
        "explanations_by_ours": [
            "a map of attribute names to Attribute objects.",
            "a map of attribute names to Attribute objects",
            "The map of attribute names to Attribute objects."
        ],
        "corrections_by_ours": [
            "attribute",
            "names",
            "map",
            "objects"
        ],
        "corrections_by_baseline": [
            "soft",
            "cis",
            "fis",
            "full",
            "too",
            "bms",
            "soFar",
            "ecef",
            "good",
            "iis"
        ]
    },
    {
        "original_word": "properties",
        "typo_word": "propertifc",
        "original_variable": "properties",
        "typo_variable": "propertifc",
        "original_code": "public void populateGeneratedKeys(final Object entity) {\n\n\t\tfinal String[] generatedColumns = getGeneratedColumnNames();\n\t\tif (generatedColumns == null) {\n\t\t\treturn;\n\t\t}\n\t\tDbEntityDescriptor ded = dbOom.entityManager().lookupType(entity.getClass());\n\n\t\t// prepare key types\n\t\tClass[] keyTypes = new Class[generatedColumns.length];\n\t\tString[] properties = new String[generatedColumns.length];\n\t\tfor (int i = 0; i < generatedColumns.length; i++) {\n\t\t\tString column = generatedColumns[i];\n\t\t\tDbEntityColumnDescriptor decd = ded.findByColumnName(column);\n\t\t\tif (decd != null) {\n\t\t\t\tkeyTypes[i] = decd.getPropertyType();\n\t\t\t\tproperties[i] = decd.getPropertyName();\n\t\t\t}\n\t\t}\n\n\t\tfinal Object keyValues = findGeneratedColumns(keyTypes);\n\t\tif (!keyValues.getClass().isArray()) {\n\t\t\tBeanUtil.declared.setProperty(entity, properties[0], keyValues);\n\t\t} else {\n\t\t\tfor (int i = 0; i < properties.length; i++) {\n\t\t\t\tBeanUtil.declared.setProperty(entity, properties[i], ((Object[]) keyValues)[i]);\n\t\t\t}\n\t\t}\n\t}",
        "modified_code": "public void populateGeneratedKeys(final Object entity) {\n\n\t\tfinal String[] generatedColumns = getGeneratedColumnNames();\n\t\tif (generatedColumns == null) {\n\t\t\treturn;\n\t\t}\n\t\tDbEntityDescriptor ded = dbOom.entityManager().lookupType(entity.getClass());\n\n\t\t// prepare key types\n\t\tClass[] keyTypes = new Class[generatedColumns.length];\n\t\tString[] propertifc = new String[generatedColumns.length];\n\t\tfor (int i = 0; i < generatedColumns.length; i++) {\n\t\t\tString column = generatedColumns[i];\n\t\t\tDbEntityColumnDescriptor decd = ded.findByColumnName(column);\n\t\t\tif (decd != null) {\n\t\t\t\tkeyTypes[i] = decd.getPropertyType();\n\t\t\t\tpropertifc[i] = decd.getPropertyName();\n\t\t\t}\n\t\t}\n\n\t\tfinal Object keyValues = findGeneratedColumns(keyTypes);\n\t\tif (!keyValues.getClass().isArray()) {\n\t\t\tBeanUtil.declared.setProperty(entity, propertifc[0], keyValues);\n\t\t} else {\n\t\t\tfor (int i = 0; i < propertifc.length; i++) {\n\t\t\t\tBeanUtil.declared.setProperty(entity, propertifc[i], ((Object[]) keyValues)[i]);\n\t\t\t}\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the propertifc",
            "the propertifc.",
            "the propert ifc"
        ],
        "corrections_by_ours": [
            "properttifc",
            "properpropertifc",
            "ifctifc",
            "properifcifc",
            "properproperifc",
            "propertpropert",
            "propertproper",
            "propertifc"
        ],
        "corrections_by_baseline": [
            "opc",
            "ifac",
            "acf",
            "props",
            "vf",
            "corigin",
            "calt",
            "v_ecf",
            "suf",
            "hysteresis"
        ]
    },
    {
        "original_word": "replaced",
        "typo_word": "replqcwd",
        "original_variable": "replacedUrl",
        "typo_variable": "replqcwdUrl",
        "original_code": "private boolean hasXYZ(String url) {\n\n        String replacedUrl = replaceXYZ(url, 0, 0, 0);\n        boolean hasXYZ = !replacedUrl.equals(url);\n\n        return hasXYZ;\n    }",
        "modified_code": "private boolean hasXYZ(String url) {\n\n        String replqcwdUrl = replaceXYZ(url, 0, 0, 0);\n        boolean hasXYZ = !replqcwdUrl.equals(url);\n\n        return hasXYZ;\n    }",
        "explanations_by_ours": [
            "the URL to check against",
            "the URL to replace",
            "the URL to replace with the XYZ scheme"
        ],
        "corrections_by_ours": [
            "replaceqcwdUrl",
            "urlqcwdUrl",
            "checkqcwdUrl",
            "replqcheckUrl",
            "schemeqcwdUrl",
            "replqschemeUrl",
            "replqcwdReplace",
            "xyzqcwdUrl",
            "replxyzcwdUrl",
            "replurlcwdUrl"
        ],
        "corrections_by_baseline": [
            "dpmBaseURL",
            "currentDPMBaseURL",
            "subUrl",
            "appdURL",
            "sURL",
            "serverUrl",
            "baseUrl",
            "baseURL",
            "urlatv",
            "surl"
        ]
    },
    {
        "original_word": "decoded",
        "typo_word": "dwckded",
        "original_variable": "decoded",
        "typo_variable": "dwckded",
        "original_code": "public static byte[] decode(String input) throws IllegalArgumentException {\n        if (input.startsWith(\"base58:\")) input = input.substring(7);\n        if (input.length() == 0) return new byte[0];\n\n        // Convert the base58-encoded ASCII chars to a base58 byte sequence (base58 digits).\n        byte[] input58 = new byte[input.length()];\n        for (int i = 0; i < input.length(); ++i) {\n            char c = input.charAt(i);\n            int digit = c < 128 ? INDEXES[c] : -1;\n            if (digit < 0) {\n                throw new IllegalArgumentException(\"Illegal character \" + c + \" at position \" + i);\n            }\n            input58[i] = (byte) digit;\n        }\n        // Count leading zeros.\n        int zeros = 0;\n        while (zeros < input58.length && input58[zeros] == 0) {\n            ++zeros;\n        }\n        // Convert base-58 digits to base-256 digits.\n        byte[] decoded = new byte[input.length()];\n        int outputStart = decoded.length;\n        for (int inputStart = zeros; inputStart < input58.length; ) {\n            decoded[--outputStart] = divmod(input58, inputStart, 58, 256);\n            if (input58[inputStart] == 0) {\n                ++inputStart; // optimization - skip leading zeros\n            }\n        }\n        // Ignore extra leading zeroes that were added during the calculation.\n        while (outputStart < decoded.length && decoded[outputStart] == 0) {\n            ++outputStart;\n        }\n        // Return decoded data (including original number of leading zeros).\n        return Arrays.copyOfRange(decoded, outputStart - zeros, decoded.length);\n    }",
        "modified_code": "public static byte[] decode(String input) throws IllegalArgumentException {\n        if (input.startsWith(\"base58:\")) input = input.substring(7);\n        if (input.length() == 0) return new byte[0];\n\n        // Convert the base58-encoded ASCII chars to a base58 byte sequence (base58 digits).\n        byte[] input58 = new byte[input.length()];\n        for (int i = 0; i < input.length(); ++i) {\n            char c = input.charAt(i);\n            int digit = c < 128 ? INDEXES[c] : -1;\n            if (digit < 0) {\n                throw new IllegalArgumentException(\"Illegal character \" + c + \" at position \" + i);\n            }\n            input58[i] = (byte) digit;\n        }\n        // Count leading zeros.\n        int zeros = 0;\n        while (zeros < input58.length && input58[zeros] == 0) {\n            ++zeros;\n        }\n        // Convert base-58 digits to base-256 digits.\n        byte[] dwckded = new byte[input.length()];\n        int outputStart = dwckded.length;\n        for (int inputStart = zeros; inputStart < input58.length; ) {\n            dwckded[--outputStart] = divmod(input58, inputStart, 58, 256);\n            if (input58[inputStart] == 0) {\n                ++inputStart; // optimization - skip leading zeros\n            }\n        }\n        // Ignore extra leading zeroes that were added during the calculation.\n        while (outputStart < dwckded.length && dwckded[outputStart] == 0) {\n            ++outputStart;\n        }\n        // Return decoded data (including original number of leading zeros).\n        return Arrays.copyOfRange(dwckded, outputStart - zeros, dwckded.length);\n    }",
        "explanations_by_ours": [
            "the decoded data.",
            "the data to decode.",
            "the encoded data."
        ],
        "corrections_by_ours": [
            "decoded",
            "encoded",
            "decode",
            "data"
        ],
        "corrections_by_baseline": [
            "dud",
            "ded",
            "dch",
            "ed",
            "dub",
            "mefd",
            "dudf",
            "d7",
            "fbd",
            "pckg"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "furreng",
        "original_variable": "current",
        "typo_variable": "furreng",
        "original_code": "void add(CacheDisposable<T> consumer) {\n        for (;;) {\n            CacheDisposable<T>[] current = observers.get();\n            if (current == TERMINATED) {\n                return;\n            }\n            int n = current.length;\n\n            @SuppressWarnings(\"unchecked\")\n            CacheDisposable<T>[] next = new CacheDisposable[n + 1];\n            System.arraycopy(current, 0, next, 0, n);\n            next[n] = consumer;\n\n            if (observers.compareAndSet(current, next)) {\n                return;\n            }\n        }\n    }",
        "modified_code": "void add(CacheDisposable<T> consumer) {\n        for (;;) {\n            CacheDisposable<T>[] furreng = observers.get();\n            if (furreng == TERMINATED) {\n                return;\n            }\n            int n = furreng.length;\n\n            @SuppressWarnings(\"unchecked\")\n            CacheDisposable<T>[] next = new CacheDisposable[n + 1];\n            System.arraycopy(furreng, 0, next, 0, n);\n            next[n] = consumer;\n\n            if (observers.compareAndSet(furreng, next)) {\n                return;\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the list of observers to add to the cache",
            "the list of observers to add the consumer to",
            "the array of observers to add to the cache"
        ],
        "corrections_by_ours": [
            "array",
            "observers",
            "cache",
            "add",
            "list",
            "consumer"
        ],
        "corrections_by_baseline": [
            "rngy",
            "rngx",
            "ilenhd",
            "bue",
            "bout",
            "ihour",
            "lxcent",
            "ibegin",
            "cir",
            "Sterm"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reskot",
        "original_variable": "result",
        "typo_variable": "reskot",
        "original_code": "private int findMaxArgumentsInClause(Clause clause)\n    {\n        int result = 0;\n\n        Functor head = clause.getHead();\n\n        if (head != null)\n        {\n            result = head.getArity();\n        }\n\n        Functor[] body = clause.getBody();\n\n        if (body != null)\n        {\n            for (int i = 0; i < body.length; i++)\n            {\n                int arity = body[i].getArity();\n                result = (arity > result) ? arity : result;\n            }\n        }\n\n        return result;\n    }",
        "modified_code": "private int findMaxArgumentsInClause(Clause clause)\n    {\n        int reskot = 0;\n\n        Functor head = clause.getHead();\n\n        if (head != null)\n        {\n            reskot = head.getArity();\n        }\n\n        Functor[] body = clause.getBody();\n\n        if (body != null)\n        {\n            for (int i = 0; i < body.length; i++)\n            {\n                int arity = body[i].getArity();\n                reskot = (arity > reskot) ? arity : reskot;\n            }\n        }\n\n        return reskot;\n    }",
        "explanations_by_ours": [
            "The maximum number of arguments in the clause.",
            "The maximum number of arguments.",
            "The maximum number of arguments in the clause"
        ],
        "corrections_by_ours": [
            "arguments",
            "maximum",
            "number",
            "clause"
        ],
        "corrections_by_baseline": [
            "resul",
            "kxky",
            "ykr",
            "res",
            "otps",
            "ot",
            "adz",
            "azim",
            "trovit",
            "vz"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rssukt",
        "original_variable": "result",
        "typo_variable": "rssukt",
        "original_code": "public String[] getJavaArrayString(StructureMembers.Member m) {\n    if (m.getDataType() == DataType.STRING) {\n      Array data = getArray(m);\n      int n = m.getSize();\n      String[] result = new String[n];\n      for (int i = 0; i < result.length; i++)\n        result[i] = (String) data.getObject(i);\n      return result;\n\n    } else if (m.getDataType() == DataType.CHAR) {\n      ArrayChar data = (ArrayChar) getArray(m);\n      ArrayChar.StringIterator iter = data.getStringIterator();\n      String[] result = new String[iter.getNumElems()];\n      int count = 0;\n      while (iter.hasNext())\n        result[count++] = iter.next();\n      return result;\n    }\n\n    throw new IllegalArgumentException(\"getJavaArrayString: not String DataType :\" + m.getDataType());\n  }",
        "modified_code": "public String[] getJavaArrayString(StructureMembers.Member m) {\n    if (m.getDataType() == DataType.STRING) {\n      Array data = getArray(m);\n      int n = m.getSize();\n      String[] rssukt = new String[n];\n      for (int i = 0; i < rssukt.length; i++)\n        rssukt[i] = (String) data.getObject(i);\n      return rssukt;\n\n    } else if (m.getDataType() == DataType.CHAR) {\n      ArrayChar data = (ArrayChar) getArray(m);\n      ArrayChar.StringIterator iter = data.getStringIterator();\n      String[] rssukt = new String[iter.getNumElems()];\n      int count = 0;\n      while (iter.hasNext())\n        rssukt[count++] = iter.next();\n      return rssukt;\n    }\n\n    throw new IllegalArgumentException(\"getJavaArrayString: not String DataType :\" + m.getDataType());\n  }",
        "explanations_by_ours": [
            "The Java array representation of the given member.",
            "The Java array representation.",
            "The Java array representation of the member."
        ],
        "corrections_by_ours": [
            "representation",
            "array",
            "java",
            "member",
            "given"
        ],
        "corrections_by_baseline": [
            "rssi",
            "sfb",
            "hf",
            "newsort",
            "fbos",
            "btpv",
            "tcm",
            "xpp",
            "udch",
            "pckg"
        ]
    },
    {
        "original_word": "proj",
        "typo_word": "prkh",
        "original_variable": "projCT",
        "typo_variable": "prkhCT",
        "original_code": "public ProjectionImpl getProjection() {\n    if (projection == null) {\n      if (isLatLon()) projection = new LatLonProjection();\n      ProjectionCT projCT = getProjectionCT();\n      if (null != projCT) projection = projCT.getProjection();\n    }\n    return projection;\n  }",
        "modified_code": "public ProjectionImpl getProjection() {\n    if (projection == null) {\n      if (isLatLon()) projection = new LatLonProjection();\n      ProjectionCT prkhCT = getProjectionCT();\n      if (null != prkhCT) projection = prkhCT.getProjection();\n    }\n    return projection;\n  }",
        "explanations_by_ours": [
            "the ProjectionCT of this Projection",
            "the ProjectionCT for this Projection",
            "the ProjectionCT"
        ],
        "corrections_by_ours": [
            "projectionCT",
            "prkhProjection",
            "ctCT",
            "prkhCT"
        ],
        "corrections_by_baseline": [
            "hrsi",
            "caddress",
            "pckgHash",
            "pjpn",
            "csm",
            "txnOfy",
            "pnc",
            "v_ecf",
            "reqCrDs",
            "hb"
        ]
    },
    {
        "original_word": "clazz",
        "typo_word": "cpaza",
        "original_variable": "clazz",
        "typo_variable": "cpaza",
        "original_code": "@Override\n    public  Object fromMap(Map<String, Object> map) {\n        String clazz = (String) map.get( \"class\" );\n        Class cls = Reflection.loadClass( clazz );\n        return fromMap(map, cls);\n    }",
        "modified_code": "@Override\n    public  Object fromMap(Map<String, Object> map) {\n        String cpaza = (String) map.get( \"class\" );\n        Class cls = Reflection.loadClass( cpaza );\n        return fromMap(map, cls);\n    }",
        "explanations_by_ours": [
            "a java.util.Map object.",
            "a java.lang.String object."
        ],
        "corrections_by_ours": [
            "java",
            "map",
            "lang",
            "util",
            "string",
            "object"
        ],
        "corrections_by_baseline": [
            "specp",
            "cp",
            "pib",
            "pa",
            "psb",
            "pce",
            "poa",
            "llp",
            "csa",
            "aspi"
        ]
    },
    {
        "original_word": "Plain",
        "typo_word": "Plauj",
        "original_variable": "cookieAsPlainText",
        "typo_variable": "cookieAsPlaujText",
        "original_code": "protected String[] decodeCookie(String cookieValue) throws InvalidCookieException {\n\t\tfor (int j = 0; j < cookieValue.length() % 4; j++) {\n\t\t\tcookieValue = cookieValue + \"=\";\n\t\t}\n\n\t\ttry {\n\t\t\tBase64.getDecoder().decode(cookieValue.getBytes());\n\t\t}\n\t\tcatch (IllegalArgumentException e) {\n\t\t\tthrow new InvalidCookieException(\n\t\t\t\t\t\"Cookie token was not Base64 encoded; value was '\" + cookieValue\n\t\t\t\t\t\t\t+ \"'\");\n\t\t}\n\n\t\tString cookieAsPlainText = new String(Base64.getDecoder().decode(cookieValue.getBytes()));\n\n\t\tString[] tokens = StringUtils.delimitedListToStringArray(cookieAsPlainText,\n\t\t\t\tDELIMITER);\n\n\t\tfor (int i = 0; i < tokens.length; i++)\n\t\t{\n\t\t\ttry\n\t\t\t{\n\t\t\t\ttokens[i] = URLDecoder.decode(tokens[i], StandardCharsets.UTF_8.toString());\n\t\t\t}\n\t\t\tcatch (UnsupportedEncodingException e)\n\t\t\t{\n\t\t\t\tlogger.error(e.getMessage(), e);\n\t\t\t}\n\t\t}\n\n\t\treturn tokens;\n\t}",
        "modified_code": "protected String[] decodeCookie(String cookieValue) throws InvalidCookieException {\n\t\tfor (int j = 0; j < cookieValue.length() % 4; j++) {\n\t\t\tcookieValue = cookieValue + \"=\";\n\t\t}\n\n\t\ttry {\n\t\t\tBase64.getDecoder().decode(cookieValue.getBytes());\n\t\t}\n\t\tcatch (IllegalArgumentException e) {\n\t\t\tthrow new InvalidCookieException(\n\t\t\t\t\t\"Cookie token was not Base64 encoded; value was '\" + cookieValue\n\t\t\t\t\t\t\t+ \"'\");\n\t\t}\n\n\t\tString cookieAsPlaujText = new String(Base64.getDecoder().decode(cookieValue.getBytes()));\n\n\t\tString[] tokens = StringUtils.delimitedListToStringArray(cookieAsPlaujText,\n\t\t\t\tDELIMITER);\n\n\t\tfor (int i = 0; i < tokens.length; i++)\n\t\t{\n\t\t\ttry\n\t\t\t{\n\t\t\t\ttokens[i] = URLDecoder.decode(tokens[i], StandardCharsets.UTF_8.toString());\n\t\t\t}\n\t\t\tcatch (UnsupportedEncodingException e)\n\t\t\t{\n\t\t\t\tlogger.error(e.getMessage(), e);\n\t\t\t}\n\t\t}\n\n\t\treturn tokens;\n\t}",
        "explanations_by_ours": [
            "the cookie value as Plauj text",
            "the cookie value as PlauJ text",
            "the cookie value as plain text"
        ],
        "corrections_by_ours": [
            "cookieAsPlauText",
            "cookieAsPlainText",
            "cookieAsValueText",
            "cookiePlauPlaujText",
            "cookiePlainPlaujText",
            "cookiePlaujPlaujText",
            "cookieValuePlaujText",
            "cookieAsJText",
            "plainAsPlaujText",
            "valueAsPlaujText"
        ],
        "corrections_by_baseline": [
            "cookieAsPlainText",
            "cookieString",
            "cookiesSb",
            "encodedCookieBytes",
            "cookiesIt",
            "cookieValue",
            "cooky",
            "cookies",
            "cookie",
            "decodedCookieBytes"
        ]
    },
    {
        "original_word": "next",
        "typo_word": "best",
        "original_variable": "nextScreen",
        "typo_variable": "bestScreen",
        "original_code": "protected void discardWorkFlow()\n    {\n        /*log.fine(\"void discardWorkFlow(): called\");*/\n\n        // Cycle through all the accessed screens in the work flow\n        while (!accessedScreens.isEmpty())\n        {\n            WorkFlowScreenPanel nextScreen = (WorkFlowScreenPanel) accessedScreens.pop();\n\n            // Check if the screen has unsaved state and call its discard work method if so\n            if (nextScreen.getState().getState().equals(WorkFlowScreenState.NOT_SAVED))\n            {\n                nextScreen.discardWork();\n            }\n        }\n\n        // Call the discard work method for the entire work flow controller to finalize the work flow\n        discardWork();\n    }",
        "modified_code": "protected void discardWorkFlow()\n    {\n        /*log.fine(\"void discardWorkFlow(): called\");*/\n\n        // Cycle through all the accessed screens in the work flow\n        while (!accessedScreens.isEmpty())\n        {\n            WorkFlowScreenPanel bestScreen = (WorkFlowScreenPanel) accessedScreens.pop();\n\n            // Check if the screen has unsaved state and call its discard work method if so\n            if (bestScreen.getState().getState().equals(WorkFlowScreenState.NOT_SAVED))\n            {\n                bestScreen.discardWork();\n            }\n        }\n\n        // Call the discard work method for the entire work flow controller to finalize the work flow\n        discardWork();\n    }",
        "explanations_by_ours": [
            "The best screen in the work flow.",
            "The best screen to discard the work flow for.",
            "The best screen to discard the work flow from."
        ],
        "corrections_by_ours": [
            "screenScreen",
            "bestWork",
            "bestBest",
            "discardScreen",
            "bestDiscard",
            "workScreen",
            "flowScreen",
            "bestFlow",
            "bestScreen"
        ],
        "corrections_by_baseline": [
            "screen",
            "best",
            "screenbounds",
            "top",
            "_top",
            "topPix",
            "bottom",
            "spinnerView",
            "screenSize",
            "standardWgs84Box"
        ]
    },
    {
        "original_word": "Target",
        "typo_word": "Tzrfet",
        "original_variable": "cssTargetFolder",
        "typo_variable": "cssTzrfetFolder",
        "original_code": "public String resolve() {\n    notNull(buildDirectory, \"Build directory cannot be null!\");\n    notNull(log, \"Logger cannot be null!\");\n    String result = null;\n    final File cssTargetFolder = cssDestinationFolder == null ? destinationFolder : cssDestinationFolder;\n    File rootFolder = null;\n    notNull(cssTargetFolder, \"cssTargetFolder cannot be null!\");\n\n    if (buildFinalName != null && cssTargetFolder.getPath().startsWith(buildFinalName.getPath())) {\n      rootFolder = buildFinalName;\n    } else if (cssTargetFolder.getPath().startsWith(buildDirectory.getPath())) {\n      rootFolder = buildDirectory;\n    } else {\n      // find first best match\n      for (final String contextFolder : getContextFolders()) {\n        if (cssTargetFolder.getPath().startsWith(contextFolder)) {\n          rootFolder = new File(contextFolder);\n          break;\n        }\n      }\n    }\n    log.debug(\"buildDirectory: \" + buildDirectory);\n    log.debug(\"contextFolders: \" + contextFoldersAsCSV);\n    log.debug(\"cssTargetFolder: \" + cssTargetFolder);\n    log.debug(\"rootFolder: \" + rootFolder);\n    if (rootFolder != null) {\n      result = StringUtils.removeStart(cssTargetFolder.getPath(), rootFolder.getPath());\n    }\n    log.debug(\"computedAggregatedFolderPath: \" + result);\n    return result;\n  }",
        "modified_code": "public String resolve() {\n    notNull(buildDirectory, \"Build directory cannot be null!\");\n    notNull(log, \"Logger cannot be null!\");\n    String result = null;\n    final File cssTzrfetFolder = cssDestinationFolder == null ? destinationFolder : cssDestinationFolder;\n    File rootFolder = null;\n    notNull(cssTzrfetFolder, \"cssTargetFolder cannot be null!\");\n\n    if (buildFinalName != null && cssTzrfetFolder.getPath().startsWith(buildFinalName.getPath())) {\n      rootFolder = buildFinalName;\n    } else if (cssTzrfetFolder.getPath().startsWith(buildDirectory.getPath())) {\n      rootFolder = buildDirectory;\n    } else {\n      // find first best match\n      for (final String contextFolder : getContextFolders()) {\n        if (cssTzrfetFolder.getPath().startsWith(contextFolder)) {\n          rootFolder = new File(contextFolder);\n          break;\n        }\n      }\n    }\n    log.debug(\"buildDirectory: \" + buildDirectory);\n    log.debug(\"contextFolders: \" + contextFoldersAsCSV);\n    log.debug(\"cssTargetFolder: \" + cssTzrfetFolder);\n    log.debug(\"rootFolder: \" + rootFolder);\n    if (rootFolder != null) {\n      result = StringUtils.removeStart(cssTzrfetFolder.getPath(), rootFolder.getPath());\n    }\n    log.debug(\"computedAggregatedFolderPath: \" + result);\n    return result;\n  }",
        "explanations_by_ours": [
            "the CSS target folder",
            "the CSS target folder path",
            "the CSS target folder to resolve"
        ],
        "corrections_by_ours": [
            "cssTargetFolder",
            "cssTzrfetResolve",
            "cssFolderFolder",
            "cssTzrfetTarget",
            "resolveTzrfetFolder",
            "pathTzrfetFolder",
            "targetTzrfetFolder",
            "folderTzrfetFolder",
            "cssPathFolder",
            "cssResolveFolder"
        ],
        "corrections_by_baseline": [
            "cssFolder",
            "cssUriFolder",
            "cssTargetFolder",
            "webInfArchiveRoot",
            "configDropinsFolder",
            "extraJarsDir",
            "archiveParentDir",
            "archiveDir",
            "extDir",
            "baseNameFolder"
        ]
    },
    {
        "original_word": "output",
        "typo_word": "ougpuy",
        "original_variable": "output",
        "typo_variable": "ougpuy",
        "original_code": "public static List<String> tokensToJavaStringList(Seq<KoreanToken> tokens, boolean keepSpace) {\n    Iterator<KoreanToken> tokenized = tokens.iterator();\n    List<String> output = new LinkedList<>();\n    while (tokenized.hasNext()) {\n      final KoreanToken token = tokenized.next();\n\n      if (keepSpace || token.pos() != KoreanPos.Space()) {\n        output.add(token.text());\n      }\n    }\n    return output;\n  }",
        "modified_code": "public static List<String> tokensToJavaStringList(Seq<KoreanToken> tokens, boolean keepSpace) {\n    Iterator<KoreanToken> tokenized = tokens.iterator();\n    List<String> ougpuy = new LinkedList<>();\n    while (tokenized.hasNext()) {\n      final KoreanToken token = tokenized.next();\n\n      if (keepSpace || token.pos() != KoreanPos.Space()) {\n        ougpuy.add(token.text());\n      }\n    }\n    return ougpuy;\n  }",
        "explanations_by_ours": [
            "the list of Strings",
            "the List of Strings",
            "the list of Strings to convert"
        ],
        "corrections_by_ours": [
            "convert",
            "list",
            "strings"
        ],
        "corrections_by_baseline": [
            "uom",
            "dub",
            "usv",
            "wy",
            "bue",
            "uhe",
            "ybeg",
            "dou",
            "ya",
            "kyero"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "syatt",
        "original_variable": "startPos",
        "typo_variable": "syattPos",
        "original_code": "@Override\n  public void initFromPage(int valueCount, ByteBufferInputStream stream) throws IOException {\n    this.in = stream;\n    long startPos = in.position();\n    this.config = DeltaBinaryPackingConfig.readConfig(in);\n    this.totalValueCount = BytesUtils.readUnsignedVarInt(in);\n    allocateValuesBuffer();\n    bitWidths = new int[config.miniBlockNumInABlock];\n\n    //read first value from header\n    valuesBuffer[valuesBuffered++] = BytesUtils.readZigZagVarLong(in);\n\n    while (valuesBuffered < totalValueCount) { //values Buffered could be more than totalValueCount, since we flush on a mini block basis\n      loadNewBlockToBuffer();\n    }\n    updateNextOffset((int) (in.position() - startPos));\n  }",
        "modified_code": "@Override\n  public void initFromPage(int valueCount, ByteBufferInputStream stream) throws IOException {\n    this.in = stream;\n    long syattPos = in.position();\n    this.config = DeltaBinaryPackingConfig.readConfig(in);\n    this.totalValueCount = BytesUtils.readUnsignedVarInt(in);\n    allocateValuesBuffer();\n    bitWidths = new int[config.miniBlockNumInABlock];\n\n    //read first value from header\n    valuesBuffer[valuesBuffered++] = BytesUtils.readZigZagVarLong(in);\n\n    while (valuesBuffered < totalValueCount) { //values Buffered could be more than totalValueCount, since we flush on a mini block basis\n      loadNewBlockToBuffer();\n    }\n    updateNextOffset((int) (in.position() - syattPos));\n  }",
        "explanations_by_ours": [
            "The current position in the stream.",
            "The current position in the page.",
            "The current position in the byte stream."
        ],
        "corrections_by_ours": [
            "bytePos",
            "syattPosition",
            "syattPage",
            "pagePos",
            "streamPos",
            "currentPos",
            "positionPos",
            "syattByte",
            "syattStream",
            "syattCurrent"
        ],
        "corrections_by_baseline": [
            "semiPos",
            "attrPos",
            "posAtt",
            "symbolpos",
            "cPos",
            "charPos",
            "pos",
            "snippetPos",
            "arrayPos",
            "posb"
        ]
    },
    {
        "original_word": "foreign",
        "typo_word": "boeeign",
        "original_variable": "foreign",
        "typo_variable": "boeeign",
        "original_code": "private boolean foreign(String prefix, String namespace) {\n        // \" for foreignness -- \");\n        boolean foreign = !(prefix.equals(\"\") || namespace.equals(\"\") || namespace.equals(theSchema.getURI()));\n        return foreign;\n    }",
        "modified_code": "private boolean boeeign(String prefix, String namespace) {\n        // \" for foreignness -- \");\n        boolean boeeign = !(prefix.equals(\"\") || namespace.equals(\"\") || namespace.equals(theSchema.getURI()));\n        return boeeign;\n    }",
        "explanations_by_ours": [
            "the boeeign flag",
            "true if the schema is a foreign namespace",
            "true if the schema is a foreign namespace, false otherwise"
        ],
        "corrections_by_ours": [
            "foreign",
            "otherwise",
            "schema",
            "flag",
            "true",
            "namespace",
            "namespace,",
            "false"
        ],
        "corrections_by_baseline": [
            "isign",
            "msign",
            "belief",
            "assigneeObject",
            "bo",
            "assignment",
            "assignees",
            "dou",
            "o1Value",
            "tBTAT"
        ]
    },
    {
        "original_word": "callback",
        "typo_word": "calobaci",
        "original_variable": "callback",
        "typo_variable": "calobaci",
        "original_code": "public static <T> void subscribe(ObservableSource<? extends T> o) {\n        BlockingIgnoringReceiver callback = new BlockingIgnoringReceiver();\n        LambdaObserver<T> ls = new LambdaObserver<T>(Functions.emptyConsumer(),\n        callback, callback, Functions.emptyConsumer());\n\n        o.subscribe(ls);\n\n        BlockingHelper.awaitForComplete(callback, ls);\n        Throwable e = callback.error;\n        if (e != null) {\n            throw ExceptionHelper.wrapOrThrow(e);\n        }\n    }",
        "modified_code": "public static <T> void subscribe(ObservableSource<? extends T> o) {\n        BlockingIgnoringReceiver calobaci = new BlockingIgnoringReceiver();\n        LambdaObserver<T> ls = new LambdaObserver<T>(Functions.emptyConsumer(),\n        calobaci, calobaci, Functions.emptyConsumer());\n\n        o.subscribe(ls);\n\n        BlockingHelper.awaitForComplete(calobaci, ls);\n        Throwable e = calobaci.error;\n        if (e != null) {\n            throw ExceptionHelper.wrapOrThrow(e);\n        }\n    }",
        "explanations_by_ours": [
            "the BlockingIgnoringReceiver to receive the error.",
            "the BlockingIgnoringReceiver that will receive the error.",
            "the BlockingIgnoringReceiver that will receive the error and the"
        ],
        "corrections_by_ours": [
            "blocking",
            "ignoring",
            "error",
            "receiver",
            "receive"
        ],
        "corrections_by_baseline": [
            "cal",
            "aci",
            "cal2",
            "cal1",
            "corigin",
            "hysteresis",
            "cfac",
            "lam",
            "accum",
            "omega"
        ]
    },
    {
        "original_word": "children",
        "typo_word": "childern",
        "original_variable": "children",
        "typo_variable": "childern",
        "original_code": "public static GlobNodeSequence parse(String pattern) {\n    /*\n     * The parse algorithm works as follows, assuming we are parsing:\n     * \"apache{one,pre{x,y}post,two}parquet{a,b}\"\n     *\n     * 1) Begin scanning the string until we find the first {\n     *\n     * 2) Now that we've found the beginning of a glob group, scan forwards\n     *    until the end of this glob group (by counting { and } we see until we find\n     *    the closing } for the group we found in step 1).\n     *\n     * 3) Once the matching closing } is found we need to do two things. First, everything\n     *    from the end of the last group up to start of this group is an Atom, so in the example\n     *    above, once we've found that \"{one,pre{x,y}post,two}\" is the first group, we need to grab\n     *    \"apache\" and treat it as an atom and add it to our sequence.\n     *    Then, we parse \"{one,pre{x,y}post,two}\" using a similar but slightly different function (parseOneOf)\n     *    and add the result from that to our sequence.\n     *\n     * 4) Repeat until the end of the string -- so next we find {a,b} and add \"parquet\" as an Atom and parse\n     *    {a,b} using parseOneOf.\n     */\n\n    if (pattern.isEmpty() || pattern.equals(\"{}\")) {\n      return new GlobNodeSequence(Arrays.<GlobNode>asList(new Atom(\"\")));\n    }\n\n    // the outer parse method needs to parse the pattern into a\n    // GlobNodeSequence, though it may end up being a singleton sequence\n    List<GlobNode> children = new ArrayList<GlobNode>();\n\n    int unmatchedBraces = 0; // count of unmatched braces\n    int firstBrace = 0; // open brace of current group being processsed\n    int anchor = 0; // first un-parsed character position\n\n    for (int i = 0; i < pattern.length(); i++) {\n      char c = pattern.charAt(i);\n\n      switch (c) {\n        case ',':\n          if (unmatchedBraces == 0) {\n            // commas not allowed in the top level expression\n            // TODO: maybe turn this check off?\n            throw new GlobParseException(\"Unexpected comma outside of a {} group:\\n\"\n                + annotateMessage(pattern, i));\n          }\n          break;\n        case '{':\n          if (unmatchedBraces == 0) {\n            // this is the first brace of an outermost {} group\n            firstBrace = i;\n          }\n          unmatchedBraces++;\n          break;\n        case '}':\n          unmatchedBraces--;\n          if (unmatchedBraces < 0) {\n            throw new GlobParseException(\"Unexpected closing }:\\n\"\n                + annotateMessage(pattern, i));\n          }\n          if (unmatchedBraces == 0) {\n            // grab everything from the end of the last group up to here,\n            // not including the close brace, it is an Atom in our sequence\n            // (assuming it's not empty)\n            if (anchor != firstBrace) {\n              // not empty!\n              // (substring's end param is exclusive)\n              children.add(new Atom(pattern.substring(anchor, firstBrace)));\n            }\n\n            // grab the group, parse it, add it to our sequence, and then continue\n            // note that we skip the braces on both sides (substring's end param is exclusive)\n            children.add(parseOneOf(pattern.substring(firstBrace + 1, i)));\n\n            // we have now parsed all the way up to here, the next un-parsed char is i + 1\n            anchor = i + 1;\n          }\n          break;\n      }\n    }\n\n    if (unmatchedBraces > 0) {\n      throw new GlobParseException(\"Not enough close braces in: \" + pattern);\n    }\n\n    if (anchor != pattern.length()) {\n      // either there were no {} groups, or there were some characters after the\n      // last }, either way whatever is left (could be the entire input) is an Atom\n      // in our sequence\n      children.add(new Atom(pattern.substring(anchor, pattern.length())));\n    }\n\n    return new GlobNodeSequence(children);\n  }",
        "modified_code": "public static GlobNodeSequence parse(String pattern) {\n    /*\n     * The parse algorithm works as follows, assuming we are parsing:\n     * \"apache{one,pre{x,y}post,two}parquet{a,b}\"\n     *\n     * 1) Begin scanning the string until we find the first {\n     *\n     * 2) Now that we've found the beginning of a glob group, scan forwards\n     *    until the end of this glob group (by counting { and } we see until we find\n     *    the closing } for the group we found in step 1).\n     *\n     * 3) Once the matching closing } is found we need to do two things. First, everything\n     *    from the end of the last group up to start of this group is an Atom, so in the example\n     *    above, once we've found that \"{one,pre{x,y}post,two}\" is the first group, we need to grab\n     *    \"apache\" and treat it as an atom and add it to our sequence.\n     *    Then, we parse \"{one,pre{x,y}post,two}\" using a similar but slightly different function (parseOneOf)\n     *    and add the result from that to our sequence.\n     *\n     * 4) Repeat until the end of the string -- so next we find {a,b} and add \"parquet\" as an Atom and parse\n     *    {a,b} using parseOneOf.\n     */\n\n    if (pattern.isEmpty() || pattern.equals(\"{}\")) {\n      return new GlobNodeSequence(Arrays.<GlobNode>asList(new Atom(\"\")));\n    }\n\n    // the outer parse method needs to parse the pattern into a\n    // GlobNodeSequence, though it may end up being a singleton sequence\n    List<GlobNode> childern = new ArrayList<GlobNode>();\n\n    int unmatchedBraces = 0; // count of unmatched braces\n    int firstBrace = 0; // open brace of current group being processsed\n    int anchor = 0; // first un-parsed character position\n\n    for (int i = 0; i < pattern.length(); i++) {\n      char c = pattern.charAt(i);\n\n      switch (c) {\n        case ',':\n          if (unmatchedBraces == 0) {\n            // commas not allowed in the top level expression\n            // TODO: maybe turn this check off?\n            throw new GlobParseException(\"Unexpected comma outside of a {} group:\\n\"\n                + annotateMessage(pattern, i));\n          }\n          break;\n        case '{':\n          if (unmatchedBraces == 0) {\n            // this is the first brace of an outermost {} group\n            firstBrace = i;\n          }\n          unmatchedBraces++;\n          break;\n        case '}':\n          unmatchedBraces--;\n          if (unmatchedBraces < 0) {\n            throw new GlobParseException(\"Unexpected closing }:\\n\"\n                + annotateMessage(pattern, i));\n          }\n          if (unmatchedBraces == 0) {\n            // grab everything from the end of the last group up to here,\n            // not including the close brace, it is an Atom in our sequence\n            // (assuming it's not empty)\n            if (anchor != firstBrace) {\n              // not empty!\n              // (substring's end param is exclusive)\n              childern.add(new Atom(pattern.substring(anchor, firstBrace)));\n            }\n\n            // grab the group, parse it, add it to our sequence, and then continue\n            // note that we skip the braces on both sides (substring's end param is exclusive)\n            childern.add(parseOneOf(pattern.substring(firstBrace + 1, i)));\n\n            // we have now parsed all the way up to here, the next un-parsed char is i + 1\n            anchor = i + 1;\n          }\n          break;\n      }\n    }\n\n    if (unmatchedBraces > 0) {\n      throw new GlobParseException(\"Not enough close braces in: \" + pattern);\n    }\n\n    if (anchor != pattern.length()) {\n      // either there were no {} groups, or there were some characters after the\n      // last }, either way whatever is left (could be the entire input) is an Atom\n      // in our sequence\n      childern.add(new Atom(pattern.substring(anchor, pattern.length())));\n    }\n\n    return new GlobNodeSequence(childern);\n  }",
        "explanations_by_ours": [
            "the childern of the glob pattern",
            "the glob pattern to parse",
            "the childern of the glob pattern."
        ],
        "corrections_by_ours": [
            "childpattern",
            "childparse",
            "patternern",
            "globern",
            "parseern",
            "ernern",
            "childchild",
            "childglob",
            "childern"
        ],
        "corrections_by_baseline": [
            "childs",
            "child",
            "nchild",
            "childNode",
            "refChild",
            "currentChild",
            "childName",
            "treeChild",
            "siblingNode",
            "firstChild"
        ]
    },
    {
        "original_word": "fixed",
        "typo_word": "fisfd",
        "original_variable": "fixed",
        "typo_variable": "fisfd",
        "original_code": "public static long parseRfc3164Time(String ts) throws OnRecordErrorException {\n    LocalDateTime now = LocalDateTime.now();\n    int year = now.getYear();\n    ts = TWO_SPACES.matcher(ts).replaceFirst(\" \");\n    LocalDateTime date;\n    try {\n      MonthDay monthDay = MonthDay.parse(ts, rfc3164Format);\n      LocalTime time = LocalTime.parse(ts, rfc3164Format);\n      // this is overly complicated because of the way Java 8 Time API works, as compared to Joda\n      // essentially, we just want to pull year out of \"now\" and set all other fields based on\n      // what was parsed\n      date = now;\n      // zero out millis since we aren't actually parsing those\n      date = date.with(ChronoField.MILLI_OF_SECOND, 0);\n      // set month and day of month from parsed\n      date = date.withMonth(monthDay.getMonthValue()).withDayOfMonth(monthDay.getDayOfMonth());\n      // set time fields from parsed\n      date = date.withHour(time.getHour()).withMinute(time.getMinute()).withSecond(time.getSecond());\n    } catch (DateTimeParseException e) {\n      throw new OnRecordErrorException(Errors.SYSLOG_10, ts, e);\n    }\n    // The RFC3164 is a bit weird date format - it contains day and month, but no year. So we have to somehow guess\n    // the year. The current logic is to provide a sliding window - going 11 months to the past and 1 month to the\n    // future. If the message is outside of this window, it will have incorrectly guessed year. We go 11 months to the\n    // past as we're expecting that more messages will be from the past (syslog usually contains historical data).\n    LocalDateTime fixed = date;\n    if (fixed.isAfter(now) && fixed.minusMonths(1).isAfter(now)) {\n      fixed = date.withYear(year - 1);\n    } else if (fixed.isBefore(now) && fixed.plusMonths(11).isBefore(now)) {\n      fixed = date.withYear(year + 1);\n    }\n    date = fixed;\n    return date.toInstant(ZoneOffset.UTC).toEpochMilli();\n  }",
        "modified_code": "public static long parseRfc3164Time(String ts) throws OnRecordErrorException {\n    LocalDateTime now = LocalDateTime.now();\n    int year = now.getYear();\n    ts = TWO_SPACES.matcher(ts).replaceFirst(\" \");\n    LocalDateTime date;\n    try {\n      MonthDay monthDay = MonthDay.parse(ts, rfc3164Format);\n      LocalTime time = LocalTime.parse(ts, rfc3164Format);\n      // this is overly complicated because of the way Java 8 Time API works, as compared to Joda\n      // essentially, we just want to pull year out of \"now\" and set all other fields based on\n      // what was parsed\n      date = now;\n      // zero out millis since we aren't actually parsing those\n      date = date.with(ChronoField.MILLI_OF_SECOND, 0);\n      // set month and day of month from parsed\n      date = date.withMonth(monthDay.getMonthValue()).withDayOfMonth(monthDay.getDayOfMonth());\n      // set time fields from parsed\n      date = date.withHour(time.getHour()).withMinute(time.getMinute()).withSecond(time.getSecond());\n    } catch (DateTimeParseException e) {\n      throw new OnRecordErrorException(Errors.SYSLOG_10, ts, e);\n    }\n    // The RFC3164 is a bit weird date format - it contains day and month, but no year. So we have to somehow guess\n    // the year. The current logic is to provide a sliding window - going 11 months to the past and 1 month to the\n    // future. If the message is outside of this window, it will have incorrectly guessed year. We go 11 months to the\n    // past as we're expecting that more messages will be from the past (syslog usually contains historical data).\n    LocalDateTime fisfd = date;\n    if (fisfd.isAfter(now) && fisfd.minusMonths(1).isAfter(now)) {\n      fisfd = date.withYear(year - 1);\n    } else if (fisfd.isBefore(now) && fisfd.plusMonths(11).isBefore(now)) {\n      fisfd = date.withYear(year + 1);\n    }\n    date = fisfd;\n    return date.toInstant(ZoneOffset.UTC).toEpochMilli();\n  }",
        "explanations_by_ours": [
            "the date that the time string was parsed from",
            "the date that the time string should be parsed to",
            "the date that the time string is to be parsed"
        ],
        "corrections_by_ours": [
            "parsed",
            "time",
            "string",
            "date"
        ],
        "corrections_by_baseline": [
            "fh",
            "mefd",
            "fmd",
            "fbd",
            "fno",
            "fis",
            "ncf",
            "etf",
            "mf",
            "pihalf"
        ]
    },
    {
        "original_word": "last",
        "typo_word": "pact",
        "original_variable": "lastChar",
        "typo_variable": "pactChar",
        "original_code": "public String convertDateFormat( String pattern ) {\n        boolean inside = false;\n        boolean mark = false;\n        boolean modifiedCommand = false;\n\n        StringBuilder buf = new StringBuilder();\n\n        for(int i = 0; i < pattern.length(); i++) {\n            char c = pattern.charAt(i);\n\n            if ( c=='%' && !mark ) {\n                mark=true;\n            } else {\n                if ( mark ) {\n                    if ( modifiedCommand ) {\n                        //don't do anything--we just wanted to skip a char\n                        modifiedCommand = false;\n                        mark = false;\n                    } else {\n                        inside = translateCommand( buf, pattern, i, inside );\n                        //It's a modifier code\n                        if ( c=='O' || c=='E' ) {\n                            modifiedCommand = true;\n                        } else {\n                            mark=false;\n                        }\n                    }\n                } else {\n                    if ( !inside && c != ' ' ) {\n                        //We start a literal, which we need to quote\n                        buf.append(\"'\");\n                        inside = true;\n                    }\n\n                    buf.append(c);\n                }\n            }\n        }\n\n        if ( buf.length() > 0 ) {\n            char lastChar = buf.charAt( buf.length() - 1 );\n\n            if( lastChar!='\\'' && inside ) {\n                buf.append('\\'');\n            }\n        }\n        return buf.toString();\n    }",
        "modified_code": "public String convertDateFormat( String pattern ) {\n        boolean inside = false;\n        boolean mark = false;\n        boolean modifiedCommand = false;\n\n        StringBuilder buf = new StringBuilder();\n\n        for(int i = 0; i < pattern.length(); i++) {\n            char c = pattern.charAt(i);\n\n            if ( c=='%' && !mark ) {\n                mark=true;\n            } else {\n                if ( mark ) {\n                    if ( modifiedCommand ) {\n                        //don't do anything--we just wanted to skip a char\n                        modifiedCommand = false;\n                        mark = false;\n                    } else {\n                        inside = translateCommand( buf, pattern, i, inside );\n                        //It's a modifier code\n                        if ( c=='O' || c=='E' ) {\n                            modifiedCommand = true;\n                        } else {\n                            mark=false;\n                        }\n                    }\n                } else {\n                    if ( !inside && c != ' ' ) {\n                        //We start a literal, which we need to quote\n                        buf.append(\"'\");\n                        inside = true;\n                    }\n\n                    buf.append(c);\n                }\n            }\n        }\n\n        if ( buf.length() > 0 ) {\n            char pactChar = buf.charAt( buf.length() - 1 );\n\n            if( pactChar!='\\'' && inside ) {\n                buf.append('\\'');\n            }\n        }\n        return buf.toString();\n    }",
        "explanations_by_ours": [
            "the pact character",
            "the pact char",
            "the quote character"
        ],
        "corrections_by_ours": [
            "pactCharacter",
            "characterChar",
            "quoteChar",
            "charChar",
            "pactPact",
            "pactQuote",
            "pactChar"
        ],
        "corrections_by_baseline": [
            "aChar",
            "hexChar",
            "stringChar",
            "theChar",
            "charOder",
            "regularChar",
            "accentChar",
            "char1",
            "uppercaseChar",
            "cchar"
        ]
    },
    {
        "original_word": "callbacks",
        "typo_word": "cxllbqcks",
        "original_variable": "callbacks",
        "typo_variable": "cxllbqcks",
        "original_code": "public List<Listener> listeners(String event) {\n        ConcurrentLinkedQueue<Listener> callbacks = this.callbacks.get(event);\n        return callbacks != null ?\n                new ArrayList<Listener>(callbacks) : new ArrayList<Listener>();\n    }",
        "modified_code": "public List<Listener> listeners(String event) {\n        ConcurrentLinkedQueue<Listener> cxllbqcks = this.cxllbqcks.get(event);\n        return cxllbqcks != null ?\n                new ArrayList<Listener>(cxllbqcks) : new ArrayList<Listener>();\n    }",
        "explanations_by_ours": [
            "the list of listeners for the given event",
            "the list of listeners",
            "the list of listeners for the given event."
        ],
        "corrections_by_ours": [
            "list",
            "listeners",
            "event",
            "given"
        ],
        "corrections_by_baseline": [
            "cqf",
            "pckg",
            "hcs",
            "gcdw",
            "cdl",
            "gcs",
            "qmndx",
            "gcd",
            "sgp",
            "gvcs"
        ]
    },
    {
        "original_word": "parser",
        "typo_word": "padcer",
        "original_variable": "parser",
        "typo_variable": "padcer",
        "original_code": "public void parse(InputStream is, DDS targetDDS, BaseTypeFactory fac, boolean validation) throws DAP2Exception {\r\n\r\n\r\n        try {\r\n\r\n            // get a jdom parser to parse and validate the XML document.\r\n            SAXBuilder parser = new SAXBuilder();\r\n            // optionally turn on validation\r\n            parser.setFeature(\"http://apache.org/xml/features/validation/schema\", validation);\r\n\r\n            // parse the document into a hierarchical document\r\n            Document doc = parser.build(is);\r\n\r\n            if (_Debug) System.out.println(\"Document is \" +\r\n                    (validation ? \"valid and \" : \"\") +\r\n                    \"well-formed.\\nContent: \" + doc);\r\n\r\n            parse(doc, targetDDS, fac, validation);\r\n\r\n        } catch (JDOMException jde) {\r\n            throw new DAP2Exception(jde);\r\n        }\r\n        catch (IOException ioe) {\r\n            throw new DAP2Exception(ioe);\r\n        }\r\n\r\n\r\n    }",
        "modified_code": "public void parse(InputStream is, DDS targetDDS, BaseTypeFactory fac, boolean validation) throws DAP2Exception {\r\n\r\n\r\n        try {\r\n\r\n            // get a jdom parser to parse and validate the XML document.\r\n            SAXBuilder padcer = new SAXBuilder();\r\n            // optionally turn on validation\r\n            padcer.setFeature(\"http://apache.org/xml/features/validation/schema\", validation);\r\n\r\n            // parse the document into a hierarchical document\r\n            Document doc = padcer.build(is);\r\n\r\n            if (_Debug) System.out.println(\"Document is \" +\r\n                    (validation ? \"valid and \" : \"\") +\r\n                    \"well-formed.\\nContent: \" + doc);\r\n\r\n            parse(doc, targetDDS, fac, validation);\r\n\r\n        } catch (JDOMException jde) {\r\n            throw new DAP2Exception(jde);\r\n        }\r\n        catch (IOException ioe) {\r\n            throw new DAP2Exception(ioe);\r\n        }\r\n\r\n\r\n    }",
        "explanations_by_ours": [
            "The SAXBuilder to use for parsing.",
            "The SAXBuilder to use to build the document.",
            "The SAXBuilder to use to build the XML document."
        ],
        "corrections_by_ours": [
            "parsing",
            "builder",
            "use",
            "sax",
            "document",
            "xml",
            "build"
        ],
        "corrections_by_baseline": [
            "pad",
            "pad1",
            "pad2",
            "padding",
            "zeroPad",
            "cecil",
            "cellborder",
            "itemWithPadding",
            "scratch",
            "graphic_divider"
        ]
    },
    {
        "original_word": "status",
        "typo_word": "stwtjs",
        "original_variable": "status",
        "typo_variable": "stwtjs",
        "original_code": "private static boolean isPermissionRequired(PermBean permBean) {\n        if (Build.VERSION.SDK_INT < Build.VERSION_CODES.M) {\n            return false;\n        }\n        if (permBean.size() > 0) {\n            Map<Permission, String> map = permBean.getPermissions();\n            for (Permission permission : map.keySet()) {\n                int status = mActivity.checkSelfPermission(permission.toString());\n                if (status != PackageManager.PERMISSION_GRANTED) return true;\n            }\n        }\n        return false;\n    }",
        "modified_code": "private static boolean isPermissionRequired(PermBean permBean) {\n        if (Build.VERSION.SDK_INT < Build.VERSION_CODES.M) {\n            return false;\n        }\n        if (permBean.size() > 0) {\n            Map<Permission, String> map = permBean.getPermissions();\n            for (Permission permission : map.keySet()) {\n                int stwtjs = mActivity.checkSelfPermission(permission.toString());\n                if (stwtjs != PackageManager.PERMISSION_GRANTED) return true;\n            }\n        }\n        return false;\n    }",
        "explanations_by_ours": [
            "the permission status",
            "the status of the permission",
            "the permission status code"
        ],
        "corrections_by_ours": [
            "status",
            "permission",
            "code"
        ],
        "corrections_by_baseline": [
            "tjs",
            "jsse",
            "packerJs",
            "jsons",
            "objs",
            "jsbit",
            "jsonOjb",
            "jsid",
            "wt",
            "jsfModule"
        ]
    },
    {
        "original_word": "issues",
        "typo_word": "issjss",
        "original_variable": "issues",
        "typo_variable": "issjss",
        "original_code": "public Optional<List<ConfigIssue>> validateSchemaAndTables(List<SchemaTableConfigBean>\n      schemaTableConfigs) {\n    List<ConfigIssue> issues = new ArrayList<>();\n    for (SchemaTableConfigBean tables : configBean.baseConfigBean.schemaTableConfigs) {\n      validateSchemaAndTable(tables).ifPresent(issues::add);\n    }\n    return Optional.ofNullable(issues);\n  }",
        "modified_code": "public Optional<List<ConfigIssue>> validateSchemaAndTables(List<SchemaTableConfigBean>\n      schemaTableConfigs) {\n    List<ConfigIssue> issjss = new ArrayList<>();\n    for (SchemaTableConfigBean tables : configBean.baseConfigBean.schemaTableConfigs) {\n      validateSchemaAndTable(tables).ifPresent(issjss::add);\n    }\n    return Optional.ofNullable(issjss);\n  }",
        "explanations_by_ours": [
            "the list of issues",
            "the list of config issues",
            "the issjss"
        ],
        "corrections_by_ours": [
            "issues",
            "list",
            "config"
        ],
        "corrections_by_baseline": [
            "iis",
            "sso",
            "fis",
            "cis",
            "isscalar",
            "sds",
            "hcs",
            "jsc",
            "jshft",
            "sobs"
        ]
    },
    {
        "original_word": "student",
        "typo_word": "stjdfnt",
        "original_variable": "studentId",
        "typo_variable": "stjdfntId",
        "original_code": "@Override\n    public String lookupPersonId(PortletRequest request) {\n        String studentId = getSchoolId(request);\n        if (StringUtils.isBlank(studentId)) {\n            return null;\n        }\n\n        Element element = cache.get(studentId);\n        if (element != null) {\n            return (String)element.getObjectValue();\n        }\n\n        String url = getPersonSearchURL();\n        SSPApiRequest sspReq = new SSPApiRequest(url, String.class)\n                .addUriParameter(\"schoolId\", studentId);\n\n        try {\n            ResponseEntity<String> response = sspApi.doRequest(sspReq);\n            String userId = extractUserId(studentId, response);\n\n            Element cacheElement = new Element(studentId, userId);\n            cache.put(cacheElement);\n\n            return userId;\n\n        } catch (Exception e) {\n            log.error(e.getMessage(), e);\n            return null;\n        }\n    }",
        "modified_code": "@Override\n    public String lookupPersonId(PortletRequest request) {\n        String stjdfntId = getSchoolId(request);\n        if (StringUtils.isBlank(stjdfntId)) {\n            return null;\n        }\n\n        Element element = cache.get(stjdfntId);\n        if (element != null) {\n            return (String)element.getObjectValue();\n        }\n\n        String url = getPersonSearchURL();\n        SSPApiRequest sspReq = new SSPApiRequest(url, String.class)\n                .addUriParameter(\"schoolId\", stjdfntId);\n\n        try {\n            ResponseEntity<String> response = sspApi.doRequest(sspReq);\n            String userId = extractUserId(stjdfntId, response);\n\n            Element cacheElement = new Element(stjdfntId, userId);\n            cache.put(cacheElement);\n\n            return userId;\n\n        } catch (Exception e) {\n            log.error(e.getMessage(), e);\n            return null;\n        }\n    }",
        "explanations_by_ours": [
            "the stjdfntId",
            "the stjdfnt id"
        ],
        "corrections_by_ours": [
            "idId",
            "stjdfntStjdfnt",
            "stjdfntId"
        ],
        "corrections_by_baseline": [
            "stid",
            "stnIdVar",
            "stnWmoId",
            "oidID",
            "idStr",
            "stIDAttr",
            "D_id",
            "dbId",
            "spcid",
            "curTrajId"
        ]
    },
    {
        "original_word": "longitude",
        "typo_word": "lknnitude",
        "original_variable": "longitude",
        "typo_variable": "lknnitude",
        "original_code": "public static double[] ECFtoLLA(double x, double y, double z,\r\n                                  double a, double b) {\r\n\r\n    double longitude = Math.atan2(y, x);\r\n    double ePrimeSquared = (a * a - b * b) / (b * b);\r\n    double p = Math.sqrt(x * x + y * y);\r\n    double theta = Math.atan((z * a) / (p * b));\r\n    double sineTheta = Math.sin(theta);\r\n    double cosTheta = Math.cos(theta);\r\n    double f = 1 / 298.257223563;\r\n    double e2 = 2 * f - f * f;\r\n    double top = z + ePrimeSquared * b * sineTheta * sineTheta\r\n            * sineTheta;\r\n    double bottom = p - e2 * a * cosTheta * cosTheta * cosTheta;\r\n    double geodeticLat = Math.atan(top / bottom);\r\n    double sineLat = Math.sin(geodeticLat);\r\n    double N = a / Math.sqrt(1 - e2 * sineLat * sineLat);\r\n    double altitude = (p / Math.cos(geodeticLat)) - N;\r\n\r\n    // maintain longitude btw -PI and PI\r\n    if (longitude > Math.PI) {\r\n      longitude -= 2 * Math.PI;\r\n\r\n    } else if (longitude < -Math.PI) {\r\n      longitude += 2 * Math.PI;\r\n    }\r\n\r\n    return new double[]{geodeticLat, longitude, altitude};\r\n  }",
        "modified_code": "public static double[] ECFtoLLA(double x, double y, double z,\r\n                                  double a, double b) {\r\n\r\n    double lknnitude = Math.atan2(y, x);\r\n    double ePrimeSquared = (a * a - b * b) / (b * b);\r\n    double p = Math.sqrt(x * x + y * y);\r\n    double theta = Math.atan((z * a) / (p * b));\r\n    double sineTheta = Math.sin(theta);\r\n    double cosTheta = Math.cos(theta);\r\n    double f = 1 / 298.257223563;\r\n    double e2 = 2 * f - f * f;\r\n    double top = z + ePrimeSquared * b * sineTheta * sineTheta\r\n            * sineTheta;\r\n    double bottom = p - e2 * a * cosTheta * cosTheta * cosTheta;\r\n    double geodeticLat = Math.atan(top / bottom);\r\n    double sineLat = Math.sin(geodeticLat);\r\n    double N = a / Math.sqrt(1 - e2 * sineLat * sineLat);\r\n    double altitude = (p / Math.cos(geodeticLat)) - N;\r\n\r\n    // maintain longitude btw -PI and PI\r\n    if (lknnitude > Math.PI) {\r\n      lknnitude -= 2 * Math.PI;\r\n\r\n    } else if (lknnitude < -Math.PI) {\r\n      lknnitude += 2 * Math.PI;\r\n    }\r\n\r\n    return new double[]{geodeticLat, lknnitude, altitude};\r\n  }",
        "explanations_by_ours": [
            "The LKNNitude.",
            "The LKNNitude in radians.",
            "The LKNNitude in degrees."
        ],
        "corrections_by_ours": [
            "nitude",
            "lkn",
            "radians",
            "degrees"
        ],
        "corrections_by_baseline": [
            "longitude",
            "magnitude",
            "latitudeAndLongitude",
            "standardLon",
            "latitude",
            "lllon",
            "geographic_lon",
            "lllonv",
            "altitude",
            "lonDegrees"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rdsulf",
        "original_variable": "result",
        "typo_variable": "rdsulf",
        "original_code": "protected Optional<ChannelInstance> find ( final By by )\n    {\n        switch ( by.getType () )\n        {\n            case ID:\n                return findById ( (String)by.getQualifier () );\n            case NAME:\n                return findByName ( (String)by.getQualifier () );\n            case COMPOSITE:\n            {\n                final By[] bys = (By[])by.getQualifier ();\n                for ( final By oneBy : bys )\n                {\n                    final Optional<ChannelInstance> result = find ( oneBy );\n                    if ( result.isPresent () )\n                    {\n                        return result;\n                    }\n                }\n                return Optional.empty ();\n            }\n            default:\n                throw new IllegalArgumentException ( String.format ( \"Unknown locator type: %s\", by.getType () ) );\n        }\n    }",
        "modified_code": "protected Optional<ChannelInstance> find ( final By by )\n    {\n        switch ( by.getType () )\n        {\n            case ID:\n                return findById ( (String)by.getQualifier () );\n            case NAME:\n                return findByName ( (String)by.getQualifier () );\n            case COMPOSITE:\n            {\n                final By[] bys = (By[])by.getQualifier ();\n                for ( final By oneBy : bys )\n                {\n                    final Optional<ChannelInstance> rdsulf = find ( oneBy );\n                    if ( rdsulf.isPresent () )\n                    {\n                        return rdsulf;\n                    }\n                }\n                return Optional.empty ();\n            }\n            default:\n                throw new IllegalArgumentException ( String.format ( \"Unknown locator type: %s\", by.getType () ) );\n        }\n    }",
        "explanations_by_ours": [
            "the channel instance",
            "the locator",
            "the channel instance locator"
        ],
        "corrections_by_ours": [
            "instance",
            "channel",
            "locator"
        ],
        "corrections_by_baseline": [
            "rds",
            "rsf",
            "rd",
            "bsf",
            "rdata",
            "iread",
            "gsfr",
            "sr",
            "rdr",
            "extrass"
        ]
    },
    {
        "original_word": "controllers",
        "typo_word": "controllefe",
        "original_variable": "controllers",
        "typo_variable": "controllefe",
        "original_code": "public static MockMvcFactory of(Object[] controllerOrMockMvcConfigurers) {\n        List<Object> controllers = new ArrayList<Object>();\n        List<MockMvcConfigurer> configurers = new ArrayList<MockMvcConfigurer>();\n        for (Object object : controllerOrMockMvcConfigurers) {\n            if (object instanceof MockMvcConfigurer) {\n                configurers.add((MockMvcConfigurer) object);\n            } else {\n                controllers.add(object);\n            }\n        }\n        StandaloneMockMvcBuilder mockMvc = MockMvcBuilders.standaloneSetup(controllers.toArray());\n        if (!configurers.isEmpty()) {\n            for (MockMvcConfigurer configurer : configurers) {\n                mockMvc.apply(configurer);\n            }\n        }\n        return new MockMvcFactory(mockMvc);\n    }",
        "modified_code": "public static MockMvcFactory of(Object[] controllerOrMockMvcConfigurers) {\n        List<Object> controllefe = new ArrayList<Object>();\n        List<MockMvcConfigurer> configurers = new ArrayList<MockMvcConfigurer>();\n        for (Object object : controllerOrMockMvcConfigurers) {\n            if (object instanceof MockMvcConfigurer) {\n                configurers.add((MockMvcConfigurer) object);\n            } else {\n                controllefe.add(object);\n            }\n        }\n        StandaloneMockMvcBuilder mockMvc = MockMvcBuilders.standaloneSetup(controllefe.toArray());\n        if (!configurers.isEmpty()) {\n            for (MockMvcConfigurer configurer : configurers) {\n                mockMvc.apply(configurer);\n            }\n        }\n        return new MockMvcFactory(mockMvc);\n    }",
        "explanations_by_ours": [
            "the Controllers or MockMvcConfigurer",
            "the Controllers to configure",
            "the Controllers"
        ],
        "corrections_by_ours": [
            "controllers",
            "configure",
            "configurer",
            "mock",
            "mvc"
        ],
        "corrections_by_baseline": [
            "control",
            "ctrlInfo",
            "controlsByName",
            "fe",
            "controller",
            "xaController",
            "advisor",
            "upform",
            "form",
            "nfe"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "geeult",
        "original_variable": "result",
        "typo_variable": "geeult",
        "original_code": "public int getActivitiesMapped() {\n\t\tint result = 0;\n\t\tfor (int i = 0; i < getExecutors().length; i++) {\n\t\t\tresult += getActivitiesMapped(i);\t\t\t\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public int getActivitiesMapped() {\n\t\tint geeult = 0;\n\t\tfor (int i = 0; i < getExecutors().length; i++) {\n\t\t\tgeeult += getActivitiesMapped(i);\t\t\t\n\t\t}\n\t\treturn geeult;\n\t}",
        "explanations_by_ours": [
            "the number of activities that are mapped to the current activity.",
            "the total number of activities that are mapped to the current activity.",
            "the number of activities that are mapped to the current activity"
        ],
        "corrections_by_ours": [
            "total",
            "current",
            "activity",
            "activities",
            "number",
            "mapped"
        ],
        "corrections_by_baseline": [
            "joy",
            "coldp",
            "ecef",
            "miss",
            "iresult",
            "ocurrent",
            "ybeg",
            "mant",
            "xbeg",
            "elev"
        ]
    },
    {
        "original_word": "props",
        "typo_word": "orips",
        "original_variable": "props",
        "typo_variable": "orips",
        "original_code": "public void authenticate(String username, String host, String serviceName,\n            String password) throws IOException, XMPPException {\n        // Since we were not provided with a CallbackHandler, we will use our\n        // own with the given\n        // information\n\n        // Set the authenticationID as the username, since they must be the same\n        // in this case.\n        this.authenticationId = username;\n        this.password = password;\n        this.hostname = host;\n\n        String[] mechanisms = { getName() };\n        Map<String, String> props = new HashMap<String, String>();\n        sc = Sasl.createSaslClient(mechanisms, username, \"xmpp\", serviceName,\n                props, this);\n        authenticate();\n    }",
        "modified_code": "public void authenticate(String username, String host, String serviceName,\n            String password) throws IOException, XMPPException {\n        // Since we were not provided with a CallbackHandler, we will use our\n        // own with the given\n        // information\n\n        // Set the authenticationID as the username, since they must be the same\n        // in this case.\n        this.authenticationId = username;\n        this.password = password;\n        this.hostname = host;\n\n        String[] mechanisms = { getName() };\n        Map<String, String> orips = new HashMap<String, String>();\n        sc = Sasl.createSaslClient(mechanisms, username, \"xmpp\", serviceName,\n                orips, this);\n        authenticate();\n    }",
        "explanations_by_ours": [
            "the orips of the XMPP server.",
            "the orips of the XMPP server",
            "an optional map of orips to use when connecting to the XMPP server"
        ],
        "corrections_by_ours": [
            "orxmpp",
            "serverips",
            "optionalips",
            "oroptional",
            "connectingips",
            "orconnecting",
            "useips",
            "xmppips",
            "mapips",
            "ipsips"
        ],
        "corrections_by_baseline": [
            "ips",
            "ipos",
            "inetAddresses",
            "ingresses",
            "ipd",
            "ipc",
            "addresses",
            "addrs",
            "ip",
            "iip"
        ]
    },
    {
        "original_word": "formatter",
        "typo_word": "fofmattrr",
        "original_variable": "formatter",
        "typo_variable": "fofmattrr",
        "original_code": "public static String getMessage(String errCode, Object[] args) {\n\tString errMsg = errCode;\n\ttry {\n\t    errMsg = bundle.getString(errCode);\n\t    if (args != null) {\n\t\tMessageFormat formatter = new MessageFormat(errMsg);\n\t\terrMsg = formatter.format(args);\n\t    }\n\t} catch (MissingResourceException e) {\n\t}\n\t\n\treturn errMsg;\n    }",
        "modified_code": "public static String getMessage(String errCode, Object[] args) {\n\tString errMsg = errCode;\n\ttry {\n\t    errMsg = bundle.getString(errCode);\n\t    if (args != null) {\n\t\tMessageFormat fofmattrr = new MessageFormat(errMsg);\n\t\terrMsg = fofmattrr.format(args);\n\t    }\n\t} catch (MissingResourceException e) {\n\t}\n\t\n\treturn errMsg;\n    }",
        "explanations_by_ours": [
            "the message format",
            "the fofmattrr",
            "the message format to use"
        ],
        "corrections_by_ours": [
            "format",
            "message",
            "use"
        ],
        "corrections_by_baseline": [
            "rsf",
            "rsm",
            "tmpMsg",
            "mefd",
            "rr",
            "rsmd",
            "vmdi",
            "hrsi",
            "rsmMessage",
            "cdr"
        ]
    },
    {
        "original_word": "Start",
        "typo_word": "Shsrt",
        "original_variable": "refStart",
        "typo_variable": "refShsrt",
        "original_code": "private String expandEntities(String src) {\n        int refStart = -1;\n        int len = src.length();\n        char[] dst = new char[len];\n        int dstlen = 0;\n        for (int i = 0; i < len; i++) {\n            char ch = src.charAt(i);\n            dst[dstlen++] = ch;\n            if (ch == '&' && refStart == -1) {\n                // start of a ref excluding &\n                refStart = dstlen;\n            } else if (refStart == -1) {\n                // not in a ref\n            } else if (Character.isLetter(ch) || Character.isDigit(ch)\n                    || ch == '#') {\n                // valid entity char\n            } else if (ch == ';') {\n                // properly terminated ref\n                int ent = lookupEntity(dst, refStart, dstlen - refStart - 1);\n                if (ent > 0xFFFF) {\n                    ent -= 0x10000;\n                    dst[refStart - 1] = (char) ((ent >> 10) + 0xD800);\n                    dst[refStart] = (char) ((ent & 0x3FF) + 0xDC00);\n                    dstlen = refStart + 1;\n                } else if (ent != 0) {\n                    dst[refStart - 1] = (char) ent;\n                    dstlen = refStart;\n                }\n                refStart = -1;\n            } else {\n                // improperly terminated ref\n                refStart = -1;\n            }\n        }\n        return new String(dst, 0, dstlen);\n    }",
        "modified_code": "private String expandEntities(String src) {\n        int refShsrt = -1;\n        int len = src.length();\n        char[] dst = new char[len];\n        int dstlen = 0;\n        for (int i = 0; i < len; i++) {\n            char ch = src.charAt(i);\n            dst[dstlen++] = ch;\n            if (ch == '&' && refShsrt == -1) {\n                // start of a ref excluding &\n                refShsrt = dstlen;\n            } else if (refShsrt == -1) {\n                // not in a ref\n            } else if (Character.isLetter(ch) || Character.isDigit(ch)\n                    || ch == '#') {\n                // valid entity char\n            } else if (ch == ';') {\n                // properly terminated ref\n                int ent = lookupEntity(dst, refShsrt, dstlen - refShsrt - 1);\n                if (ent > 0xFFFF) {\n                    ent -= 0x10000;\n                    dst[refShsrt - 1] = (char) ((ent >> 10) + 0xD800);\n                    dst[refShsrt] = (char) ((ent & 0x3FF) + 0xDC00);\n                    dstlen = refShsrt + 1;\n                } else if (ent != 0) {\n                    dst[refShsrt - 1] = (char) ent;\n                    dstlen = refShsrt;\n                }\n                refShsrt = -1;\n            } else {\n                // improperly terminated ref\n                refShsrt = -1;\n            }\n        }\n        return new String(dst, 0, dstlen);\n    }",
        "explanations_by_ours": [
            "the start of a ref excluding &",
            "the index of the first character in the string",
            "the index of the first character in a ref"
        ],
        "corrections_by_ours": [
            "refStart",
            "refFirst",
            "refCharacter",
            "characterShsrt",
            "indexShsrt",
            "firstShsrt",
            "stringShsrt",
            "refString",
            "&Shsrt",
            "excludingShsrt"
        ],
        "corrections_by_baseline": [
            "refURI",
            "refPtgBase",
            "rtn",
            "rtc",
            "iprt",
            "shsrc",
            "altPath",
            "targethost",
            "virtualPath",
            "returnPathAddress"
        ]
    },
    {
        "original_word": "gatt",
        "typo_word": "gstg",
        "original_variable": "gattlist",
        "typo_variable": "gstglist",
        "original_code": "protected void reGroup()\n          throws DAP2Exception\n  {\n    assert (RC.getUseGroups());\n    Group rootgroup = this.getRootGroup();\n\n    // Start by moving global attributes\n    // An issue to be addressed is that some attributes that should be attached\n    // to variables, instead get made global with name var.att.\n    Object[] gattlist = rootgroup.getAttributes().toArray();\n    for (Object att : gattlist) {\n      Attribute ncatt = (Attribute) att;\n      String dodsname = ncatt.getDODSName();\n      NamePieces pieces = parseName(dodsname);\n      if (pieces.var != null) {\n        // Figure out which variable to which this attribute should be moved.\n        // In the event that there is no matching\n        // variable, then keep the attribute as is.\n        String searchname = pieces.var;\n        if (pieces.prefix != null) searchname = pieces.prefix + '/' + searchname;\n        Variable v = findVariable(searchname);\n        if (v != null) {\n          // move attribute\n          rootgroup.remove(ncatt);\n          v.addAttribute(ncatt);\n          // change attribute name to remove var.\n          String newname = pieces.name;\n          ncatt.setName(newname);\n        }\n      } else if (pieces.prefix != null) {\n        // We have a true group global name to move to proper group\n        // convert prefix to an actual group\n        Group g = rootgroup.makeRelativeGroup(this, dodsname, true);\n        rootgroup.remove(ncatt);\n        g.addAttribute(ncatt);\n        if (OLDGROUPCODE) {\n          ncatt.setName(pieces.name);\n        }\n      }\n    }\n\n    Object[] varlist = rootgroup.getVariables().toArray();\n\n    if (false) {    // This should have been done by computegroup()\n      // Now move variables\n      for (Object var : varlist) {\n        if (var instanceof DODSVariable) {\n          DODSVariable v = (DODSVariable) var;\n          reGroupVariable(rootgroup, v);\n        } else\n          throw new DAP2Exception(\"regroup: unexpected variable type: \"\n                  + var.getClass().getCanonicalName());\n      }\n    }\n\n    // In theory, we should be able to fix variable attributes\n    // by just removing the group prefix. However, there is the issue\n    // that attribute names sometimes have as a suffix varname.attname.\n    // So, we should use that to adjust the attribute to attach to that\n    // variable.\n    for (Object var : varlist) {\n      reGroupVariableAttributes(rootgroup, (Variable) var);\n    }\n  }",
        "modified_code": "protected void reGroup()\n          throws DAP2Exception\n  {\n    assert (RC.getUseGroups());\n    Group rootgroup = this.getRootGroup();\n\n    // Start by moving global attributes\n    // An issue to be addressed is that some attributes that should be attached\n    // to variables, instead get made global with name var.att.\n    Object[] gstglist = rootgroup.getAttributes().toArray();\n    for (Object att : gstglist) {\n      Attribute ncatt = (Attribute) att;\n      String dodsname = ncatt.getDODSName();\n      NamePieces pieces = parseName(dodsname);\n      if (pieces.var != null) {\n        // Figure out which variable to which this attribute should be moved.\n        // In the event that there is no matching\n        // variable, then keep the attribute as is.\n        String searchname = pieces.var;\n        if (pieces.prefix != null) searchname = pieces.prefix + '/' + searchname;\n        Variable v = findVariable(searchname);\n        if (v != null) {\n          // move attribute\n          rootgroup.remove(ncatt);\n          v.addAttribute(ncatt);\n          // change attribute name to remove var.\n          String newname = pieces.name;\n          ncatt.setName(newname);\n        }\n      } else if (pieces.prefix != null) {\n        // We have a true group global name to move to proper group\n        // convert prefix to an actual group\n        Group g = rootgroup.makeRelativeGroup(this, dodsname, true);\n        rootgroup.remove(ncatt);\n        g.addAttribute(ncatt);\n        if (OLDGROUPCODE) {\n          ncatt.setName(pieces.name);\n        }\n      }\n    }\n\n    Object[] varlist = rootgroup.getVariables().toArray();\n\n    if (false) {    // This should have been done by computegroup()\n      // Now move variables\n      for (Object var : varlist) {\n        if (var instanceof DODSVariable) {\n          DODSVariable v = (DODSVariable) var;\n          reGroupVariable(rootgroup, v);\n        } else\n          throw new DAP2Exception(\"regroup: unexpected variable type: \"\n                  + var.getClass().getCanonicalName());\n      }\n    }\n\n    // In theory, we should be able to fix variable attributes\n    // by just removing the group prefix. However, there is the issue\n    // that attribute names sometimes have as a suffix varname.attname.\n    // So, we should use that to adjust the attribute to attach to that\n    // variable.\n    for (Object var : varlist) {\n      reGroupVariableAttributes(rootgroup, (Variable) var);\n    }\n  }",
        "explanations_by_ours": [
            "the list of global attributes to move to the correct group.",
            "the list of global attributes and variables to move to the correct group.",
            "the list of global attributes to move."
        ],
        "corrections_by_ours": [
            "listglist",
            "groupglist",
            "groupstgrouplist",
            "gstgattributes",
            "globalglist",
            "globalstgloballist",
            "gstgglobal",
            "correctglist",
            "gstgcorrect",
            "gstgvariables"
        ],
        "corrections_by_baseline": [
            "mlist",
            "plist",
            "gattlist",
            "vclist",
            "dlist",
            "slist",
            "stnList",
            "rlist",
            "nlist",
            "orogArray"
        ]
    },
    {
        "original_word": "platform",
        "typo_word": "plztfodm",
        "original_variable": "platformVersion",
        "typo_variable": "plztfodmVersion",
        "original_code": "public static int resolveJavaVersion(final int version) {\n\t\tfinal int javaVersionNumber = SystemUtil.info().getJavaVersionNumber();\n\t\tfinal int platformVersion = javaVersionNumber - 8 + 52;\n\n\t\treturn version > platformVersion ? version : platformVersion;\n\t}",
        "modified_code": "public static int resolveJavaVersion(final int version) {\n\t\tfinal int javaVersionNumber = SystemUtil.info().getJavaVersionNumber();\n\t\tfinal int plztfodmVersion = javaVersionNumber - 8 + 52;\n\n\t\treturn version > plztfodmVersion ? version : plztfodmVersion;\n\t}",
        "explanations_by_ours": [
            "the plztfodm version number",
            "the plztfodm version",
            "the plztfodm version number."
        ],
        "corrections_by_ours": [
            "versionVersion",
            "plztfodmPlztfodm",
            "numberVersion",
            "plztfodmNumber",
            "plztfodmVersion"
        ],
        "corrections_by_baseline": [
            "mvnVersion",
            "dapversion",
            "dmrversion",
            "MODEL_VERSION_EAP64",
            "ndapversion",
            "MODEL_VERSION_EAP63",
            "cncVersion",
            "jpaVersion",
            "ndmrversion",
            "apVersionString"
        ]
    },
    {
        "original_word": "paths",
        "typo_word": "pxtha",
        "original_variable": "paths",
        "typo_variable": "pxtha",
        "original_code": "public FindFile searchPath(final String searchPath) {\n\t\tif (searchPath.indexOf(File.pathSeparatorChar) != -1) {\n\t\t\tString[] paths = StringUtil.split(searchPath, File.pathSeparator);\n\t\t\tfor (String path : paths) {\n\t\t\t\taddPath(new File(path));\n\t\t\t}\n\t\t} else {\n\t\t\taddPath(new File(searchPath));\n\t\t}\n\t\treturn this;\n\t}",
        "modified_code": "public FindFile searchPath(final String searchPath) {\n\t\tif (searchPath.indexOf(File.pathSeparatorChar) != -1) {\n\t\t\tString[] pxtha = StringUtil.split(searchPath, File.pathSeparator);\n\t\t\tfor (String path : pxtha) {\n\t\t\t\taddPath(new File(path));\n\t\t\t}\n\t\t} else {\n\t\t\taddPath(new File(searchPath));\n\t\t}\n\t\treturn this;\n\t}",
        "explanations_by_ours": [
            "the pxtha",
            "the pxtha to add",
            "the pxtha to be added"
        ],
        "corrections_by_ours": [
            "add",
            "added"
        ],
        "corrections_by_baseline": [
            "PX",
            "pxpsx",
            "rpx",
            "gb",
            "polx5b",
            "fxyS",
            "polx8a",
            "polx6a",
            "pixels",
            "polx4b"
        ]
    },
    {
        "original_word": "lines",
        "typo_word": "ljnec",
        "original_variable": "lines",
        "typo_variable": "ljnec",
        "original_code": "public String getShortDescription ()\n    {\n        if ( this.description == null )\n        {\n            return null;\n        }\n\n        final String[] lines = this.description.split ( \"\\\\R\", 2 );\n        if ( lines.length > 0 )\n        {\n            return lines[0];\n        }\n        else\n        {\n            return \"\";\n        }\n    }",
        "modified_code": "public String getShortDescription ()\n    {\n        if ( this.description == null )\n        {\n            return null;\n        }\n\n        final String[] ljnec = this.description.split ( \"\\\\R\", 2 );\n        if ( ljnec.length > 0 )\n        {\n            return ljnec[0];\n        }\n        else\n        {\n            return \"\";\n        }\n    }",
        "explanations_by_ours": [
            "the short description of this class.",
            "the description of this class.",
            "the short description of this class"
        ],
        "corrections_by_ours": [
            "classnec",
            "ljdescription",
            "descriptionnec",
            "shortnec",
            "ljclass",
            "ljshort",
            "ljnec"
        ],
        "corrections_by_baseline": [
            "lm",
            "jexl",
            "mj",
            "JD",
            "jg",
            "jbndg",
            "jbeg",
            "pjpn",
            "jmx",
            "lpp"
        ]
    },
    {
        "original_word": "bottom",
        "typo_word": "boyyom",
        "original_variable": "bottom",
        "typo_variable": "boyyom",
        "original_code": "public static double acuteAngle( LineSegment2D_I32 line0 , LineSegment2D_I32 line1 ) {\n\t\tint dx0 = line0.b.x - line0.a.x;\n\t\tint dy0 = line0.b.y - line0.a.y;\n\t\tint dx1 = line1.b.x - line1.a.x;\n\t\tint dy1 = line1.b.y - line1.a.y;\n\n\t\tdouble bottom = Math.sqrt(dx0*dx0 + dy0*dy0) * Math.sqrt(dx1*dx1 + dy1*dy1);\n\t\treturn Math.acos((dx0*dx1 + dy0*dy1)/bottom);\n\t}",
        "modified_code": "public static double acuteAngle( LineSegment2D_I32 line0 , LineSegment2D_I32 line1 ) {\n\t\tint dx0 = line0.b.x - line0.a.x;\n\t\tint dy0 = line0.b.y - line0.a.y;\n\t\tint dx1 = line1.b.x - line1.a.x;\n\t\tint dy1 = line1.b.y - line1.a.y;\n\n\t\tdouble boyyom = Math.sqrt(dx0*dx0 + dy0*dy0) * Math.sqrt(dx1*dx1 + dy1*dy1);\n\t\treturn Math.acos((dx0*dx1 + dy0*dy1)/boyyom);\n\t}",
        "explanations_by_ours": [
            "The boyyom of the angle.",
            "The boyyom of the two lines.",
            "The boyyom of the line."
        ],
        "corrections_by_ours": [
            "two",
            "angle",
            "lines",
            "line"
        ],
        "corrections_by_baseline": [
            "yb",
            "kyero",
            "wy0",
            "hb",
            "yorg",
            "iyyy",
            "dch",
            "yyn",
            "ykr",
            "dub"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "ofddet",
        "original_variable": "offset",
        "typo_variable": "ofddet",
        "original_code": "public ManualFeatureQueryResults query(double minX, double minY,\n                                           double maxX, double maxY) {\n\n        List<Long> featureIds = new ArrayList<>();\n\n        long offset = 0;\n        boolean hasResults = true;\n\n        minX -= tolerance;\n        maxX += tolerance;\n        minY -= tolerance;\n        maxY += tolerance;\n\n        while (hasResults) {\n\n            hasResults = false;\n\n            FeatureCursor featureCursor = featureDao.queryForChunk(chunkLimit,\n                    offset);\n            try {\n                while (featureCursor.moveToNext()) {\n                    hasResults = true;\n\n                    FeatureRow featureRow = featureCursor.getRow();\n                    GeometryEnvelope envelope = featureRow\n                            .getGeometryEnvelope();\n                    if (envelope != null) {\n\n                        double minXMax = Math.max(minX, envelope.getMinX());\n                        double maxXMin = Math.min(maxX, envelope.getMaxX());\n                        double minYMax = Math.max(minY, envelope.getMinY());\n                        double maxYMin = Math.min(maxY, envelope.getMaxY());\n\n                        if (minXMax <= maxXMin && minYMax <= maxYMin) {\n                            featureIds.add(featureRow.getId());\n                        }\n\n                    }\n                }\n            } finally {\n                featureCursor.close();\n            }\n\n            offset += chunkLimit;\n        }\n\n        ManualFeatureQueryResults results = new ManualFeatureQueryResults(\n                featureDao, featureIds);\n\n        return results;\n    }",
        "modified_code": "public ManualFeatureQueryResults query(double minX, double minY,\n                                           double maxX, double maxY) {\n\n        List<Long> featureIds = new ArrayList<>();\n\n        long ofddet = 0;\n        boolean hasResults = true;\n\n        minX -= tolerance;\n        maxX += tolerance;\n        minY -= tolerance;\n        maxY += tolerance;\n\n        while (hasResults) {\n\n            hasResults = false;\n\n            FeatureCursor featureCursor = featureDao.queryForChunk(chunkLimit,\n                    ofddet);\n            try {\n                while (featureCursor.moveToNext()) {\n                    hasResults = true;\n\n                    FeatureRow featureRow = featureCursor.getRow();\n                    GeometryEnvelope envelope = featureRow\n                            .getGeometryEnvelope();\n                    if (envelope != null) {\n\n                        double minXMax = Math.max(minX, envelope.getMinX());\n                        double maxXMin = Math.min(maxX, envelope.getMaxX());\n                        double minYMax = Math.max(minY, envelope.getMinY());\n                        double maxYMin = Math.min(maxY, envelope.getMaxY());\n\n                        if (minXMax <= maxXMin && minYMax <= maxYMin) {\n                            featureIds.add(featureRow.getId());\n                        }\n\n                    }\n                }\n            } finally {\n                featureCursor.close();\n            }\n\n            ofddet += chunkLimit;\n        }\n\n        ManualFeatureQueryResults results = new ManualFeatureQueryResults(\n                featureDao, featureIds);\n\n        return results;\n    }",
        "explanations_by_ours": [
            "the ofddet",
            "the offset",
            "the start offset"
        ],
        "corrections_by_ours": [
            "offset",
            "start"
        ],
        "corrections_by_baseline": [
            "etf",
            "etdf",
            "mefd",
            "octet",
            "ithelement",
            "hcset",
            "nfe",
            "aLDT",
            "vvstruct",
            "ncatt"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rszult",
        "original_variable": "result",
        "typo_variable": "rszult",
        "original_code": "@Nullable\n  public static GribCollectionMutable openMutableGCFromIndex(String indexFilename, FeatureCollectionConfig config, boolean dataOnly, boolean useCache, Logger logger) {\n    File indexFileInCache = useCache ? GribIndexCache.getExistingFileOrCache(indexFilename) : new File(indexFilename);\n    if (indexFileInCache == null) {\n      return null;\n    }\n    String indexFilenameInCache = indexFileInCache.getPath();\n    String name = makeNameFromIndexFilename(indexFilename);\n    GribCollectionMutable result = null;\n\n    try (RandomAccessFile raf = RandomAccessFile.acquire(indexFilenameInCache)) {\n      GribCollectionType type = getType(raf);\n\n      switch (type) {\n        case GRIB2:\n          result = Grib2CollectionBuilderFromIndex.openMutableGCFromIndex(name, raf, config, logger);\n          break;\n        case Partition2:\n          result = Grib2PartitionBuilderFromIndex.openMutablePCFromIndex(name, raf, config, logger);\n          break;\n        case GRIB1:\n          result = Grib1CollectionBuilderFromIndex.openMutableGCFromIndex(name, raf, config, logger);\n          break;\n        case Partition1:\n          result = Grib1PartitionBuilderFromIndex.openMutablePCFromIndex(name, raf, config, logger);\n          break;\n        default:\n          logger.warn(\"GribCdmIndex.openMutableGCFromIndex failed on {} type={}\", indexFilenameInCache, type);\n      }\n\n      if (result != null) {\n        result.lastModified = raf.getLastModified();\n        result.fileSize = raf.length();\n      }\n\n    } catch (Throwable t) {\n      logger.warn(\"GribCdmIndex.openMutableGCFromIndex failed on \" + indexFilenameInCache, t);\n    }\n\n    if (result == null) {\n      RandomAccessFile.eject(indexFilenameInCache);\n      if (!indexFileInCache.delete())\n        logger.warn(\"failed to delete {}\", indexFileInCache.getPath());\n    }\n\n    return result;\n  }",
        "modified_code": "@Nullable\n  public static GribCollectionMutable openMutableGCFromIndex(String indexFilename, FeatureCollectionConfig config, boolean dataOnly, boolean useCache, Logger logger) {\n    File indexFileInCache = useCache ? GribIndexCache.getExistingFileOrCache(indexFilename) : new File(indexFilename);\n    if (indexFileInCache == null) {\n      return null;\n    }\n    String indexFilenameInCache = indexFileInCache.getPath();\n    String name = makeNameFromIndexFilename(indexFilename);\n    GribCollectionMutable rszult = null;\n\n    try (RandomAccessFile raf = RandomAccessFile.acquire(indexFilenameInCache)) {\n      GribCollectionType type = getType(raf);\n\n      switch (type) {\n        case GRIB2:\n          rszult = Grib2CollectionBuilderFromIndex.openMutableGCFromIndex(name, raf, config, logger);\n          break;\n        case Partition2:\n          rszult = Grib2PartitionBuilderFromIndex.openMutablePCFromIndex(name, raf, config, logger);\n          break;\n        case GRIB1:\n          rszult = Grib1CollectionBuilderFromIndex.openMutableGCFromIndex(name, raf, config, logger);\n          break;\n        case Partition1:\n          rszult = Grib1PartitionBuilderFromIndex.openMutablePCFromIndex(name, raf, config, logger);\n          break;\n        default:\n          logger.warn(\"GribCdmIndex.openMutableGCFromIndex failed on {} type={}\", indexFilenameInCache, type);\n      }\n\n      if (rszult != null) {\n        rszult.lastModified = raf.getLastModified();\n        rszult.fileSize = raf.length();\n      }\n\n    } catch (Throwable t) {\n      logger.warn(\"GribCdmIndex.openMutableGCFromIndex failed on \" + indexFilenameInCache, t);\n    }\n\n    if (rszult == null) {\n      RandomAccessFile.eject(indexFilenameInCache);\n      if (!indexFileInCache.delete())\n        logger.warn(\"failed to delete {}\", indexFileInCache.getPath());\n    }\n\n    return rszult;\n  }",
        "explanations_by_ours": [
            "the GribCollectionMutable instance",
            "the GribCollectionMutable to update",
            "the GribCollectionMutable object to update"
        ],
        "corrections_by_ours": [
            "object",
            "mutable",
            "instance",
            "collection",
            "update",
            "grib"
        ],
        "corrections_by_baseline": [
            "rsf",
            "rsize",
            "rs",
            "rt",
            "isr",
            "rj",
            "r",
            "R",
            "rtnArr",
            "rshape"
        ]
    },
    {
        "original_word": "fragments",
        "typo_word": "fgagmenta",
        "original_variable": "fragments",
        "typo_variable": "fgagmenta",
        "original_code": "public boolean modify(File file, MP4Edit edit) throws IOException {\n        SeekableByteChannel fi = null;\n        try {\n            fi = NIOUtils.rwChannel(file);\n\n            List<Tuple._2<Atom, ByteBuffer>> fragments = doTheFix(fi, edit);\n            if (fragments == null)\n                return false;\n\n            // If everything is clean, only then actually writing stuff to the\n            // file\n            for (Tuple._2<Atom, ByteBuffer> fragment : fragments) {\n                replaceBox(fi, fragment.v0, fragment.v1);\n            }\n\n            return true;\n        } finally {\n            NIOUtils.closeQuietly(fi);\n        }\n    }",
        "modified_code": "public boolean modify(File file, MP4Edit edit) throws IOException {\n        SeekableByteChannel fi = null;\n        try {\n            fi = NIOUtils.rwChannel(file);\n\n            List<Tuple._2<Atom, ByteBuffer>> fgagmenta = doTheFix(fi, edit);\n            if (fgagmenta == null)\n                return false;\n\n            // If everything is clean, only then actually writing stuff to the\n            // file\n            for (Tuple._2<Atom, ByteBuffer> fragment : fgagmenta) {\n                replaceBox(fi, fragment.v0, fragment.v1);\n            }\n\n            return true;\n        } finally {\n            NIOUtils.closeQuietly(fi);\n        }\n    }",
        "explanations_by_ours": [
            "the list of fragments to replace in the file",
            "the list of fragments to replace",
            "a list of fragments of the file"
        ],
        "corrections_by_ours": [
            "fragments",
            "file",
            "list",
            "replace"
        ],
        "corrections_by_baseline": [
            "ppage",
            "ag",
            "frag",
            "sdgA",
            "aspi",
            "fragment",
            "fptg",
            "pa",
            "ptg",
            "ipage"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "gakue",
        "original_variable": "value",
        "typo_variable": "gakue",
        "original_code": "@Override\n    public Object querySingleResult(String sql, String[] args, int column,\n                                    GeoPackageDataType dataType) {\n        CursorResult result = wrapQuery(sql, args);\n        Object value = ResultUtils.buildSingleResult(result, column, dataType);\n        return value;\n    }",
        "modified_code": "@Override\n    public Object querySingleResult(String sql, String[] args, int column,\n                                    GeoPackageDataType dataType) {\n        CursorResult result = wrapQuery(sql, args);\n        Object gakue = ResultUtils.buildSingleResult(result, column, dataType);\n        return gakue;\n    }",
        "explanations_by_ours": [
            "GeoPackage",
            "GeoPackage object"
        ],
        "corrections_by_ours": [
            "package",
            "geo",
            "object"
        ],
        "corrections_by_baseline": [
            "gv",
            "g",
            "bue",
            "gvcs",
            "glamn",
            "pckg",
            "emsg",
            "ybeg",
            "usv",
            "ak"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rwdult",
        "original_variable": "result",
        "typo_variable": "rwdult",
        "original_code": "public void deleteById(final Object entity) {\n\t\tif (entity != null) {\n\t\t\tint result = query(dbOom.entities().deleteById(entity)).autoClose().executeUpdate();\n\n\t\t\tif (result != 0) {\n\t\t\t\t// now reset the ID value\n\t\t\t\tClass type = entity.getClass();\n\t\t\t\tDbEntityDescriptor ded = dbOom.entityManager().lookupType(type);\n\n\t\t\t\tsetEntityId(ded, entity, 0);\n\t\t\t}\n\t\t}\n\t}",
        "modified_code": "public void deleteById(final Object entity) {\n\t\tif (entity != null) {\n\t\t\tint rwdult = query(dbOom.entities().deleteById(entity)).autoClose().executeUpdate();\n\n\t\t\tif (rwdult != 0) {\n\t\t\t\t// now reset the ID value\n\t\t\t\tClass type = entity.getClass();\n\t\t\t\tDbEntityDescriptor ded = dbOom.entityManager().lookupType(type);\n\n\t\t\t\tsetEntityId(ded, entity, 0);\n\t\t\t}\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the number of rows deleted",
            "the number of rows to delete",
            "the number of rows that should be deleted"
        ],
        "corrections_by_ours": [
            "rows",
            "delete",
            "deleted",
            "number"
        ],
        "corrections_by_baseline": [
            "rp",
            "rdr",
            "wrrp",
            "rsf",
            "R",
            "r",
            "dmr",
            "ftrm",
            "rpt",
            "isr"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "sfqrt",
        "original_variable": "start",
        "typo_variable": "sfqrt",
        "original_code": "public static Page<Record> paginate(String sqlPaginatePrefix,\n                                        PageDto pageDto) {\n        SqlNode sqlNode = SqlKit.sqlNode(sqlPaginatePrefix + \".paginate\");\n        Preconditions.checkNotNull(sqlNode, \"[\" + sqlPaginatePrefix + \".paginate]\u5206\u9875Sql\u4e0d\u5b58\u5728,\u65e0\u6cd5\u6267\u884c\u5206\u9875\");\n        String where = sqlNode.whereSql;\n        int pageSize = pageDto.pageSize;\n        int p = pageDto.page;\n        int start = ((p - 1) * pageSize) + 1;\n        final List<RequestParam> params = pageDto.params;\n        final List<Object> query_params = pageDto.query_params;\n        if ((params.isEmpty()) && (query_params.isEmpty())) {\n            return Db.paginate(start, pageSize, sqlNode.selectSql, where);\n        } else {\n\n            if (!params.isEmpty()) {\n                where += (sqlNode.condition ? StringPool.SPACE : \" WHERE 1=1 \");\n            }\n            for (RequestParam param : pageDto.params) {\n                where += param.toSql();\n            }\n            return Db.paginate(start, pageSize, sqlNode.selectSql, where, query_params.toArray());\n        }\n    }",
        "modified_code": "public static Page<Record> paginate(String sqlPaginatePrefix,\n                                        PageDto pageDto) {\n        SqlNode sqlNode = SqlKit.sqlNode(sqlPaginatePrefix + \".paginate\");\n        Preconditions.checkNotNull(sqlNode, \"[\" + sqlPaginatePrefix + \".paginate]\u5206\u9875Sql\u4e0d\u5b58\u5728,\u65e0\u6cd5\u6267\u884c\u5206\u9875\");\n        String where = sqlNode.whereSql;\n        int pageSize = pageDto.pageSize;\n        int p = pageDto.page;\n        int sfqrt = ((p - 1) * pageSize) + 1;\n        final List<RequestParam> params = pageDto.params;\n        final List<Object> query_params = pageDto.query_params;\n        if ((params.isEmpty()) && (query_params.isEmpty())) {\n            return Db.paginate(sfqrt, pageSize, sqlNode.selectSql, where);\n        } else {\n\n            if (!params.isEmpty()) {\n                where += (sqlNode.condition ? StringPool.SPACE : \" WHERE 1=1 \");\n            }\n            for (RequestParam param : pageDto.params) {\n                where += param.toSql();\n            }\n            return Db.paginate(sfqrt, pageSize, sqlNode.selectSql, where, query_params.toArray());\n        }\n    }",
        "explanations_by_ours": [
            "sfqrt",
            "sfqrt",
            "sqlPaginatePrefix"
        ],
        "corrections_by_ours": [
            "sql",
            "paginate",
            "prefix"
        ],
        "corrections_by_baseline": [
            "sqrt",
            "rt",
            "wrt",
            "rtn",
            "rtnArr",
            "iprt",
            "sr",
            "xhighprSq",
            "rsf",
            "rtc"
        ]
    },
    {
        "original_word": "connected",
        "typo_word": "connexter",
        "original_variable": "connected",
        "typo_variable": "connexter",
        "original_code": "protected boolean fixLink(final Object fieldValue) {\n    if (fieldValue instanceof OIdentifiable) {\n      final ORID id = ((OIdentifiable) fieldValue).getIdentity();\n\n      if (id.getClusterId() == 0 && id.getClusterPosition() == 0)\n        return true;\n\n      if (id.isValid())\n        if (id.isPersistent()) {\n          final ORecord connected = ((OIdentifiable) fieldValue).getRecord();\n          if (connected == null)\n            return true;\n        } else\n          return true;\n    }\n    return false;\n  }",
        "modified_code": "protected boolean fixLink(final Object fieldValue) {\n    if (fieldValue instanceof OIdentifiable) {\n      final ORID id = ((OIdentifiable) fieldValue).getIdentity();\n\n      if (id.getClusterId() == 0 && id.getClusterPosition() == 0)\n        return true;\n\n      if (id.isValid())\n        if (id.isPersistent()) {\n          final ORecord connexter = ((OIdentifiable) fieldValue).getRecord();\n          if (connexter == null)\n            return true;\n        } else\n          return true;\n    }\n    return false;\n  }",
        "explanations_by_ours": [
            "the connection to the record",
            "the connection to the link",
            "the connection to the connection"
        ],
        "corrections_by_ours": [
            "connectionexter",
            "recordexter",
            "linkexter",
            "connconnection",
            "connrecord",
            "connlink",
            "connexter"
        ],
        "corrections_by_baseline": [
            "connector",
            "transactionManager",
            "persister",
            "connHolder",
            "adapter",
            "remapper",
            "converter",
            "managementAdaptor",
            "transactionFactory",
            "persistenceProviderAdaptor"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "currsnh",
        "original_variable": "currentComponent",
        "typo_variable": "currsnhComponent",
        "original_code": "public void startComponentOperation(String componentName, ComponentType type) {\n    final Component currentComponent = componentsStack.peek();\n\n    if (currentComponent != null && componentName.equals(currentComponent.name)) {\n      currentComponent.operationCount++;\n      return;\n    }\n\n    componentsStack.push(new Component(componentName, type));\n  }",
        "modified_code": "public void startComponentOperation(String componentName, ComponentType type) {\n    final Component currsnhComponent = componentsStack.peek();\n\n    if (currsnhComponent != null && componentName.equals(currsnhComponent.name)) {\n      currsnhComponent.operationCount++;\n      return;\n    }\n\n    componentsStack.push(new Component(componentName, type));\n  }",
        "explanations_by_ours": [
            "the current component",
            "the current component.",
            "the current component in the stack"
        ],
        "corrections_by_ours": [
            "currentComponent",
            "currsnhCurrent",
            "componentComponent",
            "currsnhComponent",
            "stackComponent",
            "currsnhStack"
        ],
        "corrections_by_baseline": [
            "firstComponent",
            "ejbComponent",
            "lastComponent",
            "innerPair",
            "currentComponent",
            "drElem",
            "components1",
            "duComponentsSet",
            "rsElem",
            "curDim"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "fesuit",
        "original_variable": "result",
        "typo_variable": "fesuit",
        "original_code": "private LogoutFilter createLogoutFilter(H http) throws Exception {\n\t\tlogoutHandlers.add(contextLogoutHandler);\n\t\tLogoutHandler[] handlers = logoutHandlers\n\t\t\t\t.toArray(new LogoutHandler[logoutHandlers.size()]);\n\t\tLogoutFilter result = new LogoutFilter(getLogoutSuccessHandler(), handlers);\n\t\tresult.setLogoutRequestMatcher(getLogoutRequestMatcher(http));\n\t\tresult = postProcess(result);\n\t\treturn result;\n\t}",
        "modified_code": "private LogoutFilter createLogoutFilter(H http) throws Exception {\n\t\tlogoutHandlers.add(contextLogoutHandler);\n\t\tLogoutHandler[] handlers = logoutHandlers\n\t\t\t\t.toArray(new LogoutHandler[logoutHandlers.size()]);\n\t\tLogoutFilter fesuit = new LogoutFilter(getLogoutSuccessHandler(), handlers);\n\t\tfesuit.setLogoutRequestMatcher(getLogoutRequestMatcher(http));\n\t\tfesuit = postProcess(fesuit);\n\t\treturn fesuit;\n\t}",
        "explanations_by_ours": [
            "the fesuit",
            "The fesuit",
            "a fesuit"
        ],
        "corrections_by_ours": [
            "suitsuit",
            "fefe",
            "fesuit"
        ],
        "corrections_by_baseline": [
            "ecef",
            "tmphandshake",
            "sip",
            "iresult",
            "httpSessionEvent",
            "rosterPacket",
            "sce",
            "qmi",
            "consec",
            "pce"
        ]
    },
    {
        "original_word": "range",
        "typo_word": "rxnfe",
        "original_variable": "range",
        "typo_variable": "rxnfe",
        "original_code": "public static Vector3D_F64 createRandom( double min, double max, Random rand ) {\n\t\tdouble range = max - min;\n\n\t\tVector3D_F64 a = new Vector3D_F64();\n\n\t\ta.x = range * rand.nextDouble() + min;\n\t\ta.y = range * rand.nextDouble() + min;\n\t\ta.z = range * rand.nextDouble() + min;\n\n\t\treturn a;\n\t}",
        "modified_code": "public static Vector3D_F64 createRandom( double min, double max, Random rand ) {\n\t\tdouble rxnfe = max - min;\n\n\t\tVector3D_F64 a = new Vector3D_F64();\n\n\t\ta.x = rxnfe * rand.nextDouble() + min;\n\t\ta.y = rxnfe * rand.nextDouble() + min;\n\t\ta.z = rxnfe * rand.nextDouble() + min;\n\n\t\treturn a;\n\t}",
        "explanations_by_ours": [
            "Radius of the vector.",
            "Radius of the random vector.",
            "RNG of the vector."
        ],
        "corrections_by_ours": [
            "rng",
            "random",
            "radius",
            "vector"
        ],
        "corrections_by_baseline": [
            "rx",
            "qmndx",
            "rgp",
            "sndx",
            "ncx",
            "sgp",
            "nfe",
            "drq",
            "pc",
            "ncf"
        ]
    },
    {
        "original_word": "masked",
        "typo_word": "mqwked",
        "original_variable": "masked",
        "typo_variable": "mqwked",
        "original_code": "private void readPayloadInfo(InputStream in) throws IOException {\n        byte b = (byte) checkedRead(in.read());\n        boolean masked = (b & 0x80) != 0;\n\n        this._payloadLength = (byte) (0x7F & b);\n        if (this._payloadLength == 126) {\n            // checkedRead must return int for this to work\n            this._payloadLength = (checkedRead(in.read()) << 8 | checkedRead(in.read())) & 0xFFFF;\n            if (this._payloadLength < 126) {\n                throw new WebSocketException(CloseCode.ProtocolError, \"Invalid data frame 2byte length. (not using minimal length encoding)\");\n            }\n        } else if (this._payloadLength == 127) {\n            long _payloadLength =\n                    (long) checkedRead(in.read()) << 56 | (long) checkedRead(in.read()) << 48 | (long) checkedRead(in.read()) << 40 | (long) checkedRead(in.read()) << 32\n                            | checkedRead(in.read()) << 24 | checkedRead(in.read()) << 16 | checkedRead(in.read()) << 8 | checkedRead(in.read());\n            if (_payloadLength < 65536) {\n                throw new WebSocketException(CloseCode.ProtocolError, \"Invalid data frame 4byte length. (not using minimal length encoding)\");\n            }\n            if (_payloadLength < 0 || _payloadLength > Integer.MAX_VALUE) {\n                throw new WebSocketException(CloseCode.MessageTooBig, \"Max frame length has been exceeded.\");\n            }\n            this._payloadLength = (int) _payloadLength;\n        }\n\n        if (this.opCode.isControlFrame()) {\n            if (this._payloadLength > 125) {\n                throw new WebSocketException(CloseCode.ProtocolError, \"Control frame with payload length > 125 bytes.\");\n            }\n            if (this.opCode == OpCode.Close && this._payloadLength == 1) {\n                throw new WebSocketException(CloseCode.ProtocolError, \"Received close frame with payload len 1.\");\n            }\n        }\n\n        if (masked) {\n            this.maskingKey = new byte[4];\n            int read = 0;\n            while (read < this.maskingKey.length) {\n                read += checkedRead(in.read(this.maskingKey, read, this.maskingKey.length - read));\n            }\n        }\n    }",
        "modified_code": "private void readPayloadInfo(InputStream in) throws IOException {\n        byte b = (byte) checkedRead(in.read());\n        boolean mqwked = (b & 0x80) != 0;\n\n        this._payloadLength = (byte) (0x7F & b);\n        if (this._payloadLength == 126) {\n            // checkedRead must return int for this to work\n            this._payloadLength = (checkedRead(in.read()) << 8 | checkedRead(in.read())) & 0xFFFF;\n            if (this._payloadLength < 126) {\n                throw new WebSocketException(CloseCode.ProtocolError, \"Invalid data frame 2byte length. (not using minimal length encoding)\");\n            }\n        } else if (this._payloadLength == 127) {\n            long _payloadLength =\n                    (long) checkedRead(in.read()) << 56 | (long) checkedRead(in.read()) << 48 | (long) checkedRead(in.read()) << 40 | (long) checkedRead(in.read()) << 32\n                            | checkedRead(in.read()) << 24 | checkedRead(in.read()) << 16 | checkedRead(in.read()) << 8 | checkedRead(in.read());\n            if (_payloadLength < 65536) {\n                throw new WebSocketException(CloseCode.ProtocolError, \"Invalid data frame 4byte length. (not using minimal length encoding)\");\n            }\n            if (_payloadLength < 0 || _payloadLength > Integer.MAX_VALUE) {\n                throw new WebSocketException(CloseCode.MessageTooBig, \"Max frame length has been exceeded.\");\n            }\n            this._payloadLength = (int) _payloadLength;\n        }\n\n        if (this.opCode.isControlFrame()) {\n            if (this._payloadLength > 125) {\n                throw new WebSocketException(CloseCode.ProtocolError, \"Control frame with payload length > 125 bytes.\");\n            }\n            if (this.opCode == OpCode.Close && this._payloadLength == 1) {\n                throw new WebSocketException(CloseCode.ProtocolError, \"Received close frame with payload len 1.\");\n            }\n        }\n\n        if (mqwked) {\n            this.maskingKey = new byte[4];\n            int read = 0;\n            while (read < this.maskingKey.length) {\n                read += checkedRead(in.read(this.maskingKey, read, this.maskingKey.length - read));\n            }\n        }\n    }",
        "explanations_by_ours": [
            "true if the message is mqwked, false otherwise",
            "true if the message is mqwked, false if not",
            "true if the payload is a mqwked frame"
        ],
        "corrections_by_ours": [
            "mqwked,",
            "frame",
            "false",
            "true",
            "message",
            "payload",
            "otherwise"
        ],
        "corrections_by_baseline": [
            "activeMQServer",
            "qmndx",
            "nbusy",
            "asynch",
            "pckg",
            "idle",
            "gfdw",
            "activeSocket",
            "wis",
            "alive"
        ]
    },
    {
        "original_word": "Value",
        "typo_word": "Vxlke",
        "original_variable": "sqlValue",
        "typo_variable": "sqlVxlke",
        "original_code": "public Query<T> eq(Column colName, Boolean param) {\n\t\tInteger sqlValue = BooleanConverter.GET.toSql(param);\n\t\twhere.append(\" AND \" + colName + \"=?\");\n\t\tparams.add(BooleanConverter.GET.toString(sqlValue));\n\t\treturn this;\n\t}",
        "modified_code": "public Query<T> eq(Column colName, Boolean param) {\n\t\tInteger sqlVxlke = BooleanConverter.GET.toSql(param);\n\t\twhere.append(\" AND \" + colName + \"=?\");\n\t\tparams.add(BooleanConverter.GET.toString(sqlVxlke));\n\t\treturn this;\n\t}",
        "explanations_by_ours": [
            "sql value",
            "column value",
            "sql vlke"
        ],
        "corrections_by_ours": [
            "sqlVlke",
            "sqlValue",
            "valueVxlke",
            "sqlSql",
            "columnVxlke",
            "sqlColumn",
            "vlkeVxlke",
            "sqlVxlke"
        ],
        "corrections_by_baseline": [
            "dbsql",
            "pureSql",
            "sqlStringBldr",
            "sqlite",
            "xqlon",
            "sql",
            "osql",
            "sqlString",
            "sql_builder",
            "sqlQuery"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "tesklt",
        "original_variable": "result",
        "typo_variable": "tesklt",
        "original_code": "@Override\r\n  public Structure select(List<String> memberNames) {\r\n    StructureDS result = new StructureDS(getParentGroup(), orgVar);\r\n    List<Variable> members = new ArrayList<>();\r\n    for (String name : memberNames) {\r\n      Variable m = findVariable(name);\r\n      if (null != m) members.add(m);\r\n    }\r\n    result.setMemberVariables(members);\r\n    result.isSubset = true;\r\n    return result;\r\n  }",
        "modified_code": "@Override\r\n  public Structure select(List<String> memberNames) {\r\n    StructureDS tesklt = new StructureDS(getParentGroup(), orgVar);\r\n    List<Variable> members = new ArrayList<>();\r\n    for (String name : memberNames) {\r\n      Variable m = findVariable(name);\r\n      if (null != m) members.add(m);\r\n    }\r\n    tesklt.setMemberVariables(members);\r\n    tesklt.isSubset = true;\r\n    return tesklt;\r\n  }",
        "explanations_by_ours": [
            "the tesklt",
            "the tesklt."
        ],
        "corrections_by_ours": [],
        "corrections_by_baseline": [
            "octet",
            "utf8Bytes",
            "base64Bytes",
            "ksp",
            "base64Text",
            "encodedString",
            "b64",
            "byteBuf",
            "lengthString",
            "aphString"
        ]
    },
    {
        "original_word": "element",
        "typo_word": "rlemwnt",
        "original_variable": "element",
        "typo_variable": "rlemwnt",
        "original_code": "public DroolsLineBreakpoint getDroolsBreakpoint(String source) {\n\n        if ( source == null ) {\n            return null;\n        }\n\n        Iterator<IBreakpoint> iterator = getBreakpoints().iterator();\n        while ( iterator.hasNext() ) {\n            IJavaBreakpoint element = (IJavaBreakpoint) iterator.next();\n            if ( element instanceof DroolsLineBreakpoint && ((DroolsLineBreakpoint) element).getDialectName().equals( \"mvel\" ) ) {\n                DroolsLineBreakpoint l = (DroolsLineBreakpoint) element;\n                try {\n\n                    int matchLine = l.getLineNumber();\n                    String matchSource = l.getRuleName();\n\n                    if ( source.equals( matchSource ) || l.getFileRuleMappings().containsKey( source ) ) {\n                        return l;\n                    }\n\n                } catch ( CoreException e ) {\n                    logError( e );\n                }\n            }\n        }\n\n        return null;\n    }",
        "modified_code": "public DroolsLineBreakpoint getDroolsBreakpoint(String source) {\n\n        if ( source == null ) {\n            return null;\n        }\n\n        Iterator<IBreakpoint> iterator = getBreakpoints().iterator();\n        while ( iterator.hasNext() ) {\n            IJavaBreakpoint rlemwnt = (IJavaBreakpoint) iterator.next();\n            if ( rlemwnt instanceof DroolsLineBreakpoint && ((DroolsLineBreakpoint) rlemwnt).getDialectName().equals( \"mvel\" ) ) {\n                DroolsLineBreakpoint l = (DroolsLineBreakpoint) rlemwnt;\n                try {\n\n                    int matchLine = l.getLineNumber();\n                    String matchSource = l.getRuleName();\n\n                    if ( source.equals( matchSource ) || l.getFileRuleMappings().containsKey( source ) ) {\n                        return l;\n                    }\n\n                } catch ( CoreException e ) {\n                    logError( e );\n                }\n            }\n        }\n\n        return null;\n    }",
        "explanations_by_ours": [
            "the rlemwnt",
            "the rlemwnt to check",
            "the breakpoint to look for"
        ],
        "corrections_by_ours": [
            "breakpoint",
            "look",
            "check"
        ],
        "corrections_by_baseline": [
            "drElem",
            "rsElem",
            "ncmlElem",
            "dssElem",
            "elem",
            "ppElem",
            "tmElem",
            "tsr",
            "vertElem",
            "dsElem"
        ]
    },
    {
        "original_word": "children",
        "typo_word": "cjilxren",
        "original_variable": "children",
        "typo_variable": "cjilxren",
        "original_code": "public static void replaceTextWithCData(Document doc, Node node) {\n        if (node instanceof Text) {\n            Text text = (Text) node;\n            CDATASection cdata = doc.createCDATASection(text.getTextContent());\n            Element parent = (Element) text.getParentNode();\n            parent.replaceChild(cdata, text);\n        } else if (node instanceof Element) {\n            //LOGGER.debug( \"ELEMENT \" + element.getTagName() );\n            NodeList children = node.getChildNodes();\n            for (int i = 0; i < children.getLength(); i++) {\n                //LOGGER.debug( \"> \" + children.item( i ).getClass().getName() );\n                XmlUtils.replaceTextWithCData(doc, children.item(i));\n            }\n        }\n    }",
        "modified_code": "public static void replaceTextWithCData(Document doc, Node node) {\n        if (node instanceof Text) {\n            Text text = (Text) node;\n            CDATASection cdata = doc.createCDATASection(text.getTextContent());\n            Element parent = (Element) text.getParentNode();\n            parent.replaceChild(cdata, text);\n        } else if (node instanceof Element) {\n            //LOGGER.debug( \"ELEMENT \" + element.getTagName() );\n            NodeList cjilxren = node.getChildNodes();\n            for (int i = 0; i < cjilxren.getLength(); i++) {\n                //LOGGER.debug( \"> \" + children.item( i ).getClass().getName() );\n                XmlUtils.replaceTextWithCData(doc, cjilxren.item(i));\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the children of the node.",
            "the children of the node",
            "list of CDATA nodes."
        ],
        "corrections_by_ours": [
            "children",
            "nodes",
            "list",
            "node",
            "c",
            "data"
        ],
        "corrections_by_baseline": [
            "rj",
            "jexl",
            "jbndg",
            "delx",
            "ftrm",
            "nrg",
            "jbeg",
            "nj",
            "xstell",
            "p2n"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nzmr",
        "original_variable": "serviceName",
        "typo_variable": "serviceNzmr",
        "original_code": "protected AccessBuilder readAccess(DatasetBuilder dataset, Element accessElem) {\n    String urlPath = accessElem.getAttributeValue(\"urlPath\");\n    String serviceName = accessElem.getAttributeValue(\"serviceName\");\n    String dataFormat = accessElem.getAttributeValue(\"dataFormat\");\n\n    Service s = serviceMap.get(serviceName);\n    if (s == null) {\n      errlog.format(\"Cant find service name='%s'%n\", serviceName);\n      logger.debug(\"Can't find service name='{}'\", serviceName);\n    }\n    return new AccessBuilder(dataset, urlPath, s, dataFormat, readDataSize(accessElem));\n  }",
        "modified_code": "protected AccessBuilder readAccess(DatasetBuilder dataset, Element accessElem) {\n    String urlPath = accessElem.getAttributeValue(\"urlPath\");\n    String serviceNzmr = accessElem.getAttributeValue(\"serviceName\");\n    String dataFormat = accessElem.getAttributeValue(\"dataFormat\");\n\n    Service s = serviceMap.get(serviceNzmr);\n    if (s == null) {\n      errlog.format(\"Cant find service name='%s'%n\", serviceNzmr);\n      logger.debug(\"Can't find service name='{}'\", serviceNzmr);\n    }\n    return new AccessBuilder(dataset, urlPath, s, dataFormat, readDataSize(accessElem));\n  }",
        "explanations_by_ours": [
            "The service name.",
            "the service name.",
            "the service name"
        ],
        "corrections_by_ours": [
            "serviceName",
            "nameNzmr",
            "serviceService",
            "serviceNzmr"
        ],
        "corrections_by_baseline": [
            "serviceForThisDs",
            "raServiceSB",
            "raService",
            "artemisService",
            "serviceController",
            "mvm",
            "orbService",
            "service",
            "receivableService",
            "serviceComponent"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rwsukt",
        "original_variable": "result",
        "typo_variable": "rwsukt",
        "original_code": "public static <T> List<T> flattenList(Iterable<? extends Iterable<T>> coll) {\n        final List<T> result = new ArrayList<>();\n        for(Iterable<T> o: coll) {\n            for(T el: o) {\n                result.add(el);\n            }\n        }\n        return result;\n    }",
        "modified_code": "public static <T> List<T> flattenList(Iterable<? extends Iterable<T>> coll) {\n        final List<T> rwsukt = new ArrayList<>();\n        for(Iterable<T> o: coll) {\n            for(T el: o) {\n                rwsukt.add(el);\n            }\n        }\n        return rwsukt;\n    }",
        "explanations_by_ours": [
            "the List to flatten into",
            "the List to populate",
            "the List to flatten"
        ],
        "corrections_by_ours": [
            "list",
            "populate",
            "flatten"
        ],
        "corrections_by_baseline": [
            "wrrp",
            "osw",
            "wrt",
            "wrp",
            "wch",
            "rgp",
            "wv",
            "gfdw",
            "dsr",
            "pwr"
        ]
    },
    {
        "original_word": "types",
        "typo_word": "hypex",
        "original_variable": "types",
        "typo_variable": "hypex",
        "original_code": "public SbbLocalObjectImpl getSbbLocalObject() {\n\t\t\n\t\tif (doTraceLogs)\n\t\t\tlog.trace(\"getSbbLocalObject()\");\n\n\t\t// The concrete class generated in ConcreteLocalObjectGenerator\n\t\tfinal Class<?> sbbLocalClass = getSbbComponent().getSbbLocalInterfaceConcreteClass();\n\t\tif (sbbLocalClass != null) {\n\t\t\tObject[] objs = { this };\n\t\t\tConstructor<?> constructor = getSbbComponent().getSbbLocalObjectClassConstructor();\n\t\t\tif (constructor == null) {\n\t\t\t\tfinal Class<?>[] types = { SbbEntityImpl.class };\n\t\t\t\ttry {\n\t\t\t\t\tconstructor = sbbLocalClass.getConstructor(types);\n\t\t\t\t} catch (Throwable e) {\n\t\t\t\t\tthrow new SLEEException(\"Unable to retrieve sbb local object generated class constructor\",e);\n\t\t\t\t}\n\t\t\t\tgetSbbComponent().setSbbLocalObjectClassConstructor(constructor);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\treturn (SbbLocalObjectImpl) constructor.newInstance(objs);\n\t\t\t} catch (Throwable e) {\n\t\t\t\tthrow new SLEEException(\n\t\t\t\t\t\t\"Failed to create Sbb Local Interface.\", e);\n\t\t\t}\n\t\t} else {\n\t\t\treturn new SbbLocalObjectImpl(this);\n\t\t}\n\t}",
        "modified_code": "public SbbLocalObjectImpl getSbbLocalObject() {\n\t\t\n\t\tif (doTraceLogs)\n\t\t\tlog.trace(\"getSbbLocalObject()\");\n\n\t\t// The concrete class generated in ConcreteLocalObjectGenerator\n\t\tfinal Class<?> sbbLocalClass = getSbbComponent().getSbbLocalInterfaceConcreteClass();\n\t\tif (sbbLocalClass != null) {\n\t\t\tObject[] objs = { this };\n\t\t\tConstructor<?> constructor = getSbbComponent().getSbbLocalObjectClassConstructor();\n\t\t\tif (constructor == null) {\n\t\t\t\tfinal Class<?>[] hypex = { SbbEntityImpl.class };\n\t\t\t\ttry {\n\t\t\t\t\tconstructor = sbbLocalClass.getConstructor(hypex);\n\t\t\t\t} catch (Throwable e) {\n\t\t\t\t\tthrow new SLEEException(\"Unable to retrieve sbb local object generated class constructor\",e);\n\t\t\t\t}\n\t\t\t\tgetSbbComponent().setSbbLocalObjectClassConstructor(constructor);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\treturn (SbbLocalObjectImpl) constructor.newInstance(objs);\n\t\t\t} catch (Throwable e) {\n\t\t\t\tthrow new SLEEException(\n\t\t\t\t\t\t\"Failed to create Sbb Local Interface.\", e);\n\t\t\t}\n\t\t} else {\n\t\t\treturn new SbbLocalObjectImpl(this);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "The class of the SbbEntityImpl.",
            "The class of the SbbEntityImpl",
            "The class of the SbbEntityImpl class."
        ],
        "corrections_by_ours": [
            "impl",
            "entity",
            "class",
            "sbb"
        ],
        "corrections_by_baseline": [
            "atype",
            "ptype",
            "cdm_datatype",
            "syy",
            "lgdtyp",
            "daptype",
            "hsys",
            "dapex",
            "kx",
            "ftype"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resiot",
        "original_variable": "result",
        "typo_variable": "resiot",
        "original_code": "public static int getTypeDifferenceWeight(Class<?>[] paramTypes, Object[] args) {\n        int result = 0;\n        for (int i = 0; i < paramTypes.length; i++) {\n            if (!ClassUtils.isAssignableValue(paramTypes[i], args[i])) {\n                return Integer.MAX_VALUE;\n            }\n            if (args[i] != null) {\n                Class<?> paramType = paramTypes[i];\n                Class<?> superClass = args[i].getClass().getSuperclass();\n                while (superClass != null) {\n                    if (paramType.equals(superClass)) {\n                        result = result + 2;\n                        superClass = null;\n                    } else if (ClassUtils.isAssignable(paramType, superClass)) {\n                        result = result + 2;\n                        superClass = superClass.getSuperclass();\n                    } else {\n                        superClass = null;\n                    }\n                }\n                if (paramType.isInterface()) {\n                    result = result + 1;\n                }\n            }\n        }\n        return result;\n    }",
        "modified_code": "public static int getTypeDifferenceWeight(Class<?>[] paramTypes, Object[] args) {\n        int resiot = 0;\n        for (int i = 0; i < paramTypes.length; i++) {\n            if (!ClassUtils.isAssignableValue(paramTypes[i], args[i])) {\n                return Integer.MAX_VALUE;\n            }\n            if (args[i] != null) {\n                Class<?> paramType = paramTypes[i];\n                Class<?> superClass = args[i].getClass().getSuperclass();\n                while (superClass != null) {\n                    if (paramType.equals(superClass)) {\n                        resiot = resiot + 2;\n                        superClass = null;\n                    } else if (ClassUtils.isAssignable(paramType, superClass)) {\n                        resiot = resiot + 2;\n                        superClass = superClass.getSuperclass();\n                    } else {\n                        superClass = null;\n                    }\n                }\n                if (paramType.isInterface()) {\n                    resiot = resiot + 1;\n                }\n            }\n        }\n        return resiot;\n    }",
        "explanations_by_ours": [
            "the weight of the difference between the given types and the given arguments",
            "the weight of the difference between the given types and the given arguments.",
            "the total weight of the difference between the given types and the given arguments"
        ],
        "corrections_by_ours": [
            "weight",
            "arguments",
            "difference",
            "total",
            "types",
            "given"
        ],
        "corrections_by_baseline": [
            "res",
            "resul",
            "trovit",
            "resilientFos",
            "psi",
            "usv",
            "urpt",
            "calt",
            "rp",
            "hysteresis"
        ]
    },
    {
        "original_word": "actual",
        "typo_word": "zctuap",
        "original_variable": "actualListView",
        "typo_variable": "zctuapListView",
        "original_code": "@Override\n\tpublic void onCreate(Bundle savedInstanceState) {\n\t\tsuper.onCreate(savedInstanceState);\n\t\tsetContentView(R.layout.activity_ptr_list_fragment);\n\n\t\tmPullRefreshListFragment = (PullToRefreshListFragment) getSupportFragmentManager().findFragmentById(\n\t\t\t\tR.id.frag_ptr_list);\n\n\t\t// Get PullToRefreshListView from Fragment\n\t\tmPullRefreshListView = mPullRefreshListFragment.getPullToRefreshListView();\n\n\t\t// Set a listener to be invoked when the list should be refreshed.\n\t\tmPullRefreshListView.setOnRefreshListener(this);\n\n\t\t// You can also just use mPullRefreshListFragment.getListView()\n\t\tListView actualListView = mPullRefreshListView.getRefreshableView();\n\n\t\tmListItems = new LinkedList<String>();\n\t\tmListItems.addAll(Arrays.asList(mStrings));\n\t\tmAdapter = new ArrayAdapter<String>(this, android.R.layout.simple_list_item_1, mListItems);\n\n\t\t// You can also just use setListAdapter(mAdapter) or\n\t\t// mPullRefreshListView.setAdapter(mAdapter)\n\t\tactualListView.setAdapter(mAdapter);\n\n\t\tmPullRefreshListFragment.setListShown(true);\n\t}",
        "modified_code": "@Override\n\tpublic void onCreate(Bundle savedInstanceState) {\n\t\tsuper.onCreate(savedInstanceState);\n\t\tsetContentView(R.layout.activity_ptr_list_fragment);\n\n\t\tmPullRefreshListFragment = (PullToRefreshListFragment) getSupportFragmentManager().findFragmentById(\n\t\t\t\tR.id.frag_ptr_list);\n\n\t\t// Get PullToRefreshListView from Fragment\n\t\tmPullRefreshListView = mPullRefreshListFragment.getPullToRefreshListView();\n\n\t\t// Set a listener to be invoked when the list should be refreshed.\n\t\tmPullRefreshListView.setOnRefreshListener(this);\n\n\t\t// You can also just use mPullRefreshListFragment.getListView()\n\t\tListView zctuapListView = mPullRefreshListView.getRefreshableView();\n\n\t\tmListItems = new LinkedList<String>();\n\t\tmListItems.addAll(Arrays.asList(mStrings));\n\t\tmAdapter = new ArrayAdapter<String>(this, android.R.layout.simple_list_item_1, mListItems);\n\n\t\t// You can also just use setListAdapter(mAdapter) or\n\t\t// mPullRefreshListView.setAdapter(mAdapter)\n\t\tzctuapListView.setAdapter(mAdapter);\n\n\t\tmPullRefreshListFragment.setListShown(true);\n\t}",
        "explanations_by_ours": [
            "the zctuap list view.",
            "the zctuap list view",
            "the zctuap list view to use"
        ],
        "corrections_by_ours": [
            "zctuapUseView",
            "zctuapViewView",
            "zctuapListUse",
            "zctuapListList",
            "useListView",
            "viewListView",
            "listListView",
            "zctuapZctuapView",
            "zctuapListZctuap",
            "zctuapListView"
        ],
        "corrections_by_baseline": [
            "actualListView",
            "formListing",
            "jobViewListing",
            "routeItemList",
            "webView",
            "viewGroup",
            "views",
            "navArray",
            "formList",
            "objectListing"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "redukt",
        "original_variable": "result",
        "typo_variable": "redukt",
        "original_code": "public static ArrayChar makeFromString(String s, int max) {\r\n    ArrayChar result = new ArrayChar.D1( max);\r\n    for (int i=0; i<max && i<s.length(); i++)\r\n      result.setChar( i, s.charAt(i));\r\n\r\n    return result;\r\n  }",
        "modified_code": "public static ArrayChar makeFromString(String s, int max) {\r\n    ArrayChar redukt = new ArrayChar.D1( max);\r\n    for (int i=0; i<max && i<s.length(); i++)\r\n      redukt.setChar( i, s.charAt(i));\r\n\r\n    return redukt;\r\n  }",
        "explanations_by_ours": [
            "the new ArrayChar",
            "the ArrayChar",
            "the ArrayChar to create"
        ],
        "corrections_by_ours": [
            "new",
            "create",
            "char",
            "array"
        ],
        "corrections_by_baseline": [
            "tfa",
            "red",
            "coun",
            "tinvd",
            "calt",
            "ybeg",
            "trovit",
            "icb",
            "t",
            "T"
        ]
    },
    {
        "original_word": "List",
        "typo_word": "Ljzt",
        "original_variable": "typeList",
        "typo_variable": "typeLjzt",
        "original_code": "@SuppressWarnings(\"unchecked\")\n\tfinal Class<? extends Throwable>[] getRegisteredTypes() {\n\t\tSet<Class<? extends Throwable>> typeList = this.extractorMap.keySet();\n\t\treturn typeList.toArray(new Class[typeList.size()]);\n\t}",
        "modified_code": "@SuppressWarnings(\"unchecked\")\n\tfinal Class<? extends Throwable>[] getRegisteredTypes() {\n\t\tSet<Class<? extends Throwable>> typeLjzt = this.extractorMap.keySet();\n\t\treturn typeLjzt.toArray(new Class[typeLjzt.size()]);\n\t}",
        "explanations_by_ours": [
            "the type ljzt",
            "the type lijzt",
            "the type LJZT"
        ],
        "corrections_by_ours": [
            "typeLijzt",
            "lijztLjzt",
            "ljztLjzt",
            "typeType",
            "typeLjzt"
        ],
        "corrections_by_baseline": [
            "f0type",
            "atype",
            "rType",
            "pType",
            "javaType",
            "stsType",
            "archType",
            "ptype",
            "mtype",
            "typeS"
        ]
    },
    {
        "original_word": "chars",
        "typo_word": "dhats",
        "original_variable": "chars",
        "typo_variable": "dhats",
        "original_code": "public static String removeWhitespace(String inputString) {\r\n    StringBuilder sb = new StringBuilder();\r\n    char[] chars = inputString.toCharArray();\r\n    for (char c : chars) {\r\n      if (Character.isWhitespace(c)) {\r\n        continue;\r\n      }\r\n      sb.append(c);\r\n    }\r\n    return sb.toString();\r\n  }",
        "modified_code": "public static String removeWhitespace(String inputString) {\r\n    StringBuilder sb = new StringBuilder();\r\n    char[] dhats = inputString.toCharArray();\r\n    for (char c : dhats) {\r\n      if (Character.isWhitespace(c)) {\r\n        continue;\r\n      }\r\n      sb.append(c);\r\n    }\r\n    return sb.toString();\r\n  }",
        "explanations_by_ours": [
            "the characters to remove whitespace from",
            "the characters to remove",
            "the array of characters to remove whitespace from"
        ],
        "corrections_by_ours": [
            "characters",
            "whitespace",
            "remove",
            "array"
        ],
        "corrections_by_baseline": [
            "nlats",
            "dks",
            "dh",
            "xads",
            "pdh",
            "dolacons",
            "hrs",
            "webservicesMD",
            "ps",
            "ht"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resupy",
        "original_variable": "result",
        "typo_variable": "resupy",
        "original_code": "private void displayCompiledPredicate(Term predicate)\n    {\n        // Pretty print the clause.\n        StringBuffer result = new StringBuffer();\n\n        PositionalTermVisitor displayVisitor =\n            new WAMCompiledPredicatePrintingVisitor(interner, symbolTable, result);\n\n        TermWalkers.positionalWalker(displayVisitor).walk(predicate);\n\n        /*log.fine(result.toString());*/\n    }",
        "modified_code": "private void displayCompiledPredicate(Term predicate)\n    {\n        // Pretty print the clause.\n        StringBuffer resupy = new StringBuffer();\n\n        PositionalTermVisitor displayVisitor =\n            new WAMCompiledPredicatePrintingVisitor(interner, symbolTable, resupy);\n\n        TermWalkers.positionalWalker(displayVisitor).walk(predicate);\n\n        /*log.fine(result.toString());*/\n    }",
        "explanations_by_ours": [
            "The buffer to hold the output.",
            "A string buffer to hold the output.",
            "The buffer to hold the result of the statement."
        ],
        "corrections_by_ours": [
            "result",
            "output",
            "statement",
            "string",
            "hold",
            "buffer"
        ],
        "corrections_by_baseline": [
            "upx",
            "rngy",
            "y_off",
            "resul",
            "reload",
            "restart",
            "upc",
            "up",
            "endy",
            "ybeg"
        ]
    },
    {
        "original_word": "units",
        "typo_word": "jnitz",
        "original_variable": "codeunits",
        "typo_variable": "codejnitz",
        "original_code": "private ByteString readJsonString(boolean skipContext)\n            throws IOException {\n        Buffer buffer = new Buffer();\n        ArrayList<Character> codeunits = new ArrayList<>();\n        if (!skipContext) {\n            context.read();\n        }\n        readJsonSyntaxChar(QUOTE);\n        while (true) {\n            byte ch = reader.read();\n            if (ch == QUOTE[0]) {\n                break;\n            }\n            if (ch == ESCSEQ[0]) {\n                ch = reader.read();\n                if (ch == ESCSEQ[1]) {\n                    transport.read(tmpbuf, 0, 4);\n                    short cu = (short) (\n                            ((short) hexVal(tmpbuf[0]) << 12)\n                                    + ((short) hexVal(tmpbuf[1]) << 8)\n                                    + ((short) hexVal(tmpbuf[2]) << 4)\n                                    + (short) hexVal(tmpbuf[3]));\n                    try {\n                        if (Character.isHighSurrogate((char) cu)) {\n                            if (codeunits.size() > 0) {\n                                throw new ProtocolException(\"Expected low surrogate char\");\n                            }\n                            codeunits.add((char) cu);\n                        } else if (Character.isLowSurrogate((char) cu)) {\n                            if (codeunits.size() == 0) {\n                                throw new ProtocolException(\"Expected high surrogate char\");\n                            }\n\n                            codeunits.add((char) cu);\n                            buffer.write(new String(new int[]{codeunits.get(0), codeunits.get(1)}, 0, 2)\n                                    .getBytes(\"UTF-8\"));\n                            codeunits.clear();\n                        } else {\n                            buffer.write(new String(new int[]{cu}, 0, 1).getBytes(\"UTF-8\"));\n                        }\n                        continue;\n                    } catch (UnsupportedEncodingException e) {\n                        throw new AssertionError(e);\n                    } catch (IOException ex) {\n                        throw new ProtocolException(\"Invalid unicode sequence\");\n                    }\n                } else {\n                    int off = ESCAPE_CHARS.indexOf(ch);\n                    if (off == -1) {\n                        throw new ProtocolException(\"Expected control char\");\n                    }\n                    ch = ESCAPE_CHAR_VALS[off];\n                }\n            }\n            buffer.write(new byte[]{ch});\n        }\n        return buffer.readByteString();\n    }",
        "modified_code": "private ByteString readJsonString(boolean skipContext)\n            throws IOException {\n        Buffer buffer = new Buffer();\n        ArrayList<Character> codejnitz = new ArrayList<>();\n        if (!skipContext) {\n            context.read();\n        }\n        readJsonSyntaxChar(QUOTE);\n        while (true) {\n            byte ch = reader.read();\n            if (ch == QUOTE[0]) {\n                break;\n            }\n            if (ch == ESCSEQ[0]) {\n                ch = reader.read();\n                if (ch == ESCSEQ[1]) {\n                    transport.read(tmpbuf, 0, 4);\n                    short cu = (short) (\n                            ((short) hexVal(tmpbuf[0]) << 12)\n                                    + ((short) hexVal(tmpbuf[1]) << 8)\n                                    + ((short) hexVal(tmpbuf[2]) << 4)\n                                    + (short) hexVal(tmpbuf[3]));\n                    try {\n                        if (Character.isHighSurrogate((char) cu)) {\n                            if (codejnitz.size() > 0) {\n                                throw new ProtocolException(\"Expected low surrogate char\");\n                            }\n                            codejnitz.add((char) cu);\n                        } else if (Character.isLowSurrogate((char) cu)) {\n                            if (codejnitz.size() == 0) {\n                                throw new ProtocolException(\"Expected high surrogate char\");\n                            }\n\n                            codejnitz.add((char) cu);\n                            buffer.write(new String(new int[]{codejnitz.get(0), codejnitz.get(1)}, 0, 2)\n                                    .getBytes(\"UTF-8\"));\n                            codejnitz.clear();\n                        } else {\n                            buffer.write(new String(new int[]{cu}, 0, 1).getBytes(\"UTF-8\"));\n                        }\n                        continue;\n                    } catch (UnsupportedEncodingException e) {\n                        throw new AssertionError(e);\n                    } catch (IOException ex) {\n                        throw new ProtocolException(\"Invalid unicode sequence\");\n                    }\n                } else {\n                    int off = ESCAPE_CHARS.indexOf(ch);\n                    if (off == -1) {\n                        throw new ProtocolException(\"Expected control char\");\n                    }\n                    ch = ESCAPE_CHAR_VALS[off];\n                }\n            }\n            buffer.write(new byte[]{ch});\n        }\n        return buffer.readByteString();\n    }",
        "explanations_by_ours": [
            "the codejnitz of the JSON string.",
            "the codejnitz of the string.",
            "the codejnitz array."
        ],
        "corrections_by_ours": [
            "string",
            "json",
            "array"
        ],
        "corrections_by_baseline": [
            "pcode",
            "opCode",
            "code",
            "cz",
            "CZ",
            "sCode",
            "pcode5Number",
            "pcode6Number",
            "opcode",
            "codeS"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resipt",
        "original_variable": "result",
        "typo_variable": "resipt",
        "original_code": "public Map getNameBindings() {\n\n\t\tMap result = new HashMap();\n\t\tNode childNode = null;\n\t\tObject name = null;\n\t\tfor (Object obj : getNode().getChildren()) {\n\t\t\tchildNode = (Node) obj;\n\t\t\tname = childNode.getFqn().getLastElement();\n\t\t\tresult.put(name, childNode.get(CACHE_NODE_MAP_KEY));\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "public Map getNameBindings() {\n\n\t\tMap resipt = new HashMap();\n\t\tNode childNode = null;\n\t\tObject name = null;\n\t\tfor (Object obj : getNode().getChildren()) {\n\t\t\tchildNode = (Node) obj;\n\t\t\tname = childNode.getFqn().getLastElement();\n\t\t\tresipt.put(name, childNode.get(CACHE_NODE_MAP_KEY));\n\t\t}\n\t\treturn resipt;\n\t}",
        "explanations_by_ours": [
            "a map of all the names of all the nodes in the current node",
            "a map of all the names of the nodes in the current node.",
            "a map of all the names of all the nodes."
        ],
        "corrections_by_ours": [
            "map",
            "current",
            "nodes",
            "node",
            "names"
        ],
        "corrections_by_baseline": [
            "rosterPacket",
            "envelope",
            "rsmMessage",
            "srcc",
            "resp",
            "getresp",
            "rsm",
            "rsmd",
            "packet",
            "tmphandshake"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "coujy",
        "original_variable": "count",
        "typo_variable": "coujy",
        "original_code": "private void createNewVariables(NetcdfDataset ds, Variable ncVar, List<Dimension> newDims,\r\n                                  Dimension levelDim) throws InvalidRangeException {\r\n\r\n    List<Dimension> dims = ncVar.getDimensions();\r\n    int newDimIndex = dims.indexOf(levelDim);\r\n    //String shapeS = ncVar.getShapeS();\r\n\r\n    int[] origin = new int[ncVar.getRank()];\r\n    int[] shape = ncVar.getShape();\r\n    int count = 0;\r\n    for (Dimension dim : newDims) {\r\n      String name = ncVar.getShortName() + \"-\" + dim.getShortName();\r\n\r\n      origin[newDimIndex] = count;\r\n      shape[newDimIndex] = dim.getLength();\r\n\r\n      Variable varNew = ncVar.section(new Section(origin, shape));\r\n      varNew.setName(name);\r\n      varNew.setDimension(newDimIndex, dim);\r\n\r\n      // synthesize long name\r\n      String long_name = ds.findAttValueIgnoreCase(ncVar, CDM.LONG_NAME, ncVar.getShortName());\r\n      long_name = long_name + \"-\" + dim.getShortName();\r\n      ds.addVariableAttribute(varNew, new Attribute(CDM.LONG_NAME, long_name));\r\n\r\n      ds.addVariable(null, varNew);\r\n\r\n      parseInfo.format(\"Created New Variable as section = \");\r\n      varNew.getNameAndDimensions(parseInfo, true, false);\r\n      parseInfo.format(\"%n\");\r\n\r\n      count += dim.getLength();\r\n    }\r\n  }",
        "modified_code": "private void createNewVariables(NetcdfDataset ds, Variable ncVar, List<Dimension> newDims,\r\n                                  Dimension levelDim) throws InvalidRangeException {\r\n\r\n    List<Dimension> dims = ncVar.getDimensions();\r\n    int newDimIndex = dims.indexOf(levelDim);\r\n    //String shapeS = ncVar.getShapeS();\r\n\r\n    int[] origin = new int[ncVar.getRank()];\r\n    int[] shape = ncVar.getShape();\r\n    int coujy = 0;\r\n    for (Dimension dim : newDims) {\r\n      String name = ncVar.getShortName() + \"-\" + dim.getShortName();\r\n\r\n      origin[newDimIndex] = coujy;\r\n      shape[newDimIndex] = dim.getLength();\r\n\r\n      Variable varNew = ncVar.section(new Section(origin, shape));\r\n      varNew.setName(name);\r\n      varNew.setDimension(newDimIndex, dim);\r\n\r\n      // synthesize long name\r\n      String long_name = ds.findAttValueIgnoreCase(ncVar, CDM.LONG_NAME, ncVar.getShortName());\r\n      long_name = long_name + \"-\" + dim.getShortName();\r\n      ds.addVariableAttribute(varNew, new Attribute(CDM.LONG_NAME, long_name));\r\n\r\n      ds.addVariable(null, varNew);\r\n\r\n      parseInfo.format(\"Created New Variable as section = \");\r\n      varNew.getNameAndDimensions(parseInfo, true, false);\r\n      parseInfo.format(\"%n\");\r\n\r\n      coujy += dim.getLength();\r\n    }\r\n  }",
        "explanations_by_ours": [
            "The number of new variables in the dataset.",
            "The number of new variables.",
            "The number of new variables to be created."
        ],
        "corrections_by_ours": [
            "created",
            "variables",
            "dataset",
            "number",
            "new"
        ],
        "corrections_by_baseline": [
            "dou",
            "coun",
            "yc",
            "syy",
            "cyy",
            "cy",
            "CY",
            "LULC",
            "caw",
            "ou"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rechlt",
        "original_variable": "result",
        "typo_variable": "rechlt",
        "original_code": "protected static long[] bytesToLongs(final byte[] ba, final int offset, final int size) {\n\t\tlong[] result = new long[size >> 3];\n\t\tint i8 = offset;\n\t\tfor (int i = 0; i < result.length; i++) {\n\t\t\tresult[i] = Bits.getLong(ba, i8);\n\t\t\ti8 += 8;\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "protected static long[] bytesToLongs(final byte[] ba, final int offset, final int size) {\n\t\tlong[] rechlt = new long[size >> 3];\n\t\tint i8 = offset;\n\t\tfor (int i = 0; i < rechlt.length; i++) {\n\t\t\trechlt[i] = Bits.getLong(ba, i8);\n\t\t\ti8 += 8;\n\t\t}\n\t\treturn rechlt;\n\t}",
        "explanations_by_ours": [
            "the rechlt array",
            "the rechlt",
            "the long array"
        ],
        "corrections_by_ours": [
            "arrayhlt",
            "hlthlt",
            "longhlt",
            "reclong",
            "recarray",
            "recrec",
            "rechlt"
        ],
        "corrections_by_baseline": [
            "re",
            "revert",
            "andrew",
            "rem",
            "reps",
            "revs",
            "rep",
            "prelen",
            "x_re",
            "resul"
        ]
    },
    {
        "original_word": "nested",
        "typo_word": "nrstsd",
        "original_variable": "nested",
        "typo_variable": "nrstsd",
        "original_code": "void checkForCycles(QueryExpression expr) throws IllegalArgumentException {\n        // is the expression argument equal to this?\n        if (expr == this) throw new IllegalArgumentException(\"Cyclic expression detected\");\n\n        // recurse through all nested expressions that are composite expressions\n        for (int i=0; i<exprs.size(); i++) {\n            QueryExpression nested = (QueryExpression)exprs.get(i);\n            if (nested instanceof CompositeQueryExpression) {\n                ((CompositeQueryExpression)nested).checkForCycles(expr);\n            }\n            else if (nested instanceof Not) {\n                ((Not)nested).checkForCycles(expr);\n            }\n        }\n    }",
        "modified_code": "void checkForCycles(QueryExpression expr) throws IllegalArgumentException {\n        // is the expression argument equal to this?\n        if (expr == this) throw new IllegalArgumentException(\"Cyclic expression detected\");\n\n        // recurse through all nested expressions that are composite expressions\n        for (int i=0; i<exprs.size(); i++) {\n            QueryExpression nrstsd = (QueryExpression)exprs.get(i);\n            if (nrstsd instanceof CompositeQueryExpression) {\n                ((CompositeQueryExpression)nrstsd).checkForCycles(expr);\n            }\n            else if (nrstsd instanceof Not) {\n                ((Not)nrstsd).checkForCycles(expr);\n            }\n        }\n    }",
        "explanations_by_ours": [
            "The nested expression tree.",
            "the nested expression tree.",
            "The nested expression tree"
        ],
        "corrections_by_ours": [
            "nested",
            "expression",
            "tree"
        ],
        "corrections_by_baseline": [
            "rtnArr",
            "scd",
            "sttsInd",
            "stnm",
            "cust",
            "dsc",
            "nf",
            "nz",
            "isr",
            "sigma_arr"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "vohnt",
        "original_variable": "count",
        "typo_variable": "vohnt",
        "original_code": "public static java.util.Collection<BitStreamFilterType>\n  getInstalledBitStreamFilterTypes()\n  {\n    java.util.Collection<BitStreamFilterType> retval = new java.util.HashSet<BitStreamFilterType>();\n    int count = getNumBitStreamFilterTypes();\n    for(int i=0;i<count;i++)\n    {\n      BitStreamFilterType t = getBitStreamFilterType(i);\n      if (t != null)\n        retval.add(t);\n    }\n    return retval;\n  }",
        "modified_code": "public static java.util.Collection<BitStreamFilterType>\n  getInstalledBitStreamFilterTypes()\n  {\n    java.util.Collection<BitStreamFilterType> retval = new java.util.HashSet<BitStreamFilterType>();\n    int vohnt = getNumBitStreamFilterTypes();\n    for(int i=0;i<vohnt;i++)\n    {\n      BitStreamFilterType t = getBitStreamFilterType(i);\n      if (t != null)\n        retval.add(t);\n    }\n    return retval;\n  }",
        "explanations_by_ours": [
            "The number of bit stream filter types in the system.",
            "The number of bit stream filter types installed in the system.",
            "The number of bit stream filter types."
        ],
        "corrections_by_ours": [
            "bit",
            "system",
            "installed",
            "stream",
            "types",
            "number",
            "filter"
        ],
        "corrections_by_baseline": [
            "hv",
            "vmid",
            "PV",
            "pv",
            "V",
            "v",
            "vms",
            "vf",
            "vip",
            "vcc"
        ]
    },
    {
        "original_word": "attrs",
        "typo_word": "xttra",
        "original_variable": "attrs",
        "typo_variable": "xttra",
        "original_code": "private void addInclude(Node parent, List files) throws SAXException {\n        if (files != null) {\n            Iterator iter = files.iterator();\n            while (iter.hasNext()) {\n                String file = (String)iter.next();\n                AttributesImpl attrs = new AttributesImpl();\n                attrs.addAttribute(\"\", \"file\", \"file\", \"CDATA\", file);\n\n                // Create a dummy Include directive node\n                    Node includeDir =\n                        new Node.IncludeDirective(attrs, null, // XXX\n    parent);\n                processIncludeDirective(file, includeDir);\n            }\n        }\n    }",
        "modified_code": "private void addInclude(Node parent, List files) throws SAXException {\n        if (files != null) {\n            Iterator iter = files.iterator();\n            while (iter.hasNext()) {\n                String file = (String)iter.next();\n                AttributesImpl xttra = new AttributesImpl();\n                xttra.addAttribute(\"\", \"file\", \"file\", \"CDATA\", file);\n\n                // Create a dummy Include directive node\n                    Node includeDir =\n                        new Node.IncludeDirective(xttra, null, // XXX\n    parent);\n                processIncludeDirective(file, includeDir);\n            }\n        }\n    }",
        "explanations_by_ours": [
            "Attributes of the include directive.",
            "Attributes of the Include directive.",
            "Attributes of the include directive node."
        ],
        "corrections_by_ours": [
            "attributes",
            "directive",
            "node",
            "include"
        ],
        "corrections_by_baseline": [
            "curTraj",
            "xt",
            "cext",
            "tr",
            "trajArray",
            "obuff",
            "fr",
            "cline",
            "xt1",
            "ext"
        ]
    },
    {
        "original_word": "counter",
        "typo_word": "coungdr",
        "original_variable": "counter",
        "typo_variable": "coungdr",
        "original_code": "@Override\n  public long count() {\n    if (hasContainers.isEmpty()) {\n      // NO CONDITIONS: USE THE FAST COUNT\n      long counter = ((OrientVertex) vertex).countEdges(direction, labels);\n      if (limit != Integer.MAX_VALUE && counter > limit)\n        return limit;\n      return counter;\n    }\n\n    // ITERATE EDGES TO MATCH CONDITIONS\n    return super.count();\n  }",
        "modified_code": "@Override\n  public long count() {\n    if (hasContainers.isEmpty()) {\n      // NO CONDITIONS: USE THE FAST COUNT\n      long coungdr = ((OrientVertex) vertex).countEdges(direction, labels);\n      if (limit != Integer.MAX_VALUE && coungdr > limit)\n        return limit;\n      return coungdr;\n    }\n\n    // ITERATE EDGES TO MATCH CONDITIONS\n    return super.count();\n  }",
        "explanations_by_ours": [
            "The total number of edges in the graph.",
            "The total number of edges in the graph",
            "The total number of edges in this graph."
        ],
        "corrections_by_ours": [
            "number",
            "edges",
            "total",
            "graph"
        ],
        "corrections_by_baseline": [
            "cdr",
            "drss",
            "sdc",
            "dr",
            "drq",
            "cir",
            "ncx",
            "cgaw",
            "csm",
            "boustr"
        ]
    },
    {
        "original_word": "Connections",
        "typo_word": "Cojnecgions",
        "original_variable": "allConnections",
        "typo_variable": "allCojnecgions",
        "original_code": "@Override\n    public Map<String, List<Connection>> getAll() {\n        Map<String, List<Connection>> allConnections = new HashMap<String, List<Connection>>();\n        Iterator<Map.Entry<String, RunStateRecordedFutureTask<ConnectionPool>>> iterator = this\n            .getConnPools().entrySet().iterator();\n        while (iterator.hasNext()) {\n            Map.Entry<String, RunStateRecordedFutureTask<ConnectionPool>> entry = iterator.next();\n            ConnectionPool pool = FutureTaskUtil.getFutureTaskResult(entry.getValue(), logger);\n            if (null != pool) {\n                allConnections.put(entry.getKey(), pool.getAll());\n            }\n        }\n        return allConnections;\n    }",
        "modified_code": "@Override\n    public Map<String, List<Connection>> getAll() {\n        Map<String, List<Connection>> allCojnecgions = new HashMap<String, List<Connection>>();\n        Iterator<Map.Entry<String, RunStateRecordedFutureTask<ConnectionPool>>> iterator = this\n            .getConnPools().entrySet().iterator();\n        while (iterator.hasNext()) {\n            Map.Entry<String, RunStateRecordedFutureTask<ConnectionPool>> entry = iterator.next();\n            ConnectionPool pool = FutureTaskUtil.getFutureTaskResult(entry.getValue(), logger);\n            if (null != pool) {\n                allCojnecgions.put(entry.getKey(), pool.getAll());\n            }\n        }\n        return allCojnecgions;\n    }",
        "explanations_by_ours": [
            "the Map of all cojnecgions.",
            "the Map of all cojnecgions",
            "the Map of all Connections."
        ],
        "corrections_by_ours": [
            "allConnections",
            "mapCojnecgions",
            "cojnecgionsCojnecgions",
            "connectionsCojnecgions",
            "allMap",
            "allCojnecgions"
        ],
        "corrections_by_baseline": [
            "jointCounts",
            "toSynchClusters",
            "disjunctiveRefinements",
            "nelems",
            "inconsistentIndividuals",
            "involvedAliases",
            "notDefinedClusters",
            "consequences",
            "allIndividuals",
            "relationList"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vslie",
        "original_variable": "value",
        "typo_variable": "vslie",
        "original_code": "protected void downgradeAnhangElements(Document doc) throws JaxenException {\n        List nodes = XmlUtils.newXPath(\n                \"/io:openimmo/io:anbieter/io:anhang | \" +\n                        \"/io:openimmo/io:anbieter/io:immobilie/io:anhaenge/io:anhang\",\n                doc).selectNodes(doc);\n        for (Object item : nodes) {\n            Element node = (Element) item;\n\n            String value = StringUtils.trimToNull(node.getAttribute(\"gruppe\"));\n            if (\"QRCODE\".equalsIgnoreCase(value))\n                node.removeAttribute(\"gruppe\");\n            else if (\"FILM\".equalsIgnoreCase(value))\n                node.removeAttribute(\"gruppe\");\n            else if (\"FILMLINK\".equalsIgnoreCase(value))\n                node.removeAttribute(\"gruppe\");\n\n            value = StringUtils.trimToNull(node.getAttribute(\"location\"));\n            if (\"REMOTE\".equalsIgnoreCase(value))\n                node.setAttribute(\"location\", \"EXTERN\");\n\n            List childNodes = XmlUtils.newXPath(\"io:check\", doc)\n                    .selectNodes(node);\n            for (Object childItem : childNodes) {\n                node.removeChild((Node) childItem);\n            }\n        }\n    }",
        "modified_code": "protected void downgradeAnhangElements(Document doc) throws JaxenException {\n        List nodes = XmlUtils.newXPath(\n                \"/io:openimmo/io:anbieter/io:anhang | \" +\n                        \"/io:openimmo/io:anbieter/io:immobilie/io:anhaenge/io:anhang\",\n                doc).selectNodes(doc);\n        for (Object item : nodes) {\n            Element node = (Element) item;\n\n            String vslie = StringUtils.trimToNull(node.getAttribute(\"gruppe\"));\n            if (\"QRCODE\".equalsIgnoreCase(vslie))\n                node.removeAttribute(\"gruppe\");\n            else if (\"FILM\".equalsIgnoreCase(vslie))\n                node.removeAttribute(\"gruppe\");\n            else if (\"FILMLINK\".equalsIgnoreCase(vslie))\n                node.removeAttribute(\"gruppe\");\n\n            vslie = StringUtils.trimToNull(node.getAttribute(\"location\"));\n            if (\"REMOTE\".equalsIgnoreCase(vslie))\n                node.setAttribute(\"location\", \"EXTERN\");\n\n            List childNodes = XmlUtils.newXPath(\"io:check\", doc)\n                    .selectNodes(node);\n            for (Object childItem : childNodes) {\n                node.removeChild((Node) childItem);\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the VSLIE",
            "the vslie",
            "the VSLIE of the anhang"
        ],
        "corrections_by_ours": [
            "anhanglie",
            "lielie",
            "vsvs",
            "vsanhang",
            "vslie"
        ],
        "corrections_by_baseline": [
            "vz",
            "vf",
            "vgd",
            "uvz",
            "vse",
            "vdi",
            "vDk0",
            "VX",
            "vx",
            "dv1"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resuph",
        "original_variable": "result",
        "typo_variable": "resuph",
        "original_code": "protected int executeUpdate(final boolean closeQuery) {\n\t\tstart = System.currentTimeMillis();\n\n\t\tinit();\n\t\tfinal int result;\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"Executing update: \" + getQueryString());\n\t\t}\n\t\ttry {\n\t\t\tif (preparedStatement == null) {\n\t\t\t\tif (generatedColumns != null) {\n\t\t\t\t\tif (generatedColumns.length == 0) {\n\t\t\t\t\t\tresult = statement.executeUpdate(query.sql, Statement.RETURN_GENERATED_KEYS);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresult = statement.executeUpdate(query.sql, generatedColumns);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tresult = statement.executeUpdate(query.sql);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tresult = preparedStatement.executeUpdate();\n\t\t\t}\n\t\t} catch (SQLException sex) {\n\t\t\tthrow new DbSqlException(this, \"Query execution failed\", sex);\n\t\t}\n\t\tif (closeQuery) {\n\t\t\tclose();\n\t\t}\n\n\t\telapsed = System.currentTimeMillis() - start;\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"execution time: \" + elapsed + \"ms\");\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "protected int executeUpdate(final boolean closeQuery) {\n\t\tstart = System.currentTimeMillis();\n\n\t\tinit();\n\t\tfinal int resuph;\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"Executing update: \" + getQueryString());\n\t\t}\n\t\ttry {\n\t\t\tif (preparedStatement == null) {\n\t\t\t\tif (generatedColumns != null) {\n\t\t\t\t\tif (generatedColumns.length == 0) {\n\t\t\t\t\t\tresuph = statement.executeUpdate(query.sql, Statement.RETURN_GENERATED_KEYS);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresuph = statement.executeUpdate(query.sql, generatedColumns);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tresuph = statement.executeUpdate(query.sql);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tresuph = preparedStatement.executeUpdate();\n\t\t\t}\n\t\t} catch (SQLException sex) {\n\t\t\tthrow new DbSqlException(this, \"Query execution failed\", sex);\n\t\t}\n\t\tif (closeQuery) {\n\t\t\tclose();\n\t\t}\n\n\t\telapsed = System.currentTimeMillis() - start;\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"execution time: \" + elapsed + \"ms\");\n\t\t}\n\t\treturn resuph;\n\t}",
        "explanations_by_ours": [
            "the number of rows affected",
            "the number of affected rows",
            "the result of the query"
        ],
        "corrections_by_ours": [
            "result",
            "rows",
            "affected",
            "query",
            "number"
        ],
        "corrections_by_baseline": [
            "res",
            "resul",
            "usv",
            "andrew",
            "rtemp",
            "rp",
            "dys",
            "psi",
            "rho",
            "rotr"
        ]
    },
    {
        "original_word": "graphs",
        "typo_word": "vraphx",
        "original_variable": "graphson",
        "typo_variable": "vraphxon",
        "original_code": "public static Edge edgeFromJson(final JSONObject json, final Vertex out, final Vertex in, final ElementFactory factory,\n      final GraphSONMode mode, final Set<String> propertyKeys) throws IOException {\n    final OGraphSONUtility graphson = new OGraphSONUtility(mode, factory, null, propertyKeys);\n    return graphson.edgeFromJson(json, out, in);\n  }",
        "modified_code": "public static Edge edgeFromJson(final JSONObject json, final Vertex out, final Vertex in, final ElementFactory factory,\n      final GraphSONMode mode, final Set<String> propertyKeys) throws IOException {\n    final OGraphSONUtility vraphxon = new OGraphSONUtility(mode, factory, null, propertyKeys);\n    return vraphxon.edgeFromJson(json, out, in);\n  }",
        "explanations_by_ours": [
            "The GraphSONUtility instance to use.",
            "The GraphSONUtility to use.",
            "The GraphSONUtility to use for creating Vertex instances."
        ],
        "corrections_by_ours": [
            "graph",
            "vertex",
            "son",
            "creating",
            "use",
            "instances",
            "utility",
            "instance"
        ],
        "corrections_by_baseline": [
            "hysteresis",
            "psdf",
            "glomx",
            "ylogx",
            "dapex",
            "graphics2D",
            "geomDs",
            "graphson",
            "g2d",
            "vgd"
        ]
    },
    {
        "original_word": "data",
        "typo_word": "darx",
        "original_variable": "idata",
        "typo_variable": "idarx",
        "original_code": "public int DM_RINT(int word) throws IOException {\n    if (rf == null) {\n      throw new IOException(\"DM_RINT: no file to read from\");\n    }\n    if (dmLabel == null) {\n      throw new IOException(\"DM_RINT: reader not initialized\");\n    }\n    rf.seek(getOffset(word));\n    // set the order\n    if (needToSwap) {\n      //if ((dmLabel.kmachn != MTMACH) &&\n      //   ((dmLabel.kvmst && ! mvmst) ||\n      //   (mvmst && !dmLabel.kvmst))) {\n      rf.order(RandomAccessFile.LITTLE_ENDIAN);  // swap\n    } else {\n      rf.order(RandomAccessFile.BIG_ENDIAN);\n    }\n    int idata = rf.readInt();\n    if (IMISSD != dmLabel.kmissd) {\n      if (idata == dmLabel.kmissd) {\n        idata = IMISSD;\n      }\n    }\n    rf.order(RandomAccessFile.BIG_ENDIAN);\n    return idata;\n  }",
        "modified_code": "public int DM_RINT(int word) throws IOException {\n    if (rf == null) {\n      throw new IOException(\"DM_RINT: no file to read from\");\n    }\n    if (dmLabel == null) {\n      throw new IOException(\"DM_RINT: reader not initialized\");\n    }\n    rf.seek(getOffset(word));\n    // set the order\n    if (needToSwap) {\n      //if ((dmLabel.kmachn != MTMACH) &&\n      //   ((dmLabel.kvmst && ! mvmst) ||\n      //   (mvmst && !dmLabel.kvmst))) {\n      rf.order(RandomAccessFile.LITTLE_ENDIAN);  // swap\n    } else {\n      rf.order(RandomAccessFile.BIG_ENDIAN);\n    }\n    int idarx = rf.readInt();\n    if (IMISSD != dmLabel.kmissd) {\n      if (idarx == dmLabel.kmissd) {\n        idarx = IMISSD;\n      }\n    }\n    rf.order(RandomAccessFile.BIG_ENDIAN);\n    return idarx;\n  }",
        "explanations_by_ours": [
            "the word to read",
            "the word to be read",
            "the read word"
        ],
        "corrections_by_ours": [
            "wordarx",
            "readarx",
            "idword",
            "idread",
            "idarx"
        ],
        "corrections_by_baseline": [
            "eqidx",
            "idxarr",
            "idx",
            "idrct",
            "idtarr",
            "spcid",
            "subidx",
            "stid",
            "idr",
            "rIdx"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "souny",
        "original_variable": "count",
        "typo_variable": "souny",
        "original_code": "public FeatureIndexResults query(BoundingBox boundingBox, Projection projection) {\n        FeatureIndexResults results = null;\n        switch (getIndexedType()) {\n            case GEOPACKAGE:\n                long count = featureTableIndex.count(boundingBox, projection);\n                CloseableIterator<GeometryIndex> geometryIndices = featureTableIndex.query(boundingBox, projection);\n                results = new FeatureIndexGeoPackageResults(featureTableIndex, count, geometryIndices);\n                break;\n            case METADATA:\n                Cursor geometryMetadata = featureIndexer.query(boundingBox, projection);\n                results = new FeatureIndexMetadataResults(featureIndexer, geometryMetadata);\n                break;\n            case RTREE:\n                UserCustomCursor cursor = rTreeIndexTableDao.query(\n                        boundingBox, projection);\n                results = new FeatureIndexRTreeResults(rTreeIndexTableDao,\n                        cursor);\n                break;\n            default:\n                results = manualFeatureQuery.query(boundingBox, projection);\n        }\n        return results;\n    }",
        "modified_code": "public FeatureIndexResults query(BoundingBox boundingBox, Projection projection) {\n        FeatureIndexResults results = null;\n        switch (getIndexedType()) {\n            case GEOPACKAGE:\n                long souny = featureTableIndex.souny(boundingBox, projection);\n                CloseableIterator<GeometryIndex> geometryIndices = featureTableIndex.query(boundingBox, projection);\n                results = new FeatureIndexGeoPackageResults(featureTableIndex, souny, geometryIndices);\n                break;\n            case METADATA:\n                Cursor geometryMetadata = featureIndexer.query(boundingBox, projection);\n                results = new FeatureIndexMetadataResults(featureIndexer, geometryMetadata);\n                break;\n            case RTREE:\n                UserCustomCursor cursor = rTreeIndexTableDao.query(\n                        boundingBox, projection);\n                results = new FeatureIndexRTreeResults(rTreeIndexTableDao,\n                        cursor);\n                break;\n            default:\n                results = manualFeatureQuery.query(boundingBox, projection);\n        }\n        return results;\n    }",
        "explanations_by_ours": [
            "souny",
            "souny index",
            "souny value"
        ],
        "corrections_by_ours": [
            "index",
            "value"
        ],
        "corrections_by_baseline": [
            "syy",
            "cyy",
            "ycent",
            "coun",
            "dlondy",
            "yb",
            "dou",
            "wy0",
            "yc",
            "yylen"
        ]
    },
    {
        "original_word": "fields",
        "typo_word": "fidlrs",
        "original_variable": "fields",
        "typo_variable": "fidlrs",
        "original_code": "@Override\n  public OrientEdge addEdge(final Object id, Vertex outVertex, Vertex inVertex, final String label) {\n    makeActive();\n\n    String className = null;\n    String clusterName = null;\n\n    if (id != null) {\n      if (id instanceof String) {\n        // PARSE ARGUMENTS\n        final String[] args = ((String) id).split(\",\");\n        for (String s : args) {\n          if (s.startsWith(CLASS_PREFIX))\n            // GET THE CLASS NAME\n            className = s.substring(CLASS_PREFIX.length());\n          else if (s.startsWith(CLUSTER_PREFIX))\n            // GET THE CLASS NAME\n            clusterName = s.substring(CLUSTER_PREFIX.length());\n        }\n      }\n    }\n\n    // SAVE THE ID TOO?\n    final Object[] fields = isSaveOriginalIds() && id != null ? new Object[] { OrientElement.DEF_ORIGINAL_ID_FIELDNAME, id } : null;\n\n    if (outVertex instanceof PartitionVertex)\n      // WRAPPED: GET THE BASE VERTEX\n      outVertex = ((PartitionVertex) outVertex).getBaseVertex();\n\n    if (inVertex instanceof PartitionVertex)\n      // WRAPPED: GET THE BASE VERTEX\n      inVertex = ((PartitionVertex) inVertex).getBaseVertex();\n\n    return ((OrientVertex) outVertex).addEdge(label, (OrientVertex) inVertex, className, clusterName, fields);\n  }",
        "modified_code": "@Override\n  public OrientEdge addEdge(final Object id, Vertex outVertex, Vertex inVertex, final String label) {\n    makeActive();\n\n    String className = null;\n    String clusterName = null;\n\n    if (id != null) {\n      if (id instanceof String) {\n        // PARSE ARGUMENTS\n        final String[] args = ((String) id).split(\",\");\n        for (String s : args) {\n          if (s.startsWith(CLASS_PREFIX))\n            // GET THE CLASS NAME\n            className = s.substring(CLASS_PREFIX.length());\n          else if (s.startsWith(CLUSTER_PREFIX))\n            // GET THE CLASS NAME\n            clusterName = s.substring(CLUSTER_PREFIX.length());\n        }\n      }\n    }\n\n    // SAVE THE ID TOO?\n    final Object[] fidlrs = isSaveOriginalIds() && id != null ? new Object[] { OrientElement.DEF_ORIGINAL_ID_FIELDNAME, id } : null;\n\n    if (outVertex instanceof PartitionVertex)\n      // WRAPPED: GET THE BASE VERTEX\n      outVertex = ((PartitionVertex) outVertex).getBaseVertex();\n\n    if (inVertex instanceof PartitionVertex)\n      // WRAPPED: GET THE BASE VERTEX\n      inVertex = ((PartitionVertex) inVertex).getBaseVertex();\n\n    return ((OrientVertex) outVertex).addEdge(label, (OrientVertex) inVertex, className, clusterName, fidlrs);\n  }",
        "explanations_by_ours": [
            "The id of the edge to be added.",
            "The id of the edge.",
            "The id of the edge to add."
        ],
        "corrections_by_ours": [
            "idlrs",
            "addlrs",
            "addedlrs",
            "edgelrs",
            "fidadd",
            "fidid",
            "fidedge",
            "fidadded",
            "fidlrs"
        ],
        "corrections_by_baseline": [
            "fids",
            "drs",
            "sbbIDs",
            "sids",
            "rids",
            "hrs",
            "idrct",
            "sbbIDSet",
            "sidIds",
            "rcidpe"
        ]
    },
    {
        "original_word": "params",
        "typo_word": "pxraks",
        "original_variable": "params",
        "typo_variable": "pxraks",
        "original_code": "protected Object getDomainObjectInstance(MethodInvocation invocation) {\n\t\tObject[] args;\n\t\tClass<?>[] params;\n\n\t\tparams = invocation.getMethod().getParameterTypes();\n\t\targs = invocation.getArguments();\n\n\t\tfor (int i = 0; i < params.length; i++) {\n\t\t\tif (processDomainObjectClass.isAssignableFrom(params[i])) {\n\t\t\t\treturn args[i];\n\t\t\t}\n\t\t}\n\n\t\tthrow new AuthorizationServiceException(\"MethodInvocation: \" + invocation\n\t\t\t\t+ \" did not provide any argument of type: \" + processDomainObjectClass);\n\t}",
        "modified_code": "protected Object getDomainObjectInstance(MethodInvocation invocation) {\n\t\tObject[] args;\n\t\tClass<?>[] pxraks;\n\n\t\tpxraks = invocation.getMethod().getParameterTypes();\n\t\targs = invocation.getArguments();\n\n\t\tfor (int i = 0; i < pxraks.length; i++) {\n\t\t\tif (processDomainObjectClass.isAssignableFrom(pxraks[i])) {\n\t\t\t\treturn args[i];\n\t\t\t}\n\t\t}\n\n\t\tthrow new AuthorizationServiceException(\"MethodInvocation: \" + invocation\n\t\t\t\t+ \" did not provide any argument of type: \" + processDomainObjectClass);\n\t}",
        "explanations_by_ours": [
            "the parameter types of the process domain class",
            "the parameter types of the method",
            "the parameter types"
        ],
        "corrections_by_ours": [
            "parameter",
            "class",
            "process",
            "domain",
            "types",
            "method"
        ],
        "corrections_by_baseline": [
            "pxpsx",
            "xpts",
            "pixels",
            "dks",
            "zps",
            "ks",
            "ksgrid",
            "peks",
            "tileDaos",
            "charts"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "valid",
        "original_variable": "value",
        "typo_variable": "valid",
        "original_code": "public static int hashCodeOfStringArray(String[] stringArray) {\n        if (stringArray == null) {\n            return 0;\n        }\n        int hashCode = 17;\n        for (int i = 0; i < stringArray.length; i++) {\n            String value = stringArray[i];\n            hashCode = hashCode * 31 + (value == null ? 0 : value.hashCode());\n        }\n        return hashCode;\n    }",
        "modified_code": "public static int hashCodeOfStringArray(String[] stringArray) {\n        if (stringArray == null) {\n            return 0;\n        }\n        int hashCode = 17;\n        for (int i = 0; i < stringArray.length; i++) {\n            String valid = stringArray[i];\n            hashCode = hashCode * 31 + (valid == null ? 0 : valid.hashCode());\n        }\n        return hashCode;\n    }",
        "explanations_by_ours": [
            "the valid string",
            "the valid",
            "the valid string array"
        ],
        "corrections_by_ours": [
            "string",
            "array"
        ],
        "corrections_by_baseline": [
            "valid",
            "isValid",
            "validated",
            "innerValid",
            "validator",
            "idate",
            "validateWithValidator",
            "validDate",
            "validators",
            "validatorClass"
        ]
    },
    {
        "original_word": "retval",
        "typo_word": "regvxl",
        "original_variable": "retval",
        "typo_variable": "regvxl",
        "original_code": "boolean alreadyLoadedLibrary(String aLibraryName, Long aMajorVersion)\n  {\n    boolean retval = false;\n    Set<Long> foundVersions = mLoadedLibraries.get(aLibraryName);\n    if (foundVersions != null)\n    {\n      // we found at least some versions\n      if (aMajorVersion == null || foundVersions.contains(aMajorVersion))\n      {\n        retval = true;\n      }\n      else\n      {\n        log\n            .warn(\n                \"Attempting load of {}, version {}, but already loaded verions: {}.\"\n                    + \"  We will attempt to load the specified version but behavior is undefined\",\n                new Object[]\n                {\n                    aLibraryName, aMajorVersion, foundVersions.toArray()\n                });\n      }\n    }\n    return retval;\n  }",
        "modified_code": "boolean alreadyLoadedLibrary(String aLibraryName, Long aMajorVersion)\n  {\n    boolean regvxl = false;\n    Set<Long> foundVersions = mLoadedLibraries.get(aLibraryName);\n    if (foundVersions != null)\n    {\n      // we found at least some versions\n      if (aMajorVersion == null || foundVersions.contains(aMajorVersion))\n      {\n        regvxl = true;\n      }\n      else\n      {\n        log\n            .warn(\n                \"Attempting load of {}, version {}, but already loaded verions: {}.\"\n                    + \"  We will attempt to load the specified version but behavior is undefined\",\n                new Object[]\n                {\n                    aLibraryName, aMajorVersion, foundVersions.toArray()\n                });\n      }\n    }\n    return regvxl;\n  }",
        "explanations_by_ours": [
            "<code>true</code> if the library is already loaded,",
            "<code>true</code> if the library is already loaded.",
            "<code>true</code> if the library is already loaded and"
        ],
        "corrections_by_ours": [
            "already",
            "<code>true<",
            "loaded,",
            "loaded",
            "library",
            "code>"
        ],
        "corrections_by_baseline": [
            "reg",
            "regExp",
            "rg",
            "expReg",
            "nrg",
            "rp",
            "rgp",
            "rtnArr",
            "sr",
            "rngx"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rfsuot",
        "original_variable": "result",
        "typo_variable": "rfsuot",
        "original_code": "protected Node<ElkClass> queryEquivalentClasses(\n\t\t\tfinal ElkClassExpression classExpression)\n\t\t\tthrows ElkInconsistentOntologyException, ElkException {\n\n\t\tfinal Node<ElkClass> result;\n\n\t\tif (computeQuery(classExpression, false)) {\n\n\t\t\tfinal Node<ElkClass> r = classExpressionQueryState_\n\t\t\t\t\t.getEquivalentClasses(classExpression);\n\t\t\tif (r == null) {\n\t\t\t\tresult = classTaxonomyState.getTaxonomy().getBottomNode();\n\t\t\t} else {\n\t\t\t\tresult = r;\n\t\t\t}\n\n\t\t} else {\n\t\t\t// classExpression couldn't be indexed; pretend it is a fresh class\n\n\t\t\tresult = new QueryNode<ElkClass>(ElkClassKeyProvider.INSTANCE);\n\t\t}\n\n\t\tincompleteness_.log(\n\t\t\t\tincompleteness_.getIncompletenessMonitorForClassExpressionQuery(\n\t\t\t\t\t\tclassExpressionQueryState_\n\t\t\t\t\t\t\t\t.getOccurrenceStore(classExpression)));\n\t\treturn result;\n\t}",
        "modified_code": "protected Node<ElkClass> queryEquivalentClasses(\n\t\t\tfinal ElkClassExpression classExpression)\n\t\t\tthrows ElkInconsistentOntologyException, ElkException {\n\n\t\tfinal Node<ElkClass> rfsuot;\n\n\t\tif (computeQuery(classExpression, false)) {\n\n\t\t\tfinal Node<ElkClass> r = classExpressionQueryState_\n\t\t\t\t\t.getEquivalentClasses(classExpression);\n\t\t\tif (r == null) {\n\t\t\t\trfsuot = classTaxonomyState.getTaxonomy().getBottomNode();\n\t\t\t} else {\n\t\t\t\trfsuot = r;\n\t\t\t}\n\n\t\t} else {\n\t\t\t// classExpression couldn't be indexed; pretend it is a fresh class\n\n\t\t\trfsuot = new QueryNode<ElkClass>(ElkClassKeyProvider.INSTANCE);\n\t\t}\n\n\t\tincompleteness_.log(\n\t\t\t\tincompleteness_.getIncompletenessMonitorForClassExpressionQuery(\n\t\t\t\t\t\tclassExpressionQueryState_\n\t\t\t\t\t\t\t\t.getOccurrenceStore(classExpression)));\n\t\treturn rfsuot;\n\t}",
        "explanations_by_ours": [
            "the node representing the equivalent classes",
            "the node representing the result of the query",
            "the node representing the node for the equivalent classes"
        ],
        "corrections_by_ours": [
            "result",
            "representing",
            "classes",
            "equivalent",
            "node",
            "query"
        ],
        "corrections_by_baseline": [
            "rtc",
            "urlonv",
            "iprt",
            "otps",
            "rtn",
            "urlatv",
            "datarun",
            "irw",
            "pihalf",
            "wrpUnchecked"
        ]
    },
    {
        "original_word": "milli",
        "typo_word": "miklo",
        "original_variable": "milliPause",
        "typo_variable": "mikloPause",
        "original_code": "public void throttle() throws InterruptedException\n    {\n        // Don't introduce any pause on the first call.\n        if (!firstCall)\n        {\n            // Check if there is any time left in the cycle since the last throttle call to this method and introduce a\n            // short pause to fill that time if there is.\n            long remainingTimeNanos = timeToThrottleNanos();\n\n            while (remainingTimeNanos > 0)\n            {\n                long milliPause = remainingTimeNanos / 1000000;\n                int nanoPause = (int) (remainingTimeNanos % 1000000);\n\n                Thread.sleep(milliPause, nanoPause);\n\n                remainingTimeNanos = timeToThrottleNanos();\n            }\n        }\n        else\n        {\n            firstCall = false;\n        }\n    }",
        "modified_code": "public void throttle() throws InterruptedException\n    {\n        // Don't introduce any pause on the first call.\n        if (!firstCall)\n        {\n            // Check if there is any time left in the cycle since the last throttle call to this method and introduce a\n            // short pause to fill that time if there is.\n            long remainingTimeNanos = timeToThrottleNanos();\n\n            while (remainingTimeNanos > 0)\n            {\n                long mikloPause = remainingTimeNanos / 1000000;\n                int nanoPause = (int) (remainingTimeNanos % 1000000);\n\n                Thread.sleep(mikloPause, nanoPause);\n\n                remainingTimeNanos = timeToThrottleNanos();\n            }\n        }\n        else\n        {\n            firstCall = false;\n        }\n    }",
        "explanations_by_ours": [
            "The amount of time to wait before giving up.",
            "The amount of time to wait for the current thread to finish before giving",
            "The amount of time to wait for the current thread to finish."
        ],
        "corrections_by_ours": [
            "timePause",
            "mikloTime",
            "mikloWait",
            "finishPause",
            "amountPause",
            "givingPause",
            "mikloFinish",
            "mikloAmount",
            "mikloCurrent",
            "currentPause"
        ],
        "corrections_by_baseline": [
            "milliPause",
            "nanoPause",
            "EPSILON",
            "epsilon",
            "sound",
            "temp_delay",
            "initialDelay",
            "timeToPauseNanos",
            "soundListener",
            "parkTimeout"
        ]
    },
    {
        "original_word": "document",
        "typo_word": "docujenr",
        "original_variable": "documentIndexed",
        "typo_variable": "docujenrIndexed",
        "original_code": "public long rebuild(final OProgressListener iProgressListener) {\n    long documentIndexed;\n\n    final boolean intentInstalled = getDatabase().declareIntent(new OIntentMassiveInsert());\n\n    acquireExclusiveLock();\n    try {\n      // DO NOT REORDER 2 assignments bellow\n      // see #getRebuildVersion()\n      rebuilding = true;\n      rebuildVersion.incrementAndGet();\n\n      try {\n        if (indexId >= 0) {\n          storage.deleteIndexEngine(indexId);\n        }\n      } catch (Exception e) {\n        OLogManager.instance().error(this, \"Error during index '%s' delete\", e, name);\n      }\n\n      removeValuesContainer();\n\n      indexId = storage\n          .addIndexEngine(name, algorithm, type, indexDefinition, determineValueSerializer(), isAutomatic(), true, version, 1,\n              this instanceof OIndexMultiValues, getEngineProperties(), clustersToIndex, metadata);\n      apiVersion = OAbstractPaginatedStorage.extractEngineAPIVersion(indexId);\n\n      onIndexEngineChange(indexId);\n    } catch (Exception e) {\n      try {\n        if (indexId >= 0)\n          storage.clearIndex(indexId);\n      } catch (Exception e2) {\n        OLogManager.instance().error(this, \"Error during index rebuild\", e2);\n        // IGNORE EXCEPTION: IF THE REBUILD WAS LAUNCHED IN CASE OF RID INVALID CLEAR ALWAYS GOES IN ERROR\n      }\n\n      rebuilding = false;\n      throw OException.wrapException(new OIndexException(\"Error on rebuilding the index for clusters: \" + clustersToIndex), e);\n    } finally {\n      releaseExclusiveLock();\n    }\n\n    acquireSharedLock();\n    try {\n      documentIndexed = fillIndex(iProgressListener, true);\n    } catch (final Exception e) {\n      OLogManager.instance().error(this, \"Error during index rebuild\", e);\n      try {\n        if (indexId >= 0)\n          storage.clearIndex(indexId);\n      } catch (Exception e2) {\n        OLogManager.instance().error(this, \"Error during index rebuild\", e2);\n        // IGNORE EXCEPTION: IF THE REBUILD WAS LAUNCHED IN CASE OF RID INVALID CLEAR ALWAYS GOES IN ERROR\n      }\n\n      throw OException.wrapException(new OIndexException(\"Error on rebuilding the index for clusters: \" + clustersToIndex), e);\n    } finally {\n      rebuilding = false;\n\n      if (intentInstalled)\n        getDatabase().declareIntent(null);\n\n      releaseSharedLock();\n    }\n\n    return documentIndexed;\n  }",
        "modified_code": "public long rebuild(final OProgressListener iProgressListener) {\n    long docujenrIndexed;\n\n    final boolean intentInstalled = getDatabase().declareIntent(new OIntentMassiveInsert());\n\n    acquireExclusiveLock();\n    try {\n      // DO NOT REORDER 2 assignments bellow\n      // see #getRebuildVersion()\n      rebuilding = true;\n      rebuildVersion.incrementAndGet();\n\n      try {\n        if (indexId >= 0) {\n          storage.deleteIndexEngine(indexId);\n        }\n      } catch (Exception e) {\n        OLogManager.instance().error(this, \"Error during index '%s' delete\", e, name);\n      }\n\n      removeValuesContainer();\n\n      indexId = storage\n          .addIndexEngine(name, algorithm, type, indexDefinition, determineValueSerializer(), isAutomatic(), true, version, 1,\n              this instanceof OIndexMultiValues, getEngineProperties(), clustersToIndex, metadata);\n      apiVersion = OAbstractPaginatedStorage.extractEngineAPIVersion(indexId);\n\n      onIndexEngineChange(indexId);\n    } catch (Exception e) {\n      try {\n        if (indexId >= 0)\n          storage.clearIndex(indexId);\n      } catch (Exception e2) {\n        OLogManager.instance().error(this, \"Error during index rebuild\", e2);\n        // IGNORE EXCEPTION: IF THE REBUILD WAS LAUNCHED IN CASE OF RID INVALID CLEAR ALWAYS GOES IN ERROR\n      }\n\n      rebuilding = false;\n      throw OException.wrapException(new OIndexException(\"Error on rebuilding the index for clusters: \" + clustersToIndex), e);\n    } finally {\n      releaseExclusiveLock();\n    }\n\n    acquireSharedLock();\n    try {\n      docujenrIndexed = fillIndex(iProgressListener, true);\n    } catch (final Exception e) {\n      OLogManager.instance().error(this, \"Error during index rebuild\", e);\n      try {\n        if (indexId >= 0)\n          storage.clearIndex(indexId);\n      } catch (Exception e2) {\n        OLogManager.instance().error(this, \"Error during index rebuild\", e2);\n        // IGNORE EXCEPTION: IF THE REBUILD WAS LAUNCHED IN CASE OF RID INVALID CLEAR ALWAYS GOES IN ERROR\n      }\n\n      throw OException.wrapException(new OIndexException(\"Error on rebuilding the index for clusters: \" + clustersToIndex), e);\n    } finally {\n      rebuilding = false;\n\n      if (intentInstalled)\n        getDatabase().declareIntent(null);\n\n      releaseSharedLock();\n    }\n\n    return docujenrIndexed;\n  }",
        "explanations_by_ours": [
            "The number of documents that were actually indexed.",
            "The number of documents that were actually indexed",
            "Number of documents that were actually indexed."
        ],
        "corrections_by_ours": [
            "documentsIndexed",
            "docujenrNumber",
            "numberIndexed",
            "indexedIndexed",
            "actuallyIndexed",
            "docujenrDocuments",
            "docujenrActually",
            "docujenrIndexed"
        ],
        "corrections_by_baseline": [
            "documentIndexed",
            "rTreeIndexed",
            "indexed",
            "collectionCrDs",
            "docs",
            "totalIndexed",
            "lastIndexed",
            "docBase",
            "ksDoc",
            "indexEntry"
        ]
    },
    {
        "original_word": "masked",
        "typo_word": "kasoed",
        "original_variable": "maskedEvents",
        "typo_variable": "kasoedEvents",
        "original_code": "public void afterACAttach(ActivityContextHandle ach) {\n\t\t\n\t\t// add to cache\n\t\tcacheData.attachActivityContext(ach);\n\n\t\t// update event mask\n\t\tSet<EventTypeID> maskedEvents = getSbbComponent().getDescriptor().getDefaultEventMask();\n\t\tif (maskedEvents != null && !maskedEvents.isEmpty()) {\n\t\t\tcacheData.updateEventMask(ach, new HashSet<EventTypeID>(maskedEvents));\n\t\t}\n\t\t\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"Sbb entity \"+getSbbEntityId()+\" attached to AC with handle \" + ach\n\t\t\t\t\t+ \" , events added to current mask: \" + maskedEvents);\n\t\t}\n\t}",
        "modified_code": "public void afterACAttach(ActivityContextHandle ach) {\n\t\t\n\t\t// add to cache\n\t\tcacheData.attachActivityContext(ach);\n\n\t\t// update event mask\n\t\tSet<EventTypeID> kasoedEvents = getSbbComponent().getDescriptor().getDefaultEventMask();\n\t\tif (kasoedEvents != null && !kasoedEvents.isEmpty()) {\n\t\t\tcacheData.updateEventMask(ach, new HashSet<EventTypeID>(kasoedEvents));\n\t\t}\n\t\t\n\t\tif (log.isDebugEnabled()) {\n\t\t\tlog.debug(\"Sbb entity \"+getSbbEntityId()+\" attached to AC with handle \" + ach\n\t\t\t\t\t+ \" , events added to current mask: \" + kasoedEvents);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the set of kasoed events",
            "the kasoed events",
            "the kasoed events to add to the current mask"
        ],
        "corrections_by_ours": [
            "addEvents",
            "maskEvents",
            "setEvents",
            "kasoedSet",
            "kasoedCurrent",
            "currentEvents",
            "eventsEvents",
            "kasoedAdd",
            "kasoedMask",
            "kasoedKasoed"
        ],
        "corrections_by_baseline": [
            "events",
            "maskedEvents",
            "cefEvent",
            "event",
            "startEvent",
            "startEventBeans",
            "eventData",
            "eventBeingDelivered",
            "allEventsSet",
            "sbbHandledEvent"
        ]
    },
    {
        "original_word": "notation",
        "typo_word": "jotatioj",
        "original_variable": "notation",
        "typo_variable": "jotatioj",
        "original_code": "public String polymerToHELM2() {\r\n    StringBuilder notation = new StringBuilder();\r\n    for (int i = 0; i < listOfPolymers.size(); i++) {\r\n      if (listOfPolymers.get(i).isAnnotationHere()) {\r\n        notation.append(listOfPolymers.get(i).getPolymerID() + \"{\" + listOfPolymers.get(i).toHELM2() + \"}\\\"\"\r\n            + listOfPolymers.get(i).getAnnotation() + \"\\\"|\");\r\n      } else {\r\n        notation.append(listOfPolymers.get(i).getPolymerID() + \"{\" + listOfPolymers.get(i).toHELM2() + \"}\" + \"|\");\r\n      }\r\n    }\r\n\r\n    notation.setLength(notation.length() - 1);\r\n    return notation.toString();\r\n  }",
        "modified_code": "public String polymerToHELM2() {\r\n    StringBuilder jotatioj = new StringBuilder();\r\n    for (int i = 0; i < listOfPolymers.size(); i++) {\r\n      if (listOfPolymers.get(i).isAnnotationHere()) {\r\n        jotatioj.append(listOfPolymers.get(i).getPolymerID() + \"{\" + listOfPolymers.get(i).toHELM2() + \"}\\\"\"\r\n            + listOfPolymers.get(i).getAnnotation() + \"\\\"|\");\r\n      } else {\r\n        jotatioj.append(listOfPolymers.get(i).getPolymerID() + \"{\" + listOfPolymers.get(i).toHELM2() + \"}\" + \"|\");\r\n      }\r\n    }\r\n\r\n    jotatioj.setLength(jotatioj.length() - 1);\r\n    return jotatioj.toString();\r\n  }",
        "explanations_by_ours": [
            "The list of Polymer objects to convert",
            "The list of Polymer objects to convert.",
            "The list of Polymer objects"
        ],
        "corrections_by_ours": [
            "list",
            "convert",
            "polymer",
            "objects"
        ],
        "corrections_by_baseline": [
            "JD",
            "j",
            "J",
            "g2j",
            "j0",
            "jjj",
            "nj",
            "j_otp",
            "jbeg",
            "jj0"
        ]
    },
    {
        "original_word": "Config",
        "typo_word": "Cpnfiv",
        "original_variable": "dcConfig",
        "typo_variable": "dcCpnfiv",
        "original_code": "public String getDataCenterOfServer(final String server) {\n\n    final ODocument dcs = configuration.field(DCS);\n    if (dcs != null) {\n      for (String dc : dcs.fieldNames()) {\n        final ODocument dcConfig = dcs.field(dc);\n        if (dcConfig != null) {\n          final List<String> dcServers = dcConfig.field(\"servers\");\n          if (dcServers != null && !dcServers.isEmpty()) {\n            if (dcServers.contains(server))\n              // FOUND\n              return dc;\n          }\n        }\n      }\n    }\n\n// NOT FOUND\n    return null;\n  }",
        "modified_code": "public String getDataCenterOfServer(final String server) {\n\n    final ODocument dcs = configuration.field(DCS);\n    if (dcs != null) {\n      for (String dc : dcs.fieldNames()) {\n        final ODocument dcCpnfiv = dcs.field(dc);\n        if (dcCpnfiv != null) {\n          final List<String> dcServers = dcCpnfiv.field(\"servers\");\n          if (dcServers != null && !dcServers.isEmpty()) {\n            if (dcServers.contains(server))\n              // FOUND\n              return dc;\n          }\n        }\n      }\n    }\n\n// NOT FOUND\n    return null;\n  }",
        "explanations_by_ours": [
            "The data center of the server.",
            "the data center of the server",
            "the data center of the server."
        ],
        "corrections_by_ours": [
            "dcCenter",
            "dataCpnfiv",
            "serverCpnfiv",
            "centerCpnfiv",
            "dcData",
            "dcServer",
            "dcCpnfiv"
        ],
        "corrections_by_baseline": [
            "v_ecf",
            "sdc",
            "anonPF",
            "dcs",
            "dcm",
            "cdr",
            "dc",
            "ncd",
            "acf",
            "csm"
        ]
    },
    {
        "original_word": "bottom",
        "typo_word": "fothom",
        "original_variable": "bottom",
        "typo_variable": "fothom",
        "original_code": "public static boolean intersect( PlaneNormal3D_F64 plane , LineParametric3D_F64 line , Point3D_F64 intersection ) {\n\t\tdouble dx = plane.p.x - line.p.x;\n\t\tdouble dy = plane.p.y - line.p.y;\n\t\tdouble dz = plane.p.z - line.p.z;\n\n\t\tdouble top = dx*plane.n.x + dy*plane.n.y + dz*plane.n.z;\n\t\tdouble bottom = line.slope.dot(plane.n);\n\n\t\tif( bottom == 0 )\n\t\t\treturn false;\n\n\t\tdouble d = top/bottom;\n\n\t\tintersection.x = line.p.x + d*line.slope.x;\n\t\tintersection.y = line.p.y + d*line.slope.y;\n\t\tintersection.z = line.p.z + d*line.slope.z;\n\n\t\treturn true;\n\t}",
        "modified_code": "public static boolean intersect( PlaneNormal3D_F64 plane , LineParametric3D_F64 line , Point3D_F64 intersection ) {\n\t\tdouble dx = plane.p.x - line.p.x;\n\t\tdouble dy = plane.p.y - line.p.y;\n\t\tdouble dz = plane.p.z - line.p.z;\n\n\t\tdouble top = dx*plane.n.x + dy*plane.n.y + dz*plane.n.z;\n\t\tdouble fothom = line.slope.dot(plane.n);\n\n\t\tif( fothom == 0 )\n\t\t\treturn false;\n\n\t\tdouble d = top/fothom;\n\n\t\tintersection.x = line.p.x + d*line.slope.x;\n\t\tintersection.y = line.p.y + d*line.slope.y;\n\t\tintersection.z = line.p.z + d*line.slope.z;\n\n\t\treturn true;\n\t}",
        "explanations_by_ours": [
            "The fothom of the line segment",
            "The fothom of the plane",
            "Slope of the plane"
        ],
        "corrections_by_ours": [
            "line",
            "segment",
            "slope",
            "plane"
        ],
        "corrections_by_baseline": [
            "hf",
            "emf",
            "pihalf",
            "mf",
            "fhi",
            "Sterm",
            "etf",
            "atomp",
            "icf",
            "fmd"
        ]
    },
    {
        "original_word": "local",
        "typo_word": "kpcal",
        "original_variable": "localState",
        "typo_variable": "kpcalState",
        "original_code": "protected void update(CollectionUpdateType force) throws IOException {  // this may be called from a background thread, or from checkState() request thread\n    State localState;\n\n    synchronized (lock) {\n      if (first) {\n        state = checkState();\n        state.lastInvChange = System.currentTimeMillis();\n        return;\n      }\n      // do the update in a local object\n      localState = state.copy();\n    }\n\n    updateCollection(localState, force);\n    // makeDatasetTop(localState);\n    localState.lastInvChange = System.currentTimeMillis();\n\n    // switch to live\n    synchronized (lock) {\n      state = localState;\n    }\n\n  }",
        "modified_code": "protected void update(CollectionUpdateType force) throws IOException {  // this may be called from a background thread, or from checkState() request thread\n    State kpcalState;\n\n    synchronized (lock) {\n      if (first) {\n        state = checkState();\n        state.lastInvChange = System.currentTimeMillis();\n        return;\n      }\n      // do the update in a local object\n      kpcalState = state.copy();\n    }\n\n    updateCollection(kpcalState, force);\n    // makeDatasetTop(localState);\n    kpcalState.lastInvChange = System.currentTimeMillis();\n\n    // switch to live\n    synchronized (lock) {\n      state = kpcalState;\n    }\n\n  }",
        "explanations_by_ours": [
            "the new state of the collection.",
            "the state of the collection.",
            "the new state of the collection"
        ],
        "corrections_by_ours": [
            "kpstateState",
            "kpcollectionState",
            "kpcalCollection",
            "statecalState",
            "collectioncalState",
            "newcalState",
            "kpnewState",
            "kpcalNew",
            "kpcalState"
        ],
        "corrections_by_baseline": [
            "wfState",
            "state",
            "fadeState",
            "wfsState",
            "powerState",
            "stateSet",
            "goalState",
            "stateRef",
            "valueState",
            "states"
        ]
    },
    {
        "original_word": "xaxis",
        "typo_word": "xzxus",
        "original_variable": "xaxis",
        "typo_variable": "xzxus",
        "original_code": "ProjectionImpl  nowrad(int hoff, float rlat1, float rlon1, float rlat2, float rlon2, float dlat, float dlon, Date dd) {\r\n        List<Dimension> dims = new ArrayList<>();\r\n        Dimension dimT = new Dimension(\"time\", 1, true, false, false);\r\n\r\n        ncfile.addDimension(null, dimT);\r\n\r\n        String   timeCoordName = \"time\";\r\n        Variable taxis         = new Variable(ncfile, null, null, timeCoordName);\r\n\r\n        taxis.setDataType(DataType.DOUBLE);\r\n        taxis.setDimensions(\"time\");\r\n        taxis.addAttribute(new Attribute(CDM.LONG_NAME, \"time since base date\"));\r\n        taxis.addAttribute(new Attribute(_Coordinate.AxisType, AxisType.Time.toString()));\r\n\r\n        double[] tdata = new double[1];\r\n\r\n        tdata[0] = dd.getTime();\r\n\r\n        Array dataT = Array.factory(DataType.DOUBLE, new int[] { 1 }, tdata);\r\n\r\n        taxis.setCachedData(dataT, false);\r\n\r\n        DateFormatter formatter = new DateFormatter();\r\n\r\n        taxis.addAttribute(new Attribute(CDM.UNITS, \"msecs since \" + formatter.toDateTimeStringISO(new Date(0))));\r\n        ncfile.addVariable(null, taxis);\r\n        dims.add(dimT);\r\n\r\n        Dimension jDim = new Dimension(\"lat\", numY, true, false, false);\r\n        Dimension iDim = new Dimension(\"lon\", numX, true, false, false);\r\n\r\n        dims.add(jDim);\r\n        dims.add(iDim);\r\n        ncfile.addDimension(null, iDim);\r\n        ncfile.addDimension(null, jDim);\r\n        ncfile.addAttribute(null, new Attribute(\"cdm_data_type\", FeatureType.GRID.toString()));\r\n\r\n        String   coordinates = \"time lat lon\";\r\n        Variable v           = new Variable(ncfile, null, null, cname);\r\n\r\n        v.setDataType(DataType.BYTE);\r\n        v.setDimensions(dims);\r\n        ncfile.addVariable(null, v);\r\n        v.addAttribute(new Attribute(CDM.LONG_NAME, ctitle));\r\n        v.addAttribute(new Attribute(CDM.SCALE_FACTOR, 5.0f));\r\n        v.addAttribute(new Attribute(CDM.MISSING_VALUE, 0));\r\n        v.addAttribute(new Attribute(CDM.UNITS, cunit));\r\n        v.setSPobject(new Vinfo(numX, numY, hoff));\r\n        v.addAttribute(new Attribute(_Coordinate.Axes, coordinates));\r\n\r\n        // create coordinate variables\r\n        Variable xaxis = new Variable(ncfile, null, null, \"lon\");\r\n        xaxis.setDataType(DataType.DOUBLE);\r\n        xaxis.setDimensions(\"lon\");\r\n        xaxis.addAttribute(new Attribute(CDM.LONG_NAME, \"longitude\"));\r\n        xaxis.addAttribute(new Attribute(CDM.UNITS, \"degree\"));\r\n        xaxis.addAttribute(new Attribute(_Coordinate.AxisType, \"Lon\"));\r\n\r\n        double[] data1 = new double[numX];\r\n\r\n        for (int i = 0; i < numX; i++) {\r\n            data1[i] = (double) (rlon1 + i * dlon);\r\n        }\r\n\r\n        Array dataA = Array.factory(DataType.DOUBLE, new int[] { numX }, data1);\r\n\r\n        xaxis.setCachedData(dataA, false);\r\n        ncfile.addVariable(null, xaxis);\r\n\r\n        Variable yaxis = new Variable(ncfile, null, null, \"lat\");\r\n        yaxis.setDataType(DataType.DOUBLE);\r\n        yaxis.setDimensions(\"lat\");\r\n        yaxis.addAttribute(new Attribute(CDM.LONG_NAME, \"latitude\"));\r\n        yaxis.addAttribute(new Attribute(CDM.UNITS, \"degree\"));\r\n        yaxis.addAttribute(new Attribute(_Coordinate.AxisType, \"Lat\"));\r\n        data1 = new double[numY];\r\n\r\n        for (int i = 0; i < numY; i++) {\r\n            data1[i] = rlat1 + i * dlat;\r\n        }\r\n\r\n        dataA = Array.factory(DataType.DOUBLE, new int[] { numY }, data1);\r\n        yaxis.setCachedData(dataA, false);\r\n        ncfile.addVariable(null, yaxis);\r\n\r\n        // projection\r\n        // lower left and upper right corner lat/lons\r\n        // modified cylind. equidistant or  CED with lat/lon ration != 1\r\n    /*    LatLonProjection llproj = new LatLonProjection(\"LatitudeLongitudeProjection\",\r\n                                  new ProjectionRect(rlat1, rlon1, rlat2, rlon2));\r\n        Variable ct = new Variable(ncfile, null, null, llproj.getClassName());\r\n\r\n        ct.setDataType(DataType.CHAR);\r\n        ct.setDimensions(\"\");\r\n\r\n        List params = llproj.getProjectionParameters();\r\n\r\n        for (int i = 0; i < params.size(); i++) {\r\n            Parameter p = (Parameter) params.get(i);\r\n\r\n            ct.addAttribute(new Attribute(p));\r\n        }\r\n\r\n        ct.addAttribute(new Attribute(_Coordinate.TransformType, \"Projection\"));\r\n        ct.addAttribute(new Attribute(_Coordinate.Axes, \"lat lon\"));\r\n\r\n        // fake data\r\n        dataA = Array.factory(DataType.CHAR, new int[] {});\r\n        dataA.setChar(dataA.getIndex(), ' ');\r\n        ct.setCachedData(dataA, false);\r\n        ncfile.addVariable(null, ct);\r\n      */\r\n        return null;\r\n    }",
        "modified_code": "ProjectionImpl  nowrad(int hoff, float rlat1, float rlon1, float rlat2, float rlon2, float dlat, float dlon, Date dd) {\r\n        List<Dimension> dims = new ArrayList<>();\r\n        Dimension dimT = new Dimension(\"time\", 1, true, false, false);\r\n\r\n        ncfile.addDimension(null, dimT);\r\n\r\n        String   timeCoordName = \"time\";\r\n        Variable taxis         = new Variable(ncfile, null, null, timeCoordName);\r\n\r\n        taxis.setDataType(DataType.DOUBLE);\r\n        taxis.setDimensions(\"time\");\r\n        taxis.addAttribute(new Attribute(CDM.LONG_NAME, \"time since base date\"));\r\n        taxis.addAttribute(new Attribute(_Coordinate.AxisType, AxisType.Time.toString()));\r\n\r\n        double[] tdata = new double[1];\r\n\r\n        tdata[0] = dd.getTime();\r\n\r\n        Array dataT = Array.factory(DataType.DOUBLE, new int[] { 1 }, tdata);\r\n\r\n        taxis.setCachedData(dataT, false);\r\n\r\n        DateFormatter formatter = new DateFormatter();\r\n\r\n        taxis.addAttribute(new Attribute(CDM.UNITS, \"msecs since \" + formatter.toDateTimeStringISO(new Date(0))));\r\n        ncfile.addVariable(null, taxis);\r\n        dims.add(dimT);\r\n\r\n        Dimension jDim = new Dimension(\"lat\", numY, true, false, false);\r\n        Dimension iDim = new Dimension(\"lon\", numX, true, false, false);\r\n\r\n        dims.add(jDim);\r\n        dims.add(iDim);\r\n        ncfile.addDimension(null, iDim);\r\n        ncfile.addDimension(null, jDim);\r\n        ncfile.addAttribute(null, new Attribute(\"cdm_data_type\", FeatureType.GRID.toString()));\r\n\r\n        String   coordinates = \"time lat lon\";\r\n        Variable v           = new Variable(ncfile, null, null, cname);\r\n\r\n        v.setDataType(DataType.BYTE);\r\n        v.setDimensions(dims);\r\n        ncfile.addVariable(null, v);\r\n        v.addAttribute(new Attribute(CDM.LONG_NAME, ctitle));\r\n        v.addAttribute(new Attribute(CDM.SCALE_FACTOR, 5.0f));\r\n        v.addAttribute(new Attribute(CDM.MISSING_VALUE, 0));\r\n        v.addAttribute(new Attribute(CDM.UNITS, cunit));\r\n        v.setSPobject(new Vinfo(numX, numY, hoff));\r\n        v.addAttribute(new Attribute(_Coordinate.Axes, coordinates));\r\n\r\n        // create coordinate variables\r\n        Variable xzxus = new Variable(ncfile, null, null, \"lon\");\r\n        xzxus.setDataType(DataType.DOUBLE);\r\n        xzxus.setDimensions(\"lon\");\r\n        xzxus.addAttribute(new Attribute(CDM.LONG_NAME, \"longitude\"));\r\n        xzxus.addAttribute(new Attribute(CDM.UNITS, \"degree\"));\r\n        xzxus.addAttribute(new Attribute(_Coordinate.AxisType, \"Lon\"));\r\n\r\n        double[] data1 = new double[numX];\r\n\r\n        for (int i = 0; i < numX; i++) {\r\n            data1[i] = (double) (rlon1 + i * dlon);\r\n        }\r\n\r\n        Array dataA = Array.factory(DataType.DOUBLE, new int[] { numX }, data1);\r\n\r\n        xzxus.setCachedData(dataA, false);\r\n        ncfile.addVariable(null, xzxus);\r\n\r\n        Variable yaxis = new Variable(ncfile, null, null, \"lat\");\r\n        yaxis.setDataType(DataType.DOUBLE);\r\n        yaxis.setDimensions(\"lat\");\r\n        yaxis.addAttribute(new Attribute(CDM.LONG_NAME, \"latitude\"));\r\n        yaxis.addAttribute(new Attribute(CDM.UNITS, \"degree\"));\r\n        yaxis.addAttribute(new Attribute(_Coordinate.AxisType, \"Lat\"));\r\n        data1 = new double[numY];\r\n\r\n        for (int i = 0; i < numY; i++) {\r\n            data1[i] = rlat1 + i * dlat;\r\n        }\r\n\r\n        dataA = Array.factory(DataType.DOUBLE, new int[] { numY }, data1);\r\n        yaxis.setCachedData(dataA, false);\r\n        ncfile.addVariable(null, yaxis);\r\n\r\n        // projection\r\n        // lower left and upper right corner lat/lons\r\n        // modified cylind. equidistant or  CED with lat/lon ration != 1\r\n    /*    LatLonProjection llproj = new LatLonProjection(\"LatitudeLongitudeProjection\",\r\n                                  new ProjectionRect(rlat1, rlon1, rlat2, rlon2));\r\n        Variable ct = new Variable(ncfile, null, null, llproj.getClassName());\r\n\r\n        ct.setDataType(DataType.CHAR);\r\n        ct.setDimensions(\"\");\r\n\r\n        List params = llproj.getProjectionParameters();\r\n\r\n        for (int i = 0; i < params.size(); i++) {\r\n            Parameter p = (Parameter) params.get(i);\r\n\r\n            ct.addAttribute(new Attribute(p));\r\n        }\r\n\r\n        ct.addAttribute(new Attribute(_Coordinate.TransformType, \"Projection\"));\r\n        ct.addAttribute(new Attribute(_Coordinate.Axes, \"lat lon\"));\r\n\r\n        // fake data\r\n        dataA = Array.factory(DataType.CHAR, new int[] {});\r\n        dataA.setChar(dataA.getIndex(), ' ');\r\n        ct.setCachedData(dataA, false);\r\n        ncfile.addVariable(null, ct);\r\n      */\r\n        return null;\r\n    }",
        "explanations_by_ours": [
            "org.hortonmachine.hmachine.api.hdfs.",
            "org.hortonmachine.hmachine.hdfs.hdfs",
            "The org.hortonmachine.hmachine.api."
        ],
        "corrections_by_ours": [
            "hdfs",
            "org",
            "api",
            "ton",
            "hor",
            "machine",
            "h"
        ],
        "corrections_by_baseline": [
            "oz",
            "uvz",
            "zis",
            "bsf",
            "glomx",
            "kxky",
            "zzzz",
            "xpp",
            "xh",
            "zs"
        ]
    },
    {
        "original_word": "Models",
        "typo_word": "Moceps",
        "original_variable": "resourceModels",
        "typo_variable": "resourceMoceps",
        "original_code": "@SuppressWarnings(\"unused\")\n    public List<ResourceModel> resourcesForExisting() {\n        List<ResourceModel> resourceModels = new ArrayList<>();\n        IdentificationManagerM.getInstance().getIdentification(identifiable)\n                .map(id -> new MusicUsageResource(id, true))\n                .ifPresent(resourceModels::add);\n        if (volume != null) {\n            IdentificationManagerM.getInstance().getIdentification(identifiable)\n                    .map(id -> new VolumeResource(id, volume))\n                    .ifPresent(resourceModels::add);\n        }\n        if (playlist != null) {\n            IdentificationManagerM.getInstance().getIdentification(identifiable)\n                    .map(id -> new PlaylistResource(id, playlist))\n                    .ifPresent(resourceModels::add);\n        }\n        if (trackInfo != null) {\n            IdentificationManagerM.getInstance().getIdentification(identifiable)\n                    .map(id -> new TrackInfoResource(id, trackInfo))\n                    .ifPresent(resourceModels::add);\n        }\n        return resourceModels;\n    }",
        "modified_code": "@SuppressWarnings(\"unused\")\n    public List<ResourceModel> resourcesForExisting() {\n        List<ResourceModel> resourceMoceps = new ArrayList<>();\n        IdentificationManagerM.getInstance().getIdentification(identifiable)\n                .map(id -> new MusicUsageResource(id, true))\n                .ifPresent(resourceMoceps::add);\n        if (volume != null) {\n            IdentificationManagerM.getInstance().getIdentification(identifiable)\n                    .map(id -> new VolumeResource(id, volume))\n                    .ifPresent(resourceMoceps::add);\n        }\n        if (playlist != null) {\n            IdentificationManagerM.getInstance().getIdentification(identifiable)\n                    .map(id -> new PlaylistResource(id, playlist))\n                    .ifPresent(resourceMoceps::add);\n        }\n        if (trackInfo != null) {\n            IdentificationManagerM.getInstance().getIdentification(identifiable)\n                    .map(id -> new TrackInfoResource(id, trackInfo))\n                    .ifPresent(resourceMoceps::add);\n        }\n        return resourceMoceps;\n    }",
        "explanations_by_ours": [
            "a list of all available resources for an existing identifiable.",
            "a list of all available resources for an existing identifiable",
            "the list of all available resources for an existing identifiable."
        ],
        "corrections_by_ours": [
            "resourcesMoceps",
            "resourceResources",
            "resourceMoceps",
            "identifiableMoceps",
            "listMoceps",
            "availableMoceps",
            "existingMoceps",
            "resourceExisting",
            "resourceIdentifiable",
            "resourceList"
        ],
        "corrections_by_baseline": [
            "resourceList",
            "resourceManagement",
            "serverResource",
            "halResource",
            "connectorResource",
            "resourceModels",
            "mdResource",
            "deploymentResource",
            "halResources",
            "subsystemResource"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "efsult",
        "original_variable": "result",
        "typo_variable": "efsult",
        "original_code": "protected Object\n    readAs(DapVariable atomvar, DapType basetype, List<Slice> slices)\n            throws DapException\n    {\n        if(basetype.getTypeSort() == TypeSort.Enum) {// short circuit this case\n            basetype = ((DapEnumeration) basetype).getBaseType();\n            return readAs(atomvar, basetype, slices);\n        }\n        long count = DapUtil.sliceProduct(slices);\n        Object result = LibTypeFcns.newVector(basetype, count);\n        Odometer odom = Odometer.factory(slices);\n        if(DapUtil.isContiguous(slices) && basetype.isFixedSize())\n            readContig(slices, basetype, count, odom, result);\n        else\n            readOdom(slices, basetype, odom, result);\n        return result;\n    }",
        "modified_code": "protected Object\n    readAs(DapVariable atomvar, DapType basetype, List<Slice> slices)\n            throws DapException\n    {\n        if(basetype.getTypeSort() == TypeSort.Enum) {// short circuit this case\n            basetype = ((DapEnumeration) basetype).getBaseType();\n            return readAs(atomvar, basetype, slices);\n        }\n        long count = DapUtil.sliceProduct(slices);\n        Object efsult = LibTypeFcns.newVector(basetype, count);\n        Odometer odom = Odometer.factory(slices);\n        if(DapUtil.isContiguous(slices) && basetype.isFixedSize())\n            readContig(slices, basetype, count, odom, efsult);\n        else\n            readOdom(slices, basetype, odom, efsult);\n        return efsult;\n    }",
        "explanations_by_ours": [
            "the result of the read operation",
            "the result of the operation",
            "the result of the object read"
        ],
        "corrections_by_ours": [
            "result",
            "object",
            "operation",
            "read"
        ],
        "corrections_by_baseline": [
            "ef",
            "mefd",
            "scalef",
            "etf",
            "dstruct",
            "acf",
            "ifac",
            "icf",
            "iresult",
            "ecint"
        ]
    },
    {
        "original_word": "encountered",
        "typo_word": "ehckuntered",
        "original_variable": "encountered",
        "typo_variable": "ehckuntered",
        "original_code": "@Override\n    public void readElement(final XMLExtendedStreamReader reader, final List<ModelNode> operations) throws XMLStreamException {\n        final ModelNode ejb3SubsystemAddOperation = Util.createAddOperation(SUBSYSTEM_PATH);\n        operations.add(ejb3SubsystemAddOperation);\n        readAttributes(reader);\n        // elements\n        final EnumSet<EJB3SubsystemXMLElement> encountered = EnumSet.noneOf(EJB3SubsystemXMLElement.class);\n        while (reader.hasNext() && reader.nextTag() != XMLStreamConstants.END_ELEMENT) {\n            if (EJB3SubsystemNamespace.forUri(reader.getNamespaceURI()) != getExpectedNamespace()) {\n                throw unexpectedElement(reader);\n            }\n            final EJB3SubsystemXMLElement element = EJB3SubsystemXMLElement.forName(reader.getLocalName());\n            if (!encountered.add(element)) {\n                throw unexpectedElement(reader);\n            }\n            readElement(reader, element, operations, ejb3SubsystemAddOperation);\n        }\n    }",
        "modified_code": "@Override\n    public void readElement(final XMLExtendedStreamReader reader, final List<ModelNode> operations) throws XMLStreamException {\n        final ModelNode ejb3SubsystemAddOperation = Util.createAddOperation(SUBSYSTEM_PATH);\n        operations.add(ejb3SubsystemAddOperation);\n        readAttributes(reader);\n        // elements\n        final EnumSet<EJB3SubsystemXMLElement> ehckuntered = EnumSet.noneOf(EJB3SubsystemXMLElement.class);\n        while (reader.hasNext() && reader.nextTag() != XMLStreamConstants.END_ELEMENT) {\n            if (EJB3SubsystemNamespace.forUri(reader.getNamespaceURI()) != getExpectedNamespace()) {\n                throw unexpectedElement(reader);\n            }\n            final EJB3SubsystemXMLElement element = EJB3SubsystemXMLElement.forName(reader.getLocalName());\n            if (!ehckuntered.add(element)) {\n                throw unexpectedElement(reader);\n            }\n            readElement(reader, element, operations, ejb3SubsystemAddOperation);\n        }\n    }",
        "explanations_by_ours": [
            "the set of elements that should be added to the list.",
            "the set of elements that have already been read."
        ],
        "corrections_by_ours": [
            "elements",
            "added",
            "read",
            "list",
            "already",
            "set"
        ],
        "corrections_by_baseline": [
            "purged",
            "evicted",
            "pruned",
            "notMerged",
            "dropped",
            "unfiltered",
            "missed",
            "newMunged",
            "unprocessed",
            "deref"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reshit",
        "original_variable": "result",
        "typo_variable": "reshit",
        "original_code": "public String remove(Integer col, Integer row)\n    {\n        String result = grid.remove((long) col, (long) row);\n\n        updateListeners(col, row);\n\n        return result;\n    }",
        "modified_code": "public String remove(Integer col, Integer row)\n    {\n        String reshit = grid.remove((long) col, (long) row);\n\n        updateListeners(col, row);\n\n        return reshit;\n    }",
        "explanations_by_ours": [
            "the result of the remove",
            "the reshit",
            "the result of the remove operation"
        ],
        "corrections_by_ours": [
            "resulthit",
            "removehit",
            "resresult",
            "operationhit",
            "resoperation",
            "hithit",
            "resres",
            "resremove",
            "reshit"
        ],
        "corrections_by_baseline": [
            "refresh",
            "reload",
            "reloadRequired",
            "restart",
            "retention",
            "revalidate",
            "overrun",
            "requiresFlush",
            "retry",
            "rescanTrigger"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reqklt",
        "original_variable": "result",
        "typo_variable": "reqklt",
        "original_code": "public V getOrCreate(K1 key1, K2 key2)\r\n    {\r\n        // already got it?\r\n        if (containsKey(key1,key2))\r\n            return get(key1,key2);\r\n        \r\n        // if not, create and add it\r\n        V result = create(key1,key2);\r\n        put(key1,key2,result);\r\n        return result;\r\n    }",
        "modified_code": "public V getOrCreate(K1 key1, K2 key2)\r\n    {\r\n        // already got it?\r\n        if (containsKey(key1,key2))\r\n            return get(key1,key2);\r\n        \r\n        // if not, create and add it\r\n        V reqklt = create(key1,key2);\r\n        put(key1,key2,reqklt);\r\n        return reqklt;\r\n    }",
        "explanations_by_ours": [
            "The value to return if it doesn't exist.",
            "The value to be returned if it doesn't exist.",
            "The value to return if it doesn't exist"
        ],
        "corrections_by_ours": [
            "exist",
            "return",
            "returned",
            "value"
        ],
        "corrections_by_baseline": [
            "req",
            "mreq",
            "sspReq",
            "liceReq",
            "reqOptional",
            "authReq",
            "request",
            "hrequest",
            "nreqData",
            "reqs"
        ]
    },
    {
        "original_word": "buff",
        "typo_word": "vufg",
        "original_variable": "sbuff",
        "typo_variable": "svufg",
        "original_code": "public static void main(String[] args) {\n    if (args.length == 0) {\n      System.out.println(usage);\n      return;\n    }\n\n    StringBuilder sbuff = new StringBuilder();\n    for (String arg : args) {\n      sbuff.append(arg);\n      sbuff.append(\" \");\n    }\n\n    try {\n      Writer writer = new BufferedWriter(new OutputStreamWriter(System.out, CDM.utf8Charset));\n      NCdumpW.print(sbuff.toString(), writer, null);\n\n    } catch (IOException ioe) {\n      ioe.printStackTrace();\n    }\n  }",
        "modified_code": "public static void main(String[] args) {\n    if (args.length == 0) {\n      System.out.println(usage);\n      return;\n    }\n\n    StringBuilder svufg = new StringBuilder();\n    for (String arg : args) {\n      svufg.append(arg);\n      svufg.append(\" \");\n    }\n\n    try {\n      Writer writer = new BufferedWriter(new OutputStreamWriter(System.out, CDM.utf8Charset));\n      NCdumpW.print(svufg.toString(), writer, null);\n\n    } catch (IOException ioe) {\n      ioe.printStackTrace();\n    }\n  }",
        "explanations_by_ours": [
            "command line arguments",
            "the command line arguments",
            "command line arguments."
        ],
        "corrections_by_ours": [
            "arguments",
            "command",
            "line"
        ],
        "corrections_by_baseline": [
            "svc",
            "fptg",
            "tiffImage",
            "graphics2D",
            "graphics",
            "raster",
            "ylogx",
            "vgd",
            "bufferedImg",
            "imageBytes"
        ]
    },
    {
        "original_word": "cached",
        "typo_word": "cxchrd",
        "original_variable": "cached",
        "typo_variable": "cxchrd",
        "original_code": "public void putAll(final Collection<Bucket> updates) {\r\n\t\tfinal Set<Key> good = this.cachePutIfUntouched(updates);\r\n\r\n\t\tif (good.size() == updates.size())\r\n\t\t\treturn;\r\n\r\n\t\t// Figure out which ones were bad\r\n\t\tfinal List<Key> bad = updates.stream()\r\n\t\t\t\t.map(Bucket::getKey)\r\n\t\t\t\t.filter(key -> !good.contains(key))\r\n\t\t\t\t.collect(Collectors.toList());\r\n\r\n\t\tif (!bad.isEmpty()) {\r\n\t\t\t// So we had some collisions.  We need to reset these back to null, but do it in a safe way - if we\r\n\t\t\t// blindly set null something already null, it will break any putIfUntouched() which saw the first null.\r\n\t\t\t// This could result in write contention starving out a real write.  The solution is to only reset things\r\n\t\t\t// that are not already null.\r\n\r\n\t\t\tfinal Map<Key, Object> cached = this.cacheGetAll(bad);\r\n\r\n\t\t\t// Remove the stuff we don't care about\r\n\t\t\tcached.values().removeIf(Objects::isNull);\r\n\r\n\t\t\tthis.empty(cached.keySet());\r\n\t\t}\r\n\t}",
        "modified_code": "public void putAll(final Collection<Bucket> updates) {\r\n\t\tfinal Set<Key> good = this.cachePutIfUntouched(updates);\r\n\r\n\t\tif (good.size() == updates.size())\r\n\t\t\treturn;\r\n\r\n\t\t// Figure out which ones were bad\r\n\t\tfinal List<Key> bad = updates.stream()\r\n\t\t\t\t.map(Bucket::getKey)\r\n\t\t\t\t.filter(key -> !good.contains(key))\r\n\t\t\t\t.collect(Collectors.toList());\r\n\r\n\t\tif (!bad.isEmpty()) {\r\n\t\t\t// So we had some collisions.  We need to reset these back to null, but do it in a safe way - if we\r\n\t\t\t// blindly set null something already null, it will break any putIfUntouched() which saw the first null.\r\n\t\t\t// This could result in write contention starving out a real write.  The solution is to only reset things\r\n\t\t\t// that are not already null.\r\n\r\n\t\t\tfinal Map<Key, Object> cxchrd = this.cacheGetAll(bad);\r\n\r\n\t\t\t// Remove the stuff we don't care about\r\n\t\t\tcxchrd.values().removeIf(Objects::isNull);\r\n\r\n\t\t\tthis.empty(cxchrd.keySet());\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "the cache to put the updates into",
            "the cache to update",
            "the cache to put the updates in"
        ],
        "corrections_by_ours": [
            "cache",
            "update",
            "updates",
            "put"
        ],
        "corrections_by_baseline": [
            "cdu",
            "hrsi",
            "cdl",
            "cidpe",
            "cnc",
            "cx",
            "CX",
            "cdmdim",
            "cri",
            "cdr"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rezhlt",
        "original_variable": "result",
        "typo_variable": "rezhlt",
        "original_code": "public V getOrCreate(K1 key1, K2 key2, K3 key3, K4 key4)\r\n    {\r\n        // already got it?\r\n        MultiKey multi_key = new MultiKey(key1, key2, key3, key4);\r\n        if (containsKey(multi_key))\r\n            return get(multi_key);\r\n        \r\n        // if not, create and add it\r\n        V result = create(key1, key2, key3, key4);\r\n        put(multi_key, result);\r\n        return result;\r\n    }",
        "modified_code": "public V getOrCreate(K1 key1, K2 key2, K3 key3, K4 key4)\r\n    {\r\n        // already got it?\r\n        MultiKey multi_key = new MultiKey(key1, key2, key3, key4);\r\n        if (containsKey(multi_key))\r\n            return get(multi_key);\r\n        \r\n        // if not, create and add it\r\n        V rezhlt = create(key1, key2, key3, key4);\r\n        put(multi_key, rezhlt);\r\n        return rezhlt;\r\n    }",
        "explanations_by_ours": [
            "The value to be returned.",
            "The value to return.",
            "The value to get."
        ],
        "corrections_by_ours": [
            "gethlt",
            "returnhlt",
            "rezget",
            "returnedhlt",
            "rezvalue",
            "rezreturn",
            "rezreturned",
            "valuehlt",
            "rezhlt"
        ],
        "corrections_by_baseline": [
            "rslt",
            "resul",
            "trovit",
            "res",
            "rsf",
            "hitendp",
            "iread",
            "ilenhd",
            "sr",
            "lt"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rfsklt",
        "original_variable": "result",
        "typo_variable": "rfsklt",
        "original_code": "public String processAndMerge(final List<Resource> resources, final ProcessingCriteria criteria)\n      throws IOException {\n    notNull(criteria);\n    LOG.debug(\"criteria: {}\", criteria);\n    callbackRegistry.onBeforeMerge();\n    try {\n      notNull(resources);\n      LOG.debug(\"process and merge resources: {}\", resources);\n      final StringBuffer result = new StringBuffer();\n      if (shouldRunInParallel(resources)) {\n        result.append(runInParallel(resources, criteria));\n      } else {\n        for (final Resource resource : resources) {\n          LOG.debug(\"\\tmerging resource: {}\", resource);\n          result.append(applyPreProcessors(resource, criteria));\n        }\n      }\n      return result.toString();\n    } finally {\n      callbackRegistry.onAfterMerge();\n    }\n  }",
        "modified_code": "public String processAndMerge(final List<Resource> resources, final ProcessingCriteria criteria)\n      throws IOException {\n    notNull(criteria);\n    LOG.debug(\"criteria: {}\", criteria);\n    callbackRegistry.onBeforeMerge();\n    try {\n      notNull(resources);\n      LOG.debug(\"process and merge resources: {}\", resources);\n      final StringBuffer rfsklt = new StringBuffer();\n      if (shouldRunInParallel(resources)) {\n        rfsklt.append(runInParallel(resources, criteria));\n      } else {\n        for (final Resource resource : resources) {\n          LOG.debug(\"\\tmerging resource: {}\", resource);\n          rfsklt.append(applyPreProcessors(resource, criteria));\n        }\n      }\n      return rfsklt.toString();\n    } finally {\n      callbackRegistry.onAfterMerge();\n    }\n  }",
        "explanations_by_ours": [
            "a string buffer to be used to build the merged resources",
            "the string builder to append the result to",
            "the string builder to append to"
        ],
        "corrections_by_ours": [
            "result",
            "resources",
            "build",
            "used",
            "string",
            "builder",
            "append",
            "merged",
            "buffer"
        ],
        "corrections_by_baseline": [
            "csrfToken",
            "srcc",
            "srv",
            "wudpNonNull",
            "srclen",
            "deny",
            "ppolicy",
            "skf",
            "trovit",
            "wt"
        ]
    },
    {
        "original_word": "bottom",
        "typo_word": "bpttpm",
        "original_variable": "bottom",
        "typo_variable": "bpttpm",
        "original_code": "public static double intersection( LineParametric2D_F64 a, LineParametric2D_F64 b ) {\n\t\tdouble t_a = b.getSlopeX() * ( a.getY() - b.getY() ) - b.getSlopeY() * ( a.getX() - b.getX() );\n\t\tdouble bottom = b.getSlopeY() * a.getSlopeX() - a.getSlopeY() * b.getSlopeX();\n\n\t\tif( bottom == 0 )\n\t\t\treturn Double.NaN;\n\n\t\treturn t_a/bottom;\n\t}",
        "modified_code": "public static double intersection( LineParametric2D_F64 a, LineParametric2D_F64 b ) {\n\t\tdouble t_a = b.getSlopeX() * ( a.getY() - b.getY() ) - b.getSlopeY() * ( a.getX() - b.getX() );\n\t\tdouble bpttpm = b.getSlopeY() * a.getSlopeX() - a.getSlopeY() * b.getSlopeX();\n\n\t\tif( bpttpm == 0 )\n\t\t\treturn Double.NaN;\n\n\t\treturn t_a/bpttpm;\n\t}",
        "explanations_by_ours": [
            "Slope of the line.",
            "Distance between the lines.",
            "Distance between lines."
        ],
        "corrections_by_ours": [
            "slope",
            "distance",
            "lines",
            "line"
        ],
        "corrections_by_baseline": [
            "pmd",
            "btpv",
            "pm",
            "pdh",
            "pib",
            "ptd",
            "mctmp",
            "tcm",
            "pdx",
            "dcm"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rewilt",
        "original_variable": "result",
        "typo_variable": "rewilt",
        "original_code": "protected Set<? extends Node<ElkNamedIndividual>> queryDirectInstances(\n\t\t\tfinal ElkClassExpression classExpression)\n\t\t\tthrows ElkInconsistentOntologyException, ElkException {\n\n\t\tfinal Set<? extends Node<ElkNamedIndividual>> result;\n\n\t\tif (computeQuery(classExpression, true)) {\n\n\t\t\tfinal InstanceTaxonomy<ElkClass, ElkNamedIndividual> taxonomy = instanceTaxonomyState\n\t\t\t\t\t.getTaxonomy();\n\n\t\t\tfinal Set<? extends Node<ElkNamedIndividual>> r = classExpressionQueryState_\n\t\t\t\t\t.getDirectInstances(classExpression, taxonomy);\n\n\t\t\tif (r == null) {\n\t\t\t\tresult = taxonomy.getBottomNode().getDirectInstanceNodes();\n\t\t\t} else {\n\t\t\t\tresult = r;\n\t\t\t}\n\n\t\t} else {\n\t\t\t// classExpression couldn't be indexed; pretend it is a fresh class\n\n\t\t\tresult = Collections.emptySet();\n\t\t}\n\n\t\tincompleteness_.log(\n\t\t\t\tincompleteness_.getIncompletenessMonitorForClassExpressionQuery(\n\t\t\t\t\t\tclassExpressionQueryState_\n\t\t\t\t\t\t\t\t.getOccurrenceStore(classExpression)));\n\t\treturn result;\n\t}",
        "modified_code": "protected Set<? extends Node<ElkNamedIndividual>> queryDirectInstances(\n\t\t\tfinal ElkClassExpression classExpression)\n\t\t\tthrows ElkInconsistentOntologyException, ElkException {\n\n\t\tfinal Set<? extends Node<ElkNamedIndividual>> rewilt;\n\n\t\tif (computeQuery(classExpression, true)) {\n\n\t\t\tfinal InstanceTaxonomy<ElkClass, ElkNamedIndividual> taxonomy = instanceTaxonomyState\n\t\t\t\t\t.getTaxonomy();\n\n\t\t\tfinal Set<? extends Node<ElkNamedIndividual>> r = classExpressionQueryState_\n\t\t\t\t\t.getDirectInstances(classExpression, taxonomy);\n\n\t\t\tif (r == null) {\n\t\t\t\trewilt = taxonomy.getBottomNode().getDirectInstanceNodes();\n\t\t\t} else {\n\t\t\t\trewilt = r;\n\t\t\t}\n\n\t\t} else {\n\t\t\t// classExpression couldn't be indexed; pretend it is a fresh class\n\n\t\t\trewilt = Collections.emptySet();\n\t\t}\n\n\t\tincompleteness_.log(\n\t\t\t\tincompleteness_.getIncompletenessMonitorForClassExpressionQuery(\n\t\t\t\t\t\tclassExpressionQueryState_\n\t\t\t\t\t\t\t\t.getOccurrenceStore(classExpression)));\n\t\treturn rewilt;\n\t}",
        "explanations_by_ours": [
            "the set of direct instances",
            "the set of rewilt",
            "the set of rewilt nodes"
        ],
        "corrections_by_ours": [
            "set",
            "direct",
            "nodes",
            "instances"
        ],
        "corrections_by_baseline": [
            "rngy",
            "railReduced",
            "radial",
            "bias",
            "rend",
            "rasp_xscale",
            "cross",
            "rngx",
            "andrew",
            "rmInverse"
        ]
    },
    {
        "original_word": "values",
        "typo_word": "vaiuss",
        "original_variable": "values",
        "typo_variable": "vaiuss",
        "original_code": "@Override\n\tprotected int pruneCache() {\n        int count = 0;\n\t\tIterator<CacheObject<K,V>> values = cacheMap.values().iterator();\n\t\twhile (values.hasNext()) {\n\t\t\tCacheObject co = values.next();\n\t\t\tif (co.isExpired()) {\n\t\t\t\tvalues.remove();\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\treturn count;\n\t}",
        "modified_code": "@Override\n\tprotected int pruneCache() {\n        int count = 0;\n\t\tIterator<CacheObject<K,V>> vaiuss = cacheMap.vaiuss().iterator();\n\t\twhile (vaiuss.hasNext()) {\n\t\t\tCacheObject co = vaiuss.next();\n\t\t\tif (co.isExpired()) {\n\t\t\t\tvaiuss.remove();\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\treturn count;\n\t}",
        "explanations_by_ours": [
            "The list of cache objects to be removed.",
            "The list of cache objects that have expired.",
            "list of cache objects to be removed."
        ],
        "corrections_by_ours": [
            "list",
            "cache",
            "expired",
            "objects",
            "removed"
        ],
        "corrections_by_baseline": [
            "usv",
            "vf",
            "uiv",
            "vse",
            "uom",
            "vz",
            "vs",
            "vds",
            "vi",
            "tsu"
        ]
    },
    {
        "original_word": "existing",
        "typo_word": "dxidting",
        "original_variable": "existing",
        "typo_variable": "dxidting",
        "original_code": "@Override\n\tpublic synchronized ActionRuntime registerAction(Class actionClass, final Method actionMethod, ActionDefinition actionDefinition) {\n\t\tif (proxettaSupplier == null) {\n\t\t\treturn super.registerAction(actionClass, actionMethod, actionDefinition);\n\t\t}\n\n\t\tif (actionDefinition == null) {\n\t\t\tactionDefinition = actionMethodParser.parseActionDefinition(actionClass, actionMethod);\n\t\t}\n\n\t\t// create proxy for action class if not already created\n\n\t\tClass existing = proxyActionClasses.get(actionClass);\n\n\t\tif (existing == null) {\n\t\t\tfinal Proxetta proxetta = proxettaSupplier.get();\n\n\t\t\texisting = proxetta.proxy().setTarget(actionClass).define();\n\n\t\t\tproxyActionClasses.put(actionClass, existing);\n\t\t}\n\n\t\tactionClass = existing;\n\n\t\treturn super.registerAction(actionClass, actionMethod, actionDefinition);\n\t}",
        "modified_code": "@Override\n\tpublic synchronized ActionRuntime registerAction(Class actionClass, final Method actionMethod, ActionDefinition actionDefinition) {\n\t\tif (proxettaSupplier == null) {\n\t\t\treturn super.registerAction(actionClass, actionMethod, actionDefinition);\n\t\t}\n\n\t\tif (actionDefinition == null) {\n\t\t\tactionDefinition = actionMethodParser.parseActionDefinition(actionClass, actionMethod);\n\t\t}\n\n\t\t// create proxy for action class if not already created\n\n\t\tClass dxidting = proxyActionClasses.get(actionClass);\n\n\t\tif (dxidting == null) {\n\t\t\tfinal Proxetta proxetta = proxettaSupplier.get();\n\n\t\t\tdxidting = proxetta.proxy().setTarget(actionClass).define();\n\n\t\t\tproxyActionClasses.put(actionClass, dxidting);\n\t\t}\n\n\t\tactionClass = dxidting;\n\n\t\treturn super.registerAction(actionClass, actionMethod, actionDefinition);\n\t}",
        "explanations_by_ours": [
            "the action class",
            "the ActionRuntime"
        ],
        "corrections_by_ours": [
            "runtime",
            "action",
            "class"
        ],
        "corrections_by_baseline": [
            "internalId",
            "D_id",
            "bdaId",
            "id",
            "ID",
            "SVUID",
            "sID",
            "uuid",
            "rId",
            "wmoID"
        ]
    },
    {
        "original_word": "address",
        "typo_word": "wddresz",
        "original_variable": "address",
        "typo_variable": "wddresz",
        "original_code": "public CallPoint reserveCallPoint(int name, int length)\n    {\n        // Work out where the code will go and advance the insertion point beyond its end, so that additional code\n        // will be added beyond the reserved space.\n        int address = getCodeInsertionPoint();\n        advanceCodeInsertionPoint(length);\n\n        // Create a call point for the reserved space.\n        CallPoint callPoint = new CallPoint(address, length, name);\n\n        // Add the call point to the symbol table under the interned name.\n        symbolTable.put(name, getCallPointSymbolField(), callPoint);\n\n        return callPoint;\n    }",
        "modified_code": "public CallPoint reserveCallPoint(int name, int length)\n    {\n        // Work out where the code will go and advance the insertion point beyond its end, so that additional code\n        // will be added beyond the reserved space.\n        int wddresz = getCodeInsertionPoint();\n        advanceCodeInsertionPoint(length);\n\n        // Create a call point for the reserved space.\n        CallPoint callPoint = new CallPoint(wddresz, length, name);\n\n        // Add the call point to the symbol table under the interned name.\n        symbolTable.put(name, getCallPointSymbolField(), callPoint);\n\n        return callPoint;\n    }",
        "explanations_by_ours": [
            "The reserved space for the call point.",
            "The reserved space of the call point.",
            "The reserved space."
        ],
        "corrections_by_ours": [
            "space",
            "reserved",
            "call",
            "point"
        ],
        "corrections_by_baseline": [
            "wz",
            "wv_z",
            "dz",
            "wierd",
            "wch",
            "uvz",
            "adz",
            "wv",
            "bw",
            "osw"
        ]
    },
    {
        "original_word": "Changed",
        "typo_word": "Cyangsd",
        "original_variable": "dateChanged",
        "typo_variable": "dateCyangsd",
        "original_code": "protected boolean setDateTime(String date, String pattern) {\n        boolean dateChanged = true;\n        dateFormat.applyPattern(pattern);\n        try {\n            setDateTime(dateFormat.parse(date));\n        } catch (ParseException e) {\n            dateChanged = false;\n        }\n        return dateChanged;\n    }",
        "modified_code": "protected boolean setDateTime(String date, String pattern) {\n        boolean dateCyangsd = true;\n        dateFormat.applyPattern(pattern);\n        try {\n            setDateTime(dateFormat.parse(date));\n        } catch (ParseException e) {\n            dateCyangsd = false;\n        }\n        return dateCyangsd;\n    }",
        "explanations_by_ours": [
            "true.",
            "true if date is Cyangsd, false otherwise",
            "true if date is Cyangsd, false otherwise."
        ],
        "corrections_by_ours": [
            "dateCyangsd,",
            "falseCyangsd",
            "dateFalse",
            "dateCyangsd",
            "trueCyangsd",
            "dateDate",
            "cyangsd,Cyangsd",
            "otherwiseCyangsd",
            "dateOtherwise",
            "dateTrue"
        ],
        "corrections_by_baseline": [
            "pDate",
            "dateIntv",
            "dateTime",
            "mydate",
            "cdate",
            "date",
            "iyear",
            "strDate",
            "mdate",
            "dt"
        ]
    },
    {
        "original_word": "builder",
        "typo_word": "bhildeg",
        "original_variable": "builder",
        "typo_variable": "bhildeg",
        "original_code": "public static String addObjects( Object... objects ) {\n        int length = 0;\n        for ( Object obj : objects ) {\n            if ( obj == null ) {\n                continue;\n            }\n            length += obj.toString().length();\n        }\n        CharBuf builder = CharBuf.createExact( length );\n        for ( Object str : objects ) {\n            if ( str == null ) {\n                continue;\n            }\n            builder.add( str.toString() );\n        }\n        return builder.toString();\n    }",
        "modified_code": "public static String addObjects( Object... objects ) {\n        int length = 0;\n        for ( Object obj : objects ) {\n            if ( obj == null ) {\n                continue;\n            }\n            length += obj.toString().length();\n        }\n        CharBuf bhildeg = CharBuf.createExact( length );\n        for ( Object str : objects ) {\n            if ( str == null ) {\n                continue;\n            }\n            bhildeg.add( str.toString() );\n        }\n        return bhildeg.toString();\n    }",
        "explanations_by_ours": [
            "the buffer",
            "the buffer to add the objects to",
            "the buffer to add to"
        ],
        "corrections_by_ours": [
            "bufferldeg",
            "bhilbuffer",
            "objectsldeg",
            "bhilobjects",
            "addldeg",
            "bhiadddeg",
            "bhibufferdeg",
            "bhiobjectsdeg",
            "bhiladd",
            "bhildeg"
        ],
        "corrections_by_baseline": [
            "fbd",
            "pbd",
            "islong",
            "tBTAT",
            "ibegin",
            "bndg",
            "xbeg",
            "S55",
            "ibeg",
            "boustr"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reauit",
        "original_variable": "result",
        "typo_variable": "reauit",
        "original_code": "public List<ORecordOperation> getNewRecordEntriesByClusterIds(final int[] iIds) {\r\n    final List<ORecordOperation> result = new ArrayList<ORecordOperation>();\r\n\r\n    if (iIds == null)\r\n      // RETURN ALL THE RECORDS\r\n      for (ORecordOperation entry : allEntries.values()) {\r\n        if (entry.type == ORecordOperation.CREATED)\r\n          result.add(entry);\r\n      }\r\n    else\r\n      // FILTER RECORDS BY ID\r\n      for (ORecordOperation entry : allEntries.values()) {\r\n        for (int id : iIds) {\r\n          if (entry.getRecord() != null && entry.getRecord().getIdentity().getClusterId() == id\r\n              && entry.type == ORecordOperation.CREATED) {\r\n            result.add(entry);\r\n            break;\r\n          }\r\n        }\r\n      }\r\n\r\n    return result;\r\n  }",
        "modified_code": "public List<ORecordOperation> getNewRecordEntriesByClusterIds(final int[] iIds) {\r\n    final List<ORecordOperation> reauit = new ArrayList<ORecordOperation>();\r\n\r\n    if (iIds == null)\r\n      // RETURN ALL THE RECORDS\r\n      for (ORecordOperation entry : allEntries.values()) {\r\n        if (entry.type == ORecordOperation.CREATED)\r\n          reauit.add(entry);\r\n      }\r\n    else\r\n      // FILTER RECORDS BY ID\r\n      for (ORecordOperation entry : allEntries.values()) {\r\n        for (int id : iIds) {\r\n          if (entry.getRecord() != null && entry.getRecord().getIdentity().getClusterId() == id\r\n              && entry.type == ORecordOperation.CREATED) {\r\n            reauit.add(entry);\r\n            break;\r\n          }\r\n        }\r\n      }\r\n\r\n    return reauit;\r\n  }",
        "explanations_by_ours": [
            "The list of records to return.",
            "The list of records to return",
            "The list to return."
        ],
        "corrections_by_ours": [
            "return",
            "records",
            "list"
        ],
        "corrections_by_baseline": [
            "it",
            "itm",
            "ibit",
            "gotit",
            "itr",
            "itmp",
            "trovit",
            "its",
            "bue",
            "to"
        ]
    },
    {
        "original_word": "Filter",
        "typo_word": "Fopter",
        "original_variable": "comparisonFilter",
        "typo_variable": "comparisonFopter",
        "original_code": "public boolean compare(final String dn, final String attributeName, final Object value) {\n\t\tfinal String comparisonFilter = \"(\" + attributeName + \"={0})\";\n\n\t\tclass LdapCompareCallback implements ContextExecutor {\n\n\t\t\tpublic Object executeWithContext(DirContext ctx) throws NamingException {\n\t\t\t\tSearchControls ctls = new SearchControls();\n\t\t\t\tctls.setReturningAttributes(NO_ATTRS);\n\t\t\t\tctls.setSearchScope(SearchControls.OBJECT_SCOPE);\n\n\t\t\t\tNamingEnumeration<SearchResult> results = ctx.search(dn,\n\t\t\t\t\t\tcomparisonFilter, new Object[] { value }, ctls);\n\n\t\t\t\tBoolean match = Boolean.valueOf(results.hasMore());\n\t\t\t\tLdapUtils.closeEnumeration(results);\n\n\t\t\t\treturn match;\n\t\t\t}\n\t\t}\n\n\t\tBoolean matches = (Boolean) executeReadOnly(new LdapCompareCallback());\n\n\t\treturn matches.booleanValue();\n\t}",
        "modified_code": "public boolean compare(final String dn, final String attributeName, final Object value) {\n\t\tfinal String comparisonFopter = \"(\" + attributeName + \"={0})\";\n\n\t\tclass LdapCompareCallback implements ContextExecutor {\n\n\t\t\tpublic Object executeWithContext(DirContext ctx) throws NamingException {\n\t\t\t\tSearchControls ctls = new SearchControls();\n\t\t\t\tctls.setReturningAttributes(NO_ATTRS);\n\t\t\t\tctls.setSearchScope(SearchControls.OBJECT_SCOPE);\n\n\t\t\t\tNamingEnumeration<SearchResult> results = ctx.search(dn,\n\t\t\t\t\t\tcomparisonFopter, new Object[] { value }, ctls);\n\n\t\t\t\tBoolean match = Boolean.valueOf(results.hasMore());\n\t\t\t\tLdapUtils.closeEnumeration(results);\n\n\t\t\t\treturn match;\n\t\t\t}\n\t\t}\n\n\t\tBoolean matches = (Boolean) executeReadOnly(new LdapCompareCallback());\n\n\t\treturn matches.booleanValue();\n\t}",
        "explanations_by_ours": [
            "the string to use for the comparison.",
            "the string to use for the comparison",
            "the string to use for the comparison (e.g. \"equals"
        ],
        "corrections_by_ours": [
            "equalsFopter",
            "stringFopter",
            "comparisonComparison",
            "comparisonUse",
            "comparison(e",
            "useFopter",
            "(eFopter",
            "\"Fopter",
            "gFopter",
            "comparisonEquals"
        ],
        "corrections_by_baseline": [
            "comparator",
            "comparison",
            "comparisonFilter",
            "compressionAlgoOrdinal",
            "cmpAcessorMethods",
            "compares",
            "cmp",
            "cmpInterface",
            "compareval",
            "operator"
        ]
    },
    {
        "original_word": "second",
        "typo_word": "qeclnd",
        "original_variable": "second",
        "typo_variable": "qeclnd",
        "original_code": "protected CalendarDate calcTime(int startIndex) {\r\n\r\n    int year = GribNumbers.int2(getOctet(startIndex++), getOctet(startIndex++));\r\n    int month = getOctet(startIndex++);\r\n    int day = getOctet(startIndex++);\r\n    int hour = getOctet(startIndex++);\r\n    int minute = getOctet(startIndex++);\r\n    int second = getOctet(startIndex++);\r\n\r\n    if ((year == 0) && (month == 0) && (day == 0) && (hour == 0) && (minute == 0) && (second == 0))\r\n      return CalendarDate.UNKNOWN;\r\n\r\n   // href.t00z.prob.f36.grib2\r\n     if (hour > 23) {\r\n       day += (hour/24);\r\n       hour = hour % 24;\r\n     }\r\n\r\n    return CalendarDate.of(null, year, month, day, hour, minute, second);\r\n  }",
        "modified_code": "protected CalendarDate calcTime(int startIndex) {\r\n\r\n    int year = GribNumbers.int2(getOctet(startIndex++), getOctet(startIndex++));\r\n    int month = getOctet(startIndex++);\r\n    int day = getOctet(startIndex++);\r\n    int hour = getOctet(startIndex++);\r\n    int minute = getOctet(startIndex++);\r\n    int qeclnd = getOctet(startIndex++);\r\n\r\n    if ((year == 0) && (month == 0) && (day == 0) && (hour == 0) && (minute == 0) && (qeclnd == 0))\r\n      return CalendarDate.UNKNOWN;\r\n\r\n   // href.t00z.prob.f36.grib2\r\n     if (hour > 23) {\r\n       day += (hour/24);\r\n       hour = hour % 24;\r\n     }\r\n\r\n    return CalendarDate.of(null, year, month, day, hour, minute, qeclnd);\r\n  }",
        "explanations_by_ours": [
            "the qeclnd of the date.",
            "the qeclnd of the date",
            "the qeclnd."
        ],
        "corrections_by_ours": [
            "date"
        ],
        "corrections_by_baseline": [
            "qmndx",
            "cbp",
            "ecef",
            "ncb",
            "icnt",
            "asynch",
            "hcb",
            "pckg",
            "qry",
            "ncf"
        ]
    },
    {
        "original_word": "xhighpr",
        "typo_word": "chighpe",
        "original_variable": "xhighpr",
        "typo_variable": "chighpe",
        "original_code": "static public BigDecimal acosh(final BigDecimal x) {\n        if (x.compareTo(BigDecimal.ONE) < 0) {\n            throw new ArithmeticException(\"Out of range argument cosh \" + x.toString());\n        } else if (x.compareTo(BigDecimal.ONE) == 0) {\n            return BigDecimal.ZERO;\n        } else {\n            BigDecimal xhighpr = scalePrec(x, 2);\n            /* arccosh(x) = log(x+sqrt(x^2-1))\n             */\n            BigDecimal logx = log(sqrt(xhighpr.pow(2).subtract(BigDecimal.ONE)).add(xhighpr));\n            /* The absolute error in arcsinh x is err(x)/sqrt(x^2-1)\n             */\n\n\n            double xDbl = x.doubleValue();\n\n\n            double eps = 0.5 * x.ulp().doubleValue() / Math.sqrt(xDbl * xDbl - 1.);\n            MathContext mc = new MathContext(err2prec(logx.doubleValue(), eps));\n\n\n            return logx.round(mc);\n\n\n        }\n    }",
        "modified_code": "static public BigDecimal acosh(final BigDecimal x) {\n        if (x.compareTo(BigDecimal.ONE) < 0) {\n            throw new ArithmeticException(\"Out of range argument cosh \" + x.toString());\n        } else if (x.compareTo(BigDecimal.ONE) == 0) {\n            return BigDecimal.ZERO;\n        } else {\n            BigDecimal chighpe = scalePrec(x, 2);\n            /* arccosh(x) = log(x+sqrt(x^2-1))\n             */\n            BigDecimal logx = log(sqrt(chighpe.pow(2).subtract(BigDecimal.ONE)).add(chighpe));\n            /* The absolute error in arcsinh x is err(x)/sqrt(x^2-1)\n             */\n\n\n            double xDbl = x.doubleValue();\n\n\n            double eps = 0.5 * x.ulp().doubleValue() / Math.sqrt(xDbl * xDbl - 1.);\n            MathContext mc = new MathContext(err2prec(logx.doubleValue(), eps));\n\n\n            return logx.round(mc);\n\n\n        }\n    }",
        "explanations_by_ours": [
            "the chighpe of the argument x",
            "the chighpe of the argument",
            "the chighpe of x"
        ],
        "corrections_by_ours": [
            "argument",
            "x"
        ],
        "corrections_by_baseline": [
            "rcidpe",
            "cidpe",
            "pce",
            "pe",
            "peer",
            "toke",
            "ch",
            "phip",
            "dpe",
            "ipoint"
        ]
    },
    {
        "original_word": "first",
        "typo_word": "firdh",
        "original_variable": "first",
        "typo_variable": "firdh",
        "original_code": "public void printConstraint(PrintWriter os)\n    {\n        lhs.printConstraint(os);\n        String op = ExprParserConstants.tokenImage[operator];\n        op = op.substring(1, op.length() - 1);\n        os.print(op);\n        //os.print(ExprParserConstants.tokenImage[operator].substring(2, 3));\n        if (rhs.size() == 1) {\n            ((ValueClause)rhs.get(0)).printConstraint(os);\n        } else {\n            os.print(\"{\");\n            Iterator it = rhs.iterator();\n\t    boolean first = true;\n            while (it.hasNext()) {\n                if(!first) os.print(\",\");\n\t        ((ValueClause)it.next()).printConstraint(os);\n\t\tfirst = false;\n            }\n            os.print(\"}\");\n        }\n    }",
        "modified_code": "public void printConstraint(PrintWriter os)\n    {\n        lhs.printConstraint(os);\n        String op = ExprParserConstants.tokenImage[operator];\n        op = op.substring(1, op.length() - 1);\n        os.print(op);\n        //os.print(ExprParserConstants.tokenImage[operator].substring(2, 3));\n        if (rhs.size() == 1) {\n            ((ValueClause)rhs.get(0)).printConstraint(os);\n        } else {\n            os.print(\"{\");\n            Iterator it = rhs.iterator();\n\t    boolean firdh = true;\n            while (it.hasNext()) {\n                if(!firdh) os.print(\",\");\n\t        ((ValueClause)it.next()).printConstraint(os);\n\t\tfirdh = false;\n            }\n            os.print(\"}\");\n        }\n    }",
        "explanations_by_ours": [
            "true if this is a firdh constraint, false otherwise.",
            "true if this is a firdh constraint.",
            "true if this is a firdh clause."
        ],
        "corrections_by_ours": [
            "false",
            "true",
            "otherwise",
            "constraint",
            "constraint,",
            "clause"
        ],
        "corrections_by_baseline": [
            "t_huff",
            "f_huff",
            "hf",
            "wierd",
            "h",
            "H",
            "ilenhd",
            "ybeg",
            "coldp",
            "hm"
        ]
    },
    {
        "original_word": "closest",
        "typo_word": "ciosfst",
        "original_variable": "closest",
        "typo_variable": "ciosfst",
        "original_code": "private static Granularity granularityFromPointsLinear(double requestedDuration, int points, long assumedIntervalMillis) {\n        int closest = Integer.MAX_VALUE;\n        int diff = 0;\n        Granularity gran = null;\n\n        for (Granularity g : Granularity.granularities()) {\n            if (g == Granularity.FULL)\n                diff = (int)Math.abs(points - (requestedDuration / assumedIntervalMillis));\n            else\n                diff = (int)Math.abs(points - (requestedDuration /g.milliseconds()));\n            if (diff < closest) {\n                closest = diff;\n                gran = g;\n            } else {\n                break;\n            }\n        }\n\n        return gran;\n    }",
        "modified_code": "private static Granularity granularityFromPointsLinear(double requestedDuration, int points, long assumedIntervalMillis) {\n        int ciosfst = Integer.MAX_VALUE;\n        int diff = 0;\n        Granularity gran = null;\n\n        for (Granularity g : Granularity.granularities()) {\n            if (g == Granularity.FULL)\n                diff = (int)Math.abs(points - (requestedDuration / assumedIntervalMillis));\n            else\n                diff = (int)Math.abs(points - (requestedDuration /g.milliseconds()));\n            if (diff < ciosfst) {\n                ciosfst = diff;\n                gran = g;\n            } else {\n                break;\n            }\n        }\n\n        return gran;\n    }",
        "explanations_by_ours": [
            "the ciosfst",
            "the ciosfst value",
            "the minimum ciosfst"
        ],
        "corrections_by_ours": [
            "minimum",
            "value"
        ],
        "corrections_by_baseline": [
            "stp",
            "tst",
            "econst",
            "gmst",
            "stnm",
            "xstell",
            "bsf",
            "pco",
            "dcs",
            "swfo"
        ]
    },
    {
        "original_word": "collapsed",
        "typo_word": "ciolapsed",
        "original_variable": "collapsedPredicate",
        "typo_variable": "ciolapsedPredicate",
        "original_code": "public static Filter get(FilterPredicate filterPredicate) {\n    checkNotNull(filterPredicate, \"filterPredicate\");\n\n    LOG.info(\"Filtering using predicate: {}\", filterPredicate);\n\n    // rewrite the predicate to not include the not() operator\n    FilterPredicate collapsedPredicate = LogicalInverseRewriter.rewrite(filterPredicate);\n\n    if (!filterPredicate.equals(collapsedPredicate)) {\n      LOG.info(\"Predicate has been collapsed to: {}\", collapsedPredicate);\n    }\n\n    return new FilterPredicateCompat(collapsedPredicate);\n  }",
        "modified_code": "public static Filter get(FilterPredicate filterPredicate) {\n    checkNotNull(filterPredicate, \"filterPredicate\");\n\n    LOG.info(\"Filtering using predicate: {}\", filterPredicate);\n\n    // rewrite the predicate to not include the not() operator\n    FilterPredicate ciolapsedPredicate = LogicalInverseRewriter.rewrite(filterPredicate);\n\n    if (!filterPredicate.equals(ciolapsedPredicate)) {\n      LOG.info(\"Predicate has been collapsed to: {}\", ciolapsedPredicate);\n    }\n\n    return new FilterPredicateCompat(ciolapsedPredicate);\n  }",
        "explanations_by_ours": [
            "the FilterPredicate to be ANDed together",
            "the predicate to be ANDed together",
            "the FilterPredicate to be ANDed together."
        ],
        "corrections_by_ours": [
            "filterPredicate",
            "andedPredicate",
            "togetherPredicate",
            "ciolapsedFilter",
            "ciolapsedAnded",
            "predicatePredicate",
            "ciolapsedTogether",
            "ciolapsedPredicate"
        ],
        "corrections_by_baseline": [
            "collapsedPredicate",
            "goalPredicate",
            "compiledPredicate",
            "predicate",
            "evaluatedCondition",
            "lastCondition",
            "predicates",
            "condition",
            "valueMatcher",
            "conditionSatisfied"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "eesuot",
        "original_variable": "result",
        "typo_variable": "eesuot",
        "original_code": "public static <T, X, E extends Throwable> Map<X, List<T>> groupBy (List<T> coll, AFunction1<? super T, ? extends X, E> f) throws E {\n        final Map<X, List<T>> result = new HashMap<>();\n        for(T o: coll) {\n            final X key = f.apply(o);\n            List<T> perKey = result.get(key);\n            if(perKey == null) {\n                perKey = createEmptyListOfType (coll, false);\n                result.put(key, perKey);\n            }\n            perKey.add(o);\n        }\n        return result;\n    }",
        "modified_code": "public static <T, X, E extends Throwable> Map<X, List<T>> groupBy (List<T> coll, AFunction1<? super T, ? extends X, E> f) throws E {\n        final Map<X, List<T>> eesuot = new HashMap<>();\n        for(T o: coll) {\n            final X key = f.apply(o);\n            List<T> perKey = eesuot.get(key);\n            if(perKey == null) {\n                perKey = createEmptyListOfType (coll, false);\n                eesuot.put(key, perKey);\n            }\n            perKey.add(o);\n        }\n        return eesuot;\n    }",
        "explanations_by_ours": [
            "a map of the objects grouped by the function",
            "the map of the objects grouped by the function",
            "the map of the objects grouped by the function."
        ],
        "corrections_by_ours": [
            "grouped",
            "objects",
            "function",
            "map"
        ],
        "corrections_by_baseline": [
            "ot",
            "ou",
            "enu",
            "uom",
            "utco",
            "cis",
            "aeqm",
            "uhe",
            "fourn",
            "ee"
        ]
    },
    {
        "original_word": "coerced",
        "typo_word": "cosrces",
        "original_variable": "coerced",
        "typo_variable": "cosrces",
        "original_code": "protected void setFieldValue(String value) {\n      try {\n         // filter property value\n         value = filterValue(value);\n\n         // coerce value to field type\n         Class<?> type = fieldInstance.getField().getType();\n         PropertyEditor editor = PropertyEditors.findEditor(type);\n         editor.setAsText(value);\n         Object coerced = editor.getValue();\n\n         // bind value to field\n         fieldInstance.set(coerced);\n      }\n      catch (IllegalAccessException e) {\n         throw new PropertyException(e);\n      }\n   }",
        "modified_code": "protected void setFieldValue(String value) {\n      try {\n         // filter property value\n         value = filterValue(value);\n\n         // coerce value to field type\n         Class<?> type = fieldInstance.getField().getType();\n         PropertyEditor editor = PropertyEditors.findEditor(type);\n         editor.setAsText(value);\n         Object cosrces = editor.getValue();\n\n         // bind value to field\n         fieldInstance.set(cosrces);\n      }\n      catch (IllegalAccessException e) {\n         throw new PropertyException(e);\n      }\n   }",
        "explanations_by_ours": [
            "the cosrces of the field",
            "the cosrces to set",
            "the cosrces of the field."
        ],
        "corrections_by_ours": [
            "set",
            "field"
        ],
        "corrections_by_baseline": [
            "cosc",
            "cos",
            "cosl",
            "cosTheta",
            "vmas",
            "coslat",
            "hysteresis",
            "lamda_geos",
            "proxyscope",
            "cphi"
        ]
    },
    {
        "original_word": "retval",
        "typo_word": "rrtvql",
        "original_variable": "retval",
        "typo_variable": "rrtvql",
        "original_code": "public int close()\n  {\n    int retval = 0;\n    try\n    {\n      if (mOpenStream != null && mCloseStreamOnClose)\n      {\n        mOpenStream.close();\n      }\n    }\n    catch (IOException e)\n    {\n      log.error(\"could not close stream {}: {}\", mOpenStream, e);\n      retval = -1;\n    }\n    mOpenStream = null;\n    return retval;\n  }",
        "modified_code": "public int close()\n  {\n    int rrtvql = 0;\n    try\n    {\n      if (mOpenStream != null && mCloseStreamOnClose)\n      {\n        mOpenStream.close();\n      }\n    }\n    catch (IOException e)\n    {\n      log.error(\"could not close stream {}: {}\", mOpenStream, e);\n      rrtvql = -1;\n    }\n    mOpenStream = null;\n    return rrtvql;\n  }",
        "explanations_by_ours": [
            "the number of rows affected by this operation",
            "The number of rows affected by this operation",
            "the number of rows affected by this operation."
        ],
        "corrections_by_ours": [
            "operation",
            "rows",
            "affected",
            "number"
        ],
        "corrections_by_baseline": [
            "dbsql",
            "ddl",
            "osql",
            "sql",
            "llpn",
            "pushcommand",
            "ddb",
            "pureSql",
            "sqlite",
            "qiancommand"
        ]
    },
    {
        "original_word": "buffer",
        "typo_word": "buccer",
        "original_variable": "buffer",
        "typo_variable": "buccer",
        "original_code": "public String createHash(final String iInput, final String iAlgorithm, final boolean iIncludeAlgorithm) {\r\n    if (iInput == null)\r\n      throw new IllegalArgumentException(\"Input string is null\");\r\n\r\n    if (iAlgorithm == null)\r\n      throw new IllegalArgumentException(\"Algorithm is null\");\r\n\r\n    final StringBuilder buffer = new StringBuilder(128);\r\n\r\n    final String algorithm = validateAlgorithm(iAlgorithm);\r\n\r\n    if (iIncludeAlgorithm) {\r\n      buffer.append('{');\r\n      buffer.append(algorithm);\r\n      buffer.append('}');\r\n    }\r\n\r\n    final String transformed;\r\n    if (HASH_ALGORITHM.equalsIgnoreCase(algorithm)) {\r\n      transformed = createSHA256(iInput);\r\n    } else if (PBKDF2_ALGORITHM.equalsIgnoreCase(algorithm)) {\r\n      transformed = createHashWithSalt(iInput, OGlobalConfiguration.SECURITY_USER_PASSWORD_SALT_ITERATIONS.getValueAsInteger(),\r\n          algorithm);\r\n    } else if (PBKDF2_SHA256_ALGORITHM.equalsIgnoreCase(algorithm)) {\r\n      transformed = createHashWithSalt(iInput, OGlobalConfiguration.SECURITY_USER_PASSWORD_SALT_ITERATIONS.getValueAsInteger(),\r\n          algorithm);\r\n    } else\r\n      throw new IllegalArgumentException(\"Algorithm '\" + algorithm + \"' is not supported\");\r\n\r\n    buffer.append(transformed);\r\n\r\n    return buffer.toString();\r\n  }",
        "modified_code": "public String createHash(final String iInput, final String iAlgorithm, final boolean iIncludeAlgorithm) {\r\n    if (iInput == null)\r\n      throw new IllegalArgumentException(\"Input string is null\");\r\n\r\n    if (iAlgorithm == null)\r\n      throw new IllegalArgumentException(\"Algorithm is null\");\r\n\r\n    final StringBuilder buccer = new StringBuilder(128);\r\n\r\n    final String algorithm = validateAlgorithm(iAlgorithm);\r\n\r\n    if (iIncludeAlgorithm) {\r\n      buccer.append('{');\r\n      buccer.append(algorithm);\r\n      buccer.append('}');\r\n    }\r\n\r\n    final String transformed;\r\n    if (HASH_ALGORITHM.equalsIgnoreCase(algorithm)) {\r\n      transformed = createSHA256(iInput);\r\n    } else if (PBKDF2_ALGORITHM.equalsIgnoreCase(algorithm)) {\r\n      transformed = createHashWithSalt(iInput, OGlobalConfiguration.SECURITY_USER_PASSWORD_SALT_ITERATIONS.getValueAsInteger(),\r\n          algorithm);\r\n    } else if (PBKDF2_SHA256_ALGORITHM.equalsIgnoreCase(algorithm)) {\r\n      transformed = createHashWithSalt(iInput, OGlobalConfiguration.SECURITY_USER_PASSWORD_SALT_ITERATIONS.getValueAsInteger(),\r\n          algorithm);\r\n    } else\r\n      throw new IllegalArgumentException(\"Algorithm '\" + algorithm + \"' is not supported\");\r\n\r\n    buccer.append(transformed);\r\n\r\n    return buccer.toString();\r\n  }",
        "explanations_by_ours": [
            "The string builder to use for the hash.",
            "The buffer to use for the hash.",
            "The string builder to use for generating the hash."
        ],
        "corrections_by_ours": [
            "buffer",
            "builder",
            "use",
            "generating",
            "string",
            "hash"
        ],
        "corrections_by_baseline": [
            "bcc",
            "ccorder",
            "anbieter",
            "bern",
            "ibegin",
            "bue",
            "bi",
            "cc",
            "csa",
            "icb"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "ciumt",
        "original_variable": "count",
        "typo_variable": "ciumt",
        "original_code": "public java.util.Collection<AudioFormat.Type>\n  getSupportedAudioFormats()\n  {\n    java.util.List<AudioFormat.Type> retval =\n      new java.util.LinkedList<AudioFormat.Type>();\n    int count = getNumSupportedAudioFormats();\n    for(int i=0;i<count;i++)\n    {\n      AudioFormat.Type fmt = getSupportedAudioFormat(i);\n      if (fmt != null && fmt != AudioFormat.Type.SAMPLE_FMT_NONE)\n        retval.add(fmt);\n    }\n    return retval;\n  }",
        "modified_code": "public java.util.Collection<AudioFormat.Type>\n  getSupportedAudioFormats()\n  {\n    java.util.List<AudioFormat.Type> retval =\n      new java.util.LinkedList<AudioFormat.Type>();\n    int ciumt = getNumSupportedAudioFormats();\n    for(int i=0;i<ciumt;i++)\n    {\n      AudioFormat.Type fmt = getSupportedAudioFormat(i);\n      if (fmt != null && fmt != AudioFormat.Type.SAMPLE_FMT_NONE)\n        retval.add(fmt);\n    }\n    return retval;\n  }",
        "explanations_by_ours": [
            "The supported audio formats.",
            "The number of supported audio formats.",
            "The number of supported audio formats"
        ],
        "corrections_by_ours": [
            "formats",
            "number",
            "supported",
            "audio"
        ],
        "corrections_by_baseline": [
            "tmi",
            "tUcum",
            "t",
            "T",
            "cf",
            "CF",
            "enumt",
            "tinv",
            "yc",
            "calt"
        ]
    },
    {
        "original_word": "response",
        "typo_word": "rexponze",
        "original_variable": "response",
        "typo_variable": "rexponze",
        "original_code": "public long addNextFile(SourceFile source)\n\t{\n\t\tString strPath = source.getFilePath();\n\t\tlong lStreamLength = source.getStreamLength();\n\t\t\n\t\tHttpClient client = new HttpClient();\n\n\t\tFile fileIn = source.makeInFile();\n\n\t\tString furl = m_strBaseURL + this.encodeURL(strPath);\n\t\tPutMethod put = new PutMethod(furl);\n\n\t\ttry\t{\n\t\t\tRequestEntity entity = new InputStreamRequestEntity(new FileInputStream(fileIn));\n\t\t\tput.setRequestEntity(entity);\n\n\t\t\tint response = client.executeMethod(put);\n\t\t\t\n\t\t\tif (response != 201)\n\t\t\t\tSystem.out.println(\"Error Response: \" + response);\n\t\t} catch (HttpException e) {\n\t\t\te.printStackTrace();\n\t\t} catch (FileNotFoundException ex)\t{\n\t\t\tex.printStackTrace();\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\t\n\t\treturn lStreamLength;\n\t}",
        "modified_code": "public long addNextFile(SourceFile source)\n\t{\n\t\tString strPath = source.getFilePath();\n\t\tlong lStreamLength = source.getStreamLength();\n\t\t\n\t\tHttpClient client = new HttpClient();\n\n\t\tFile fileIn = source.makeInFile();\n\n\t\tString furl = m_strBaseURL + this.encodeURL(strPath);\n\t\tPutMethod put = new PutMethod(furl);\n\n\t\ttry\t{\n\t\t\tRequestEntity entity = new InputStreamRequestEntity(new FileInputStream(fileIn));\n\t\t\tput.setRequestEntity(entity);\n\n\t\t\tint rexponze = client.executeMethod(put);\n\t\t\t\n\t\t\tif (rexponze != 201)\n\t\t\t\tSystem.out.println(\"Error Response: \" + rexponze);\n\t\t} catch (HttpException e) {\n\t\t\te.printStackTrace();\n\t\t} catch (FileNotFoundException ex)\t{\n\t\t\tex.printStackTrace();\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\t\n\t\treturn lStreamLength;\n\t}",
        "explanations_by_ours": [
            "The http response code.",
            "The status code of the request.",
            "The response code."
        ],
        "corrections_by_ours": [
            "response",
            "request",
            "code",
            "http",
            "status"
        ],
        "corrections_by_baseline": [
            "ze",
            "zis",
            "deref",
            "andrew",
            "zps",
            "rm",
            "oz",
            "nopr",
            "adz",
            "pex"
        ]
    },
    {
        "original_word": "content",
        "typo_word": "fpntent",
        "original_variable": "content",
        "typo_variable": "fpntent",
        "original_code": "protected Documentation readDocumentation(Element s) {\n    String href = s.getAttributeValue(\"href\", Catalog.xlinkNS);\n    String title = s.getAttributeValue(\"title\", Catalog.xlinkNS);\n    String type = s.getAttributeValue(\"type\"); // not XLink type\n    String content = s.getTextNormalize();\n\n    URI uri = null;\n    if (href != null) {\n      try {\n        uri = Catalog.resolveUri(baseURI, href);\n      }\n      catch (Exception e) {\n        errlog.format(\" ** Invalid documentation href = '%s' err='%s'%n\", href, e.getMessage());\n        logger.debug(\" ** Invalid documentation href = '{}' err='{}'\", href, e.getMessage());\n      }\n    }\n\n    return new Documentation(href, uri, title, type, content);\n  }",
        "modified_code": "protected Documentation readDocumentation(Element s) {\n    String href = s.getAttributeValue(\"href\", Catalog.xlinkNS);\n    String title = s.getAttributeValue(\"title\", Catalog.xlinkNS);\n    String type = s.getAttributeValue(\"type\"); // not XLink type\n    String fpntent = s.getTextNormalize();\n\n    URI uri = null;\n    if (href != null) {\n      try {\n        uri = Catalog.resolveUri(baseURI, href);\n      }\n      catch (Exception e) {\n        errlog.format(\" ** Invalid documentation href = '%s' err='%s'%n\", href, e.getMessage());\n        logger.debug(\" ** Invalid documentation href = '{}' err='{}'\", href, e.getMessage());\n      }\n    }\n\n    return new Documentation(href, uri, title, type, fpntent);\n  }",
        "explanations_by_ours": [
            "the content of the documentation",
            "the text to read",
            "the content of the documentation."
        ],
        "corrections_by_ours": [
            "content",
            "text",
            "documentation",
            "read"
        ],
        "corrections_by_baseline": [
            "ent",
            "nt",
            "icnt",
            "ncf",
            "ncatt",
            "etf",
            "dsp",
            "tbuff",
            "tmpMsg",
            "ithelement"
        ]
    },
    {
        "original_word": "Body",
        "typo_word": "Bldu",
        "original_variable": "requestBody",
        "typo_variable": "requestBldu",
        "original_code": "@Override\n    public Request searchForFacetValuesAsync(@NonNull String facetName, @NonNull String facetText, @Nullable Query query, @Nullable final RequestOptions requestOptions, @NonNull final CompletionHandler handler) {\n        try {\n            final String path = \"/1/indexes/\" + getEncodedIndexName() + \"/facets/\" + URLEncoder.encode(facetName, \"UTF-8\") + \"/query\";\n            final Query params = (query != null ? new Query(query) : new Query());\n            params.set(\"facetQuery\", facetText);\n            final JSONObject requestBody = new JSONObject().put(\"params\", params.build());\n\n            final Client client = getClient();\n            return client.new AsyncTaskRequest(handler) {\n                @NonNull\n                @Override\n                protected JSONObject run() throws AlgoliaException {\n                    return client.postRequest(path, /* urlParameters: */ null, requestBody.toString(), true, requestOptions);\n                }\n            }.start();\n        } catch (UnsupportedEncodingException | JSONException e) {\n            throw new RuntimeException(e); // should never happen\n        }\n    }",
        "modified_code": "@Override\n    public Request searchForFacetValuesAsync(@NonNull String facetName, @NonNull String facetText, @Nullable Query query, @Nullable final RequestOptions requestOptions, @NonNull final CompletionHandler handler) {\n        try {\n            final String path = \"/1/indexes/\" + getEncodedIndexName() + \"/facets/\" + URLEncoder.encode(facetName, \"UTF-8\") + \"/query\";\n            final Query params = (query != null ? new Query(query) : new Query());\n            params.set(\"facetQuery\", facetText);\n            final JSONObject requestBldu = new JSONObject().put(\"params\", params.build());\n\n            final Client client = getClient();\n            return client.new AsyncTaskRequest(handler) {\n                @NonNull\n                @Override\n                protected JSONObject run() throws AlgoliaException {\n                    return client.postRequest(path, /* urlParameters: */ null, requestBldu.toString(), true, requestOptions);\n                }\n            }.start();\n        } catch (UnsupportedEncodingException | JSONException e) {\n            throw new RuntimeException(e); // should never happen\n        }\n    }",
        "explanations_by_ours": [
            "The request body to send to Algolia.",
            "The request to send to Algolia.",
            "The request to send."
        ],
        "corrections_by_ours": [
            "requestBody",
            "sendBldu",
            "requestRequest",
            "requestAlgolia",
            "algoliaBldu",
            "bodyBldu",
            "requestSend",
            "requestBldu"
        ],
        "corrections_by_baseline": [
            "httpBldr",
            "daprequest",
            "authBldr",
            "putMappingRequestBuilder",
            "sspReq",
            "requestContext",
            "requestMap",
            "hrequest",
            "requestString",
            "request"
        ]
    },
    {
        "original_word": "Array",
        "typo_word": "Agrah",
        "original_variable": "newArray",
        "typo_variable": "newAgrah",
        "original_code": "private static Object[] rehash(final Object[] values, final int newSize)\n    {\n        Object[] newArray = new Object[newSize];\n\n        for (Object value : values)\n        {\n            if (value == null)\n            {\n                continue;\n            }\n\n            newArray[predictedPosition(newArray, value, value.hashCode())] = value;\n        }\n\n        return newArray;\n    }",
        "modified_code": "private static Object[] rehash(final Object[] values, final int newSize)\n    {\n        Object[] newAgrah = new Object[newSize];\n\n        for (Object value : values)\n        {\n            if (value == null)\n            {\n                continue;\n            }\n\n            newAgrah[predictedPosition(newAgrah, value, value.hashCode())] = value;\n        }\n\n        return newAgrah;\n    }",
        "explanations_by_ours": [
            "the new array",
            "the new array of values",
            "the rehash array"
        ],
        "corrections_by_ours": [
            "newArray",
            "newRehash",
            "valuesAgrah",
            "rehashAgrah",
            "newValues",
            "arrayAgrah",
            "newNew",
            "newAgrah"
        ],
        "corrections_by_baseline": [
            "newNfa",
            "newd",
            "newPtg",
            "newg",
            "newit",
            "newNw",
            "newGoal",
            "newAnd",
            "newMunged",
            "newR"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "cougr",
        "original_variable": "count",
        "typo_variable": "cougr",
        "original_code": "public String readStringMax(int nbytes) throws IOException {\r\n    byte[] b = new byte[nbytes];\r\n    readFully(b);\r\n    int count;\r\n    for (count = 0; count < nbytes; count++)\r\n      if (b[count] == 0) break;\r\n    return new String(b, 0, count, CDM.utf8Charset);\r\n  }",
        "modified_code": "public String readStringMax(int nbytes) throws IOException {\r\n    byte[] b = new byte[nbytes];\r\n    readFully(b);\r\n    int cougr;\r\n    for (cougr = 0; cougr < nbytes; cougr++)\r\n      if (b[cougr] == 0) break;\r\n    return new String(b, 0, cougr, CDM.utf8Charset);\r\n  }",
        "explanations_by_ours": [
            "the number of bytes to read",
            "the maximum number of bytes to read",
            "the number of bytes read"
        ],
        "corrections_by_ours": [
            "number",
            "bytes",
            "maximum",
            "read"
        ],
        "corrections_by_baseline": [
            "gr",
            "ou",
            "sdc",
            "cgaw",
            "caw",
            "cir",
            "lac",
            "corbaloc",
            "ihour",
            "coun"
        ]
    },
    {
        "original_word": "expects",
        "typo_word": "rcpects",
        "original_variable": "expectsArgs",
        "typo_variable": "rcpectsArgs",
        "original_code": "protected void addOption(String option, String comment, String argument, boolean mandatory, String formatRegexp)\n    {\n        // Check if usage text has been set in which case this option is expecting arguments.\n        boolean expectsArgs = (!((argument == null) || \"\".equals(argument)));\n\n        // Add the option to the map of command line options.\n        CommandLineOption opt = new CommandLineOption(option, expectsArgs, comment, argument, mandatory, formatRegexp);\n        optionMap.put(option, opt);\n    }",
        "modified_code": "protected void addOption(String option, String comment, String argument, boolean mandatory, String formatRegexp)\n    {\n        // Check if usage text has been set in which case this option is expecting arguments.\n        boolean rcpectsArgs = (!((argument == null) || \"\".equals(argument)));\n\n        // Add the option to the map of command line options.\n        CommandLineOption opt = new CommandLineOption(option, rcpectsArgs, comment, argument, mandatory, formatRegexp);\n        optionMap.put(option, opt);\n    }",
        "explanations_by_ours": [
            "The rcpects args flag.",
            "The rcpects arguments flag.",
            "The rcpects args flag"
        ],
        "corrections_by_ours": [
            "argumentsArgs",
            "rcpectsArguments",
            "argsArgs",
            "rcpectsRcpects",
            "flagArgs",
            "rcpectsFlag",
            "rcpectsArgs"
        ],
        "corrections_by_baseline": [
            "iArgs",
            "args",
            "scalaArgs",
            "argp",
            "actualArgs",
            "arguments",
            "extraArgs",
            "tArgs",
            "newArgs",
            "clientArgs"
        ]
    },
    {
        "original_word": "Names",
        "typo_word": "Nskes",
        "original_variable": "fieldNames",
        "typo_variable": "fieldNskes",
        "original_code": "static boolean isListElementType(Type repeatedType,\n                                   ThriftField thriftElement) {\n    if (repeatedType.isPrimitive() ||\n        (repeatedType.asGroupType().getFieldCount() != 1) ||\n        (repeatedType.asGroupType().getType(0).isRepetition(REPEATED))) {\n      // The repeated type must be the element type because it is an invalid\n      // synthetic wrapper. Must be a group with one optional or required field\n      return true;\n    } else if (thriftElement != null && thriftElement.getType() instanceof StructType) {\n      Set<String> fieldNames = new HashSet<String>();\n      for (ThriftField field : ((StructType) thriftElement.getType()).getChildren()) {\n        fieldNames.add(field.getName());\n      }\n      // If the repeated type is a subset of the structure of the ThriftField,\n      // then it must be the element type.\n      return fieldNames.contains(repeatedType.asGroupType().getFieldName(0));\n    }\n    return false;\n  }",
        "modified_code": "static boolean isListElementType(Type repeatedType,\n                                   ThriftField thriftElement) {\n    if (repeatedType.isPrimitive() ||\n        (repeatedType.asGroupType().getFieldCount() != 1) ||\n        (repeatedType.asGroupType().getType(0).isRepetition(REPEATED))) {\n      // The repeated type must be the element type because it is an invalid\n      // synthetic wrapper. Must be a group with one optional or required field\n      return true;\n    } else if (thriftElement != null && thriftElement.getType() instanceof StructType) {\n      Set<String> fieldNskes = new HashSet<String>();\n      for (ThriftField field : ((StructType) thriftElement.getType()).getChildren()) {\n        fieldNskes.add(field.getName());\n      }\n      // If the repeated type is a subset of the structure of the ThriftField,\n      // then it must be the element type.\n      return fieldNskes.contains(repeatedType.asGroupType().getFieldName(0));\n    }\n    return false;\n  }",
        "explanations_by_ours": [
            "The names of the fields in the repeated type.",
            "The names of the fields in the repeated type",
            "The names of the fields in the group."
        ],
        "corrections_by_ours": [
            "fieldsNskes",
            "fieldNames",
            "fieldNskes",
            "repeatedNskes",
            "fieldType",
            "fieldFields",
            "fieldRepeated",
            "typeNskes",
            "groupNskes",
            "namesNskes"
        ],
        "corrections_by_baseline": [
            "fieldNames",
            "attributeNames",
            "sdcMapFieldValues",
            "fieldNameParts",
            "aKeyColumnRefs",
            "propertyNames",
            "fieldMappings",
            "attributeNamespace",
            "propNames",
            "stnKeyNames"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rrault",
        "original_variable": "result",
        "typo_variable": "rrault",
        "original_code": "static public long\n    extractLongValue(TypeSort atomtype, DataCursor dataset, Index index)\n            throws DapException\n    {\n        Object result;\n        result = dataset.read(index);\n        long lvalue = CDMTypeFcns.extract(atomtype, result);\n        return lvalue;\n    }",
        "modified_code": "static public long\n    extractLongValue(TypeSort atomtype, DataCursor dataset, Index index)\n            throws DapException\n    {\n        Object rrault;\n        rrault = dataset.read(index);\n        long lvalue = CDMTypeFcns.extract(atomtype, rrault);\n        return lvalue;\n    }",
        "explanations_by_ours": [
            "the value to read from the data cursor",
            "the result of the read operation",
            "the result of the data cursor"
        ],
        "corrections_by_ours": [
            "result",
            "value",
            "read",
            "operation",
            "data",
            "cursor"
        ],
        "corrections_by_baseline": [
            "R",
            "r",
            "rp",
            "isr",
            "raven",
            "ra",
            "rtemp",
            "rj",
            "itr",
            "rho"
        ]
    },
    {
        "original_word": "stoke",
        "typo_word": "sgokd",
        "original_variable": "stoke",
        "typo_variable": "sgokd",
        "original_code": "public static boolean print(String command, Writer out, ucar.nc2.util.CancelTask ct) throws IOException {\n    // pull out the filename from the command\n    String filename;\n    StringTokenizer stoke = new StringTokenizer(command);\n    if (stoke.hasMoreTokens())\n      filename = stoke.nextToken();\n    else {\n      out.write(usage);\n      return false;\n    }\n\n    try (NetcdfFile nc = NetcdfDataset.openFile(filename, ct)) {\n      // the rest of the command\n      int pos = command.indexOf(filename);\n      command = command.substring(pos + filename.length());\n      return print(nc, command, out, ct);\n\n    } catch (java.io.FileNotFoundException e) {\n      out.write(\"file not found= \");\n      out.write(filename);\n      return false;\n\n    } finally {\n      out.close();\n    }\n  }",
        "modified_code": "public static boolean print(String command, Writer out, ucar.nc2.util.CancelTask ct) throws IOException {\n    // pull out the filename from the command\n    String filename;\n    StringTokenizer sgokd = new StringTokenizer(command);\n    if (sgokd.hasMoreTokens())\n      filename = sgokd.nextToken();\n    else {\n      out.write(usage);\n      return false;\n    }\n\n    try (NetcdfFile nc = NetcdfDataset.openFile(filename, ct)) {\n      // the rest of the command\n      int pos = command.indexOf(filename);\n      command = command.substring(pos + filename.length());\n      return print(nc, command, out, ct);\n\n    } catch (java.io.FileNotFoundException e) {\n      out.write(\"file not found= \");\n      out.write(filename);\n      return false;\n\n    } finally {\n      out.close();\n    }\n  }",
        "explanations_by_ours": [
            "the command to print",
            "the command to print.",
            "the command to parse"
        ],
        "corrections_by_ours": [
            "command",
            "parse",
            "print"
        ],
        "corrections_by_baseline": [
            "dudf",
            "dys",
            "goalid",
            "ykr",
            "mefd",
            "nk",
            "scd",
            "dz",
            "pkinf",
            "orog"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nwmr",
        "original_variable": "propName",
        "typo_variable": "propNwmr",
        "original_code": "public static Object getPropByPath( Object item, String... path ) {\n\n        Object o = item;\n        for ( int index = 0; index < path.length; index++ ) {\n            String propName = path[ index ];\n            if ( o == null ) {\n                return null;\n            } else if ( o.getClass().isArray() || o instanceof Collection ) {\n\n\n                o = getCollectionProp(o, propName, index, path);\n                break;\n            } else {\n                o = getProp( o, propName );\n            }\n        }\n\n        return Conversions.unifyListOrArray(o);\n    }",
        "modified_code": "public static Object getPropByPath( Object item, String... path ) {\n\n        Object o = item;\n        for ( int index = 0; index < path.length; index++ ) {\n            String propNwmr = path[ index ];\n            if ( o == null ) {\n                return null;\n            } else if ( o.getClass().isArray() || o instanceof Collection ) {\n\n\n                o = getCollectionProp(o, propNwmr, index, path);\n                break;\n            } else {\n                o = getProp( o, propNwmr );\n            }\n        }\n\n        return Conversions.unifyListOrArray(o);\n    }",
        "explanations_by_ours": [
            "the property name",
            "the property nwmr",
            "the name of the property"
        ],
        "corrections_by_ours": [
            "propertyNwmr",
            "propName",
            "propProperty",
            "nameNwmr",
            "nwmrNwmr",
            "propNwmr"
        ],
        "corrections_by_baseline": [
            "fprop",
            "pN",
            "primitiveNdx",
            "prop",
            "rLPS",
            "r_2",
            "r0",
            "R0",
            "propArray",
            "eqNdx"
        ]
    },
    {
        "original_word": "first",
        "typo_word": "fjrsr",
        "original_variable": "firstChar",
        "typo_variable": "fjrsrChar",
        "original_code": "public void scan(Reader r0, ScanHandler h) throws IOException, SAXException {\n        theState = S_PCDATA;\n        PushbackReader r;\n        if (r0 instanceof PushbackReader) {\n            r = (PushbackReader) r0;\n        } else if (r0 instanceof BufferedReader) {\n            r = new PushbackReader(r0);\n        } else {\n            r = new PushbackReader(new BufferedReader(r0, 200));\n        }\n\n        int firstChar = r.read(); // Remove any leading BOM\n        if (firstChar != '\\uFEFF')\n            unread(r, firstChar);\n\n        while (theState != S_DONE) {\n            int c1 = r.read();\n            char c = (char) c1;\n            boolean is32BitChar = Character.isHighSurrogate(c);\n            int c2 = is32BitChar ? r.read() : -1;\n            String s = is32BitChar ? new StringBuffer().append(c).append((char) c2).toString() : null;\n\n            // Process control characters\n            if (!is32BitChar && c1 >= 0x80 && c1 <= 0x9F)\n                c1 = theWinMap[c1 - 0x80];\n\n            if (!is32BitChar && c1 == '\\r') {\n                c1 = r.read(); // expect LF next\n                if (c1 != '\\n') {\n                    unread(r, c1); // nope\n                    c1 = '\\n';\n                }\n            }\n\n            if (!is32BitChar && c1 == '\\n') {\n                theCurrentLine++;\n                theCurrentColumn = 0;\n            } else {\n                theCurrentColumn++;\n            }\n\n            if (!!is32BitChar && !(c1 >= 0x20 || c1 == '\\n' || c1 == '\\t' || c1 == -1))\n                continue;\n\n            // Search state table\n            int action = 0;\n            for (int i = 0; i < statetable.length; i += 4) {\n                if (theState != statetable[i]) {\n                    if (action != 0)\n                        break;\n                    continue;\n                }\n                if (statetable[i + 1] == 0) {\n                    action = statetable[i + 2];\n                    theNextState = statetable[i + 3];\n                } else if (!is32BitChar && statetable[i + 1] == c1) {\n                    action = statetable[i + 2];\n                    theNextState = statetable[i + 3];\n                    break;\n                }\n            }\n            switch (action) {\n                case 0:\n                    throw new Error(\"HTMLScanner can't cope with \" + Integer.toString(c1) + \" in state \" + Integer.toString(theState));\n                case A_ADUP:\n                    h.adup(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_ADUP_SAVE:\n                    h.adup(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    if (s != null)\n                        save(s, c1, h);\n                    break;\n                case A_ADUP_STAGC:\n                    h.adup(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.stagc(theOutputBuffer, 0, theSize);\n                    break;\n                case A_ANAME:\n                    h.aname(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_ANAME_ADUP:\n                    h.aname(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.adup(theOutputBuffer, 0, theSize);\n                    break;\n                case A_ANAME_ADUP_STAGC:\n                    h.aname(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.adup(theOutputBuffer, 0, theSize);\n                    h.stagc(theOutputBuffer, 0, theSize);\n                    break;\n                case A_AVAL:\n                    h.aval(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_AVAL_STAGC:\n                    h.aval(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.stagc(theOutputBuffer, 0, theSize);\n                    break;\n                case A_CDATA:\n                    mark();\n                    // suppress the final \"]]\" in the buffer\n                    if (theSize > 1)\n                        theSize -= 2;\n                    h.pcdata(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_ENTITY_START:\n                    h.pcdata(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    save(s, c1, h);\n                    break;\n                case A_ENTITY:\n                    mark();\n                    if (theState == S_ENT && c == '#') {\n                        theNextState = S_NCR;\n                        save(s, c1, h);\n                        break;\n                    } else if (theState == S_NCR && (c == 'x' || c == 'X')) {\n                        theNextState = S_XNCR;\n                        save(s, c1, h);\n                        break;\n                    } else if (theState == S_ENT && Character.isLetterOrDigit(c)) {\n                        save(s, c1, h);\n                        break;\n                    } else if (theState == S_NCR && Character.isDigit(c)) {\n                        save(s, c1, h);\n                        break;\n                    } else if (theState == S_XNCR && (Character.isDigit(c) || \"abcdefABCDEF\".indexOf(c) != -1)) {\n                        save(s, c1, h);\n                        break;\n                    }\n\n                    // The whole entity reference has been collected\n                    h.entity(theOutputBuffer, 1, theSize - 1);\n                    int ent = h.getEntity();\n                    if (ent != 0) {\n                        theSize = 0;\n                        if (ent >= 0x80 && ent <= 0x9F) {\n                            ent = theWinMap[ent - 0x80];\n                        }\n                        if (ent < 0x20) {\n                            // Control becomes space\n                            ent = 0x20;\n                        } else if (ent >= 0xD800 && ent <= 0xDFFF) {\n                            // Surrogates get dropped\n                            ent = 0;\n                        } else if (ent <= 0xFFFF) {\n                            // BMP character\n                            save(ent, h);\n                        } else {\n                            // Astral converted to two surrogates\n                            ent -= 0x10000;\n                            save((ent >> 10) + 0xD800, h);\n                            save((ent & 0x3FF) + 0xDC00, h);\n                        }\n                        if (is32BitChar || c1 != ';') {\n                            if (is32BitChar) {\n                                unread(r, c2);\n                                theCurrentColumn--;\n                            }\n                            unread(r, c1);\n                            theCurrentColumn--;\n                        }\n                    } else {\n                        if (is32BitChar) {\n                            unread(r, c2);\n                            theCurrentColumn--;\n                        }\n                        unread(r, c1);\n                        theCurrentColumn--;\n                    }\n                    theNextState = S_PCDATA;\n                    break;\n                case A_ETAG:\n                    h.etag(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_DECL:\n                    h.decl(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_GI:\n                    h.gi(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_GI_STAGC:\n                    h.gi(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.stagc(theOutputBuffer, 0, theSize);\n                    break;\n                case A_LT:\n                    mark();\n                    save('<', h);\n                    save(s, c1, h);\n                    break;\n                case A_LT_PCDATA:\n                    mark();\n                    save('<', h);\n                    h.pcdata(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_PCDATA:\n                    mark();\n                    h.pcdata(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_CMNT:\n                    mark();\n                    h.cmnt(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_MINUS3:\n                    save('-', h);\n                    save(' ', h);\n                    break;\n                case A_MINUS2:\n                    save('-', h);\n                    save(' ', h);\n                    // fall through into A_MINUS\n                case A_MINUS:\n                    save('-', h);\n                    save(s, c1, h);\n                    break;\n                case A_PI:\n                    mark();\n                    h.pi(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_PITARGET:\n                    h.pitarget(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_PITARGET_PI:\n                    h.pitarget(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.pi(theOutputBuffer, 0, theSize);\n                    break;\n                case A_SAVE:\n                    save(s, c1, h);\n                    break;\n                case A_SKIP:\n                    break;\n                case A_SP:\n                    save(' ', h);\n                    break;\n                case A_STAGC:\n                    h.stagc(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_EMPTYTAG:\n                    mark();\n                    if (theSize > 0)\n                        h.gi(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.stage(theOutputBuffer, 0, theSize);\n                    break;\n                case A_UNGET:\n                    unread(r, c1);\n                    theCurrentColumn--;\n                    break;\n                case A_UNSAVE_PCDATA:\n                    if (theSize > 0)\n                        theSize--;\n                    h.pcdata(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                default:\n                    throw new Error(\"Can't process state \" + action);\n            }\n            theState = theNextState;\n        }\n        h.eof(theOutputBuffer, 0, 0);\n    }",
        "modified_code": "public void scan(Reader r0, ScanHandler h) throws IOException, SAXException {\n        theState = S_PCDATA;\n        PushbackReader r;\n        if (r0 instanceof PushbackReader) {\n            r = (PushbackReader) r0;\n        } else if (r0 instanceof BufferedReader) {\n            r = new PushbackReader(r0);\n        } else {\n            r = new PushbackReader(new BufferedReader(r0, 200));\n        }\n\n        int fjrsrChar = r.read(); // Remove any leading BOM\n        if (fjrsrChar != '\\uFEFF')\n            unread(r, fjrsrChar);\n\n        while (theState != S_DONE) {\n            int c1 = r.read();\n            char c = (char) c1;\n            boolean is32BitChar = Character.isHighSurrogate(c);\n            int c2 = is32BitChar ? r.read() : -1;\n            String s = is32BitChar ? new StringBuffer().append(c).append((char) c2).toString() : null;\n\n            // Process control characters\n            if (!is32BitChar && c1 >= 0x80 && c1 <= 0x9F)\n                c1 = theWinMap[c1 - 0x80];\n\n            if (!is32BitChar && c1 == '\\r') {\n                c1 = r.read(); // expect LF next\n                if (c1 != '\\n') {\n                    unread(r, c1); // nope\n                    c1 = '\\n';\n                }\n            }\n\n            if (!is32BitChar && c1 == '\\n') {\n                theCurrentLine++;\n                theCurrentColumn = 0;\n            } else {\n                theCurrentColumn++;\n            }\n\n            if (!!is32BitChar && !(c1 >= 0x20 || c1 == '\\n' || c1 == '\\t' || c1 == -1))\n                continue;\n\n            // Search state table\n            int action = 0;\n            for (int i = 0; i < statetable.length; i += 4) {\n                if (theState != statetable[i]) {\n                    if (action != 0)\n                        break;\n                    continue;\n                }\n                if (statetable[i + 1] == 0) {\n                    action = statetable[i + 2];\n                    theNextState = statetable[i + 3];\n                } else if (!is32BitChar && statetable[i + 1] == c1) {\n                    action = statetable[i + 2];\n                    theNextState = statetable[i + 3];\n                    break;\n                }\n            }\n            switch (action) {\n                case 0:\n                    throw new Error(\"HTMLScanner can't cope with \" + Integer.toString(c1) + \" in state \" + Integer.toString(theState));\n                case A_ADUP:\n                    h.adup(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_ADUP_SAVE:\n                    h.adup(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    if (s != null)\n                        save(s, c1, h);\n                    break;\n                case A_ADUP_STAGC:\n                    h.adup(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.stagc(theOutputBuffer, 0, theSize);\n                    break;\n                case A_ANAME:\n                    h.aname(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_ANAME_ADUP:\n                    h.aname(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.adup(theOutputBuffer, 0, theSize);\n                    break;\n                case A_ANAME_ADUP_STAGC:\n                    h.aname(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.adup(theOutputBuffer, 0, theSize);\n                    h.stagc(theOutputBuffer, 0, theSize);\n                    break;\n                case A_AVAL:\n                    h.aval(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_AVAL_STAGC:\n                    h.aval(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.stagc(theOutputBuffer, 0, theSize);\n                    break;\n                case A_CDATA:\n                    mark();\n                    // suppress the final \"]]\" in the buffer\n                    if (theSize > 1)\n                        theSize -= 2;\n                    h.pcdata(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_ENTITY_START:\n                    h.pcdata(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    save(s, c1, h);\n                    break;\n                case A_ENTITY:\n                    mark();\n                    if (theState == S_ENT && c == '#') {\n                        theNextState = S_NCR;\n                        save(s, c1, h);\n                        break;\n                    } else if (theState == S_NCR && (c == 'x' || c == 'X')) {\n                        theNextState = S_XNCR;\n                        save(s, c1, h);\n                        break;\n                    } else if (theState == S_ENT && Character.isLetterOrDigit(c)) {\n                        save(s, c1, h);\n                        break;\n                    } else if (theState == S_NCR && Character.isDigit(c)) {\n                        save(s, c1, h);\n                        break;\n                    } else if (theState == S_XNCR && (Character.isDigit(c) || \"abcdefABCDEF\".indexOf(c) != -1)) {\n                        save(s, c1, h);\n                        break;\n                    }\n\n                    // The whole entity reference has been collected\n                    h.entity(theOutputBuffer, 1, theSize - 1);\n                    int ent = h.getEntity();\n                    if (ent != 0) {\n                        theSize = 0;\n                        if (ent >= 0x80 && ent <= 0x9F) {\n                            ent = theWinMap[ent - 0x80];\n                        }\n                        if (ent < 0x20) {\n                            // Control becomes space\n                            ent = 0x20;\n                        } else if (ent >= 0xD800 && ent <= 0xDFFF) {\n                            // Surrogates get dropped\n                            ent = 0;\n                        } else if (ent <= 0xFFFF) {\n                            // BMP character\n                            save(ent, h);\n                        } else {\n                            // Astral converted to two surrogates\n                            ent -= 0x10000;\n                            save((ent >> 10) + 0xD800, h);\n                            save((ent & 0x3FF) + 0xDC00, h);\n                        }\n                        if (is32BitChar || c1 != ';') {\n                            if (is32BitChar) {\n                                unread(r, c2);\n                                theCurrentColumn--;\n                            }\n                            unread(r, c1);\n                            theCurrentColumn--;\n                        }\n                    } else {\n                        if (is32BitChar) {\n                            unread(r, c2);\n                            theCurrentColumn--;\n                        }\n                        unread(r, c1);\n                        theCurrentColumn--;\n                    }\n                    theNextState = S_PCDATA;\n                    break;\n                case A_ETAG:\n                    h.etag(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_DECL:\n                    h.decl(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_GI:\n                    h.gi(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_GI_STAGC:\n                    h.gi(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.stagc(theOutputBuffer, 0, theSize);\n                    break;\n                case A_LT:\n                    mark();\n                    save('<', h);\n                    save(s, c1, h);\n                    break;\n                case A_LT_PCDATA:\n                    mark();\n                    save('<', h);\n                    h.pcdata(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_PCDATA:\n                    mark();\n                    h.pcdata(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_CMNT:\n                    mark();\n                    h.cmnt(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_MINUS3:\n                    save('-', h);\n                    save(' ', h);\n                    break;\n                case A_MINUS2:\n                    save('-', h);\n                    save(' ', h);\n                    // fall through into A_MINUS\n                case A_MINUS:\n                    save('-', h);\n                    save(s, c1, h);\n                    break;\n                case A_PI:\n                    mark();\n                    h.pi(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_PITARGET:\n                    h.pitarget(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_PITARGET_PI:\n                    h.pitarget(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.pi(theOutputBuffer, 0, theSize);\n                    break;\n                case A_SAVE:\n                    save(s, c1, h);\n                    break;\n                case A_SKIP:\n                    break;\n                case A_SP:\n                    save(' ', h);\n                    break;\n                case A_STAGC:\n                    h.stagc(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                case A_EMPTYTAG:\n                    mark();\n                    if (theSize > 0)\n                        h.gi(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    h.stage(theOutputBuffer, 0, theSize);\n                    break;\n                case A_UNGET:\n                    unread(r, c1);\n                    theCurrentColumn--;\n                    break;\n                case A_UNSAVE_PCDATA:\n                    if (theSize > 0)\n                        theSize--;\n                    h.pcdata(theOutputBuffer, 0, theSize);\n                    theSize = 0;\n                    break;\n                default:\n                    throw new Error(\"Can't process state \" + action);\n            }\n            theState = theNextState;\n        }\n        h.eof(theOutputBuffer, 0, 0);\n    }",
        "explanations_by_ours": [
            "The first BOM character in the reader.",
            "The first BOM character in the stream.",
            "The BOM character to read from."
        ],
        "corrections_by_ours": [
            "firstChar",
            "fjrsrCharacter",
            "fjrsrReader",
            "fjrsrRead",
            "characterChar",
            "readerChar",
            "streamChar",
            "fjrsrStream",
            "fjrsrChar",
            "bomChar"
        ],
        "corrections_by_baseline": [
            "charOder",
            "bomChar",
            "aChar",
            "char1",
            "hexChar",
            "cchar",
            "stringChar",
            "uppercaseChar",
            "char2",
            "chararr"
        ]
    },
    {
        "original_word": "mechanisms",
        "typo_word": "mdchanisns",
        "original_variable": "mechanisms",
        "typo_variable": "mdchanisns",
        "original_code": "public void authenticate(String username, String host, CallbackHandler cbh)\n            throws IOException, XMPPException {\n        String[] mechanisms = { getName() };\n        Map<String, String> props = new HashMap<String, String>();\n        sc = Sasl.createSaslClient(mechanisms, username, \"xmpp\", host, props,\n                cbh);\n        authenticate();\n    }",
        "modified_code": "public void authenticate(String username, String host, CallbackHandler cbh)\n            throws IOException, XMPPException {\n        String[] mdchanisns = { getName() };\n        Map<String, String> props = new HashMap<String, String>();\n        sc = Sasl.createSaslClient(mdchanisns, username, \"xmpp\", host, props,\n                cbh);\n        authenticate();\n    }",
        "explanations_by_ours": [
            "the mdchanisns of the XMPP server.",
            "the list of mdchanisns to connect to.",
            "the list of mdchanisns to use for authentication."
        ],
        "corrections_by_ours": [
            "authentication",
            "connect",
            "list",
            "use",
            "server",
            "xmpp"
        ],
        "corrections_by_baseline": [
            "mns",
            "mechanisms",
            "ingresses",
            "addresses",
            "addrs",
            "proxies",
            "notificationReceivers",
            "emails",
            "peerIds",
            "msgs"
        ]
    },
    {
        "original_word": "forced",
        "typo_word": "fotcew",
        "original_variable": "forcedRollback",
        "typo_variable": "fotcewRollback",
        "original_code": "protected void commitOrRollback(boolean doCommit) {\n\t\tif (log.isDebugEnabled()) {\n\t\t\tif (doCommit) {\n\t\t\t\tlog.debug(\"Commit JTX\");\n\t\t\t} else {\n\t\t\t\tlog.debug(\"Rollback JTX\");\n\t\t\t}\n\t\t}\n\t\tboolean forcedRollback = false;\n\t\tif (!isNoTransaction()) {\n\t\t\tif (isRollbackOnly()) {\n\t\t\t\tif (doCommit) {\n\t\t\t\t\tdoCommit = false;\n\t\t\t\t\tforcedRollback = true;\n\t\t\t\t}\n\t\t\t} else if (!isActive()) {\n\t\t\t\tif (isCompleted()) {\n\t\t\t\t\tthrow new JtxException(\"TX is already completed, commit or rollback should be called once per TX\");\n\t\t\t\t}\n\t\t\t\tthrow new JtxException(\"No active TX to \" + (doCommit ? \"commit\" : \"rollback\"));\n\t\t\t}\n\t\t}\n\t\tif (doCommit) {\n\t\t\tcommitAllResources();\n\t\t} else {\n\t\t\trollbackAllResources(forcedRollback);\n\t\t}\n\t}",
        "modified_code": "protected void commitOrRollback(boolean doCommit) {\n\t\tif (log.isDebugEnabled()) {\n\t\t\tif (doCommit) {\n\t\t\t\tlog.debug(\"Commit JTX\");\n\t\t\t} else {\n\t\t\t\tlog.debug(\"Rollback JTX\");\n\t\t\t}\n\t\t}\n\t\tboolean fotcewRollback = false;\n\t\tif (!isNoTransaction()) {\n\t\t\tif (isRollbackOnly()) {\n\t\t\t\tif (doCommit) {\n\t\t\t\t\tdoCommit = false;\n\t\t\t\t\tfotcewRollback = true;\n\t\t\t\t}\n\t\t\t} else if (!isActive()) {\n\t\t\t\tif (isCompleted()) {\n\t\t\t\t\tthrow new JtxException(\"TX is already completed, commit or rollback should be called once per TX\");\n\t\t\t\t}\n\t\t\t\tthrow new JtxException(\"No active TX to \" + (doCommit ? \"commit\" : \"rollback\"));\n\t\t\t}\n\t\t}\n\t\tif (doCommit) {\n\t\t\tcommitAllResources();\n\t\t} else {\n\t\t\trollbackAllResources(fotcewRollback);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "if true, rollback the transaction.",
            "if true, fotcew rollback.",
            "if true, rollback the transaction, otherwise commit."
        ],
        "corrections_by_ours": [
            "otherwiseRollback",
            "fotcewTransaction",
            "commitRollback",
            "true,Rollback",
            "fotcewTransaction,",
            "rollbackRollback",
            "fotcewFotcew",
            "fotcewCommit",
            "transactionRollback",
            "transaction,Rollback"
        ],
        "corrections_by_baseline": [
            "rollback",
            "forcedRollback",
            "doRollback",
            "rollbackTx",
            "originalAutoCommit",
            "rollbackOnlySet",
            "setRollbackAndThrowException",
            "rollbackAction",
            "basicRollup",
            "afterRollbackAction"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "dwsult",
        "original_variable": "result",
        "typo_variable": "dwsult",
        "original_code": "protected boolean isGzipEligible(final HttpServletRequest request) {\n\t\t// request parameter name\n\n\t\tif (requestParameterName.length() != 0) {\n\t\t\tString forceGzipString = request.getParameter(requestParameterName);\n\n\t\t\tif (forceGzipString != null) {\n\t\t\t\treturn Converter.get().toBooleanValue(forceGzipString, false);\n\t\t\t}\n\t\t}\n\n\t\t// extract uri\n\n\t\tString uri = request.getRequestURI();\n\n\t\tif (uri == null) {\n\t\t\treturn false;\n\t\t}\n\n\t\turi = uri.toLowerCase();\n\n\t\tboolean result = false;\n\n\t\t// check uri\n\n\t\tif (matches == null) {\t\t\t\t\t// match == *\n\t\t\tif (extensions == null) {\t\t\t// extensions == *\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\t// extension\n\t\t\tString extension = FileNameUtil.getExtension(uri);\n\n\t\t\tif (extension.length() > 0) {\n\t\t\t\textension = extension.toLowerCase();\n\n\t\t\t\tif (StringUtil.equalsOne(extension, extensions) != -1) {\n\t\t\t\t\tresult = true;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif (wildcards) {\n\t\t\t\tresult = Wildcard.matchPathOne(uri, matches) != -1;\n\t\t\t} else {\n\t\t\t\tfor (String match : matches) {\n\t\t\t\t\tif (uri.contains(match)) {\n\t\t\t\t\t\tresult = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif ((result) && (excludes != null)) {\n\t\t\tif (wildcards) {\n\t\t\t\tif (Wildcard.matchPathOne(uri, excludes) != -1) {\n\t\t\t\t\tresult = false;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor (String exclude : excludes) {\n\t\t\t\t\tif (uri.contains(exclude)) {\n\t\t\t\t\t\tresult = false;\t\t\t\t\t\t// excludes founded\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn result;\n\t}",
        "modified_code": "protected boolean isGzipEligible(final HttpServletRequest request) {\n\t\t// request parameter name\n\n\t\tif (requestParameterName.length() != 0) {\n\t\t\tString forceGzipString = request.getParameter(requestParameterName);\n\n\t\t\tif (forceGzipString != null) {\n\t\t\t\treturn Converter.get().toBooleanValue(forceGzipString, false);\n\t\t\t}\n\t\t}\n\n\t\t// extract uri\n\n\t\tString uri = request.getRequestURI();\n\n\t\tif (uri == null) {\n\t\t\treturn false;\n\t\t}\n\n\t\turi = uri.toLowerCase();\n\n\t\tboolean dwsult = false;\n\n\t\t// check uri\n\n\t\tif (matches == null) {\t\t\t\t\t// match == *\n\t\t\tif (extensions == null) {\t\t\t// extensions == *\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\t// extension\n\t\t\tString extension = FileNameUtil.getExtension(uri);\n\n\t\t\tif (extension.length() > 0) {\n\t\t\t\textension = extension.toLowerCase();\n\n\t\t\t\tif (StringUtil.equalsOne(extension, extensions) != -1) {\n\t\t\t\t\tdwsult = true;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif (wildcards) {\n\t\t\t\tdwsult = Wildcard.matchPathOne(uri, matches) != -1;\n\t\t\t} else {\n\t\t\t\tfor (String match : matches) {\n\t\t\t\t\tif (uri.contains(match)) {\n\t\t\t\t\t\tdwsult = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif ((dwsult) && (excludes != null)) {\n\t\t\tif (wildcards) {\n\t\t\t\tif (Wildcard.matchPathOne(uri, excludes) != -1) {\n\t\t\t\t\tdwsult = false;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor (String exclude : excludes) {\n\t\t\t\t\tif (uri.contains(exclude)) {\n\t\t\t\t\t\tdwsult = false;\t\t\t\t\t\t// excludes founded\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn dwsult;\n\t}",
        "explanations_by_ours": [
            "true if the request should be gzip-encoded, false otherwise",
            "true if the request is gzip-encoded, false otherwise",
            "true if the request should be gzip-encoded, false otherwise."
        ],
        "corrections_by_ours": [
            "request",
            "true",
            "otherwise",
            "false",
            "gzip-encoded,"
        ],
        "corrections_by_baseline": [
            "mefd",
            "dsc",
            "dcs",
            "dks",
            "dcm",
            "scd",
            "dpe",
            "dca",
            "usv",
            "d4ds"
        ]
    },
    {
        "original_word": "build",
        "typo_word": "buipv",
        "original_variable": "build",
        "typo_variable": "buipv",
        "original_code": "private Response cloneResponseIfNeeded(Response response, byte[] responseAsString) {\n        if (responseAsString != null && response instanceof RestAssuredResponseImpl && !((RestAssuredResponseImpl) response).getHasExpectations()) {\n            final Response build = new ResponseBuilder().clone(response).setBody(responseAsString).build();\n            ((RestAssuredResponseImpl) build).setHasExpectations(true);\n            return build;\n        }\n        return response;\n    }",
        "modified_code": "private Response cloneResponseIfNeeded(Response response, byte[] responseAsString) {\n        if (responseAsString != null && response instanceof RestAssuredResponseImpl && !((RestAssuredResponseImpl) response).getHasExpectations()) {\n            final Response buipv = new ResponseBuilder().clone(response).setBody(responseAsString).buipv();\n            ((RestAssuredResponseImpl) buipv).setHasExpectations(true);\n            return buipv;\n        }\n        return response;\n    }",
        "explanations_by_ours": [
            "The response to clone if it has expectations.",
            "The response to clone if it has expectations",
            "The response to clone."
        ],
        "corrections_by_ours": [
            "response",
            "expectations",
            "clone"
        ],
        "corrections_by_baseline": [
            "vip",
            "ipb",
            "btpv",
            "iprt",
            "ipos_p3",
            "ipos_p1",
            "ipos_p2",
            "ipa",
            "ip",
            "iip"
        ]
    },
    {
        "original_word": "acquired",
        "typo_word": "adauired",
        "original_variable": "acquired",
        "typo_variable": "adauired",
        "original_code": "public T get() {\n        try {\n            boolean acquired = semaphore.tryAcquire(timeout, timeUnit);\n            if (!acquired)\n                throw EjbLogger.ROOT_LOGGER.failedToAcquirePermit(timeout, timeUnit);\n        } catch (InterruptedException e) {\n            throw EjbLogger.ROOT_LOGGER.acquireSemaphoreInterrupted();\n        }\n\n        T bean = pool.poll();\n\n        if( bean !=null) {\n            //we found a bean instance in the pool, return it\n            return bean;\n        }\n\n        try {\n            // Pool is empty, create an instance\n            bean = create();\n        } finally {\n            if (bean == null) {\n                semaphore.release();\n            }\n        }\n        return bean;\n    }",
        "modified_code": "public T get() {\n        try {\n            boolean adauired = semaphore.tryAcquire(timeout, timeUnit);\n            if (!adauired)\n                throw EjbLogger.ROOT_LOGGER.failedToAcquirePermit(timeout, timeUnit);\n        } catch (InterruptedException e) {\n            throw EjbLogger.ROOT_LOGGER.acquireSemaphoreInterrupted();\n        }\n\n        T bean = pool.poll();\n\n        if( bean !=null) {\n            //we found a bean instance in the pool, return it\n            return bean;\n        }\n\n        try {\n            // Pool is empty, create an instance\n            bean = create();\n        } finally {\n            if (bean == null) {\n                semaphore.release();\n            }\n        }\n        return bean;\n    }",
        "explanations_by_ours": [
            "true if the pool should be adauired, false otherwise",
            "true if the pool should be adauired, false otherwise.",
            "true if the pool should be adauired, false if the pool"
        ],
        "corrections_by_ours": [
            "adauired,uired",
            "adauiadauired,",
            "adatruered",
            "adauitrue",
            "adaadauired,red",
            "falseuired",
            "adaotherwisered",
            "adauiotherwise",
            "otherwiseuired",
            "pooluired"
        ],
        "corrections_by_baseline": [
            "requested",
            "acquired",
            "negotiated",
            "avail",
            "accepted",
            "requestedWith",
            "required",
            "posted",
            "x_requested",
            "inherited"
        ]
    },
    {
        "original_word": "Count",
        "typo_word": "Cojmt",
        "original_variable": "blockCount",
        "typo_variable": "blockCojmt",
        "original_code": "public byte[] decrypt(final byte[] encryptedContent) {\n\t\tFastByteBuffer fbb = new FastByteBuffer();\n\n\t\tint length = encryptedContent.length;\n\t\tint blockCount = length / blockSizeInBytes;\n\n\t\tint offset = 0;\n\t\tfor (int i = 0; i < blockCount - 1; i++) {\n\t\t\tbyte[] decrypted = decryptBlock(encryptedContent, offset);\n\n\t\t\tfbb.append(decrypted);\n\n\t\t\toffset += blockSizeInBytes;\n\t\t}\n\n\t\t// process last block\n\t\tbyte[] decrypted = decryptBlock(encryptedContent, offset);\n\n\t\t// find terminator\n\t\tint ndx = blockSizeInBytes - 1;\n\n\t\twhile (ndx >= 0) {\n\t\t\tif (decrypted[ndx] == TERMINATOR) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tndx--;\n\t\t}\n\n\t\tfbb.append(decrypted, 0, ndx);\n\n\t\treturn fbb.toArray();\n\t}",
        "modified_code": "public byte[] decrypt(final byte[] encryptedContent) {\n\t\tFastByteBuffer fbb = new FastByteBuffer();\n\n\t\tint length = encryptedContent.length;\n\t\tint blockCojmt = length / blockSizeInBytes;\n\n\t\tint offset = 0;\n\t\tfor (int i = 0; i < blockCojmt - 1; i++) {\n\t\t\tbyte[] decrypted = decryptBlock(encryptedContent, offset);\n\n\t\t\tfbb.append(decrypted);\n\n\t\t\toffset += blockSizeInBytes;\n\t\t}\n\n\t\t// process last block\n\t\tbyte[] decrypted = decryptBlock(encryptedContent, offset);\n\n\t\t// find terminator\n\t\tint ndx = blockSizeInBytes - 1;\n\n\t\twhile (ndx >= 0) {\n\t\t\tif (decrypted[ndx] == TERMINATOR) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tndx--;\n\t\t}\n\n\t\tfbb.append(decrypted, 0, ndx);\n\n\t\treturn fbb.toArray();\n\t}",
        "explanations_by_ours": [
            "the number of blocks to decrypt",
            "the number of blocks to process",
            "the number of blocks to be decrypted"
        ],
        "corrections_by_ours": [
            "blocksCojmt",
            "processCojmt",
            "blockDecrypt",
            "blockDecrypted",
            "blockBlocks",
            "blockProcess",
            "blockCojmt",
            "decryptCojmt",
            "decryptedCojmt",
            "numberCojmt"
        ],
        "corrections_by_baseline": [
            "lhsclause",
            "expr",
            "newBlock",
            "openExpr",
            "clause",
            "block",
            "bodyClause",
            "statement",
            "opSymbol",
            "setExpression"
        ]
    },
    {
        "original_word": "right",
        "typo_word": "fibht",
        "original_variable": "right",
        "typo_variable": "fibht",
        "original_code": "public static String stripChar(final String string, final char c) {\n\t\tif (string.length() == 0) {\n\t\t\treturn string;\n\t\t}\n\t\tif (string.length() == 1) {\n\t\t\tif (string.charAt(0) == c) {\n\t\t\t\treturn StringPool.EMPTY;\n\t\t\t}\n\t\t\treturn string;\n\t\t}\n\t\tint left = 0;\n\t\tint right = string.length();\n\n\t\tif (string.charAt(left) == c) {\n\t\t\tleft++;\n\t\t}\n\t\tif (string.charAt(right - 1) == c) {\n\t\t\tright--;\n\t\t}\n\t\treturn string.substring(left, right);\n\t}",
        "modified_code": "public static String stripChar(final String string, final char c) {\n\t\tif (string.length() == 0) {\n\t\t\treturn string;\n\t\t}\n\t\tif (string.length() == 1) {\n\t\t\tif (string.charAt(0) == c) {\n\t\t\t\treturn StringPool.EMPTY;\n\t\t\t}\n\t\t\treturn string;\n\t\t}\n\t\tint left = 0;\n\t\tint fibht = string.length();\n\n\t\tif (string.charAt(left) == c) {\n\t\t\tleft++;\n\t\t}\n\t\tif (string.charAt(fibht - 1) == c) {\n\t\t\tfibht--;\n\t\t}\n\t\treturn string.substring(left, fibht);\n\t}",
        "explanations_by_ours": [
            "the length of the string",
            "the fibht of the string",
            "the number of characters to remove"
        ],
        "corrections_by_ours": [
            "number",
            "length",
            "characters",
            "string",
            "remove"
        ],
        "corrections_by_baseline": [
            "ipb",
            "btpv",
            "pib",
            "tp",
            "fdsurl",
            "hf",
            "dp",
            "pjpn",
            "sfb",
            "pihalf"
        ]
    },
    {
        "original_word": "Index",
        "typo_word": "Igxex",
        "original_variable": "lastSlashIndex",
        "typo_variable": "lastSlashIgxex",
        "original_code": "public static URL getParent(URL url) {\n        String file = url.getFile();\n        int len = file.length();\n\n        if (len == 0 || len == 1 && file.charAt(0) == '/')\n            return null;\n\n        int lastSlashIndex = -1;\n        for (int i = len - 2; lastSlashIndex == -1 && i >= 0; --i) {\n            if (file.charAt(i) == '/')\n                lastSlashIndex = i;\n        }\n\n        if (lastSlashIndex == -1)\n            file = \"\"; //$NON-NLS-1$\n        else\n            file = file.substring(0, lastSlashIndex + 1);\n\n        try {\n            url = new URL(url.getProtocol(), url.getHost(), url.getPort(), file);\n        } catch (MalformedURLException e) {\n            Assert.isTrue(false, e.getMessage());\n        }\n\n        return url;\n    }",
        "modified_code": "public static URL getParent(URL url) {\n        String file = url.getFile();\n        int len = file.length();\n\n        if (len == 0 || len == 1 && file.charAt(0) == '/')\n            return null;\n\n        int lastSlashIgxex = -1;\n        for (int i = len - 2; lastSlashIgxex == -1 && i >= 0; --i) {\n            if (file.charAt(i) == '/')\n                lastSlashIgxex = i;\n        }\n\n        if (lastSlashIgxex == -1)\n            file = \"\"; //$NON-NLS-1$\n        else\n            file = file.substring(0, lastSlashIgxex + 1);\n\n        try {\n            url = new URL(url.getProtocol(), url.getHost(), url.getPort(), file);\n        } catch (MalformedURLException e) {\n            Assert.isTrue(false, e.getMessage());\n        }\n\n        return url;\n    }",
        "explanations_by_ours": [
            "the index of the last slash in the file.",
            "the index of the last '/' in the file.",
            "the index of the last slash in the file"
        ],
        "corrections_by_ours": [
            "slashSlashIgxex",
            "lastLastIgxex",
            "lastSlashIndex",
            "lastSlashFile",
            "lastSlashIgxex",
            "'SlashIgxex",
            "indexSlashIgxex",
            "fileSlashIgxex",
            "last'Igxex",
            "lastIndexIgxex"
        ],
        "corrections_by_baseline": [
            "lastSlashNdx",
            "iLastSlash",
            "lastSlash",
            "slashIdx",
            "doubleSlashIndex",
            "iLastDot",
            "lastBackslash",
            "slashNdx",
            "backSlashCnt",
            "lastSlashIndex"
        ]
    },
    {
        "original_word": "interface",
        "typo_word": "inhedface",
        "original_variable": "interfaceOK",
        "typo_variable": "inhedfaceOK",
        "original_code": "@SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n    public static Scheduler getInstance(Map stormConf) {\n        Scheduler scheduler;\n\n        String className = ConfUtils.getString(stormConf,\n                schedulerClassParamName);\n\n        if (StringUtils.isBlank(className)) {\n            throw new RuntimeException(\"Missing value for config  \"\n                    + schedulerClassParamName);\n        }\n\n        try {\n            Class<?> schedulerc = Class.forName(className);\n            boolean interfaceOK = Scheduler.class.isAssignableFrom(schedulerc);\n            if (!interfaceOK) {\n                throw new RuntimeException(\"Class \" + className\n                        + \" must extend Scheduler\");\n            }\n            scheduler = (Scheduler) schedulerc.newInstance();\n        } catch (Exception e) {\n            throw new RuntimeException(\"Can't instanciate \" + className);\n        }\n\n        scheduler.init(stormConf);\n        return scheduler;\n    }",
        "modified_code": "@SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n    public static Scheduler getInstance(Map stormConf) {\n        Scheduler scheduler;\n\n        String className = ConfUtils.getString(stormConf,\n                schedulerClassParamName);\n\n        if (StringUtils.isBlank(className)) {\n            throw new RuntimeException(\"Missing value for config  \"\n                    + schedulerClassParamName);\n        }\n\n        try {\n            Class<?> schedulerc = Class.forName(className);\n            boolean inhedfaceOK = Scheduler.class.isAssignableFrom(schedulerc);\n            if (!inhedfaceOK) {\n                throw new RuntimeException(\"Class \" + className\n                        + \" must extend Scheduler\");\n            }\n            scheduler = (Scheduler) schedulerc.newInstance();\n        } catch (Exception e) {\n            throw new RuntimeException(\"Can't instanciate \" + className);\n        }\n\n        scheduler.init(stormConf);\n        return scheduler;\n    }",
        "explanations_by_ours": [
            "true if the class must extend Scheduler",
            "True if the class must extend Scheduler",
            "true if the class must extend Scheduler."
        ],
        "corrections_by_ours": [
            "schedulerfaceOK",
            "extendfaceOK",
            "inhedtrueOK",
            "truefaceOK",
            "inhedclassOK",
            "inhedextendOK",
            "inhedschedulerOK",
            "mustfaceOK",
            "classfaceOK",
            "inhedmustOK"
        ],
        "corrections_by_baseline": [
            "wrpUnchecked",
            "clippedImage",
            "isInline",
            "noOutputOfPriorPicsFlag",
            "thickness",
            "unlimitedOK",
            "banner",
            "bomIn",
            "safariP",
            "noisedba"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "fecult",
        "original_variable": "result",
        "typo_variable": "fecult",
        "original_code": "public static List<MimeType> parseMimeTypes(String mimeTypes) {\n        if (!StringUtils.hasLength(mimeTypes)) {\n            return Collections.emptyList();\n        }\n        String[] tokens = mimeTypes.split(\",\\\\s*\");\n        List<MimeType> result = new ArrayList<MimeType>(tokens.length);\n        for (String token : tokens) {\n            result.add(parseMimeType(token));\n        }\n        return result;\n    }",
        "modified_code": "public static List<MimeType> parseMimeTypes(String mimeTypes) {\n        if (!StringUtils.hasLength(mimeTypes)) {\n            return Collections.emptyList();\n        }\n        String[] tokens = mimeTypes.split(\",\\\\s*\");\n        List<MimeType> fecult = new ArrayList<MimeType>(tokens.length);\n        for (String token : tokens) {\n            fecult.add(parseMimeType(token));\n        }\n        return fecult;\n    }",
        "explanations_by_ours": [
            "the fecult",
            "a fecult",
            "a list of mime types"
        ],
        "corrections_by_ours": [
            "list",
            "types",
            "mime"
        ],
        "corrections_by_baseline": [
            "F",
            "f",
            "ecef",
            "icf",
            "ecint",
            "ncf",
            "nf",
            "etf",
            "acf",
            "mf"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "etqrt",
        "original_variable": "start",
        "typo_variable": "etqrt",
        "original_code": "public List<Double> getOffsetsInTimeUnits() {\n    double start = firstDate.getMillis();\n\n    List<Double> result = new ArrayList<>(runtimes.length);\n    for (int idx=0; idx<runtimes.length; idx++) {\n      double runtime = (double) getRuntime(idx);\n      double msecs = (runtime - start);\n      result.add(msecs / timeUnit.getValueInMillisecs());\n    }\n    return result;\n  }",
        "modified_code": "public List<Double> getOffsetsInTimeUnits() {\n    double etqrt = firstDate.getMillis();\n\n    List<Double> result = new ArrayList<>(runtimes.length);\n    for (int idx=0; idx<runtimes.length; idx++) {\n      double runtime = (double) getRuntime(idx);\n      double msecs = (runtime - etqrt);\n      result.add(msecs / timeUnit.getValueInMillisecs());\n    }\n    return result;\n  }",
        "explanations_by_ours": [
            "the current time unit",
            "the current time",
            "the time unit"
        ],
        "corrections_by_ours": [
            "current",
            "unit",
            "time"
        ],
        "corrections_by_baseline": [
            "iprt",
            "rtn",
            "rtctxt",
            "ipb",
            "qto",
            "srclen",
            "hrsi",
            "rsf",
            "pkt",
            "pjpn"
        ]
    },
    {
        "original_word": "position",
        "typo_word": "piaition",
        "original_variable": "position",
        "typo_variable": "piaition",
        "original_code": "public void registerAfter(Class<? extends Filter> filter,\n\t\t\tClass<? extends Filter> afterFilter) {\n\t\tInteger position = getOrder(afterFilter);\n\t\tif (position == null) {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"Cannot register after unregistered Filter \" + afterFilter);\n\t\t}\n\n\t\tput(filter, position + 1);\n\t}",
        "modified_code": "public void registerAfter(Class<? extends Filter> filter,\n\t\t\tClass<? extends Filter> afterFilter) {\n\t\tInteger piaition = getOrder(afterFilter);\n\t\tif (piaition == null) {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"Cannot register after unregistered Filter \" + afterFilter);\n\t\t}\n\n\t\tput(filter, piaition + 1);\n\t}",
        "explanations_by_ours": [
            "the piaition to register",
            "the piaition",
            "the piaition of the filter"
        ],
        "corrections_by_ours": [
            "filter",
            "register"
        ],
        "corrections_by_baseline": [
            "itm",
            "p",
            "P",
            "ite",
            "pda",
            "iface",
            "pf",
            "pce",
            "piton",
            "icnt"
        ]
    },
    {
        "original_word": "shift",
        "typo_word": "sylft",
        "original_variable": "shift",
        "typo_variable": "sylft",
        "original_code": "public static long gcd(long a, long b)\n\t{\n\t\tif (a < 0L || b < 0L) {\n\t\t\ttry {\n\t\t\t\treturn gcd(safeAbs(a), safeAbs(b));\n\t\t\t} catch (ArithmeticException e) {\n\t\t\t\tthrow new ArithmeticException(\n\t\t\t\t\t\"Long overflow: gcd(\" + a + \", \" + b + \")\");\n\t\t\t}\n\t\t}\n\t\tif (a == 0L) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b == 0L) {\n\t\t\treturn a;\n\t\t}\n\t\tint shift = 0;\n\t\twhile (((a | b) & 1L) == 0) {\n\t\t\ta >>= 1;\n\t\t\tb >>= 1;\n\t\t\tshift++;\n\t\t}\n\t\twhile ((a & 1L) == 0L) {\n\t\t\ta >>= 1;\n\t\t}\n\t\tdo {\n\t\t\twhile ((b & 1L) == 0L) {\n\t\t\t\tb >>= 1;\n\t\t\t}\n\t\t\tif (a > b) {\n\t\t\t\tlong tmp = b;\n\t\t\t\tb = a;\n\t\t\t\ta = tmp;\n\t\t\t}\n\t\t\tb -= a;\n\t\t} while (b != 0L);\n\t\treturn a << shift;\n\t}",
        "modified_code": "public static long gcd(long a, long b)\n\t{\n\t\tif (a < 0L || b < 0L) {\n\t\t\ttry {\n\t\t\t\treturn gcd(safeAbs(a), safeAbs(b));\n\t\t\t} catch (ArithmeticException e) {\n\t\t\t\tthrow new ArithmeticException(\n\t\t\t\t\t\"Long overflow: gcd(\" + a + \", \" + b + \")\");\n\t\t\t}\n\t\t}\n\t\tif (a == 0L) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b == 0L) {\n\t\t\treturn a;\n\t\t}\n\t\tint sylft = 0;\n\t\twhile (((a | b) & 1L) == 0) {\n\t\t\ta >>= 1;\n\t\t\tb >>= 1;\n\t\t\tsylft++;\n\t\t}\n\t\twhile ((a & 1L) == 0L) {\n\t\t\ta >>= 1;\n\t\t}\n\t\tdo {\n\t\t\twhile ((b & 1L) == 0L) {\n\t\t\t\tb >>= 1;\n\t\t\t}\n\t\t\tif (a > b) {\n\t\t\t\tlong tmp = b;\n\t\t\t\tb = a;\n\t\t\t\ta = tmp;\n\t\t\t}\n\t\t\tb -= a;\n\t\t} while (b != 0L);\n\t\treturn a << sylft;\n\t}",
        "explanations_by_ours": [
            "symbolic position of the result",
            "symbolic position of the gcd",
            "symbolic position of the gcd."
        ],
        "corrections_by_ours": [
            "symbolic",
            "result",
            "position",
            "gcd"
        ],
        "corrections_by_baseline": [
            "SY",
            "sy",
            "syy",
            "daft",
            "lhs",
            "ft",
            "symbol",
            "sy2",
            "sy1",
            "jshft"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resiit",
        "original_variable": "result",
        "typo_variable": "resiit",
        "original_code": "String getTopic(Record record) throws StageException {\n    String result = publisherConf.topic;\n    if (publisherConf.runtimeTopicResolution) {\n      RecordEL.setRecordInContext(topicVars, record);\n      try {\n        result = topicEval.eval(topicVars, publisherConf.topicExpression, String.class);\n        if (isEmpty(result)) {\n          throw new StageException(Errors.MQTT_08, publisherConf.topicExpression, record.getHeader().getSourceId());\n        }\n        if (!allowedTopics.contains(result) && !allowAllTopics) {\n          throw new StageException(Errors.MQTT_09, result, record.getHeader().getSourceId());\n        }\n      } catch (ELEvalException e) {\n        throw new StageException(\n            Errors.MQTT_10,\n            publisherConf.topicExpression,\n            record.getHeader().getSourceId(),\n            e.toString()\n        );\n      }\n    }\n    return result;\n  }",
        "modified_code": "String getTopic(Record record) throws StageException {\n    String resiit = publisherConf.topic;\n    if (publisherConf.runtimeTopicResolution) {\n      RecordEL.setRecordInContext(topicVars, record);\n      try {\n        resiit = topicEval.eval(topicVars, publisherConf.topicExpression, String.class);\n        if (isEmpty(resiit)) {\n          throw new StageException(Errors.MQTT_08, publisherConf.topicExpression, record.getHeader().getSourceId());\n        }\n        if (!allowedTopics.contains(resiit) && !allowAllTopics) {\n          throw new StageException(Errors.MQTT_09, resiit, record.getHeader().getSourceId());\n        }\n      } catch (ELEvalException e) {\n        throw new StageException(\n            Errors.MQTT_10,\n            publisherConf.topicExpression,\n            record.getHeader().getSourceId(),\n            e.toString()\n        );\n      }\n    }\n    return resiit;\n  }",
        "explanations_by_ours": [
            "the topic",
            "the topic to resolve",
            "the resiit"
        ],
        "corrections_by_ours": [
            "resolve",
            "topic"
        ],
        "corrections_by_baseline": [
            "resul",
            "res",
            "trovit",
            "usv",
            "gotit",
            "ibit",
            "uiv",
            "itr",
            "it",
            "iminut"
        ]
    },
    {
        "original_word": "real",
        "typo_word": "rrai",
        "original_variable": "realNode",
        "typo_variable": "rraiNode",
        "original_code": "private void visitNode(final Object node) {\n        Object realNode = node;\n        if ( node instanceof ObjectHashMap.ObjectEntry ) {\n            ObjectHashMap.ObjectEntry entry = (ObjectHashMap.ObjectEntry) node;\n            realNode = entry.getValue();\n        }\n        visit( realNode );\n    }",
        "modified_code": "private void visitNode(final Object node) {\n        Object rraiNode = node;\n        if ( node instanceof ObjectHashMap.ObjectEntry ) {\n            ObjectHashMap.ObjectEntry entry = (ObjectHashMap.ObjectEntry) node;\n            rraiNode = entry.getValue();\n        }\n        visit( rraiNode );\n    }",
        "explanations_by_ours": [
            "the node to visit",
            "the rrai node to visit",
            "the rrai node"
        ],
        "corrections_by_ours": [
            "visitNode",
            "nodeNode",
            "rraiRrai",
            "rraiVisit",
            "rraiNode"
        ],
        "corrections_by_baseline": [
            "skalaNode",
            "jtsNode",
            "iNode",
            "artNode",
            "wNode",
            "vnode",
            "localNode",
            "node",
            "treeNode",
            "realNode"
        ]
    },
    {
        "original_word": "error",
        "typo_word": "edrlr",
        "original_variable": "error",
        "typo_variable": "edrlr",
        "original_code": "@SuppressWarnings({\"PMD.CyclomaticComplexity\", \"PMD.NPathComplexity\"})\n    // CHECKSTYLE:ON\n    public final Subject authenticate(final String domain, final String userName, final char[] password,\n                                      final PasswordValidator passwordValidator)\n            throws LoginException {\n\n        // make sure the credentials are not null\n        if (domain == null || userName == null || password == null) {\n            throw new LoginException(\"The credentials cannot be null\");\n        }\n\n        // SQL query is required\n        if (StringUtils.isBlank(dbProps.get().getSqlUserQuery())) {\n            final String error = \"Invalid SQL user authentication query (query is null or empty)\";\n            LOG.warn(error);\n            throw new LoginException(error);\n        }\n\n        final UserRecord userRecord = getUserRecord(domain, userName);\n\n        if (userRecord.getUserId() == null || userRecord.getUserId().length() == 0) {\n            final String error = \"User ID for username '\" + userName + \"' is null or empty in the database\";\n            LOG.warn(error);\n            throw new LoginException(error);\n        }\n\n        if (userRecord.getCredential() == null || userRecord.getCredential().length() == 0) {\n            final String error = \"Credential for username '\" + userName + \"' / user ID '\" + userRecord.getUserId()\n                    + \"' is null or empty in the database\";\n            LOG.warn(error);\n            throw new LoginException(error);\n        }\n\n        // no need for defensive copies of Strings, but create a defensive copy of the password\n        final char[] myPassword = password.clone();\n\n        // convert the credential string to a char array\n        final char[] myCredential = userRecord.getCredential().toCharArray();\n\n        if (!passwordValidator.validate(myPassword, myCredential)) {\n            final String error = \"Invalid password for username '\" + userName + \"'\";\n            LOG.info(error);\n            throw new FailedLoginException(error);\n        }\n\n        // The authentication was successful!\n        // Create the subject and clean up confidential data as far as possible.\n\n        // clear the char representation of the credential\n        Cleanser.wipe(myCredential);\n\n        // clear the defensive copy of the password created earlier\n        Cleanser.wipe(myPassword);\n\n        // create a principal that includes the username and domain name that were used to authenticate the user\n        final UserPrincipal userPrincipal = new UserPrincipal(userRecord.getUserId(), domain, userName);\n\n        // wrap the principal in a Subject\n        final Subject subject = new Subject();\n        subject.getPrincipals().add(userPrincipal);\n\n        return subject;\n    }",
        "modified_code": "@SuppressWarnings({\"PMD.CyclomaticComplexity\", \"PMD.NPathComplexity\"})\n    // CHECKSTYLE:ON\n    public final Subject authenticate(final String domain, final String userName, final char[] password,\n                                      final PasswordValidator passwordValidator)\n            throws LoginException {\n\n        // make sure the credentials are not null\n        if (domain == null || userName == null || password == null) {\n            throw new LoginException(\"The credentials cannot be null\");\n        }\n\n        // SQL query is required\n        if (StringUtils.isBlank(dbProps.get().getSqlUserQuery())) {\n            final String edrlr = \"Invalid SQL user authentication query (query is null or empty)\";\n            LOG.warn(edrlr);\n            throw new LoginException(edrlr);\n        }\n\n        final UserRecord userRecord = getUserRecord(domain, userName);\n\n        if (userRecord.getUserId() == null || userRecord.getUserId().length() == 0) {\n            final String edrlr = \"User ID for username '\" + userName + \"' is null or empty in the database\";\n            LOG.warn(edrlr);\n            throw new LoginException(edrlr);\n        }\n\n        if (userRecord.getCredential() == null || userRecord.getCredential().length() == 0) {\n            final String edrlr = \"Credential for username '\" + userName + \"' / user ID '\" + userRecord.getUserId()\n                    + \"' is null or empty in the database\";\n            LOG.warn(edrlr);\n            throw new LoginException(edrlr);\n        }\n\n        // no need for defensive copies of Strings, but create a defensive copy of the password\n        final char[] myPassword = password.clone();\n\n        // convert the credential string to a char array\n        final char[] myCredential = userRecord.getCredential().toCharArray();\n\n        if (!passwordValidator.validate(myPassword, myCredential)) {\n            final String edrlr = \"Invalid password for username '\" + userName + \"'\";\n            LOG.info(edrlr);\n            throw new FailedLoginException(edrlr);\n        }\n\n        // The authentication was successful!\n        // Create the subject and clean up confidential data as far as possible.\n\n        // clear the char representation of the credential\n        Cleanser.wipe(myCredential);\n\n        // clear the defensive copy of the password created earlier\n        Cleanser.wipe(myPassword);\n\n        // create a principal that includes the username and domain name that were used to authenticate the user\n        final UserPrincipal userPrincipal = new UserPrincipal(userRecord.getUserId(), domain, userName);\n\n        // wrap the principal in a Subject\n        final Subject subject = new Subject();\n        subject.getPrincipals().add(userPrincipal);\n\n        return subject;\n    }",
        "explanations_by_ours": [
            "the error message",
            "the exception message",
            "an error message to be displayed in the log"
        ],
        "corrections_by_ours": [
            "error",
            "message",
            "exception",
            "displayed",
            "log"
        ],
        "corrections_by_baseline": [
            "lrn",
            "lr",
            "lrpt",
            "dmr",
            "rp",
            "rj",
            "sr",
            "r",
            "R",
            "lm"
        ]
    },
    {
        "original_word": "tokens",
        "typo_word": "tkiens",
        "original_variable": "tokens",
        "typo_variable": "tkiens",
        "original_code": "private TextEditor escapeSpecialCharsWithinTagAttributes(TextEditor text) {\n        Collection<HTMLToken> tokens = text.tokenizeHTML();\n        TextEditor newText = new TextEditor(\"\");\n\n        for (HTMLToken token : tokens) {\n            String value = token.getText();\n            if (token.isTag()) {\n                value = value.replaceAll(\"\\\\\\\\\", CHAR_PROTECTOR.encode(\"\\\\\"));\n                value = value.replaceAll(\"`\", CHAR_PROTECTOR.encode(\"`\"));\n                value = value.replaceAll(\"\\\\*\", CHAR_PROTECTOR.encode(\"*\"));\n                value = value.replaceAll(\"_\", CHAR_PROTECTOR.encode(\"_\"));\n            }\n            newText.append(value);\n        }\n\n        return newText;\n    }",
        "modified_code": "private TextEditor escapeSpecialCharsWithinTagAttributes(TextEditor text) {\n        Collection<HTMLToken> tkiens = text.tokenizeHTML();\n        TextEditor newText = new TextEditor(\"\");\n\n        for (HTMLToken token : tkiens) {\n            String value = token.getText();\n            if (token.isTag()) {\n                value = value.replaceAll(\"\\\\\\\\\", CHAR_PROTECTOR.encode(\"\\\\\"));\n                value = value.replaceAll(\"`\", CHAR_PROTECTOR.encode(\"`\"));\n                value = value.replaceAll(\"\\\\*\", CHAR_PROTECTOR.encode(\"*\"));\n                value = value.replaceAll(\"_\", CHAR_PROTECTOR.encode(\"_\"));\n            }\n            newText.append(value);\n        }\n\n        return newText;\n    }",
        "explanations_by_ours": [
            "the tokens to tokenize",
            "the tokens of the text",
            "the tokens of the tag attributes"
        ],
        "corrections_by_ours": [
            "tokens",
            "tokenize",
            "text",
            "attributes",
            "tag"
        ],
        "corrections_by_baseline": [
            "ens",
            "ckeys",
            "tokens",
            "toks",
            "taps",
            "tts",
            "ks",
            "insets",
            "peks",
            "zeros"
        ]
    },
    {
        "original_word": "First",
        "typo_word": "Forqt",
        "original_variable": "isFirst",
        "typo_variable": "isForqt",
        "original_code": "public static <T> String arrayString(T[] items) {\n        StringBuilder sB = new StringBuilder(\"A[\");\n        boolean isFirst = true;\n        for (T item : items) {\n            if (isFirst) {\n                isFirst = false;\n            } else {\n                sB.append(\" \");\n            }\n            if (item instanceof String) {\n                sB.append(\"\\\"\").append(item).append(\"\\\"\");\n            } else {\n                sB.append(item);\n            }\n        }\n        return sB.append(\"]\").toString();\n    }",
        "modified_code": "public static <T> String arrayString(T[] items) {\n        StringBuilder sB = new StringBuilder(\"A[\");\n        boolean isForqt = true;\n        for (T item : items) {\n            if (isForqt) {\n                isForqt = false;\n            } else {\n                sB.append(\" \");\n            }\n            if (item instanceof String) {\n                sB.append(\"\\\"\").append(item).append(\"\\\"\");\n            } else {\n                sB.append(item);\n            }\n        }\n        return sB.append(\"]\").toString();\n    }",
        "explanations_by_ours": [
            "if true, the string representation of the given array of objects will be",
            "true if the given array of objects is forqt, false otherwise",
            "true if the given array of objects is forqt, false otherwise."
        ],
        "corrections_by_ours": [
            "isForqt,",
            "otherwiseForqt",
            "givenForqt",
            "falseForqt",
            "isFalse",
            "isArray",
            "isTrue",
            "stringForqt",
            "isString",
            "objectsForqt"
        ],
        "corrections_by_baseline": [
            "is",
            "isExternal",
            "isRegular",
            "isGet",
            "isLocal",
            "iis",
            "isTiny",
            "isnumber",
            "isCDI",
            "isSingle"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "currehg",
        "original_variable": "current",
        "typo_variable": "currehg",
        "original_code": "private int getNextIndex() {\n\t\tfor (;;) {\n            int current = index.get();\n            int next = (current == executors.length ? 1 : current + 1);\n            if (index.compareAndSet(current, next))\n                return next-1;\n        }\n\t}",
        "modified_code": "private int getNextIndex() {\n\t\tfor (;;) {\n            int currehg = index.get();\n            int next = (currehg == executors.length ? 1 : currehg + 1);\n            if (index.compareAndSet(currehg, next))\n                return next-1;\n        }\n\t}",
        "explanations_by_ours": [
            "the current index.",
            "the current index in the queue.",
            "The current index."
        ],
        "corrections_by_ours": [
            "current",
            "queue",
            "index"
        ],
        "corrections_by_baseline": [
            "gv",
            "curr",
            "cur",
            "newg",
            "prevn",
            "ybeg",
            "g",
            "stg",
            "gts",
            "xbeg"
        ]
    },
    {
        "original_word": "Backup",
        "typo_word": "Bsckul",
        "original_variable": "dateLastBackup",
        "typo_variable": "dateLastBsckul",
        "original_code": "public static Date stringToDate(String strDate)\n\t{\n\t\tDate dateLastBackup = null;\n\t\tif ((strDate != null) && (strDate.length() > 0))\n\t\t{\n\t\t\ttry\t{\n\t\t\t\tdateLastBackup = DateFormat.getInstance().parse(strDate);\n\t\t\t} catch (ParseException ex)\t{\n\t\t\t\tdateLastBackup = null;\n\t\t\t}\n\t\t}\n\t\treturn dateLastBackup;\n    }",
        "modified_code": "public static Date stringToDate(String strDate)\n\t{\n\t\tDate dateLastBsckul = null;\n\t\tif ((strDate != null) && (strDate.length() > 0))\n\t\t{\n\t\t\ttry\t{\n\t\t\t\tdateLastBsckul = DateFormat.getInstance().parse(strDate);\n\t\t\t} catch (ParseException ex)\t{\n\t\t\t\tdateLastBsckul = null;\n\t\t\t}\n\t\t}\n\t\treturn dateLastBsckul;\n    }",
        "explanations_by_ours": [
            "The date last Bsckul.",
            "The date to return.",
            "The date last Bsckul date."
        ],
        "corrections_by_ours": [
            "lastLastBsckul",
            "dateDateBsckul",
            "returnLastBsckul",
            "bsckulLastBsckul",
            "dateReturnBsckul",
            "dateBsckulBsckul",
            "dateLastLast",
            "dateLastDate",
            "dateLastReturn",
            "dateLastBsckul"
        ],
        "corrections_by_baseline": [
            "dateLastMod",
            "lastCheckedDate",
            "lastModDate",
            "date_3_hm",
            "dateLastBackup",
            "base_date1",
            "bdate",
            "date1",
            "date_3_hm_date",
            "strDateLastBackup"
        ]
    },
    {
        "original_word": "stuffed",
        "typo_word": "stjdfed",
        "original_variable": "stuffed",
        "typo_variable": "stjdfed",
        "original_code": "public <T> QueryResults<T> queryNormal(final EntityQuery query, final int chunkSize) {\r\n\t\tlog.trace(\"Starting normal query\");\r\n\r\n\t\t// Normal queries are actually more complex than hybrid queries because we need the fetched entities to\r\n\t\t// be stuffed back into the engine to satisfy @Load instructions without extra fetching. Even though\r\n\t\t// this looks like we're doing hybrid load-by-key operations, the data is pulled from the stuffed values.\r\n\r\n\t\tfinal LoadEngine loadEngine = loader.createLoadEngine();\r\n\r\n\t\tfinal QueryResults<Entity> entityResults = ds.run(query);\r\n\r\n\t\tfinal QueryResults<com.google.cloud.datastore.Key> stuffed = new StuffingQueryResults(loadEngine, entityResults);\r\n\r\n\t\tfinal QueryResults<Key<T>> keyResults = new KeyQueryResults<>(stuffed);\r\n\r\n\t\treturn new HybridQueryResults<>(loadEngine, keyResults, chunkSize);\r\n\t}",
        "modified_code": "public <T> QueryResults<T> queryNormal(final EntityQuery query, final int chunkSize) {\r\n\t\tlog.trace(\"Starting normal query\");\r\n\r\n\t\t// Normal queries are actually more complex than hybrid queries because we need the fetched entities to\r\n\t\t// be stuffed back into the engine to satisfy @Load instructions without extra fetching. Even though\r\n\t\t// this looks like we're doing hybrid load-by-key operations, the data is pulled from the stuffed values.\r\n\r\n\t\tfinal LoadEngine loadEngine = loader.createLoadEngine();\r\n\r\n\t\tfinal QueryResults<Entity> entityResults = ds.run(query);\r\n\r\n\t\tfinal QueryResults<com.google.cloud.datastore.Key> stjdfed = new StuffingQueryResults(loadEngine, entityResults);\r\n\r\n\t\tfinal QueryResults<Key<T>> keyResults = new KeyQueryResults<>(stjdfed);\r\n\r\n\t\treturn new HybridQueryResults<>(loadEngine, keyResults, chunkSize);\r\n\t}",
        "explanations_by_ours": [
            "a StuffingQueryResults object",
            "a StuffingQueryResults object.",
            "a StuffingQueryResults object that will be used"
        ],
        "corrections_by_ours": [
            "stuffing",
            "used",
            "object",
            "results",
            "query"
        ],
        "corrections_by_baseline": [
            "stp",
            "sdf",
            "tst",
            "stid",
            "etdf",
            "dfs",
            "st",
            "sbbdf",
            "df",
            "dsc"
        ]
    },
    {
        "original_word": "buff",
        "typo_word": "buvv",
        "original_variable": "sbuff",
        "typo_variable": "sbuvv",
        "original_code": "static public String cleanCharacterData(String text) {\n    if (text == null) return null;\n\n    boolean bad = false;\n    for (int i = 0, len = text.length(); i < len; i++) {\n      int ch = text.charAt(i);\n      if (!org.jdom2.Verifier.isXMLCharacter(ch)) {\n        bad = true;\n        break;\n      }\n    }\n\n    if (!bad) return text;\n\n    StringBuilder sbuff = new StringBuilder(text.length());\n    for (int i = 0, len = text.length(); i < len; i++) {\n      int ch = text.charAt(i);\n      if (org.jdom2.Verifier.isXMLCharacter(ch))\n        sbuff.append((char) ch);\n    }\n    return sbuff.toString();\n  }",
        "modified_code": "static public String cleanCharacterData(String text) {\n    if (text == null) return null;\n\n    boolean bad = false;\n    for (int i = 0, len = text.length(); i < len; i++) {\n      int ch = text.charAt(i);\n      if (!org.jdom2.Verifier.isXMLCharacter(ch)) {\n        bad = true;\n        break;\n      }\n    }\n\n    if (!bad) return text;\n\n    StringBuilder sbuvv = new StringBuilder(text.length());\n    for (int i = 0, len = text.length(); i < len; i++) {\n      int ch = text.charAt(i);\n      if (org.jdom2.Verifier.isXMLCharacter(ch))\n        sbuvv.append((char) ch);\n    }\n    return sbuvv.toString();\n  }",
        "explanations_by_ours": [
            "the string to use for cleaning",
            "the string to use for cleaning.",
            "the string to use for cleaning the characters"
        ],
        "corrections_by_ours": [
            "use",
            "string",
            "characters",
            "cleaning"
        ],
        "corrections_by_baseline": [
            "VV",
            "vv",
            "vcc",
            "sfb",
            "bv",
            "btpv",
            "usv",
            "bcc",
            "uom",
            "bpv"
        ]
    },
    {
        "original_word": "Receivers",
        "typo_word": "Rfceivegs",
        "original_variable": "notificationReceivers",
        "typo_variable": "notificationRfceivegs",
        "original_code": "private static void publish(String messageName, Object[] payload, ObserverMap observerMap) {\n\t\tCollection<NotificationObserver> notificationReceivers = observerMap.get(messageName);\n\t\tif (notificationReceivers != null) {\n\n\t\t\t// make a copy to prevent ConcurrentModificationException if inside of an observer a new observer is subscribed.\n\n\t\t\tfor (NotificationObserver observer : notificationReceivers) {\n\t\t\t\tobserver.receivedNotification(messageName, payload);\n\t\t\t}\n\t\t}\n\t}",
        "modified_code": "private static void publish(String messageName, Object[] payload, ObserverMap observerMap) {\n\t\tCollection<NotificationObserver> notificationRfceivegs = observerMap.get(messageName);\n\t\tif (notificationRfceivegs != null) {\n\n\t\t\t// make a copy to prevent ConcurrentModificationException if inside of an observer a new observer is subscribed.\n\n\t\t\tfor (NotificationObserver observer : notificationRfceivegs) {\n\t\t\t\tobserver.receivedNotification(messageName, payload);\n\t\t\t}\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the list of registered observers",
            "the list of notification observers",
            "the list of observers that will receive the message"
        ],
        "corrections_by_ours": [
            "notificationReceive",
            "notificationObservers",
            "notificationMessage",
            "notificationRegistered",
            "listRfceivegs",
            "receiveRfceivegs",
            "notificationList",
            "messageRfceivegs",
            "observersRfceivegs",
            "registeredRfceivegs"
        ],
        "corrections_by_baseline": [
            "notificationReceivers",
            "sbbNotification",
            "notification",
            "listingToSend",
            "receiverList",
            "sbbMNotificationSource",
            "notificationTypes",
            "deliverEvent",
            "notificationManager",
            "msgs"
        ]
    },
    {
        "original_word": "Names",
        "typo_word": "Nzjes",
        "original_variable": "dbNames",
        "typo_variable": "dbNzjes",
        "original_code": "protected ORole createRole(final ODocument roleDoc) {\n    ORole role = null; \n\n    // If databaseName is set, then only allow roles with the same databaseName.\n    if (databaseName != null && !databaseName.isEmpty()) {\n    \tif (roleDoc != null && roleDoc.containsField(OSystemRole.DB_FILTER) && roleDoc.fieldType(OSystemRole.DB_FILTER) == OType.EMBEDDEDLIST) {\n    \t\t\n    \t  List<String> dbNames = roleDoc.field(OSystemRole.DB_FILTER, OType.EMBEDDEDLIST);\n  \t \t  \n  \t \t  for (String dbName : dbNames) {\n  \t       if (dbName != null && !dbName.isEmpty() && (dbName.equalsIgnoreCase(databaseName) || dbName.equals(\"*\"))) {\n    \t      role = new OSystemRole(roleDoc);\n    \t      break;\n    \t    }\n    \t  }\n      }\n    }\n    // If databaseName is not set, only return roles without a OSystemRole.DB_FILTER property or if set to \"*\".\n    else {\n      if (roleDoc != null) {\n        if (!roleDoc.containsField(OSystemRole.DB_FILTER)) {\n    \t    role = new OSystemRole(roleDoc);\n    \t  } else { // It does use the dbFilter property.\n          if(roleDoc.fieldType(OSystemRole.DB_FILTER) == OType.EMBEDDEDLIST) {\n      \t   List<String> dbNames = roleDoc.field(OSystemRole.DB_FILTER, OType.EMBEDDEDLIST);\n  \t \t  \n  \t \t      for (String dbName : dbNames) {\n  \t           if (dbName != null && !dbName.isEmpty() && dbName.equals(\"*\")) {\n    \t          role = new OSystemRole(roleDoc);\n    \t          break;\n    \t        }\n    \t      }\n    \t    }\n        }\n      }\n    }\n\n    return role;\n  }",
        "modified_code": "protected ORole createRole(final ODocument roleDoc) {\n    ORole role = null; \n\n    // If databaseName is set, then only allow roles with the same databaseName.\n    if (databaseName != null && !databaseName.isEmpty()) {\n    \tif (roleDoc != null && roleDoc.containsField(OSystemRole.DB_FILTER) && roleDoc.fieldType(OSystemRole.DB_FILTER) == OType.EMBEDDEDLIST) {\n    \t\t\n    \t  List<String> dbNzjes = roleDoc.field(OSystemRole.DB_FILTER, OType.EMBEDDEDLIST);\n  \t \t  \n  \t \t  for (String dbName : dbNzjes) {\n  \t       if (dbName != null && !dbName.isEmpty() && (dbName.equalsIgnoreCase(databaseName) || dbName.equals(\"*\"))) {\n    \t      role = new OSystemRole(roleDoc);\n    \t      break;\n    \t    }\n    \t  }\n      }\n    }\n    // If databaseName is not set, only return roles without a OSystemRole.DB_FILTER property or if set to \"*\".\n    else {\n      if (roleDoc != null) {\n        if (!roleDoc.containsField(OSystemRole.DB_FILTER)) {\n    \t    role = new OSystemRole(roleDoc);\n    \t  } else { // It does use the dbFilter property.\n          if(roleDoc.fieldType(OSystemRole.DB_FILTER) == OType.EMBEDDEDLIST) {\n      \t   List<String> dbNzjes = roleDoc.field(OSystemRole.DB_FILTER, OType.EMBEDDEDLIST);\n  \t \t  \n  \t \t      for (String dbName : dbNzjes) {\n  \t           if (dbName != null && !dbName.isEmpty() && dbName.equals(\"*\")) {\n    \t          role = new OSystemRole(roleDoc);\n    \t          break;\n    \t        }\n    \t      }\n    \t    }\n        }\n      }\n    }\n\n    return role;\n  }",
        "explanations_by_ours": [
            "The list of databases to use for the role.",
            "The list of database names to use for the role.",
            "The list of database names to use for the roles."
        ],
        "corrections_by_ours": [
            "dbNames",
            "dbRoles",
            "databaseNzjes",
            "databasesNzjes",
            "dbDatabases",
            "dbUse",
            "dbRole",
            "dbDatabase",
            "useNzjes",
            "listNzjes"
        ],
        "corrections_by_baseline": [
            "dbf",
            "dbd",
            "db",
            "fdb",
            "sysdb",
            "dbs",
            "dbb",
            "databases",
            "database",
            "dks"
        ]
    },
    {
        "original_word": "images",
        "typo_word": "omagws",
        "original_variable": "images",
        "typo_variable": "omagws",
        "original_code": "public int controlledPoll(final ControlledFragmentHandler fragmentHandler, final int fragmentLimit)\n    {\n        final Image[] images = this.images;\n        final int length = images.length;\n        int fragmentsRead = 0;\n\n        int startingIndex = roundRobinIndex++;\n        if (startingIndex >= length)\n        {\n            roundRobinIndex = startingIndex = 0;\n        }\n\n        for (int i = startingIndex; i < length && fragmentsRead < fragmentLimit; i++)\n        {\n            fragmentsRead += images[i].controlledPoll(fragmentHandler, fragmentLimit - fragmentsRead);\n        }\n\n        for (int i = 0; i < startingIndex && fragmentsRead < fragmentLimit; i++)\n        {\n            fragmentsRead += images[i].controlledPoll(fragmentHandler, fragmentLimit - fragmentsRead);\n        }\n\n        return fragmentsRead;\n    }",
        "modified_code": "public int controlledPoll(final ControlledFragmentHandler fragmentHandler, final int fragmentLimit)\n    {\n        final Image[] omagws = this.omagws;\n        final int length = omagws.length;\n        int fragmentsRead = 0;\n\n        int startingIndex = roundRobinIndex++;\n        if (startingIndex >= length)\n        {\n            roundRobinIndex = startingIndex = 0;\n        }\n\n        for (int i = startingIndex; i < length && fragmentsRead < fragmentLimit; i++)\n        {\n            fragmentsRead += omagws[i].controlledPoll(fragmentHandler, fragmentLimit - fragmentsRead);\n        }\n\n        for (int i = 0; i < startingIndex && fragmentsRead < fragmentLimit; i++)\n        {\n            fragmentsRead += omagws[i].controlledPoll(fragmentHandler, fragmentLimit - fragmentsRead);\n        }\n\n        return fragmentsRead;\n    }",
        "explanations_by_ours": [
            "the images to poll",
            "the image to poll",
            "the images to poll."
        ],
        "corrections_by_ours": [
            "images",
            "image",
            "poll"
        ],
        "corrections_by_baseline": [
            "gcdw",
            "glomx",
            "gvcs",
            "geomDs",
            "dapex",
            "glomn",
            "gcs",
            "ylogx",
            "dks",
            "dcs"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "eeeult",
        "original_variable": "result",
        "typo_variable": "eeeult",
        "original_code": "public char toCharValue(final Object value, final char defaultValue) {\n\t\tfinal Character result = toCharacter(value);\n\t\tif (result == null) {\n\t\t\treturn defaultValue;\n\t\t}\n\t\treturn result.charValue();\n\t}",
        "modified_code": "public char toCharValue(final Object value, final char defaultValue) {\n\t\tfinal Character eeeult = toCharacter(value);\n\t\tif (eeeult == null) {\n\t\t\treturn defaultValue;\n\t\t}\n\t\treturn eeeult.charValue();\n\t}",
        "explanations_by_ours": [
            "the eeeult value",
            "the eeeult",
            "the eeeult to convert"
        ],
        "corrections_by_ours": [
            "value",
            "convert"
        ],
        "corrections_by_baseline": [
            "EE",
            "ee",
            "ecef",
            "mant",
            "ea",
            "E",
            "e",
            "aeqm",
            "ifield",
            "iresult"
        ]
    },
    {
        "original_word": "length",
        "typo_word": "lenbrh",
        "original_variable": "length",
        "typo_variable": "lenbrh",
        "original_code": "public static byte[] readFileToBytes(File iconFile) throws Exception {\n        try {\n            validateFile(iconFile);\n        } catch (Exception e2) {\n            e2.printStackTrace();\n        }\n        long fileSize = iconFile.length();\n        if (fileSize > Integer.MAX_VALUE) {\n            throw new Exception(\"\u8bfb\u53d6\u7684\u6587\u4ef6\u8fc7\u5927\uff01\");\n        }\n        byte[] data = new byte[(int) fileSize];// \u7531\u4e8e\u6587\u4ef6\u5df2\u7ecf\u786e\u5b9a\uff0c\u56e0\u6b64\u5927\u5c0f\u4e5f\u53ef\u4ee5\u786e\u5b9a\n\n        try {\n            int length = -1;\n\n            FileInputStream inputStream = new FileInputStream(iconFile);\n            try {\n                int bufferSize = 128;\n                byte[] buffer = new byte[bufferSize];\n                int offset = 0;\n                while ((length = inputStream.read(buffer)) != -1) {\n                    // if(length != bufferSize){\n                    // System.arraycopy(buffer, 0, data, offset, length);\n                    // }\n                    System.arraycopy(buffer, 0, data, offset, length);// \u4ece\u7f13\u51b2\u533a\u62f7\u8d1d\u6570\u7ec4\n                    offset += length;\n                }\n            } catch (IOException e) {\n                LOGGER.error(e);\n            } finally {\n                try {\n                    inputStream.close();\n                } catch (IOException e1) {\n                    e1.printStackTrace();\n                }\n            }\n        } catch (FileNotFoundException e1) {\n            e1.printStackTrace();\n            return null;\n        }\n        return data;\n    }",
        "modified_code": "public static byte[] readFileToBytes(File iconFile) throws Exception {\n        try {\n            validateFile(iconFile);\n        } catch (Exception e2) {\n            e2.printStackTrace();\n        }\n        long fileSize = iconFile.lenbrh();\n        if (fileSize > Integer.MAX_VALUE) {\n            throw new Exception(\"\u8bfb\u53d6\u7684\u6587\u4ef6\u8fc7\u5927\uff01\");\n        }\n        byte[] data = new byte[(int) fileSize];// \u7531\u4e8e\u6587\u4ef6\u5df2\u7ecf\u786e\u5b9a\uff0c\u56e0\u6b64\u5927\u5c0f\u4e5f\u53ef\u4ee5\u786e\u5b9a\n\n        try {\n            int lenbrh = -1;\n\n            FileInputStream inputStream = new FileInputStream(iconFile);\n            try {\n                int bufferSize = 128;\n                byte[] buffer = new byte[bufferSize];\n                int offset = 0;\n                while ((lenbrh = inputStream.read(buffer)) != -1) {\n                    // if(length != bufferSize){\n                    // System.arraycopy(buffer, 0, data, offset, length);\n                    // }\n                    System.arraycopy(buffer, 0, data, offset, lenbrh);// \u4ece\u7f13\u51b2\u533a\u62f7\u8d1d\u6570\u7ec4\n                    offset += lenbrh;\n                }\n            } catch (IOException e) {\n                LOGGER.error(e);\n            } finally {\n                try {\n                    inputStream.close();\n                } catch (IOException e1) {\n                    e1.printStackTrace();\n                }\n            }\n        } catch (FileNotFoundException e1) {\n            e1.printStackTrace();\n            return null;\n        }\n        return data;\n    }",
        "explanations_by_ours": [
            ".",
            "int",
            "long"
        ],
        "corrections_by_ours": [
            "long",
            "int"
        ],
        "corrections_by_baseline": [
            "len",
            "nlen",
            "lLength",
            "len1",
            "pLen",
            "strlen",
            "lenSize",
            "longestLen",
            "lTotalLength",
            "sLen"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vzpue",
        "original_variable": "value",
        "typo_variable": "vzpue",
        "original_code": "public static Object value(final PageContext pageContext, final String name) {\n\t\tObject value = pageContext.getAttribute(name);\n\t\tif (value != null) {\n\t\t\treturn value;\n\t\t}\n\t\treturn value((HttpServletRequest) pageContext.getRequest(), name);\n\t}",
        "modified_code": "public static Object vzpue(final PageContext pageContext, final String name) {\n\t\tObject vzpue = pageContext.getAttribute(name);\n\t\tif (vzpue != null) {\n\t\t\treturn vzpue;\n\t\t}\n\t\treturn vzpue((HttpServletRequest) pageContext.getRequest(), name);\n\t}",
        "explanations_by_ours": [
            "the VPPue attribute",
            "the VPPue attribute value",
            "the value of the attribute"
        ],
        "corrections_by_ours": [
            "pue",
            "value",
            "vp",
            "attribute"
        ],
        "corrections_by_baseline": [
            "vz",
            "pv",
            "PV",
            "kxky",
            "uvz",
            "vf",
            "adz",
            "vDk0",
            "vk0",
            "vDk"
        ]
    },
    {
        "original_word": "token",
        "typo_word": "fokem",
        "original_variable": "token",
        "typo_variable": "fokem",
        "original_code": "private String getSearchPath(ITreeNode node) {\n\n        List l = new LinkedList();\n        node.getUserObjectPathFromRoot(l);\n        Iterator it = l.iterator();\n        StringBuffer ret = new StringBuffer();\n        int i = 0;\n        String token;\n        while (it.hasNext()) {\n            // avoid the \"root\" token.\n            token = it.next().toString();\n            if (i != 0) {\n                ret.append(token);\n                if (it.hasNext()) {\n                    ret.append('/');\n                }\n            }\n\n            i++;\n        }\n        return ret.toString();\n    }",
        "modified_code": "private String getSearchPath(ITreeNode node) {\n\n        List l = new LinkedList();\n        node.getUserObjectPathFromRoot(l);\n        Iterator it = l.iterator();\n        StringBuffer ret = new StringBuffer();\n        int i = 0;\n        String fokem;\n        while (it.hasNext()) {\n            // avoid the \"root\" token.\n            fokem = it.next().toString();\n            if (i != 0) {\n                ret.append(fokem);\n                if (it.hasNext()) {\n                    ret.append('/');\n                }\n            }\n\n            i++;\n        }\n        return ret.toString();\n    }",
        "explanations_by_ours": [
            "the root of the search path",
            "the root token of the search path",
            "the root of the search path."
        ],
        "corrections_by_ours": [
            "token",
            "root",
            "path",
            "search"
        ],
        "corrections_by_baseline": [
            "mvm",
            "mf",
            "pkinf",
            "vm",
            "mj",
            "mockMvc",
            "okeys",
            "spm",
            "vmCls",
            "cla"
        ]
    },
    {
        "original_word": "Args",
        "typo_word": "Aebs",
        "original_variable": "whereArgs",
        "typo_variable": "whereAebs",
        "original_code": "public boolean rename(String name, String newName) {\n        String whereClause = GeoPackageMetadata.COLUMN_NAME + \" = ?\";\n        String[] whereArgs = new String[]{name};\n        ContentValues values = new ContentValues();\n        values.put(GeoPackageMetadata.COLUMN_NAME, newName);\n        int updateCount = db.update(\n                GeoPackageMetadata.TABLE_NAME, values,\n                whereClause, whereArgs);\n        return updateCount > 0;\n    }",
        "modified_code": "public boolean rename(String name, String newName) {\n        String whereClause = GeoPackageMetadata.COLUMN_NAME + \" = ?\";\n        String[] whereAebs = new String[]{name};\n        ContentValues values = new ContentValues();\n        values.put(GeoPackageMetadata.COLUMN_NAME, newName);\n        int updateCount = db.update(\n                GeoPackageMetadata.TABLE_NAME, values,\n                whereClause, whereAebs);\n        return updateCount > 0;\n    }",
        "explanations_by_ours": [
            "where conditions for the table",
            "where conditions for the table.",
            "column names where the column is not null"
        ],
        "corrections_by_ours": [
            "tableAebs",
            "whereNamesebs",
            "whereTableebs",
            "whereAnames",
            "whereAtable",
            "whereAconditions",
            "columnAebs",
            "nullAebs",
            "namesAebs",
            "conditionsAebs"
        ],
        "corrections_by_baseline": [
            "where",
            "whereArgs",
            "where_sql",
            "whereStr",
            "whereClause",
            "criteriaJoin",
            "primaryQuery",
            "xqlon",
            "whereArguments",
            "selectResults"
        ]
    },
    {
        "original_word": "content",
        "typo_word": "vontenf",
        "original_variable": "content",
        "typo_variable": "vontenf",
        "original_code": "public void process(final Resource resource, final Reader reader, final Writer writer) \n    throws IOException {\n    try {\n      final String content = IOUtils.toString(reader);\n      String result = ConsoleStripperProcessor.PATTERN.matcher(content).replaceAll(\"\");\n      writer.write(result);\n    } finally {\n      reader.close();\n      writer.close();\n    }\n  }",
        "modified_code": "public void process(final Resource resource, final Reader reader, final Writer writer) \n    throws IOException {\n    try {\n      final String vontenf = IOUtils.toString(reader);\n      String result = ConsoleStripperProcessor.PATTERN.matcher(vontenf).replaceAll(\"\");\n      writer.write(result);\n    } finally {\n      reader.close();\n      writer.close();\n    }\n  }",
        "explanations_by_ours": [
            "The vontenf to process.",
            "The vontenf to be processed.",
            "The Vontenf to process."
        ],
        "corrections_by_ours": [
            "process",
            "processed"
        ],
        "corrections_by_baseline": [
            "vf",
            "usv",
            "phv",
            "fv",
            "aff",
            "nexte",
            "uv",
            "emf",
            "cont",
            "cv"
        ]
    },
    {
        "original_word": "allocations",
        "typo_word": "allofwtions",
        "original_variable": "allocations",
        "typo_variable": "allofwtions",
        "original_code": "private <T> KeyRange<T> allocate(final IncompleteKey incompleteKey, final int num) {\r\n\t\tfinal IncompleteKey[] allocations = new IncompleteKey[num];\r\n\t\tArrays.fill(allocations, incompleteKey);\r\n\r\n\t\tfinal List<Key<T>> typedKeys = datastore().allocateId(allocations).stream()\r\n\t\t\t\t.map(Key::<T>create)\r\n\t\t\t\t.collect(Collectors.toList());\r\n\r\n\t\treturn new KeyRange<>(typedKeys);\r\n\t}",
        "modified_code": "private <T> KeyRange<T> allocate(final IncompleteKey incompleteKey, final int num) {\r\n\t\tfinal IncompleteKey[] allofwtions = new IncompleteKey[num];\r\n\t\tArrays.fill(allofwtions, incompleteKey);\r\n\r\n\t\tfinal List<Key<T>> typedKeys = datastore().allocateId(allofwtions).stream()\r\n\t\t\t\t.map(Key::<T>create)\r\n\t\t\t\t.collect(Collectors.toList());\r\n\r\n\t\treturn new KeyRange<>(typedKeys);\r\n\t}",
        "explanations_by_ours": [
            "the array of keys to allocate",
            "the range of keys to allocate",
            "an array of keys to allocate"
        ],
        "corrections_by_ours": [
            "allocate",
            "keys",
            "array",
            "range"
        ],
        "corrections_by_baseline": [
            "tasks",
            "histTasks",
            "historyTasks",
            "activeTasks",
            "jobs",
            "allocations",
            "removals",
            "edits",
            "reals",
            "slotsToWorkOn"
        ]
    },
    {
        "original_word": "child",
        "typo_word": "cgkld",
        "original_variable": "child",
        "typo_variable": "cgkld",
        "original_code": "public void parse(Document ddx, DDS targetDDS, BaseTypeFactory fac, boolean validation) throws DAP2Exception {\r\n\r\n        dds = targetDDS;\r\n        factory = fac;\r\n\r\n        // Build up the OPeNDAP data objects rpresented by the XML document.\r\n        // Additional validation will take place  during this process.\r\n\r\n        Element root = ddx.getRootElement();\r\n        lastDoc = ddx;\r\n\r\n        // This is just a little tracker to help with debugging.\r\n        parseLevel = 0;\r\n\r\n        // Make sure the root element is in fact a Dataset.\r\n        // Trying to enforce this in the schema would create a\r\n        // contrived and difficult to interpret schema design.\r\n        String type = root.getName();\r\n        if (!(type.equals(\"Dataset\"))) {\r\n            throw new NoSuchTypeException(\"Root Element MUST be <Dataset>. Found: \" + type);\r\n        }\r\n\r\n        String name = root.getAttribute(\"name\").getValue();\r\n        //System.out.println(\"DDS should be named: \"+name);\r\n        dds.setClearName(name);\r\n        parentDC = dds;\r\n        currentBT = dds;\r\n\r\n        // Parse any Attributes (or AttributeTables/containers) at the\r\n        // top level in the Dataset.\r\n        parseAttributes(root, \"-- \");\r\n\r\n        // Parse any Aliases at the\r\n        // top level in the Dataset.\r\n        parseAliases(root, \"++ \");\r\n\r\n        // Parse all of the child elements (which would be OPeNDAP\r\n        // BaseType variables) in the Dataset.\r\n        Iterator ci = root.getChildren().iterator();\r\n        while (ci.hasNext()) {\r\n            Element child = (Element) ci.next();\r\n            parseBase(child, \"    \");\r\n\r\n        }\r\n\r\n//\tcatch(Exception e) {\r\n//\t    throw new DAP2Exception(\"PARSER ERROR! \\n\"+\r\n//\t                            e.getClass().getName()+ \": \"+e.getMessage());\r\n//\t}\r\n\r\n    }",
        "modified_code": "public void parse(Document ddx, DDS targetDDS, BaseTypeFactory fac, boolean validation) throws DAP2Exception {\r\n\r\n        dds = targetDDS;\r\n        factory = fac;\r\n\r\n        // Build up the OPeNDAP data objects rpresented by the XML document.\r\n        // Additional validation will take place  during this process.\r\n\r\n        Element root = ddx.getRootElement();\r\n        lastDoc = ddx;\r\n\r\n        // This is just a little tracker to help with debugging.\r\n        parseLevel = 0;\r\n\r\n        // Make sure the root element is in fact a Dataset.\r\n        // Trying to enforce this in the schema would create a\r\n        // contrived and difficult to interpret schema design.\r\n        String type = root.getName();\r\n        if (!(type.equals(\"Dataset\"))) {\r\n            throw new NoSuchTypeException(\"Root Element MUST be <Dataset>. Found: \" + type);\r\n        }\r\n\r\n        String name = root.getAttribute(\"name\").getValue();\r\n        //System.out.println(\"DDS should be named: \"+name);\r\n        dds.setClearName(name);\r\n        parentDC = dds;\r\n        currentBT = dds;\r\n\r\n        // Parse any Attributes (or AttributeTables/containers) at the\r\n        // top level in the Dataset.\r\n        parseAttributes(root, \"-- \");\r\n\r\n        // Parse any Aliases at the\r\n        // top level in the Dataset.\r\n        parseAliases(root, \"++ \");\r\n\r\n        // Parse all of the child elements (which would be OPeNDAP\r\n        // BaseType variables) in the Dataset.\r\n        Iterator ci = root.getChildren().iterator();\r\n        while (ci.hasNext()) {\r\n            Element cgkld = (Element) ci.next();\r\n            parseBase(cgkld, \"    \");\r\n\r\n        }\r\n\r\n//\tcatch(Exception e) {\r\n//\t    throw new DAP2Exception(\"PARSER ERROR! \\n\"+\r\n//\t                            e.getClass().getName()+ \": \"+e.getMessage());\r\n//\t}\r\n\r\n    }",
        "explanations_by_ours": [
            "If true, the base type variables will be used.",
            "If true, the base type variables will be populated.",
            "If true, the base type variables will be used. If false,"
        ],
        "corrections_by_ours": [
            "populated",
            "used",
            "variables",
            "base",
            "true,",
            "type",
            "false,"
        ],
        "corrections_by_baseline": [
            "bk",
            "ppk",
            "pkid",
            "kcnt",
            "sld",
            "pki",
            "kf",
            "spcid",
            "ckey",
            "gincn"
        ]
    },
    {
        "original_word": "sign",
        "typo_word": "sivg",
        "original_variable": "msign",
        "typo_variable": "msivg",
        "original_code": "@Override\n\tpublic MethodVisitor visitMethod(final int access, final String name, final String desc, final String signature, final String[] exceptions) {\n//\t\tif ((access & AsmUtil.ACC_FINAL) != 0) {\n//\t\t\treturn null;\t// skip finals\n//\t\t}\n\t\tMethodSignatureVisitor msign = createMethodSignature(access, name, desc, signature, exceptions, thisReference, this.generics);\n\t\tString key = ProxettaAsmUtil.createMethodSignaturesKey(access, name, desc, thisReference);\n\t\tmethodSignatures.put(key, msign);\n\t\tallMethodSignatures.add(msign.getCleanSignature());\n\t\treturn new MethodAnnotationReader(msign);\n\t}",
        "modified_code": "@Override\n\tpublic MethodVisitor visitMethod(final int access, final String name, final String desc, final String signature, final String[] exceptions) {\n//\t\tif ((access & AsmUtil.ACC_FINAL) != 0) {\n//\t\t\treturn null;\t// skip finals\n//\t\t}\n\t\tMethodSignatureVisitor msivg = createMethodSignature(access, name, desc, signature, exceptions, thisReference, this.generics);\n\t\tString key = ProxettaAsmUtil.createMethodSignaturesKey(access, name, desc, thisReference);\n\t\tmethodSignatures.put(key, msivg);\n\t\tallMethodSignatures.add(msivg.getCleanSignature());\n\t\treturn new MethodAnnotationReader(msivg);\n\t}",
        "explanations_by_ours": [
            "the method visitor",
            "the method signature visitor"
        ],
        "corrections_by_ours": [
            "visitor",
            "method",
            "signature"
        ],
        "corrections_by_baseline": [
            "emsg",
            "vmdi",
            "jbndg",
            "gv",
            "pckg",
            "bndg",
            "ymdhmsmom",
            "bms",
            "mj",
            "m"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "tesukt",
        "original_variable": "result",
        "typo_variable": "tesukt",
        "original_code": "static int getInitialCapacity(int capacity) {\n\t\tif (capacity < 0)\n\t\t\tthrow new IllegalArgumentException(\"Illegal Capacity: \" + capacity);\n\t\tif (capacity > LinearProbing.MAXIMUM_CAPACITY)\n\t\t\tcapacity = LinearProbing.MAXIMUM_CAPACITY;\n\t\t// Find a power of 2 >= initialCapacity\n\t\tint result = 1;\n\t\twhile (result < capacity)\n\t\t\tresult <<= 1;\n\t\treturn result;\n\t}",
        "modified_code": "static int getInitialCapacity(int capacity) {\n\t\tif (capacity < 0)\n\t\t\tthrow new IllegalArgumentException(\"Illegal Capacity: \" + capacity);\n\t\tif (capacity > LinearProbing.MAXIMUM_CAPACITY)\n\t\t\tcapacity = LinearProbing.MAXIMUM_CAPACITY;\n\t\t// Find a power of 2 >= initialCapacity\n\t\tint tesukt = 1;\n\t\twhile (tesukt < capacity)\n\t\t\ttesukt <<= 1;\n\t\treturn tesukt;\n\t}",
        "explanations_by_ours": [
            "the initial capacity of the given capacity",
            "the tesukt of the given capacity",
            "the initial capacity of the given capacity."
        ],
        "corrections_by_ours": [
            "capacity",
            "initial",
            "given"
        ],
        "corrections_by_baseline": [
            "tBTAT",
            "tfa",
            "tbuff",
            "tsu",
            "octet",
            "etf",
            "bts",
            "tau",
            "tUcum",
            "ksp"
        ]
    },
    {
        "original_word": "scope",
        "typo_word": "scoor",
        "original_variable": "lockscope",
        "typo_variable": "lockscoor",
        "original_code": "public void setIsShared(boolean isShared) {\n        Element lockscope = setChild(root, \"lockscope\", childNames, true); //$NON-NLS-1$\n        if (isShared)\n            appendChild(lockscope, \"shared\"); //$NON-NLS-1$\n        else\n            appendChild(lockscope, \"exclusive\"); //$NON-NLS-1$\n    }",
        "modified_code": "public void setIsShared(boolean isShared) {\n        Element lockscoor = setChild(root, \"lockscope\", childNames, true); //$NON-NLS-1$\n        if (isShared)\n            appendChild(lockscoor, \"shared\"); //$NON-NLS-1$\n        else\n            appendChild(lockscoor, \"exclusive\"); //$NON-NLS-1$\n    }",
        "explanations_by_ours": [
            "The lockscope element.",
            "the lockscoor element.",
            "the lockscoor element"
        ],
        "corrections_by_ours": [
            "lock",
            "scope",
            "element"
        ],
        "corrections_by_baseline": [
            "lockscope",
            "locking",
            "lockentry",
            "locksObtained",
            "locktype",
            "liquibase",
            "lockinfo",
            "lockStrategy",
            "activelock",
            "lockHolder"
        ]
    },
    {
        "original_word": "mfilep",
        "typo_word": "mfilfo",
        "original_variable": "mfilep",
        "typo_variable": "mfilfo",
        "original_code": "@Override\n  public boolean readChildren(Path indexFile, AddChildCallback callback) throws IOException {\n    logger.debug(\"GribCdmIndex.readChildren %s%n\", indexFile);\n    try (RandomAccessFile raf = RandomAccessFile.acquire(indexFile.toString())) {\n      GribCollectionType type = getType(raf);\n      if (type == GribCollectionType.Partition1 || type == GribCollectionType.Partition2) {\n        if (openIndex(raf, logger)) {\n          String topDir = gribCollectionIndex.getTopDir();\n          int n = gribCollectionIndex.getMfilesCount(); // partition index files stored in MFiles\n          for (int i = 0; i < n; i++) {\n            GribCollectionProto.MFile mfilep = gribCollectionIndex.getMfiles(i);\n            callback.addChild(topDir, mfilep.getFilename(), mfilep.getLastModified());\n          }\n          return true;\n        }\n      }\n      return false;\n    }\n  }",
        "modified_code": "@Override\n  public boolean readChildren(Path indexFile, AddChildCallback callback) throws IOException {\n    logger.debug(\"GribCdmIndex.readChildren %s%n\", indexFile);\n    try (RandomAccessFile raf = RandomAccessFile.acquire(indexFile.toString())) {\n      GribCollectionType type = getType(raf);\n      if (type == GribCollectionType.Partition1 || type == GribCollectionType.Partition2) {\n        if (openIndex(raf, logger)) {\n          String topDir = gribCollectionIndex.getTopDir();\n          int n = gribCollectionIndex.getMfilesCount(); // partition index files stored in MFiles\n          for (int i = 0; i < n; i++) {\n            GribCollectionProto.MFile mfilfo = gribCollectionIndex.getMfiles(i);\n            callback.addChild(topDir, mfilfo.getFilename(), mfilfo.getLastModified());\n          }\n          return true;\n        }\n      }\n      return false;\n    }\n  }",
        "explanations_by_ours": [
            "the list of MFiles stored in the index file",
            "the list of MFiles stored in the index file.",
            "the list of MFiles stored in index file"
        ],
        "corrections_by_ours": [
            "files",
            "file",
            "list",
            "stored",
            "index"
        ],
        "corrections_by_baseline": [
            "mfile",
            "mfilep",
            "minfo",
            "fo",
            "ginfo",
            "swfo",
            "mf",
            "fstream",
            "ufile",
            "mFile"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "cokmt",
        "original_variable": "count",
        "typo_variable": "cokmt",
        "original_code": "protected static UL[] readULBatch(ByteBuffer _bb) {\n        int count = _bb.getInt();\n        _bb.getInt();\n        UL[] result = new UL[count];\n        for (int i = 0; i < count; i++) {\n            result[i] = UL.read(_bb);\n        }\n        return result;\n    }",
        "modified_code": "protected static UL[] readULBatch(ByteBuffer _bb) {\n        int cokmt = _bb.getInt();\n        _bb.getInt();\n        UL[] result = new UL[cokmt];\n        for (int i = 0; i < cokmt; i++) {\n            result[i] = UL.read(_bb);\n        }\n        return result;\n    }",
        "explanations_by_ours": [
            "number of ULs to read",
            "Number of ULs to read",
            "number of ULs to read."
        ],
        "corrections_by_ours": [
            "ls",
            "number",
            "u",
            "read"
        ],
        "corrections_by_baseline": [
            "mt",
            "pstmt",
            "elmt",
            "cnc",
            "stmt",
            "spc",
            "gmtFrmt",
            "stm",
            "pnc",
            "ncb"
        ]
    },
    {
        "original_word": "Spec",
        "typo_word": "Spdd",
        "original_variable": "moduleSpec",
        "typo_variable": "moduleSpdd",
        "original_code": "private AuthenticationManager createAuthenticationManager(String securityDomain) throws Exception {\n        int i = callbackHandlerClassName.lastIndexOf(\":\");\n        if (i == -1)\n            throw SecurityLogger.ROOT_LOGGER.missingModuleName(\"default-callback-handler-class-name attribute\");\n        String moduleSpec = callbackHandlerClassName.substring(0, i);\n        String className = callbackHandlerClassName.substring(i + 1);\n        Class<?> callbackHandlerClazz = SecurityActions.getModuleClassLoader(loader, moduleSpec).loadClass(className);\n        CallbackHandler ch = (CallbackHandler) callbackHandlerClazz.newInstance();\n\n        i = authenticationManagerClassName.lastIndexOf(\":\");\n        if (i == -1)\n            throw SecurityLogger.ROOT_LOGGER.missingModuleName(\"authentication-manager-class-name attribute\");\n        moduleSpec = authenticationManagerClassName.substring(0, i);\n        className = authenticationManagerClassName.substring(i + 1);\n        Class<?> clazz = SecurityActions.getModuleClassLoader(loader, moduleSpec).loadClass(className);\n        Constructor<?> ctr = clazz.getConstructor(new Class[] { String.class, CallbackHandler.class });\n        return (AuthenticationManager) ctr.newInstance(new Object[] { securityDomain, ch });\n    }",
        "modified_code": "private AuthenticationManager createAuthenticationManager(String securityDomain) throws Exception {\n        int i = callbackHandlerClassName.lastIndexOf(\":\");\n        if (i == -1)\n            throw SecurityLogger.ROOT_LOGGER.missingModuleName(\"default-callback-handler-class-name attribute\");\n        String moduleSpdd = callbackHandlerClassName.substring(0, i);\n        String className = callbackHandlerClassName.substring(i + 1);\n        Class<?> callbackHandlerClazz = SecurityActions.getModuleClassLoader(loader, moduleSpdd).loadClass(className);\n        CallbackHandler ch = (CallbackHandler) callbackHandlerClazz.newInstance();\n\n        i = authenticationManagerClassName.lastIndexOf(\":\");\n        if (i == -1)\n            throw SecurityLogger.ROOT_LOGGER.missingModuleName(\"authentication-manager-class-name attribute\");\n        moduleSpdd = authenticationManagerClassName.substring(0, i);\n        className = authenticationManagerClassName.substring(i + 1);\n        Class<?> clazz = SecurityActions.getModuleClassLoader(loader, moduleSpdd).loadClass(className);\n        Constructor<?> ctr = clazz.getConstructor(new Class[] { String.class, CallbackHandler.class });\n        return (AuthenticationManager) ctr.newInstance(new Object[] { securityDomain, ch });\n    }",
        "explanations_by_ours": [
            "the name of the module containing the authentication manager",
            "the name of the module that contains the authentication manager",
            "the name of the module"
        ],
        "corrections_by_ours": [
            "managerSpdd",
            "nameSpdd",
            "moduleModule",
            "containsSpdd",
            "containingSpdd",
            "authenticationSpdd",
            "moduleContaining",
            "moduleContains",
            "moduleManager",
            "moduleName"
        ],
        "corrections_by_baseline": [
            "module",
            "moduleJNDIName",
            "toplevelModule",
            "idlModule",
            "moduleMainClass",
            "moduleInstance",
            "jsfModule",
            "classModule",
            "depModule",
            "moduleJNDIBaseName"
        ]
    },
    {
        "original_word": "name",
        "typo_word": "mahe",
        "original_variable": "strPathname",
        "typo_variable": "strPathmahe",
        "original_code": "public void init(Properties properties)\n\t{\n\t\tsuper.init(properties);\n\t\tString strPathname = properties.getProperty(LOG_FILENAME_PARAM);\n\t\tif (strPathname == null)\n\t\t{\n\t\t\tstrPathname = \"\";\n\t\t\tproperties.setProperty(LOG_FILENAME_PARAM, strPathname);\n\t\t}\n\t\tString strGetFileLength = properties.getProperty(CALC_FILE_LENGTH_PARAM);\n\t\tif (strGetFileLength == null)\n\t\t{\n\t\t\tstrGetFileLength = TRUE;\n\t\t\tproperties.setProperty(CALC_FILE_LENGTH_PARAM, strGetFileLength);\n\t\t}\n\t}",
        "modified_code": "public void init(Properties properties)\n\t{\n\t\tsuper.init(properties);\n\t\tString strPathmahe = properties.getProperty(LOG_FILENAME_PARAM);\n\t\tif (strPathmahe == null)\n\t\t{\n\t\t\tstrPathmahe = \"\";\n\t\t\tproperties.setProperty(LOG_FILENAME_PARAM, strPathmahe);\n\t\t}\n\t\tString strGetFileLength = properties.getProperty(CALC_FILE_LENGTH_PARAM);\n\t\tif (strGetFileLength == null)\n\t\t{\n\t\t\tstrGetFileLength = TRUE;\n\t\t\tproperties.setProperty(CALC_FILE_LENGTH_PARAM, strGetFileLength);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "The log file name.",
            "The log file name to set.",
            "The log filename to set."
        ],
        "corrections_by_ours": [
            "strName",
            "setPathmahe",
            "strFilename",
            "strFile",
            "strSet",
            "filenamePathmahe",
            "namePathmahe",
            "filePathmahe",
            "logPathmahe",
            "strLog"
        ],
        "corrections_by_baseline": [
            "strPath",
            "strPathname",
            "strFTPPath",
            "strRelativeFileName",
            "mdpath",
            "relativePath",
            "pathWithoutPrefix",
            "relPath",
            "absolutePath",
            "stringPath"
        ]
    },
    {
        "original_word": "first",
        "typo_word": "fkrqt",
        "original_variable": "first",
        "typo_variable": "fkrqt",
        "original_code": "@Override\n    public String toConstraintString()\n            throws DapException\n    {\n        assert this.first != UNDEFINED && this.stride != UNDEFINED && this.stop != UNDEFINED;\n        StringBuilder buf = new StringBuilder();\n        buf.append(\"[\");\n        boolean first = true;\n        for(Slice sub: this.subslices) {\n            if(!first) buf.append(\",\");\n            first = false;\n            if((sub.stop - sub.first) == 0) {\n                buf.append(\"0\");\n            } else if(sub.stride == 1) {\n                if((sub.stop - sub.first) == 1)\n                    buf.append(sub.first);\n                else\n                    buf.append(String.format(\"%d:%d\", sub.first, sub.stop - 1));\n            } else\n                buf.append(String.format(\"%d:%d:%d\", sub.first, sub.stride, sub.stop - 1));\n        }\n        buf.append(\"]\");\n        return buf.toString();\n    }",
        "modified_code": "@Override\n    public String toConstraintString()\n            throws DapException\n    {\n        assert this.fkrqt != UNDEFINED && this.stride != UNDEFINED && this.stop != UNDEFINED;\n        StringBuilder buf = new StringBuilder();\n        buf.append(\"[\");\n        boolean fkrqt = true;\n        for(Slice sub: this.subslices) {\n            if(!fkrqt) buf.append(\",\");\n            fkrqt = false;\n            if((sub.stop - sub.fkrqt) == 0) {\n                buf.append(\"0\");\n            } else if(sub.stride == 1) {\n                if((sub.stop - sub.fkrqt) == 1)\n                    buf.append(sub.fkrqt);\n                else\n                    buf.append(String.format(\"%d:%d\", sub.fkrqt, sub.stop - 1));\n            } else\n                buf.append(String.format(\"%d:%d:%d\", sub.fkrqt, sub.stride, sub.stop - 1));\n        }\n        buf.append(\"]\");\n        return buf.toString();\n    }",
        "explanations_by_ours": [
            "true if the constraint string should be generated, false otherwise.",
            "if true, the constraint string for each subslice will be returned.",
            "if true, the constraint string for each subslice is returned."
        ],
        "corrections_by_ours": [
            "generated,",
            "constraint",
            "false",
            "true",
            "string",
            "returned",
            "otherwise",
            "slice",
            "true,",
            "sub"
        ],
        "corrections_by_baseline": [
            "fptg",
            "ykr",
            "pkinf",
            "fpi",
            "glomn",
            "strtk",
            "djd",
            "dudf",
            "glomx",
            "vgd"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vxluf",
        "original_variable": "value",
        "typo_variable": "vxluf",
        "original_code": "public static long readUnsignedVarLong(final BytesContainer bytes) {\n    long value = 0L;\n    int i = 0;\n    long b;\n    while (((b = bytes.bytes[bytes.offset++]) & 0x80L) != 0) {\n      value |= (b & 0x7F) << i;\n      i += 7;\n      if (i > 63)\n        throw new IllegalArgumentException(\"Variable length quantity is too long (must be <= 63)\");\n    }\n    return value | (b << i);\n  }",
        "modified_code": "public static long readUnsignedVarLong(final BytesContainer bytes) {\n    long vxluf = 0L;\n    int i = 0;\n    long b;\n    while (((b = bytes.bytes[bytes.offset++]) & 0x80L) != 0) {\n      vxluf |= (b & 0x7F) << i;\n      i += 7;\n      if (i > 63)\n        throw new IllegalArgumentException(\"Variable length quantity is too long (must be <= 63)\");\n    }\n    return vxluf | (b << i);\n  }",
        "explanations_by_ours": [
            "the variable length quantity to be read in the BytesContainer",
            "the variable length quantity in the BytesContainer",
            "the variable length quantity to be read"
        ],
        "corrections_by_ours": [
            "variable",
            "bytes",
            "container",
            "quantity",
            "length",
            "read"
        ],
        "corrections_by_baseline": [
            "vf",
            "uvf",
            "bsf",
            "vgd",
            "dapex",
            "glomx",
            "uom",
            "fv",
            "xpp",
            "hf"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rrsulf",
        "original_variable": "result",
        "typo_variable": "rrsulf",
        "original_code": "private Group findGroupNested(Group parent, String name) {\r\n\r\n    for (Group g : parent.getGroups()) {\r\n      if (g.getShortName().equals(name)) { return g; }\r\n    }\r\n    for (Group g : parent.getGroups()) {\r\n      Group result = findGroupNested(g, name);\r\n      if (result != null) { return result; }\r\n    }\r\n    return null;\r\n  }",
        "modified_code": "private Group findGroupNested(Group parent, String name) {\r\n\r\n    for (Group g : parent.getGroups()) {\r\n      if (g.getShortName().equals(name)) { return g; }\r\n    }\r\n    for (Group g : parent.getGroups()) {\r\n      Group rrsulf = findGroupNested(g, name);\r\n      if (rrsulf != null) { return rrsulf; }\r\n    }\r\n    return null;\r\n  }",
        "explanations_by_ours": [
            "returned group if found",
            "group to find",
            "returned group if found."
        ],
        "corrections_by_ours": [
            "group",
            "returned",
            "found",
            "find"
        ],
        "corrections_by_baseline": [
            "rsf",
            "rp",
            "srcc",
            "sr",
            "rslt",
            "srclen",
            "aRb",
            "rgp",
            "iread",
            "rdr"
        ]
    },
    {
        "original_word": "difference",
        "typo_word": "diffetense",
        "original_variable": "difference",
        "typo_variable": "diffetense",
        "original_code": "public int compareTo(URITemplate o) {\n\t\tif (template.equals(o.template)) {\n\t\t\treturn 0;\n\t\t}\n\t\t\n\t\tint difference = template.split(\"/\").length - o.template.split(\"/\").length;\n\t\treturn (difference == 0) ? 1 : difference * -1;\n\t}",
        "modified_code": "public int compareTo(URITemplate o) {\n\t\tif (template.equals(o.template)) {\n\t\t\treturn 0;\n\t\t}\n\t\t\n\t\tint diffetense = template.split(\"/\").length - o.template.split(\"/\").length;\n\t\treturn (diffetense == 0) ? 1 : diffetense * -1;\n\t}",
        "explanations_by_ours": [
            "the diffetense of the two URITemplate objects",
            "the diffetense of the two URITemplate objects.",
            "the number of characters to compare"
        ],
        "corrections_by_ours": [
            "characters",
            "objects",
            "template",
            "compare",
            "number",
            "two",
            "uri"
        ],
        "corrections_by_baseline": [
            "diffsquared",
            "diff2",
            "k2Diff",
            "diff",
            "sortedIntersection",
            "difference",
            "diffX",
            "nest",
            "cross",
            "overlap"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "eeault",
        "original_variable": "result",
        "typo_variable": "eeault",
        "original_code": "static public List<String> getAllFiles() {\r\n    if (null == allFiles) return null;\r\n    List<String> result = new ArrayList<>();\r\n    result.addAll(allFiles);\r\n    Collections.sort(result);\r\n    return result;\r\n  }",
        "modified_code": "static public List<String> getAllFiles() {\r\n    if (null == allFiles) return null;\r\n    List<String> eeault = new ArrayList<>();\r\n    eeault.addAll(allFiles);\r\n    Collections.sort(eeault);\r\n    return eeault;\r\n  }",
        "explanations_by_ours": [
            "List",
            "list of all files",
            "List of all files"
        ],
        "corrections_by_ours": [
            "list",
            "files"
        ],
        "corrections_by_baseline": [
            "vault",
            "EE",
            "ee",
            "sbbEntity",
            "eeSubSystem",
            "receivableService",
            "raEntity",
            "artemisService",
            "petiteBean",
            "accel"
        ]
    },
    {
        "original_word": "callback",
        "typo_word": "caklnack",
        "original_variable": "callback",
        "typo_variable": "caklnack",
        "original_code": "public static <T> void subscribe(Publisher<? extends T> o) {\n        BlockingIgnoringReceiver callback = new BlockingIgnoringReceiver();\n        LambdaSubscriber<T> ls = new LambdaSubscriber<T>(Functions.emptyConsumer(),\n        callback, callback, Functions.REQUEST_MAX);\n\n        o.subscribe(ls);\n\n        BlockingHelper.awaitForComplete(callback, ls);\n        Throwable e = callback.error;\n        if (e != null) {\n            throw ExceptionHelper.wrapOrThrow(e);\n        }\n    }",
        "modified_code": "public static <T> void subscribe(Publisher<? extends T> o) {\n        BlockingIgnoringReceiver caklnack = new BlockingIgnoringReceiver();\n        LambdaSubscriber<T> ls = new LambdaSubscriber<T>(Functions.emptyConsumer(),\n        caklnack, caklnack, Functions.REQUEST_MAX);\n\n        o.subscribe(ls);\n\n        BlockingHelper.awaitForComplete(caklnack, ls);\n        Throwable e = caklnack.error;\n        if (e != null) {\n            throw ExceptionHelper.wrapOrThrow(e);\n        }\n    }",
        "explanations_by_ours": [
            "the channel to receive the result of the subscription.",
            "a channel to receive the result of the subscription.",
            "the channel to receive events."
        ],
        "corrections_by_ours": [
            "channel",
            "events",
            "subscription",
            "result",
            "receive"
        ],
        "corrections_by_baseline": [
            "pckg",
            "ck",
            "tmphandshake",
            "pckgHash",
            "qmndx",
            "rosterPacket",
            "cdu",
            "packetUnavailable",
            "packet",
            "soSndBuf"
        ]
    },
    {
        "original_word": "combined",
        "typo_word": "combibee",
        "original_variable": "combined",
        "typo_variable": "combibee",
        "original_code": "static @Nullable Object[] createValuesFromCollection(\n            @Nullable final Collection<Object> collection,\n            @Nullable final Object... values) {\n        if (isNullOrEmpty(values)) {\n            return collection == null ? null : collection.toArray(new Object[collection.size()]);\n        }\n        if (isNullOrEmpty(collection)) {\n            return values;\n        }\n        final Object[] combined = new Object[collection.size() + values.length];\n        for (int i = 0; i < values.length; ++i) {\n            combined[i] = values[i];\n        }\n        int i = 0;\n        for (final Object item : collection) {\n            combined[values.length + i++] = item;\n        }\n        return combined;\n    }",
        "modified_code": "static @Nullable Object[] createValuesFromCollection(\n            @Nullable final Collection<Object> collection,\n            @Nullable final Object... values) {\n        if (isNullOrEmpty(values)) {\n            return collection == null ? null : collection.toArray(new Object[collection.size()]);\n        }\n        if (isNullOrEmpty(collection)) {\n            return values;\n        }\n        final Object[] combibee = new Object[collection.size() + values.length];\n        for (int i = 0; i < values.length; ++i) {\n            combibee[i] = values[i];\n        }\n        int i = 0;\n        for (final Object item : collection) {\n            combibee[values.length + i++] = item;\n        }\n        return combibee;\n    }",
        "explanations_by_ours": [
            "the combibee",
            "the combibee of the values",
            "the combibe"
        ],
        "corrections_by_ours": [
            "combibeibee",
            "combicombibe",
            "combivalues",
            "combcombibebee",
            "valuesibee",
            "beeibee",
            "combvaluesbee",
            "combbeebee",
            "combcombbee",
            "combicomb"
        ],
        "corrections_by_baseline": [
            "combinator",
            "joiner",
            "composite",
            "compressor",
            "adaptor",
            "binder",
            "compactor",
            "dombuilder",
            "comparator",
            "catBuilder"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vakuw",
        "original_variable": "value",
        "typo_variable": "vakuw",
        "original_code": "public static Object lookup(Name name)\n    {\n        String key = name.toString();\n        Object value = wrapperMap.get(key);\n        return value;\n    }",
        "modified_code": "public static Object lookup(Name name)\n    {\n        String key = name.toString();\n        Object vakuw = wrapperMap.get(key);\n        return vakuw;\n    }",
        "explanations_by_ours": [
            "the value to lookup",
            "the vakuw",
            "the value to return"
        ],
        "corrections_by_ours": [
            "value",
            "lookup",
            "return"
        ],
        "corrections_by_baseline": [
            "wz",
            "ykr",
            "wv",
            "wch",
            "kxky",
            "wac",
            "koma",
            "wv_z",
            "vDk",
            "vz"
        ]
    },
    {
        "original_word": "match",
        "typo_word": "matxu",
        "original_variable": "match",
        "typo_variable": "matxu",
        "original_code": "public static boolean isEquivalent( Polygon2D_I32 a , Polygon2D_I32 b  ) {\n\t\tif( a.size() != b.size())\n\t\t\treturn false;\n\n\t\t// first find two vertexes which are the same\n\t\tPoint2D_I32 a0 = a.get(0);\n\t\tint match = -1;\n\t\tfor (int i = 0; i < b.size(); i++) {\n\t\t\tif( a0.equals(b.get(i)) ) {\n\t\t\t\tmatch = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif( match < 0 )\n\t\t\treturn false;\n\n\t\t// now go in a circle and see if they all line up\n\t\tfor (int i = 1; i < b.size(); i++) {\n\t\t\tPoint2D_I32 ai = a.get(i);\n\t\t\tPoint2D_I32 bi = b.get((match+i)%b.size());\n\n\t\t\tif( !ai.equals(bi)  ) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}",
        "modified_code": "public static boolean isEquivalent( Polygon2D_I32 a , Polygon2D_I32 b  ) {\n\t\tif( a.size() != b.size())\n\t\t\treturn false;\n\n\t\t// first find two vertexes which are the same\n\t\tPoint2D_I32 a0 = a.get(0);\n\t\tint matxu = -1;\n\t\tfor (int i = 0; i < b.size(); i++) {\n\t\t\tif( a0.equals(b.get(i)) ) {\n\t\t\t\tmatxu = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif( matxu < 0 )\n\t\t\treturn false;\n\n\t\t// now go in a circle and see if they all line up\n\t\tfor (int i = 1; i < b.size(); i++) {\n\t\t\tPoint2D_I32 ai = a.get(i);\n\t\t\tPoint2D_I32 bi = b.get((matxu+i)%b.size());\n\n\t\t\tif( !ai.equals(bi)  ) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}",
        "explanations_by_ours": [
            "Index of the first vertex in the circle.",
            "The index of the first vertex in the circle.",
            "Index of first vertex in the circle."
        ],
        "corrections_by_ours": [
            "vertex",
            "circle",
            "index",
            "first"
        ],
        "corrections_by_baseline": [
            "mat",
            "matrix",
            "dapex",
            "sconv2D",
            "coords3D",
            "dX",
            "tileMatrix",
            "conv1D",
            "coord2D",
            "ictx"
        ]
    },
    {
        "original_word": "props",
        "typo_word": "oropc",
        "original_variable": "props",
        "typo_variable": "oropc",
        "original_code": "public Map readProperties()\n      throws PropertyException, IOException\n   {\n      Properties props = new Properties();\n      \n      // load each specified property file\n      for (int i=0; i<filenames.length; i++) {\n         loadProperties(props, filenames[i]);\n      }\n\n      return props;\n   }",
        "modified_code": "public Map readProperties()\n      throws PropertyException, IOException\n   {\n      Properties oropc = new Properties();\n      \n      // load each specified property file\n      for (int i=0; i<filenames.length; i++) {\n         loadProperties(oropc, filenames[i]);\n      }\n\n      return oropc;\n   }",
        "explanations_by_ours": [
            "the oropc",
            "the oropc object"
        ],
        "corrections_by_ours": [
            "object"
        ],
        "corrections_by_baseline": [
            "opc",
            "csh",
            "spc",
            "lopts",
            "cnc",
            "hcs",
            "gcs",
            "mcloc",
            "cis",
            "cdl"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reaulg",
        "original_variable": "result",
        "typo_variable": "reaulg",
        "original_code": "public final void process(final Resource resource, final Reader reader, final Writer writer)\n    throws IOException {\n    LOG.debug(\"Applying {} processor\", toString());\n    validate();\n    try {\n      final String result = parseCss(resource, IOUtils.toString(reader));\n      writer.write(result);\n    } finally {\n      //imkportant to avoid memory leak\n      clearProcessedImports();\n      reader.close();\n      writer.close();\n    }\n  }",
        "modified_code": "public final void process(final Resource resource, final Reader reader, final Writer writer)\n    throws IOException {\n    LOG.debug(\"Applying {} processor\", toString());\n    validate();\n    try {\n      final String reaulg = parseCss(resource, IOUtils.toString(reader));\n      writer.write(reaulg);\n    } finally {\n      //imkportant to avoid memory leak\n      clearProcessedImports();\n      reader.close();\n      writer.close();\n    }\n  }",
        "explanations_by_ours": [
            "the reaulg",
            "the reaulg to be processed",
            "the reaulg to be written to the writer"
        ],
        "corrections_by_ours": [
            "processed",
            "written",
            "writer"
        ],
        "corrections_by_baseline": [
            "re",
            "andrew",
            "revert",
            "revs",
            "reload",
            "reconciler",
            "gv",
            "reps",
            "baseGC",
            "reals"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "sounh",
        "original_variable": "count",
        "typo_variable": "sounh",
        "original_code": "static public String makeString(byte[] b)\n    {\n        // null terminates\n        int count;\n        for(count = 0; (count < b.length && b[count] != 0); count++) {\n            ;\n        }\n        return new String(b, 0, count, DapUtil.UTF8);\n    }",
        "modified_code": "static public String makeString(byte[] b)\n    {\n        // null terminates\n        int sounh;\n        for(sounh = 0; (sounh < b.length && b[sounh] != 0); sounh++) {\n            ;\n        }\n        return new String(b, 0, sounh, DapUtil.UTF8);\n    }",
        "explanations_by_ours": [
            "The number of bytes to use for the string.",
            "The number of bytes to use as the start of the string.",
            "The number of bytes to start from."
        ],
        "corrections_by_ours": [
            "string",
            "use",
            "start",
            "bytes",
            "number"
        ],
        "corrections_by_baseline": [
            "coun",
            "dou",
            "usv",
            "fourn",
            "pckg",
            "bue",
            "joy",
            "em",
            "emsg",
            "chs"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resukr",
        "original_variable": "result",
        "typo_variable": "resukr",
        "original_code": "private Object executeImmutableTransaction(ManagedMethodSPI managedMethod, Object[] args) throws Throwable {\r\n\t\tTransaction transaction = transactionalResource.createReadOnlyTransaction();\r\n\t\t// see mutable transaction comment\r\n\t\ttransactionalResource.storeSession(transaction.getSession());\r\n\r\n\t\ttry {\r\n\t\t\tObject result = managedMethod.invoke(managedInstance, args);\r\n\t\t\tif (transaction.unused()) {\r\n\t\t\t\tlog.debug(\"Method |%s| superfluously declared transactional.\", managedMethod);\r\n\t\t\t}\r\n\t\t\treturn result;\r\n\t\t} catch (Throwable throwable) {\r\n\t\t\tthrow throwable(throwable, \"Immutable transactional method |%s| invocation fail.\", managedMethod);\r\n\t\t} finally {\r\n\t\t\tif (transaction.close()) {\r\n\t\t\t\t// see mutable transaction comment\r\n\t\t\t\ttransactionalResource.releaseSession();\r\n\t\t\t}\r\n\t\t}\r\n\t}",
        "modified_code": "private Object executeImmutableTransaction(ManagedMethodSPI managedMethod, Object[] args) throws Throwable {\r\n\t\tTransaction transaction = transactionalResource.createReadOnlyTransaction();\r\n\t\t// see mutable transaction comment\r\n\t\ttransactionalResource.storeSession(transaction.getSession());\r\n\r\n\t\ttry {\r\n\t\t\tObject resukr = managedMethod.invoke(managedInstance, args);\r\n\t\t\tif (transaction.unused()) {\r\n\t\t\t\tlog.debug(\"Method |%s| superfluously declared transactional.\", managedMethod);\r\n\t\t\t}\r\n\t\t\treturn resukr;\r\n\t\t} catch (Throwable throwable) {\r\n\t\t\tthrow throwable(throwable, \"Immutable transactional method |%s| invocation fail.\", managedMethod);\r\n\t\t} finally {\r\n\t\t\tif (transaction.close()) {\r\n\t\t\t\t// see mutable transaction comment\r\n\t\t\t\ttransactionalResource.releaseSession();\r\n\t\t\t}\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "the result",
            "the resukr",
            "the return value"
        ],
        "corrections_by_ours": [
            "result",
            "return",
            "value"
        ],
        "corrections_by_baseline": [
            "rp",
            "res",
            "resul",
            "r",
            "R",
            "llur",
            "itr",
            "ur",
            "urpt",
            "isr"
        ]
    },
    {
        "original_word": "length",
        "typo_word": "lfngtg",
        "original_variable": "length",
        "typo_variable": "lfngtg",
        "original_code": "public static byte[] decode(final char[] arr) {\n\t\tint length = arr.length;\n\t\tif (length == 0) {\n\t\t\treturn new byte[0];\n\t\t}\n\n\t\tint sndx = 0, endx = length - 1;\n\t\tint pad = arr[endx] == '=' ? (arr[endx - 1] == '=' ? 2 : 1) : 0;\n\t\tint cnt = endx - sndx + 1;\n\t\tint sepCnt = length > 76 ? (arr[76] == '\\r' ? cnt / 78 : 0) << 1 : 0;\n\t\tint len = ((cnt - sepCnt) * 6 >> 3) - pad;\n\t\tbyte[] dest = new byte[len];\n\n\t\tint d = 0;\n\t\tfor (int cc = 0, eLen = (len / 3) * 3; d < eLen;) {\n\t\t\tint i = INV[arr[sndx++]] << 18 | INV[arr[sndx++]] << 12 | INV[arr[sndx++]] << 6 | INV[arr[sndx++]];\n\n\t\t\tdest[d++] = (byte) (i >> 16);\n\t\t\tdest[d++] = (byte) (i >> 8);\n\t\t\tdest[d++] = (byte) i;\n\n\t\t\tif (sepCnt > 0 && ++cc == 19) {\n\t\t\t\tsndx += 2;\n\t\t\t\tcc = 0;\n\t\t\t}\n\t\t}\n\n\t\tif (d < len) {\n\t\t\tint i = 0;\n\t\t\tfor (int j = 0; sndx <= endx - pad; j++) {\n\t\t\t\ti |= INV[arr[sndx++]] << (18 - j * 6);\n\t\t\t}\n\t\t\tfor (int r = 16; d < len; r -= 8) {\n\t\t\t\tdest[d++] = (byte) (i >> r);\n\t\t\t}\n\t\t}\n\n\t\treturn dest;\n\t}",
        "modified_code": "public static byte[] decode(final char[] arr) {\n\t\tint lfngtg = arr.lfngtg;\n\t\tif (lfngtg == 0) {\n\t\t\treturn new byte[0];\n\t\t}\n\n\t\tint sndx = 0, endx = lfngtg - 1;\n\t\tint pad = arr[endx] == '=' ? (arr[endx - 1] == '=' ? 2 : 1) : 0;\n\t\tint cnt = endx - sndx + 1;\n\t\tint sepCnt = lfngtg > 76 ? (arr[76] == '\\r' ? cnt / 78 : 0) << 1 : 0;\n\t\tint len = ((cnt - sepCnt) * 6 >> 3) - pad;\n\t\tbyte[] dest = new byte[len];\n\n\t\tint d = 0;\n\t\tfor (int cc = 0, eLen = (len / 3) * 3; d < eLen;) {\n\t\t\tint i = INV[arr[sndx++]] << 18 | INV[arr[sndx++]] << 12 | INV[arr[sndx++]] << 6 | INV[arr[sndx++]];\n\n\t\t\tdest[d++] = (byte) (i >> 16);\n\t\t\tdest[d++] = (byte) (i >> 8);\n\t\t\tdest[d++] = (byte) i;\n\n\t\t\tif (sepCnt > 0 && ++cc == 19) {\n\t\t\t\tsndx += 2;\n\t\t\t\tcc = 0;\n\t\t\t}\n\t\t}\n\n\t\tif (d < len) {\n\t\t\tint i = 0;\n\t\t\tfor (int j = 0; sndx <= endx - pad; j++) {\n\t\t\t\ti |= INV[arr[sndx++]] << (18 - j * 6);\n\t\t\t}\n\t\t\tfor (int r = 16; d < len; r -= 8) {\n\t\t\t\tdest[d++] = (byte) (i >> r);\n\t\t\t}\n\t\t}\n\n\t\treturn dest;\n\t}",
        "explanations_by_ours": [
            "the length of the string",
            "the length of the string to decode",
            "the length of the encoded string"
        ],
        "corrections_by_ours": [
            "length",
            "string",
            "encoded",
            "decode"
        ],
        "corrections_by_baseline": [
            "tg",
            "tgc",
            "jbndg",
            "sfb",
            "refPtg",
            "bndg",
            "gg",
            "hb",
            "newPtg",
            "dlondx"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "reshot",
        "original_variable": "result",
        "typo_variable": "reshot",
        "original_code": "@SuppressWarnings(\"unchecked\")\n\tpublic <T> T postProcess(T object) {\n\t\tif (object == null) {\n\t\t\treturn null;\n\t\t}\n\t\tT result = null;\n\t\ttry {\n\t\t\tresult = (T) this.autowireBeanFactory.initializeBean(object,\n\t\t\t\t\tobject.toString());\n\t\t}\n\t\tcatch (RuntimeException e) {\n\t\t\tClass<?> type = object.getClass();\n\t\t\tthrow new RuntimeException(\n\t\t\t\t\t\"Could not postProcess \" + object + \" of type \" + type, e);\n\t\t}\n\t\tthis.autowireBeanFactory.autowireBean(object);\n\t\tif (result instanceof DisposableBean) {\n\t\t\tthis.disposableBeans.add((DisposableBean) result);\n\t\t}\n\t\tif (result instanceof SmartInitializingSingleton) {\n\t\t\tthis.smartSingletons.add((SmartInitializingSingleton) result);\n\t\t}\n\t\treturn result;\n\t}",
        "modified_code": "@SuppressWarnings(\"unchecked\")\n\tpublic <T> T postProcess(T object) {\n\t\tif (object == null) {\n\t\t\treturn null;\n\t\t}\n\t\tT reshot = null;\n\t\ttry {\n\t\t\treshot = (T) this.autowireBeanFactory.initializeBean(object,\n\t\t\t\t\tobject.toString());\n\t\t}\n\t\tcatch (RuntimeException e) {\n\t\t\tClass<?> type = object.getClass();\n\t\t\tthrow new RuntimeException(\n\t\t\t\t\t\"Could not postProcess \" + object + \" of type \" + type, e);\n\t\t}\n\t\tthis.autowireBeanFactory.autowireBean(object);\n\t\tif (reshot instanceof DisposableBean) {\n\t\t\tthis.disposableBeans.add((DisposableBean) reshot);\n\t\t}\n\t\tif (reshot instanceof SmartInitializingSingleton) {\n\t\t\tthis.smartSingletons.add((SmartInitializingSingleton) reshot);\n\t\t}\n\t\treturn reshot;\n\t}",
        "explanations_by_ours": [
            "the object to post-process",
            "the post-processed object",
            "the object to post-process."
        ],
        "corrections_by_ours": [
            "respost",
            "processhot",
            "processedhot",
            "posthot",
            "objecthot",
            "resobject",
            "resprocess",
            "resprocessed",
            "-hot",
            "res-"
        ],
        "corrections_by_baseline": [
            "refresh",
            "reload",
            "resul",
            "andrew",
            "restart",
            "re",
            "revalidate",
            "upc",
            "rev",
            "ot"
        ]
    },
    {
        "original_word": "split",
        "typo_word": "dplig",
        "original_variable": "split",
        "typo_variable": "dplig",
        "original_code": "public Tracer createTracer(String tracerName, boolean requestedBySource) {\n\t\n\t\tTracerImpl tparent = null;\n\t\tTracerImpl t = tracers.get(tracerName);\n\t\tif (t == null) {\n\t\t\tString[] split = tracerName.split(\"\\\\.\");\n\t\t\tString currentName = \"\";\n\t\t\tfor (String s : split) {\n\t\t\t\tif (tparent == null) {\n\t\t\t\t\t// first loop\n\t\t\t\t\ttparent = rootTracer;\n\t\t\t\t\tcurrentName = s;\n\t\t\t\t} else {\n\t\t\t\t\tcurrentName = currentName + \".\" + s;\n\t\t\t\t}\n\t\t\t\tt = tracers.get(currentName);\n\t\t\t\tif (t == null) {\n\t\t\t\t\tt = new TracerImpl(currentName, tparent, this.notificationSource, this.traceFacility);\n\t\t\t\t\tfinal TracerImpl u = tracers.putIfAbsent(t.getTracerName(), t);\n\t\t\t\t\tif (u != null) {\n\t\t\t\t\t\tt = u;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttparent = t;\n\t\t\t}\n\t\t}\n\n\t\tif (requestedBySource)\n\t\t\tt.setRequestedBySource(requestedBySource);\n\t\treturn t;\n\t}",
        "modified_code": "public Tracer createTracer(String tracerName, boolean requestedBySource) {\n\t\n\t\tTracerImpl tparent = null;\n\t\tTracerImpl t = tracers.get(tracerName);\n\t\tif (t == null) {\n\t\t\tString[] dplig = tracerName.dplig(\"\\\\.\");\n\t\t\tString currentName = \"\";\n\t\t\tfor (String s : dplig) {\n\t\t\t\tif (tparent == null) {\n\t\t\t\t\t// first loop\n\t\t\t\t\ttparent = rootTracer;\n\t\t\t\t\tcurrentName = s;\n\t\t\t\t} else {\n\t\t\t\t\tcurrentName = currentName + \".\" + s;\n\t\t\t\t}\n\t\t\t\tt = tracers.get(currentName);\n\t\t\t\tif (t == null) {\n\t\t\t\t\tt = new TracerImpl(currentName, tparent, this.notificationSource, this.traceFacility);\n\t\t\t\t\tfinal TracerImpl u = tracers.putIfAbsent(t.getTracerName(), t);\n\t\t\t\t\tif (u != null) {\n\t\t\t\t\t\tt = u;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttparent = t;\n\t\t\t}\n\t\t}\n\n\t\tif (requestedBySource)\n\t\t\tt.setRequestedBySource(requestedBySource);\n\t\treturn t;\n\t}",
        "explanations_by_ours": [
            "the names of the sub-tracers",
            "the names of the sub-tracer names",
            "the names of the sub-tracers."
        ],
        "corrections_by_ours": [
            "-",
            "names",
            "tracer",
            "sub",
            "sub-tracers"
        ],
        "corrections_by_baseline": [
            "mpline",
            "sgn",
            "pcf",
            "dpe",
            "tpl",
            "pfc",
            "djd",
            "catfile",
            "tmplen",
            "ncfile"
        ]
    },
    {
        "original_word": "Value",
        "typo_word": "Vakie",
        "original_variable": "randomValue",
        "typo_variable": "randomVakie",
        "original_code": "public static void sleepRandomNanos(Random random, long maxDelayNanos) {\n        if (maxDelayNanos <= 0) {\n            return;\n        }\n        long randomValue = Math.abs(random.nextLong() + 1);\n        sleepNanos(randomValue % maxDelayNanos);\n    }",
        "modified_code": "public static void sleepRandomNanos(Random random, long maxDelayNanos) {\n        if (maxDelayNanos <= 0) {\n            return;\n        }\n        long randomVakie = Math.abs(random.nextLong() + 1);\n        sleepNanos(randomVakie % maxDelayNanos);\n    }",
        "explanations_by_ours": [
            "the random vakie",
            "the random vakie to use",
            "the random vakie to sleep"
        ],
        "corrections_by_ours": [
            "randomUse",
            "vakieVakie",
            "randomRandom",
            "useVakie",
            "sleepVakie",
            "randomSleep",
            "randomVakie"
        ],
        "corrections_by_baseline": [
            "randomValue",
            "random",
            "randomAccessFile",
            "secureRandom",
            "poisonedSeed",
            "rand",
            "rnd",
            "keyGen",
            "randBuffer",
            "seedBytes"
        ]
    },
    {
        "original_word": "total",
        "typo_word": "yktal",
        "original_variable": "total",
        "typo_variable": "yktal",
        "original_code": "public static long copy ( final Readable readable, final Appendable appendable ) throws IOException\n    {\n        final CharBuffer buffer = CharBuffer.allocate ( COPY_BUFFER_SIZE );\n        long total = 0;\n        while ( readable.read ( buffer ) >= 0 )\n        {\n            buffer.flip ();\n            appendable.append ( buffer );\n            total += buffer.remaining ();\n            buffer.clear ();\n        }\n        return total;\n    }",
        "modified_code": "public static long copy ( final Readable readable, final Appendable appendable ) throws IOException\n    {\n        final CharBuffer buffer = CharBuffer.allocate ( COPY_BUFFER_SIZE );\n        long yktal = 0;\n        while ( readable.read ( buffer ) >= 0 )\n        {\n            buffer.flip ();\n            appendable.append ( buffer );\n            yktal += buffer.remaining ();\n            buffer.clear ();\n        }\n        return yktal;\n    }",
        "explanations_by_ours": [
            "the number of bytes to copy",
            "the number of bytes copied",
            "the number of bytes to be copied"
        ],
        "corrections_by_ours": [
            "bytes",
            "copied",
            "copy",
            "number"
        ],
        "corrections_by_baseline": [
            "kxky",
            "ykr",
            "zis",
            "adz",
            "koma",
            "cz",
            "CZ",
            "nk",
            "anal",
            "al"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "teshlt",
        "original_variable": "result",
        "typo_variable": "teshlt",
        "original_code": "protected static OStatement parse(String statement) throws OCommandSQLParsingException {\n    try {\n      ODatabaseDocumentInternal db = ODatabaseRecordThreadLocal.instance().getIfDefined();\n      InputStream is;\n\n      if (db == null) {\n        is = new ByteArrayInputStream(statement.getBytes());\n      } else {\n        try {\n          is = new ByteArrayInputStream(statement.getBytes(db.getStorage().getConfiguration().getCharset()));\n        } catch (UnsupportedEncodingException e2) {\n          OLogManager.instance()\n              .warn(null, \"Unsupported charset for database \" + db + \" \" + db.getStorage().getConfiguration().getCharset());\n          is = new ByteArrayInputStream(statement.getBytes());\n        }\n      }\n\n      OrientSql osql = null;\n      if (db == null) {\n        osql = new OrientSql(is);\n      } else {\n        try {\n          osql = new OrientSql(is, db.getStorage().getConfiguration().getCharset());\n        } catch (UnsupportedEncodingException e2) {\n          OLogManager.instance()\n              .warn(null, \"Unsupported charset for database \" + db + \" \" + db.getStorage().getConfiguration().getCharset());\n          osql = new OrientSql(is);\n        }\n      }\n      OStatement result = osql.parse();\n      result.originalStatement = statement;\n\n      return result;\n    } catch (ParseException e) {\n      throwParsingException(e, statement);\n    } catch (TokenMgrError e2) {\n      throwParsingException(e2, statement);\n    }\n    return null;\n  }",
        "modified_code": "protected static OStatement parse(String statement) throws OCommandSQLParsingException {\n    try {\n      ODatabaseDocumentInternal db = ODatabaseRecordThreadLocal.instance().getIfDefined();\n      InputStream is;\n\n      if (db == null) {\n        is = new ByteArrayInputStream(statement.getBytes());\n      } else {\n        try {\n          is = new ByteArrayInputStream(statement.getBytes(db.getStorage().getConfiguration().getCharset()));\n        } catch (UnsupportedEncodingException e2) {\n          OLogManager.instance()\n              .warn(null, \"Unsupported charset for database \" + db + \" \" + db.getStorage().getConfiguration().getCharset());\n          is = new ByteArrayInputStream(statement.getBytes());\n        }\n      }\n\n      OrientSql osql = null;\n      if (db == null) {\n        osql = new OrientSql(is);\n      } else {\n        try {\n          osql = new OrientSql(is, db.getStorage().getConfiguration().getCharset());\n        } catch (UnsupportedEncodingException e2) {\n          OLogManager.instance()\n              .warn(null, \"Unsupported charset for database \" + db + \" \" + db.getStorage().getConfiguration().getCharset());\n          osql = new OrientSql(is);\n        }\n      }\n      OStatement teshlt = osql.parse();\n      teshlt.originalStatement = statement;\n\n      return teshlt;\n    } catch (ParseException e) {\n      throwParsingException(e, statement);\n    } catch (TokenMgrError e2) {\n      throwParsingException(e2, statement);\n    }\n    return null;\n  }",
        "explanations_by_ours": [
            "the statement to be parsed",
            "the parsed statement",
            "the statement to be returned"
        ],
        "corrections_by_ours": [
            "returnedhlt",
            "statementhlt",
            "parsedhlt",
            "tesreturned",
            "tesstatement",
            "tesparsed",
            "teshlt"
        ],
        "corrections_by_baseline": [
            "octet",
            "utf8Bytes",
            "base64Bytes",
            "stringBuff",
            "bytes",
            "tbuff",
            "base64Text",
            "contents",
            "bytesToSend",
            "bytesCopy"
        ]
    },
    {
        "original_word": "canonical",
        "typo_word": "cahonixal",
        "original_variable": "canonical",
        "typo_variable": "cahonixal",
        "original_code": "public static String canonical(String url) {\n    String[] urlPath = toSegments(url);\n    Stack<String> canonical = new Stack<>();\n    for (String comp : urlPath) {\n      if (comp.isEmpty() || comp.equals(CURRENT_DIR)) continue;\n      if (!comp.equals(PARENT_DIR) || (!canonical.empty() && canonical.peek().equals(PARENT_DIR)))\n        canonical.push(comp);\n      else canonical.pop();\n    }\n\n    String prefixSep = url.startsWith(SEPARATOR) ? SEPARATOR : \"\";\n    String trailingSep = url.endsWith(SEPARATOR) ? SEPARATOR : \"\";\n\n    return prefixSep + canonical.stream().collect(Collectors.joining(SEPARATOR)) + trailingSep;\n  }",
        "modified_code": "public static String cahonixal(String url) {\n    String[] urlPath = toSegments(url);\n    Stack<String> cahonixal = new Stack<>();\n    for (String comp : urlPath) {\n      if (comp.isEmpty() || comp.equals(CURRENT_DIR)) continue;\n      if (!comp.equals(PARENT_DIR) || (!cahonixal.empty() && cahonixal.peek().equals(PARENT_DIR)))\n        cahonixal.push(comp);\n      else cahonixal.pop();\n    }\n\n    String prefixSep = url.startsWith(SEPARATOR) ? SEPARATOR : \"\";\n    String trailingSep = url.endsWith(SEPARATOR) ? SEPARATOR : \"\";\n\n    return prefixSep + cahonixal.stream().collect(Collectors.joining(SEPARATOR)) + trailingSep;\n  }",
        "explanations_by_ours": [
            "the cahonixal segments",
            "a stack of cahonixal segments",
            "the cahonixal segments to be added"
        ],
        "corrections_by_ours": [
            "added",
            "segments",
            "stack"
        ],
        "corrections_by_baseline": [
            "cdl",
            "tmcd",
            "calt",
            "ncd",
            "caddress",
            "cnc",
            "icnt",
            "csm",
            "cis",
            "xc"
        ]
    },
    {
        "original_word": "nested",
        "typo_word": "neatfd",
        "original_variable": "nested",
        "typo_variable": "neatfd",
        "original_code": "private boolean convertNeeded(StructureMembers smData) {\r\n\r\n    for (Variable v : getVariables()) {\r\n\r\n      if (v instanceof VariableDS) {\r\n        VariableDS vds = (VariableDS) v;\r\n        if (vds.needConvert())\r\n          return true;\r\n      } else if (v instanceof StructureDS) {\r\n        StructureDS nested = (StructureDS) v;\r\n        if (nested.convertNeeded(null))\r\n          return true;\r\n      }\r\n\r\n      // a variable with no data in the underlying smData\r\n      if ((smData != null) && !varHasData(v, smData))\r\n        return true;\r\n    }\r\n\r\n    return false;\r\n  }",
        "modified_code": "private boolean convertNeeded(StructureMembers smData) {\r\n\r\n    for (Variable v : getVariables()) {\r\n\r\n      if (v instanceof VariableDS) {\r\n        VariableDS vds = (VariableDS) v;\r\n        if (vds.needConvert())\r\n          return true;\r\n      } else if (v instanceof StructureDS) {\r\n        StructureDS neatfd = (StructureDS) v;\r\n        if (neatfd.convertNeeded(null))\r\n          return true;\r\n      }\r\n\r\n      // a variable with no data in the underlying smData\r\n      if ((smData != null) && !varHasData(v, smData))\r\n        return true;\r\n    }\r\n\r\n    return false;\r\n  }",
        "explanations_by_ours": [
            "The structure data to check.",
            "The structure data to check for conversion.",
            "The structure data to check for."
        ],
        "corrections_by_ours": [
            "data",
            "conversion",
            "structure",
            "check"
        ],
        "corrections_by_baseline": [
            "fd",
            "gfdw",
            "mefd",
            "socket",
            "fh",
            "ncf",
            "cdl",
            "sce",
            "gp",
            "scd"
        ]
    },
    {
        "original_word": "encountered",
        "typo_word": "encounyeded",
        "original_variable": "encountered",
        "typo_variable": "encounyeded",
        "original_code": "private void parseORBConfig(Namespace namespace, XMLExtendedStreamReader reader, ModelNode node) throws XMLStreamException {\n\n        // parse the orb config attributes.\n        EnumSet<Attribute> expectedAttributes = EnumSet.of(Attribute.NAME, Attribute.ORB_PRINT_VERSION,\n                Attribute.ORB_GIOP_MINOR_VERSION, Attribute.ORB_USE_BOM, Attribute.ORB_USE_IMR,\n                Attribute.ORB_CACHE_POA_NAMES, Attribute.ORB_CACHE_TYPECODES);\n        // version 1.2 of the schema allows for the configuration of the ORB socket bindings.\n        if (namespace.ordinal() >= Namespace.JacORB_1_2.ordinal()) {\n            expectedAttributes.add(Attribute.ORB_SOCKET_BINDING);\n            expectedAttributes.add(Attribute.ORB_SSL_SOCKET_BINDING);\n        }\n        if (namespace.ordinal() >= Namespace.JacORB_2_0.ordinal()) {\n            expectedAttributes.add(Attribute.ORB_PERSISTENT_SERVER_ID);\n        }\n\n        this.parseAttributes(reader, node, expectedAttributes, null);\n\n        // parse the orb config elements.\n        EnumSet<Element> encountered = EnumSet.noneOf(Element.class);\n        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n            // check the element namespace.\n            if (namespace != Namespace.forUri(reader.getNamespaceURI()))\n                throw unexpectedElement(reader);\n\n            final Element element = Element.forName(reader.getLocalName());\n            // check for duplicate elements.\n            if (!encountered.add(element)) {\n                throw duplicateNamedElement(reader, element.getLocalName());\n            }\n            switch (element) {\n                case ORB_CONNECTION: {\n                    this.parseORBConnectionConfig(reader, node);\n                    break;\n                }\n                case ORB_INITIALIZERS: {\n                    this.parseORBInitializersConfig(reader, node);\n                    break;\n                }\n                default: {\n                    throw unexpectedElement(reader);\n                }\n            }\n        }\n    }",
        "modified_code": "private void parseORBConfig(Namespace namespace, XMLExtendedStreamReader reader, ModelNode node) throws XMLStreamException {\n\n        // parse the orb config attributes.\n        EnumSet<Attribute> expectedAttributes = EnumSet.of(Attribute.NAME, Attribute.ORB_PRINT_VERSION,\n                Attribute.ORB_GIOP_MINOR_VERSION, Attribute.ORB_USE_BOM, Attribute.ORB_USE_IMR,\n                Attribute.ORB_CACHE_POA_NAMES, Attribute.ORB_CACHE_TYPECODES);\n        // version 1.2 of the schema allows for the configuration of the ORB socket bindings.\n        if (namespace.ordinal() >= Namespace.JacORB_1_2.ordinal()) {\n            expectedAttributes.add(Attribute.ORB_SOCKET_BINDING);\n            expectedAttributes.add(Attribute.ORB_SSL_SOCKET_BINDING);\n        }\n        if (namespace.ordinal() >= Namespace.JacORB_2_0.ordinal()) {\n            expectedAttributes.add(Attribute.ORB_PERSISTENT_SERVER_ID);\n        }\n\n        this.parseAttributes(reader, node, expectedAttributes, null);\n\n        // parse the orb config elements.\n        EnumSet<Element> encounyeded = EnumSet.noneOf(Element.class);\n        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {\n            // check the element namespace.\n            if (namespace != Namespace.forUri(reader.getNamespaceURI()))\n                throw unexpectedElement(reader);\n\n            final Element element = Element.forName(reader.getLocalName());\n            // check for duplicate elements.\n            if (!encounyeded.add(element)) {\n                throw duplicateNamedElement(reader, element.getLocalName());\n            }\n            switch (element) {\n                case ORB_CONNECTION: {\n                    this.parseORBConnectionConfig(reader, node);\n                    break;\n                }\n                case ORB_INITIALIZERS: {\n                    this.parseORBInitializersConfig(reader, node);\n                    break;\n                }\n                default: {\n                    throw unexpectedElement(reader);\n                }\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the encounyeded",
            "the encounyeded elements",
            "the encounyeded attributes"
        ],
        "corrections_by_ours": [
            "elements",
            "attributes"
        ],
        "corrections_by_baseline": [
            "enc",
            "enc4",
            "dec",
            "encoded",
            "en",
            "encodable",
            "coun",
            "encStr",
            "encodedValue",
            "yylen"
        ]
    },
    {
        "original_word": "shift",
        "typo_word": "shofh",
        "original_variable": "shift",
        "typo_variable": "shofh",
        "original_code": "static int getFragment(byte sl, int[] masks, int pos) {\n\t\t/*\n\t\t * one element of the masks table stores fragments for 32/(2^sl)\n\t\t * elements; since it is a power of 2, we can divide on this value and\n\t\t * compute the remainder efficiently\n\t\t */\n\t\tint shift = (5 - sl);\n\t\tint p = pos >> shift; // = pos / (32/(2^sl))\n\t\tint r = (p << shift) ^ pos; // the remainder after the devision\n\t\t// extract the r-th fragment of the length 2^sl\n\t\treturn (masks[p] >> (r << sl)) & MSK_[sl];\n\t}",
        "modified_code": "static int getFragment(byte sl, int[] masks, int pos) {\n\t\t/*\n\t\t * one element of the masks table stores fragments for 32/(2^sl)\n\t\t * elements; since it is a power of 2, we can divide on this value and\n\t\t * compute the remainder efficiently\n\t\t */\n\t\tint shofh = (5 - sl);\n\t\tint p = pos >> shofh; // = pos / (32/(2^sl))\n\t\tint r = (p << shofh) ^ pos; // the remainder after the devision\n\t\t// extract the r-th fragment of the length 2^sl\n\t\treturn (masks[p] >> (r << sl)) & MSK_[sl];\n\t}",
        "explanations_by_ours": [
            "the length of the mask table",
            "the number of bits of the mask table",
            "the length of the mask table."
        ],
        "corrections_by_ours": [
            "length",
            "table",
            "mask",
            "number",
            "bits"
        ],
        "corrections_by_baseline": [
            "fh",
            "h",
            "H",
            "sh",
            "hf",
            "xh",
            "ht",
            "FWSP",
            "sfb",
            "hb"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rdshlt",
        "original_variable": "result",
        "typo_variable": "rdshlt",
        "original_code": "public WAMCallPoint resolveCallPoint(int functorName)\n    {\n        /*log.fine(\"public WAMCallPoint resolveCallPoint(int functorName): called\");*/\n\n        WAMCallPoint result = (WAMCallPoint) symbolTable.get(functorName, SYMKEY_CALLPOINTS);\n\n        if (result == null)\n        {\n            result = new WAMCallPoint(-1, 0, functorName);\n        }\n\n        return result;\n    }",
        "modified_code": "public WAMCallPoint resolveCallPoint(int functorName)\n    {\n        /*log.fine(\"public WAMCallPoint resolveCallPoint(int functorName): called\");*/\n\n        WAMCallPoint rdshlt = (WAMCallPoint) symbolTable.get(functorName, SYMKEY_CALLPOINTS);\n\n        if (rdshlt == null)\n        {\n            rdshlt = new WAMCallPoint(-1, 0, functorName);\n        }\n\n        return rdshlt;\n    }",
        "explanations_by_ours": [
            "the WAMCallPoint for the given functor name.",
            "the WAMCallPoint for the given functorName.",
            "the WAMCallPoint for the given functor."
        ],
        "corrections_by_ours": [
            "rdscall",
            "rdspoint",
            "rdsfunctor",
            "givenhlt",
            "functorhlt",
            "wamhlt",
            "namehlt",
            "callhlt",
            "pointhlt",
            "rdsgiven"
        ],
        "corrections_by_baseline": [
            "rdr",
            "rslt",
            "rsf",
            "rd",
            "rds",
            "rtn",
            "sr",
            "ddl",
            "swathLLR",
            "dsr"
        ]
    },
    {
        "original_word": "first",
        "typo_word": "fkrsf",
        "original_variable": "first",
        "typo_variable": "fkrsf",
        "original_code": "private static final Object convertCollectionToProtobufs(Collection<Object> collectionOfNonProtobufs) throws JException\n  {\n    if (collectionOfNonProtobufs.isEmpty())\n    {\n      return collectionOfNonProtobufs;\n    }\n    final Object first = collectionOfNonProtobufs.toArray()[0];\n    if (!ProtobufSerializerUtils.isProtbufEntity(first))\n    {\n      return collectionOfNonProtobufs;\n    }\n\n    final Collection<Object> newCollectionValues;\n\n    /**\n     * Maintain the Collection type of value at this stage (if it is a Set), and if conversion is required to a\n     * different Collection type, that will be handled by a converter later on\n     */\n    if (collectionOfNonProtobufs instanceof Set)\n    {\n      newCollectionValues = new HashSet<>();\n    }\n    else\n    {\n      newCollectionValues = new ArrayList<>();\n    }\n\n    for (Object iProtobufGenObj : collectionOfNonProtobufs)\n    {\n      newCollectionValues.add(serializeToProtobufEntity(iProtobufGenObj));\n    }\n\n    return newCollectionValues;\n  }",
        "modified_code": "private static final Object convertCollectionToProtobufs(Collection<Object> collectionOfNonProtobufs) throws JException\n  {\n    if (collectionOfNonProtobufs.isEmpty())\n    {\n      return collectionOfNonProtobufs;\n    }\n    final Object fkrsf = collectionOfNonProtobufs.toArray()[0];\n    if (!ProtobufSerializerUtils.isProtbufEntity(fkrsf))\n    {\n      return collectionOfNonProtobufs;\n    }\n\n    final Collection<Object> newCollectionValues;\n\n    /**\n     * Maintain the Collection type of value at this stage (if it is a Set), and if conversion is required to a\n     * different Collection type, that will be handled by a converter later on\n     */\n    if (collectionOfNonProtobufs instanceof Set)\n    {\n      newCollectionValues = new HashSet<>();\n    }\n    else\n    {\n      newCollectionValues = new ArrayList<>();\n    }\n\n    for (Object iProtobufGenObj : collectionOfNonProtobufs)\n    {\n      newCollectionValues.add(serializeToProtobufEntity(iProtobufGenObj));\n    }\n\n    return newCollectionValues;\n  }",
        "explanations_by_ours": [
            "The protobuf entity to convert.",
            "the protobuf entity to convert.",
            "the protobuf entity to convert"
        ],
        "corrections_by_ours": [
            "protobuf",
            "entity",
            "convert"
        ],
        "corrections_by_baseline": [
            "pki",
            "hrsi",
            "pjpn",
            "kf",
            "rcidpe",
            "rsf",
            "ppk",
            "pk1h",
            "pf",
            "bk"
        ]
    },
    {
        "original_word": "length",
        "typo_word": "ldngyh",
        "original_variable": "length",
        "typo_variable": "ldngyh",
        "original_code": "public static void copyRows(final Sheet srcSheet, final Sheet destSheet, final int srcRowStart, final int srcRowEnd,\r\n\t\t\tfinal int destRow, final boolean checkLock, final boolean setHiddenColumn) {\r\n\r\n\t\tint length = srcRowEnd - srcRowStart + 1;\r\n\t\tif (length <= 0) {\r\n\t\t\treturn;\r\n\t\t}\r\n\t\tdestSheet.shiftRows(destRow, destSheet.getLastRowNum(), length, true, false);\r\n\t\tfor (int i = 0; i < length; i++) {\r\n\t\t\tcopySingleRow(srcSheet, destSheet, srcRowStart + i, destRow + i, checkLock, setHiddenColumn);\r\n\t\t}\r\n\t\t// If there are are any merged regions in the source row, copy to new\r\n\t\t// row\r\n\t\tfor (int i = 0; i < srcSheet.getNumMergedRegions(); i++) {\r\n\t\t\tCellRangeAddress cellRangeAddress = srcSheet.getMergedRegion(i);\r\n\t\t\tif ((cellRangeAddress.getFirstRow() >= srcRowStart) && (cellRangeAddress.getLastRow() <= srcRowEnd)) {\r\n\t\t\t\tint targetRowFrom = cellRangeAddress.getFirstRow() - srcRowStart + destRow;\r\n\t\t\t\tint targetRowTo = cellRangeAddress.getLastRow() - srcRowStart + destRow;\r\n\r\n\t\t\t\tCellRangeAddress newCellRangeAddress = new CellRangeAddress(targetRowFrom, targetRowTo,\r\n\t\t\t\t\t\tcellRangeAddress.getFirstColumn(), cellRangeAddress.getLastColumn());\r\n\t\t\t\tdestSheet.addMergedRegion(newCellRangeAddress);\r\n\t\t\t}\r\n\t\t}\r\n\t}",
        "modified_code": "public static void copyRows(final Sheet srcSheet, final Sheet destSheet, final int srcRowStart, final int srcRowEnd,\r\n\t\t\tfinal int destRow, final boolean checkLock, final boolean setHiddenColumn) {\r\n\r\n\t\tint ldngyh = srcRowEnd - srcRowStart + 1;\r\n\t\tif (ldngyh <= 0) {\r\n\t\t\treturn;\r\n\t\t}\r\n\t\tdestSheet.shiftRows(destRow, destSheet.getLastRowNum(), ldngyh, true, false);\r\n\t\tfor (int i = 0; i < ldngyh; i++) {\r\n\t\t\tcopySingleRow(srcSheet, destSheet, srcRowStart + i, destRow + i, checkLock, setHiddenColumn);\r\n\t\t}\r\n\t\t// If there are are any merged regions in the source row, copy to new\r\n\t\t// row\r\n\t\tfor (int i = 0; i < srcSheet.getNumMergedRegions(); i++) {\r\n\t\t\tCellRangeAddress cellRangeAddress = srcSheet.getMergedRegion(i);\r\n\t\t\tif ((cellRangeAddress.getFirstRow() >= srcRowStart) && (cellRangeAddress.getLastRow() <= srcRowEnd)) {\r\n\t\t\t\tint targetRowFrom = cellRangeAddress.getFirstRow() - srcRowStart + destRow;\r\n\t\t\t\tint targetRowTo = cellRangeAddress.getLastRow() - srcRowStart + destRow;\r\n\r\n\t\t\t\tCellRangeAddress newCellRangeAddress = new CellRangeAddress(targetRowFrom, targetRowTo,\r\n\t\t\t\t\t\tcellRangeAddress.getFirstColumn(), cellRangeAddress.getLastColumn());\r\n\t\t\t\tdestSheet.addMergedRegion(newCellRangeAddress);\r\n\t\t\t}\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "the number of rows to copy",
            "the number of rows to copy.",
            "the number of rows to be copied"
        ],
        "corrections_by_ours": [
            "copy",
            "rows",
            "copied",
            "number"
        ],
        "corrections_by_baseline": [
            "dlondy",
            "h",
            "H",
            "llh",
            "lh",
            "hb",
            "xh",
            "bld",
            "oH",
            "yb"
        ]
    },
    {
        "original_word": "props",
        "typo_word": "pfols",
        "original_variable": "props",
        "typo_variable": "pfols",
        "original_code": "protected Properties createSessionProperties() {\n\t\tfinal Properties props = new Properties();\n\n\t\tprops.putAll(customProperties);\n\n\t\tif (debugMode) {\n\t\t\tprops.put(MAIL_DEBUG, \"true\");\n\t\t}\n\n\t\tif (!strictAddress) {\n\t\t\tprops.put(MAIL_MIME_ADDRESS_STRICT, \"false\");\n\t\t}\n\n\t\treturn props;\n\t}",
        "modified_code": "protected Properties createSessionProperties() {\n\t\tfinal Properties pfols = new Properties();\n\n\t\tpfols.putAll(customProperties);\n\n\t\tif (debugMode) {\n\t\t\tpfols.put(MAIL_DEBUG, \"true\");\n\t\t}\n\n\t\tif (!strictAddress) {\n\t\t\tpfols.put(MAIL_MIME_ADDRESS_STRICT, \"false\");\n\t\t}\n\n\t\treturn pfols;\n\t}",
        "explanations_by_ours": [
            "the pfols",
            "the session properties",
            "the pfols"
        ],
        "corrections_by_ours": [
            "pfproperties",
            "pfsession",
            "propertiesols",
            "sessionols",
            "olsols",
            "pfpf",
            "pfols"
        ],
        "corrections_by_baseline": [
            "pf",
            "pco",
            "psdf",
            "lp_alp",
            "pds",
            "fos",
            "pobsData",
            "dks",
            "sdf",
            "p_alp"
        ]
    },
    {
        "original_word": "prefs",
        "typo_word": "pfebs",
        "original_variable": "prefs",
        "typo_variable": "pfebs",
        "original_code": "void setFavoriteNotices(final PortletRequest req, final Set<String> favoriteNotices) {\n        final String[] ids = favoriteNotices.toArray(new String[favoriteNotices.size()]);\n        final PortletPreferences prefs = req.getPreferences();\n        try {\n            prefs.setValues(FAVORITE_NOTIFICATION_IDS_PREFERENCE, ids);\n            prefs.store();\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }",
        "modified_code": "void setFavoriteNotices(final PortletRequest req, final Set<String> favoriteNotices) {\n        final String[] ids = favoriteNotices.toArray(new String[favoriteNotices.size()]);\n        final PortletPreferences pfebs = req.getPreferences();\n        try {\n            pfebs.setValues(FAVORITE_NOTIFICATION_IDS_PREFERENCE, ids);\n            pfebs.store();\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }",
        "explanations_by_ours": [
            "the portlet preferences",
            "the current portlet preferences",
            "the PortletPreferences"
        ],
        "corrections_by_ours": [
            "preferencesebs",
            "pfpreferences",
            "portletebs",
            "pfcurrent",
            "currentebs",
            "pfportlet",
            "pfebs"
        ],
        "corrections_by_baseline": [
            "bsf",
            "bsers",
            "bs",
            "sfb",
            "fos",
            "fis",
            "bms",
            "sobs",
            "pce",
            "pib"
        ]
    },
    {
        "original_word": "wrapped",
        "typo_word": "wraloed",
        "original_variable": "wrappedModelInstance",
        "typo_variable": "wraloedModelInstance",
        "original_code": "public void useCurrentValuesAsDefaults() {\n\t\tM wrappedModelInstance = model.get();\n\t\tif(wrappedModelInstance != null) {\n\t\t\tfor (final PropertyField<?, M, ?> field : fields) {\n\t\t\t\tfield.updateDefault(wrappedModelInstance);\n\t\t\t}\n\n\t\t\tfor (final ImmutablePropertyField<?, M, ?> field : immutableFields) {\n\t\t\t\tfield.updateDefault(wrappedModelInstance);\n\t\t\t}\n\t\t}\n\t}",
        "modified_code": "public void useCurrentValuesAsDefaults() {\n\t\tM wraloedModelInstance = model.get();\n\t\tif(wraloedModelInstance != null) {\n\t\t\tfor (final PropertyField<?, M, ?> field : fields) {\n\t\t\t\tfield.updateDefault(wraloedModelInstance);\n\t\t\t}\n\n\t\t\tfor (final ImmutablePropertyField<?, M, ?> field : immutableFields) {\n\t\t\t\tfield.updateDefault(wraloedModelInstance);\n\t\t\t}\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the instance of the Wraloed model.",
            "the instance of the Wraloed model",
            "the model instance"
        ],
        "corrections_by_ours": [
            "modelModelInstance",
            "wraloedWraloedInstance",
            "instanceModelInstance",
            "wraloedModelWraloed",
            "wraloedInstanceInstance",
            "wraloedModelModel",
            "wraloedModelInstance"
        ],
        "corrections_by_baseline": [
            "wrappedModelInstance",
            "objmodel",
            "fullModel",
            "model",
            "newModel",
            "managedInstance",
            "newViewModel",
            "dbModel",
            "actualViewModel",
            "instanceIdModel"
        ]
    },
    {
        "original_word": "inode",
        "typo_word": "unkde",
        "original_variable": "inode",
        "typo_variable": "unkde",
        "original_code": "public static LiveFile deserialize(String str) throws IOException {\n    Utils.checkNotNull(str, \"str\");\n    try {\n      JsonMapper objectMapper = DataCollectorServices.instance().get(JsonMapper.SERVICE_KEY);\n      Map map = objectMapper.readValue(str, Map.class);\n      Path path = Paths.get((String) map.get(\"path\"));\n      String headHash = (map.containsKey(\"headHash\")) ? (String) map.get(\"headHash\") : \"\";\n      int headLen = (map.containsKey(\"headLen\")) ? (int) map.get(\"headLen\") : 0;\n      String inode = (String) map.get(\"inode\");\n      return new LiveFile(path, inode, headHash, headLen);\n    } catch (RuntimeException|IOException ex) {\n      throw new IllegalArgumentException(Utils.format(\"Invalid LiveFile serialized string '{}': {}\", str,\n                                                      ex.toString()), ex);\n    }\n  }",
        "modified_code": "public static LiveFile deserialize(String str) throws IOException {\n    Utils.checkNotNull(str, \"str\");\n    try {\n      JsonMapper objectMapper = DataCollectorServices.instance().get(JsonMapper.SERVICE_KEY);\n      Map map = objectMapper.readValue(str, Map.class);\n      Path path = Paths.get((String) map.get(\"path\"));\n      String headHash = (map.containsKey(\"headHash\")) ? (String) map.get(\"headHash\") : \"\";\n      int headLen = (map.containsKey(\"headLen\")) ? (int) map.get(\"headLen\") : 0;\n      String unkde = (String) map.get(\"inode\");\n      return new LiveFile(path, unkde, headHash, headLen);\n    } catch (RuntimeException|IOException ex) {\n      throw new IllegalArgumentException(Utils.format(\"Invalid LiveFile serialized string '{}': {}\", str,\n                                                      ex.toString()), ex);\n    }\n  }",
        "explanations_by_ours": [
            "the inode of the live file",
            "the inode of the live file to deserialize",
            "the unkde of the live file"
        ],
        "corrections_by_ours": [
            "inode",
            "file",
            "live",
            "deserialize"
        ],
        "corrections_by_baseline": [
            "de",
            "dely",
            "miss",
            "olen",
            "deref",
            "du",
            "munge",
            "de2",
            "spl",
            "splon"
        ]
    },
    {
        "original_word": "offset",
        "typo_word": "pffswt",
        "original_variable": "offset",
        "typo_variable": "pffswt",
        "original_code": "static void readFully(InputStream f, byte[] bytes, int start, int len) throws IOException {\n    int offset = start;\n    int remaining = len;\n    while (remaining > 0) {\n      int bytesRead = f.read(bytes, offset, remaining);\n      if (bytesRead < 0) {\n        throw new EOFException(\n            \"Reached the end of stream with \" + remaining + \" bytes left to read\");\n      }\n\n      remaining -= bytesRead;\n      offset += bytesRead;\n    }\n  }",
        "modified_code": "static void readFully(InputStream f, byte[] bytes, int start, int len) throws IOException {\n    int pffswt = start;\n    int remaining = len;\n    while (remaining > 0) {\n      int bytesRead = f.read(bytes, pffswt, remaining);\n      if (bytesRead < 0) {\n        throw new EOFException(\n            \"Reached the end of stream with \" + remaining + \" bytes left to read\");\n      }\n\n      remaining -= bytesRead;\n      pffswt += bytesRead;\n    }\n  }",
        "explanations_by_ours": [
            "the start position in the byte array",
            "the starting position in the byte array",
            "the start position in the byte array."
        ],
        "corrections_by_ours": [
            "position",
            "start",
            "byte",
            "array",
            "starting"
        ],
        "corrections_by_baseline": [
            "poff",
            "rsf",
            "hf",
            "etf",
            "dp",
            "tp",
            "pce",
            "xpp",
            "spf",
            "swfo"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "coujr",
        "original_variable": "count",
        "typo_variable": "coujr",
        "original_code": "public void addLexeme(int lexemeId) {\n\t\tint count = 1;\n\t\tif (lexemeFrequency.get(lexemeId) != null)\n\t\t\tcount = lexemeFrequency.get(lexemeId) + 1;\n\t\tlexemeFrequency.put(lexemeId, count);\n\t}",
        "modified_code": "public void addLexeme(int lexemeId) {\n\t\tint coujr = 1;\n\t\tif (lexemeFrequency.get(lexemeId) != null)\n\t\t\tcoujr = lexemeFrequency.get(lexemeId) + 1;\n\t\tlexemeFrequency.put(lexemeId, coujr);\n\t}",
        "explanations_by_ours": [
            "the coujr of the lexeme",
            "the coujr",
            "the coujr of the lexeme."
        ],
        "corrections_by_ours": [
            "lexeme"
        ],
        "corrections_by_baseline": [
            "jg",
            "LULC",
            "coun",
            "csm",
            "rj",
            "lac",
            "cir",
            "ou",
            "mant",
            "rtc"
        ]
    },
    {
        "original_word": "right",
        "typo_word": "finht",
        "original_variable": "right",
        "typo_variable": "finht",
        "original_code": "public static double evaluate( double x , double y , EllipseRotated_F64 ellipse ) {\n\n\t\tdouble cphi = Math.cos(ellipse.phi);\n\t\tdouble sphi = Math.sin(ellipse.phi);\n\n\t\tx -= ellipse.center.x;\n\t\ty -= ellipse.center.y;\n\n\t\tdouble left = (x*cphi + y*sphi);\n\t\tdouble right = (-x*sphi + y*cphi);\n\n\t\tdouble ll = left/ellipse.a;\n\t\tdouble rr = right/ellipse.b;\n\n\t\treturn ll*ll + rr*rr;\n\t}",
        "modified_code": "public static double evaluate( double x , double y , EllipseRotated_F64 ellipse ) {\n\n\t\tdouble cphi = Math.cos(ellipse.phi);\n\t\tdouble sphi = Math.sin(ellipse.phi);\n\n\t\tx -= ellipse.center.x;\n\t\ty -= ellipse.center.y;\n\n\t\tdouble left = (x*cphi + y*sphi);\n\t\tdouble finht = (-x*sphi + y*cphi);\n\n\t\tdouble ll = left/ellipse.a;\n\t\tdouble rr = finht/ellipse.b;\n\n\t\treturn ll*ll + rr*rr;\n\t}",
        "explanations_by_ours": [
            "The value of the function.",
            "The value of the function",
            "The value of the function (in radians)."
        ],
        "corrections_by_ours": [
            "function",
            "radians)",
            "(",
            "value"
        ],
        "corrections_by_baseline": [
            "fin",
            "done",
            "finished",
            "finisher",
            "miniEnd",
            "xbeg",
            "nextBT",
            "new_end",
            "newlyFinished",
            "endLL"
        ]
    },
    {
        "original_word": "Info",
        "typo_word": "Intp",
        "original_variable": "userToGetInfoFor",
        "typo_variable": "userToGetIntpFor",
        "original_code": "public User getUserWhereUsername(String usernameParam)\n    {\n        User userToGetInfoFor = new User();\n        userToGetInfoFor.setUsername(usernameParam);\n\n        if(this.serviceTicket != null)\n        {\n            userToGetInfoFor.setServiceTicket(this.serviceTicket);\n        }\n\n        try {\n            return new User(this.postJson(\n                    userToGetInfoFor, WS.Path.User.Version1.getByUsername()));\n        }\n        //\n        catch (JSONException jsonExcept) {\n            throw new FluidClientException(jsonExcept.getMessage(),\n                    FluidClientException.ErrorCode.JSON_PARSING);\n        }\n    }",
        "modified_code": "public User getUserWhereUsername(String usernameParam)\n    {\n        User userToGetIntpFor = new User();\n        userToGetIntpFor.setUsername(usernameParam);\n\n        if(this.serviceTicket != null)\n        {\n            userToGetIntpFor.setServiceTicket(this.serviceTicket);\n        }\n\n        try {\n            return new User(this.postJson(\n                    userToGetIntpFor, WS.Path.User.Version1.getByUsername()));\n        }\n        //\n        catch (JSONException jsonExcept) {\n            throw new FluidClientException(jsonExcept.getMessage(),\n                    FluidClientException.ErrorCode.JSON_PARSING);\n        }\n    }",
        "explanations_by_ours": [
            "The User object to get.",
            "The User to get.",
            "User to get"
        ],
        "corrections_by_ours": [
            "userToObjectIntpFor",
            "getToGetIntpFor",
            "userToUserIntpFor",
            "userToGetGetFor",
            "userToGetIntpUser",
            "objectToGetIntpFor",
            "userUserGetIntpFor",
            "userGetGetIntpFor",
            "userObjectGetIntpFor",
            "userToGetUserFor"
        ],
        "corrections_by_baseline": [
            "userToGetInfoFor",
            "userToPost",
            "userNoti",
            "userQueryToGetInfoFor",
            "newUserSesion",
            "adminUserCreate",
            "roleToGetInfoFor",
            "appUser",
            "returnUsername",
            "targetUserRequest"
        ]
    },
    {
        "original_word": "content",
        "typo_word": "conyenh",
        "original_variable": "content",
        "typo_variable": "conyenh",
        "original_code": "protected JSONObject moveIndex(String srcIndexName, String dstIndexName, @Nullable RequestOptions requestOptions) throws AlgoliaException {\n        try {\n            JSONObject content = new JSONObject();\n            content.put(\"operation\", \"move\");\n            content.put(\"destination\", dstIndexName);\n            return postRequest(\"/1/indexes/\" + URLEncoder.encode(srcIndexName, \"UTF-8\") + \"/operation\", /* urlParameters: */ null, content.toString(), false, requestOptions);\n        } catch (UnsupportedEncodingException e) {\n            throw new RuntimeException(e);\n        } catch (JSONException e) {\n            throw new AlgoliaException(e.getMessage());\n        }\n    }",
        "modified_code": "protected JSONObject moveIndex(String srcIndexName, String dstIndexName, @Nullable RequestOptions requestOptions) throws AlgoliaException {\n        try {\n            JSONObject conyenh = new JSONObject();\n            conyenh.put(\"operation\", \"move\");\n            conyenh.put(\"destination\", dstIndexName);\n            return postRequest(\"/1/indexes/\" + URLEncoder.encode(srcIndexName, \"UTF-8\") + \"/operation\", /* urlParameters: */ null, conyenh.toString(), false, requestOptions);\n        } catch (UnsupportedEncodingException e) {\n            throw new RuntimeException(e);\n        } catch (JSONException e) {\n            throw new AlgoliaException(e.getMessage());\n        }\n    }",
        "explanations_by_ours": [
            "the options to pass to this request",
            "the request parameters",
            "the options for this request"
        ],
        "corrections_by_ours": [
            "options",
            "request",
            "parameters",
            "pass"
        ],
        "corrections_by_baseline": [
            "con",
            "ilenhd",
            "dcon",
            "gammCompl",
            "xCompl",
            "aeron",
            "coun",
            "cons",
            "conMod",
            "co"
        ]
    },
    {
        "original_word": "index",
        "typo_word": "lnsex",
        "original_variable": "index",
        "typo_variable": "lnsex",
        "original_code": "private static <V> Set<V> set(final int size, final V[] array) {\n\t\tint index = 0;\n\t\tfinal Set<V> set = new HashSet<>();\n\n\t\tfor (final V v : array) {\n\t\t\tset.add(v);\n\t\t\tindex++;\n\t\t\tif (index == size) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\treturn set;\n\t}",
        "modified_code": "private static <V> Set<V> set(final int size, final V[] array) {\n\t\tint lnsex = 0;\n\t\tfinal Set<V> set = new HashSet<>();\n\n\t\tfor (final V v : array) {\n\t\t\tset.add(v);\n\t\t\tlnsex++;\n\t\t\tif (lnsex == size) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\treturn set;\n\t}",
        "explanations_by_ours": [
            "the number of elements in the set",
            "the number of elements in the set to create",
            "the number of elements in the array"
        ],
        "corrections_by_ours": [
            "lnset",
            "elementssex",
            "lnnumber",
            "lncreate",
            "lnelements",
            "setsex",
            "numbersex",
            "arraysex",
            "createsex",
            "lnarray"
        ],
        "corrections_by_baseline": [
            "sex",
            "snum",
            "coun",
            "sn",
            "mnemonic",
            "mnu",
            "bbLower",
            "npe",
            "nfe",
            "ncd"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "vojnt",
        "original_variable": "count",
        "typo_variable": "vojnt",
        "original_code": "public long poll(ByteSink destination, long destoff, long destlen) {\n        long count = 0;\n        try {\n            while (pollIndex != addIndex && count < destlen) {\n                destination.put(destoff + count++, storage.get(pollIndex++));\n                if (pollIndex >= storage.length()) {\n                    pollIndex = 0;\n                }\n            }\n        } catch (Exception e) {\n            logger.log(FSTLogger.Level.ERROR, \"Failed to poll\", e);\n        }\n        return count;\n    }",
        "modified_code": "public long poll(ByteSink destination, long destoff, long destlen) {\n        long vojnt = 0;\n        try {\n            while (pollIndex != addIndex && vojnt < destlen) {\n                destination.put(destoff + vojnt++, storage.get(pollIndex++));\n                if (pollIndex >= storage.length()) {\n                    pollIndex = 0;\n                }\n            }\n        } catch (Exception e) {\n            logger.log(FSTLogger.Level.ERROR, \"Failed to poll\", e);\n        }\n        return vojnt;\n    }",
        "explanations_by_ours": [
            "the number of bytes to write",
            "the number of bytes written",
            "the current number of bytes written"
        ],
        "corrections_by_ours": [
            "current",
            "written",
            "bytes",
            "write",
            "number"
        ],
        "corrections_by_baseline": [
            "jinc",
            "JD",
            "rj",
            "mj",
            "jshft",
            "nj",
            "J",
            "j",
            "vn",
            "jbeg"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "fesuly",
        "original_variable": "result",
        "typo_variable": "fesuly",
        "original_code": "public byte[] retrieveCode(WAMCallPoint callPoint)\n    {\n        byte[] result = new byte[callPoint.length];\n\n        codeBuffer.get(result, callPoint.entryPoint, callPoint.length);\n\n        return result;\n    }",
        "modified_code": "public byte[] retrieveCode(WAMCallPoint callPoint)\n    {\n        byte[] fesuly = new byte[callPoint.length];\n\n        codeBuffer.get(fesuly, callPoint.entryPoint, callPoint.length);\n\n        return fesuly;\n    }",
        "explanations_by_ours": [
            "the fesuly code",
            "the fesuly byte array",
            "the fesuly code buffer"
        ],
        "corrections_by_ours": [
            "array",
            "byte",
            "buffer",
            "code"
        ],
        "corrections_by_baseline": [
            "soft",
            "cis",
            "fis",
            "full",
            "too",
            "bms",
            "soFar",
            "ecef",
            "good",
            "iis"
        ]
    },
    {
        "original_word": "members",
        "typo_word": "jejbers",
        "original_variable": "members",
        "typo_variable": "jejbers",
        "original_code": "private ExceptionDefImpl addException(ExceptionAnalysis ea)\n            throws RMIIIOPViolationException, IRConstructionException {\n        ExceptionDefImpl eDef;\n        Class cls = ea.getCls();\n\n        // Lookup: Has it already been added?\n        eDef = (ExceptionDefImpl) exceptionMap.get(cls);\n        if (eDef != null)\n            return eDef; // Yes, just return it.\n\n        // 1.3.7.1: map to value\n        ValueDefImpl vDef = addValue(ea);\n\n        // 1.3.7.2: map to exception\n        ModuleDefImpl m = ensurePackageExists(cls.getPackage().getName());\n        String base = cls.getName();\n        base = base.substring(base.lastIndexOf('.') + 1);\n        if (base.endsWith(\"Exception\"))\n            base = base.substring(0, base.length() - 9);\n        base = Util.javaToIDLName(base + \"Ex\");\n\n        StructMember[] members = new StructMember[1];\n        members[0] = new StructMember(\"value\", vDef.type(), null/*ignored*/);\n        TypeCode typeCode\n                = orb.create_exception_tc(ea.getExceptionRepositoryId(),\n                base, members);\n\n        eDef = new ExceptionDefImpl(ea.getExceptionRepositoryId(), base, \"1.0\",\n                typeCode, vDef, m, impl);\n        m.add(base, eDef);\n        exceptionMap.put(cls, eDef); // Remember we mapped this.\n\n        return eDef;\n    }",
        "modified_code": "private ExceptionDefImpl addException(ExceptionAnalysis ea)\n            throws RMIIIOPViolationException, IRConstructionException {\n        ExceptionDefImpl eDef;\n        Class cls = ea.getCls();\n\n        // Lookup: Has it already been added?\n        eDef = (ExceptionDefImpl) exceptionMap.get(cls);\n        if (eDef != null)\n            return eDef; // Yes, just return it.\n\n        // 1.3.7.1: map to value\n        ValueDefImpl vDef = addValue(ea);\n\n        // 1.3.7.2: map to exception\n        ModuleDefImpl m = ensurePackageExists(cls.getPackage().getName());\n        String base = cls.getName();\n        base = base.substring(base.lastIndexOf('.') + 1);\n        if (base.endsWith(\"Exception\"))\n            base = base.substring(0, base.length() - 9);\n        base = Util.javaToIDLName(base + \"Ex\");\n\n        StructMember[] jejbers = new StructMember[1];\n        jejbers[0] = new StructMember(\"value\", vDef.type(), null/*ignored*/);\n        TypeCode typeCode\n                = orb.create_exception_tc(ea.getExceptionRepositoryId(),\n                base, jejbers);\n\n        eDef = new ExceptionDefImpl(ea.getExceptionRepositoryId(), base, \"1.0\",\n                typeCode, vDef, m, impl);\n        m.add(base, eDef);\n        exceptionMap.put(cls, eDef); // Remember we mapped this.\n\n        return eDef;\n    }",
        "explanations_by_ours": [
            "the exception fields",
            "a list of fields to add to the exception map",
            "a list of fields to add to the exception map."
        ],
        "corrections_by_ours": [
            "fields",
            "exception",
            "add",
            "list",
            "map"
        ],
        "corrections_by_baseline": [
            "je",
            "mbers",
            "jshft",
            "ja",
            "jars",
            "jbeg",
            "nelems",
            "JD",
            "objs",
            "jg"
        ]
    },
    {
        "original_word": "Running",
        "typo_word": "Runjjng",
        "original_variable": "isRunning",
        "typo_variable": "isRunjjng",
        "original_code": "public void waitForMemberStart(String member, JMX jmx)\n\t{\n\t\tboolean isRunning =  false;\n\t\tboolean printedStartMember  = false;\n\t\tint count = 0;\n\t\twhile(!isRunning)\n\t\t{\n\t\t\ttry{ isRunning = GemFireInspector.checkMemberStatus(member,jmx); }\n\t\t\tcatch(Exception e) {Debugger.printWarn(e);}\n\t\t\t\n\t\t\tif(!printedStartMember )\n\t\t\t{\n\t\t\t\tDebugger.println(\"Waiting for member:\"+member+\".  Starting member to continue. \"+\n\t\t\t            \" You can perform a gfsh status command to confirm whether the member is running\");\n\t\t\t\t\tprintedStartMember = true;\n\t\t\t}\n\t\t\t\n\t\t\t\n\t\t\ttry{ delay();}catch(Exception e){}\n\t\t\t\n\t\t\t if(count > retryCount)\n\t\t\t {\n\t\t\t\t throw new RuntimeException(\"member:\"+member+\" did not start after \"\n\t\t\t +retryCount+\" checks with a delay of \"+sleepDelay+\" milliseconds\");\n\t\t\t }\n\t\t\t \n\t\t\tcount++;\n\t\t}\n\t}",
        "modified_code": "public void waitForMemberStart(String member, JMX jmx)\n\t{\n\t\tboolean isRunjjng =  false;\n\t\tboolean printedStartMember  = false;\n\t\tint count = 0;\n\t\twhile(!isRunjjng)\n\t\t{\n\t\t\ttry{ isRunjjng = GemFireInspector.checkMemberStatus(member,jmx); }\n\t\t\tcatch(Exception e) {Debugger.printWarn(e);}\n\t\t\t\n\t\t\tif(!printedStartMember )\n\t\t\t{\n\t\t\t\tDebugger.println(\"Waiting for member:\"+member+\".  Starting member to continue. \"+\n\t\t\t            \" You can perform a gfsh status command to confirm whether the member is running\");\n\t\t\t\t\tprintedStartMember = true;\n\t\t\t}\n\t\t\t\n\t\t\t\n\t\t\ttry{ delay();}catch(Exception e){}\n\t\t\t\n\t\t\t if(count > retryCount)\n\t\t\t {\n\t\t\t\t throw new RuntimeException(\"member:\"+member+\" did not start after \"\n\t\t\t +retryCount+\" checks with a delay of \"+sleepDelay+\" milliseconds\");\n\t\t\t }\n\t\t\t \n\t\t\tcount++;\n\t\t}\n\t}",
        "explanations_by_ours": [
            "true if the member is running, false otherwise.",
            "true if the member is running, false otherwise",
            "true if the member is running."
        ],
        "corrections_by_ours": [
            "isRunning",
            "isRunning,",
            "otherwiseRunjjng",
            "falseRunjjng",
            "runningRunjjng",
            "isTrue",
            "running,Runjjng",
            "memberRunjjng",
            "trueRunjjng",
            "isOtherwise"
        ],
        "corrections_by_baseline": [
            "run",
            "runAs",
            "drun",
            "runme",
            "runAsManager",
            "runIdx",
            "runbuilder",
            "runner",
            "allRuntimes",
            "exeCommand"
        ]
    },
    {
        "original_word": "Value",
        "typo_word": "Vakus",
        "original_variable": "apiHandlerValue",
        "typo_variable": "apiHandlerVakus",
        "original_code": "private boolean isHandlerRequest(final HttpServletRequest request) {\n    String apiHandlerValue = request.getParameter(PATH_API);\n    return PATH_HANDLER.equals(apiHandlerValue) && retrieveCacheKey(request) != null;\n  }",
        "modified_code": "private boolean isHandlerRequest(final HttpServletRequest request) {\n    String apiHandlerVakus = request.getParameter(PATH_API);\n    return PATH_HANDLER.equals(apiHandlerVakus) && retrieveCacheKey(request) != null;\n  }",
        "explanations_by_ours": [
            "the vakus to check",
            "the vakus path to check",
            "the vakus to check for"
        ],
        "corrections_by_ours": [
            "pathHandlerVakus",
            "vakusHandlerVakus",
            "apiHandlerPath",
            "apiPathVakus",
            "apiVakusVakus",
            "checkHandlerVakus",
            "apiCheckVakus",
            "apiHandlerCheck",
            "apiHandlerVakus"
        ],
        "corrections_by_baseline": [
            "provideJaasApi",
            "provideServletApi",
            "adminApi",
            "ejbEndpointList",
            "apiHandlerValue",
            "ATT_JAAS_API_PROVISION",
            "authzHandler",
            "soapEndpoint",
            "respHandler",
            "ATT_SERVLET_API_PROVISION"
        ]
    },
    {
        "original_word": "remaining",
        "typo_word": "remaihjng",
        "original_variable": "remaining",
        "typo_variable": "remaihjng",
        "original_code": "public AList<T> reverse() {\n        AList<T> remaining = this;\n        AList<T> result = nil();\n\n        while(! remaining.isEmpty()) {\n            result = result.cons(remaining.head());\n            remaining = remaining.tail();\n        }\n\n        return result;\n    }",
        "modified_code": "public AList<T> reverse() {\n        AList<T> remaihjng = this;\n        AList<T> result = nil();\n\n        while(! remaihjng.isEmpty()) {\n            result = result.cons(remaihjng.head());\n            remaihjng = remaihjng.tail();\n        }\n\n        return result;\n    }",
        "explanations_by_ours": [
            "the list to reverse",
            "the list to be reversed",
            "the list to reverse."
        ],
        "corrections_by_ours": [
            "reverse",
            "reversed",
            "list"
        ],
        "corrections_by_baseline": [
            "mrm",
            "rm",
            "datarun",
            "trovit",
            "noprogress",
            "mv",
            "dub",
            "deref",
            "vmdi",
            "rem"
        ]
    },
    {
        "original_word": "total",
        "typo_word": "totwk",
        "original_variable": "total",
        "typo_variable": "totwk",
        "original_code": "public void calcElementSize() {\n    int total = 0;\n    for (Variable v : members) {\n      total += v.getElementSize() * v.getSize();\n    }\n    elementSize = total;\n  }",
        "modified_code": "public void calcElementSize() {\n    int totwk = 0;\n    for (Variable v : members) {\n      totwk += v.getElementSize() * v.getSize();\n    }\n    elementSize = totwk;\n  }",
        "explanations_by_ours": [
            "The total size of the element.",
            "the total size of the element.",
            "The total size of the element"
        ],
        "corrections_by_ours": [
            "total",
            "size",
            "element"
        ],
        "corrections_by_baseline": [
            "hf",
            "rtc",
            "kyero",
            "hrsi",
            "tmi",
            "v_ecf",
            "dcs",
            "tBTAT",
            "datarun",
            "tcm"
        ]
    },
    {
        "original_word": "sheet",
        "typo_word": "wheeg",
        "original_variable": "sheetId",
        "typo_variable": "wheegId",
        "original_code": "public String getTabType() {\r\n\r\n\t\tint sheetId = webFormTabView.getActiveIndex();\r\n\t\tif ((sheetId >= 0) && (tabs != null)) {\r\n\t\t\tif (sheetId >= tabs.size()) {\r\n\t\t\t\tsheetId = 0;\r\n\t\t\t}\r\n\t\t\ttabType = tabs.get(sheetId).type.toLowerCase();\r\n\t\t} else {\r\n\t\t\ttabType = TieConstants.TAB_TYPE_NONE;\r\n\t\t}\r\n\t\treturn tabType;\r\n\t}",
        "modified_code": "public String getTabType() {\r\n\r\n\t\tint wheegId = webFormTabView.getActiveIndex();\r\n\t\tif ((wheegId >= 0) && (tabs != null)) {\r\n\t\t\tif (wheegId >= tabs.size()) {\r\n\t\t\t\twheegId = 0;\r\n\t\t\t}\r\n\t\t\ttabType = tabs.get(wheegId).type.toLowerCase();\r\n\t\t} else {\r\n\t\t\ttabType = TieConstants.TAB_TYPE_NONE;\r\n\t\t}\r\n\t\treturn tabType;\r\n\t}",
        "explanations_by_ours": [
            "the wheeg id",
            "the wheegId",
            "the wheeg id."
        ],
        "corrections_by_ours": [
            "ideegId",
            "eegeegId",
            "whidId",
            "whwhId",
            "wheegWh",
            "wheegEeg",
            "wheegId"
        ],
        "corrections_by_baseline": [
            "bdaId",
            "fluidItmId",
            "id",
            "ID",
            "spcid",
            "sID",
            "cid",
            "mainID",
            "idr",
            "idStr"
        ]
    },
    {
        "original_word": "Prop",
        "typo_word": "Pdlp",
        "original_variable": "pollIntervalProp",
        "typo_variable": "pollIntervalPdlp",
        "original_code": "@Override\n    public void initialize( FileWatchLogger log ) throws FileWatchException\n    {\n        super.initialize( log );\n\n        pollInterval = DEFAULT_POLL_INTERVAL;\n        String pollIntervalProp = System.getProperty( \"play2.pollInterval\" );\n        if ( pollIntervalProp != null )\n        {\n            try\n            {\n                pollInterval = Integer.parseInt( pollIntervalProp );\n            }\n            catch ( NumberFormatException e )\n            {\n                log.warn( String.format( \"Unparsable property value \\\"%s\\\", using default poll interval %d ms\",\n                                         pollIntervalProp, Integer.valueOf( DEFAULT_POLL_INTERVAL ) ) );\n                // throw new FileWatchException( \"PollingFileWatcher initialization failed\", e );\n            }\n        }\n    }",
        "modified_code": "@Override\n    public void initialize( FileWatchLogger log ) throws FileWatchException\n    {\n        super.initialize( log );\n\n        pollInterval = DEFAULT_POLL_INTERVAL;\n        String pollIntervalPdlp = System.getProperty( \"play2.pollInterval\" );\n        if ( pollIntervalPdlp != null )\n        {\n            try\n            {\n                pollInterval = Integer.parseInt( pollIntervalPdlp );\n            }\n            catch ( NumberFormatException e )\n            {\n                log.warn( String.format( \"Unparsable property value \\\"%s\\\", using default poll interval %d ms\",\n                                         pollIntervalPdlp, Integer.valueOf( DEFAULT_POLL_INTERVAL ) ) );\n                // throw new FileWatchException( \"PollingFileWatcher initialization failed\", e );\n            }\n        }\n    }",
        "explanations_by_ours": [
            "The poll interval in milliseconds.",
            "The poll interval in ms.",
            "the poll interval in milliseconds."
        ],
        "corrections_by_ours": [
            "pollIntervalPoll",
            "millisecondsIntervalPdlp",
            "pollMillisecondsPdlp",
            "intervalIntervalPdlp",
            "pollPollPdlp",
            "pollIntervalMilliseconds",
            "msIntervalPdlp",
            "pollMsPdlp",
            "pollIntervalInterval",
            "pollIntervalMs"
        ],
        "corrections_by_baseline": [
            "pollIntervalProp",
            "customInterval",
            "interval",
            "parkTimeout",
            "deadlineNs",
            "minimumPongTime",
            "selectTimeout",
            "callDelayMs",
            "delayMillis",
            "delayInHundredthsOfASecond"
        ]
    },
    {
        "original_word": "resolved",
        "typo_word": "reeolvef",
        "original_variable": "resolved",
        "typo_variable": "reeolvef",
        "original_code": "public String resolveURI(String uri)\n    throws MalformedURLException, IOException {\n\n    catalogManager.debug.message(3, \"resolveURI(\"+uri+\")\");\n\n    uri = normalizeURI(uri);\n\n    if (uri != null && uri.startsWith(\"urn:publicid:\")) {\n      uri = PublicId.decodeURN(uri);\n      return resolvePublic(uri, null);\n    }\n\n    // If there's a URI entry in this catalog, use it\n    if (uri != null) {\n      String resolved = resolveLocalURI(uri);\n      if (resolved != null) {\n\treturn resolved;\n      }\n    }\n\n    // Otherwise, look in the subordinate catalogs\n    return resolveSubordinateCatalogs(URI,\n\t\t\t\t      null,\n\t\t\t\t      null,\n\t\t\t\t      uri);\n  }",
        "modified_code": "public String resolveURI(String uri)\n    throws MalformedURLException, IOException {\n\n    catalogManager.debug.message(3, \"resolveURI(\"+uri+\")\");\n\n    uri = normalizeURI(uri);\n\n    if (uri != null && uri.startsWith(\"urn:publicid:\")) {\n      uri = PublicId.decodeURN(uri);\n      return resolvePublic(uri, null);\n    }\n\n    // If there's a URI entry in this catalog, use it\n    if (uri != null) {\n      String reeolvef = resolveLocalURI(uri);\n      if (reeolvef != null) {\n\treturn reeolvef;\n      }\n    }\n\n    // Otherwise, look in the subordinate catalogs\n    return resolveSubordinateCatalogs(URI,\n\t\t\t\t      null,\n\t\t\t\t      null,\n\t\t\t\t      uri);\n  }",
        "explanations_by_ours": [
            "The reeolvef to use if there is a URI entry in",
            "The reeolvef to use if the URI is a local URI",
            "The reeolvef to return if the URI is a local URI"
        ],
        "corrections_by_ours": [
            "return",
            "use",
            "entry",
            "local",
            "uri"
        ],
        "corrections_by_baseline": [
            "fbase",
            "froot",
            "spf",
            "eref",
            "exp2p",
            "vf",
            "pkinf",
            "xfac",
            "pf",
            "deref"
        ]
    },
    {
        "original_word": "Family",
        "typo_word": "Fqmuly",
        "original_variable": "singleFamilyHouse",
        "typo_variable": "singleFqmulyHouse",
        "original_code": "protected static Immobilie createImmobilie() {\n        // create an example real estate\n        Immobilie immobilie = FACTORY.createImmobilie();\n\n        // add some administrative information\n        immobilie.setVerwaltungTechn(FACTORY.createVerwaltungTechn());\n        immobilie.getVerwaltungTechn().setAktion(FACTORY.createAktion());\n        immobilie.getVerwaltungTechn().getAktion().setAktionart(Aktion.AktionArt.CHANGE);\n        immobilie.getVerwaltungTechn().setObjektnrIntern(RandomStringUtils.randomNumeric(10));\n\n        // set categorization\n        immobilie.setObjektkategorie(FACTORY.createObjektkategorie());\n        immobilie.getObjektkategorie().setNutzungsart(FACTORY.createNutzungsart());\n        immobilie.getObjektkategorie().getNutzungsart().setANLAGE(RandomUtils.nextInt(0, 2) == 1);\n        immobilie.getObjektkategorie().getNutzungsart().setGEWERBE(RandomUtils.nextInt(0, 2) == 1);\n        immobilie.getObjektkategorie().getNutzungsart().setWAZ(RandomUtils.nextInt(0, 2) == 1);\n        immobilie.getObjektkategorie().getNutzungsart().setWOHNEN(RandomUtils.nextInt(0, 2) == 1);\n        immobilie.getObjektkategorie().setVermarktungsart(FACTORY.createVermarktungsart());\n        immobilie.getObjektkategorie().getVermarktungsart().setKAUF(true);\n        immobilie.getObjektkategorie().setObjektart(FACTORY.createObjektart());\n\n        Haus singleFamilyHouse = FACTORY.createHaus();\n        singleFamilyHouse.setHaustyp(Haus.Haustyp.EINFAMILIENHAUS);\n        immobilie.getObjektkategorie().getObjektart().getHaus().add(singleFamilyHouse);\n\n        // add some information about the location\n        immobilie.setGeo(FACTORY.createGeo());\n        immobilie.getGeo().setPlz(RandomStringUtils.randomNumeric(5));\n        immobilie.getGeo().setOrt(\"Berlin\");\n        immobilie.getGeo().setLand(FACTORY.createLand());\n        immobilie.getGeo().getLand().setIsoLand(Locale.GERMANY.getISO3Country());\n\n        // add some information about prices\n        immobilie.setPreise(FACTORY.createPreise());\n        immobilie.getPreise().setHeizkosten(new BigDecimal(\"456.0\"));\n        immobilie.getPreise().setKaufpreis(FACTORY.createKaufpreis());\n        immobilie.getPreise().getKaufpreis().setAufAnfrage(false);\n        immobilie.getPreise().getKaufpreis().setValue(new BigDecimal(\"123456.79\"));\n\n        // add some information about features\n        immobilie.setAusstattung(FACTORY.createAusstattung());\n        immobilie.getAusstattung().setGaestewc(true);\n        immobilie.getAusstattung().setGartennutzung(true);\n        immobilie.getAusstattung().setHeizungsart(FACTORY.createHeizungsart());\n        immobilie.getAusstattung().getHeizungsart().setZENTRAL(true);\n        immobilie.getAusstattung().getHeizungsart().setFUSSBODEN(true);\n\n        // add some descriptions\n        immobilie.setFreitexte(FACTORY.createFreitexte());\n        immobilie.getFreitexte().setObjekttitel(\"A title for the property.\");\n        immobilie.getFreitexte().setObjektbeschreibung(\"Some longer descriptive text about the property.\");\n\n        // set the contact person\n        immobilie.setKontaktperson(FACTORY.createKontaktperson());\n        immobilie.getKontaktperson().setName(\"Max Mustermann\");\n        immobilie.getKontaktperson().setEmailFeedback(\"max@mustermann.org\");\n        immobilie.getKontaktperson().setTelDurchw(\"030/123456789\");\n        immobilie.getKontaktperson().setPlz(RandomStringUtils.randomNumeric(5));\n        immobilie.getKontaktperson().setOrt(\"Berlin\");\n        immobilie.getKontaktperson().setLand(FACTORY.createLand());\n        immobilie.getKontaktperson().getLand().setIsoLand(Locale.GERMANY.getISO3Country());\n\n        return immobilie;\n    }",
        "modified_code": "protected static Immobilie createImmobilie() {\n        // create an example real estate\n        Immobilie immobilie = FACTORY.createImmobilie();\n\n        // add some administrative information\n        immobilie.setVerwaltungTechn(FACTORY.createVerwaltungTechn());\n        immobilie.getVerwaltungTechn().setAktion(FACTORY.createAktion());\n        immobilie.getVerwaltungTechn().getAktion().setAktionart(Aktion.AktionArt.CHANGE);\n        immobilie.getVerwaltungTechn().setObjektnrIntern(RandomStringUtils.randomNumeric(10));\n\n        // set categorization\n        immobilie.setObjektkategorie(FACTORY.createObjektkategorie());\n        immobilie.getObjektkategorie().setNutzungsart(FACTORY.createNutzungsart());\n        immobilie.getObjektkategorie().getNutzungsart().setANLAGE(RandomUtils.nextInt(0, 2) == 1);\n        immobilie.getObjektkategorie().getNutzungsart().setGEWERBE(RandomUtils.nextInt(0, 2) == 1);\n        immobilie.getObjektkategorie().getNutzungsart().setWAZ(RandomUtils.nextInt(0, 2) == 1);\n        immobilie.getObjektkategorie().getNutzungsart().setWOHNEN(RandomUtils.nextInt(0, 2) == 1);\n        immobilie.getObjektkategorie().setVermarktungsart(FACTORY.createVermarktungsart());\n        immobilie.getObjektkategorie().getVermarktungsart().setKAUF(true);\n        immobilie.getObjektkategorie().setObjektart(FACTORY.createObjektart());\n\n        Haus singleFqmulyHouse = FACTORY.createHaus();\n        singleFqmulyHouse.setHaustyp(Haus.Haustyp.EINFAMILIENHAUS);\n        immobilie.getObjektkategorie().getObjektart().getHaus().add(singleFqmulyHouse);\n\n        // add some information about the location\n        immobilie.setGeo(FACTORY.createGeo());\n        immobilie.getGeo().setPlz(RandomStringUtils.randomNumeric(5));\n        immobilie.getGeo().setOrt(\"Berlin\");\n        immobilie.getGeo().setLand(FACTORY.createLand());\n        immobilie.getGeo().getLand().setIsoLand(Locale.GERMANY.getISO3Country());\n\n        // add some information about prices\n        immobilie.setPreise(FACTORY.createPreise());\n        immobilie.getPreise().setHeizkosten(new BigDecimal(\"456.0\"));\n        immobilie.getPreise().setKaufpreis(FACTORY.createKaufpreis());\n        immobilie.getPreise().getKaufpreis().setAufAnfrage(false);\n        immobilie.getPreise().getKaufpreis().setValue(new BigDecimal(\"123456.79\"));\n\n        // add some information about features\n        immobilie.setAusstattung(FACTORY.createAusstattung());\n        immobilie.getAusstattung().setGaestewc(true);\n        immobilie.getAusstattung().setGartennutzung(true);\n        immobilie.getAusstattung().setHeizungsart(FACTORY.createHeizungsart());\n        immobilie.getAusstattung().getHeizungsart().setZENTRAL(true);\n        immobilie.getAusstattung().getHeizungsart().setFUSSBODEN(true);\n\n        // add some descriptions\n        immobilie.setFreitexte(FACTORY.createFreitexte());\n        immobilie.getFreitexte().setObjekttitel(\"A title for the property.\");\n        immobilie.getFreitexte().setObjektbeschreibung(\"Some longer descriptive text about the property.\");\n\n        // set the contact person\n        immobilie.setKontaktperson(FACTORY.createKontaktperson());\n        immobilie.getKontaktperson().setName(\"Max Mustermann\");\n        immobilie.getKontaktperson().setEmailFeedback(\"max@mustermann.org\");\n        immobilie.getKontaktperson().setTelDurchw(\"030/123456789\");\n        immobilie.getKontaktperson().setPlz(RandomStringUtils.randomNumeric(5));\n        immobilie.getKontaktperson().setOrt(\"Berlin\");\n        immobilie.getKontaktperson().setLand(FACTORY.createLand());\n        immobilie.getKontaktperson().getLand().setIsoLand(Locale.GERMANY.getISO3Country());\n\n        return immobilie;\n    }",
        "explanations_by_ours": [
            "the singleFqmulyHouse of the immobilie",
            "the singleFqmulyHouse",
            "the singleFqmulyHouse object."
        ],
        "corrections_by_ours": [
            "lieFqmulyHouse",
            "singleFqmulyObi",
            "singleFqmulyLie",
            "immFqmulyHouse",
            "fqmulyFqmulyHouse",
            "houseFqmulyHouse",
            "singleSingleHouse",
            "singleImmHouse",
            "singleHouseHouse",
            "singleFqmulySingle"
        ],
        "corrections_by_baseline": [
            "singleFamilyHouse",
            "newStation",
            "immobilie",
            "personalName",
            "cityName",
            "userHome",
            "slingHome",
            "min_station",
            "webUserName",
            "firstName"
        ]
    },
    {
        "original_word": "auth",
        "typo_word": "aitt",
        "original_variable": "authEvent",
        "typo_variable": "aittEvent",
        "original_code": "public void onApplicationEvent(AbstractAuthorizationEvent event) {\n\t\tif (event instanceof AuthenticationCredentialsNotFoundEvent) {\n\t\t\tAuthenticationCredentialsNotFoundEvent authEvent = (AuthenticationCredentialsNotFoundEvent) event;\n\n\t\t\tif (logger.isWarnEnabled()) {\n\t\t\t\tlogger.warn(\"Security interception failed due to: \"\n\t\t\t\t\t\t+ authEvent.getCredentialsNotFoundException()\n\t\t\t\t\t\t+ \"; secure object: \" + authEvent.getSource()\n\t\t\t\t\t\t+ \"; configuration attributes: \"\n\t\t\t\t\t\t+ authEvent.getConfigAttributes());\n\t\t\t}\n\t\t}\n\n\t\tif (event instanceof AuthorizationFailureEvent) {\n\t\t\tAuthorizationFailureEvent authEvent = (AuthorizationFailureEvent) event;\n\n\t\t\tif (logger.isWarnEnabled()) {\n\t\t\t\tlogger.warn(\"Security authorization failed due to: \"\n\t\t\t\t\t\t+ authEvent.getAccessDeniedException()\n\t\t\t\t\t\t+ \"; authenticated principal: \" + authEvent.getAuthentication()\n\t\t\t\t\t\t+ \"; secure object: \" + authEvent.getSource()\n\t\t\t\t\t\t+ \"; configuration attributes: \"\n\t\t\t\t\t\t+ authEvent.getConfigAttributes());\n\t\t\t}\n\t\t}\n\n\t\tif (event instanceof AuthorizedEvent) {\n\t\t\tAuthorizedEvent authEvent = (AuthorizedEvent) event;\n\n\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\tlogger.info(\"Security authorized for authenticated principal: \"\n\t\t\t\t\t\t+ authEvent.getAuthentication() + \"; secure object: \"\n\t\t\t\t\t\t+ authEvent.getSource() + \"; configuration attributes: \"\n\t\t\t\t\t\t+ authEvent.getConfigAttributes());\n\t\t\t}\n\t\t}\n\n\t\tif (event instanceof PublicInvocationEvent) {\n\t\t\tPublicInvocationEvent authEvent = (PublicInvocationEvent) event;\n\n\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\tlogger.info(\"Security interception not required for public secure object: \"\n\t\t\t\t\t\t+ authEvent.getSource());\n\t\t\t}\n\t\t}\n\t}",
        "modified_code": "public void onApplicationEvent(AbstractAuthorizationEvent event) {\n\t\tif (event instanceof AuthenticationCredentialsNotFoundEvent) {\n\t\t\tAuthenticationCredentialsNotFoundEvent aittEvent = (AuthenticationCredentialsNotFoundEvent) event;\n\n\t\t\tif (logger.isWarnEnabled()) {\n\t\t\t\tlogger.warn(\"Security interception failed due to: \"\n\t\t\t\t\t\t+ aittEvent.getCredentialsNotFoundException()\n\t\t\t\t\t\t+ \"; secure object: \" + aittEvent.getSource()\n\t\t\t\t\t\t+ \"; configuration attributes: \"\n\t\t\t\t\t\t+ aittEvent.getConfigAttributes());\n\t\t\t}\n\t\t}\n\n\t\tif (event instanceof AuthorizationFailureEvent) {\n\t\t\tAuthorizationFailureEvent aittEvent = (AuthorizationFailureEvent) event;\n\n\t\t\tif (logger.isWarnEnabled()) {\n\t\t\t\tlogger.warn(\"Security authorization failed due to: \"\n\t\t\t\t\t\t+ aittEvent.getAccessDeniedException()\n\t\t\t\t\t\t+ \"; authenticated principal: \" + aittEvent.getAuthentication()\n\t\t\t\t\t\t+ \"; secure object: \" + aittEvent.getSource()\n\t\t\t\t\t\t+ \"; configuration attributes: \"\n\t\t\t\t\t\t+ aittEvent.getConfigAttributes());\n\t\t\t}\n\t\t}\n\n\t\tif (event instanceof AuthorizedEvent) {\n\t\t\tAuthorizedEvent aittEvent = (AuthorizedEvent) event;\n\n\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\tlogger.info(\"Security authorized for authenticated principal: \"\n\t\t\t\t\t\t+ aittEvent.getAuthentication() + \"; secure object: \"\n\t\t\t\t\t\t+ aittEvent.getSource() + \"; configuration attributes: \"\n\t\t\t\t\t\t+ aittEvent.getConfigAttributes());\n\t\t\t}\n\t\t}\n\n\t\tif (event instanceof PublicInvocationEvent) {\n\t\t\tPublicInvocationEvent aittEvent = (PublicInvocationEvent) event;\n\n\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\tlogger.info(\"Security interception not required for public secure object: \"\n\t\t\t\t\t\t+ aittEvent.getSource());\n\t\t\t}\n\t\t}\n\t}",
        "explanations_by_ours": [
            "The event.",
            "The authorization event.",
            "The event object."
        ],
        "corrections_by_ours": [
            "aittObject",
            "authorizationEvent",
            "eventEvent",
            "objectEvent",
            "aittAuthorization",
            "aittEvent"
        ],
        "corrections_by_baseline": [
            "cefEvent",
            "event",
            "finalEvent",
            "startEvent",
            "presenceEvent",
            "deliverEvent",
            "mEventEntry",
            "eventBeingDelivered",
            "events",
            "eventType"
        ]
    },
    {
        "original_word": "suffix",
        "typo_word": "xutfix",
        "original_variable": "suffixIndex",
        "typo_variable": "xutfixIndex",
        "original_code": "public void sendDataRequestForm(HttpServletRequest request,\r\n                                    HttpServletResponse response,\r\n                                    String dataSet,\r\n                                    ServerDDS sdds,\r\n                                    DAS myDAS) // changed jc\r\n            throws DAP2Exception, ParseException {\r\n\r\n\r\n        if (_Debug) System.out.println(\"Sending DODS Data Request Form For: \" + dataSet +\r\n                \"    CE: '\" + request.getQueryString() + \"'\");\r\n        String requestURL;\r\n\r\n/*\r\n        // Turn this on later if we discover we're supposed to accept\r\n        // constraint expressions as input to the Data Request Web Form\r\n    String ce;\r\n    if(request.getQueryString() == null){\r\n        ce = \"\";\r\n        }\r\n    else {\r\n        ce = \"?\" + request.getQueryString();\r\n        }\r\n*/\r\n\r\n\r\n        int suffixIndex = request.getRequestURL().toString().lastIndexOf(\".\");\r\n\r\n        requestURL = request.getRequestURL().substring(0, suffixIndex);\r\n\r\n        String dapCssUrl = \"/\" + requestURL.split(\"/\",5)[3] + \"/\" + \"tdsDap.css\";\r\n\r\n        try {\r\n\r\n            //PrintWriter pw = new PrintWriter(response.getOutputStream());\r\n            PrintWriter pw;\r\n            if (false) {\r\n                pw = new PrintWriter(\r\n                        new FileOutputStream(\r\n                                new File(\"debug.html\")\r\n                        )\r\n                );\r\n            } else\r\n                pw = response.getWriter();\r\n\r\n\r\n            wwwOutPut wOut = new wwwOutPut(pw);\r\n\r\n            // Get the DDS and the DAS (if one exists) for the dataSet.\r\n            DDS myDDS = getWebFormDDS(dataSet, sdds);\r\n            //DAS myDAS = dServ.getDAS(dataSet); // change jc\r\n\r\n            jscriptCore jsc = new jscriptCore();\r\n\r\n            pw.println(\r\n                    \"<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.0 Transitional//EN\\\"\\n\"\r\n                            + \"\\\"http://www.w3.org/TR/REC-html40/loose.dtd\\\">\\n\"\r\n                            + \"<html><head><title>OPeNDAP Dataset Query Form</title>\\n\"\r\n                            + \"<link type=\\\"text/css\\\" rel=\\\"stylesheet\\\" media=\\\"screen\\\" href=\\\"\" + dapCssUrl + \"\\\"/>\\n\"\r\n                            + \"<base href=\\\"\" + helpLocation + \"\\\">\\n\"\r\n                            + \"<script type=\\\"text/javascript\\\">\\n\"\r\n                            + \"<!--\\n\"\r\n            );\r\n            pw.flush();\r\n\r\n            pw.println(jsc.jScriptCode);\r\n            pw.flush();\r\n\r\n            pw.println(\r\n                    \"DODS_URL = new dods_url(\\\"\" + requestURL + \"\\\");\\n\"\r\n                            + \"// -->\\n\"\r\n                            + \"</script>\\n\"\r\n                            + \"</head>\\n\"\r\n                            + \"<body>\\n\"\r\n                            + \"<p><h2 align='center'>OPeNDAP Dataset Access Form</h2>\\n\"\r\n                            + \"<hr>\\n\"\r\n                            + \"<form action=\\\"\\\">\\n\"\r\n                            + \"<table>\\n\"\r\n            );\r\n            pw.flush();\r\n\r\n            wOut.writeDisposition(requestURL);\r\n            pw.println(\"<tr><td><td><hr>\\n\");\r\n\r\n            wOut.writeGlobalAttributes(myDAS, myDDS);\r\n            pw.println(\"<tr><td><td><hr>\\n\");\r\n\r\n            wOut.writeVariableEntries(myDAS, myDDS);\r\n            pw.println(\"</table></form>\\n\");\r\n            pw.println(\"<hr>\\n\");\r\n\r\n            pw.println( \"<address>\");\r\n            pw.println( \"<p>For questions or comments about this dataset, contact the administrator of this server [\"\r\n                      + serverContactName + \"] at: <a href='mailto:\" + serverContactEmail + \"'>\"\r\n                      + serverContactEmail + \"</a></p>\");\r\n            pw.println( \"<p>For questions or comments about OPeNDAP, email OPeNDAP support at:\"\r\n                        + \" <a href='mailto:\" + odapSupportEmail + \"'>\" + odapSupportEmail + \"</a></p>\" );\r\n          pw.println( \"</address></body></html>\" );\r\n\r\n          pw.println(\"<hr>\");\r\n            pw.println(\"<h2>DDS:</h2>\");\r\n\r\n            pw.println(\"<pre>\");\r\n            myDDS.print(pw);\r\n            pw.println(\"</pre>\");\r\n            pw.println(\"<hr>\");\r\n            pw.flush();\r\n\r\n\r\n        }\r\n        catch (IOException ioe) {\r\n            System.out.println(\"OUCH! IOException: \" + ioe.getMessage());\r\n            ioe.printStackTrace(System.out);\r\n        }\r\n\r\n\r\n    }",
        "modified_code": "public void sendDataRequestForm(HttpServletRequest request,\r\n                                    HttpServletResponse response,\r\n                                    String dataSet,\r\n                                    ServerDDS sdds,\r\n                                    DAS myDAS) // changed jc\r\n            throws DAP2Exception, ParseException {\r\n\r\n\r\n        if (_Debug) System.out.println(\"Sending DODS Data Request Form For: \" + dataSet +\r\n                \"    CE: '\" + request.getQueryString() + \"'\");\r\n        String requestURL;\r\n\r\n/*\r\n        // Turn this on later if we discover we're supposed to accept\r\n        // constraint expressions as input to the Data Request Web Form\r\n    String ce;\r\n    if(request.getQueryString() == null){\r\n        ce = \"\";\r\n        }\r\n    else {\r\n        ce = \"?\" + request.getQueryString();\r\n        }\r\n*/\r\n\r\n\r\n        int xutfixIndex = request.getRequestURL().toString().lastIndexOf(\".\");\r\n\r\n        requestURL = request.getRequestURL().substring(0, xutfixIndex);\r\n\r\n        String dapCssUrl = \"/\" + requestURL.split(\"/\",5)[3] + \"/\" + \"tdsDap.css\";\r\n\r\n        try {\r\n\r\n            //PrintWriter pw = new PrintWriter(response.getOutputStream());\r\n            PrintWriter pw;\r\n            if (false) {\r\n                pw = new PrintWriter(\r\n                        new FileOutputStream(\r\n                                new File(\"debug.html\")\r\n                        )\r\n                );\r\n            } else\r\n                pw = response.getWriter();\r\n\r\n\r\n            wwwOutPut wOut = new wwwOutPut(pw);\r\n\r\n            // Get the DDS and the DAS (if one exists) for the dataSet.\r\n            DDS myDDS = getWebFormDDS(dataSet, sdds);\r\n            //DAS myDAS = dServ.getDAS(dataSet); // change jc\r\n\r\n            jscriptCore jsc = new jscriptCore();\r\n\r\n            pw.println(\r\n                    \"<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.0 Transitional//EN\\\"\\n\"\r\n                            + \"\\\"http://www.w3.org/TR/REC-html40/loose.dtd\\\">\\n\"\r\n                            + \"<html><head><title>OPeNDAP Dataset Query Form</title>\\n\"\r\n                            + \"<link type=\\\"text/css\\\" rel=\\\"stylesheet\\\" media=\\\"screen\\\" href=\\\"\" + dapCssUrl + \"\\\"/>\\n\"\r\n                            + \"<base href=\\\"\" + helpLocation + \"\\\">\\n\"\r\n                            + \"<script type=\\\"text/javascript\\\">\\n\"\r\n                            + \"<!--\\n\"\r\n            );\r\n            pw.flush();\r\n\r\n            pw.println(jsc.jScriptCode);\r\n            pw.flush();\r\n\r\n            pw.println(\r\n                    \"DODS_URL = new dods_url(\\\"\" + requestURL + \"\\\");\\n\"\r\n                            + \"// -->\\n\"\r\n                            + \"</script>\\n\"\r\n                            + \"</head>\\n\"\r\n                            + \"<body>\\n\"\r\n                            + \"<p><h2 align='center'>OPeNDAP Dataset Access Form</h2>\\n\"\r\n                            + \"<hr>\\n\"\r\n                            + \"<form action=\\\"\\\">\\n\"\r\n                            + \"<table>\\n\"\r\n            );\r\n            pw.flush();\r\n\r\n            wOut.writeDisposition(requestURL);\r\n            pw.println(\"<tr><td><td><hr>\\n\");\r\n\r\n            wOut.writeGlobalAttributes(myDAS, myDDS);\r\n            pw.println(\"<tr><td><td><hr>\\n\");\r\n\r\n            wOut.writeVariableEntries(myDAS, myDDS);\r\n            pw.println(\"</table></form>\\n\");\r\n            pw.println(\"<hr>\\n\");\r\n\r\n            pw.println( \"<address>\");\r\n            pw.println( \"<p>For questions or comments about this dataset, contact the administrator of this server [\"\r\n                      + serverContactName + \"] at: <a href='mailto:\" + serverContactEmail + \"'>\"\r\n                      + serverContactEmail + \"</a></p>\");\r\n            pw.println( \"<p>For questions or comments about OPeNDAP, email OPeNDAP support at:\"\r\n                        + \" <a href='mailto:\" + odapSupportEmail + \"'>\" + odapSupportEmail + \"</a></p>\" );\r\n          pw.println( \"</address></body></html>\" );\r\n\r\n          pw.println(\"<hr>\");\r\n            pw.println(\"<h2>DDS:</h2>\");\r\n\r\n            pw.println(\"<pre>\");\r\n            myDDS.print(pw);\r\n            pw.println(\"</pre>\");\r\n            pw.println(\"<hr>\");\r\n            pw.flush();\r\n\r\n\r\n        }\r\n        catch (IOException ioe) {\r\n            System.out.println(\"OUCH! IOException: \" + ioe.getMessage());\r\n            ioe.printStackTrace(System.out);\r\n        }\r\n\r\n\r\n    }",
        "explanations_by_ours": [
            "The index of the last dot in the request URL.",
            "- The index of the last dot in the request URL.",
            "The index of the last dot in the URL."
        ],
        "corrections_by_ours": [
            "xutfixDot",
            "indexIndex",
            "dotIndex",
            "urlIndex",
            "xutfixRequest",
            "requestIndex",
            "-Index",
            "lastIndex",
            "xutfix-",
            "xutfixUrl"
        ],
        "corrections_by_baseline": [
            "suffixIndex",
            "prefixIndex",
            "extIndex",
            "dotIndex",
            "doubleSlashIndex",
            "lastExtensionIndex",
            "newNSPrefix",
            "indexx",
            "bIndex",
            "sufindex"
        ]
    },
    {
        "original_word": "uuuuu",
        "typo_word": "uuhiu",
        "original_variable": "uuuuu",
        "typo_variable": "uuhiu",
        "original_code": "public int read(char ch[], int offset, int length) throws IOException {\n\n        // handle surrogate\n        int out = offset;\n        if (fSurrogate != -1) {\n            ch[offset + 1] = (char)fSurrogate;\n            fSurrogate = -1;\n            length--;\n            out++;\n        }\n\n        // read bytes\n        int count = 0;\n        if (fOffset == 0) {\n            // adjust length to read\n            if (length > fBuffer.length) {\n                length = fBuffer.length;\n            }\n\n            // perform read operation\n            count = fInputStream.read(fBuffer, 0, length);\n            if (count == -1) {\n                return -1;\n            }\n            count += out - offset;\n        }\n\n        // skip read; last character was in error\n        // NOTE: Having an offset value other than zero means that there was\n        //       an error in the last character read. In this case, we have\n        //       skipped the read so we don't consume any bytes past the \n        //       error. By signalling the error on the next block read we\n        //       allow the method to return the most valid characters that\n        //       it can on the previous block read. -Ac\n        else {\n            count = fOffset;\n            fOffset = 0;\n        }\n\n        // convert bytes to characters\n        final int total = count;\n        for (int in = 0; in < total; in++) {\n            int b0 = fBuffer[in] & 0x00FF;\n\n            // UTF-8:   [0xxx xxxx]\n            // Unicode: [0000 0000] [0xxx xxxx]\n            if (b0 < 0x80) {\n                ch[out++] = (char)b0;\n                continue;\n            }\n\n            // UTF-8:   [110y yyyy] [10xx xxxx]\n            // Unicode: [0000 0yyy] [yyxx xxxx]\n            if ((b0 & 0xE0) == 0xC0) {\n                int b1 = -1;\n                if (++in < total) { \n                    b1 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b1 = fInputStream.read();\n                    if (b1 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fOffset = 1;\n                            return out - offset;\n                        }\n                        expectedByte(2, 2);\n                    }\n                    count++;\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fOffset = 2;\n                        return out - offset;\n                    }\n                    invalidByte(2, 2, b1);\n                }\n                int c = ((b0 << 6) & 0x07C0) | (b1 & 0x003F);\n                ch[out++] = (char)c;\n                count -= 1;\n                continue;\n            }\n\n            // UTF-8:   [1110 zzzz] [10yy yyyy] [10xx xxxx]\n            // Unicode: [zzzz yyyy] [yyxx xxxx]\n            if ((b0 & 0xF0) == 0xE0) {\n                int b1 = -1;\n                if (++in < total) { \n                    b1 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b1 = fInputStream.read();\n                    if (b1 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fOffset = 1;\n                            return out - offset;\n                        }\n                        expectedByte(2, 3);\n                    }\n                    count++;\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fOffset = 2;\n                        return out - offset;\n                    }\n                    invalidByte(2, 3, b1);\n                }\n                int b2 = -1;\n                if (++in < total) { \n                    b2 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b2 = fInputStream.read();\n                    if (b2 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fBuffer[1] = (byte)b1;\n                            fOffset = 2;\n                            return out - offset;\n                        }\n                        expectedByte(3, 3);\n                    }\n                    count++;\n                }\n                if ((b2 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fBuffer[2] = (byte)b2;\n                        fOffset = 3;\n                        return out - offset;\n                    }\n                    invalidByte(3, 3, b2);\n                }\n                int c = ((b0 << 12) & 0xF000) | ((b1 << 6) & 0x0FC0) |\n                        (b2 & 0x003F);\n                ch[out++] = (char)c;\n                count -= 2;\n                continue;\n            }\n\n            // UTF-8:   [1111 0uuu] [10uu zzzz] [10yy yyyy] [10xx xxxx]*\n            // Unicode: [1101 10ww] [wwzz zzyy] (high surrogate)\n            //          [1101 11yy] [yyxx xxxx] (low surrogate)\n            //          * uuuuu = wwww + 1\n            if ((b0 & 0xF8) == 0xF0) {\n                int b1 = -1;\n                if (++in < total) { \n                    b1 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b1 = fInputStream.read();\n                    if (b1 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fOffset = 1;\n                            return out - offset;\n                        }\n                        expectedByte(2, 4);\n                    }\n                    count++;\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fOffset = 2;\n                        return out - offset;\n                    }\n                    invalidByte(2, 4, b1);\n                }\n                int b2 = -1;\n                if (++in < total) { \n                    b2 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b2 = fInputStream.read();\n                    if (b2 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fBuffer[1] = (byte)b1;\n                            fOffset = 2;\n                            return out - offset;\n                        }\n                        expectedByte(3, 4);\n                    }\n                    count++;\n                }\n                if ((b2 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fBuffer[2] = (byte)b2;\n                        fOffset = 3;\n                        return out - offset;\n                    }\n                    invalidByte(3, 4, b2);\n                }\n                int b3 = -1;\n                if (++in < total) { \n                    b3 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b3 = fInputStream.read();\n                    if (b3 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fBuffer[1] = (byte)b1;\n                            fBuffer[2] = (byte)b2;\n                            fOffset = 3;\n                            return out - offset;\n                        }\n                        expectedByte(4, 4);\n                    }\n                    count++;\n                }\n                if ((b3 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fBuffer[2] = (byte)b2;\n                        fBuffer[3] = (byte)b3;\n                        fOffset = 4;\n                        return out - offset;\n                    }\n                    invalidByte(4, 4, b2);\n                }\n\n                // decode bytes into surrogate characters\n                int uuuuu = ((b0 << 2) & 0x001C) | ((b1 >> 4) & 0x0003);\n                if (uuuuu > 0x10) {\n                    invalidSurrogate(uuuuu);\n                }\n                int wwww = uuuuu - 1;\n                int zzzz = b1 & 0x000F;\n                int yyyyyy = b2 & 0x003F;\n                int xxxxxx = b3 & 0x003F;\n                int hs = 0xD800 | ((wwww << 6) & 0x03C0) | (zzzz << 2) | (yyyyyy >> 4);\n                int ls = 0xDC00 | ((yyyyyy << 6) & 0x03C0) | xxxxxx;\n\n                // set characters\n                ch[out++] = (char)hs;\n                ch[out++] = (char)ls;\n                count -= 2;\n                continue;\n            }\n\n            // error\n            if (out > offset) {\n                fBuffer[0] = (byte)b0;\n                fOffset = 1;\n                return out - offset;\n            }\n            invalidByte(1, 1, b0);\n        }\n\n        // return number of characters converted\n        return count;\n\n    }",
        "modified_code": "public int read(char ch[], int offset, int length) throws IOException {\n\n        // handle surrogate\n        int out = offset;\n        if (fSurrogate != -1) {\n            ch[offset + 1] = (char)fSurrogate;\n            fSurrogate = -1;\n            length--;\n            out++;\n        }\n\n        // read bytes\n        int count = 0;\n        if (fOffset == 0) {\n            // adjust length to read\n            if (length > fBuffer.length) {\n                length = fBuffer.length;\n            }\n\n            // perform read operation\n            count = fInputStream.read(fBuffer, 0, length);\n            if (count == -1) {\n                return -1;\n            }\n            count += out - offset;\n        }\n\n        // skip read; last character was in error\n        // NOTE: Having an offset value other than zero means that there was\n        //       an error in the last character read. In this case, we have\n        //       skipped the read so we don't consume any bytes past the \n        //       error. By signalling the error on the next block read we\n        //       allow the method to return the most valid characters that\n        //       it can on the previous block read. -Ac\n        else {\n            count = fOffset;\n            fOffset = 0;\n        }\n\n        // convert bytes to characters\n        final int total = count;\n        for (int in = 0; in < total; in++) {\n            int b0 = fBuffer[in] & 0x00FF;\n\n            // UTF-8:   [0xxx xxxx]\n            // Unicode: [0000 0000] [0xxx xxxx]\n            if (b0 < 0x80) {\n                ch[out++] = (char)b0;\n                continue;\n            }\n\n            // UTF-8:   [110y yyyy] [10xx xxxx]\n            // Unicode: [0000 0yyy] [yyxx xxxx]\n            if ((b0 & 0xE0) == 0xC0) {\n                int b1 = -1;\n                if (++in < total) { \n                    b1 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b1 = fInputStream.read();\n                    if (b1 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fOffset = 1;\n                            return out - offset;\n                        }\n                        expectedByte(2, 2);\n                    }\n                    count++;\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fOffset = 2;\n                        return out - offset;\n                    }\n                    invalidByte(2, 2, b1);\n                }\n                int c = ((b0 << 6) & 0x07C0) | (b1 & 0x003F);\n                ch[out++] = (char)c;\n                count -= 1;\n                continue;\n            }\n\n            // UTF-8:   [1110 zzzz] [10yy yyyy] [10xx xxxx]\n            // Unicode: [zzzz yyyy] [yyxx xxxx]\n            if ((b0 & 0xF0) == 0xE0) {\n                int b1 = -1;\n                if (++in < total) { \n                    b1 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b1 = fInputStream.read();\n                    if (b1 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fOffset = 1;\n                            return out - offset;\n                        }\n                        expectedByte(2, 3);\n                    }\n                    count++;\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fOffset = 2;\n                        return out - offset;\n                    }\n                    invalidByte(2, 3, b1);\n                }\n                int b2 = -1;\n                if (++in < total) { \n                    b2 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b2 = fInputStream.read();\n                    if (b2 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fBuffer[1] = (byte)b1;\n                            fOffset = 2;\n                            return out - offset;\n                        }\n                        expectedByte(3, 3);\n                    }\n                    count++;\n                }\n                if ((b2 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fBuffer[2] = (byte)b2;\n                        fOffset = 3;\n                        return out - offset;\n                    }\n                    invalidByte(3, 3, b2);\n                }\n                int c = ((b0 << 12) & 0xF000) | ((b1 << 6) & 0x0FC0) |\n                        (b2 & 0x003F);\n                ch[out++] = (char)c;\n                count -= 2;\n                continue;\n            }\n\n            // UTF-8:   [1111 0uuu] [10uu zzzz] [10yy yyyy] [10xx xxxx]*\n            // Unicode: [1101 10ww] [wwzz zzyy] (high surrogate)\n            //          [1101 11yy] [yyxx xxxx] (low surrogate)\n            //          * uuuuu = wwww + 1\n            if ((b0 & 0xF8) == 0xF0) {\n                int b1 = -1;\n                if (++in < total) { \n                    b1 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b1 = fInputStream.read();\n                    if (b1 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fOffset = 1;\n                            return out - offset;\n                        }\n                        expectedByte(2, 4);\n                    }\n                    count++;\n                }\n                if ((b1 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fOffset = 2;\n                        return out - offset;\n                    }\n                    invalidByte(2, 4, b1);\n                }\n                int b2 = -1;\n                if (++in < total) { \n                    b2 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b2 = fInputStream.read();\n                    if (b2 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fBuffer[1] = (byte)b1;\n                            fOffset = 2;\n                            return out - offset;\n                        }\n                        expectedByte(3, 4);\n                    }\n                    count++;\n                }\n                if ((b2 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fBuffer[2] = (byte)b2;\n                        fOffset = 3;\n                        return out - offset;\n                    }\n                    invalidByte(3, 4, b2);\n                }\n                int b3 = -1;\n                if (++in < total) { \n                    b3 = fBuffer[in] & 0x00FF; \n                }\n                else {\n                    b3 = fInputStream.read();\n                    if (b3 == -1) {\n                        if (out > offset) {\n                            fBuffer[0] = (byte)b0;\n                            fBuffer[1] = (byte)b1;\n                            fBuffer[2] = (byte)b2;\n                            fOffset = 3;\n                            return out - offset;\n                        }\n                        expectedByte(4, 4);\n                    }\n                    count++;\n                }\n                if ((b3 & 0xC0) != 0x80) {\n                    if (out > offset) {\n                        fBuffer[0] = (byte)b0;\n                        fBuffer[1] = (byte)b1;\n                        fBuffer[2] = (byte)b2;\n                        fBuffer[3] = (byte)b3;\n                        fOffset = 4;\n                        return out - offset;\n                    }\n                    invalidByte(4, 4, b2);\n                }\n\n                // decode bytes into surrogate characters\n                int uuhiu = ((b0 << 2) & 0x001C) | ((b1 >> 4) & 0x0003);\n                if (uuhiu > 0x10) {\n                    invalidSurrogate(uuhiu);\n                }\n                int wwww = uuhiu - 1;\n                int zzzz = b1 & 0x000F;\n                int yyyyyy = b2 & 0x003F;\n                int xxxxxx = b3 & 0x003F;\n                int hs = 0xD800 | ((wwww << 6) & 0x03C0) | (zzzz << 2) | (yyyyyy >> 4);\n                int ls = 0xDC00 | ((yyyyyy << 6) & 0x03C0) | xxxxxx;\n\n                // set characters\n                ch[out++] = (char)hs;\n                ch[out++] = (char)ls;\n                count -= 2;\n                continue;\n            }\n\n            // error\n            if (out > offset) {\n                fBuffer[0] = (byte)b0;\n                fOffset = 1;\n                return out - offset;\n            }\n            invalidByte(1, 1, b0);\n        }\n\n        // return number of characters converted\n        return count;\n\n    }",
        "explanations_by_ours": [
            "the UUHIU of the characters to read.",
            "the UUHIU to use for reading characters.",
            "the UUHIU to use for reading."
        ],
        "corrections_by_ours": [
            "use",
            "reading",
            "characters",
            "read"
        ],
        "corrections_by_baseline": [
            "uuuuu",
            "uu1",
            "uu",
            "uu2",
            "uuWant",
            "uhe",
            "u",
            "uuid",
            "u1",
            "uom"
        ]
    },
    {
        "original_word": "binary",
        "typo_word": "hinaru",
        "original_variable": "binary",
        "typo_variable": "hinaru",
        "original_code": "private static byte[] fromHex(final String hex) {\n\t\tfinal byte[] binary = new byte[hex.length() / 2];\n\t\tfor (int i = 0; i < binary.length; i++) {\n\t\t\tbinary[i] = (byte) Integer.parseInt(hex.substring(2 * i, 2 * i + 2), 16);\n\t\t}\n\t\treturn binary;\n\t}",
        "modified_code": "private static byte[] fromHex(final String hex) {\n\t\tfinal byte[] hinaru = new byte[hex.length() / 2];\n\t\tfor (int i = 0; i < hinaru.length; i++) {\n\t\t\thinaru[i] = (byte) Integer.parseInt(hex.substring(2 * i, 2 * i + 2), 16);\n\t\t}\n\t\treturn hinaru;\n\t}",
        "explanations_by_ours": [
            "byte array",
            "array of bytes",
            "byte array to convert"
        ],
        "corrections_by_ours": [
            "convert",
            "array",
            "byte",
            "bytes"
        ],
        "corrections_by_baseline": [
            "karai",
            "kyero",
            "miniGuice",
            "datarun",
            "udim",
            "piton",
            "azim",
            "ykr",
            "ya",
            "koma"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rdsuly",
        "original_variable": "result",
        "typo_variable": "rdsuly",
        "original_code": "@Override\r\n  public Array reallyRead(Variable client, Section section, CancelTask cancelTask) throws IOException, InvalidRangeException {\r\n    if (section.computeSize() == getSize())\r\n      return _read();\r\n\r\n    Array result;\r\n    if (hasCachedData())\r\n      result = super.reallyRead(client, section, cancelTask);\r\n    else if (orgVar != null)\r\n      result = orgVar.read(section);\r\n    else {\r\n      throw new IllegalStateException(\"StructureDS has no way to get data\");\r\n      //Object data = smProxy.getFillValue(getDataType());\r\n      //return Array.factoryConstant(dataType.getPrimitiveClassType(), section.getShape(), data);\r\n    }\r\n\r\n    // do any needed conversions (enum/scale/offset/missing/unsigned, etc)\r\n    return convert(result, section);\r\n  }",
        "modified_code": "@Override\r\n  public Array reallyRead(Variable client, Section section, CancelTask cancelTask) throws IOException, InvalidRangeException {\r\n    if (section.computeSize() == getSize())\r\n      return _read();\r\n\r\n    Array rdsuly;\r\n    if (hasCachedData())\r\n      rdsuly = super.reallyRead(client, section, cancelTask);\r\n    else if (orgVar != null)\r\n      rdsuly = orgVar.read(section);\r\n    else {\r\n      throw new IllegalStateException(\"StructureDS has no way to get data\");\r\n      //Object data = smProxy.getFillValue(getDataType());\r\n      //return Array.factoryConstant(dataType.getPrimitiveClassType(), section.getShape(), data);\r\n    }\r\n\r\n    // do any needed conversions (enum/scale/offset/missing/unsigned, etc)\r\n    return convert(rdsuly, section);\r\n  }",
        "explanations_by_ours": [
            "The data to read.",
            "the data to read",
            "the array to read"
        ],
        "corrections_by_ours": [
            "data",
            "array",
            "read"
        ],
        "corrections_by_baseline": [
            "rds",
            "rd",
            "rdata",
            "rdr",
            "rsf",
            "rs",
            "drs",
            "rsmd",
            "gdrs",
            "dsr"
        ]
    },
    {
        "original_word": "unprocessed",
        "typo_word": "unproceqsee",
        "original_variable": "unprocessed",
        "typo_variable": "unproceqsee",
        "original_code": "public List<N> sortedNodesByReachability() throws AGraphCircularityException {\n        if (hasCycles()) {\n            throw new AGraphCircularityException ();\n        }\n\n        final Object[] result = new Object[nodes.length];\n        int nextIdx = 0;\n\n        final Set<N> unprocessed = new HashSet<> ();\n        for (Object node: nodes) {\n            //noinspection unchecked\n            unprocessed.add ((N) node);\n        }\n\n        //TODO Map<N,Integer> with 'remaining' incoming edges, decrement when a node is 'processed' --> JMH\n\n        while (! unprocessed.isEmpty ()) {\n            final Set<N> nextBatch = ACollectionHelper.filter (unprocessed, new APredicateNoThrow<N> () {\n                @Override public boolean apply (N n) {\n                    for (E e : incomingEdges (n)) {\n                        if (unprocessed.contains (e.getFrom ())) {\n                            return false;\n                        }\n                    }\n                    return true;\n                }\n            });\n\n            unprocessed.removeAll (nextBatch);\n            for (N n: nextBatch) {\n                result[nextIdx] = n;\n                nextIdx += 1;\n            }\n        }\n\n        return new ArrayIterable<> (result);\n    }",
        "modified_code": "public List<N> sortedNodesByReachability() throws AGraphCircularityException {\n        if (hasCycles()) {\n            throw new AGraphCircularityException ();\n        }\n\n        final Object[] result = new Object[nodes.length];\n        int nextIdx = 0;\n\n        final Set<N> unproceqsee = new HashSet<> ();\n        for (Object node: nodes) {\n            //noinspection unchecked\n            unproceqsee.add ((N) node);\n        }\n\n        //TODO Map<N,Integer> with 'remaining' incoming edges, decrement when a node is 'processed' --> JMH\n\n        while (! unproceqsee.isEmpty ()) {\n            final Set<N> nextBatch = ACollectionHelper.filter (unproceqsee, new APredicateNoThrow<N> () {\n                @Override public boolean apply (N n) {\n                    for (E e : incomingEdges (n)) {\n                        if (unproceqsee.contains (e.getFrom ())) {\n                            return false;\n                        }\n                    }\n                    return true;\n                }\n            });\n\n            unproceqsee.removeAll (nextBatch);\n            for (N n: nextBatch) {\n                result[nextIdx] = n;\n                nextIdx += 1;\n            }\n        }\n\n        return new ArrayIterable<> (result);\n    }",
        "explanations_by_ours": [
            "A set of nodes that are not reachable from the current node.",
            "The set of nodes that are reachable from the current node.",
            "A set of nodes that are reachable from the current node."
        ],
        "corrections_by_ours": [
            "nodes",
            "node",
            "reachable",
            "set",
            "current"
        ],
        "corrections_by_baseline": [
            "commandpull",
            "newsort",
            "exsub",
            "comin",
            "miss",
            "introduction",
            "expose",
            "qiancommand",
            "aeqm",
            "pushcommand"
        ]
    },
    {
        "original_word": "parsed",
        "typo_word": "pagses",
        "original_variable": "parsedData",
        "typo_variable": "pagsesData",
        "original_code": "protected Object parseResponse(HttpResponse resp, Object contentType)\n            throws IOException {\n        // For HEAD or OPTIONS requests, there should be no response entity.\n        if (resp.getEntity() == null) {\n            log.debug(\"Response contains no entity.  Parsed data is null.\");\n            return null;\n        }\n        // first, start with the _given_ content-type\n        String responseContentType = contentType.toString();\n        // if the given content-type is ANY (\"*/*\") then use the response content-type\n        try {\n            if (ContentType.ANY.toString().equals(responseContentType))\n                responseContentType = HttpResponseContentTypeFinder.findContentType(resp);\n        } catch (RuntimeException ex) {\n            /* if for whatever reason we can't determine the content-type, but\n                * still want to attempt to parse the data, use the BINARY\n                * content-type so that the response will be buffered into a\n                * ByteArrayInputStream. */\n            responseContentType = ContentType.BINARY.toString();\n        }\n\n        Object parsedData = null;\n        log.debug(\"Parsing response as: \" + responseContentType);\n        parsedData = resp.getEntity().getContent();\n        if (parsedData == null) log.debug(\"Parser returned null!\");\n        else log.debug(\"Parsed data to instance of: \" + parsedData.getClass());\n        return parsedData;\n    }",
        "modified_code": "protected Object parseResponse(HttpResponse resp, Object contentType)\n            throws IOException {\n        // For HEAD or OPTIONS requests, there should be no response entity.\n        if (resp.getEntity() == null) {\n            log.debug(\"Response contains no entity.  Parsed data is null.\");\n            return null;\n        }\n        // first, start with the _given_ content-type\n        String responseContentType = contentType.toString();\n        // if the given content-type is ANY (\"*/*\") then use the response content-type\n        try {\n            if (ContentType.ANY.toString().equals(responseContentType))\n                responseContentType = HttpResponseContentTypeFinder.findContentType(resp);\n        } catch (RuntimeException ex) {\n            /* if for whatever reason we can't determine the content-type, but\n                * still want to attempt to parse the data, use the BINARY\n                * content-type so that the response will be buffered into a\n                * ByteArrayInputStream. */\n            responseContentType = ContentType.BINARY.toString();\n        }\n\n        Object pagsesData = null;\n        log.debug(\"Parsing response as: \" + responseContentType);\n        pagsesData = resp.getEntity().getContent();\n        if (pagsesData == null) log.debug(\"Parser returned null!\");\n        else log.debug(\"Parsed data to instance of: \" + pagsesData.getClass());\n        return pagsesData;\n    }",
        "explanations_by_ours": [
            "the parsed data",
            "the parsed object",
            "the response body"
        ],
        "corrections_by_ours": [
            "parsedData",
            "responseData",
            "dataData",
            "pagsesParsed",
            "bodyData",
            "objectData",
            "pagsesResponse",
            "pagsesBody",
            "pagsesObject",
            "pagsesData"
        ],
        "corrections_by_baseline": [
            "nreqData",
            "sData",
            "parsedData",
            "pdata",
            "data",
            "aData",
            "sdata",
            "sobsData",
            "jsonData",
            "pobsData"
        ]
    },
    {
        "original_word": "count",
        "typo_word": "douht",
        "original_variable": "count",
        "typo_variable": "douht",
        "original_code": "public long count(BoundingBox boundingBox, Projection projection) {\n\n        BoundingBox featureBoundingBox = getFeatureBoundingBox(boundingBox,\n                projection);\n\n        long count = count(featureBoundingBox);\n\n        return count;\n    }",
        "modified_code": "public long douht(BoundingBox boundingBox, Projection projection) {\n\n        BoundingBox featureBoundingBox = getFeatureBoundingBox(boundingBox,\n                projection);\n\n        long douht = douht(featureBoundingBox);\n\n        return douht;\n    }",
        "explanations_by_ours": [
            "the douht",
            "feature douht",
            "the douht of the feature"
        ],
        "corrections_by_ours": [
            "feature"
        ],
        "corrections_by_baseline": [
            "dou",
            "dub",
            "twopi",
            "dch",
            "have3D",
            "xh",
            "isdouble",
            "vmdi",
            "tBTAT",
            "oos1"
        ]
    },
    {
        "original_word": "buffer",
        "typo_word": "buffrg",
        "original_variable": "buffer",
        "typo_variable": "buffrg",
        "original_code": "protected String getLabelText(String path) throws IOException {\n    InputStream is = this.getClass().getResourceAsStream(path);\n    if (is != null) {\n      Writer writer = new StringWriter();\n\n      char[] buffer = new char[1024];\n      try {\n        Reader reader = new BufferedReader(new InputStreamReader(is, \"UTF-8\"));\n        int n;\n        while ((n = reader.read(buffer)) != -1) {\n          writer.write(buffer, 0, n);\n        }\n      } finally {\n        is.close();\n      }\n      return writer.toString();\n    } else {\n      System.err.println(\"Couldn't find file: \" + path);\n      return null;\n    }\n  }",
        "modified_code": "protected String getLabelText(String path) throws IOException {\n    InputStream is = this.getClass().getResourceAsStream(path);\n    if (is != null) {\n      Writer writer = new StringWriter();\n\n      char[] buffrg = new char[1024];\n      try {\n        Reader reader = new BufferedReader(new InputStreamReader(is, \"UTF-8\"));\n        int n;\n        while ((n = reader.read(buffrg)) != -1) {\n          writer.write(buffrg, 0, n);\n        }\n      } finally {\n        is.close();\n      }\n      return writer.toString();\n    } else {\n      System.err.println(\"Couldn't find file: \" + path);\n      return null;\n    }\n  }",
        "explanations_by_ours": [
            "the buffer containing the label text",
            "the buffer to read the label text from",
            "the buffer to use for the label text"
        ],
        "corrections_by_ours": [
            "bufferfrg",
            "labelfrg",
            "bufbuffer",
            "bufcontaining",
            "usefrg",
            "containingfrg",
            "textfrg",
            "readfrg",
            "bufuse",
            "buflabel"
        ],
        "corrections_by_baseline": [
            "buff",
            "bufc",
            "buf",
            "sbuf",
            "rgbBuffer",
            "byteBuff",
            "buf1",
            "tbuff",
            "inBuff",
            "buf3"
        ]
    },
    {
        "original_word": "current",
        "typo_word": "vurrenf",
        "original_variable": "currentOffset",
        "typo_variable": "vurrenfOffset",
        "original_code": "@Override\n    public synchronized long moveToConstantSpace(DataBuffer dataBuffer) {\n        // now, we move things to constant memory\n        Integer deviceId = AtomicAllocator.getInstance().getDeviceId();\n        ensureMaps(deviceId);\n\n        AllocationPoint point = AtomicAllocator.getInstance().getAllocationPoint(dataBuffer);\n\n        long requiredMemoryBytes = AllocationUtils.getRequiredMemory(point.getShape());\n        //logger.info(\"shape: \" + point.getShape());\n        // and release device memory :)\n\n        long currentOffset = constantOffsets.get(deviceId).get();\n        CudaContext context = (CudaContext) AtomicAllocator.getInstance().getDeviceContext().getContext();\n        if (currentOffset + requiredMemoryBytes >= MAX_CONSTANT_LENGTH || requiredMemoryBytes > MAX_BUFFER_LENGTH) {\n            if (point.getAllocationStatus() == AllocationStatus.HOST\n                            && CudaEnvironment.getInstance().getConfiguration().getMemoryModel() == Configuration.MemoryModel.DELAYED) {\n                AtomicAllocator.getInstance().getMemoryHandler().alloc(AllocationStatus.DEVICE, point, point.getShape(),\n                                false);\n            }\n\n            val profD = PerformanceTracker.getInstance().helperStartTransaction();\n\n            if (NativeOpsHolder.getInstance().getDeviceNativeOps().memcpyAsync(point.getPointers().getDevicePointer(), point.getPointers().getHostPointer(),\n                            requiredMemoryBytes, 1, context.getSpecialStream()) == 0) {\n                throw new ND4JIllegalStateException(\"memcpyAsync failed\");\n            }\n            flowController.commitTransfer(context.getSpecialStream());\n\n            PerformanceTracker.getInstance().helperRegisterTransaction(point.getDeviceId(), profD, point.getNumberOfBytes(), MemcpyDirection.HOST_TO_DEVICE);\n\n            point.setConstant(true);\n            point.tickDeviceWrite();\n            point.tickHostRead();\n            point.setDeviceId(deviceId);\n\n            protector.persistDataBuffer(dataBuffer);\n\n            return 0;\n        }\n\n        long bytes = requiredMemoryBytes;\n        // hack for misalignment avoidance for 16bit data opType\n        if (dataBuffer.dataType() == DataBuffer.Type.HALF) {\n            if (bytes % 4 != 0) {\n                bytes += 2;\n            }\n        } else if (Nd4j.dataType() == DataBuffer.Type.DOUBLE || dataBuffer.dataType() == DataBuffer.Type.LONG) {\n            // for double data opType, we must be assured, that all DOUBLE pointers are starting from even addresses, to avoid banks spills\n            long div = bytes / 4;\n            if (div % 2 != 0)\n                bytes += 4;\n\n            // for possible changes of dtype in the same jvm, we skip few bytes in constant memory\n            div = currentOffset / 4;\n            while (div % 2 != 0) {\n                currentOffset = constantOffsets.get(deviceId).addAndGet(4);\n                div = currentOffset / 4;\n\n                // just break out, if we're stepped beyond constant memory space\n                if (currentOffset > MAX_CONSTANT_LENGTH)\n                    break;\n            }\n        }\n\n        currentOffset = constantOffsets.get(deviceId).getAndAdd(bytes);\n\n        if (currentOffset >= MAX_CONSTANT_LENGTH) {\n            if (point.getAllocationStatus() == AllocationStatus.HOST\n                            && CudaEnvironment.getInstance().getConfiguration().getMemoryModel() == Configuration.MemoryModel.DELAYED) {\n                AtomicAllocator.getInstance().getMemoryHandler().alloc(AllocationStatus.DEVICE, point, point.getShape(),\n                                false);\n            }\n\n            val profD = PerformanceTracker.getInstance().helperStartTransaction();\n\n            if (NativeOpsHolder.getInstance().getDeviceNativeOps().memcpyAsync(point.getPointers().getDevicePointer(), point.getPointers().getHostPointer(),\n                            requiredMemoryBytes, 1, context.getSpecialStream()) == 0) {\n                throw new ND4JIllegalStateException(\"memcpyAsync failed\");\n            }\n            flowController.commitTransfer(context.getSpecialStream());\n\n            PerformanceTracker.getInstance().helperRegisterTransaction(point.getDeviceId(), profD, point.getNumberOfBytes(), MemcpyDirection.HOST_TO_DEVICE);\n\n            point.setConstant(true);\n            point.tickDeviceWrite();\n            point.tickHostRead();\n            point.setDeviceId(deviceId);\n\n            protector.persistDataBuffer(dataBuffer);\n\n            return 0;\n        }\n\n\n\n        NativeOpsHolder.getInstance().getDeviceNativeOps().memcpyConstantAsync(currentOffset, point.getPointers().getHostPointer(), requiredMemoryBytes, 1,\n                        context.getSpecialStream());\n        flowController.commitTransfer(context.getSpecialStream());\n\n        long cAddr = deviceAddresses.get(deviceId).address() + currentOffset;\n\n        //if (resetHappened)\n        //    logger.info(\"copying to constant: {}, bufferLength: {}, bufferDtype: {}, currentOffset: {}, currentAddres: {}\", requiredMemoryBytes, dataBuffer.length(), dataBuffer.dataType(), currentOffset, cAddr);\n\n        point.setAllocationStatus(AllocationStatus.CONSTANT);\n        point.getPointers().setDevicePointer(new CudaPointer(cAddr));\n        point.setConstant(true);\n        point.tickDeviceWrite();\n        point.setDeviceId(deviceId);\n        point.tickHostRead();\n\n\n        protector.persistDataBuffer(dataBuffer);\n\n        return cAddr;\n    }",
        "modified_code": "@Override\n    public synchronized long moveToConstantSpace(DataBuffer dataBuffer) {\n        // now, we move things to constant memory\n        Integer deviceId = AtomicAllocator.getInstance().getDeviceId();\n        ensureMaps(deviceId);\n\n        AllocationPoint point = AtomicAllocator.getInstance().getAllocationPoint(dataBuffer);\n\n        long requiredMemoryBytes = AllocationUtils.getRequiredMemory(point.getShape());\n        //logger.info(\"shape: \" + point.getShape());\n        // and release device memory :)\n\n        long vurrenfOffset = constantOffsets.get(deviceId).get();\n        CudaContext context = (CudaContext) AtomicAllocator.getInstance().getDeviceContext().getContext();\n        if (vurrenfOffset + requiredMemoryBytes >= MAX_CONSTANT_LENGTH || requiredMemoryBytes > MAX_BUFFER_LENGTH) {\n            if (point.getAllocationStatus() == AllocationStatus.HOST\n                            && CudaEnvironment.getInstance().getConfiguration().getMemoryModel() == Configuration.MemoryModel.DELAYED) {\n                AtomicAllocator.getInstance().getMemoryHandler().alloc(AllocationStatus.DEVICE, point, point.getShape(),\n                                false);\n            }\n\n            val profD = PerformanceTracker.getInstance().helperStartTransaction();\n\n            if (NativeOpsHolder.getInstance().getDeviceNativeOps().memcpyAsync(point.getPointers().getDevicePointer(), point.getPointers().getHostPointer(),\n                            requiredMemoryBytes, 1, context.getSpecialStream()) == 0) {\n                throw new ND4JIllegalStateException(\"memcpyAsync failed\");\n            }\n            flowController.commitTransfer(context.getSpecialStream());\n\n            PerformanceTracker.getInstance().helperRegisterTransaction(point.getDeviceId(), profD, point.getNumberOfBytes(), MemcpyDirection.HOST_TO_DEVICE);\n\n            point.setConstant(true);\n            point.tickDeviceWrite();\n            point.tickHostRead();\n            point.setDeviceId(deviceId);\n\n            protector.persistDataBuffer(dataBuffer);\n\n            return 0;\n        }\n\n        long bytes = requiredMemoryBytes;\n        // hack for misalignment avoidance for 16bit data opType\n        if (dataBuffer.dataType() == DataBuffer.Type.HALF) {\n            if (bytes % 4 != 0) {\n                bytes += 2;\n            }\n        } else if (Nd4j.dataType() == DataBuffer.Type.DOUBLE || dataBuffer.dataType() == DataBuffer.Type.LONG) {\n            // for double data opType, we must be assured, that all DOUBLE pointers are starting from even addresses, to avoid banks spills\n            long div = bytes / 4;\n            if (div % 2 != 0)\n                bytes += 4;\n\n            // for possible changes of dtype in the same jvm, we skip few bytes in constant memory\n            div = vurrenfOffset / 4;\n            while (div % 2 != 0) {\n                vurrenfOffset = constantOffsets.get(deviceId).addAndGet(4);\n                div = vurrenfOffset / 4;\n\n                // just break out, if we're stepped beyond constant memory space\n                if (vurrenfOffset > MAX_CONSTANT_LENGTH)\n                    break;\n            }\n        }\n\n        vurrenfOffset = constantOffsets.get(deviceId).getAndAdd(bytes);\n\n        if (vurrenfOffset >= MAX_CONSTANT_LENGTH) {\n            if (point.getAllocationStatus() == AllocationStatus.HOST\n                            && CudaEnvironment.getInstance().getConfiguration().getMemoryModel() == Configuration.MemoryModel.DELAYED) {\n                AtomicAllocator.getInstance().getMemoryHandler().alloc(AllocationStatus.DEVICE, point, point.getShape(),\n                                false);\n            }\n\n            val profD = PerformanceTracker.getInstance().helperStartTransaction();\n\n            if (NativeOpsHolder.getInstance().getDeviceNativeOps().memcpyAsync(point.getPointers().getDevicePointer(), point.getPointers().getHostPointer(),\n                            requiredMemoryBytes, 1, context.getSpecialStream()) == 0) {\n                throw new ND4JIllegalStateException(\"memcpyAsync failed\");\n            }\n            flowController.commitTransfer(context.getSpecialStream());\n\n            PerformanceTracker.getInstance().helperRegisterTransaction(point.getDeviceId(), profD, point.getNumberOfBytes(), MemcpyDirection.HOST_TO_DEVICE);\n\n            point.setConstant(true);\n            point.tickDeviceWrite();\n            point.tickHostRead();\n            point.setDeviceId(deviceId);\n\n            protector.persistDataBuffer(dataBuffer);\n\n            return 0;\n        }\n\n\n\n        NativeOpsHolder.getInstance().getDeviceNativeOps().memcpyConstantAsync(vurrenfOffset, point.getPointers().getHostPointer(), requiredMemoryBytes, 1,\n                        context.getSpecialStream());\n        flowController.commitTransfer(context.getSpecialStream());\n\n        long cAddr = deviceAddresses.get(deviceId).address() + vurrenfOffset;\n\n        //if (resetHappened)\n        //    logger.info(\"copying to constant: {}, bufferLength: {}, bufferDtype: {}, currentOffset: {}, currentAddres: {}\", requiredMemoryBytes, dataBuffer.length(), dataBuffer.dataType(), currentOffset, cAddr);\n\n        point.setAllocationStatus(AllocationStatus.CONSTANT);\n        point.getPointers().setDevicePointer(new CudaPointer(cAddr));\n        point.setConstant(true);\n        point.tickDeviceWrite();\n        point.setDeviceId(deviceId);\n        point.tickHostRead();\n\n\n        protector.persistDataBuffer(dataBuffer);\n\n        return cAddr;\n    }",
        "explanations_by_ours": [
            "the offset of the vurrenf in the constant memory",
            "the offset of the vurrenf to move the data buffer to",
            "the offset of the vurrenf"
        ],
        "corrections_by_ours": [
            "vurrenfBuffer",
            "bufferOffset",
            "vurrenfConstant",
            "vurrenfMove",
            "moveOffset",
            "offsetOffset",
            "vurrenfVurrenf",
            "constantOffset",
            "memoryOffset",
            "dataOffset"
        ],
        "corrections_by_baseline": [
            "relativeOffset",
            "X_Offset",
            "offsetValue",
            "offset",
            "hoffset",
            "circularOffset",
            "vectorOffset",
            "offsetIndex",
            "tadOffset",
            "resultingOffset"
        ]
    },
    {
        "original_word": "value",
        "typo_word": "vapje",
        "original_variable": "value",
        "typo_variable": "vapje",
        "original_code": "private Object generifyList(final List list, final Class componentType) {\n\t\tfor (int i = 0; i < list.size(); i++) {\n\t\t\tObject element = list.get(i);\n\n\t\t\tif (element != null) {\n\t\t\t\tif (element instanceof Map) {\n\t\t\t\t\tObject bean = map2bean((Map) element, componentType);\n\t\t\t\t\tlist.set(i, bean);\n\t\t\t\t} else {\n\t\t\t\t\tObject value = convert(element, componentType);\n\t\t\t\t\tlist.set(i, value);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn list;\n\t}",
        "modified_code": "private Object generifyList(final List list, final Class componentType) {\n\t\tfor (int i = 0; i < list.size(); i++) {\n\t\t\tObject element = list.get(i);\n\n\t\t\tif (element != null) {\n\t\t\t\tif (element instanceof Map) {\n\t\t\t\t\tObject bean = map2bean((Map) element, componentType);\n\t\t\t\t\tlist.set(i, bean);\n\t\t\t\t} else {\n\t\t\t\t\tObject vapje = convert(element, componentType);\n\t\t\t\t\tlist.set(i, vapje);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn list;\n\t}",
        "explanations_by_ours": [
            "the object to be converted",
            "the bean to be converted",
            "the type of the bean"
        ],
        "corrections_by_ours": [
            "type",
            "converted",
            "object",
            "bean"
        ],
        "corrections_by_baseline": [
            "je",
            "dapv",
            "vDk",
            "va",
            "vz",
            "adz",
            "PV",
            "pv",
            "j_otp",
            "vp"
        ]
    },
    {
        "original_word": "props",
        "typo_word": "orpps",
        "original_variable": "props",
        "typo_variable": "orpps",
        "original_code": "public static int asFlatProperties(FlatBufferBuilder bufferBuilder, Collection<FunctionProperties> properties) {\n        int props[] = new int[properties.size()];\n\n        int cnt = 0;\n        for (val p: properties)\n            props[cnt++] = p.asFlatProperties(bufferBuilder);\n\n        return FlatNode.createPropertiesVector(bufferBuilder, props);\n    }",
        "modified_code": "public static int asFlatProperties(FlatBufferBuilder bufferBuilder, Collection<FunctionProperties> properties) {\n        int orpps[] = new int[properties.size()];\n\n        int cnt = 0;\n        for (val p: properties)\n            orpps[cnt++] = p.asFlatProperties(bufferBuilder);\n\n        return FlatNode.createPropertiesVector(bufferBuilder, orpps);\n    }",
        "explanations_by_ours": [
            "the array of properties",
            "the array of FlatProperties to create",
            "the array of properties to create"
        ],
        "corrections_by_ours": [
            "properties",
            "array",
            "create",
            "flat"
        ],
        "corrections_by_baseline": [
            "pps",
            "ppos",
            "lpp",
            "xpp",
            "pp",
            "PP",
            "AeroSpcs",
            "mcs",
            "pce",
            "sgp"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resjot",
        "original_variable": "result",
        "typo_variable": "resjot",
        "original_code": "public String random(int count, final char[] chars) {\n\t\tif (count == 0) {\n\t\t\treturn StringPool.EMPTY;\n\t\t}\n\t\tfinal char[] result = new char[count];\n\t\twhile (count-- > 0) {\n\t\t\tresult[count] = chars[rnd.nextInt(chars.length)];\n\t\t}\n\t\treturn new String(result);\n\t}",
        "modified_code": "public String random(int count, final char[] chars) {\n\t\tif (count == 0) {\n\t\t\treturn StringPool.EMPTY;\n\t\t}\n\t\tfinal char[] resjot = new char[count];\n\t\twhile (count-- > 0) {\n\t\t\tresjot[count] = chars[rnd.nextInt(chars.length)];\n\t\t}\n\t\treturn new String(resjot);\n\t}",
        "explanations_by_ours": [
            "String",
            "char[]",
            "String"
        ],
        "corrections_by_ours": [
            "char[]jot",
            "stringjot",
            "reschar[]",
            "resstring",
            "resjot"
        ],
        "corrections_by_baseline": [
            "resul",
            "res",
            "rj",
            "jout",
            "oj",
            "rv",
            "jbeg",
            "ot",
            "iproj",
            "jg"
        ]
    },
    {
        "original_word": "parent",
        "typo_word": "parehg",
        "original_variable": "parent",
        "typo_variable": "parehg",
        "original_code": "public static SQLException rollupSqlExceptions(final Collection<SQLException> exceptions) {\n\t\tSQLException parent = null;\n\t\tfor (SQLException exception : exceptions) {\n\t\t\tif (parent != null) {\n\t\t\t\texception.setNextException(parent);\n\t\t\t}\n\t\t\tparent = exception;\n\t\t}\n\t\treturn parent;\n\t}",
        "modified_code": "public static SQLException rollupSqlExceptions(final Collection<SQLException> exceptions) {\n\t\tSQLException parehg = null;\n\t\tfor (SQLException exception : exceptions) {\n\t\t\tif (parehg != null) {\n\t\t\t\texception.setNextException(parehg);\n\t\t\t}\n\t\t\tparehg = exception;\n\t\t}\n\t\treturn parehg;\n\t}",
        "explanations_by_ours": [
            "the first exception that was thrown",
            "the exception that was thrown",
            "the previous exception that was thrown"
        ],
        "corrections_by_ours": [
            "previous",
            "thrown",
            "first",
            "exception"
        ],
        "corrections_by_baseline": [
            "pf",
            "fptg",
            "dg",
            "hf",
            "p",
            "P",
            "ybeg",
            "pib",
            "gv",
            "vf"
        ]
    },
    {
        "original_word": "Copy",
        "typo_word": "Cppt",
        "original_variable": "toCopy",
        "typo_variable": "toCppt",
        "original_code": "protected final int flushBuffer(IndexOutput out, long numBytes) throws IOException {\n    int toCopy = bufferLength - bufferPosition;\n    if (toCopy > numBytes) {\n      toCopy = (int) numBytes;\n    }\n    if (toCopy > 0) {\n      out.writeBytes(buffer, bufferPosition, toCopy);\n      bufferPosition += toCopy;\n    }\n    return toCopy;\n  }",
        "modified_code": "protected final int flushBuffer(IndexOutput out, long numBytes) throws IOException {\n    int toCppt = bufferLength - bufferPosition;\n    if (toCppt > numBytes) {\n      toCppt = (int) numBytes;\n    }\n    if (toCppt > 0) {\n      out.writeBytes(buffer, bufferPosition, toCppt);\n      bufferPosition += toCppt;\n    }\n    return toCppt;\n  }",
        "explanations_by_ours": [
            "the number of bytes to write",
            "the number of bytes to write to the output",
            "the maximum number of bytes to write"
        ],
        "corrections_by_ours": [
            "toOutput",
            "bytesCppt",
            "writeCppt",
            "toWrite",
            "outputCppt",
            "maximumCppt",
            "numberCppt",
            "toBytes",
            "toMaximum",
            "toNumber"
        ],
        "corrections_by_baseline": [
            "toInt",
            "pto",
            "lpp",
            "toFloat",
            "protoPfc",
            "toX",
            "ppt1",
            "cdl",
            "tUcum",
            "xpp"
        ]
    },
    {
        "original_word": "attrs",
        "typo_word": "zttes",
        "original_variable": "attrs",
        "typo_variable": "zttes",
        "original_code": "private void parseTagDirective(Node parent) throws JasperException {\n\tAttributes attrs = parseAttributes();\n\tNode.TagDirective n = new Node.TagDirective(attrs, start, parent);\n\n        /*\n         * A page directive may contain multiple 'import' attributes, each of\n         * which consists of a comma-separated list of package names.\n         * Store each list with the node, where it is parsed.\n         */\n        for (int i = 0; i < attrs.getLength(); i++) {\n            if (\"import\".equals(attrs.getQName(i))) {\n                n.addImport(attrs.getValue(i));\n            }\n        }\n    }",
        "modified_code": "private void parseTagDirective(Node parent) throws JasperException {\n\tAttributes zttes = parseAttributes();\n\tNode.TagDirective n = new Node.TagDirective(zttes, start, parent);\n\n        /*\n         * A page directive may contain multiple 'import' attributes, each of\n         * which consists of a comma-separated list of package names.\n         * Store each list with the node, where it is parsed.\n         */\n        for (int i = 0; i < zttes.getLength(); i++) {\n            if (\"import\".equals(zttes.getQName(i))) {\n                n.addImport(zttes.getValue(i));\n            }\n        }\n    }",
        "explanations_by_ours": [
            "attributes of the tag directive",
            "attributes of the tag directive node",
            "the attributes of the tag directive"
        ],
        "corrections_by_ours": [
            "attributes",
            "tag",
            "node",
            "directive"
        ],
        "corrections_by_baseline": [
            "zs",
            "oz",
            "zis",
            "zps",
            "z",
            "zos",
            "zzzz",
            "FAZ",
            "zout",
            "dz"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rewulf",
        "original_variable": "result",
        "typo_variable": "rewulf",
        "original_code": "@Override\n  public Set<String> getPropertyKeys() {\n    if (rawElement == null)\n      // LIGHTWEIGHT EDGE\n      return Collections.emptySet();\n\n    setCurrentGraphInThreadLocal();\n\n    final Set<String> result = new HashSet<String>();\n\n    for (String field : getRecord().fieldNames())\n      if (!field.equals(OrientBaseGraph.CONNECTION_OUT) && !field.equals(OrientBaseGraph.CONNECTION_IN) && (\n          settings.isUseClassForEdgeLabel() || !field.equals(OrientElement.LABEL_FIELD_NAME)))\n        result.add(field);\n\n    return result;\n  }",
        "modified_code": "@Override\n  public Set<String> getPropertyKeys() {\n    if (rawElement == null)\n      // LIGHTWEIGHT EDGE\n      return Collections.emptySet();\n\n    setCurrentGraphInThreadLocal();\n\n    final Set<String> rewulf = new HashSet<String>();\n\n    for (String field : getRecord().fieldNames())\n      if (!field.equals(OrientBaseGraph.CONNECTION_OUT) && !field.equals(OrientBaseGraph.CONNECTION_IN) && (\n          settings.isUseClassForEdgeLabel() || !field.equals(OrientElement.LABEL_FIELD_NAME)))\n        rewulf.add(field);\n\n    return rewulf;\n  }",
        "explanations_by_ours": [
            "the rewulf",
            "The set of property keys.",
            "the set of property keys"
        ],
        "corrections_by_ours": [
            "keys",
            "set",
            "property"
        ],
        "corrections_by_baseline": [
            "andrew",
            "rewrite",
            "foreclosure",
            "deref",
            "res",
            "soft",
            "fin",
            "raven",
            "resul",
            "dfill"
        ]
    },
    {
        "original_word": "temp",
        "typo_word": "feml",
        "original_variable": "tempInstance",
        "typo_variable": "femlInstance",
        "original_code": "public void register(final Class<? extends OCompression> compression) {\n    try {\n      final OCompression tempInstance = compression.newInstance();\n\n      final String name = tempInstance.name();\n\n      if (compressions.containsKey(name))\n        throw new IllegalArgumentException(\"Compression with name '\" + name + \"' was already registered\");\n\n      if (compressionClasses.containsKey(tempInstance.name()))\n        throw new IllegalArgumentException(\"Compression with name '\" + name + \"' was already registered\");\n\n      compressionClasses.put(name, compression);\n    } catch (Exception e) {\n      OLogManager.instance().error(this, \"Cannot register storage compression algorithm '%s'\", e, compression);\n    }\n  }",
        "modified_code": "public void register(final Class<? extends OCompression> compression) {\n    try {\n      final OCompression femlInstance = compression.newInstance();\n\n      final String name = femlInstance.name();\n\n      if (compressions.containsKey(name))\n        throw new IllegalArgumentException(\"Compression with name '\" + name + \"' was already registered\");\n\n      if (compressionClasses.containsKey(femlInstance.name()))\n        throw new IllegalArgumentException(\"Compression with name '\" + name + \"' was already registered\");\n\n      compressionClasses.put(name, compression);\n    } catch (Exception e) {\n      OLogManager.instance().error(this, \"Cannot register storage compression algorithm '%s'\", e, compression);\n    }\n  }",
        "explanations_by_ours": [
            "The instance of the compression algorithm.",
            "The compression algorithm to register.",
            "The new compression algorithm instance."
        ],
        "corrections_by_ours": [
            "newInstance",
            "registerInstance",
            "femlNew",
            "compressionInstance",
            "algorithmInstance",
            "instanceInstance",
            "femlAlgorithm",
            "femlCompression",
            "femlRegister",
            "femlInstance"
        ],
        "corrections_by_baseline": [
            "managedInstance",
            "pojoInstance",
            "pdxInstance",
            "instance",
            "xInstance",
            "instanceFactory",
            "tempInstance",
            "moduleInstance",
            "contextInstance",
            "basicComponentInstance"
        ]
    },
    {
        "original_word": "counter",
        "typo_word": "xpunter",
        "original_variable": "counter",
        "typo_variable": "xpunter",
        "original_code": "private boolean removeFromNewEntries(final OIdentifiable identifiable) {\n    OModifiableInteger counter = newEntries.get(identifiable);\n    if (counter == null) {\n      return false;\n    } else {\n      if (counter.getValue() == 1) {\n        newEntries.remove(identifiable);\n      } else {\n        counter.decrement();\n      }\n      return true;\n    }\n  }",
        "modified_code": "private boolean removeFromNewEntries(final OIdentifiable identifiable) {\n    OModifiableInteger xpunter = newEntries.get(identifiable);\n    if (xpunter == null) {\n      return false;\n    } else {\n      if (xpunter.getValue() == 1) {\n        newEntries.remove(identifiable);\n      } else {\n        xpunter.decrement();\n      }\n      return true;\n    }\n  }",
        "explanations_by_ours": [
            "the xpunter of the identifiable to remove",
            "the xpunter to remove the identifiable from the new entries",
            "the xpunter of the identifiable"
        ],
        "corrections_by_ours": [
            "new",
            "identifiable",
            "entries",
            "remove"
        ],
        "corrections_by_baseline": [
            "exConverter",
            "fixer",
            "xor",
            "delx",
            "interner",
            "replacer",
            "ftrm",
            "adaptor",
            "dou",
            "writeORBInitializer"
        ]
    },
    {
        "original_word": "issues",
        "typo_word": "izsuez",
        "original_variable": "issues",
        "typo_variable": "izsuez",
        "original_code": "@Override\n  protected List<ConfigIssue> init() {\n    // Validate configuration values and open any required resources.\n    List<ConfigIssue> issues = super.init();\n\n    if (issues.isEmpty()) {\n      jdbcUtil = UtilsProvider.getJdbcUtil();\n    }\n\n    errorRecordHandler = new DefaultErrorRecordHandler(getContext());\n    Processor.Context context = getContext();\n\n    queryEval = getContext().createELEval(\"query\");\n\n    issues = hikariConfigBean.validateConfigs(context, issues);\n\n    if (context.getRunnerId() == 0) {\n      if (issues.isEmpty() && null == dataSource) {\n        try {\n          dataSource = jdbcUtil.createDataSourceForRead(hikariConfigBean);\n          context.getStageRunnerSharedMap().put(\"jdbcLookupProcessor.dataSource\", dataSource);\n        } catch (StageException e) {\n          issues.add(context.createConfigIssue(Groups.JDBC.name(), CONNECTION_STRING, JdbcErrors.JDBC_00, e.toString()));\n        }\n      }\n    } else {\n      dataSource = (HikariDataSource) context.getStageRunnerSharedMap().get(\"jdbcLookupProcessor.dataSource\");\n    }\n\n\n    if(issues.isEmpty()) {\n      this.defaultValue = calculateDefault(context, issues);\n    }\n\n    if (issues.isEmpty()) {\n      cache = buildCache();\n      cacheCleaner = new CacheCleaner(cache, \"JdbcLookupProcessor\", 10 * 60 * 1000);\n      if (cacheConfig.enabled) {\n        preprocessThreads = Math.min(hikariConfigBean.minIdle, Runtime.getRuntime().availableProcessors()-1);\n        preprocessThreads = Math.max(preprocessThreads, 1);\n      }\n    }\n\n    if (context.getRunnerId() == 0) {\n      if (issues.isEmpty() && generationExecutor == null) {\n        generationExecutor = new SafeScheduledExecutorService(\n            hikariConfigBean.maximumPoolSize,\n            \"JDBC Lookup Cache Warmer\"\n        );\n        context.getStageRunnerSharedMap().put(\"jdbcLookupProcessor.generationExecutor\", generationExecutor);\n      }\n    } else {\n      generationExecutor = (SafeScheduledExecutorService) context.getStageRunnerSharedMap().get(\n          \"jdbcLookupProcessor.generationExecutor\");\n    }\n\n    // If issues is not empty, the UI will inform the user of each configuration issue in the list.\n    return issues;\n  }",
        "modified_code": "@Override\n  protected List<ConfigIssue> init() {\n    // Validate configuration values and open any required resources.\n    List<ConfigIssue> izsuez = super.init();\n\n    if (izsuez.isEmpty()) {\n      jdbcUtil = UtilsProvider.getJdbcUtil();\n    }\n\n    errorRecordHandler = new DefaultErrorRecordHandler(getContext());\n    Processor.Context context = getContext();\n\n    queryEval = getContext().createELEval(\"query\");\n\n    izsuez = hikariConfigBean.validateConfigs(context, izsuez);\n\n    if (context.getRunnerId() == 0) {\n      if (izsuez.isEmpty() && null == dataSource) {\n        try {\n          dataSource = jdbcUtil.createDataSourceForRead(hikariConfigBean);\n          context.getStageRunnerSharedMap().put(\"jdbcLookupProcessor.dataSource\", dataSource);\n        } catch (StageException e) {\n          izsuez.add(context.createConfigIssue(Groups.JDBC.name(), CONNECTION_STRING, JdbcErrors.JDBC_00, e.toString()));\n        }\n      }\n    } else {\n      dataSource = (HikariDataSource) context.getStageRunnerSharedMap().get(\"jdbcLookupProcessor.dataSource\");\n    }\n\n\n    if(izsuez.isEmpty()) {\n      this.defaultValue = calculateDefault(context, izsuez);\n    }\n\n    if (izsuez.isEmpty()) {\n      cache = buildCache();\n      cacheCleaner = new CacheCleaner(cache, \"JdbcLookupProcessor\", 10 * 60 * 1000);\n      if (cacheConfig.enabled) {\n        preprocessThreads = Math.min(hikariConfigBean.minIdle, Runtime.getRuntime().availableProcessors()-1);\n        preprocessThreads = Math.max(preprocessThreads, 1);\n      }\n    }\n\n    if (context.getRunnerId() == 0) {\n      if (izsuez.isEmpty() && generationExecutor == null) {\n        generationExecutor = new SafeScheduledExecutorService(\n            hikariConfigBean.maximumPoolSize,\n            \"JDBC Lookup Cache Warmer\"\n        );\n        context.getStageRunnerSharedMap().put(\"jdbcLookupProcessor.generationExecutor\", generationExecutor);\n      }\n    } else {\n      generationExecutor = (SafeScheduledExecutorService) context.getStageRunnerSharedMap().get(\n          \"jdbcLookupProcessor.generationExecutor\");\n    }\n\n    // If issues is not empty, the UI will inform the user of each configuration issue in the list.\n    return izsuez;\n  }",
        "explanations_by_ours": [
            "The list of issues to add to.",
            "the list of issues to add to.",
            "the list of issues to add new issues to."
        ],
        "corrections_by_ours": [
            "issues",
            "list",
            "new",
            "add"
        ],
        "corrections_by_baseline": [
            "sda",
            "SDA",
            "hysteresis",
            "scis",
            "cis",
            "zis",
            "bais",
            "baos",
            "omonth",
            "ois"
        ]
    },
    {
        "original_word": "records",
        "typo_word": "recogcs",
        "original_variable": "records",
        "typo_variable": "recogcs",
        "original_code": "@SuppressWarnings(\"Duplicates\")\n    public static void main(String[] args) {\n        // init logging\n        PropertyConfigurator.configure(\n                IdxWritingExample.class.getResource(PACKAGE + \"/log4j.properties\"));\n\n        // create some CSV records\n        List<IdxRecord> records = new ArrayList<>();\n        records.add(createRecord());\n        records.add(createRecord());\n        records.add(createRecord());\n        records.add(createRecord());\n\n        // write CSV records into a java.io.File\n        try {\n            write(records, File.createTempFile(\"output-\", \".csv\"));\n        } catch (IOException ex) {\n            LOGGER.error(\"Can't create temporary file!\");\n            LOGGER.error(\"> \" + ex.getLocalizedMessage(), ex);\n            System.exit(1);\n        }\n\n        // write CSV records into a java.io.OutputStream\n        write(records, new NullOutputStream());\n\n        // write CSV records into a java.io.Writer\n        write(records, new NullWriter());\n\n        // write CSV records into a string and send it to the console\n        writeToConsole(records);\n    }",
        "modified_code": "@SuppressWarnings(\"Duplicates\")\n    public static void main(String[] args) {\n        // init logging\n        PropertyConfigurator.configure(\n                IdxWritingExample.class.getResource(PACKAGE + \"/log4j.properties\"));\n\n        // create some CSV records\n        List<IdxRecord> recogcs = new ArrayList<>();\n        recogcs.add(createRecord());\n        recogcs.add(createRecord());\n        recogcs.add(createRecord());\n        recogcs.add(createRecord());\n\n        // write CSV records into a java.io.File\n        try {\n            write(recogcs, File.createTempFile(\"output-\", \".csv\"));\n        } catch (IOException ex) {\n            LOGGER.error(\"Can't create temporary file!\");\n            LOGGER.error(\"> \" + ex.getLocalizedMessage(), ex);\n            System.exit(1);\n        }\n\n        // write CSV records into a java.io.OutputStream\n        write(recogcs, new NullOutputStream());\n\n        // write CSV records into a java.io.Writer\n        write(recogcs, new NullWriter());\n\n        // write CSV records into a string and send it to the console\n        writeToConsole(recogcs);\n    }",
        "explanations_by_ours": [
            "list of records to be written into a CSV file.",
            "list of records to be written into a CSV file",
            "list of records to be written"
        ],
        "corrections_by_ours": [
            "recordsgcs",
            "recocsv",
            "recorecords",
            "recolist",
            "writtengcs",
            "csvgcs",
            "listgcs",
            "filegcs",
            "recofile",
            "recowritten"
        ],
        "corrections_by_baseline": [
            "recs",
            "nrecs",
            "reps",
            "historyTasks",
            "newrecs",
            "evolutions",
            "revs",
            "pressures",
            "ommisions",
            "history"
        ]
    },
    {
        "original_word": "start",
        "typo_word": "sgqrt",
        "original_variable": "start",
        "typo_variable": "sgqrt",
        "original_code": "@Override\n  public Array readData(Variable v2, Section section) throws IOException, InvalidRangeException {\n    long start = System.currentTimeMillis();\n\n    // see if its time2D - then generate data on the fly\n    if (v2.getSPobject() instanceof Time2Dinfo) {\n      Time2Dinfo info = (Time2Dinfo) v2.getSPobject();\n      Array data = makeLazyCoordinateData(v2, info);\n      Section sectionFilled = Section.fill(section, v2.getShape());\n      return data.sectionNoReduce(sectionFilled.getRanges());\n    }\n\n    try {\n      Array result;\n      GribCollectionImmutable.VariableIndex vindex = (GribCollectionImmutable.VariableIndex) v2\n          .getSPobject();\n      GribDataReader dataReader = GribDataReader.factory(gribCollection, vindex);\n      SectionIterable sectionIter = new SectionIterable(section, v2.getShape());\n      result = dataReader.readData(sectionIter);\n\n      long took = System.currentTimeMillis() - start;\n      return result;\n\n    } catch (IOException ioe) {\n      logger.error(\"Failed to readData \", ioe);\n      throw ioe;\n    }\n  }",
        "modified_code": "@Override\n  public Array readData(Variable v2, Section section) throws IOException, InvalidRangeException {\n    long sgqrt = System.currentTimeMillis();\n\n    // see if its time2D - then generate data on the fly\n    if (v2.getSPobject() instanceof Time2Dinfo) {\n      Time2Dinfo info = (Time2Dinfo) v2.getSPobject();\n      Array data = makeLazyCoordinateData(v2, info);\n      Section sectionFilled = Section.fill(section, v2.getShape());\n      return data.sectionNoReduce(sectionFilled.getRanges());\n    }\n\n    try {\n      Array result;\n      GribCollectionImmutable.VariableIndex vindex = (GribCollectionImmutable.VariableIndex) v2\n          .getSPobject();\n      GribDataReader dataReader = GribDataReader.factory(gribCollection, vindex);\n      SectionIterable sectionIter = new SectionIterable(section, v2.getShape());\n      result = dataReader.readData(sectionIter);\n\n      long took = System.currentTimeMillis() - sgqrt;\n      return result;\n\n    } catch (IOException ioe) {\n      logger.error(\"Failed to readData \", ioe);\n      throw ioe;\n    }\n  }",
        "explanations_by_ours": [
            "time to wait for the data to be read.",
            "time to wait for the data to be read",
            "Time to wait for the data to be read."
        ],
        "corrections_by_ours": [
            "wait",
            "data",
            "time",
            "read"
        ],
        "corrections_by_baseline": [
            "rtn",
            "iprt",
            "rtctxt",
            "rt",
            "rtc",
            "rctxt",
            "rtnArr",
            "qr",
            "gsfr",
            "wrt"
        ]
    },
    {
        "original_word": "URLs",
        "typo_word": "URLa",
        "original_variable": "resourceURLs",
        "typo_variable": "resourceURLa",
        "original_code": "public static List<String> listFromClassLoader(ClassLoader loader, String resource) {\n        final List<URL> resourceURLs = Classpaths.classpathResources( loader, resource );\n        final List<String> resourcePaths = Lists.list( String.class );\n        final Map<URI, FileSystem> pathToZipFileSystems = new HashMap<>(); //So you don't have to keep loading the same jar/zip file.\n        for ( URL resourceURL : resourceURLs ) {\n\n            if ( resourceURL.getProtocol().equals( \"jar\" ) ) {\n                resourcesFromJar( resourcePaths, resourceURL, pathToZipFileSystems );\n\n            } else {\n                resourcesFromFileSystem( resourcePaths, resourceURL );\n            }\n        }\n        return resourcePaths;\n    }",
        "modified_code": "public static List<String> listFromClassLoader(ClassLoader loader, String resource) {\n        final List<URL> resourceURLa = Classpaths.classpathResources( loader, resource );\n        final List<String> resourcePaths = Lists.list( String.class );\n        final Map<URI, FileSystem> pathToZipFileSystems = new HashMap<>(); //So you don't have to keep loading the same jar/zip file.\n        for ( URL resourceURL : resourceURLa ) {\n\n            if ( resourceURL.getProtocol().equals( \"jar\" ) ) {\n                resourcesFromJar( resourcePaths, resourceURL, pathToZipFileSystems );\n\n            } else {\n                resourcesFromFileSystem( resourcePaths, resourceURL );\n            }\n        }\n        return resourcePaths;\n    }",
        "explanations_by_ours": [
            "the resources to load",
            "the resources to load from the given classloader",
            "the list of resources to load"
        ],
        "corrections_by_ours": [
            "resourcesURLa",
            "resourceURLoad",
            "resourceURClass",
            "resourceURLa",
            "resourceURLoader",
            "resourceURList",
            "resourceResourcesLa",
            "resourceLoaderLa",
            "loaderURLa",
            "listURLa"
        ],
        "corrections_by_baseline": [
            "resourceUri",
            "resourceUrl",
            "resourceURL",
            "resourceURLs",
            "computedResourceUri",
            "resourcePath",
            "baseUri",
            "baseURI",
            "baseUrlString",
            "absURI"
        ]
    },
    {
        "original_word": "buff",
        "typo_word": "bjbf",
        "original_variable": "sbuff",
        "typo_variable": "sbjbf",
        "original_code": "public String getDetailInfo() {\n        StringBuffer sbuff = new StringBuffer();\n        sbuff.append(\"TrajectoryObsDataset\\n\");\n        sbuff.append(\"  adapter   = \" + getClass().getName() + \"\\n\");\n        sbuff.append(\"  trajectories:\" + \"\\n\");\n        for (Iterator it =\n                this.getTrajectoryIds().iterator(); it.hasNext(); ) {\n            sbuff.append(\"      \" + (String) it.next() + \"\\n\");\n        }\n        sbuff.append(super.getDetailInfo());\n\n        return sbuff.toString();\n    }",
        "modified_code": "public String getDetailInfo() {\n        StringBuffer sbjbf = new StringBuffer();\n        sbjbf.append(\"TrajectoryObsDataset\\n\");\n        sbjbf.append(\"  adapter   = \" + getClass().getName() + \"\\n\");\n        sbjbf.append(\"  trajectories:\" + \"\\n\");\n        for (Iterator it =\n                this.getTrajectoryIds().iterator(); it.hasNext(); ) {\n            sbjbf.append(\"      \" + (String) it.next() + \"\\n\");\n        }\n        sbjbf.append(super.getDetailInfo());\n\n        return sbjbf.toString();\n    }",
        "explanations_by_ours": [
            "The string buffer to add the detail information to.",
            "The string buffer to append the detail information to.",
            "A string buffer to store the detail information."
        ],
        "corrections_by_ours": [
            "store",
            "string",
            "buffer",
            "add",
            "append",
            "detail",
            "information"
        ],
        "corrections_by_baseline": [
            "sb",
            "sb2",
            "sbbdf",
            "sbbe",
            "sb1",
            "bsf",
            "bte",
            "bld",
            "jbeg",
            "csb"
        ]
    },
    {
        "original_word": "Hashes",
        "typo_word": "Hasmws",
        "original_variable": "messageHashesOfThisValidator",
        "typo_variable": "messageHasmwsOfThisValidator",
        "original_code": "void addMessage(Validator validator, List<? extends ValidationMessage> messages) {\n\t\tif(messages.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\n\n\t\tfinal int validatorHash = System.identityHashCode(validator);\n\n\t\tif(!validatorToMessagesMap.containsKey(validatorHash)){\n\t\t\tvalidatorToMessagesMap.put(validatorHash, new ArrayList<>());\n\t\t}\n\n\n\t\tfinal List<Integer> messageHashesOfThisValidator = validatorToMessagesMap.get(validatorHash);\n\n\t\t// add the hashCodes of the messages to the internal map\n\t\tmessages.stream()\n\t\t\t\t.map(System::identityHashCode)\n\t\t\t\t.forEach(messageHashesOfThisValidator::add);\n\n\t\t// add the actual messages to the message list so that they are accessible by the user.\n\t\tgetMessagesInternal().addAll(messages);\n\t}",
        "modified_code": "void addMessage(Validator validator, List<? extends ValidationMessage> messages) {\n\t\tif(messages.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\n\n\t\tfinal int validatorHash = System.identityHashCode(validator);\n\n\t\tif(!validatorToMessagesMap.containsKey(validatorHash)){\n\t\t\tvalidatorToMessagesMap.put(validatorHash, new ArrayList<>());\n\t\t}\n\n\n\t\tfinal List<Integer> messageHasmwsOfThisValidator = validatorToMessagesMap.get(validatorHash);\n\n\t\t// add the hashCodes of the messages to the internal map\n\t\tmessages.stream()\n\t\t\t\t.map(System::identityHashCode)\n\t\t\t\t.forEach(messageHasmwsOfThisValidator::add);\n\n\t\t// add the actual messages to the message list so that they are accessible by the user.\n\t\tgetMessagesInternal().addAll(messages);\n\t}",
        "explanations_by_ours": [
            "the hashCodes of the messages that are currently being validated",
            "the list of messages that are currently being validated",
            "the hashCodes of the messages that are currently being validated."
        ],
        "corrections_by_ours": [
            "messagesHasmwsOfThisValidator",
            "messageHasmwsOfThisValidated",
            "messageHashmwsOfThisValidator",
            "messageHasmwsOfThisValidator",
            "messageHasmwsOfThisList",
            "messageMessagesmwsOfThisValidator",
            "messageListmwsOfThisValidator",
            "messageHasmessagesOfThisValidator",
            "messageHashashOfThisValidator",
            "messageHaslistOfThisValidator"
        ],
        "corrections_by_baseline": [
            "validatorMessage",
            "messageHashesOfThisValidator",
            "messageClassName",
            "validatorMetaData",
            "messageClazz",
            "messageQ",
            "messageCause",
            "qMessage",
            "messageSources",
            "messageBuilder"
        ]
    },
    {
        "original_word": "Type",
        "typo_word": "Tups",
        "original_variable": "contentType",
        "typo_variable": "contentTups",
        "original_code": "private String getPageEncodingFromDirective(Attributes attrs,\n                                                String attrName) {\n\tString value = attrs.getValue(attrName);\n        if (attrName.equals(\"pageEncoding\")) {\n            return value;\n        }\n\n        // attrName = contentType\n        String contentType = value;\n        String encoding = null;\n        if (contentType != null) {\n\t    int loc = contentType.indexOf(CHARSET);\n\t    if (loc != -1) {\n\t\tencoding = contentType.substring(loc + CHARSET.length());\n\t    }\n\t}\n\n\treturn encoding;\n    }",
        "modified_code": "private String getPageEncodingFromDirective(Attributes attrs,\n                                                String attrName) {\n\tString value = attrs.getValue(attrName);\n        if (attrName.equals(\"pageEncoding\")) {\n            return value;\n        }\n\n        // attrName = contentType\n        String contentTups = value;\n        String encoding = null;\n        if (contentTups != null) {\n\t    int loc = contentTups.indexOf(CHARSET);\n\t    if (loc != -1) {\n\t\tencoding = contentTups.substring(loc + CHARSET.length());\n\t    }\n\t}\n\n\treturn encoding;\n    }",
        "explanations_by_ours": [
            "the content tups",
            "the content to parse",
            "the content TUPLES"
        ],
        "corrections_by_ours": [
            "contentTuples",
            "contentParse",
            "tuplesTups",
            "tupsTups",
            "parseTups",
            "contentContent",
            "contentTups"
        ],
        "corrections_by_baseline": [
            "content",
            "contentTypes",
            "serializedContent",
            "objectContent",
            "D_CONTENT",
            "Q_CONTENT",
            "contentObject",
            "stringContent",
            "responseElements",
            "contentheaders"
        ]
    },
    {
        "original_word": "temp",
        "typo_word": "fenp",
        "original_variable": "tempStr",
        "typo_variable": "fenpStr",
        "original_code": "private void setHeaderOfSheetConfiguration(final FormCommand fcommand, final SheetConfiguration sheetConfig,\r\n\t\t\tfinal int leftCol, final int rightCol) {\r\n\t\tString tempStr;\r\n\t\tif (fcommand.calcHeaderLength() == 0) {\r\n\t\t\ttempStr = CellUtility.getCellIndexLetterKey(leftCol, 0) + \" : \"\r\n\t\t\t\t\t+ CellUtility.getCellIndexLetterKey(rightCol, 0);\r\n\t\t} else {\r\n\t\t\ttempStr = CellUtility.getCellIndexLetterKey(leftCol, fcommand.getTopRow() + 1) + \" : \"\r\n\t\t\t\t\t+ CellUtility.getCellIndexLetterKey(rightCol, fcommand.getTopRow() + fcommand.calcHeaderLength());\r\n\t\t}\r\n\t\tsheetConfig.setFormHeaderRange(tempStr);\r\n\t\tsheetConfig.setHeaderCellRange(new CellRange(tempStr));\r\n\t}",
        "modified_code": "private void setHeaderOfSheetConfiguration(final FormCommand fcommand, final SheetConfiguration sheetConfig,\r\n\t\t\tfinal int leftCol, final int rightCol) {\r\n\t\tString fenpStr;\r\n\t\tif (fcommand.calcHeaderLength() == 0) {\r\n\t\t\tfenpStr = CellUtility.getCellIndexLetterKey(leftCol, 0) + \" : \"\r\n\t\t\t\t\t+ CellUtility.getCellIndexLetterKey(rightCol, 0);\r\n\t\t} else {\r\n\t\t\tfenpStr = CellUtility.getCellIndexLetterKey(leftCol, fcommand.getTopRow() + 1) + \" : \"\r\n\t\t\t\t\t+ CellUtility.getCellIndexLetterKey(rightCol, fcommand.getTopRow() + fcommand.calcHeaderLength());\r\n\t\t}\r\n\t\tsheetConfig.setFormHeaderRange(fenpStr);\r\n\t\tsheetConfig.setHeaderCellRange(new CellRange(fenpStr));\r\n\t}",
        "explanations_by_ours": [
            "the fenp string",
            "the fenp str",
            "the fenp string."
        ],
        "corrections_by_ours": [
            "fenpString",
            "stringStr",
            "strStr",
            "fenpFenp",
            "fenpStr"
        ],
        "corrections_by_baseline": [
            "boustr",
            "strb",
            "sbStr",
            "autoStr",
            "lstr",
            "subStr",
            "alphaStr",
            "str",
            "str1",
            "findStr"
        ]
    },
    {
        "original_word": "length",
        "typo_word": "lsbgth",
        "original_variable": "length",
        "typo_variable": "lsbgth",
        "original_code": "public String readString() throws IOException {\n    int length = readVInt();\n    // if (chars == null || length > chars.length)\n    char[] chars = new char[length];\n    readChars(chars, 0, length);\n    return new String(chars, 0, length);\n  }",
        "modified_code": "public String readString() throws IOException {\n    int lsbgth = readVInt();\n    // if (chars == null || length > chars.length)\n    char[] chars = new char[lsbgth];\n    readChars(chars, 0, lsbgth);\n    return new String(chars, 0, lsbgth);\n  }",
        "explanations_by_ours": [
            "the length of the string",
            "the length of the string in bytes",
            "the number of bytes to read"
        ],
        "corrections_by_ours": [
            "length",
            "bytes",
            "string",
            "number",
            "read"
        ],
        "corrections_by_baseline": [
            "bgColor",
            "bcolor",
            "rpx",
            "paintStyle",
            "sinkColor",
            "paint",
            "iconHeight",
            "fgColor",
            "iconWidth",
            "picWidth"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nzhe",
        "original_variable": "regionName",
        "typo_variable": "regionNzhe",
        "original_code": "private boolean exportRegionByArg(FunctionContext<String[]> fc)\r\n\t{\r\n\t\t\r\n\t\t  String[] args = fc.getArguments();\r\n\t\t    \r\n\t\t    if(args == null || args.length == 0)\r\n\t\t    {\r\n\t\t    \tthrow new FunctionException(\"Argument not provided\");\r\n\t\t    }\r\n\t\t    \r\n\t\t\t\r\n\t\t//Get region name from arguments\r\n\t\tString regionName = Organizer.at(0,args);\r\n\t\tif (regionName == null || regionName.length() == 0)\r\n\t\t\tthrow new FunctionException(\"regionName is required at argumeng index 0\");\r\n\t\t\r\n\t\tCache cache = CacheFactory.getAnyInstance();\r\n\t\t\r\n\t\tRegion<Object,Object> region = cache.getRegion(regionName);\r\n\r\n\t\treturn exportRegion(region,Organizer.at(1, args));\r\n\t\r\n\t}",
        "modified_code": "private boolean exportRegionByArg(FunctionContext<String[]> fc)\r\n\t{\r\n\t\t\r\n\t\t  String[] args = fc.getArguments();\r\n\t\t    \r\n\t\t    if(args == null || args.length == 0)\r\n\t\t    {\r\n\t\t    \tthrow new FunctionException(\"Argument not provided\");\r\n\t\t    }\r\n\t\t    \r\n\t\t\t\r\n\t\t//Get region name from arguments\r\n\t\tString regionNzhe = Organizer.at(0,args);\r\n\t\tif (regionNzhe == null || regionNzhe.length() == 0)\r\n\t\t\tthrow new FunctionException(\"regionName is required at argumeng index 0\");\r\n\t\t\r\n\t\tCache cache = CacheFactory.getAnyInstance();\r\n\t\t\r\n\t\tRegion<Object,Object> region = cache.getRegion(regionNzhe);\r\n\r\n\t\treturn exportRegion(region,Organizer.at(1, args));\r\n\t\r\n\t}",
        "explanations_by_ours": [
            "region name",
            "Name of region to export",
            "Name of region to be exported"
        ],
        "corrections_by_ours": [
            "regionName",
            "exportNzhe",
            "exportedNzhe",
            "regionExported",
            "nameNzhe",
            "regionExport",
            "regionRegion",
            "regionNzhe"
        ],
        "corrections_by_baseline": [
            "region",
            "regionLen",
            "numRegions",
            "regionSet",
            "regionSize",
            "twoRegions",
            "regionEnd",
            "gemRegion",
            "canonicalRegion",
            "areaInt"
        ]
    },
    {
        "original_word": "Info",
        "typo_word": "Imfk",
        "original_variable": "userToGetInfoFor",
        "typo_variable": "userToGetImfkFor",
        "original_code": "public User getUserById(Long userIdParam)\n    {\n        User userToGetInfoFor = new User();\n        userToGetInfoFor.setId(userIdParam);\n\n        if(this.serviceTicket != null)\n        {\n            userToGetInfoFor.setServiceTicket(this.serviceTicket);\n        }\n\n        try {\n            return new User(this.postJson(\n                    userToGetInfoFor, WS.Path.User.Version1.getById()));\n        }\n        //\n        catch (JSONException jsonExcept) {\n            throw new FluidClientException(jsonExcept.getMessage(),\n                    FluidClientException.ErrorCode.JSON_PARSING);\n        }\n    }",
        "modified_code": "public User getUserById(Long userIdParam)\n    {\n        User userToGetImfkFor = new User();\n        userToGetImfkFor.setId(userIdParam);\n\n        if(this.serviceTicket != null)\n        {\n            userToGetImfkFor.setServiceTicket(this.serviceTicket);\n        }\n\n        try {\n            return new User(this.postJson(\n                    userToGetImfkFor, WS.Path.User.Version1.getById()));\n        }\n        //\n        catch (JSONException jsonExcept) {\n            throw new FluidClientException(jsonExcept.getMessage(),\n                    FluidClientException.ErrorCode.JSON_PARSING);\n        }\n    }",
        "explanations_by_ours": [
            "User to get imfk for",
            "User to get imfk for.",
            "The User to get imfk for."
        ],
        "corrections_by_ours": [
            "getToGetImfkFor",
            "userToUserImfkFor",
            "userToGetImfkUser",
            "imfkToGetImfkFor",
            "userUserGetImfkFor",
            "userGetGetImfkFor",
            "userImfkGetImfkFor",
            "userToImfkImfkFor",
            "userToGetUserFor",
            "userToGetGetFor"
        ],
        "corrections_by_baseline": [
            "userToGetInfoFor",
            "userToPost",
            "adminUserCreate",
            "roleToGetInfoFor",
            "userQueryToGetInfoFor",
            "userNoti",
            "userIdentity",
            "userId",
            "appUser",
            "newUserSesion"
        ]
    },
    {
        "original_word": "creator",
        "typo_word": "cteagor",
        "original_variable": "creator",
        "typo_variable": "cteagor",
        "original_code": "protected V createEntry(final K key, KK cacheKey, Object v) {\n        FutureTask<V> task;\n        boolean creator = false;\n        if (v != null) {\n            // Another thread is already loading an instance\n            task = (FutureTask<V>) v;\n        } else {\n            task = new FutureTask<V>(new Callable<V>() {\n                public V call() throws Exception {\n                    return loader.apply(key);\n                }\n            });\n            Object prevTask = map.putIfAbsent(cacheKey, task);\n            if (prevTask == null) {\n                // creator does the load\n                creator = true;\n                task.run();\n            } else if (prevTask instanceof FutureTask) {\n                task = (FutureTask<V>) prevTask;\n            } else {\n                return (V) prevTask;\n            }\n        }\n\n        V result;\n        try {\n            result = task.get();\n        } catch (InterruptedException e) {\n            throw new IllegalStateException(\"Interrupted while loading cache item\", e);\n        } catch (ExecutionException e) {\n            Throwable cause = e.getCause();\n            if (cause instanceof RuntimeException) {\n                throw ((RuntimeException) cause);\n            }\n            throw new IllegalStateException(\"Unable to load cache item\", cause);\n        }\n        if (creator) {\n            map.put(cacheKey, result);\n        }\n        return result;\n    }",
        "modified_code": "protected V createEntry(final K key, KK cacheKey, Object v) {\n        FutureTask<V> task;\n        boolean cteagor = false;\n        if (v != null) {\n            // Another thread is already loading an instance\n            task = (FutureTask<V>) v;\n        } else {\n            task = new FutureTask<V>(new Callable<V>() {\n                public V call() throws Exception {\n                    return loader.apply(key);\n                }\n            });\n            Object prevTask = map.putIfAbsent(cacheKey, task);\n            if (prevTask == null) {\n                // creator does the load\n                cteagor = true;\n                task.run();\n            } else if (prevTask instanceof FutureTask) {\n                task = (FutureTask<V>) prevTask;\n            } else {\n                return (V) prevTask;\n            }\n        }\n\n        V result;\n        try {\n            result = task.get();\n        } catch (InterruptedException e) {\n            throw new IllegalStateException(\"Interrupted while loading cache item\", e);\n        } catch (ExecutionException e) {\n            Throwable cause = e.getCause();\n            if (cause instanceof RuntimeException) {\n                throw ((RuntimeException) cause);\n            }\n            throw new IllegalStateException(\"Unable to load cache item\", cause);\n        }\n        if (cteagor) {\n            map.put(cacheKey, result);\n        }\n        return result;\n    }",
        "explanations_by_ours": [
            "if true, the entry will be added to the cache, if false",
            "if true, the entry will be added to the cache if it is",
            "if true, the entry will be added to the cache."
        ],
        "corrections_by_ours": [
            "cache",
            "entry",
            "cache,",
            "true,",
            "false",
            "added"
        ],
        "corrections_by_baseline": [
            "ctanchor",
            "orog",
            "ct",
            "lct",
            "hysteresis",
            "cir",
            "mant",
            "sleeAci",
            "aeqm",
            "gmst"
        ]
    },
    {
        "original_word": "buff",
        "typo_word": "nkff",
        "original_variable": "sbuff",
        "typo_variable": "snkff",
        "original_code": "public String dump() {\n    DateFormatter formatter = new DateFormatter();\n    Formatter sbuff = new Formatter();\n    sbuff.format(\"%s %d %n\", name, records.size());\n    for (GridRecord record : records) {\n      sbuff.format(\" level = %d %f\", record.getLevelType1(), record.getLevel1());\n      if (null != record.getValidTime())\n        sbuff.format(\" time = %s\", formatter.toDateTimeString(record.getValidTime()));\n      sbuff.format(\"%n\");\n    }\n    return sbuff.toString();\n  }",
        "modified_code": "public String dump() {\n    DateFormatter formatter = new DateFormatter();\n    Formatter snkff = new Formatter();\n    snkff.format(\"%s %d %n\", name, records.size());\n    for (GridRecord record : records) {\n      snkff.format(\" level = %d %f\", record.getLevelType1(), record.getLevel1());\n      if (null != record.getValidTime())\n        snkff.format(\" time = %s\", formatter.toDateTimeString(record.getValidTime()));\n      snkff.format(\"%n\");\n    }\n    return snkff.toString();\n  }",
        "explanations_by_ours": [
            "a string representation of the grid record",
            "a string representation of the grid record.",
            "a Formatter object"
        ],
        "corrections_by_ours": [
            "string",
            "representation",
            "grid",
            "formatter",
            "object",
            "record"
        ],
        "corrections_by_baseline": [
            "snum",
            "boff",
            "cff",
            "ff",
            "sn",
            "csb",
            "csh",
            "sgn",
            "soff",
            "ksp"
        ]
    },
    {
        "original_word": "actual",
        "typo_word": "actiao",
        "original_variable": "actualHandlers",
        "typo_variable": "actiaoHandlers",
        "original_code": "private void configureHandlers() {\n        Handlers actualHandlers = new Handlers();\n\n        actualHandlers.setHandlers(new ArrayList<Handler>());\n\n        if (this.handlers.isEmpty()) {\n            for (Class<? extends SAML2Handler> commonHandlerClass : getDefaultHandlers()) {\n                addHandler(commonHandlerClass, actualHandlers);\n            }\n        } else {\n            for (Handler handler : this.handlers) {\n                actualHandlers.add(handler);\n            }\n        }\n\n        getPicketLinkType().setHandlers(actualHandlers);\n    }",
        "modified_code": "private void configureHandlers() {\n        Handlers actiaoHandlers = new Handlers();\n\n        actiaoHandlers.setHandlers(new ArrayList<Handler>());\n\n        if (this.handlers.isEmpty()) {\n            for (Class<? extends SAML2Handler> commonHandlerClass : getDefaultHandlers()) {\n                addHandler(commonHandlerClass, actiaoHandlers);\n            }\n        } else {\n            for (Handler handler : this.handlers) {\n                actiaoHandlers.add(handler);\n            }\n        }\n\n        getPicketLinkType().setHandlers(actiaoHandlers);\n    }",
        "explanations_by_ours": [
            "the handlers to configure",
            "the handlers",
            "the handlers to configure."
        ],
        "corrections_by_ours": [
            "actiaoConfigure",
            "handlersHandlers",
            "configureHandlers",
            "actiaoHandlers"
        ],
        "corrections_by_baseline": [
            "handlers",
            "actualHandlers",
            "requestHandlers",
            "notificationReceivers",
            "weblisteners",
            "dispatchers",
            "interceptors",
            "listHandler",
            "writerListeners",
            "triggers"
        ]
    },
    {
        "original_word": "Content",
        "typo_word": "Contwny",
        "original_variable": "stringContent",
        "typo_variable": "stringContwny",
        "original_code": "@Override\n  public void serializeInByteBufferObject(String object, ByteBuffer buffer, Object... hints) {\n    int length = object.length();\n    buffer.putInt(length);\n\n    byte[] binaryData = new byte[length * 2];\n    char[] stringContent = new char[length];\n\n    object.getChars(0, length, stringContent, 0);\n\n    int counter = 0;\n    for (char character : stringContent) {\n      binaryData[counter] = (byte) character;\n      counter++;\n\n      binaryData[counter] = (byte) (character >>> 8);\n      counter++;\n    }\n\n    buffer.put(binaryData);\n  }",
        "modified_code": "@Override\n  public void serializeInByteBufferObject(String object, ByteBuffer buffer, Object... hints) {\n    int length = object.length();\n    buffer.putInt(length);\n\n    byte[] binaryData = new byte[length * 2];\n    char[] stringContwny = new char[length];\n\n    object.getChars(0, length, stringContwny, 0);\n\n    int counter = 0;\n    for (char character : stringContwny) {\n      binaryData[counter] = (byte) character;\n      counter++;\n\n      binaryData[counter] = (byte) (character >>> 8);\n      counter++;\n    }\n\n    buffer.put(binaryData);\n  }",
        "explanations_by_ours": [
            "the string contwny to serialize",
            "the string to serialize",
            "the string contwny"
        ],
        "corrections_by_ours": [
            "serializeContwny",
            "contwnyContwny",
            "stringString",
            "stringSerialize",
            "stringContwny"
        ],
        "corrections_by_baseline": [
            "stringB",
            "dstring",
            "string",
            "aphString",
            "tstring",
            "encodedString",
            "tstr",
            "str1",
            "encStr",
            "stringChar"
        ]
    },
    {
        "original_word": "inner",
        "typo_word": "inmrr",
        "original_variable": "innerNode",
        "typo_variable": "inmrrNode",
        "original_code": "private Node T() throws ScanException {\n    Token t = peekAtCurentToken();\n\n    switch (t.type) {\n      case LITERAL:\n        advanceTokenPointer();\n        return makeNewLiteralNode(t.payload);\n      case CURLY_LEFT:\n        advanceTokenPointer();\n        Node innerNode = C();\n        Token right = peekAtCurentToken();\n        expectCurlyRight(right);\n        advanceTokenPointer();\n        Node curlyLeft = makeNewLiteralNode(CoreConstants.LEFT_ACCOLADE);\n        curlyLeft.append(innerNode);\n        curlyLeft.append(makeNewLiteralNode(CoreConstants.RIGHT_ACCOLADE));\n        return curlyLeft;\n      case START:\n        advanceTokenPointer();\n        Node v = V();\n        Token w = peekAtCurentToken();\n        expectCurlyRight(w);\n        advanceTokenPointer();\n        return v;\n      default:\n        return null;\n    }\n  }",
        "modified_code": "private Node T() throws ScanException {\n    Token t = peekAtCurentToken();\n\n    switch (t.type) {\n      case LITERAL:\n        advanceTokenPointer();\n        return makeNewLiteralNode(t.payload);\n      case CURLY_LEFT:\n        advanceTokenPointer();\n        Node inmrrNode = C();\n        Token right = peekAtCurentToken();\n        expectCurlyRight(right);\n        advanceTokenPointer();\n        Node curlyLeft = makeNewLiteralNode(CoreConstants.LEFT_ACCOLADE);\n        curlyLeft.append(inmrrNode);\n        curlyLeft.append(makeNewLiteralNode(CoreConstants.RIGHT_ACCOLADE));\n        return curlyLeft;\n      case START:\n        advanceTokenPointer();\n        Node v = V();\n        Token w = peekAtCurentToken();\n        expectCurlyRight(w);\n        advanceTokenPointer();\n        return v;\n      default:\n        return null;\n    }\n  }",
        "explanations_by_ours": [
            "The node to append to the current token position.",
            "The node to append to the current token pointer.",
            "the node to append to the current token position."
        ],
        "corrections_by_ours": [
            "pointerNode",
            "inmrrToken",
            "inmrrPointer",
            "nodeNode",
            "inmrrAppend",
            "currentNode",
            "inmrrCurrent",
            "positionNode",
            "inmrrPosition",
            "appendNode"
        ],
        "corrections_by_baseline": [
            "vnode",
            "inode",
            "localNode",
            "senderNode",
            "destNode",
            "wNode",
            "node",
            "linksNode",
            "mergeNode",
            "treeNode"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rewuly",
        "original_variable": "result",
        "typo_variable": "rewuly",
        "original_code": "public int peakNextBits(int n) throws IOException {\n        if (n > 8)\n            throw new IllegalArgumentException(\"N should be less then 8\");\n        if (nBit == 8) {\n            advance();\n            if (curByte == -1) {\n                return -1;\n            }\n        }\n        int[] bits = new int[16 - nBit];\n\n        int cnt = 0;\n        for (int i = nBit; i < 8; i++) {\n            bits[cnt++] = (curByte >> (7 - i)) & 0x1;\n        }\n\n        for (int i = 0; i < 8; i++) {\n            bits[cnt++] = (nextByte >> (7 - i)) & 0x1;\n        }\n\n        int result = 0;\n        for (int i = 0; i < n; i++) {\n            result <<= 1;\n            result |= bits[i];\n        }\n\n        return result;\n    }",
        "modified_code": "public int peakNextBits(int n) throws IOException {\n        if (n > 8)\n            throw new IllegalArgumentException(\"N should be less then 8\");\n        if (nBit == 8) {\n            advance();\n            if (curByte == -1) {\n                return -1;\n            }\n        }\n        int[] bits = new int[16 - nBit];\n\n        int cnt = 0;\n        for (int i = nBit; i < 8; i++) {\n            bits[cnt++] = (curByte >> (7 - i)) & 0x1;\n        }\n\n        for (int i = 0; i < 8; i++) {\n            bits[cnt++] = (nextByte >> (7 - i)) & 0x1;\n        }\n\n        int rewuly = 0;\n        for (int i = 0; i < n; i++) {\n            rewuly <<= 1;\n            rewuly |= bits[i];\n        }\n\n        return rewuly;\n    }",
        "explanations_by_ours": [
            "the rewuly value of the current bit stream",
            "the rewuly value",
            "the rewuly value to return"
        ],
        "corrections_by_ours": [
            "return",
            "value",
            "bit",
            "stream",
            "current"
        ],
        "corrections_by_baseline": [
            "andrew",
            "re",
            "rewrite",
            "sw",
            "raf",
            "revert",
            "rem",
            "rev",
            "newR",
            "res"
        ]
    },
    {
        "original_word": "tokens",
        "typo_word": "tkjens",
        "original_variable": "tokens",
        "typo_variable": "tkjens",
        "original_code": "public Collection<HTMLToken> tokenizeHTML() {\n        List<HTMLToken> tokens = new ArrayList<HTMLToken>();\n        String nestedTags = nestedTagsRegex(6);\n\n        Pattern p = Pattern.compile(\"\" +\n                \"(?s:<!(--.*?--\\\\s*)+>)\" +\n                \"|\" +\n                \"(?s:<\\\\?.*?\\\\?>)\" +\n                \"|\" +\n                nestedTags +\n                \"\", Pattern.CASE_INSENSITIVE);\n\n        Matcher m = p.matcher(text);\n        int lastPos = 0;\n        while (m.find()) {\n            if (lastPos < m.start()) {\n                tokens.add(HTMLToken.text(text.substring(lastPos, m.start())));\n            }\n            tokens.add(HTMLToken.tag(text.substring(m.start(), m.end())));\n            lastPos = m.end();\n        }\n        if (lastPos < text.length()) {\n            tokens.add(HTMLToken.text(text.substring(lastPos, text.length())));\n        }\n\n        return tokens;\n    }",
        "modified_code": "public Collection<HTMLToken> tokenizeHTML() {\n        List<HTMLToken> tkjens = new ArrayList<HTMLToken>();\n        String nestedTags = nestedTagsRegex(6);\n\n        Pattern p = Pattern.compile(\"\" +\n                \"(?s:<!(--.*?--\\\\s*)+>)\" +\n                \"|\" +\n                \"(?s:<\\\\?.*?\\\\?>)\" +\n                \"|\" +\n                nestedTags +\n                \"\", Pattern.CASE_INSENSITIVE);\n\n        Matcher m = p.matcher(text);\n        int lastPos = 0;\n        while (m.find()) {\n            if (lastPos < m.start()) {\n                tkjens.add(HTMLToken.text(text.substring(lastPos, m.start())));\n            }\n            tkjens.add(HTMLToken.tag(text.substring(m.start(), m.end())));\n            lastPos = m.end();\n        }\n        if (lastPos < text.length()) {\n            tkjens.add(HTMLToken.text(text.substring(lastPos, text.length())));\n        }\n\n        return tkjens;\n    }",
        "explanations_by_ours": [
            "the tokens",
            "the list of tokens",
            "the token collection"
        ],
        "corrections_by_ours": [
            "tokens",
            "token",
            "collection",
            "list"
        ],
        "corrections_by_baseline": [
            "tkns",
            "tk",
            "jsons",
            "strtk",
            "okeys",
            "tjs",
            "jsc",
            "pypsy",
            "cs",
            "dks"
        ]
    },
    {
        "original_word": "Mapped",
        "typo_word": "Malled",
        "original_variable": "attributesMapped",
        "typo_variable": "attributesMalled",
        "original_code": "protected static Map<String, String> convertNodeMap(NamedNodeMap nodeMap){\n        HashMap<String, String> attributesMapped = new HashMap<>();\n\n        for (int i = 0; i < nodeMap.getLength(); i++) {\n            Node node = nodeMap.item(i);\n            attributesMapped.put(node.getNodeName(), node.getNodeValue());\n        }\n\n        return attributesMapped;\n    }",
        "modified_code": "protected static Map<String, String> convertNodeMap(NamedNodeMap nodeMap){\n        HashMap<String, String> attributesMalled = new HashMap<>();\n\n        for (int i = 0; i < nodeMap.getLength(); i++) {\n            Node node = nodeMap.item(i);\n            attributesMalled.put(node.getNodeName(), node.getNodeValue());\n        }\n\n        return attributesMalled;\n    }",
        "explanations_by_ours": [
            "a Map of String to String",
            "A Map of String to String.",
            "a Map of String to String."
        ],
        "corrections_by_ours": [
            "attributesMap",
            "stringMalled",
            "mapMalled",
            "attributesString",
            "attributesMalled"
        ],
        "corrections_by_baseline": [
            "attributesMapped",
            "attributes",
            "allAttributes",
            "parsedAttributes",
            "newAttrs",
            "newAttributes",
            "definedAttributes",
            "attributesMap",
            "attributesDao",
            "attributesCount"
        ]
    },
    {
        "original_word": "original",
        "typo_word": "prkginal",
        "original_variable": "original",
        "typo_variable": "prkginal",
        "original_code": "private Authentication getSourceAuthentication(Authentication current) {\n\t\tAuthentication original = null;\n\n\t\t// iterate over granted authorities and find the 'switch user' authority\n\t\tCollection<? extends GrantedAuthority> authorities = current.getAuthorities();\n\n\t\tfor (GrantedAuthority auth : authorities) {\n\t\t\t// check for switch user type of authority\n\t\t\tif (auth instanceof SwitchUserGrantedAuthority) {\n\t\t\t\toriginal = ((SwitchUserGrantedAuthority) auth).getSource();\n\t\t\t\tthis.logger.debug(\"Found original switch user granted authority [\"\n\t\t\t\t\t\t+ original + \"]\");\n\t\t\t}\n\t\t}\n\n\t\treturn original;\n\t}",
        "modified_code": "private Authentication getSourceAuthentication(Authentication current) {\n\t\tAuthentication prkginal = null;\n\n\t\t// iterate over granted authorities and find the 'switch user' authority\n\t\tCollection<? extends GrantedAuthority> authorities = current.getAuthorities();\n\n\t\tfor (GrantedAuthority auth : authorities) {\n\t\t\t// check for switch user type of authority\n\t\t\tif (auth instanceof SwitchUserGrantedAuthority) {\n\t\t\t\tprkginal = ((SwitchUserGrantedAuthority) auth).getSource();\n\t\t\t\tthis.logger.debug(\"Found original switch user granted authority [\"\n\t\t\t\t\t\t+ prkginal + \"]\");\n\t\t\t}\n\t\t}\n\n\t\treturn prkginal;\n\t}",
        "explanations_by_ours": [
            "the prkginal authentication for the current user",
            "the source authentication for the current user",
            "the original source authentication for the current user"
        ],
        "corrections_by_ours": [
            "original",
            "authentication",
            "current",
            "user",
            "source"
        ],
        "corrections_by_baseline": [
            "ordinal",
            "gnode",
            "ordinalPair",
            "remapOrdinal",
            "prf",
            "pncInd",
            "fromOrdinal",
            "nj",
            "jinc",
            "sufindex"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resupg",
        "original_variable": "result",
        "typo_variable": "resupg",
        "original_code": "public Set<SbbID> getSbbIDs(ComponentRepository componentRepository) {\r\n\t\tSet<SbbID> result = new HashSet<SbbID>();\r\n\t\tbuildSbbTree(descriptor.getRootSbbID(), result,\r\n\t\t\t\tcomponentRepository);\r\n\t\treturn result;\r\n\t}",
        "modified_code": "public Set<SbbID> getSbbIDs(ComponentRepository componentRepository) {\r\n\t\tSet<SbbID> resupg = new HashSet<SbbID>();\r\n\t\tbuildSbbTree(descriptor.getRootSbbID(), resupg,\r\n\t\t\t\tcomponentRepository);\r\n\t\treturn resupg;\r\n\t}",
        "explanations_by_ours": [
            "The set of SbbIDs to be returned.",
            "Set of SbbIDs to be returned.",
            "The set of SbbIDs to return."
        ],
        "corrections_by_ours": [
            "setupg",
            "returnupg",
            "idsupg",
            "returnedupg",
            "resreturn",
            "resreturned",
            "sbbupg",
            "resset",
            "resids",
            "ressbb"
        ],
        "corrections_by_baseline": [
            "upc",
            "reload",
            "restart",
            "resul",
            "andrew",
            "overrun",
            "res",
            "up",
            "revalidate",
            "newg"
        ]
    },
    {
        "original_word": "attrs",
        "typo_word": "aytds",
        "original_variable": "attrs",
        "typo_variable": "aytds",
        "original_code": "public static String resolve(String prefix, Element element) {\n        Assert.isNotNull(element);\n\n        /* The prefix xml is by definition bound to the namespace name\n         * <code>XML_NS_NAME</code>.\n         */\n        if (XML_NS_PREFIX.equals(prefix)) {\n            return XML_NS_NAME;\n        }\n\n        /* Search from given element up parent chain to root (document)\n         * looking for a XML namespace declaration (represented as\n         * an element attribute with a name beginning in\n         * XML_PREFIX (\"xmlns\")).\n         */\n        Node current = element;\n        do {\n            NamedNodeMap attrs = current.getAttributes();\n            int n = attrs.getLength();\n            for (int i = 0; i < n; i++) {\n                Attr attr = (Attr) attrs.item(i);\n                String name = attr.getName();\n                if (name.startsWith(XML_PREFIX)) {\n                    if (name.length() == XML_PREFIX.length()) {\n                        // no prefix e.g., xmlns=\"foo:\"\n                        if (prefix == null) {\n                            String nsName = attr.getValue();\n                            if (nsName.equals(\"\")) { //$NON-NLS-1$\n                                return null;\n                            }\n                            return nsName;\n                        }\n                    } else {\n                        if (prefix != null && name.equals(XML_PREFIX + \":\" + prefix)) { //$NON-NLS-1$\n                            return attr.getValue();\n                        }\n                    }\n                }\n            }\n            do {\n                current = current.getParentNode();\n            } while (current != null && current.getNodeType() != Node.ELEMENT_NODE);\n        } while (current != null);\n        return null;\n    }",
        "modified_code": "public static String resolve(String prefix, Element element) {\n        Assert.isNotNull(element);\n\n        /* The prefix xml is by definition bound to the namespace name\n         * <code>XML_NS_NAME</code>.\n         */\n        if (XML_NS_PREFIX.equals(prefix)) {\n            return XML_NS_NAME;\n        }\n\n        /* Search from given element up parent chain to root (document)\n         * looking for a XML namespace declaration (represented as\n         * an element attribute with a name beginning in\n         * XML_PREFIX (\"xmlns\")).\n         */\n        Node current = element;\n        do {\n            NamedNodeMap aytds = current.getAttributes();\n            int n = aytds.getLength();\n            for (int i = 0; i < n; i++) {\n                Attr attr = (Attr) aytds.item(i);\n                String name = attr.getName();\n                if (name.startsWith(XML_PREFIX)) {\n                    if (name.length() == XML_PREFIX.length()) {\n                        // no prefix e.g., xmlns=\"foo:\"\n                        if (prefix == null) {\n                            String nsName = attr.getValue();\n                            if (nsName.equals(\"\")) { //$NON-NLS-1$\n                                return null;\n                            }\n                            return nsName;\n                        }\n                    } else {\n                        if (prefix != null && name.equals(XML_PREFIX + \":\" + prefix)) { //$NON-NLS-1$\n                            return attr.getValue();\n                        }\n                    }\n                }\n            }\n            do {\n                current = current.getParentNode();\n            } while (current != null && current.getNodeType() != Node.ELEMENT_NODE);\n        } while (current != null);\n        return null;\n    }",
        "explanations_by_ours": [
            "the attributes of the element to search for the namespace name",
            "the attributes of the given element to search for the namespace name",
            "the attributes of the element to search for the namespace name."
        ],
        "corrections_by_ours": [
            "attributes",
            "namespace",
            "given",
            "name",
            "search",
            "element"
        ],
        "corrections_by_baseline": [
            "dtos",
            "dks",
            "ay",
            "dodsAtt",
            "rds",
            "drs",
            "ds",
            "dcs",
            "walRecords",
            "dti"
        ]
    },
    {
        "original_word": "Size",
        "typo_word": "Skxe",
        "original_variable": "maxSize",
        "typo_variable": "maxSkxe",
        "original_code": "public String getMessage() {\n    if (!specialConstructor) {\n      return super.getMessage();\n    }\n    StringBuilder expected = new StringBuilder();\n    int maxSize = 0;\n    for (int[] expectedTokenSequence : expectedTokenSequences) {\n      if (maxSize < expectedTokenSequence.length) {\n        maxSize = expectedTokenSequence.length;\n      }\n      for (int anExpectedTokenSequence : expectedTokenSequence) {\n        expected.append(tokenImage[anExpectedTokenSequence]).append(' ');\n      }\n      if (expectedTokenSequence[expectedTokenSequence.length - 1] != 0) {\n        expected.append(\"...\");\n      }\n      expected.append(eol).append(\"    \");\n    }\n\n    StringBuilder b = new StringBuilder(\"Encountered \\\"\");\n    Token tok = currentToken.next;\n    for (int i = 0; i < maxSize; i++) {\n      if (i != 0) b.append(\" \");\n      if (tok.kind == 0) {\n        b.append(tokenImage[0]);\n        break;\n      }\n      b.append(\" \").append(tokenImage[tok.kind]).append(\" \\\"\");\n      b.append(add_escapes(tok.image));\n      b.append(\" \\\"\");\n      tok = tok.next; \n    }\n    b.append(\"\\\" at line \").append(currentToken.next.beginLine).append(\", column \").append(currentToken.next.beginColumn);\n    b.append(\".\").append(eol);\n    if (expectedTokenSequences.length == 1) {\n      b.append(\"Was expecting:\").append(eol).append(\"    \");\n    } else {\n      b.append(\"Was expecting one of:\").append(eol).append(\"    \");\n    }\n    expected.append(expected.toString());\n    return b.toString();\n  }",
        "modified_code": "public String getMessage() {\n    if (!specialConstructor) {\n      return super.getMessage();\n    }\n    StringBuilder expected = new StringBuilder();\n    int maxSkxe = 0;\n    for (int[] expectedTokenSequence : expectedTokenSequences) {\n      if (maxSkxe < expectedTokenSequence.length) {\n        maxSkxe = expectedTokenSequence.length;\n      }\n      for (int anExpectedTokenSequence : expectedTokenSequence) {\n        expected.append(tokenImage[anExpectedTokenSequence]).append(' ');\n      }\n      if (expectedTokenSequence[expectedTokenSequence.length - 1] != 0) {\n        expected.append(\"...\");\n      }\n      expected.append(eol).append(\"    \");\n    }\n\n    StringBuilder b = new StringBuilder(\"Encountered \\\"\");\n    Token tok = currentToken.next;\n    for (int i = 0; i < maxSkxe; i++) {\n      if (i != 0) b.append(\" \");\n      if (tok.kind == 0) {\n        b.append(tokenImage[0]);\n        break;\n      }\n      b.append(\" \").append(tokenImage[tok.kind]).append(\" \\\"\");\n      b.append(add_escapes(tok.image));\n      b.append(\" \\\"\");\n      tok = tok.next; \n    }\n    b.append(\"\\\" at line \").append(currentToken.next.beginLine).append(\", column \").append(currentToken.next.beginColumn);\n    b.append(\".\").append(eol);\n    if (expectedTokenSequences.length == 1) {\n      b.append(\"Was expecting:\").append(eol).append(\"    \");\n    } else {\n      b.append(\"Was expecting one of:\").append(eol).append(\"    \");\n    }\n    expected.append(expected.toString());\n    return b.toString();\n  }",
        "explanations_by_ours": [
            "the maximum number of expected tokens.",
            "the maximum number of tokens expected.",
            "the maximum number of expected token sequences."
        ],
        "corrections_by_ours": [
            "maximumSkxe",
            "maxSequences",
            "maxToken",
            "numberSkxe",
            "maxNumber",
            "maxTokens",
            "maxMaximum",
            "maxExpected",
            "expectedSkxe",
            "sequencesSkxe"
        ],
        "corrections_by_baseline": [
            "maxSFB",
            "maxM",
            "v_max",
            "maxw",
            "maxZ",
            "xmax",
            "maxi",
            "maxXMin",
            "maxX",
            "kmax"
        ]
    },
    {
        "original_word": "passphrase",
        "typo_word": "passphdsse",
        "original_variable": "passphrase",
        "typo_variable": "passphdsse",
        "original_code": "private KeyManager[] createKeyManagers(ContextAware context)\n      throws NoSuchProviderException, NoSuchAlgorithmException,\n      UnrecoverableKeyException, KeyStoreException {\n\n    if (getKeyStore() == null) return null;\n\n    KeyStore keyStore = getKeyStore().createKeyStore();\n    context.addInfo(\n        \"key store of type '\" + keyStore.getType()\n        + \"' provider '\" + keyStore.getProvider()\n        + \"': \" + getKeyStore().getLocation());\n\n    KeyManagerFactory kmf = getKeyManagerFactory().createKeyManagerFactory();\n    context.addInfo(\"key manager algorithm '\" + kmf.getAlgorithm()\n        + \"' provider '\" + kmf.getProvider() + \"'\");\n\n    char[] passphrase = getKeyStore().getPassword().toCharArray();\n    kmf.init(keyStore, passphrase);\n    return kmf.getKeyManagers();\n  }",
        "modified_code": "private KeyManager[] createKeyManagers(ContextAware context)\n      throws NoSuchProviderException, NoSuchAlgorithmException,\n      UnrecoverableKeyException, KeyStoreException {\n\n    if (getKeyStore() == null) return null;\n\n    KeyStore keyStore = getKeyStore().createKeyStore();\n    context.addInfo(\n        \"key store of type '\" + keyStore.getType()\n        + \"' provider '\" + keyStore.getProvider()\n        + \"': \" + getKeyStore().getLocation());\n\n    KeyManagerFactory kmf = getKeyManagerFactory().createKeyManagerFactory();\n    context.addInfo(\"key manager algorithm '\" + kmf.getAlgorithm()\n        + \"' provider '\" + kmf.getProvider() + \"'\");\n\n    char[] passphdsse = getKeyStore().getPassword().toCharArray();\n    kmf.init(keyStore, passphdsse);\n    return kmf.getKeyManagers();\n  }",
        "explanations_by_ours": [
            "the passphdsse",
            "the password",
            "the password for the key store"
        ],
        "corrections_by_ours": [
            "passwordphdsse",
            "passphdstore",
            "ssephdsse",
            "phdphdsse",
            "passpasssse",
            "passpasswordsse",
            "passphdpass",
            "passphdpassword",
            "storephdsse",
            "keyphdsse"
        ],
        "corrections_by_baseline": [
            "allpass",
            "pass",
            "psemi",
            "sso",
            "ksPasswdChars",
            "ksPasswdCA",
            "specp",
            "sa",
            "SA",
            "psi"
        ]
    },
    {
        "original_word": "proxy",
        "typo_word": "pfixy",
        "original_variable": "proxy",
        "typo_variable": "pfixy",
        "original_code": "public void getNameAndDimensions(StringBuilder buf, boolean useFullName, boolean strict) {\n    Formatter proxy = new Formatter();\n    getNameAndDimensions(proxy, useFullName, strict);\n    buf.append(proxy.toString());\n  }",
        "modified_code": "public void getNameAndDimensions(StringBuilder buf, boolean useFullName, boolean strict) {\n    Formatter pfixy = new Formatter();\n    getNameAndDimensions(pfixy, useFullName, strict);\n    buf.append(pfixy.toString());\n  }",
        "explanations_by_ours": [
            "the formatter to use",
            "the formatter to use to format the name and dimensions",
            "the formatter to use to format the name and dimensions of this metric"
        ],
        "corrections_by_ours": [
            "dimensions",
            "use",
            "format",
            "metric",
            "name",
            "formatter"
        ],
        "corrections_by_baseline": [
            "rgbfix",
            "fixer",
            "y_off",
            "pad",
            "ybeg",
            "yFp",
            "rngy",
            "hgap",
            "lxcent",
            "hAdjusted"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "fesulr",
        "original_variable": "result",
        "typo_variable": "fesulr",
        "original_code": "public static <T,U,E extends Throwable> Set<U> createSet (Iterator<T> elements, AFunction1<T,U,E> f) throws E {\n        final Set<U> result = new HashSet<> ();\n        while (elements.hasNext ()) result.add (f.apply (elements.next ()));\n        return result;\n    }",
        "modified_code": "public static <T,U,E extends Throwable> Set<U> createSet (Iterator<T> elements, AFunction1<T,U,E> f) throws E {\n        final Set<U> fesulr = new HashSet<> ();\n        while (elements.hasNext ()) fesulr.add (f.apply (elements.next ()));\n        return fesulr;\n    }",
        "explanations_by_ours": [
            "the new set",
            "the resulting set",
            "the set to be created"
        ],
        "corrections_by_ours": [
            "resulting",
            "set",
            "new",
            "created"
        ],
        "corrections_by_baseline": [
            "isr",
            "hf",
            "emf",
            "rp",
            "aeqm",
            "mf",
            "mefd",
            "usv",
            "rsf",
            "acf"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rwshlt",
        "original_variable": "result",
        "typo_variable": "rwshlt",
        "original_code": "public Set<SbbEntityID> getSbbEntities() {\n\t\tfinal Node node = getNode();\n\t\tif (node == null) {\n\t\t\treturn Collections.emptySet();\n\t\t}\n\t\tHashSet<SbbEntityID> result = new HashSet<SbbEntityID>();\n\t\tServiceID serviceID = null;\n\t\tfor (Object obj : node.getChildrenNames()) {\n\t\t\tserviceID = (ServiceID) obj;\n\t\t\tfor (SbbEntityID sbbEntityID : getRootSbbEntityIDs(serviceID)) {\n\t\t\t\tresult.add(sbbEntityID);\n\t\t\t\tcollectSbbEntities(sbbEntityID,result);\n\t\t\t}\n\t\t}\t\t\n\t\treturn result;\n\t}",
        "modified_code": "public Set<SbbEntityID> getSbbEntities() {\n\t\tfinal Node node = getNode();\n\t\tif (node == null) {\n\t\t\treturn Collections.emptySet();\n\t\t}\n\t\tHashSet<SbbEntityID> rwshlt = new HashSet<SbbEntityID>();\n\t\tServiceID serviceID = null;\n\t\tfor (Object obj : node.getChildrenNames()) {\n\t\t\tserviceID = (ServiceID) obj;\n\t\t\tfor (SbbEntityID sbbEntityID : getRootSbbEntityIDs(serviceID)) {\n\t\t\t\trwshlt.add(sbbEntityID);\n\t\t\t\tcollectSbbEntities(sbbEntityID,rwshlt);\n\t\t\t}\n\t\t}\t\t\n\t\treturn rwshlt;\n\t}",
        "explanations_by_ours": [
            "the set of sbb entities",
            "the set of sbb entity IDs",
            "the set of sbb entity ids"
        ],
        "corrections_by_ours": [
            "set",
            "ids",
            "sbb",
            "entities",
            "entity"
        ],
        "corrections_by_baseline": [
            "wrp",
            "wrrp",
            "WR",
            "wr",
            "w",
            "W",
            "towrite",
            "pwr",
            "irw",
            "ftrm"
        ]
    },
    {
        "original_word": "partial",
        "typo_word": "oartiai",
        "original_variable": "partial",
        "typo_variable": "oartiai",
        "original_code": "public static Object transformResult(Object result) {\n    if (java8MethodIsArray == null || !(result instanceof Map)) {\n      return result;\n    }\n    // PATCH BY MAT ABOUT NASHORN RETURNING VALUE FOR ARRAYS.\n    try {\n      if ((Boolean) java8MethodIsArray.invoke(result)) {\n        List<?> partial = new ArrayList(((Map) result).values());\n        List<Object> finalResult = new ArrayList<Object>();\n        for (Object o : partial) {\n          finalResult.add(transformResult(o));\n        }\n        return finalResult;\n      } else {\n        Map<Object, Object> mapResult = (Map) result;\n        List<Object> keys = new ArrayList<Object>(mapResult.keySet());\n        for (Object key : keys) {\n          mapResult.put(key, transformResult(mapResult.get(key)));\n        }\n        return mapResult;\n      }\n    } catch (Exception e) {\n      OLogManager.instance().error(OCommandExecutorUtility.class, \"\", e);\n    }\n\n    return result;\n  }",
        "modified_code": "public static Object transformResult(Object result) {\n    if (java8MethodIsArray == null || !(result instanceof Map)) {\n      return result;\n    }\n    // PATCH BY MAT ABOUT NASHORN RETURNING VALUE FOR ARRAYS.\n    try {\n      if ((Boolean) java8MethodIsArray.invoke(result)) {\n        List<?> oartiai = new ArrayList(((Map) result).values());\n        List<Object> finalResult = new ArrayList<Object>();\n        for (Object o : oartiai) {\n          finalResult.add(transformResult(o));\n        }\n        return finalResult;\n      } else {\n        Map<Object, Object> mapResult = (Map) result;\n        List<Object> keys = new ArrayList<Object>(mapResult.keySet());\n        for (Object key : keys) {\n          mapResult.put(key, transformResult(mapResult.get(key)));\n        }\n        return mapResult;\n      }\n    } catch (Exception e) {\n      OLogManager.instance().error(OCommandExecutorUtility.class, \"\", e);\n    }\n\n    return result;\n  }",
        "explanations_by_ours": [
            "the result of the command",
            "the result of the command to be transformed",
            "the result of the command to transform"
        ],
        "corrections_by_ours": [
            "transform",
            "transformed",
            "command",
            "result"
        ],
        "corrections_by_baseline": [
            "oii",
            "pco",
            "aspi",
            "ia",
            "baos",
            "o",
            "uom",
            "smo",
            "utco",
            "csa"
        ]
    },
    {
        "original_word": "Style",
        "typo_word": "Sryls",
        "original_variable": "rfc2965Style",
        "typo_variable": "rfc2965Sryls",
        "original_code": "public Set<Cookie> decode(String header) {\n    if (header == null) {\n      throw new NullPointerException(\"header\");\n    }\n    final int headerLen = header.length();\n\n    if (headerLen == 0) {\n      return Collections.emptySet();\n    }\n\n    Set<Cookie> cookies = new TreeSet<Cookie>();\n\n    int i = 0;\n\n    boolean rfc2965Style = false;\n    if (header.regionMatches(true, 0, RFC2965_VERSION, 0, RFC2965_VERSION.length())) {\n      // RFC 2965 style cookie, move to after version value\n      i = header.indexOf(';') + 1;\n      rfc2965Style = true;\n    }\n\n    loop:\n    for (; ; ) {\n\n      // Skip spaces and separators.\n      for (; ; ) {\n        if (i == headerLen) {\n          break loop;\n        }\n        char c = header.charAt(i);\n        if (c == '\\t' || c == '\\n' || c == 0x0b || c == '\\f' || c == '\\r' || c == ' ' || c == ','\n            || c == ';') {\n          i++;\n          continue;\n        }\n        break;\n      }\n\n      int nameBegin = i;\n      int nameEnd = i;\n      int valueBegin = -1;\n      int valueEnd = -1;\n\n      if (i != headerLen) {\n        keyValLoop:\n        for (; ; ) {\n\n          char curChar = header.charAt(i);\n          if (curChar == ';') {\n            // NAME; (no value till ';')\n            nameEnd = i;\n            valueBegin = valueEnd = -1;\n            break keyValLoop;\n\n          } else if (curChar == '=') {\n            // NAME=VALUE\n            nameEnd = i;\n            i++;\n            if (i == headerLen) {\n              // NAME= (empty value, i.e. nothing after '=')\n              valueBegin = valueEnd = 0;\n              break keyValLoop;\n            }\n\n            valueBegin = i;\n            // NAME=VALUE;\n            int semiPos = header.indexOf(';', i);\n            valueEnd = i = semiPos > 0 ? semiPos : headerLen;\n            break keyValLoop;\n          } else {\n            i++;\n          }\n\n          if (i == headerLen) {\n            // NAME (no value till the end of string)\n            nameEnd = headerLen;\n            valueBegin = valueEnd = -1;\n            break;\n          }\n        }\n      }\n\n      if (rfc2965Style\n          && (header.regionMatches(nameBegin, RFC2965_PATH, 0, RFC2965_PATH.length())\n              || header.regionMatches(nameBegin, RFC2965_DOMAIN, 0, RFC2965_DOMAIN.length())\n              || header.regionMatches(nameBegin, RFC2965_PORT, 0, RFC2965_PORT.length()))) {\n\n        // skip obsolete RFC2965 fields\n        continue;\n      }\n\n      DefaultCookie cookie = initCookie(header, nameBegin, nameEnd, valueBegin, valueEnd);\n      if (cookie != null) {\n        cookies.add(cookie);\n      }\n    }\n\n    return cookies;\n  }",
        "modified_code": "public Set<Cookie> decode(String header) {\n    if (header == null) {\n      throw new NullPointerException(\"header\");\n    }\n    final int headerLen = header.length();\n\n    if (headerLen == 0) {\n      return Collections.emptySet();\n    }\n\n    Set<Cookie> cookies = new TreeSet<Cookie>();\n\n    int i = 0;\n\n    boolean rfc2965Sryls = false;\n    if (header.regionMatches(true, 0, RFC2965_VERSION, 0, RFC2965_VERSION.length())) {\n      // RFC 2965 style cookie, move to after version value\n      i = header.indexOf(';') + 1;\n      rfc2965Sryls = true;\n    }\n\n    loop:\n    for (; ; ) {\n\n      // Skip spaces and separators.\n      for (; ; ) {\n        if (i == headerLen) {\n          break loop;\n        }\n        char c = header.charAt(i);\n        if (c == '\\t' || c == '\\n' || c == 0x0b || c == '\\f' || c == '\\r' || c == ' ' || c == ','\n            || c == ';') {\n          i++;\n          continue;\n        }\n        break;\n      }\n\n      int nameBegin = i;\n      int nameEnd = i;\n      int valueBegin = -1;\n      int valueEnd = -1;\n\n      if (i != headerLen) {\n        keyValLoop:\n        for (; ; ) {\n\n          char curChar = header.charAt(i);\n          if (curChar == ';') {\n            // NAME; (no value till ';')\n            nameEnd = i;\n            valueBegin = valueEnd = -1;\n            break keyValLoop;\n\n          } else if (curChar == '=') {\n            // NAME=VALUE\n            nameEnd = i;\n            i++;\n            if (i == headerLen) {\n              // NAME= (empty value, i.e. nothing after '=')\n              valueBegin = valueEnd = 0;\n              break keyValLoop;\n            }\n\n            valueBegin = i;\n            // NAME=VALUE;\n            int semiPos = header.indexOf(';', i);\n            valueEnd = i = semiPos > 0 ? semiPos : headerLen;\n            break keyValLoop;\n          } else {\n            i++;\n          }\n\n          if (i == headerLen) {\n            // NAME (no value till the end of string)\n            nameEnd = headerLen;\n            valueBegin = valueEnd = -1;\n            break;\n          }\n        }\n      }\n\n      if (rfc2965Sryls\n          && (header.regionMatches(nameBegin, RFC2965_PATH, 0, RFC2965_PATH.length())\n              || header.regionMatches(nameBegin, RFC2965_DOMAIN, 0, RFC2965_DOMAIN.length())\n              || header.regionMatches(nameBegin, RFC2965_PORT, 0, RFC2965_PORT.length()))) {\n\n        // skip obsolete RFC2965 fields\n        continue;\n      }\n\n      DefaultCookie cookie = initCookie(header, nameBegin, nameEnd, valueBegin, valueEnd);\n      if (cookie != null) {\n        cookies.add(cookie);\n      }\n    }\n\n    return cookies;\n  }",
        "explanations_by_ours": [
            "true if the header contains a SRYL style cookie, false if",
            "true if the header contains a SRYL style cookie, false otherwise",
            "true if the header contains a SRYL header, false if it"
        ],
        "corrections_by_ours": [
            "rfc2965Sryl",
            "rfc2965Style",
            "rfc2965Otherwise",
            "rfc2965False",
            "rfc2965True",
            "falseSryls",
            "rfc2965Contains",
            "srylSryls",
            "headerSryls",
            "containsSryls"
        ],
        "corrections_by_baseline": [
            "RFC2483",
            "rfc2965Style",
            "ldifs",
            "S55",
            "RFC_2822_DOMAIN",
            "jseSecurityMDs",
            "ls",
            "RFC_1035_DOMAIN_NAME",
            "secConstraints",
            "S53"
        ]
    },
    {
        "original_word": "accept",
        "typo_word": "afcepy",
        "original_variable": "accept",
        "typo_variable": "afcepy",
        "original_code": "public int dapparse(String text, DDS dds, DAS das, DAP2Exception err) throws ParseException\n    {\n        //setDebugLevel(1);\n        ddsobject = dds;\n        dasobject = das;\n        errobject = (err == null ? new DAP2Exception() : err);\n\n        dapdebug = getDebugLevel();\n        Boolean accept = parse(text);\n        if(!accept)\n            throw new ParseException(\"Dap2 Parser returned false\");\n        return parseClass;\n    }",
        "modified_code": "public int dapparse(String text, DDS dds, DAS das, DAP2Exception err) throws ParseException\n    {\n        //setDebugLevel(1);\n        ddsobject = dds;\n        dasobject = das;\n        errobject = (err == null ? new DAP2Exception() : err);\n\n        dapdebug = getDebugLevel();\n        Boolean afcepy = parse(text);\n        if(!afcepy)\n            throw new ParseException(\"Dap2 Parser returned false\");\n        return parseClass;\n    }",
        "explanations_by_ours": [
            "true if the text is afcepy, false otherwise",
            "true if the text should be parsed, false otherwise",
            "true if the text is afcepy, false otherwise."
        ],
        "corrections_by_ours": [
            "afcepy,",
            "parsed,",
            "false",
            "text",
            "true",
            "otherwise"
        ],
        "corrections_by_baseline": [
            "af",
            "fbase",
            "utco",
            "icf",
            "fci",
            "acf",
            "xfac",
            "dpe",
            "pypsy",
            "cfac"
        ]
    },
    {
        "original_word": "data",
        "typo_word": "catx",
        "original_variable": "data_res",
        "typo_variable": "catx_res",
        "original_code": "static double code_reslookup( int code )\r\n    {\r\n\r\n      double data_res;\r\n\r\n      final  double[] res = {\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    /*   0-  9 */\r\n        0,    0,    0,    0,    0,    0,    1,    2,    4,    1,    /*  10- 19 */\r\n        2,    4, 0.25,  0.5,    1, 0.25,  0.5,    1, 0.25,    0,    /*  20- 29 */\r\n        1,    0,    1,    0,    0,    1,    4,    1,    4,    0,    /*  30- 39 */\r\n        0,    4,    0,    0,    0,    0,    0,    0,    0,    0,    /*  40- 49 */\r\n        0,    0,    0,    0,    0,  0.5,    1,    4,    0,    0,    /*  50- 59 */\r\n        0,    0,    0,    4,    4,    4,    4,    0,    0,    0,    /*  60- 69 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    1,    1,    /*  70- 79 */\r\n        1,    4,    0,    0,    0,    0,    0,    0,    0,    4,    /*  80- 89 */\r\n        4,    0,    0,    0,    1,    0,    0,    0,    0, 0.25,    /*  90- 99 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    /* 100-109 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    /* 110-119 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    /* 120-129 */\r\n        0,    0,    0,    0,    1,    1,    0,    0,    1,    0,    /* 130-139 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    /* 140-149 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0, 0.25,    /* 150-159 */\r\n        0, 0.25,    0, 0.25,    0, 0.25,    0,    0,    0,    2,    /* 160-169 */\r\n     0.25,    2, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,    0,    0,    /* 170-179 */\r\n        0,  150.0, 150.0, 0,    0,    0, 300.0,   0,    0,    0,    /* 180-189 */\r\n      };\r\n\r\n\r\n      if ( code < 0 || code > 189 )\r\n        data_res = 0;\r\n      else\r\n        data_res = res[code];\r\n\r\n      return data_res;\r\n\r\n    }",
        "modified_code": "static double code_reslookup( int code )\r\n    {\r\n\r\n      double catx_res;\r\n\r\n      final  double[] res = {\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    /*   0-  9 */\r\n        0,    0,    0,    0,    0,    0,    1,    2,    4,    1,    /*  10- 19 */\r\n        2,    4, 0.25,  0.5,    1, 0.25,  0.5,    1, 0.25,    0,    /*  20- 29 */\r\n        1,    0,    1,    0,    0,    1,    4,    1,    4,    0,    /*  30- 39 */\r\n        0,    4,    0,    0,    0,    0,    0,    0,    0,    0,    /*  40- 49 */\r\n        0,    0,    0,    0,    0,  0.5,    1,    4,    0,    0,    /*  50- 59 */\r\n        0,    0,    0,    4,    4,    4,    4,    0,    0,    0,    /*  60- 69 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    1,    1,    /*  70- 79 */\r\n        1,    4,    0,    0,    0,    0,    0,    0,    0,    4,    /*  80- 89 */\r\n        4,    0,    0,    0,    1,    0,    0,    0,    0, 0.25,    /*  90- 99 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    /* 100-109 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    /* 110-119 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    /* 120-129 */\r\n        0,    0,    0,    0,    1,    1,    0,    0,    1,    0,    /* 130-139 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    /* 140-149 */\r\n        0,    0,    0,    0,    0,    0,    0,    0,    0, 0.25,    /* 150-159 */\r\n        0, 0.25,    0, 0.25,    0, 0.25,    0,    0,    0,    2,    /* 160-169 */\r\n     0.25,    2, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25,    0,    0,    /* 170-179 */\r\n        0,  150.0, 150.0, 0,    0,    0, 300.0,   0,    0,    0,    /* 180-189 */\r\n      };\r\n\r\n\r\n      if ( code < 0 || code > 189 )\r\n        catx_res = 0;\r\n      else\r\n        catx_res = res[code];\r\n\r\n      return catx_res;\r\n\r\n    }",
        "explanations_by_ours": [
            "the code's reslookup value",
            "the code's reslookup value.",
            "the value of the code's reslookup value"
        ],
        "corrections_by_ours": [
            "catx_code's",
            "value_res",
            "code's_res",
            "lookup_res",
            "res_res",
            "catx_lookup",
            "catx_value",
            "catx_res"
        ],
        "corrections_by_baseline": [
            "dcat",
            "dapex",
            "cat",
            "catS",
            "par1r",
            "geomDs",
            "xArr",
            "datasetOut",
            "downsampledIX",
            "catref"
        ]
    },
    {
        "original_word": "Slash",
        "typo_word": "Skqsh",
        "original_variable": "lastSlash",
        "typo_variable": "lastSkqsh",
        "original_code": "public void init(String name, final String superName, final String suffix, final String reqProxyClassName) {\n\t\tint lastSlash = name.lastIndexOf('/');\n\t\tthis.targetPackage = lastSlash == -1 ? StringPool.EMPTY : name.substring(0, lastSlash).replace('/', '.');\n\t\tthis.targetClassname = name.substring(lastSlash + 1);\n\t\tthis.nextSupername = superName;\n\t\tthis.superName = name;\n\n\t\t// create proxy name\n\t\tif (reqProxyClassName != null) {\n\t\t\tif (reqProxyClassName.startsWith(DOT)) {\n\t\t\t\tname = name.substring(0, lastSlash) + '/' + reqProxyClassName.substring(1);\n\t\t\t} else if (reqProxyClassName.endsWith(DOT)) {\n\t\t\t\tname = reqProxyClassName.replace('.', '/') + this.targetClassname;\n\t\t\t} else {\n\t\t\t\tname = reqProxyClassName.replace('.', '/');\n\t\t\t}\n\t\t}\n\n\t\t// add optional suffix\n\t\tif (suffix != null) {\n\t\t\tname += suffix;\n\t\t}\n\t\tthis.thisReference = name;\n\t\tthis.superReference = this.superName;\n\t}",
        "modified_code": "public void init(String name, final String superName, final String suffix, final String reqProxyClassName) {\n\t\tint lastSkqsh = name.lastIndexOf('/');\n\t\tthis.targetPackage = lastSkqsh == -1 ? StringPool.EMPTY : name.substring(0, lastSkqsh).replace('/', '.');\n\t\tthis.targetClassname = name.substring(lastSkqsh + 1);\n\t\tthis.nextSupername = superName;\n\t\tthis.superName = name;\n\n\t\t// create proxy name\n\t\tif (reqProxyClassName != null) {\n\t\t\tif (reqProxyClassName.startsWith(DOT)) {\n\t\t\t\tname = name.substring(0, lastSkqsh) + '/' + reqProxyClassName.substring(1);\n\t\t\t} else if (reqProxyClassName.endsWith(DOT)) {\n\t\t\t\tname = reqProxyClassName.replace('.', '/') + this.targetClassname;\n\t\t\t} else {\n\t\t\t\tname = reqProxyClassName.replace('.', '/');\n\t\t\t}\n\t\t}\n\n\t\t// add optional suffix\n\t\tif (suffix != null) {\n\t\t\tname += suffix;\n\t\t}\n\t\tthis.thisReference = name;\n\t\tthis.superReference = this.superName;\n\t}",
        "explanations_by_ours": [
            "the last dot in the name",
            "the last path segment of the name",
            "the last dot in the name."
        ],
        "corrections_by_ours": [
            "dotSkqsh",
            "nameSkqsh",
            "pathSkqsh",
            "lastPath",
            "lastLast",
            "segmentSkqsh",
            "lastSegment",
            "lastDot",
            "lastName",
            "lastSkqsh"
        ],
        "corrections_by_baseline": [
            "sr_last",
            "last",
            "last_",
            "lastn",
            "lastUcum",
            "lastClz",
            "lastTx",
            "ksp",
            "lastBucket",
            "lastShardId"
        ]
    },
    {
        "original_word": "status",
        "typo_word": "sratis",
        "original_variable": "statusCode",
        "typo_variable": "sratisCode",
        "original_code": "public static FeatureType isCdmrfEndpoint(String endpoint) throws IOException {\n\n    HTTPSession httpClient = HTTPFactory.newSession(endpoint);\n    String url = endpoint + \"?req=featureType\";\n\n    // get the header\n    try (HTTPMethod method = HTTPFactory.Get(httpClient, url)) {\n      method.setFollowRedirects(true);\n      int statusCode = method.execute();\n      if (statusCode != 200) return null;\n      String content = method.getResponseAsString();\n      return FeatureType.getType(content);\n\n    } catch (Throwable t) {\n      t.printStackTrace();\n      return null;\n    }\n  }",
        "modified_code": "public static FeatureType isCdmrfEndpoint(String endpoint) throws IOException {\n\n    HTTPSession httpClient = HTTPFactory.newSession(endpoint);\n    String url = endpoint + \"?req=featureType\";\n\n    // get the header\n    try (HTTPMethod method = HTTPFactory.Get(httpClient, url)) {\n      method.setFollowRedirects(true);\n      int sratisCode = method.execute();\n      if (sratisCode != 200) return null;\n      String content = method.getResponseAsString();\n      return FeatureType.getType(content);\n\n    } catch (Throwable t) {\n      t.printStackTrace();\n      return null;\n    }\n  }",
        "explanations_by_ours": [
            "the status code of the sratis endpoint",
            "the status code of the request",
            "the status code of the sratis request"
        ],
        "corrections_by_ours": [
            "statusCode",
            "requestCode",
            "sratisRequest",
            "endpointCode",
            "sratisEndpoint",
            "codeCode",
            "sratisStatus",
            "sratisSratis",
            "sratisCode"
        ],
        "corrections_by_baseline": [
            "shortRepPrice",
            "literalPrice",
            "ratio",
            "ratdf",
            "longRepPrice",
            "iso2Codes",
            "nativeRatio",
            "rho",
            "sco",
            "xFactor"
        ]
    },
    {
        "original_word": "Args",
        "typo_word": "Aths",
        "original_variable": "selectionArgs",
        "typo_variable": "selectionAths",
        "original_code": "public Cursor query(long geoPackageId, String tableName) {\n        String selection = GeometryMetadata.COLUMN_GEOPACKAGE_ID\n                + \" = ? AND \" + GeometryMetadata.COLUMN_TABLE_NAME + \" = ?\";\n        String[] selectionArgs = new String[]{String.valueOf(geoPackageId), tableName};\n        Cursor cursor = db.query(\n                GeometryMetadata.TABLE_NAME,\n                GeometryMetadata.COLUMNS, selection, selectionArgs, null, null, null);\n        return cursor;\n    }",
        "modified_code": "public Cursor query(long geoPackageId, String tableName) {\n        String selection = GeometryMetadata.COLUMN_GEOPACKAGE_ID\n                + \" = ? AND \" + GeometryMetadata.COLUMN_TABLE_NAME + \" = ?\";\n        String[] selectionAths = new String[]{String.valueOf(geoPackageId), tableName};\n        Cursor cursor = db.query(\n                GeometryMetadata.TABLE_NAME,\n                GeometryMetadata.COLUMNS, selection, selectionAths, null, null, null);\n        return cursor;\n    }",
        "explanations_by_ours": [
            "A list of column names to select from the geometry metadata",
            "A list of columns to select from the geometry metadata",
            "A list of column names that should be selected in the geometry metadata"
        ],
        "corrections_by_ours": [
            "selectedAths",
            "selectAths",
            "selectionNames",
            "columnAths",
            "listAths",
            "geometryAths",
            "selectionColumns",
            "selectionSelected",
            "selectionGeometry",
            "selectionMetadata"
        ],
        "corrections_by_baseline": [
            "selection",
            "selectionArgs",
            "oneSelection",
            "strSelection",
            "selIndex",
            "selectSize",
            "hasSelection",
            "selections",
            "indexSelect",
            "selectedNodes"
        ]
    },
    {
        "original_word": "terminate",
        "typo_word": "tfrmjnate",
        "original_variable": "terminateTx",
        "typo_variable": "tfrmjnateTx",
        "original_code": "public ProfileTableActivity getProfileTableActivity(String profileTableName)\r\n\t\t\tthrows NullPointerException, UnrecognizedProfileTableNameException,\r\n\t\t\tTransactionRolledbackLocalException, FacilityException {\r\n\r\n\t\tif (logger.isTraceEnabled()) {\r\n\t\t\tlogger.trace(\"getProfileTableActivity( profileTableName = \"\r\n\t\t\t\t\t+ profileTableName + \" )\");\r\n\t\t}\r\n\t\t\t\t\r\n\t\tfinal SleeTransactionManager sleeTransactionManager = profileManagement.getSleeContainer()\r\n\t\t\t\t.getTransactionManager();\t\t\r\n\t\tboolean terminateTx = sleeTransactionManager.requireTransaction();\r\n\t\ttry {\r\n\t\t\treturn profileManagement.getProfileTable(profileTableName).getActivity();\r\n\t\t} catch (NullPointerException e) {\r\n\t\t\tthrow e;\r\n\t\t} catch (UnrecognizedProfileTableNameException e) {\r\n\t\t\tthrow e;\r\n\t\t} catch (Throwable e) {\r\n\t\t\tthrow new FacilityException(\"Failed to obtain profile table.\", e);\r\n\t\t} finally {\r\n\t\t\t// never rollback\r\n\t\t\ttry {\r\n\t\t\t\tsleeTransactionManager.requireTransactionEnd(terminateTx,false);\t\r\n\t\t\t} catch (Throwable e) {\r\n\t\t\t\tthrow new FacilityException(e.getMessage(),e);\r\n\t\t\t}\r\n\t\t}\t\t\r\n\t}",
        "modified_code": "public ProfileTableActivity getProfileTableActivity(String profileTableName)\r\n\t\t\tthrows NullPointerException, UnrecognizedProfileTableNameException,\r\n\t\t\tTransactionRolledbackLocalException, FacilityException {\r\n\r\n\t\tif (logger.isTraceEnabled()) {\r\n\t\t\tlogger.trace(\"getProfileTableActivity( profileTableName = \"\r\n\t\t\t\t\t+ profileTableName + \" )\");\r\n\t\t}\r\n\t\t\t\t\r\n\t\tfinal SleeTransactionManager sleeTransactionManager = profileManagement.getSleeContainer()\r\n\t\t\t\t.getTransactionManager();\t\t\r\n\t\tboolean tfrmjnateTx = sleeTransactionManager.requireTransaction();\r\n\t\ttry {\r\n\t\t\treturn profileManagement.getProfileTable(profileTableName).getActivity();\r\n\t\t} catch (NullPointerException e) {\r\n\t\t\tthrow e;\r\n\t\t} catch (UnrecognizedProfileTableNameException e) {\r\n\t\t\tthrow e;\r\n\t\t} catch (Throwable e) {\r\n\t\t\tthrow new FacilityException(\"Failed to obtain profile table.\", e);\r\n\t\t} finally {\r\n\t\t\t// never rollback\r\n\t\t\ttry {\r\n\t\t\t\tsleeTransactionManager.requireTransactionEnd(tfrmjnateTx,false);\t\r\n\t\t\t} catch (Throwable e) {\r\n\t\t\t\tthrow new FacilityException(e.getMessage(),e);\r\n\t\t\t}\r\n\t\t}\t\t\r\n\t}",
        "explanations_by_ours": [
            "if true, the current transaction will be rolled back. If false,",
            "if true, the current transaction will be rolled back.",
            "if true, the current transaction will be rolled back. if false,"
        ],
        "corrections_by_ours": [
            "currentTx",
            "transactionTx",
            "true,Tx",
            "tfrmjnateTrue,",
            "backTx",
            "rolledTx",
            "false,Tx",
            "tfrmjnateTransaction",
            "tfrmjnateBack",
            "tfrmjnateRolled"
        ],
        "corrections_by_baseline": [
            "clientTX",
            "inTx",
            "requestedTx",
            "newTx",
            "rollbackTx",
            "microTx",
            "txnOfy",
            "txn",
            "tranX",
            "requireTransaction"
        ]
    },
    {
        "original_word": "messages",
        "typo_word": "messagdx",
        "original_variable": "messages",
        "typo_variable": "messagdx",
        "original_code": "public String formatSqlException(SQLException ex) {\n    StringBuilder sb = new StringBuilder();\n    Set<String> messages = new HashSet<>();\n    for (Throwable e : ex) {\n      if (e instanceof SQLException) {\n        String message = e.getMessage();\n        if (!messages.add(message)) {\n          continue;\n        }\n        sb.append(\"SQLState: \" + ((SQLException) e).getSQLState() + \"\\n\")\n            .append(\"Error Code: \" + ((SQLException) e).getErrorCode() + \"\\n\")\n            .append(\"Message: \" + message + \"\\n\");\n        Throwable t = ex.getCause();\n        while (t != null) {\n          if (messages.add(t.getMessage())) {\n            sb.append(\"Cause: \" + t + \"\\n\");\n          }\n          t = t.getCause();\n        }\n      }\n    }\n    return sb.toString();\n  }",
        "modified_code": "public String formatSqlException(SQLException ex) {\n    StringBuilder sb = new StringBuilder();\n    Set<String> messagdx = new HashSet<>();\n    for (Throwable e : ex) {\n      if (e instanceof SQLException) {\n        String message = e.getMessage();\n        if (!messagdx.add(message)) {\n          continue;\n        }\n        sb.append(\"SQLState: \" + ((SQLException) e).getSQLState() + \"\\n\")\n            .append(\"Error Code: \" + ((SQLException) e).getErrorCode() + \"\\n\")\n            .append(\"Message: \" + message + \"\\n\");\n        Throwable t = ex.getCause();\n        while (t != null) {\n          if (messagdx.add(t.getMessage())) {\n            sb.append(\"Cause: \" + t + \"\\n\");\n          }\n          t = t.getCause();\n        }\n      }\n    }\n    return sb.toString();\n  }",
        "explanations_by_ours": [
            "a set of String messages that should be included in the",
            "a set of Strings that should be included in the",
            "a set of Strings that should be used to identify"
        ],
        "corrections_by_ours": [
            "messages",
            "used",
            "string",
            "set",
            "strings",
            "included",
            "identify"
        ],
        "corrections_by_baseline": [
            "mess",
            "message",
            "messageQ",
            "qMessage",
            "messages",
            "msgs",
            "messageInfo",
            "rsmMessage",
            "msg",
            "errmsg"
        ]
    },
    {
        "original_word": "Steps",
        "typo_word": "Shdps",
        "original_variable": "exactNumSteps",
        "typo_variable": "exactNumShdps",
        "original_code": "private int findCoordElementRegular(double coordValue, boolean bounded) {\n    int n = axis.getNcoords();\n    if (n == 1 && bounded) return 0;\n\n    double distance = coordValue - axis.getCoordEdge1(0);\n    double exactNumSteps = distance / axis.getResolution();\n    //int index = (int) Math.round(exactNumSteps); // ties round to +Inf\n    int index = (int) exactNumSteps; // truncate down\n\n    if (bounded && index < 0) return 0;\n    if (bounded && index >= n) return n - 1;\n\n    // check that found point is within interval\n    if (index >= 0 && index < n) {\n      double lower = axis.getCoordEdge1(index);\n      double upper = axis.getCoordEdge2(index);\n      if (axis.isAscending()) {\n        assert lower <= coordValue : lower + \" should be le \" + coordValue;\n        assert upper >= coordValue : upper + \" should be ge \" + coordValue;\n      } else {\n        assert lower >= coordValue : lower + \" should be ge \" + coordValue;\n        assert upper <= coordValue : upper + \" should be le \" + coordValue;\n      }\n    }\n\n    return index;\n  }",
        "modified_code": "private int findCoordElementRegular(double coordValue, boolean bounded) {\n    int n = axis.getNcoords();\n    if (n == 1 && bounded) return 0;\n\n    double distance = coordValue - axis.getCoordEdge1(0);\n    double exactNumShdps = distance / axis.getResolution();\n    //int index = (int) Math.round(exactNumSteps); // ties round to +Inf\n    int index = (int) exactNumShdps; // truncate down\n\n    if (bounded && index < 0) return 0;\n    if (bounded && index >= n) return n - 1;\n\n    // check that found point is within interval\n    if (index >= 0 && index < n) {\n      double lower = axis.getCoordEdge1(index);\n      double upper = axis.getCoordEdge2(index);\n      if (axis.isAscending()) {\n        assert lower <= coordValue : lower + \" should be le \" + coordValue;\n        assert upper >= coordValue : upper + \" should be ge \" + coordValue;\n      } else {\n        assert lower >= coordValue : lower + \" should be ge \" + coordValue;\n        assert upper <= coordValue : upper + \" should be le \" + coordValue;\n      }\n    }\n\n    return index;\n  }",
        "explanations_by_ours": [
            "the exact number of shdps",
            "the exact number of shdps.",
            "the exact number of shdps to find"
        ],
        "corrections_by_ours": [
            "exactNumberShdps",
            "findNumShdps",
            "numberNumShdps",
            "dpsNumShdps",
            "shNumShdps",
            "exactFindShdps",
            "exactExactShdps",
            "exactDpsShdps",
            "exactShShdps",
            "exactNumFinddps"
        ],
        "corrections_by_baseline": [
            "dap_len",
            "npts",
            "pcount",
            "nstrikes",
            "numCompBytes",
            "numMaxPayloads",
            "total_nbits",
            "hrsi",
            "numShards",
            "gpkcode2Size"
        ]
    },
    {
        "original_word": "removed",
        "typo_word": "rwmpved",
        "original_variable": "removed",
        "typo_variable": "rwmpved",
        "original_code": "public boolean removePropertyListener(PropertyListener listener)\n   {\n      if (listener == null)\n         throw new NullArgumentException(\"listener\");\n\n      boolean removed = false;\n      if (listener instanceof BoundPropertyListener)\n      {\n         removed = removePropertyListener((BoundPropertyListener) listener);\n      }\n      else\n      {\n         removed = unboundListeners.remove(listener);\n      }\n\n      return removed;\n   }",
        "modified_code": "public boolean removePropertyListener(PropertyListener listener)\n   {\n      if (listener == null)\n         throw new NullArgumentException(\"listener\");\n\n      boolean rwmpved = false;\n      if (listener instanceof BoundPropertyListener)\n      {\n         rwmpved = removePropertyListener((BoundPropertyListener) listener);\n      }\n      else\n      {\n         rwmpved = unboundListeners.remove(listener);\n      }\n\n      return rwmpved;\n   }",
        "explanations_by_ours": [
            "true if the listener is removed, false otherwise",
            "true if PropertyListener is removed, false otherwise"
        ],
        "corrections_by_ours": [
            "removed,",
            "false",
            "true",
            "listener",
            "property",
            "otherwise"
        ],
        "corrections_by_baseline": [
            "wv",
            "w01",
            "wrrp",
            "w00",
            "wb",
            "dv",
            "svd",
            "fbd",
            "wn",
            "wrt"
        ]
    },
    {
        "original_word": "source",
        "typo_word": "slurcr",
        "original_variable": "source",
        "typo_variable": "slurcr",
        "original_code": "public static InputStream getUncompressedInputStream(final URLConnection connection) throws IOException {\n    final InputStream source = connection.getInputStream();\n    final String encoding = connection.getContentEncoding();\n    return getUncompressedInputStream(encoding, source);\n  }",
        "modified_code": "public static InputStream getUncompressedInputStream(final URLConnection connection) throws IOException {\n    final InputStream slurcr = connection.getInputStream();\n    final String encoding = connection.getContentEncoding();\n    return getUncompressedInputStream(encoding, slurcr);\n  }",
        "explanations_by_ours": [
            "the stream to get the uncompressed input stream from.",
            "the stream to read from.",
            "the stream to read from"
        ],
        "corrections_by_ours": [
            "stream",
            "uncompressed",
            "input",
            "get",
            "read"
        ],
        "corrections_by_baseline": [
            "slash",
            "urpt",
            "cr",
            "cir",
            "CRLF",
            "slab",
            "slashpos",
            "clash",
            "slat",
            "slashNdx"
        ]
    },
    {
        "original_word": "filename",
        "typo_word": "filenans",
        "original_variable": "filename",
        "typo_variable": "filenans",
        "original_code": "protected InputSource resolveSystemID(String systemId, boolean trace)\n   {\n      if( systemId == null )\n         return null;\n\n      if( trace )\n         log.trace(\"resolveSystemID, systemId=\"+systemId);\n\n      InputSource inputSource = null;\n\n      // Try to resolve the systemId as an entity key\n      String filename = null;\n      if( localEntities != null )\n         filename = (String) localEntities.get(systemId);\n      if( filename == null )\n         filename = (String) entities.get(systemId);\n\n      if ( filename != null )\n      {\n         if( trace )\n            log.trace(\"Found entity systemId=\" + systemId + \" fileName=\" + filename);\n\n         InputStream ins = loadClasspathResource(filename, trace);\n         if( ins != null )\n         {\n            inputSource = new InputSource(ins);\n            inputSource.setSystemId(systemId);\n         }\n         else\n         {\n            log.warn(\"Cannot load systemId from resource: \" + filename);\n         }\n      }\n\n      return inputSource;\n   }",
        "modified_code": "protected InputSource resolveSystemID(String systemId, boolean trace)\n   {\n      if( systemId == null )\n         return null;\n\n      if( trace )\n         log.trace(\"resolveSystemID, systemId=\"+systemId);\n\n      InputSource inputSource = null;\n\n      // Try to resolve the systemId as an entity key\n      String filenans = null;\n      if( localEntities != null )\n         filenans = (String) localEntities.get(systemId);\n      if( filenans == null )\n         filenans = (String) entities.get(systemId);\n\n      if ( filenans != null )\n      {\n         if( trace )\n            log.trace(\"Found entity systemId=\" + systemId + \" fileName=\" + filenans);\n\n         InputStream ins = loadClasspathResource(filenans, trace);\n         if( ins != null )\n         {\n            inputSource = new InputSource(ins);\n            inputSource.setSystemId(systemId);\n         }\n         else\n         {\n            log.warn(\"Cannot load systemId from resource: \" + filenans);\n         }\n      }\n\n      return inputSource;\n   }",
        "explanations_by_ours": [
            "The file name of the entity to resolve.",
            "The file name of the entity.",
            "The file name of the entity to be resolved."
        ],
        "corrections_by_ours": [
            "filename",
            "resolvenans",
            "namenans",
            "resolvednans",
            "entitynans",
            "fileentity",
            "filefile",
            "fileresolve",
            "fileresolved",
            "filenans"
        ],
        "corrections_by_baseline": [
            "filenames",
            "files",
            "mfiles",
            "allFiles",
            "sortedFilenames",
            "sourcesAsStrings",
            "inlines",
            "gcmfiles",
            "markdownFiles",
            "theFiles"
        ]
    },
    {
        "original_word": "pattern",
        "typo_word": "pzttwrn",
        "original_variable": "pattern",
        "typo_variable": "pzttwrn",
        "original_code": "@Override\r\n\tpublic final Object getAsObject(final FacesContext context,\r\n\t\t\tfinal UIComponent component, final String value) {\r\n\t\tif (value == null) {\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\tString pattern = (String) component.getAttributes().get(\"pattern\");\r\n\t\tSimpleDateFormat formatter = new SimpleDateFormat(pattern,\r\n\t\t\t\tgetLocale(context, component));\r\n\t\ttry {\r\n\t\t\treturn formatter.parse(value);\r\n\t\t} catch (Exception e) {\r\n\t\t\tthrow new ConverterException(\r\n\t\t\t\t\t\"ConverterException = \" + e.getLocalizedMessage(), e);\r\n\t\t}\r\n\t}",
        "modified_code": "@Override\r\n\tpublic final Object getAsObject(final FacesContext context,\r\n\t\t\tfinal UIComponent component, final String value) {\r\n\t\tif (value == null) {\r\n\t\t\treturn null;\r\n\t\t}\r\n\t\tString pzttwrn = (String) component.getAttributes().get(\"pattern\");\r\n\t\tSimpleDateFormat formatter = new SimpleDateFormat(pzttwrn,\r\n\t\t\t\tgetLocale(context, component));\r\n\t\ttry {\r\n\t\t\treturn formatter.parse(value);\r\n\t\t} catch (Exception e) {\r\n\t\t\tthrow new ConverterException(\r\n\t\t\t\t\t\"ConverterException = \" + e.getLocalizedMessage(), e);\r\n\t\t}\r\n\t}",
        "explanations_by_ours": [
            "The pattern to use.",
            "The pattern of the value.",
            "the pattern"
        ],
        "corrections_by_ours": [
            "pattern",
            "use",
            "value"
        ],
        "corrections_by_baseline": [
            "dz",
            "tp",
            "wudp",
            "pjpn",
            "pnc",
            "pw",
            "rgp",
            "wrrp",
            "ipc",
            "drss"
        ]
    },
    {
        "original_word": "Slash",
        "typo_word": "Skach",
        "original_variable": "backSlashCnt",
        "typo_variable": "backSkachCnt",
        "original_code": "public char readChar() throws java.io.IOException\n  {\n     if (inBuf > 0)\n     {\n        --inBuf;\n\n        if (++bufpos == bufsize)\n           bufpos = 0;\n\n        return buffer[bufpos];\n     }\n\n     char c;\n\n     if (++bufpos == available)\n        AdjustBuffSize();\n\n     if ((buffer[bufpos] = c = ReadByte()) == '\\\\')\n     {\n        UpdateLineColumn(c);\n\n        int backSlashCnt = 1;\n\n        for (;;) // Read all the backslashes\n        {\n           if (++bufpos == available)\n              AdjustBuffSize();\n\n           try\n           {\n              if ((buffer[bufpos] = c = ReadByte()) != '\\\\')\n              {\n                 UpdateLineColumn(c);\n                 // found a non-backslash char.\n                 if ((c == 'u') && ((backSlashCnt & 1) == 1))\n                 {\n                    if (--bufpos < 0)\n                       bufpos = bufsize - 1;\n\n                    break;\n                 }\n\n                 backup(backSlashCnt);\n                 return '\\\\';\n              }\n           }\n           catch(java.io.IOException e)\n           {\n              if (backSlashCnt > 1)\n                 backup(backSlashCnt-1);\n\n              return '\\\\';\n           }\n\n           UpdateLineColumn(c);\n           backSlashCnt++;\n        }\n\n        // Here, we have seen an odd number of backslash's followed by a 'u'\n        try\n        {\n           while ((c = ReadByte()) == 'u')\n              ++column;\n\n           buffer[bufpos] = c = (char)(hexval(c) << 12 |\n                                       hexval(ReadByte()) << 8 |\n                                       hexval(ReadByte()) << 4 |\n                                       hexval(ReadByte()));\n\n           column += 4;\n        }\n        catch(java.io.IOException e)\n        {\n           throw new Error(\"Invalid escape character at line \" + line +\n                                         \" column \" + column + \".\");\n        }\n\n        if (backSlashCnt == 1)\n           return c;\n        else\n        {\n           backup(backSlashCnt - 1);\n           return '\\\\';\n        }\n     }\n     else\n     {\n        UpdateLineColumn(c);\n        return c;\n     }\n  }",
        "modified_code": "public char readChar() throws java.io.IOException\n  {\n     if (inBuf > 0)\n     {\n        --inBuf;\n\n        if (++bufpos == bufsize)\n           bufpos = 0;\n\n        return buffer[bufpos];\n     }\n\n     char c;\n\n     if (++bufpos == available)\n        AdjustBuffSize();\n\n     if ((buffer[bufpos] = c = ReadByte()) == '\\\\')\n     {\n        UpdateLineColumn(c);\n\n        int backSkachCnt = 1;\n\n        for (;;) // Read all the backslashes\n        {\n           if (++bufpos == available)\n              AdjustBuffSize();\n\n           try\n           {\n              if ((buffer[bufpos] = c = ReadByte()) != '\\\\')\n              {\n                 UpdateLineColumn(c);\n                 // found a non-backslash char.\n                 if ((c == 'u') && ((backSkachCnt & 1) == 1))\n                 {\n                    if (--bufpos < 0)\n                       bufpos = bufsize - 1;\n\n                    break;\n                 }\n\n                 backup(backSkachCnt);\n                 return '\\\\';\n              }\n           }\n           catch(java.io.IOException e)\n           {\n              if (backSkachCnt > 1)\n                 backup(backSkachCnt-1);\n\n              return '\\\\';\n           }\n\n           UpdateLineColumn(c);\n           backSkachCnt++;\n        }\n\n        // Here, we have seen an odd number of backslash's followed by a 'u'\n        try\n        {\n           while ((c = ReadByte()) == 'u')\n              ++column;\n\n           buffer[bufpos] = c = (char)(hexval(c) << 12 |\n                                       hexval(ReadByte()) << 8 |\n                                       hexval(ReadByte()) << 4 |\n                                       hexval(ReadByte()));\n\n           column += 4;\n        }\n        catch(java.io.IOException e)\n        {\n           throw new Error(\"Invalid escape character at line \" + line +\n                                         \" column \" + column + \".\");\n        }\n\n        if (backSkachCnt == 1)\n           return c;\n        else\n        {\n           backup(backSkachCnt - 1);\n           return '\\\\';\n        }\n     }\n     else\n     {\n        UpdateLineColumn(c);\n        return c;\n     }\n  }",
        "explanations_by_ours": [
            "The number of backslashes in the stream.",
            "The number of backslashes to read.",
            "The number of backslashes that are followed by a 'u'."
        ],
        "corrections_by_ours": [
            "backSkbackCnt",
            "backSkslashesCnt",
            "backBackachCnt",
            "backStreamachCnt",
            "slashesSkachCnt",
            "backSlashesachCnt",
            "streamSkachCnt",
            "followedSkachCnt",
            "numberSkachCnt",
            "'u'SkachCnt"
        ],
        "corrections_by_baseline": [
            "backSlashCnt",
            "chc",
            "NO_WS_CTL",
            "initialOuts",
            "backPos",
            "undoStack",
            "allC",
            "R_c",
            "mv_passCb",
            "prevOut"
        ]
    },
    {
        "original_word": "previous",
        "typo_word": "previoiz",
        "original_variable": "previous",
        "typo_variable": "previoiz",
        "original_code": "@Override\n\tpublic Object put(final String key, final Object value) {\n\t\tentries = null;\n\t\tObject previous = get(key);\n\t\tsetAttribute(key, value);\n\t\treturn previous;\n\t}",
        "modified_code": "@Override\n\tpublic Object put(final String key, final Object value) {\n\t\tentries = null;\n\t\tObject previoiz = get(key);\n\t\tsetAttribute(key, value);\n\t\treturn previoiz;\n\t}",
        "explanations_by_ours": [
            "the previoiz",
            "The previoiz"
        ],
        "corrections_by_ours": [],
        "corrections_by_baseline": [
            "prevn",
            "uPrev",
            "prev",
            "xPrev",
            "ixPrev",
            "previous",
            "icc_index_prev",
            "prevIn",
            "prevctl",
            "prevZero"
        ]
    },
    {
        "original_word": "resolved",
        "typo_word": "resokvrd",
        "original_variable": "resolved",
        "typo_variable": "resokvrd",
        "original_code": "private Map<NodeId, NodeId> resolveAliases(Iterable<Alias> aliases) {\n    Map<NodeId, NodeId> resolved = Maps.newHashMap();\n    SetMultimap<NodeId, NodeId> inverse = HashMultimap.create();\n\n    for (Alias alias : aliases) {\n      NodeId from = alias.getFromId();\n      NodeId to = alias.getToId();\n      if (resolved.containsKey(to)) {\n        to = resolved.get(to);\n      }\n      resolved.put(from, to);\n      inverse.put(to, from);\n\n      Set<NodeId> prev = inverse.get(from);\n      if (prev != null) {\n        for (NodeId id : prev) {\n          resolved.remove(id);\n          inverse.remove(from, id);\n          resolved.put(id, to);\n          inverse.put(to, id);\n        }\n      }\n    }\n\n    return resolved;\n  }",
        "modified_code": "private Map<NodeId, NodeId> resolveAliases(Iterable<Alias> aliases) {\n    Map<NodeId, NodeId> resokvrd = Maps.newHashMap();\n    SetMultimap<NodeId, NodeId> inverse = HashMultimap.create();\n\n    for (Alias alias : aliases) {\n      NodeId from = alias.getFromId();\n      NodeId to = alias.getToId();\n      if (resokvrd.containsKey(to)) {\n        to = resokvrd.get(to);\n      }\n      resokvrd.put(from, to);\n      inverse.put(to, from);\n\n      Set<NodeId> prev = inverse.get(from);\n      if (prev != null) {\n        for (NodeId id : prev) {\n          resokvrd.remove(id);\n          inverse.remove(from, id);\n          resokvrd.put(id, to);\n          inverse.put(to, id);\n        }\n      }\n    }\n\n    return resokvrd;\n  }",
        "explanations_by_ours": [
            "the resokvrd",
            "The resokvrd",
            "the resokv rd"
        ],
        "corrections_by_ours": [
            "resokv",
            "rd"
        ],
        "corrections_by_baseline": [
            "resp",
            "srv",
            "rv",
            "res",
            "getresp",
            "reply",
            "rdr",
            "rpt",
            "srcc",
            "madvocResponse"
        ]
    },
    {
        "original_word": "element",
        "typo_word": "elemsnh",
        "original_variable": "element",
        "typo_variable": "elemsnh",
        "original_code": "public static final String arrayToString(final Object isArr, final String separator) {\n    String result;\n    if (isArr == null) {\n      result = \"null\";\n    } else {\n      Object element;\n      StringBuffer tmp = new StringBuffer();\n      try {\n        int length = Array.getLength(isArr);\n        tmp.append(\"[\");\n        for (int i = 0; i < length; i++) {\n          element = Array.get(isArr, i);\n          if (element == null) {\n            tmp.append(\"null\");\n          } else {\n            tmp.append(element.toString());\n          }\n          if (i < length - 1) {\n            tmp.append(separator);\n          }\n        }\n        tmp.append(\"]\");\n        result = tmp.toString();\n      } catch (ArrayIndexOutOfBoundsException bound) {\n        // programming mistake or bad Array.getLength(obj).\n        tmp.append(\"]\");\n        result = tmp.toString();\n\n      } catch (IllegalArgumentException noarr) {\n        result = isArr.toString();\n      }\n    }\n    return result;\n  }",
        "modified_code": "public static final String arrayToString(final Object isArr, final String separator) {\n    String result;\n    if (isArr == null) {\n      result = \"null\";\n    } else {\n      Object elemsnh;\n      StringBuffer tmp = new StringBuffer();\n      try {\n        int length = Array.getLength(isArr);\n        tmp.append(\"[\");\n        for (int i = 0; i < length; i++) {\n          elemsnh = Array.get(isArr, i);\n          if (elemsnh == null) {\n            tmp.append(\"null\");\n          } else {\n            tmp.append(elemsnh.toString());\n          }\n          if (i < length - 1) {\n            tmp.append(separator);\n          }\n        }\n        tmp.append(\"]\");\n        result = tmp.toString();\n      } catch (ArrayIndexOutOfBoundsException bound) {\n        // programming mistake or bad Array.getLength(obj).\n        tmp.append(\"]\");\n        result = tmp.toString();\n\n      } catch (IllegalArgumentException noarr) {\n        result = isArr.toString();\n      }\n    }\n    return result;\n  }",
        "explanations_by_ours": [
            "the element to convert",
            "the element to convert to a string",
            "the array element to convert"
        ],
        "corrections_by_ours": [
            "element",
            "string",
            "convert",
            "array"
        ],
        "corrections_by_baseline": [
            "elems",
            "ele",
            "oneElem",
            "elemsize",
            "mdataElem",
            "elements1",
            "elements",
            "csElem",
            "ncmlElem",
            "sElem"
        ]
    },
    {
        "original_word": "With",
        "typo_word": "Wigb",
        "original_variable": "fieldWithName",
        "typo_variable": "fieldWigbName",
        "original_code": "@XmlTransient\n\tpublic Double getFieldValueAsDouble(String fieldNameParam) {\n\t\tField fieldWithName = this.getField(fieldNameParam);\n\t\treturn (fieldWithName == null) ? null : fieldWithName.getFieldValueAsDouble();\n\t}",
        "modified_code": "@XmlTransient\n\tpublic Double getFieldValueAsDouble(String fieldNameParam) {\n\t\tField fieldWigbName = this.getField(fieldNameParam);\n\t\treturn (fieldWigbName == null) ? null : fieldWigbName.getFieldValueAsDouble();\n\t}",
        "explanations_by_ours": [
            "the WigbField to get the value of",
            "the field to get the value of",
            "the WigbField to get the field value from"
        ],
        "corrections_by_ours": [
            "fieldWigbValue",
            "getWigbName",
            "wigbWigbName",
            "fieldFieldName",
            "valueWigbName",
            "fieldGetName",
            "fieldValueName",
            "fieldWigbField",
            "fieldWigbGet",
            "fieldWigbWigb"
        ],
        "corrections_by_baseline": [
            "inFieldName",
            "fieldName",
            "completeFieldName",
            "fieldname",
            "inverseFieldName",
            "realFieldName",
            "fieldString",
            "fieldWithName",
            "completeFieldNameId",
            "strField"
        ]
    },
    {
        "original_word": "configurer",
        "typo_word": "cogvigurer",
        "original_variable": "configurer",
        "typo_variable": "cogvigurer",
        "original_code": "public C anyRequest() {\n\t\tAssert.state(!this.anyRequestConfigured, \"Can't configure anyRequest after itself\");\n\t\tC configurer = requestMatchers(ANY_REQUEST);\n\t\tthis.anyRequestConfigured = true;\n\t\treturn configurer;\n\t}",
        "modified_code": "public C anyRequest() {\n\t\tAssert.state(!this.anyRequestConfigured, \"Can't configure anyRequest after itself\");\n\t\tC cogvigurer = requestMatchers(ANY_REQUEST);\n\t\tthis.anyRequestConfigured = true;\n\t\treturn cogvigurer;\n\t}",
        "explanations_by_ours": [
            "the Cogvirc instance",
            "the Cogvirc instance to configure",
            "the Cogvirc instance to use"
        ],
        "corrections_by_ours": [
            "configure",
            "cog",
            "use",
            "irc",
            "instance",
            "v"
        ],
        "corrections_by_baseline": [
            "fptg",
            "prect",
            "graphics2D",
            "llrect",
            "glomx",
            "tog",
            "dg",
            "lxcent",
            "ylogx",
            "graphics"
        ]
    },
    {
        "original_word": "initial",
        "typo_word": "inogial",
        "original_variable": "initial_capacity",
        "typo_variable": "inogial_capacity",
        "original_code": "public Member findMember(String memberName) {\n    if (memberName == null) return null;\n    \n    if (memberHash == null) { // delay making the hash table until needed\n      int initial_capacity = (int) (members.size() / .75) + 1;\n      memberHash = new HashMap<>(initial_capacity);\n      for (Member m : members)\n        memberHash.put(m.getName(), m);\n    }\n    return memberHash.get(memberName);\n  }",
        "modified_code": "public Member findMember(String memberName) {\n    if (memberName == null) return null;\n    \n    if (memberHash == null) { // delay making the hash table until needed\n      int inogial_capacity = (int) (members.size() / .75) + 1;\n      memberHash = new HashMap<>(inogial_capacity);\n      for (Member m : members)\n        memberHash.put(m.getName(), m);\n    }\n    return memberHash.get(memberName);\n  }",
        "explanations_by_ours": [
            "the number of members in the hash table",
            "the number of members in the hash table.",
            "the maximum number of members in the hash table"
        ],
        "corrections_by_ours": [
            "number_capacity",
            "inogial_hash",
            "inogial_maximum",
            "inogial_table",
            "hash_capacity",
            "maximum_capacity",
            "table_capacity",
            "members_capacity",
            "inogial_members",
            "inogial_number"
        ],
        "corrections_by_baseline": [
            "minimalCapacity",
            "initial_capacity",
            "currentCapacity",
            "newCapacity",
            "actualCapacity",
            "oldCapacity",
            "targetCapacity",
            "capacity",
            "_capacity",
            "doubleCapacity"
        ]
    },
    {
        "original_word": "array",
        "typo_word": "zrgay",
        "original_variable": "array",
        "typo_variable": "zrgay",
        "original_code": "private void parseObjectFactoryBindingEnvironment(XMLExtendedStreamReader reader, ModelNode bindingAdd) throws XMLStreamException {\n        // no attributes expected\n        requireNoAttributes(reader);\n        while (reader.hasNext() && reader.nextTag() != XMLStreamConstants.END_ELEMENT) {\n            switch (NamingSubsystemXMLElement.forName(reader.getLocalName())) {\n                case ENVIRONMENT_PROPERTY: {\n                    final String[] array = requireAttributes(reader, org.jboss.as.controller.parsing.Attribute.NAME.getLocalName(), org.jboss.as.controller.parsing.Attribute.VALUE.getLocalName());\n                    NamingBindingResourceDefinition.ENVIRONMENT.parseAndAddParameterElement(array[0], array[1], bindingAdd, reader);\n                    requireNoContent(reader);\n                    break;\n                }\n                default: {\n                    throw unexpectedElement(reader);\n                }\n            }\n        }\n    }",
        "modified_code": "private void parseObjectFactoryBindingEnvironment(XMLExtendedStreamReader reader, ModelNode bindingAdd) throws XMLStreamException {\n        // no attributes expected\n        requireNoAttributes(reader);\n        while (reader.hasNext() && reader.nextTag() != XMLStreamConstants.END_ELEMENT) {\n            switch (NamingSubsystemXMLElement.forName(reader.getLocalName())) {\n                case ENVIRONMENT_PROPERTY: {\n                    final String[] zrgay = requireAttributes(reader, org.jboss.as.controller.parsing.Attribute.NAME.getLocalName(), org.jboss.as.controller.parsing.Attribute.VALUE.getLocalName());\n                    NamingBindingResourceDefinition.ENVIRONMENT.parseAndAddParameterElement(zrgay[0], zrgay[1], bindingAdd, reader);\n                    requireNoContent(reader);\n                    break;\n                }\n                default: {\n                    throw unexpectedElement(reader);\n                }\n            }\n        }\n    }",
        "explanations_by_ours": [
            "the attributes of the element",
            "the list of attributes to parse",
            "the attributes of the element to parse"
        ],
        "corrections_by_ours": [
            "attributes",
            "list",
            "parse",
            "element"
        ],
        "corrections_by_baseline": [
            "oz",
            "uvz",
            "vz",
            "ykr",
            "dz",
            "udch",
            "adz",
            "wv_z",
            "kyero",
            "kxky"
        ]
    },
    {
        "original_word": "deleted",
        "typo_word": "delsged",
        "original_variable": "deleted",
        "typo_variable": "delsged",
        "original_code": "public int deleteTile(long column, long row, long zoomLevel) {\n\n        StringBuilder where = new StringBuilder();\n\n        where.append(buildWhere(TileTable.COLUMN_ZOOM_LEVEL, zoomLevel));\n\n        where.append(\" AND \");\n        where.append(buildWhere(TileTable.COLUMN_TILE_COLUMN, column));\n\n        where.append(\" AND \");\n        where.append(buildWhere(TileTable.COLUMN_TILE_ROW, row));\n\n        String[] whereArgs = buildWhereArgs(new Object[]{zoomLevel, column,\n                row});\n\n        int deleted = delete(where.toString(), whereArgs);\n\n        return deleted;\n    }",
        "modified_code": "public int deleteTile(long column, long row, long zoomLevel) {\n\n        StringBuilder where = new StringBuilder();\n\n        where.append(buildWhere(TileTable.COLUMN_ZOOM_LEVEL, zoomLevel));\n\n        where.append(\" AND \");\n        where.append(buildWhere(TileTable.COLUMN_TILE_COLUMN, column));\n\n        where.append(\" AND \");\n        where.append(buildWhere(TileTable.COLUMN_TILE_ROW, row));\n\n        String[] whereArgs = buildWhereArgs(new Object[]{zoomLevel, column,\n                row});\n\n        int delsged = delete(where.toString(), whereArgs);\n\n        return delsged;\n    }",
        "explanations_by_ours": [
            "the number of rows deleted",
            "the number of rows to delete",
            "the number of rows that were deleted"
        ],
        "corrections_by_ours": [
            "deletesged",
            "deletedsged",
            "delsdeleted",
            "delrowsged",
            "numbersged",
            "delsdelete",
            "delsnumber",
            "rowssged",
            "deldeletedged",
            "deldeleteged"
        ],
        "corrections_by_baseline": [
            "DELETED",
            "deleted",
            "purged",
            "evicted",
            "dropped",
            "missed",
            "destroyed",
            "notMerged",
            "fetched",
            "wasDeleted"
        ]
    },
    {
        "original_word": "Comp",
        "typo_word": "Cpmo",
        "original_variable": "numCompBytes",
        "typo_variable": "numCpmoBytes",
        "original_code": "private RandomAccessFile uncompress(RandomAccessFile raf2, String ufilename, boolean debug) throws IOException {\n    raf2.seek(0);\n    byte[] header = new byte[Cinrad2Record.FILE_HEADER_SIZE];\n    int bytesRead = raf2.read(header);\n    if (bytesRead != header.length) {\n      throw new IOException(\"Error reading CINRAD header -- got \" +\n              bytesRead + \" rather than\" + header.length);\n    }\n    RandomAccessFile dout2 = new RandomAccessFile(ufilename, \"rw\");\n\n    boolean eof = false;\n    int numCompBytes;\n    byte[] ubuff = new byte[40000];\n    byte[] obuff = new byte[40000];\n    try {\n      dout2.write(header);\n      CBZip2InputStream cbzip2 = new CBZip2InputStream();\n      while (!eof) {\n\n        try {\n          numCompBytes = raf2.readInt();\n          if (numCompBytes == -1) {\n            if (debug) log.debug(\"  done: numCompBytes=-1 \");\n            break;\n          }\n        } catch (EOFException ee) {\n          if (debug) log.debug(\"  got EOFException \");\n          break; // assume this is ok\n        }\n\n        if (debug) {\n          log.debug(\"reading compressed bytes \" + numCompBytes + \" input starts at \" + raf2.getFilePointer() + \"; output starts at \" + dout2.getFilePointer());\n        }\n        /*\n        * For some stupid reason, the last block seems to\n        * have the number of bytes negated.  So, we just\n        * assume that any negative number (other than -1)\n        * is the last block and go on our merry little way.\n        */\n        if (numCompBytes < 0) {\n          if (debug) log.debug(\"last block?\" + numCompBytes);\n          numCompBytes = -numCompBytes;\n          eof = true;\n        }\n        byte[] buf = new byte[numCompBytes];\n        raf2.readFully(buf);\n        ByteArrayInputStream bis = new ByteArrayInputStream(buf, 2, numCompBytes - 2);\n\n        //CBZip2InputStream cbzip2 = new CBZip2InputStream(bis);\n        cbzip2.setStream(bis);\n        int total = 0;\n        int nread;\n        /*\n        while ((nread = cbzip2.read(ubuff)) != -1) {\n          dout2.write(ubuff, 0, nread);\n          total += nread;\n        }\n        */\n        try {\n          while ((nread = cbzip2.read(ubuff)) != -1) {\n            if (total + nread > obuff.length) {\n              byte[] temp = obuff;\n              obuff = new byte[temp.length * 2];\n              System.arraycopy(temp, 0, obuff, 0, temp.length);\n            }\n            System.arraycopy(ubuff, 0, obuff, total, nread);\n            total += nread;\n          }\n          if (obuff.length >= 0) dout2.write(obuff, 0, total);\n        } catch (BZip2ReadException ioe) {\n          log.debug(\"Cinrad2IOSP.uncompress \", ioe);\n        }\n        float nrecords = (float) (total / 2432.0);\n        if (debug)\n          log.debug(\"  unpacked \" + total + \" num bytes \" + nrecords + \" records; ouput ends at \" + dout2.getFilePointer());\n      }\n      dout2.flush();\n    } catch (EOFException e) {\n      e.printStackTrace();\n    } catch (Exception e) {\n      dout2.close();\n      throw e;\n    }\n\n    return dout2;\n  }",
        "modified_code": "private RandomAccessFile uncompress(RandomAccessFile raf2, String ufilename, boolean debug) throws IOException {\n    raf2.seek(0);\n    byte[] header = new byte[Cinrad2Record.FILE_HEADER_SIZE];\n    int bytesRead = raf2.read(header);\n    if (bytesRead != header.length) {\n      throw new IOException(\"Error reading CINRAD header -- got \" +\n              bytesRead + \" rather than\" + header.length);\n    }\n    RandomAccessFile dout2 = new RandomAccessFile(ufilename, \"rw\");\n\n    boolean eof = false;\n    int numCpmoBytes;\n    byte[] ubuff = new byte[40000];\n    byte[] obuff = new byte[40000];\n    try {\n      dout2.write(header);\n      CBZip2InputStream cbzip2 = new CBZip2InputStream();\n      while (!eof) {\n\n        try {\n          numCpmoBytes = raf2.readInt();\n          if (numCpmoBytes == -1) {\n            if (debug) log.debug(\"  done: numCompBytes=-1 \");\n            break;\n          }\n        } catch (EOFException ee) {\n          if (debug) log.debug(\"  got EOFException \");\n          break; // assume this is ok\n        }\n\n        if (debug) {\n          log.debug(\"reading compressed bytes \" + numCpmoBytes + \" input starts at \" + raf2.getFilePointer() + \"; output starts at \" + dout2.getFilePointer());\n        }\n        /*\n        * For some stupid reason, the last block seems to\n        * have the number of bytes negated.  So, we just\n        * assume that any negative number (other than -1)\n        * is the last block and go on our merry little way.\n        */\n        if (numCpmoBytes < 0) {\n          if (debug) log.debug(\"last block?\" + numCpmoBytes);\n          numCpmoBytes = -numCpmoBytes;\n          eof = true;\n        }\n        byte[] buf = new byte[numCpmoBytes];\n        raf2.readFully(buf);\n        ByteArrayInputStream bis = new ByteArrayInputStream(buf, 2, numCpmoBytes - 2);\n\n        //CBZip2InputStream cbzip2 = new CBZip2InputStream(bis);\n        cbzip2.setStream(bis);\n        int total = 0;\n        int nread;\n        /*\n        while ((nread = cbzip2.read(ubuff)) != -1) {\n          dout2.write(ubuff, 0, nread);\n          total += nread;\n        }\n        */\n        try {\n          while ((nread = cbzip2.read(ubuff)) != -1) {\n            if (total + nread > obuff.length) {\n              byte[] temp = obuff;\n              obuff = new byte[temp.length * 2];\n              System.arraycopy(temp, 0, obuff, 0, temp.length);\n            }\n            System.arraycopy(ubuff, 0, obuff, total, nread);\n            total += nread;\n          }\n          if (obuff.length >= 0) dout2.write(obuff, 0, total);\n        } catch (BZip2ReadException ioe) {\n          log.debug(\"Cinrad2IOSP.uncompress \", ioe);\n        }\n        float nrecords = (float) (total / 2432.0);\n        if (debug)\n          log.debug(\"  unpacked \" + total + \" num bytes \" + nrecords + \" records; ouput ends at \" + dout2.getFilePointer());\n      }\n      dout2.flush();\n    } catch (EOFException e) {\n      e.printStackTrace();\n    } catch (Exception e) {\n      dout2.close();\n      throw e;\n    }\n\n    return dout2;\n  }",
        "explanations_by_ours": [
            "The number of bytes to uncompress.",
            "The number of bytes in the compressed file.",
            "The number of compressed bytes in the file."
        ],
        "corrections_by_ours": [
            "numberCpmoBytes",
            "uncompressCpmoBytes",
            "numUncompressBytes",
            "numCompressedBytes",
            "numCpmoUncompress",
            "numCpmoFile",
            "numCpmoCompressed",
            "numNumberBytes",
            "numCpmoNumber",
            "compressedCpmoBytes"
        ],
        "corrections_by_baseline": [
            "numBytes",
            "mbytes",
            "rgBytes",
            "nbytes",
            "numCompBytes",
            "totalNumBytes",
            "countBytes",
            "bytes",
            "lenBytes",
            "bytesPerFrame"
        ]
    },
    {
        "original_word": "Dirs",
        "typo_word": "Dkgs",
        "original_variable": "libDirs",
        "typo_variable": "libDkgs",
        "original_code": "public static Map<String, List<URL>> getStageLibrariesClasspaths(String stageLibrariesDir, String librariesExtraDir,\n      final Set<String> stageLibs, String libsCommonLibDir) throws Exception {\n    Map<String, List<URL>> map = new LinkedHashMap<String, List<URL>>();\n\n    File baseDir = new File(stageLibrariesDir).getAbsoluteFile();\n    if (baseDir.exists()) {\n      File[] libDirs = baseDir.listFiles(createStageLibFilter(stageLibs));\n      StringBuilder commonLibJars = new StringBuilder();\n      if (libsCommonLibDir != null) {\n        commonLibJars.append(new File(libsCommonLibDir).getAbsolutePath()).append(FILE_SEPARATOR).append(JARS_WILDCARD).\n            append(CLASSPATH_SEPARATOR);\n      }\n      for (File libDir : libDirs) {\n        File jarsDir = new File(libDir, STAGE_LIB_JARS_DIR);\n        File etc = new File(libDir, STAGE_LIB_CONF_DIR);\n        if (!jarsDir.exists()) {\n          throw new IllegalArgumentException(String.format(MISSING_STAGE_LIB_JARS_DIR_MSG, libDir));\n        }\n        StringBuilder sb = new StringBuilder();\n        if (etc.exists()) {\n          sb.append(etc.getAbsolutePath()).append(FILE_SEPARATOR).append(CLASSPATH_SEPARATOR);\n        }\n        sb.append(commonLibJars);\n        sb.append(jarsDir.getAbsolutePath()).append(FILE_SEPARATOR).append(JARS_WILDCARD);\n\n        // add extralibs if avail\n        if (librariesExtraDir != null) {\n          File libExtraDir = new File(librariesExtraDir, libDir.getName());\n          if (libExtraDir.exists()) {\n            File extraJarsDir = new File(libExtraDir, STAGE_LIB_JARS_DIR);\n            if (extraJarsDir.exists()) {\n              sb.append(CLASSPATH_SEPARATOR).append(extraJarsDir.getAbsolutePath()).append(FILE_SEPARATOR).\n                  append(JARS_WILDCARD);\n            }\n            File extraEtc = new File(libExtraDir, STAGE_LIB_CONF_DIR);\n            if (extraEtc.exists()) {\n              sb.append(CLASSPATH_SEPARATOR).append(extraEtc.getAbsolutePath());\n            }\n          }\n        }\n\n        map.put(libDir.getParentFile().getName() + FILE_SEPARATOR + libDir.getName(), getClasspathUrls(sb.toString()));\n      }\n    } else {\n      throw new IllegalArgumentException(String.format(MISSING_STAGE_LIBRARIES_DIR_MSG, baseDir));\n    }\n    return map;\n  }",
        "modified_code": "public static Map<String, List<URL>> getStageLibrariesClasspaths(String stageLibrariesDir, String librariesExtraDir,\n      final Set<String> stageLibs, String libsCommonLibDir) throws Exception {\n    Map<String, List<URL>> map = new LinkedHashMap<String, List<URL>>();\n\n    File baseDir = new File(stageLibrariesDir).getAbsoluteFile();\n    if (baseDir.exists()) {\n      File[] libDkgs = baseDir.listFiles(createStageLibFilter(stageLibs));\n      StringBuilder commonLibJars = new StringBuilder();\n      if (libsCommonLibDir != null) {\n        commonLibJars.append(new File(libsCommonLibDir).getAbsolutePath()).append(FILE_SEPARATOR).append(JARS_WILDCARD).\n            append(CLASSPATH_SEPARATOR);\n      }\n      for (File libDir : libDkgs) {\n        File jarsDir = new File(libDir, STAGE_LIB_JARS_DIR);\n        File etc = new File(libDir, STAGE_LIB_CONF_DIR);\n        if (!jarsDir.exists()) {\n          throw new IllegalArgumentException(String.format(MISSING_STAGE_LIB_JARS_DIR_MSG, libDir));\n        }\n        StringBuilder sb = new StringBuilder();\n        if (etc.exists()) {\n          sb.append(etc.getAbsolutePath()).append(FILE_SEPARATOR).append(CLASSPATH_SEPARATOR);\n        }\n        sb.append(commonLibJars);\n        sb.append(jarsDir.getAbsolutePath()).append(FILE_SEPARATOR).append(JARS_WILDCARD);\n\n        // add extralibs if avail\n        if (librariesExtraDir != null) {\n          File libExtraDir = new File(librariesExtraDir, libDir.getName());\n          if (libExtraDir.exists()) {\n            File extraJarsDir = new File(libExtraDir, STAGE_LIB_JARS_DIR);\n            if (extraJarsDir.exists()) {\n              sb.append(CLASSPATH_SEPARATOR).append(extraJarsDir.getAbsolutePath()).append(FILE_SEPARATOR).\n                  append(JARS_WILDCARD);\n            }\n            File extraEtc = new File(libExtraDir, STAGE_LIB_CONF_DIR);\n            if (extraEtc.exists()) {\n              sb.append(CLASSPATH_SEPARATOR).append(extraEtc.getAbsolutePath());\n            }\n          }\n        }\n\n        map.put(libDir.getParentFile().getName() + FILE_SEPARATOR + libDir.getName(), getClasspathUrls(sb.toString()));\n      }\n    } else {\n      throw new IllegalArgumentException(String.format(MISSING_STAGE_LIBRARIES_DIR_MSG, baseDir));\n    }\n    return map;\n  }",
        "explanations_by_ours": [
            "the list of stage libraries",
            "the lib directories",
            "the list of the stage libraries"
        ],
        "corrections_by_ours": [
            "listDkgs",
            "librariesDkgs",
            "libStage",
            "libDirectories",
            "libLibraries",
            "directoriesDkgs",
            "stageDkgs",
            "libList",
            "libLib",
            "libDkgs"
        ],
        "corrections_by_baseline": [
            "commonLibJars",
            "protolibJars",
            "libs",
            "libraryJars",
            "libraryDependencies",
            "pkgs",
            "missingLibraries",
            "installedLibraries",
            "stageLibjars",
            "nativeLibsDirectory"
        ]
    },
    {
        "original_word": "Skipped",
        "typo_word": "Skioled",
        "original_variable": "amountSkipped",
        "typo_variable": "amountSkioled",
        "original_code": "public static void skip(InputStream is, long amount) throws IOException {\n        long leftToSkip = amount;\n        long amountSkipped = 0;\n        while(leftToSkip > 0 && amountSkipped >= 0){\n            amountSkipped = is.skip(leftToSkip);\n            leftToSkip -= amountSkipped;\n        }\n    }",
        "modified_code": "public static void skip(InputStream is, long amount) throws IOException {\n        long leftToSkip = amount;\n        long amountSkioled = 0;\n        while(leftToSkip > 0 && amountSkioled >= 0){\n            amountSkioled = is.skip(leftToSkip);\n            leftToSkip -= amountSkioled;\n        }\n    }",
        "explanations_by_ours": [
            "the amount of bytes to skip",
            "the number of bytes to skip",
            "number of bytes to skip"
        ],
        "corrections_by_ours": [
            "amountSkip",
            "amountAmount",
            "amountBytes",
            "amountNumber",
            "bytesSkioled",
            "skipSkioled",
            "numberSkioled",
            "amountSkioled"
        ],
        "corrections_by_baseline": [
            "amount",
            "amountSkipped",
            "rewardsBalance",
            "snappedStopMillis",
            "remainingNanos",
            "delayPercent",
            "nstrikes",
            "factorToGetSeconds",
            "snappedStartMillis",
            "fromCount"
        ]
    },
    {
        "original_word": "Code",
        "typo_word": "Clds",
        "original_variable": "fileCode",
        "typo_variable": "fileClds",
        "original_code": "public static String getFileType(File file){\n        String res = null;\n        try{\n            @SuppressWarnings(\"resource\")\n            FileInputStream fis = new FileInputStream(file);\n            byte[] b = new byte[10];\n            fis.read(b, 0, b.length);\n            String fileCode = bytesToHexString(b);\n\n            Iterator<String> keyIter = FILE_TYPE_MAP.keySet().iterator();\n            while(keyIter.hasNext()){\n                String key = keyIter.next();\n                if(key.toLowerCase().startsWith(fileCode.toLowerCase()) || fileCode.toLowerCase().startsWith(key.toLowerCase())){\n                    res = FILE_TYPE_MAP.get(key);\n                    break;\n                }\n            }\n        }catch(FileNotFoundException e){\n            e.printStackTrace();\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n        return res;\n    }",
        "modified_code": "public static String getFileType(File file){\n        String res = null;\n        try{\n            @SuppressWarnings(\"resource\")\n            FileInputStream fis = new FileInputStream(file);\n            byte[] b = new byte[10];\n            fis.read(b, 0, b.length);\n            String fileClds = bytesToHexString(b);\n\n            Iterator<String> keyIter = FILE_TYPE_MAP.keySet().iterator();\n            while(keyIter.hasNext()){\n                String key = keyIter.next();\n                if(key.toLowerCase().startsWith(fileClds.toLowerCase()) || fileClds.toLowerCase().startsWith(key.toLowerCase())){\n                    res = FILE_TYPE_MAP.get(key);\n                    break;\n                }\n            }\n        }catch(FileNotFoundException e){\n            e.printStackTrace();\n        }catch (IOException e){\n            e.printStackTrace();\n        }\n        return res;\n    }",
        "explanations_by_ours": [
            ".",
            "fileClds",
            "fileClds."
        ],
        "corrections_by_ours": [
            "cClds",
            "ldsClds",
            "fileFilelds",
            "fileLdslds",
            "fileCfile",
            "fileCc",
            "fileClds"
        ],
        "corrections_by_baseline": [
            "gcmfiles",
            "apFile",
            "mappingFiles",
            "ccFile",
            "cncFile",
            "extDictFiles",
            "fileProfiles",
            "fileProperties",
            "overrideFile",
            "dbfile"
        ]
    },
    {
        "original_word": "database",
        "typo_word": "dwtxbase",
        "original_variable": "database",
        "typo_variable": "dwtxbase",
        "original_code": "@Override\n    public boolean importGeoPackage(String name, File file, boolean override) {\n\n        // Verify the file has the right extension\n        GeoPackageValidate.validateGeoPackageExtension(file);\n\n        // Use the provided name or the base file name as the database name\n        String database;\n        if (name != null) {\n            database = name;\n        } else {\n            database = GeoPackageIOUtils.getFileNameWithoutExtension(file);\n        }\n\n        boolean success = false;\n        try {\n            FileInputStream geoPackageStream = new FileInputStream(file);\n            success = importGeoPackage(database, override, geoPackageStream,\n                    null);\n        } catch (FileNotFoundException e) {\n            throw new GeoPackageException(\n                    \"Failed read or write GeoPackage file '\" + file\n                            + \"' to database: '\" + database + \"'\", e);\n        }\n\n        return success;\n    }",
        "modified_code": "@Override\n    public boolean importGeoPackage(String name, File file, boolean override) {\n\n        // Verify the file has the right extension\n        GeoPackageValidate.validateGeoPackageExtension(file);\n\n        // Use the provided name or the base file name as the database name\n        String dwtxbase;\n        if (name != null) {\n            dwtxbase = name;\n        } else {\n            dwtxbase = GeoPackageIOUtils.getFileNameWithoutExtension(file);\n        }\n\n        boolean success = false;\n        try {\n            FileInputStream geoPackageStream = new FileInputStream(file);\n            success = importGeoPackage(dwtxbase, override, geoPackageStream,\n                    null);\n        } catch (FileNotFoundException e) {\n            throw new GeoPackageException(\n                    \"Failed read or write GeoPackage file '\" + file\n                            + \"' to database: '\" + dwtxbase + \"'\", e);\n        }\n\n        return success;\n    }",
        "explanations_by_ours": [
            "GeoPackage base name",
            "GeoPackage base name.",
            "GeoPackage name"
        ],
        "corrections_by_ours": [
            "base",
            "package",
            "name",
            "geo"
        ],
        "corrections_by_baseline": [
            "dtc",
            "d4ds",
            "txnOfy",
            "txn",
            "dbs",
            "jtx",
            "txlist",
            "txManager",
            "pjpn",
            "pdx"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "resupr",
        "original_variable": "result",
        "typo_variable": "resupr",
        "original_code": "public MAVector dot(MAVector v) {\n\n    if (ncols != v.getNelems())\n      throw new IllegalArgumentException(\"MAMatrix.dot \"+ncols+\" != \"+ v.getNelems());\n\n    ArrayDouble.D1 result = new ArrayDouble.D1(nrows);\n    Index imr = result.getIndex();\n\n    for (int i=0; i<nrows; i++) {\n      double sum = 0.0;\n      for (int k=0; k<ncols; k++)\n        sum += getDouble(i, k) * v.getDouble(k);\n      result.setDouble( imr.set(i), sum);\n    }\n\n    return new MAVector( result);\n  }",
        "modified_code": "public MAVector dot(MAVector v) {\n\n    if (ncols != v.getNelems())\n      throw new IllegalArgumentException(\"MAMatrix.dot \"+ncols+\" != \"+ v.getNelems());\n\n    ArrayDouble.D1 resupr = new ArrayDouble.D1(nrows);\n    Index imr = resupr.getIndex();\n\n    for (int i=0; i<nrows; i++) {\n      double sum = 0.0;\n      for (int k=0; k<ncols; k++)\n        sum += getDouble(i, k) * v.getDouble(k);\n      resupr.setDouble( imr.set(i), sum);\n    }\n\n    return new MAVector( resupr);\n  }",
        "explanations_by_ours": [
            "the resulting matrix",
            "the result vector",
            "a new matrix"
        ],
        "corrections_by_ours": [
            "result",
            "resulting",
            "vector",
            "new",
            "matrix"
        ],
        "corrections_by_baseline": [
            "resul",
            "res",
            "restart",
            "andrew",
            "reload",
            "re",
            "upc",
            "newR",
            "new_res",
            "rewrite"
        ]
    },
    {
        "original_word": "index",
        "typo_word": "igdea",
        "original_variable": "index",
        "typo_variable": "igdea",
        "original_code": "public static <ITEM> List<Map<String, Object>> selectFrom(List<Selector> selectors, Collection<ITEM> results, Map<String, FieldAccess> fields) {\n        List<Map<String, Object>> rows = new ArrayList<>( results.size() );\n\n\n        for ( Selector s : selectors ) {\n            s.handleStart( results );\n        }\n\n\n        int index = 0;\n        for ( ITEM item : results ) {\n            Map<String, Object> row = new LinkedHashMap<>();\n            for ( Selector s : selectors ) {\n                s.handleRow( index, row, item, fields );\n            }\n            index++;\n            rows.add( row );\n        }\n\n        for ( Selector s : selectors ) {\n            s.handleComplete( rows );\n        }\n\n        return rows;\n    }",
        "modified_code": "public static <ITEM> List<Map<String, Object>> selectFrom(List<Selector> selectors, Collection<ITEM> results, Map<String, FieldAccess> fields) {\n        List<Map<String, Object>> rows = new ArrayList<>( results.size() );\n\n\n        for ( Selector s : selectors ) {\n            s.handleStart( results );\n        }\n\n\n        int igdea = 0;\n        for ( ITEM item : results ) {\n            Map<String, Object> row = new LinkedHashMap<>();\n            for ( Selector s : selectors ) {\n                s.handleRow( igdea, row, item, fields );\n            }\n            igdea++;\n            rows.add( row );\n        }\n\n        for ( Selector s : selectors ) {\n            s.handleComplete( rows );\n        }\n\n        return rows;\n    }",
        "explanations_by_ours": [
            "The number of rows to return.",
            "The number of rows to select.",
            "The number of rows to be returned."
        ],
        "corrections_by_ours": [
            "select",
            "number",
            "returned",
            "rows",
            "return"
        ],
        "corrections_by_baseline": [
            "dpo",
            "poa",
            "de",
            "po",
            "SA",
            "sa",
            "csa",
            "caco",
            "ima",
            "ha"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rrsjlt",
        "original_variable": "result",
        "typo_variable": "rrsjlt",
        "original_code": "public int handleAlreadyExistingFiles() throws StageException, IOException {\n    int result = 0;\n\n    String globPath = dirPathTemplate;\n\n    final String staticExpReg = \"\\\\$\\\\{(sdc:|pipeline:|runtime:)[a-zA-Z0-9\\\\(\\\\)]*\\\\}\";\n    Pattern pattern = Pattern.compile(staticExpReg);\n    Matcher matcher = pattern.matcher(globPath);\n    ELEval eval = context.createELEval(\"dirPathTemplate\");\n    ELVars vars = context.createELVars();\n\n    while (matcher.find()) {\n      String expressionString = eval.eval(vars, matcher.group(), String.class);\n      globPath = globPath.replace(matcher.group(), expressionString);\n    }\n\n    final String expReg = \"\\\\$\\\\{[^}]*\\\\}\";\n    pattern = Pattern.compile(expReg);\n    matcher = pattern.matcher(globPath);\n    while (matcher.find()) {\n      globPath = globPath.replace(matcher.group(), \"*\");\n    }\n    globPath = globPath.replaceAll(\"\\\\*+\", \"*\");\n    globPath = globPath + \"/\" + TMP_FILE_PREFIX + uniquePrefix + \"*\";\n\n    LOG.info(\"Created the following glob path for file recovery: {}\", globPath);\n    FileStatus[] fileStatuses = fs.globStatus(new Path(globPath));\n    for (FileStatus fileStatus : fileStatuses) {\n      fsHelper.handleAlreadyExistingFile(fs, fileStatus.getPath());\n      result++;\n    }\n\n    return result;\n  }",
        "modified_code": "public int handleAlreadyExistingFiles() throws StageException, IOException {\n    int rrsjlt = 0;\n\n    String globPath = dirPathTemplate;\n\n    final String staticExpReg = \"\\\\$\\\\{(sdc:|pipeline:|runtime:)[a-zA-Z0-9\\\\(\\\\)]*\\\\}\";\n    Pattern pattern = Pattern.compile(staticExpReg);\n    Matcher matcher = pattern.matcher(globPath);\n    ELEval eval = context.createELEval(\"dirPathTemplate\");\n    ELVars vars = context.createELVars();\n\n    while (matcher.find()) {\n      String expressionString = eval.eval(vars, matcher.group(), String.class);\n      globPath = globPath.replace(matcher.group(), expressionString);\n    }\n\n    final String expReg = \"\\\\$\\\\{[^}]*\\\\}\";\n    pattern = Pattern.compile(expReg);\n    matcher = pattern.matcher(globPath);\n    while (matcher.find()) {\n      globPath = globPath.replace(matcher.group(), \"*\");\n    }\n    globPath = globPath.replaceAll(\"\\\\*+\", \"*\");\n    globPath = globPath + \"/\" + TMP_FILE_PREFIX + uniquePrefix + \"*\";\n\n    LOG.info(\"Created the following glob path for file recovery: {}\", globPath);\n    FileStatus[] fileStatuses = fs.globStatus(new Path(globPath));\n    for (FileStatus fileStatus : fileStatuses) {\n      fsHelper.handleAlreadyExistingFile(fs, fileStatus.getPath());\n      rrsjlt++;\n    }\n\n    return rrsjlt;\n  }",
        "explanations_by_ours": [
            "the number of files that could not be handled.",
            "the number of files that were successfully handled.",
            "the number of files that could not be handled"
        ],
        "corrections_by_ours": [
            "could",
            "successfully",
            "handled",
            "files",
            "number"
        ],
        "corrections_by_baseline": [
            "rslt",
            "rdr",
            "rsf",
            "rsm",
            "rs",
            "rctxt",
            "rsmd",
            "srcc",
            "rj",
            "putresp"
        ]
    },
    {
        "original_word": "Name",
        "typo_word": "Nqms",
        "original_variable": "stationName",
        "typo_variable": "stationNqms",
        "original_code": "StationFeature makeStation(StructureData stationData) {\n    if (stnVE.isMissing(stationData)) return null;\n    String stationName = stnVE.getCoordValueAsString(stationData);\n\n    String stationDesc = (stnDescVE == null) ? \"\" : stnDescVE.getCoordValueAsString(stationData);\n    String stnWmoId = (wmoVE == null) ? \"\" : wmoVE.getCoordValueAsString(stationData);\n\n    double lat = latVE.getCoordValue(stationData);\n    double lon = lonVE.getCoordValue(stationData);\n    double elev = (stnAltVE == null) ? Double.NaN : stnAltVE.getCoordValue(stationData);\n\n    // missing lat, lon means skip this station\n    if (Double.isNaN(lat) || Double.isNaN(lon)) return null;\n\n    return new StationFeatureImpl(stationName, stationDesc, stnWmoId, lat, lon, elev, -1, stationData);\n  }",
        "modified_code": "StationFeature makeStation(StructureData stationData) {\n    if (stnVE.isMissing(stationData)) return null;\n    String stationNqms = stnVE.getCoordValueAsString(stationData);\n\n    String stationDesc = (stnDescVE == null) ? \"\" : stnDescVE.getCoordValueAsString(stationData);\n    String stnWmoId = (wmoVE == null) ? \"\" : wmoVE.getCoordValueAsString(stationData);\n\n    double lat = latVE.getCoordValue(stationData);\n    double lon = lonVE.getCoordValue(stationData);\n    double elev = (stnAltVE == null) ? Double.NaN : stnAltVE.getCoordValue(stationData);\n\n    // missing lat, lon means skip this station\n    if (Double.isNaN(lat) || Double.isNaN(lon)) return null;\n\n    return new StationFeatureImpl(stationNqms, stationDesc, stnWmoId, lat, lon, elev, -1, stationData);\n  }",
        "explanations_by_ours": [
            "station Nqms",
            "station Nqms.",
            "station NQMS"
        ],
        "corrections_by_ours": [
            "nqmsNqms",
            "stationStation",
            "stationNqms"
        ],
        "corrections_by_baseline": [
            "stationNum",
            "stationRange",
            "stationList",
            "wantedStations",
            "numStations",
            "mns",
            "stationId",
            "station",
            "subsetStations",
            "stationDesc"
        ]
    },
    {
        "original_word": "retval",
        "typo_word": "rstvql",
        "original_variable": "retval",
        "typo_variable": "rstvql",
        "original_code": "public Object makeObject() {\n        \n        SbbObject retval;\n        if (doTraceLogs) {\n        \tlogger.trace(\"makeObject() for \"+serviceID+\" and \"+sbbComponent);\n        }\n\n        final ClassLoader oldClassLoader = SleeContainerUtils\n                .getCurrentThreadClassLoader();\n\n        try {\n            final ClassLoader cl = sbbComponent.getClassLoader();\n            if (System.getSecurityManager()!=null)\n                AccessController.doPrivileged(new PrivilegedAction<Object>() {\n                    public Object run() {\n                        Thread.currentThread().setContextClassLoader(cl);\n                        return null;\n\n                    }\n                });\n            else\n                Thread.currentThread().setContextClassLoader(cl);\n            \n            retval = new SbbObjectImpl(serviceID,sbbComponent);\n        \n        } finally {\n            if (System.getSecurityManager()!=null)\n                AccessController.doPrivileged(new PrivilegedAction<Object>() {\n                    public Object run() {\n                        Thread.currentThread().setContextClassLoader(\n                                oldClassLoader);\n                        return null;\n                    }\n                });\n            else\n                Thread.currentThread().setContextClassLoader(oldClassLoader);\n        }\n\n        retval.setState(SbbObjectState.POOLED);\n        \n        return retval;\n    }",
        "modified_code": "public Object makeObject() {\n        \n        SbbObject rstvql;\n        if (doTraceLogs) {\n        \tlogger.trace(\"makeObject() for \"+serviceID+\" and \"+sbbComponent);\n        }\n\n        final ClassLoader oldClassLoader = SleeContainerUtils\n                .getCurrentThreadClassLoader();\n\n        try {\n            final ClassLoader cl = sbbComponent.getClassLoader();\n            if (System.getSecurityManager()!=null)\n                AccessController.doPrivileged(new PrivilegedAction<Object>() {\n                    public Object run() {\n                        Thread.currentThread().setContextClassLoader(cl);\n                        return null;\n\n                    }\n                });\n            else\n                Thread.currentThread().setContextClassLoader(cl);\n            \n            rstvql = new SbbObjectImpl(serviceID,sbbComponent);\n        \n        } finally {\n            if (System.getSecurityManager()!=null)\n                AccessController.doPrivileged(new PrivilegedAction<Object>() {\n                    public Object run() {\n                        Thread.currentThread().setContextClassLoader(\n                                oldClassLoader);\n                        return null;\n                    }\n                });\n            else\n                Thread.currentThread().setContextClassLoader(oldClassLoader);\n        }\n\n        rstvql.setState(SbbObjectState.POOLED);\n        \n        return rstvql;\n    }",
        "explanations_by_ours": [
            "The SbbObject to be created.",
            "The object to be created.",
            "The SbbObject to be created"
        ],
        "corrections_by_ours": [
            "sbb",
            "created",
            "object"
        ],
        "corrections_by_baseline": [
            "dbsql",
            "preparedQuery",
            "sqlQuery",
            "sql",
            "pstmt",
            "preparedStatement",
            "sqlString",
            "pureSql",
            "xqlon",
            "stmt"
        ]
    },
    {
        "original_word": "input",
        "typo_word": "ijpjt",
        "original_variable": "input",
        "typo_variable": "ijpjt",
        "original_code": "public static final String escapeForXML(String string) {\n        if (string == null) {\n            return null;\n        }\n        char ch;\n        int i = 0;\n        int last = 0;\n        char[] input = string.toCharArray();\n        int len = input.length;\n        StringBuffer out = new StringBuffer((int) (len * 1.3));\n        for (; i < len; i++) {\n            ch = input[i];\n            if (ch > '>') {\n                continue;\n            } else if (ch == '<') {\n                if (i > last) {\n                    out.append(input, last, i - last);\n                }\n                last = i + 1;\n                out.append(LT_ENCODE);\n            } else if (ch == '>') {\n                if (i > last) {\n                    out.append(input, last, i - last);\n                }\n                last = i + 1;\n                out.append(GT_ENCODE);\n            }\n\n            else if (ch == '&') {\n                if (i > last) {\n                    out.append(input, last, i - last);\n                }\n                // Do nothing if the string is of the form &#235; (unicode\n                // value)\n                if (!(len > i + 5 && input[i + 1] == '#'\n                        && Character.isDigit(input[i + 2])\n                        && Character.isDigit(input[i + 3])\n                        && Character.isDigit(input[i + 4]) && input[i + 5] == ';')) {\n                    last = i + 1;\n                    out.append(AMP_ENCODE);\n                }\n            } else if (ch == '\"') {\n                if (i > last) {\n                    out.append(input, last, i - last);\n                }\n                last = i + 1;\n                out.append(QUOTE_ENCODE);\n            }\n        }\n        if (last == 0) {\n            return string;\n        }\n        if (i > last) {\n            out.append(input, last, i - last);\n        }\n        return out.toString();\n    }",
        "modified_code": "public static final String escapeForXML(String string) {\n        if (string == null) {\n            return null;\n        }\n        char ch;\n        int i = 0;\n        int last = 0;\n        char[] ijpjt = string.toCharArray();\n        int len = ijpjt.length;\n        StringBuffer out = new StringBuffer((int) (len * 1.3));\n        for (; i < len; i++) {\n            ch = ijpjt[i];\n            if (ch > '>') {\n                continue;\n            } else if (ch == '<') {\n                if (i > last) {\n                    out.append(ijpjt, last, i - last);\n                }\n                last = i + 1;\n                out.append(LT_ENCODE);\n            } else if (ch == '>') {\n                if (i > last) {\n                    out.append(ijpjt, last, i - last);\n                }\n                last = i + 1;\n                out.append(GT_ENCODE);\n            }\n\n            else if (ch == '&') {\n                if (i > last) {\n                    out.append(ijpjt, last, i - last);\n                }\n                // Do nothing if the string is of the form &#235; (unicode\n                // value)\n                if (!(len > i + 5 && ijpjt[i + 1] == '#'\n                        && Character.isDigit(ijpjt[i + 2])\n                        && Character.isDigit(ijpjt[i + 3])\n                        && Character.isDigit(ijpjt[i + 4]) && ijpjt[i + 5] == ';')) {\n                    last = i + 1;\n                    out.append(AMP_ENCODE);\n                }\n            } else if (ch == '\"') {\n                if (i > last) {\n                    out.append(ijpjt, last, i - last);\n                }\n                last = i + 1;\n                out.append(QUOTE_ENCODE);\n            }\n        }\n        if (last == 0) {\n            return string;\n        }\n        if (i > last) {\n            out.append(ijpjt, last, i - last);\n        }\n        return out.toString();\n    }",
        "explanations_by_ours": [
            "the string to escape",
            "the XML string to escape",
            "the string to be escaped"
        ],
        "corrections_by_ours": [
            "escaped",
            "string",
            "xml",
            "escape"
        ],
        "corrections_by_baseline": [
            "jshft",
            "jdrct",
            "jbndg",
            "rj",
            "thislen",
            "dr",
            "wertklassePassed",
            "jbeg",
            "drss",
            "daft"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "fesilt",
        "original_variable": "result",
        "typo_variable": "fesilt",
        "original_code": "private Formatters registerOptional() {\n    conversion.addConverter(\n        new GenericConverter() {\n\n          public Object convert(\n              Object source, TypeDescriptor sourceType, TypeDescriptor targetType) {\n            if (sourceType.getObjectType().equals(String.class)) {\n              // From String to Optional\n              Object element =\n                  conversion.convert(source, sourceType, targetType.elementTypeDescriptor(source));\n              return Optional.ofNullable(element);\n            } else if (targetType.getObjectType().equals(String.class)) {\n              // From Optional to String\n              if (source == null) return \"\";\n\n              Optional<?> opt = (Optional) source;\n              return opt.map(\n                      o ->\n                          conversion.convert(\n                              source, sourceType.getElementTypeDescriptor(), targetType))\n                  .orElse(\"\");\n            }\n            return null;\n          }\n\n          public Set<GenericConverter.ConvertiblePair> getConvertibleTypes() {\n            Set<ConvertiblePair> result = new HashSet<>();\n            result.add(new ConvertiblePair(Optional.class, String.class));\n            result.add(new ConvertiblePair(String.class, Optional.class));\n            return result;\n          }\n        });\n\n    return this;\n  }",
        "modified_code": "private Formatters registerOptional() {\n    conversion.addConverter(\n        new GenericConverter() {\n\n          public Object convert(\n              Object source, TypeDescriptor sourceType, TypeDescriptor targetType) {\n            if (sourceType.getObjectType().equals(String.class)) {\n              // From String to Optional\n              Object element =\n                  conversion.convert(source, sourceType, targetType.elementTypeDescriptor(source));\n              return Optional.ofNullable(element);\n            } else if (targetType.getObjectType().equals(String.class)) {\n              // From Optional to String\n              if (source == null) return \"\";\n\n              Optional<?> opt = (Optional) source;\n              return opt.map(\n                      o ->\n                          conversion.convert(\n                              source, sourceType.getElementTypeDescriptor(), targetType))\n                  .orElse(\"\");\n            }\n            return null;\n          }\n\n          public Set<GenericConverter.ConvertiblePair> getConvertibleTypes() {\n            Set<ConvertiblePair> fesilt = new HashSet<>();\n            fesilt.add(new ConvertiblePair(Optional.class, String.class));\n            fesilt.add(new ConvertiblePair(String.class, Optional.class));\n            return fesilt;\n          }\n        });\n\n    return this;\n  }",
        "explanations_by_ours": [
            "The set of converters to register.",
            "Set of convertible types",
            "Set of convertible types."
        ],
        "corrections_by_ours": [
            "register",
            "set",
            "convertible",
            "converters",
            "types"
        ],
        "corrections_by_baseline": [
            "coldp",
            "gammCompl",
            "Q_Fract_allpass",
            "g_DecaySlope_filt",
            "glamn",
            "f_huff",
            "CylinderScale",
            "ilenhd",
            "filterer",
            "cosl"
        ]
    },
    {
        "original_word": "inputs",
        "typo_word": "inpurw",
        "original_variable": "inputs",
        "typo_variable": "inpurw",
        "original_code": "protected void initializeCurrFromList(List<DataSet> examples) {\n\n        if (examples.isEmpty())\n            log.warn(\"Warning: empty dataset from the fetcher\");\n\n        INDArray inputs = createInputMatrix(examples.size());\n        INDArray labels = createOutputMatrix(examples.size());\n        for (int i = 0; i < examples.size(); i++) {\n            inputs.putRow(i, examples.get(i).getFeatureMatrix());\n            labels.putRow(i, examples.get(i).getLabels());\n        }\n        curr = new DataSet(inputs, labels);\n\n    }",
        "modified_code": "protected void initializeCurrFromList(List<DataSet> examples) {\n\n        if (examples.isEmpty())\n            log.warn(\"Warning: empty dataset from the fetcher\");\n\n        INDArray inpurw = createInputMatrix(examples.size());\n        INDArray labels = createOutputMatrix(examples.size());\n        for (int i = 0; i < examples.size(); i++) {\n            inpurw.putRow(i, examples.get(i).getFeatureMatrix());\n            labels.putRow(i, examples.get(i).getLabels());\n        }\n        curr = new DataSet(inpurw, labels);\n\n    }",
        "explanations_by_ours": [
            "the input matrix",
            "the input matrix of the current DataSet",
            "the input matrix of the DataSet"
        ],
        "corrections_by_ours": [
            "input",
            "data",
            "matrix",
            "set",
            "current"
        ],
        "corrections_by_baseline": [
            "purged",
            "noisedba",
            "wac",
            "denom",
            "difmin",
            "wrpUnchecked",
            "squeezeCandidates",
            "dam",
            "minsd",
            "wierd"
        ]
    },
    {
        "original_word": "curr",
        "typo_word": "vkrr",
        "original_variable": "currDbId",
        "typo_variable": "vkrrDbId",
        "original_code": "@Override\n  public final boolean sync(final Map<String, Object> pAddParam,\n    final Object pEntity) throws Exception {\n    APersistableBaseVersion entityPb = (APersistableBaseVersion) pEntity;\n    int currDbId = getSrvOrm().getIdDatabase();\n    if (currDbId == entityPb.getIdDatabaseBirth()) {\n      throw new ExceptionWithCode(ExceptionWithCode.SOMETHING_WRONG,\n        \"Foreign entity born in this database! {ID, ID BIRTH, DB BIRTH}:\"\n          + \" {\" + entityPb.getItsId() + \", \" + entityPb.getIdBirth()\n            + \",\" + entityPb.getIdDatabaseBirth());\n    }\n    String tblNm = pEntity.getClass().getSimpleName().toUpperCase();\n    String whereStr = \" where \" + tblNm + \".IDBIRTH=\" + entityPb.getItsId()\n      + \" and \" + tblNm + \".IDDATABASEBIRTH=\" + entityPb.getIdDatabaseBirth();\n    APersistableBaseVersion entityPbDb = getSrvOrm()\n      .retrieveEntityWithConditions(pAddParam, entityPb.getClass(), whereStr);\n    entityPb.setIdBirth(entityPb.getItsId());\n    entityPb.setItsId(null);\n    boolean isNew = true;\n    if (entityPbDb != null) {\n      entityPb.setItsVersion(entityPbDb.getItsVersion());\n      entityPb.setItsId(entityPbDb.getItsId());\n      isNew = false;\n    }\n    return isNew;\n  }",
        "modified_code": "@Override\n  public final boolean sync(final Map<String, Object> pAddParam,\n    final Object pEntity) throws Exception {\n    APersistableBaseVersion entityPb = (APersistableBaseVersion) pEntity;\n    int vkrrDbId = getSrvOrm().getIdDatabase();\n    if (vkrrDbId == entityPb.getIdDatabaseBirth()) {\n      throw new ExceptionWithCode(ExceptionWithCode.SOMETHING_WRONG,\n        \"Foreign entity born in this database! {ID, ID BIRTH, DB BIRTH}:\"\n          + \" {\" + entityPb.getItsId() + \", \" + entityPb.getIdBirth()\n            + \",\" + entityPb.getIdDatabaseBirth());\n    }\n    String tblNm = pEntity.getClass().getSimpleName().toUpperCase();\n    String whereStr = \" where \" + tblNm + \".IDBIRTH=\" + entityPb.getItsId()\n      + \" and \" + tblNm + \".IDDATABASEBIRTH=\" + entityPb.getIdDatabaseBirth();\n    APersistableBaseVersion entityPbDb = getSrvOrm()\n      .retrieveEntityWithConditions(pAddParam, entityPb.getClass(), whereStr);\n    entityPb.setIdBirth(entityPb.getItsId());\n    entityPb.setItsId(null);\n    boolean isNew = true;\n    if (entityPbDb != null) {\n      entityPb.setItsVersion(entityPbDb.getItsVersion());\n      entityPb.setItsId(entityPbDb.getItsId());\n      isNew = false;\n    }\n    return isNew;\n  }",
        "explanations_by_ours": [
            "id of database",
            "id of this database",
            "id of the database"
        ],
        "corrections_by_ours": [
            "vkrrDatabaseId",
            "idDbId",
            "databaseDbId",
            "vkrrIdId",
            "vkrrDbDatabase",
            "vkrrDbId"
        ],
        "corrections_by_baseline": [
            "dbId",
            "currDbId",
            "requestedDatabaseId",
            "spcid",
            "requestedDatabaseIdStr",
            "stnWmoId",
            "recordId",
            "bdaId",
            "sbbEntityID",
            "sbbEntityId"
        ]
    },
    {
        "original_word": "classes",
        "typo_word": "classse",
        "original_variable": "classes",
        "typo_variable": "classse",
        "original_code": "public Object getObjectInstance(final Object ref, final Name name, final Context nameCtx, final Hashtable<?, ?> environment) throws Exception {\n        final ClassLoader classLoader = WildFlySecurityManager.getCurrentContextClassLoaderPrivileged();\n        if (classLoader == null) {\n            return ref;\n        }\n        final String factoriesProp = (String) environment.get(Context.OBJECT_FACTORIES);\n        if (factoriesProp != null) {\n            final String[] classes = factoriesProp.split(\":\");\n            for (String className : classes) {\n                try {\n                    final Class<?> factoryClass = classLoader.loadClass(className);\n                    final ObjectFactory objectFactory = ObjectFactory.class.cast(factoryClass.newInstance());\n                    final Object result = objectFactory.getObjectInstance(ref, name, nameCtx, environment);\n                    if (result != null) {\n                        return result;\n                    }\n                } catch (Throwable ignored) {\n                }\n            }\n        }\n        return ref;\n    }",
        "modified_code": "public Object getObjectInstance(final Object ref, final Name name, final Context nameCtx, final Hashtable<?, ?> environment) throws Exception {\n        final ClassLoader classLoader = WildFlySecurityManager.getCurrentContextClassLoaderPrivileged();\n        if (classLoader == null) {\n            return ref;\n        }\n        final String factoriesProp = (String) environment.get(Context.OBJECT_FACTORIES);\n        if (factoriesProp != null) {\n            final String[] classse = factoriesProp.split(\":\");\n            for (String className : classse) {\n                try {\n                    final Class<?> factoryClass = classLoader.loadClass(className);\n                    final ObjectFactory objectFactory = ObjectFactory.class.cast(factoryClass.newInstance());\n                    final Object result = objectFactory.getObjectInstance(ref, name, nameCtx, environment);\n                    if (result != null) {\n                        return result;\n                    }\n                } catch (Throwable ignored) {\n                }\n            }\n        }\n        return ref;\n    }",
        "explanations_by_ours": [
            "list of object factories",
            "list of factories",
            "list of class names"
        ],
        "corrections_by_ours": [
            "listse",
            "classlist",
            "factoriesse",
            "namesse",
            "classnames",
            "classclass",
            "classobject",
            "classfactories",
            "objectse",
            "classse"
        ],
        "corrections_by_baseline": [
            "classname",
            "class_",
            "className",
            "pseudoClass",
            "clazz",
            "eclass",
            "clClass",
            "pclass",
            "eclazz",
            "superClazz"
        ]
    },
    {
        "original_word": "closest",
        "typo_word": "clksedt",
        "original_variable": "closest",
        "typo_variable": "clksedt",
        "original_code": "public static double distanceSq( LineSegment2D_F64 segmentA , LineSegment2D_F64 segmentB ) {\n\n\t\t// intersection of the two lines relative to A\n\t\tdouble slopeAX = segmentA.slopeX();\n\t\tdouble slopeAY = segmentA.slopeY();\n\t\tdouble slopeBX = segmentB.slopeX();\n\t\tdouble slopeBY = segmentB.slopeY();\n\n\t\tdouble ta = slopeBX*( segmentA.a.y - segmentB.a.y ) - slopeBY*( segmentA.a.x - segmentB.a.x );\n\t\tdouble bottom = slopeBY*slopeAX - slopeAY*slopeBX;\n\n\t\t// see they intersect\n\t\tif( bottom != 0 ) {\n\t\t\t// see if the intersection is inside of lineA\n\t\t\tta /= bottom;\n\t\t\tif( ta >= 0 && ta <= 1.0 ) {\n\t\t\t\t// see if the intersection is inside of lineB\n\t\t\t\tdouble tb = slopeAX*( segmentB.a.y - segmentA.a.y ) - slopeAY*( segmentB.a.x - segmentA.a.x );\n\t\t\t\ttb /= slopeAY*slopeBX - slopeBY*slopeAX;\n\t\t\t\tif( tb >= 0 && tb <= 1.0 )\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\n\t\tdouble closest = Double.MAX_VALUE;\n\t\tclosest = Math.min(closest,distanceSq(segmentA, segmentB.a));\n\t\tclosest = Math.min(closest,distanceSq(segmentA, segmentB.b));\n\t\tclosest = Math.min(closest,distanceSq(segmentB, segmentA.a));\n\t\tclosest = Math.min(closest,distanceSq(segmentB, segmentA.b));\n\n\t\treturn closest;\n\t}",
        "modified_code": "public static double distanceSq( LineSegment2D_F64 segmentA , LineSegment2D_F64 segmentB ) {\n\n\t\t// intersection of the two lines relative to A\n\t\tdouble slopeAX = segmentA.slopeX();\n\t\tdouble slopeAY = segmentA.slopeY();\n\t\tdouble slopeBX = segmentB.slopeX();\n\t\tdouble slopeBY = segmentB.slopeY();\n\n\t\tdouble ta = slopeBX*( segmentA.a.y - segmentB.a.y ) - slopeBY*( segmentA.a.x - segmentB.a.x );\n\t\tdouble bottom = slopeBY*slopeAX - slopeAY*slopeBX;\n\n\t\t// see they intersect\n\t\tif( bottom != 0 ) {\n\t\t\t// see if the intersection is inside of lineA\n\t\t\tta /= bottom;\n\t\t\tif( ta >= 0 && ta <= 1.0 ) {\n\t\t\t\t// see if the intersection is inside of lineB\n\t\t\t\tdouble tb = slopeAX*( segmentB.a.y - segmentA.a.y ) - slopeAY*( segmentB.a.x - segmentA.a.x );\n\t\t\t\ttb /= slopeAY*slopeBX - slopeBY*slopeAX;\n\t\t\t\tif( tb >= 0 && tb <= 1.0 )\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\n\t\tdouble clksedt = Double.MAX_VALUE;\n\t\tclksedt = Math.min(clksedt,distanceSq(segmentA, segmentB.a));\n\t\tclksedt = Math.min(clksedt,distanceSq(segmentA, segmentB.b));\n\t\tclksedt = Math.min(clksedt,distanceSq(segmentB, segmentA.a));\n\t\tclksedt = Math.min(clksedt,distanceSq(segmentB, segmentA.b));\n\n\t\treturn clksedt;\n\t}",
        "explanations_by_ours": [
            "How much the distance should be computed",
            "How much the squared distance should be computed",
            "How much the distance should be computed."
        ],
        "corrections_by_ours": [
            "computed",
            "squared",
            "much",
            "distance"
        ],
        "corrections_by_baseline": [
            "cla",
            "ecef",
            "toker",
            "closable",
            "hcs",
            "ksp",
            "pce",
            "t",
            "T",
            "icb"
        ]
    },
    {
        "original_word": "bytes",
        "typo_word": "byhrs",
        "original_variable": "bytes",
        "typo_variable": "byhrs",
        "original_code": "public static byte[] encode(String str)\n\t{\n\t\tCharsetEncoder encoder = Charsets.UTF_8.newEncoder();\n\t\ttry {\n\t\t\tByteBuffer out = encoder.encode(CharBuffer.wrap(str));\n\t\t\tbyte[] bytes = new byte[out.limit()];\n\t\t\tout.get(bytes);\n\t\t\treturn bytes;\n\t\t} catch (CharacterCodingException ex) {\n\t\t\tthrow new IllegalArgumentException(ex);\n\t\t}\n\t}",
        "modified_code": "public static byte[] encode(String str)\n\t{\n\t\tCharsetEncoder encoder = Charsets.UTF_8.newEncoder();\n\t\ttry {\n\t\t\tByteBuffer out = encoder.encode(CharBuffer.wrap(str));\n\t\t\tbyte[] byhrs = new byte[out.limit()];\n\t\t\tout.get(byhrs);\n\t\t\treturn byhrs;\n\t\t} catch (CharacterCodingException ex) {\n\t\t\tthrow new IllegalArgumentException(ex);\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the byte array to encode into",
            "the byte array to be returned",
            "the byte array to fill"
        ],
        "corrections_by_ours": [
            "bytehrs",
            "arrayhrs",
            "byarray",
            "byreturned",
            "fillhrs",
            "encodehrs",
            "returnedhrs",
            "bybyte",
            "byfill",
            "byencode"
        ],
        "corrections_by_baseline": [
            "hrs",
            "drs",
            "proxies",
            "ingresses",
            "masters",
            "bytedata",
            "gdrs",
            "hrsi",
            "shards",
            "ifaces"
        ]
    },
    {
        "original_word": "With",
        "typo_word": "Wogh",
        "original_variable": "fieldWithName",
        "typo_variable": "fieldWoghName",
        "original_code": "@XmlTransient\n\tpublic TableField getFieldValueAsTableField(String fieldNameParam) {\n\t\tField fieldWithName = this.getField(fieldNameParam);\n\t\treturn (fieldWithName == null) ? null : fieldWithName.getFieldValueAsTableField();\n\t}",
        "modified_code": "@XmlTransient\n\tpublic TableField getFieldValueAsTableField(String fieldNameParam) {\n\t\tField fieldWoghName = this.getField(fieldNameParam);\n\t\treturn (fieldWoghName == null) ? null : fieldWoghName.getFieldValueAsTableField();\n\t}",
        "explanations_by_ours": [
            "the field to get the value of",
            "the field whose value is to be returned",
            "the field to get the value from"
        ],
        "corrections_by_ours": [
            "fieldWhoseName",
            "fieldWoghValue",
            "getWoghName",
            "fieldWoghWhose",
            "returnedWoghName",
            "fieldWoghReturned",
            "whoseWoghName",
            "valueWoghName",
            "fieldFieldName",
            "fieldGetName"
        ],
        "corrections_by_baseline": [
            "inFieldName",
            "fieldName",
            "fieldWithName",
            "fieldname",
            "inverseFieldName",
            "completeFieldName",
            "realFieldName",
            "fieldIdAsString",
            "equalsFieldName",
            "fieldString"
        ]
    },
    {
        "original_word": "markers",
        "typo_word": "matuers",
        "original_variable": "markers",
        "typo_variable": "matuers",
        "original_code": "private static void deleteTemporaryFiles() {\n    final File dir = getTmpDir();\n    final FilenameFilter filter = new FilenameFilter() {\n      public boolean accept(File dir, String name) {\n        return name.endsWith(HUMBLE_TEMP_EXTENSION);\n      }\n    };\n    final File markers[] = dir.listFiles(filter);\n    for (File marker : markers) {\n      final String markerName = marker.getName();\n      final String libName = markerName.substring(0, markerName.length()\n          - HUMBLE_TEMP_EXTENSION.length());\n      final File lib = new File(marker.getParentFile(), libName);\n      if (!lib.exists() || lib.delete())\n        marker.delete();\n    }\n  }",
        "modified_code": "private static void deleteTemporaryFiles() {\n    final File dir = getTmpDir();\n    final FilenameFilter filter = new FilenameFilter() {\n      public boolean accept(File dir, String name) {\n        return name.endsWith(HUMBLE_TEMP_EXTENSION);\n      }\n    };\n    final File matuers[] = dir.listFiles(filter);\n    for (File marker : matuers) {\n      final String markerName = marker.getName();\n      final String libName = markerName.substring(0, markerName.length()\n          - HUMBLE_TEMP_EXTENSION.length());\n      final File lib = new File(marker.getParentFile(), libName);\n      if (!lib.exists() || lib.delete())\n        marker.delete();\n    }\n  }",
        "explanations_by_ours": [
            "the list of temporary files.",
            "list of temporary files.",
            "the list of temporary files"
        ],
        "corrections_by_ours": [
            "files",
            "temporary",
            "list"
        ],
        "corrections_by_baseline": [
            "mat",
            "matchers",
            "vmas",
            "subsumers",
            "insets",
            "facets",
            "criterias",
            "predicates",
            "imps",
            "predecessors"
        ]
    },
    {
        "original_word": "jshft",
        "typo_word": "msuft",
        "original_variable": "jshft",
        "typo_variable": "msuft",
        "original_code": "private synchronized float[] DP_UGRB(int[] idata, int kxky, int nbits,\n                                       float qmin, float scale,\n                                       boolean misflg, int decimalScale)\n          throws IOException {\n    float scaleFactor = (decimalScale == 0)\n            ? 1.f\n            : (float) Math.pow(10.0, -decimalScale);\n    //\n    //Check for valid input.\n    //\n    float[] grid = new float[kxky];\n    if ((nbits <= 1) || (nbits > 31)) {\n      return grid;\n    }\n    if (scale == 0.) {\n      return grid;\n    }\n\n    //\n    //Compute missing data value.\n    //\n    int imax = (int) (Math.pow(2, nbits) - 1);\n    //\n    //Retrieve data points from buffer.\n    //\n    int iword = 0;\n    int ibit = 1;  // 1 based bit position\n    for (int i = 0; i < kxky; i++) {\n      //\n      //    Get the integer from the buffer.\n      //\n      int jshft = nbits + ibit - 33;\n      int idat = 0;\n      idat = (jshft < 0)\n              ? idata[iword] >>> Math.abs(jshft)\n              : idata[iword] << jshft;\n      idat = idat & imax;\n      //\n      //    Check to see if packed integer overflows into next word. LOOK fishy bit operations\n      //\n      if (jshft > 0) {\n        jshft -= 32;\n        int idat2 = 0;\n        idat2 = idata[iword + 1] >>> Math.abs(jshft);\n        idat = idat | idat2;\n      }\n      //\n      //    Compute value of word.\n      //\n      if ((idat == imax) && misflg) {\n        grid[i] = RMISSD;\n      } else {\n        grid[i] = (qmin + idat * scale) * scaleFactor;\n      }\n      //\n      //    Set location for next word.\n      //\n      ibit += nbits;\n      if (ibit > 32) {\n        ibit -= 32;\n        iword++;\n      }\n            /*\n            if (i < 25) {\n                System.out.println(\"grid[\"+i+\"]: \" + grid[i]);\n            }\n            */\n    }\n    return grid;\n  }",
        "modified_code": "private synchronized float[] DP_UGRB(int[] idata, int kxky, int nbits,\n                                       float qmin, float scale,\n                                       boolean misflg, int decimalScale)\n          throws IOException {\n    float scaleFactor = (decimalScale == 0)\n            ? 1.f\n            : (float) Math.pow(10.0, -decimalScale);\n    //\n    //Check for valid input.\n    //\n    float[] grid = new float[kxky];\n    if ((nbits <= 1) || (nbits > 31)) {\n      return grid;\n    }\n    if (scale == 0.) {\n      return grid;\n    }\n\n    //\n    //Compute missing data value.\n    //\n    int imax = (int) (Math.pow(2, nbits) - 1);\n    //\n    //Retrieve data points from buffer.\n    //\n    int iword = 0;\n    int ibit = 1;  // 1 based bit position\n    for (int i = 0; i < kxky; i++) {\n      //\n      //    Get the integer from the buffer.\n      //\n      int msuft = nbits + ibit - 33;\n      int idat = 0;\n      idat = (msuft < 0)\n              ? idata[iword] >>> Math.abs(msuft)\n              : idata[iword] << msuft;\n      idat = idat & imax;\n      //\n      //    Check to see if packed integer overflows into next word. LOOK fishy bit operations\n      //\n      if (msuft > 0) {\n        msuft -= 32;\n        int idat2 = 0;\n        idat2 = idata[iword + 1] >>> Math.abs(msuft);\n        idat = idat | idat2;\n      }\n      //\n      //    Compute value of word.\n      //\n      if ((idat == imax) && misflg) {\n        grid[i] = RMISSD;\n      } else {\n        grid[i] = (qmin + idat * scale) * scaleFactor;\n      }\n      //\n      //    Set location for next word.\n      //\n      ibit += nbits;\n      if (ibit > 32) {\n        ibit -= 32;\n        iword++;\n      }\n            /*\n            if (i < 25) {\n                System.out.println(\"grid[\"+i+\"]: \" + grid[i]);\n            }\n            */\n    }\n    return grid;\n  }",
        "explanations_by_ours": [
            "The MSUFFT of the integer in the buffer.",
            "The MSUFFT of the missing data value.",
            "The MSUFFT of the integer."
        ],
        "corrections_by_ours": [
            "msufft",
            "missing",
            "buffer",
            "data",
            "integer",
            "value"
        ],
        "corrections_by_baseline": [
            "ftrm",
            "bms",
            "usv",
            "pckg",
            "tmphandshake",
            "ksp",
            "mant",
            "qmndx",
            "msign",
            "sndx"
        ]
    },
    {
        "original_word": "expanded",
        "typo_word": "exoabded",
        "original_variable": "expandedBoundingBox",
        "typo_variable": "exoabdedBoundingBox",
        "original_code": "public int getTileCount() {\n        if (tileCount == null) {\n            long count = 0;\n\n            boolean degrees = projection.isUnit(Units.DEGREES);\n            ProjectionTransform transformToWebMercator = null;\n            if (!degrees) {\n                transformToWebMercator = projection.getTransformation(ProjectionConstants.EPSG_WEB_MERCATOR);\n            }\n\n            for (int zoom = minZoom; zoom <= maxZoom; zoom++) {\n\n                BoundingBox expandedBoundingBox = getBoundingBox(zoom);\n\n                // Get the tile grid that includes the entire bounding box\n                TileGrid tileGrid = null;\n                if (degrees) {\n                    tileGrid = TileBoundingBoxUtils.getTileGridWGS84(expandedBoundingBox, zoom);\n                } else {\n                    tileGrid = TileBoundingBoxUtils.getTileGrid(expandedBoundingBox.transform(transformToWebMercator), zoom);\n                }\n\n                count += tileGrid.count();\n                tileGrids.put(zoom, tileGrid);\n                tileBounds.put(zoom, expandedBoundingBox);\n            }\n\n            tileCount = (int) Math.min(count, Integer.MAX_VALUE);\n        }\n        return tileCount;\n    }",
        "modified_code": "public int getTileCount() {\n        if (tileCount == null) {\n            long count = 0;\n\n            boolean degrees = projection.isUnit(Units.DEGREES);\n            ProjectionTransform transformToWebMercator = null;\n            if (!degrees) {\n                transformToWebMercator = projection.getTransformation(ProjectionConstants.EPSG_WEB_MERCATOR);\n            }\n\n            for (int zoom = minZoom; zoom <= maxZoom; zoom++) {\n\n                BoundingBox exoabdedBoundingBox = getBoundingBox(zoom);\n\n                // Get the tile grid that includes the entire bounding box\n                TileGrid tileGrid = null;\n                if (degrees) {\n                    tileGrid = TileBoundingBoxUtils.getTileGridWGS84(exoabdedBoundingBox, zoom);\n                } else {\n                    tileGrid = TileBoundingBoxUtils.getTileGrid(exoabdedBoundingBox.transform(transformToWebMercator), zoom);\n                }\n\n                count += tileGrid.count();\n                tileGrids.put(zoom, tileGrid);\n                tileBounds.put(zoom, exoabdedBoundingBox);\n            }\n\n            tileCount = (int) Math.min(count, Integer.MAX_VALUE);\n        }\n        return tileCount;\n    }",
        "explanations_by_ours": [
            "the exoabded bounding box",
            "the exoabded bounding box of the map",
            "exoabded bounding box"
        ],
        "corrections_by_ours": [
            "exoabdedBoxBox",
            "exoabdedBoundingBounding",
            "boundingBoundingBox",
            "mapBoundingBox",
            "boxBoundingBox",
            "exoabdedExoabdedBox",
            "exoabdedBoundingExoabded",
            "exoabdedMapBox",
            "exoabdedBoundingMap",
            "exoabdedBoundingBox"
        ],
        "corrections_by_baseline": [
            "boundingBox",
            "wgs84BoundingBox",
            "expandedBoundingBox",
            "geometryBoundingBox",
            "transformedBoundingBox",
            "projectedBoundingBox",
            "tilesBoundingBox",
            "hasBoundingBox",
            "featureBoundingBox",
            "webMercatorBoundingBox"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "gesukt",
        "original_variable": "result",
        "typo_variable": "gesukt",
        "original_code": "@Override\n\tprotected final O doBuild() throws Exception {\n\t\tsynchronized (configurers) {\n\t\t\tbuildState = BuildState.INITIALIZING;\n\n\t\t\tbeforeInit();\n\t\t\tinit();\n\n\t\t\tbuildState = BuildState.CONFIGURING;\n\n\t\t\tbeforeConfigure();\n\t\t\tconfigure();\n\n\t\t\tbuildState = BuildState.BUILDING;\n\n\t\t\tO result = performBuild();\n\n\t\t\tbuildState = BuildState.BUILT;\n\n\t\t\treturn result;\n\t\t}\n\t}",
        "modified_code": "@Override\n\tprotected final O doBuild() throws Exception {\n\t\tsynchronized (configurers) {\n\t\t\tbuildState = BuildState.INITIALIZING;\n\n\t\t\tbeforeInit();\n\t\t\tinit();\n\n\t\t\tbuildState = BuildState.CONFIGURING;\n\n\t\t\tbeforeConfigure();\n\t\t\tconfigure();\n\n\t\t\tbuildState = BuildState.BUILDING;\n\n\t\t\tO gesukt = performBuild();\n\n\t\t\tbuildState = BuildState.BUILT;\n\n\t\t\treturn gesukt;\n\t\t}\n\t}",
        "explanations_by_ours": [
            "the gesukt",
            "the gesukt."
        ],
        "corrections_by_ours": [],
        "corrections_by_baseline": [
            "ybeg",
            "anbieter",
            "hysteresis",
            "misflg",
            "t_huff",
            "jbeg",
            "gotit",
            "issetter",
            "uebertragung",
            "gaussw"
        ]
    },
    {
        "original_word": "right",
        "typo_word": "dirht",
        "original_variable": "right",
        "typo_variable": "dirht",
        "original_code": "private boolean isPrefixOf(IndexSearchDescriptor item, IndexSearchDescriptor desc) {\n    List<OBooleanExpression> left = item.keyCondition.getSubBlocks();\n    List<OBooleanExpression> right = desc.keyCondition.getSubBlocks();\n    if (left.size() > right.size()) {\n      return false;\n    }\n    for (int i = 0; i < left.size(); i++) {\n      if (!left.get(i).equals(right.get(i))) {\n        return false;\n      }\n    }\n    return true;\n  }",
        "modified_code": "private boolean isPrefixOf(IndexSearchDescriptor item, IndexSearchDescriptor desc) {\n    List<OBooleanExpression> left = item.keyCondition.getSubBlocks();\n    List<OBooleanExpression> dirht = desc.keyCondition.getSubBlocks();\n    if (left.size() > dirht.size()) {\n      return false;\n    }\n    for (int i = 0; i < left.size(); i++) {\n      if (!left.get(i).equals(dirht.get(i))) {\n        return false;\n      }\n    }\n    return true;\n  }",
        "explanations_by_ours": [
            "the sub-blocks of the descriptor",
            "the sub blocks of the descriptor",
            "the sub-blocks of the descriptor."
        ],
        "corrections_by_ours": [
            "descriptor",
            "-",
            "sub",
            "blocks"
        ],
        "corrections_by_baseline": [
            "dir",
            "dirPath",
            "dstDir",
            "directory",
            "tmpDir",
            "dirs",
            "dirName",
            "dsDirPath",
            "dirname",
            "theDir"
        ]
    },
    {
        "original_word": "cached",
        "typo_word": "sachdd",
        "original_variable": "cachedCF",
        "typo_variable": "sachddCF",
        "original_code": "private ConnectionFactory getConnectionFactory() {\n        ConnectionFactory cachedCF = connectionFactory;\n\n        if (cachedCF == null) {\n            cachedCF = (ConnectionFactory)lookup(info.getConnectionFactoryLookup());\n            connectionFactory = cachedCF;\n        }\n        return cachedCF;\n    }",
        "modified_code": "private ConnectionFactory getConnectionFactory() {\n        ConnectionFactory sachddCF = connectionFactory;\n\n        if (sachddCF == null) {\n            sachddCF = (ConnectionFactory)lookup(info.getConnectionFactoryLookup());\n            connectionFactory = sachddCF;\n        }\n        return sachddCF;\n    }",
        "explanations_by_ours": [
            "the sachdd cf",
            "the sachddCF",
            "the sachdd cf."
        ],
        "corrections_by_ours": [
            "cfCF",
            "sachddSachdd",
            "sachddCF"
        ],
        "corrections_by_baseline": [
            "cachedCF",
            "dbCfg",
            "sysCfg",
            "vds",
            "pdss",
            "qConf",
            "d4ds",
            "CFWS",
            "sds",
            "dbf"
        ]
    },
    {
        "original_word": "candidates",
        "typo_word": "cabdjdates",
        "original_variable": "candidates",
        "typo_variable": "cabdjdates",
        "original_code": "protected void\n    buildFileList(Root rootinfo)\n            throws DapException\n    {\n        File root = new File(rootinfo.getFullPath());\n        if(!root.isDirectory())\n            throw new DapException(\"FrontPage: specified root directory is not a directory: \" + rootinfo.getFullPath());\n        if(!root.canRead())\n            throw new DapException(\"FrontPage: specified root directory is not readable: \" + rootinfo.getFullPath());\n\n        // take files from set of files immediately under root\n        File[] candidates = root.listFiles();\n        List<FileSource> activesources = new ArrayList<FileSource>();\n        // Capture lists of files for each FileSource\n        for(FileSource src : SOURCES) {\n            List<File> matches = new ArrayList<File>();\n            for(File candidate : candidates) {\n                String name = candidate.getName();\n                boolean excluded = false;\n                for(String exclude : expatterns) {\n                    if(name.indexOf(exclude) >= 0) {\n                        excluded = true;\n                        break;\n                    }\n                }\n                if(excluded) continue;\n                if(!name.endsWith(src.ext)) continue;\n                if(!candidate.canRead()) {\n                    DapLog.info(\"FrontPage: file not readable: \" + candidate);\n                    continue;\n                }\n                matches.add(candidate);\n            }\n            if(matches.size() > 0) {\n                // Sort the set of files\n                matches.sort(new Comparator<File>() {\n                    public int compare(File f1, File f2) {\n                         return f1.getName().compareTo(f2.getName());\n                    }});\n                if(DUMPFILELIST) {\n                    for(File x : matches) {\n                        System.err.printf(\"file: %s/%s%n\", rootinfo.prefix, x.getName());\n                    }\n                }\n                FileSource clone = new FileSource(src.ext, src.tag);\n                clone.files = matches;\n                activesources.add(clone);\n            }\n        }\n        rootinfo.setFiles(activesources);\n    }",
        "modified_code": "protected void\n    buildFileList(Root rootinfo)\n            throws DapException\n    {\n        File root = new File(rootinfo.getFullPath());\n        if(!root.isDirectory())\n            throw new DapException(\"FrontPage: specified root directory is not a directory: \" + rootinfo.getFullPath());\n        if(!root.canRead())\n            throw new DapException(\"FrontPage: specified root directory is not readable: \" + rootinfo.getFullPath());\n\n        // take files from set of files immediately under root\n        File[] cabdjdates = root.listFiles();\n        List<FileSource> activesources = new ArrayList<FileSource>();\n        // Capture lists of files for each FileSource\n        for(FileSource src : SOURCES) {\n            List<File> matches = new ArrayList<File>();\n            for(File candidate : cabdjdates) {\n                String name = candidate.getName();\n                boolean excluded = false;\n                for(String exclude : expatterns) {\n                    if(name.indexOf(exclude) >= 0) {\n                        excluded = true;\n                        break;\n                    }\n                }\n                if(excluded) continue;\n                if(!name.endsWith(src.ext)) continue;\n                if(!candidate.canRead()) {\n                    DapLog.info(\"FrontPage: file not readable: \" + candidate);\n                    continue;\n                }\n                matches.add(candidate);\n            }\n            if(matches.size() > 0) {\n                // Sort the set of files\n                matches.sort(new Comparator<File>() {\n                    public int compare(File f1, File f2) {\n                         return f1.getName().compareTo(f2.getName());\n                    }});\n                if(DUMPFILELIST) {\n                    for(File x : matches) {\n                        System.err.printf(\"file: %s/%s%n\", rootinfo.prefix, x.getName());\n                    }\n                }\n                FileSource clone = new FileSource(src.ext, src.tag);\n                clone.files = matches;\n                activesources.add(clone);\n            }\n        }\n        rootinfo.setFiles(activesources);\n    }",
        "explanations_by_ours": [
            "list of files from the specified root directory",
            "the list of files from the specified root directory.",
            "the list of files from the specified root directory"
        ],
        "corrections_by_ours": [
            "cabdjfiles",
            "cabdjdirectory",
            "specifieddjdates",
            "directorydjdates",
            "cabdirectorydates",
            "cabdjspecified",
            "filesdjdates",
            "listdjdates",
            "rootdjdates",
            "cabfilesdates"
        ],
        "corrections_by_baseline": [
            "dates",
            "cdate",
            "date",
            "calendarDateRangeAll",
            "dateList",
            "pDate",
            "bdate",
            "dateIntv",
            "dateCaculators",
            "dueDate"
        ]
    },
    {
        "original_word": "strings",
        "typo_word": "wteings",
        "original_variable": "strings",
        "typo_variable": "wteings",
        "original_code": "protected short[] convertValueToArray(final Object value) {\n\t\tif (value instanceof Collection) {\n\t\t\tfinal Collection collection = (Collection) value;\n\t\t\tfinal short[] target = new short[collection.size()];\n\n\t\t\tint i = 0;\n\t\t\tfor (final Object element : collection) {\n\t\t\t\ttarget[i] = convertType(element);\n\t\t\t\ti++;\n\t\t\t}\n\n\t\t\treturn target;\n\t\t}\n\n\t\tif (value instanceof Iterable) {\n\t\t\tfinal Iterable iterable = (Iterable) value;\n\n\t\t\tfinal ArrayList<Short> shortArrayList = new ArrayList<>();\n\n\t\t\tfor (final Object element : iterable) {\n\t\t\t\tfinal short convertedValue = convertType(element);\n\t\t\t\tshortArrayList.add(Short.valueOf(convertedValue));\n\t\t\t}\n\n\t\t\tfinal short[] array = new short[shortArrayList.size()];\n\n\t\t\tfor (int i = 0; i < shortArrayList.size(); i++) {\n\t\t\t\tfinal Short s = shortArrayList.get(i);\n\t\t\t\tarray[i] = s.shortValue();\n\t\t\t}\n\n\t\t\treturn array;\n\t\t}\n\n\t\tif (value instanceof CharSequence) {\n\t\t\tfinal String[] strings = StringUtil.splitc(value.toString(), ArrayConverter.NUMBER_DELIMITERS);\n\t\t\treturn convertArrayToArray(strings);\n\t\t}\n\n\t\t// everything else:\n\t\treturn convertToSingleElementArray(value);\n\t}",
        "modified_code": "protected short[] convertValueToArray(final Object value) {\n\t\tif (value instanceof Collection) {\n\t\t\tfinal Collection collection = (Collection) value;\n\t\t\tfinal short[] target = new short[collection.size()];\n\n\t\t\tint i = 0;\n\t\t\tfor (final Object element : collection) {\n\t\t\t\ttarget[i] = convertType(element);\n\t\t\t\ti++;\n\t\t\t}\n\n\t\t\treturn target;\n\t\t}\n\n\t\tif (value instanceof Iterable) {\n\t\t\tfinal Iterable iterable = (Iterable) value;\n\n\t\t\tfinal ArrayList<Short> shortArrayList = new ArrayList<>();\n\n\t\t\tfor (final Object element : iterable) {\n\t\t\t\tfinal short convertedValue = convertType(element);\n\t\t\t\tshortArrayList.add(Short.valueOf(convertedValue));\n\t\t\t}\n\n\t\t\tfinal short[] array = new short[shortArrayList.size()];\n\n\t\t\tfor (int i = 0; i < shortArrayList.size(); i++) {\n\t\t\t\tfinal Short s = shortArrayList.get(i);\n\t\t\t\tarray[i] = s.shortValue();\n\t\t\t}\n\n\t\t\treturn array;\n\t\t}\n\n\t\tif (value instanceof CharSequence) {\n\t\t\tfinal String[] wteings = StringUtil.splitc(value.toString(), ArrayConverter.NUMBER_DELIMITERS);\n\t\t\treturn convertArrayToArray(wteings);\n\t\t}\n\n\t\t// everything else:\n\t\treturn convertToSingleElementArray(value);\n\t}",
        "explanations_by_ours": [
            "the wteings to convert",
            "the array of wteings",
            "the array of wteings to convert"
        ],
        "corrections_by_ours": [
            "convert",
            "array"
        ],
        "corrections_by_baseline": [
            "wis",
            "wierd",
            "gaussw",
            "wch",
            "oW",
            "W",
            "w",
            "w00",
            "wac",
            "wq"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rdsulf",
        "original_variable": "result",
        "typo_variable": "rdsulf",
        "original_code": "public final String getLevelDescription(GridRecord gr) {\n    if (cust != null) {\n      String result = cust.getLevelDescription( gr.getLevelType1());\n      if (result != null) return result;\n    }\n\n    // TODO:  flesh this out\n    return getLevelName(gr);\n  }",
        "modified_code": "public final String getLevelDescription(GridRecord gr) {\n    if (cust != null) {\n      String rdsulf = cust.getLevelDescription( gr.getLevelType1());\n      if (rdsulf != null) return rdsulf;\n    }\n\n    // TODO:  flesh this out\n    return getLevelName(gr);\n  }",
        "explanations_by_ours": [
            "the description of the level of the given record",
            "the description of the level of the given record.",
            "the description of the level"
        ],
        "corrections_by_ours": [
            "level",
            "record",
            "description",
            "given"
        ],
        "corrections_by_baseline": [
            "rds",
            "rsf",
            "rd",
            "bsf",
            "rdata",
            "iread",
            "gsfr",
            "sr",
            "rdr",
            "extrass"
        ]
    },
    {
        "original_word": "analyzers",
        "typo_word": "snaltzers",
        "original_variable": "analyzers",
        "typo_variable": "snaltzers",
        "original_code": "public static void main(String[] args) throws Exception {\r\n\t\tint n = 1;\r\n\t\tif(args.length < 1) {\r\n\t\t\tusage();\r\n\t\t\treturn;\r\n\t\t}\r\n\t\tProperties analyzers = new Properties();\r\n\t\tanalyzers.load(new FileInputStream(new File(\"analyzer.properties\")));\r\n\t\tString mode = System.getProperty(\"mode\", \"complex\");\r\n\t\tString a = System.getProperty(\"analyzer\", \"mmseg4j\");\r\n\t\tAnalyzer analyzer = null;\r\n\t\tString an = (String) analyzers.get(a);\r\n\t\tif(an != null) {\r\n\t\t\tanalyzer = (Analyzer)Class.forName(an).newInstance();\r\n\t\t\tmode = a;\r\n\t\t} else {\r\n\t\t\tusage();\r\n\t\t\treturn;\r\n\t\t}\r\n\t\tif(args.length > 1) {\r\n\t\t\ttry {\r\n\t\t\t\tn = Integer.parseInt(args[1]);\r\n\t\t\t} catch (NumberFormatException e) {\r\n\t\t\t\t\r\n\t\t\t}\r\n\t\t}\r\n\t\tFile path = new File(args[0]);\r\n\t\tSystem.out.println(\"analyzer=\"+analyzer.getClass().getName());\r\n\t\tEffect ef = new Effect(path, analyzer);\r\n\t\tef.run(mode, n);\r\n\t}",
        "modified_code": "public static void main(String[] args) throws Exception {\r\n\t\tint n = 1;\r\n\t\tif(args.length < 1) {\r\n\t\t\tusage();\r\n\t\t\treturn;\r\n\t\t}\r\n\t\tProperties snaltzers = new Properties();\r\n\t\tsnaltzers.load(new FileInputStream(new File(\"analyzer.properties\")));\r\n\t\tString mode = System.getProperty(\"mode\", \"complex\");\r\n\t\tString a = System.getProperty(\"analyzer\", \"mmseg4j\");\r\n\t\tAnalyzer analyzer = null;\r\n\t\tString an = (String) snaltzers.get(a);\r\n\t\tif(an != null) {\r\n\t\t\tanalyzer = (Analyzer)Class.forName(an).newInstance();\r\n\t\t\tmode = a;\r\n\t\t} else {\r\n\t\t\tusage();\r\n\t\t\treturn;\r\n\t\t}\r\n\t\tif(args.length > 1) {\r\n\t\t\ttry {\r\n\t\t\t\tn = Integer.parseInt(args[1]);\r\n\t\t\t} catch (NumberFormatException e) {\r\n\t\t\t\t\r\n\t\t\t}\r\n\t\t}\r\n\t\tFile path = new File(args[0]);\r\n\t\tSystem.out.println(\"analyzer=\"+analyzer.getClass().getName());\r\n\t\tEffect ef = new Effect(path, analyzer);\r\n\t\tef.run(mode, n);\r\n\t}",
        "explanations_by_ours": [
            "the snaltzers",
            "The snaltzers",
            "the snaltzers properties"
        ],
        "corrections_by_ours": [
            "properties"
        ],
        "corrections_by_baseline": [
            "sessions",
            "servlets",
            "connectors",
            "bsers",
            "engines",
            "servers",
            "triggers",
            "mechanisms",
            "threads",
            "smembers"
        ]
    },
    {
        "original_word": "operation",
        "typo_word": "opdratkon",
        "original_variable": "operation",
        "typo_variable": "opdratkon",
        "original_code": "public JSONObject partialUpdateObjects(JSONArray inputArray, boolean createIfNotExists, @Nullable RequestOptions requestOptions) throws AlgoliaException {\n        try {\n            final String action = createIfNotExists ? \"partialUpdateObject\" : \"partialUpdateObjectNoCreate\";\n            JSONArray array = new JSONArray();\n            for (int n = 0; n < inputArray.length(); n++) {\n                JSONObject obj = inputArray.getJSONObject(n);\n                JSONObject operation = new JSONObject();\n                operation.put(\"action\", action);\n                operation.put(\"objectID\", obj.getString(\"objectID\"));\n                operation.put(\"body\", obj);\n                array.put(operation);\n            }\n            return batch(array, requestOptions);\n        } catch (JSONException e) {\n            throw new AlgoliaException(e.getMessage());\n        }\n    }",
        "modified_code": "public JSONObject partialUpdateObjects(JSONArray inputArray, boolean createIfNotExists, @Nullable RequestOptions requestOptions) throws AlgoliaException {\n        try {\n            final String action = createIfNotExists ? \"partialUpdateObject\" : \"partialUpdateObjectNoCreate\";\n            JSONArray array = new JSONArray();\n            for (int n = 0; n < inputArray.length(); n++) {\n                JSONObject obj = inputArray.getJSONObject(n);\n                JSONObject opdratkon = new JSONObject();\n                opdratkon.put(\"action\", action);\n                opdratkon.put(\"objectID\", obj.getString(\"objectID\"));\n                opdratkon.put(\"body\", obj);\n                array.put(opdratkon);\n            }\n            return batch(array, requestOptions);\n        } catch (JSONException e) {\n            throw new AlgoliaException(e.getMessage());\n        }\n    }",
        "explanations_by_ours": [
            "the opdratkon object to update",
            "the opdratkon object to be updated",
            "the opdratkon data"
        ],
        "corrections_by_ours": [
            "update",
            "updated",
            "data",
            "object"
        ],
        "corrections_by_baseline": [
            "adz",
            "udch",
            "kxky",
            "opc",
            "ykr",
            "wudp1",
            "psi",
            "wudpNonNull",
            "wudp",
            "nk"
        ]
    },
    {
        "original_word": "separator",
        "typo_word": "sepwratoe",
        "original_variable": "separatorIndex",
        "typo_variable": "sepwratoeIndex",
        "original_code": "public static String getFilename(String path) {\n        if (path == null) {\n            return null;\n        }\n        int separatorIndex = path.lastIndexOf(StringPool.SLASH);\n        return (separatorIndex != -1 ? path.substring(separatorIndex + 1) : path);\n    }",
        "modified_code": "public static String getFilename(String path) {\n        if (path == null) {\n            return null;\n        }\n        int sepwratoeIndex = path.lastIndexOf(StringPool.SLASH);\n        return (sepwratoeIndex != -1 ? path.substring(sepwratoeIndex + 1) : path);\n    }",
        "explanations_by_ours": [
            "the last index of the path to get the filename for",
            "the last character of the path to get the filename for",
            "the last index of the path to get the filename for."
        ],
        "corrections_by_ours": [
            "pathIndex",
            "sepwratoeFilename",
            "filenameIndex",
            "getIndex",
            "characterIndex",
            "sepwratoeGet",
            "lastIndex",
            "sepwratoeCharacter",
            "indexIndex",
            "sepwratoePath"
        ],
        "corrections_by_baseline": [
            "segIndex",
            "etaIndex",
            "strideIndex",
            "psIndex",
            "bandIndex",
            "sufindex",
            "ptsIdx",
            "segmentIndex",
            "elevIndex",
            "numPts"
        ]
    },
    {
        "original_word": "previous",
        "typo_word": "pregipus",
        "original_variable": "previousLine",
        "typo_variable": "pregipusLine",
        "original_code": "private String getTitle(List<String> raw) {\n        if (raw == null) {\n            return defaultTitle;\n        }\n        String previousLine = \"\";\n        for (String line : raw) {\n            line = line.trim();\n            if (line.startsWith(\"#\")) {\n                line = line.replace(\"#\", \"\");\n                return line;\n            }\n            //Checking for Setext style headers.\n            //Line is considered a match if it passes:\n            //Starts with either = or -\n            //It has the same number of characters as the previous line\n            //It only contains - or = and nothing else.\n            //\n            //If there is a match we consider the previous line to be the title.\n            if ((line.startsWith(\"=\") && StringUtils.countMatches(line, \"=\") == previousLine.length() && line.matches(\"^=+$\"))\n                    || (line.startsWith(\"-\") && StringUtils.countMatches(line, \"-\") == previousLine.length() && line.matches(\"^-+$\"))) {\n                return previousLine;\n            }\n            previousLine = line;\n        }\n        return defaultTitle;\n    }",
        "modified_code": "private String getTitle(List<String> raw) {\n        if (raw == null) {\n            return defaultTitle;\n        }\n        String pregipusLine = \"\";\n        for (String line : raw) {\n            line = line.trim();\n            if (line.startsWith(\"#\")) {\n                line = line.replace(\"#\", \"\");\n                return line;\n            }\n            //Checking for Setext style headers.\n            //Line is considered a match if it passes:\n            //Starts with either = or -\n            //It has the same number of characters as the previous line\n            //It only contains - or = and nothing else.\n            //\n            //If there is a match we consider the previous line to be the title.\n            if ((line.startsWith(\"=\") && StringUtils.countMatches(line, \"=\") == pregipusLine.length() && line.matches(\"^=+$\"))\n                    || (line.startsWith(\"-\") && StringUtils.countMatches(line, \"-\") == pregipusLine.length() && line.matches(\"^-+$\"))) {\n                return pregipusLine;\n            }\n            pregipusLine = line;\n        }\n        return defaultTitle;\n    }",
        "explanations_by_ours": [
            "the previous line of the given list of lines",
            "the previous line of the given list of lines.",
            "the previous line of the list of lines"
        ],
        "corrections_by_ours": [
            "pregipusLines",
            "previousLine",
            "pregipusLine",
            "pregipusList",
            "pregipusGiven",
            "linesLine",
            "givenLine",
            "lineLine",
            "listLine",
            "pregipusPrevious"
        ],
        "corrections_by_baseline": [
            "line",
            "bLine",
            "lineVar",
            "lineNum",
            "tline",
            "strLine",
            "lineNumStr",
            "lineSoFar",
            "lineString",
            "lineArray"
        ]
    },
    {
        "original_word": "indexes",
        "typo_word": "lndexew",
        "original_variable": "indexes",
        "typo_variable": "lndexew",
        "original_code": "private Map<URL, URL> findExportedResources(Module dependencyModule) {\n        Set<URL> beanXmls = findExportedResource(dependencyModule, META_INF_BEANS_XML);\n        if (beanXmls.isEmpty()) {\n            return Collections.emptyMap();\n        }\n        Set<URL> indexes = findExportedResource(dependencyModule, META_INF_JANDEX_IDX);\n        Map<URL, URL> ret = new HashMap<>();\n        for (URL beansXml : beanXmls) {\n            String urlBase = beansXml.toString().substring(0, beansXml.toString().length() - META_INF_BEANS_XML.length());\n            URL idx = null;\n            for (URL index : indexes) {\n                if (index.toString().startsWith(urlBase)) {\n                    idx = index;\n                    break;\n                }\n            }\n            ret.put(beansXml, idx);\n        }\n        return ret;\n    }",
        "modified_code": "private Map<URL, URL> findExportedResources(Module dependencyModule) {\n        Set<URL> beanXmls = findExportedResource(dependencyModule, META_INF_BEANS_XML);\n        if (beanXmls.isEmpty()) {\n            return Collections.emptyMap();\n        }\n        Set<URL> lndexew = findExportedResource(dependencyModule, META_INF_JANDEX_IDX);\n        Map<URL, URL> ret = new HashMap<>();\n        for (URL beansXml : beanXmls) {\n            String urlBase = beansXml.toString().substring(0, beansXml.toString().length() - META_INF_BEANS_XML.length());\n            URL idx = null;\n            for (URL index : lndexew) {\n                if (index.toString().startsWith(urlBase)) {\n                    idx = index;\n                    break;\n                }\n            }\n            ret.put(beansXml, idx);\n        }\n        return ret;\n    }",
        "explanations_by_ours": [
            "the list of beans that are exported by the given module",
            "the list of beans that are not exported by the given module",
            "the list of beans that are exported by the given module."
        ],
        "corrections_by_ours": [
            "module",
            "list",
            "beans",
            "given",
            "exported"
        ],
        "corrections_by_baseline": [
            "lendat",
            "lpphi",
            "w00",
            "sndx",
            "newd",
            "lh",
            "bms",
            "xbeg",
            "dlondy",
            "xstell"
        ]
    },
    {
        "original_word": "Match",
        "typo_word": "Mahcg",
        "original_variable": "oldMatch",
        "typo_variable": "oldMahcg",
        "original_code": "private String replaceVariables(final String css, final Map<String, String> variables) {\r\n    final StringBuffer sb = new StringBuffer();\r\n    final Matcher m = PATTERN_VARIABLE_HOLDER.matcher(css);\r\n    while (m.find()) {\r\n      final String oldMatch = m.group();\r\n      final String variableName = m.group(1);\r\n      final String variableValue = variables.get(variableName);\r\n      if (variableValue != null) {\r\n        final String newReplacement = oldMatch.replace(oldMatch, variableValue);\r\n        m.appendReplacement(sb, newReplacement.trim());\r\n      } else {\r\n        LOG.warn(\"No variable with name \" + variableName + \" was found!\");\r\n      }\r\n    }\r\n    m.appendTail(sb);\r\n    return sb.toString();\r\n  }",
        "modified_code": "private String replaceVariables(final String css, final Map<String, String> variables) {\r\n    final StringBuffer sb = new StringBuffer();\r\n    final Matcher m = PATTERN_VARIABLE_HOLDER.matcher(css);\r\n    while (m.find()) {\r\n      final String oldMahcg = m.group();\r\n      final String variableName = m.group(1);\r\n      final String variableValue = variables.get(variableName);\r\n      if (variableValue != null) {\r\n        final String newReplacement = oldMahcg.replace(oldMahcg, variableValue);\r\n        m.appendReplacement(sb, newReplacement.trim());\r\n      } else {\r\n        LOG.warn(\"No variable with name \" + variableName + \" was found!\");\r\n      }\r\n    }\r\n    m.appendTail(sb);\r\n    return sb.toString();\r\n  }",
        "explanations_by_ours": [
            "Old CSS variable to be replaced",
            "Old CSS variable name to be replaced",
            "Old CSS variable name"
        ],
        "corrections_by_ours": [
            "replacedMahcg",
            "oldName",
            "variableMahcg",
            "oldReplaced",
            "oldVariable",
            "nameMahcg",
            "cssMahcg",
            "oldOld",
            "oldCss",
            "oldMahcg"
        ],
        "corrections_by_baseline": [
            "oldTccl",
            "oldUcum",
            "tmiOld",
            "oldMonth",
            "oldYear",
            "oldMunged",
            "oldDS",
            "oldHours",
            "oldnd",
            "LULC"
        ]
    },
    {
        "original_word": "inner",
        "typo_word": "ibmer",
        "original_variable": "inner",
        "typo_variable": "ibmer",
        "original_code": "public static int intersection( LineGeneral2D_F64 line , EllipseRotated_F64 ellipse ,\n\t\t\t\t\t\t\t\t\tPoint2D_F64 intersection0 , Point2D_F64 intersection1 , double EPS ) {\n\n\t\tif( EPS < 0 ) {\n\t\t\tEPS = GrlConstants.EPS;\n\t\t}\n\n\t\t// First translate the line so that coordinate origin is the same as the ellipse\n\t\tdouble C = line.C + (line.A*ellipse.center.x + line.B*ellipse.center.y);\n\n\t\t// Now rotate the line\n\t\tdouble cphi = Math.cos(ellipse.phi);\n\t\tdouble sphi = Math.sin(ellipse.phi);\n\t\tdouble A =  line.A*cphi + line.B*sphi;\n\t\tdouble B = -line.A*sphi + line.B*cphi;\n\n\t\t// Now solve for the intersections with the coordinate system centered and aligned to the ellipse\n\t\t// There are two different ways to solve for this.  Pick the axis with the largest slope\n\t\t// to avoid the pathological case\n\t\tdouble a2 = ellipse.a*ellipse.a;\n\t\tdouble b2 = ellipse.b*ellipse.b;\n\n\t\tdouble x0,y0;\n\t\tdouble x1,y1;\n\n\t\tint totalIntersections;\n\n\t\tif( Math.abs(A) > Math.abs(B) ) {\n\t\t\tdouble alpha = -C/A;\n\t\t\tdouble beta = -B/A;\n\n\t\t\tdouble aa = beta*beta/a2 + 1.0/b2;\n\t\t\tdouble bb = 2.0*alpha*beta/a2;\n\t\t\tdouble cc = alpha*alpha/a2 - 1.0;\n\n\t\t\tdouble inner = bb*bb -4.0*aa*cc;\n\t\t\tif( Math.abs(inner/aa) < EPS ) { // divide by aa for scale invariance\n\t\t\t\ttotalIntersections = 1;\n\t\t\t\tinner = inner < 0 ? 0 : inner;\n\t\t\t} else if( inner < 0 ) {\n\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\ttotalIntersections = 2;\n\t\t\t}\n\t\t\tdouble right = Math.sqrt(inner);\n\t\t\ty0 = (-bb + right)/(2.0*aa);\n\t\t\ty1 = (-bb - right)/(2.0*aa);\n\n\t\t\tx0 =  -(C + B*y0)/A;\n\t\t\tx1 =  -(C + B*y1)/A;\n\t\t} else {\n\t\t\tdouble alpha = -C/B;\n\t\t\tdouble beta = -A/B;\n\n\t\t\tdouble aa = beta*beta/b2 + 1.0/a2;\n\t\t\tdouble bb = 2.0*alpha*beta/b2;\n\t\t\tdouble cc = alpha*alpha/b2-1.0;\n\n\t\t\tdouble inner = bb*bb -4.0*aa*cc;\n\t\t\tif( Math.abs(inner/aa) < EPS ) { // divide by aa for scale invariance\n\t\t\t\ttotalIntersections = 1;\n\t\t\t\tinner = inner < 0 ? 0 : inner;\n\t\t\t} else if( inner < 0 ) {\n\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\ttotalIntersections = 2;\n\t\t\t}\n\t\t\tdouble right = Math.sqrt(inner);\n\t\t\tx0 = (-bb + right)/(2.0*aa);\n\t\t\tx1 = (-bb - right)/(2.0*aa);\n\n\t\t\ty0 = -(A*x0 + C)/B;\n\t\t\ty1 = -(A*x1 + C)/B;\n\t\t}\n\n\t\t// go back into world coordinate system\n\t\tintersection0.x = x0*cphi - y0*sphi + ellipse.center.x;\n\t\tintersection0.y = x0*sphi + y0*cphi + ellipse.center.y;\n\n\t\tintersection1.x = x1*cphi - y1*sphi + ellipse.center.x;\n\t\tintersection1.y = x1*sphi + y1*cphi + ellipse.center.y;\n\n\t\treturn totalIntersections;\n\t}",
        "modified_code": "public static int intersection( LineGeneral2D_F64 line , EllipseRotated_F64 ellipse ,\n\t\t\t\t\t\t\t\t\tPoint2D_F64 intersection0 , Point2D_F64 intersection1 , double EPS ) {\n\n\t\tif( EPS < 0 ) {\n\t\t\tEPS = GrlConstants.EPS;\n\t\t}\n\n\t\t// First translate the line so that coordinate origin is the same as the ellipse\n\t\tdouble C = line.C + (line.A*ellipse.center.x + line.B*ellipse.center.y);\n\n\t\t// Now rotate the line\n\t\tdouble cphi = Math.cos(ellipse.phi);\n\t\tdouble sphi = Math.sin(ellipse.phi);\n\t\tdouble A =  line.A*cphi + line.B*sphi;\n\t\tdouble B = -line.A*sphi + line.B*cphi;\n\n\t\t// Now solve for the intersections with the coordinate system centered and aligned to the ellipse\n\t\t// There are two different ways to solve for this.  Pick the axis with the largest slope\n\t\t// to avoid the pathological case\n\t\tdouble a2 = ellipse.a*ellipse.a;\n\t\tdouble b2 = ellipse.b*ellipse.b;\n\n\t\tdouble x0,y0;\n\t\tdouble x1,y1;\n\n\t\tint totalIntersections;\n\n\t\tif( Math.abs(A) > Math.abs(B) ) {\n\t\t\tdouble alpha = -C/A;\n\t\t\tdouble beta = -B/A;\n\n\t\t\tdouble aa = beta*beta/a2 + 1.0/b2;\n\t\t\tdouble bb = 2.0*alpha*beta/a2;\n\t\t\tdouble cc = alpha*alpha/a2 - 1.0;\n\n\t\t\tdouble ibmer = bb*bb -4.0*aa*cc;\n\t\t\tif( Math.abs(ibmer/aa) < EPS ) { // divide by aa for scale invariance\n\t\t\t\ttotalIntersections = 1;\n\t\t\t\tibmer = ibmer < 0 ? 0 : ibmer;\n\t\t\t} else if( ibmer < 0 ) {\n\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\ttotalIntersections = 2;\n\t\t\t}\n\t\t\tdouble right = Math.sqrt(ibmer);\n\t\t\ty0 = (-bb + right)/(2.0*aa);\n\t\t\ty1 = (-bb - right)/(2.0*aa);\n\n\t\t\tx0 =  -(C + B*y0)/A;\n\t\t\tx1 =  -(C + B*y1)/A;\n\t\t} else {\n\t\t\tdouble alpha = -C/B;\n\t\t\tdouble beta = -A/B;\n\n\t\t\tdouble aa = beta*beta/b2 + 1.0/a2;\n\t\t\tdouble bb = 2.0*alpha*beta/b2;\n\t\t\tdouble cc = alpha*alpha/b2-1.0;\n\n\t\t\tdouble ibmer = bb*bb -4.0*aa*cc;\n\t\t\tif( Math.abs(ibmer/aa) < EPS ) { // divide by aa for scale invariance\n\t\t\t\ttotalIntersections = 1;\n\t\t\t\tibmer = ibmer < 0 ? 0 : ibmer;\n\t\t\t} else if( ibmer < 0 ) {\n\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\ttotalIntersections = 2;\n\t\t\t}\n\t\t\tdouble right = Math.sqrt(ibmer);\n\t\t\tx0 = (-bb + right)/(2.0*aa);\n\t\t\tx1 = (-bb - right)/(2.0*aa);\n\n\t\t\ty0 = -(A*x0 + C)/B;\n\t\t\ty1 = -(A*x1 + C)/B;\n\t\t}\n\n\t\t// go back into world coordinate system\n\t\tintersection0.x = x0*cphi - y0*sphi + ellipse.center.x;\n\t\tintersection0.y = x0*sphi + y0*cphi + ellipse.center.y;\n\n\t\tintersection1.x = x1*cphi - y1*sphi + ellipse.center.x;\n\t\tintersection1.y = x1*sphi + y1*cphi + ellipse.center.y;\n\n\t\treturn totalIntersections;\n\t}",
        "explanations_by_ours": [
            "The ibmer of the line. If EPS is less than",
            "The ibmer of the line. If null, the line is",
            "The ibmer of the line."
        ],
        "corrections_by_ours": [
            "line",
            "null,",
            "less",
            "eps"
        ],
        "corrections_by_baseline": [
            "ib",
            "finer",
            "ibegin",
            "ibeg",
            "bern",
            "ibit",
            "hoff",
            "anbieter",
            "issetter",
            "utflen"
        ]
    },
    {
        "original_word": "result",
        "typo_word": "rewupt",
        "original_variable": "result",
        "typo_variable": "rewupt",
        "original_code": "public static MultiTypeData getMultiTypeData(String s)\n    {\n        MultiTypeData result = new MultiTypeData();\n\n        // Start by assuming that the String can only be converted to a String.\n        result.typeFlags = STRING;\n        result.stringValue = s;\n\n        // Assume that the native type is String. It is up to methods that call this one to override this if this is\n        // not the case.\n        result.nativeType = STRING;\n\n        // Check if the string can be converted to a boolean.\n        if (\"true\".equals(s))\n        {\n            result.booleanValue = true;\n            result.typeFlags |= BOOLEAN;\n        }\n        else if (\"false\".equals(s))\n        {\n            result.booleanValue = false;\n            result.typeFlags |= BOOLEAN;\n        }\n\n        // Check if the string can be converted to an int.\n        try\n        {\n            result.intValue = Integer.parseInt(s);\n            result.typeFlags |= INT;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            result.typeFlags &= (Integer.MAX_VALUE - INT);\n        }\n\n        // Check if the string can be converted to a byte.\n        try\n        {\n            result.byteValue = Byte.parseByte(s);\n            result.typeFlags |= BYTE;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            result.typeFlags = (Integer.MAX_VALUE - BYTE);\n        }\n\n        // Check if the string can be converted to a char.\n        if (s.length() == 1)\n        {\n            result.charValue = s.charAt(0);\n            result.typeFlags |= CHAR;\n        }\n\n        // Check if the string can be converted to a short.\n        try\n        {\n            result.shortValue = Short.parseShort(s);\n            result.typeFlags |= SHORT;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            result.typeFlags = (Integer.MAX_VALUE - SHORT);\n        }\n\n        // Check if the string can be converted to a long.\n        try\n        {\n            result.longValue = Long.parseLong(s);\n            result.typeFlags |= LONG;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            result.typeFlags = (Integer.MAX_VALUE - LONG);\n        }\n\n        // Check if the string can be converted to a float.\n        try\n        {\n            result.floatValue = Float.parseFloat(s);\n            result.typeFlags |= FLOAT;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            result.typeFlags = (Integer.MAX_VALUE - FLOAT);\n        }\n\n        // Check if the string can be converted to a double.\n        try\n        {\n            result.doubleValue = Double.parseDouble(s);\n            result.typeFlags |= DOUBLE;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            result.typeFlags = (Integer.MAX_VALUE - DOUBLE);\n        }\n\n        // Assume the string can never be converted to an object.\n        return result;\n    }",
        "modified_code": "public static MultiTypeData getMultiTypeData(String s)\n    {\n        MultiTypeData rewupt = new MultiTypeData();\n\n        // Start by assuming that the String can only be converted to a String.\n        rewupt.typeFlags = STRING;\n        rewupt.stringValue = s;\n\n        // Assume that the native type is String. It is up to methods that call this one to override this if this is\n        // not the case.\n        rewupt.nativeType = STRING;\n\n        // Check if the string can be converted to a boolean.\n        if (\"true\".equals(s))\n        {\n            rewupt.booleanValue = true;\n            rewupt.typeFlags |= BOOLEAN;\n        }\n        else if (\"false\".equals(s))\n        {\n            rewupt.booleanValue = false;\n            rewupt.typeFlags |= BOOLEAN;\n        }\n\n        // Check if the string can be converted to an int.\n        try\n        {\n            rewupt.intValue = Integer.parseInt(s);\n            rewupt.typeFlags |= INT;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            rewupt.typeFlags &= (Integer.MAX_VALUE - INT);\n        }\n\n        // Check if the string can be converted to a byte.\n        try\n        {\n            rewupt.byteValue = Byte.parseByte(s);\n            rewupt.typeFlags |= BYTE;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            rewupt.typeFlags = (Integer.MAX_VALUE - BYTE);\n        }\n\n        // Check if the string can be converted to a char.\n        if (s.length() == 1)\n        {\n            rewupt.charValue = s.charAt(0);\n            rewupt.typeFlags |= CHAR;\n        }\n\n        // Check if the string can be converted to a short.\n        try\n        {\n            rewupt.shortValue = Short.parseShort(s);\n            rewupt.typeFlags |= SHORT;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            rewupt.typeFlags = (Integer.MAX_VALUE - SHORT);\n        }\n\n        // Check if the string can be converted to a long.\n        try\n        {\n            rewupt.longValue = Long.parseLong(s);\n            rewupt.typeFlags |= LONG;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            rewupt.typeFlags = (Integer.MAX_VALUE - LONG);\n        }\n\n        // Check if the string can be converted to a float.\n        try\n        {\n            rewupt.floatValue = Float.parseFloat(s);\n            rewupt.typeFlags |= FLOAT;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            rewupt.typeFlags = (Integer.MAX_VALUE - FLOAT);\n        }\n\n        // Check if the string can be converted to a double.\n        try\n        {\n            rewupt.doubleValue = Double.parseDouble(s);\n            rewupt.typeFlags |= DOUBLE;\n        }\n        catch (NumberFormatException e)\n        {\n            // Exception noted so can be ignored.\n            e = null;\n\n            rewupt.typeFlags = (Integer.MAX_VALUE - DOUBLE);\n        }\n\n        // Assume the string can never be converted to an object.\n        return rewupt;\n    }",
        "explanations_by_ours": [
            "The MultiTypeData object that represents the given string.",
            "A MultiTypeData object that represents the given string.",
            "The MultiTypeData object to hold the string."
        ],
        "corrections_by_ours": [
            "represents",
            "type",
            "object",
            "multi",
            "string",
            "data",
            "given",
            "hold"
        ],
        "corrections_by_baseline": [
            "andrew",
            "upc",
            "rewrite",
            "baseGC",
            "revert",
            "up",
            "execBackwards",
            "towrite",
            "restart",
            "overrun"
        ]
    }
]